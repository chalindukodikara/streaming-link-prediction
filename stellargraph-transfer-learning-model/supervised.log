2023-03-20 20:03:00,484 : [WARNING]  ####################################### New Training Session #######################################
2023-03-20 20:03:00,484 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 5, number of timestamps 101
2023-03-20 20:03:04,156 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-20 20:03:04,156 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-20 20:03:05,694 : [INFO]  Model initialized for training
2023-03-20 20:03:16,132 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:03:16,350 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:03:18,390 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:03:18,625 : [INFO]  Number of training examples - 11796, Number of testing examples 13106
2023-03-20 20:03:18,626 : [INFO]  Connected to the server
2023-03-20 20:03:18,626 : [INFO]  Accepted new connection at 127.0.0.1:35272
2023-03-20 20:03:18,631 : [INFO]  Initial training round 0: aggregated global model sent to client-new at 127.0.0.1:35272
2023-03-20 20:03:18,724 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:03:18,733 : [INFO]  _____________________________________________________ Initial model training started ____________________________________________________________
2023-03-20 20:03:18,734 : [INFO]  _____________________________________________________ Initial model training: training round 1 ____________________________________________________________
2023-03-20 20:03:55,444 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 1 ____________________________________________________________
2023-03-20 20:03:55,682 : [ERROR]  Client-new closed connection at 127.0.0.1:35272
2023-03-20 20:05:26,558 : [WARNING]  ####################################### New Training Session #######################################
2023-03-20 20:05:26,559 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 5, number of timestamps 101
2023-03-20 20:05:27,569 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-20 20:05:27,570 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-20 20:05:29,124 : [INFO]  Model initialized for training
2023-03-20 20:05:40,857 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:05:41,055 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:05:41,872 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:05:42,004 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-20 20:05:42,004 : [INFO]  Connected to the server
2023-03-20 20:05:42,004 : [INFO]  Accepted new connection at 127.0.0.1:41158
2023-03-20 20:05:42,005 : [INFO]  Initial training round 0: aggregated global model sent to client-new at 127.0.0.1:41158
2023-03-20 20:05:42,088 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:05:42,096 : [INFO]  _____________________________________________________ Initial model training started ____________________________________________________________
2023-03-20 20:05:42,096 : [INFO]  _____________________________________________________ Initial model training: training round 1 ____________________________________________________________
2023-03-20 20:05:50,896 : [ERROR]  Client-new closed connection at 127.0.0.1:41158
2023-03-20 20:06:22,321 : [WARNING]  ####################################### New Training Session #######################################
2023-03-20 20:06:22,321 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 5, number of timestamps 101
2023-03-20 20:06:22,930 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-20 20:06:22,930 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-20 20:06:24,316 : [INFO]  Model initialized for training
2023-03-20 20:06:36,196 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:06:36,426 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:06:36,883 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:06:37,015 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-20 20:06:37,015 : [INFO]  Connected to the server
2023-03-20 20:06:37,016 : [INFO]  Accepted new connection at 127.0.0.1:49000
2023-03-20 20:06:37,016 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:49000
2023-03-20 20:06:37,102 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:06:37,109 : [INFO]  _____________________________________________________ Initial model training started ____________________________________________________________
2023-03-20 20:06:37,109 : [INFO]  _____________________________________________________ Initial model training: training round 1 ____________________________________________________________
2023-03-20 20:07:13,905 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 1 ____________________________________________________________
2023-03-20 20:07:13,943 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:49000
2023-03-20 20:11:00,215 : [WARNING]  ####################################### New Training Session #######################################
2023-03-20 20:11:00,215 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 5, number of timestamps 101
2023-03-20 20:11:04,321 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-20 20:11:04,321 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-20 20:11:05,806 : [INFO]  Model initialized for training
2023-03-20 20:11:14,303 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:11:14,521 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:11:17,915 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-20 20:11:18,055 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-20 20:11:18,056 : [INFO]  Connected to the server
2023-03-20 20:11:18,056 : [INFO]  Accepted new connection at 127.0.0.1:51956
2023-03-20 20:11:18,056 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:51956
2023-03-20 20:11:18,142 : [INFO]  Distributed training for streaming graphs started!
2023-03-20 20:11:18,149 : [INFO]  _____________________________________________________ Initial model training started ____________________________________________________________
2023-03-20 20:11:18,149 : [INFO]  _____________________________________________________ Initial model training: training round 1 ____________________________________________________________
2023-03-20 20:11:50,432 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 1 ____________________________________________________________
2023-03-20 20:11:50,434 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:51956
2023-03-20 20:11:50,439 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:51956
2023-03-20 20:11:50,439 : [INFO]  ____________________________________ Initial training: round 1 finished____________________________________
2023-03-20 20:11:50,440 : [INFO]  _____________________________________________________ Initial model training: training round 2 ____________________________________________________________
2023-03-20 20:12:21,899 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 2 ____________________________________________________________
2023-03-20 20:12:21,901 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:51956
2023-03-20 20:12:21,901 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:51956
2023-03-20 20:12:21,902 : [INFO]  ____________________________________ Initial training: round 2 finished____________________________________
2023-03-20 20:12:21,903 : [INFO]  _____________________________________________________ Initial model training: training round 3 ____________________________________________________________
2023-03-20 20:12:56,646 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 3 ____________________________________________________________
2023-03-20 20:12:56,648 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:51956
2023-03-20 20:12:56,649 : [INFO]  Initial training round 3: aggregated global model sent to client-0 at 127.0.0.1:51956
2023-03-20 20:12:56,649 : [INFO]  ____________________________________ Initial training: round 3 finished____________________________________
2023-03-20 20:12:56,650 : [INFO]  _____________________________________________________ Initial model training: training round 4 ____________________________________________________________
2023-03-20 20:13:32,156 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 4 ____________________________________________________________
2023-03-20 20:13:32,159 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:51956
2023-03-20 20:13:32,159 : [INFO]  Initial training round 4: aggregated global model sent to client-0 at 127.0.0.1:51956
2023-03-20 20:13:32,159 : [INFO]  ____________________________________ Initial training: round 4 finished____________________________________
2023-03-20 20:13:32,161 : [INFO]  _____________________________________________________ Initial model training: training round 5 ____________________________________________________________
2023-03-20 20:14:08,408 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 5 ____________________________________________________________
2023-03-20 20:14:08,410 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:51956
2023-03-20 20:14:08,410 : [INFO]  Initial training round 5: aggregated global model sent to client-0 at 127.0.0.1:51956
2023-03-20 20:14:08,410 : [INFO]  ____________________________________ Initial training: round 5 finished____________________________________
2023-03-20 20:14:08,410 : [INFO]  ____________________________________Initial Trained final model sent to clients____________________________________
2023-03-20 20:14:41,111 : [INFO]  _____________________________________________________ Initial trained model: Final global model evalution after 5 rounds ____________________________________________________________
2023-03-20 20:14:41,112 : [INFO]  Initially trained model: Training set : loss - 0.5715205073356628, accuracy - 0.7473719716072083, recall - 0.9333672523498535, AUC - 0.8583722710609436, F1 - 0.7869907207424782, precision - 0.6803015470504761
2023-03-20 20:14:41,112 : [INFO]  Initially trained model: Testing set : loss - 0.5909004807472229, accuracy - 0.7160079479217529, recall - 0.9206470251083374, AUC - 0.827485978603363, F1 - 0.7642513462566173, precision - 0.6532756090164185
2023-03-20 20:14:41,196 : [INFO]  (Iteration id 1) Model initialized 
2023-03-20 20:14:41,720 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 00:51:18,663 : [WARNING]  ####################################### New Training Session #######################################
2023-03-21 00:51:18,663 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 2, number of timestamps 101
2023-03-21 00:51:31,454 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-21 00:51:31,455 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-21 00:51:32,994 : [INFO]  Model initialized for training
2023-03-21 00:51:40,331 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 00:51:40,535 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 00:51:47,154 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 00:51:47,375 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-21 00:51:47,376 : [INFO]  Connected to the server
2023-03-21 00:51:47,376 : [INFO]  Accepted new connection at 127.0.0.1:53742
2023-03-21 00:51:47,376 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:53742
2023-03-21 00:51:47,460 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 00:51:47,466 : [INFO]  _____________________________________________________ Initial model training started ____________________________________________________________
2023-03-21 00:51:47,466 : [INFO]  _____________________________________________________ Initial model training: training round 1 ____________________________________________________________
2023-03-21 00:52:25,875 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 1 ____________________________________________________________
2023-03-21 00:52:25,881 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:53742
2023-03-21 00:52:25,881 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:53742
2023-03-21 00:52:25,881 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-21 00:52:25,883 : [INFO]  _____________________________________________________ Initial model training: training round 2 ____________________________________________________________
2023-03-21 00:52:58,376 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 2 ____________________________________________________________
2023-03-21 00:52:58,378 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:53742
2023-03-21 00:52:58,378 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:53742
2023-03-21 00:52:58,378 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-21 00:52:58,378 : [INFO]  ____________________________________Initial Trained final model sent to clients____________________________________
2023-03-21 00:53:28,434 : [INFO]  _____________________________________________________ Initial trained model: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 00:53:28,434 : [INFO]  Initially trained model: Training set : loss - 0.5860264301300049, accuracy - 0.7232112288475037, recall - 0.9140386581420898, AUC - 0.8356429934501648, F1 - 0.7675660265437806, precision - 0.6615535616874695
2023-03-21 00:53:28,434 : [INFO]  Initially trained model: Testing set : loss - 0.5982621312141418, accuracy - 0.7034182548522949, recall - 0.9073706865310669, AUC - 0.8134757280349731, F1 - 0.7536599248408582, precision - 0.6444829702377319
2023-03-21 00:53:28,556 : [INFO]  (Iteration id 1) Model initialized 
2023-03-21 00:53:28,944 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 00:58:41,945 : [ERROR]  Client-0 closed connection at 127.0.0.1:53742
2023-03-21 00:58:48,486 : [WARNING]  ####################################### New Training Session #######################################
2023-03-21 00:58:48,486 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 2, number of timestamps 101
2023-03-21 00:58:50,480 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-21 00:58:50,481 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-21 00:58:52,491 : [INFO]  Model initialized for training
2023-03-21 00:59:05,447 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 00:59:05,646 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 00:59:06,811 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 00:59:06,945 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-21 00:59:06,946 : [INFO]  Connected to the server
2023-03-21 00:59:06,946 : [INFO]  Accepted new connection at 127.0.0.1:53686
2023-03-21 00:59:06,946 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:53686
2023-03-21 00:59:07,044 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 00:59:07,052 : [INFO]  _____________________________________________________ Initial model training started ____________________________________________________________
2023-03-21 00:59:07,052 : [INFO]  _____________________________________________________ Initial model training: training round 1 ____________________________________________________________
2023-03-21 00:59:47,754 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 1 ____________________________________________________________
2023-03-21 00:59:47,756 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 00:59:47,757 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 00:59:47,757 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-21 00:59:47,758 : [INFO]  _____________________________________________________ Initial model training: training round 2 ____________________________________________________________
2023-03-21 01:00:25,925 : [INFO]  _____________________________________________________ Sent local model to the server: initial training round 2 ____________________________________________________________
2023-03-21 01:00:25,931 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:00:25,932 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:00:25,932 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-21 01:00:25,933 : [INFO]  ____________________________________ Initial Trained final model sent to clients____________________________________
2023-03-21 01:01:23,549 : [INFO]  _____________________________________________________ Initial trained model: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:23,550 : [INFO]  Initially trained model: Training set : loss - 0.5860264301300049, accuracy - 0.7232112288475037, recall - 0.9140386581420898, AUC - 0.8356429934501648, F1 - 0.7675660265437806, precision - 0.6615535616874695
2023-03-21 01:01:23,550 : [INFO]  Initially trained model: Testing set : loss - 0.5982621312141418, accuracy - 0.7034182548522949, recall - 0.9073706865310669, AUC - 0.8134757280349731, F1 - 0.7536599248408582, precision - 0.6444829702377319
2023-03-21 01:01:23,599 : [INFO]  Batch 1 initialized 
2023-03-21 01:01:23,942 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:24,057 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:24,057 : [INFO]  _____________________________________________________ Batch number 1: training Round 1 ____________________________________________________________
2023-03-21 01:01:26,016 : [INFO]  _____________________________________________________ Batch number 1: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:26,019 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:26,019 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:26,019 : [INFO]  ____________________________________Batch 1: round 1 finished ____________________________________
2023-03-21 01:01:26,020 : [INFO]  _____________________________________________________ Batch number 1: training Round 2 ____________________________________________________________
2023-03-21 01:01:26,598 : [INFO]  _____________________________________________________ Batch number 1: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:26,600 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:26,600 : [INFO]  Batch 1, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:26,600 : [INFO]  ____________________________________Batch 1: round 2 finished ____________________________________
2023-03-21 01:01:26,600 : [INFO]  ____________________________________ Batch number 1: sent the final model to clients ____________________________________
2023-03-21 01:01:27,530 : [INFO]  Batch number 1 model fetched from the server
2023-03-21 01:01:27,530 : [INFO]  _____________________________________________________ Batch number 1: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:27,530 : [INFO]  Batch 1: Training set : loss - 0.5818300843238831, accuracy - 0.7228260636329651, recall - 0.9239130616188049, AUC - 0.8434545993804932, F1 - 0.7692307865382173, precision - 0.6589147448539734
2023-03-21 01:01:27,530 : [INFO]  Batch 1: Testing set : loss - 0.5756815671920776, accuracy - 0.7254902124404907, recall - 0.9117646813392639, AUC - 0.867310643196106, F1 - 0.768595036021771, precision - 0.6642857193946838
2023-03-21 01:01:27,610 : [INFO]  Batch 2 initialized 
2023-03-21 01:01:27,959 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:28,134 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:28,135 : [INFO]  _____________________________________________________ Batch number 2: training Round 1 ____________________________________________________________
2023-03-21 01:01:30,355 : [INFO]  _____________________________________________________ Batch number 2: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:30,357 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:30,358 : [INFO]  Batch 2, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:30,358 : [INFO]  ____________________________________Batch 2: round 1 finished ____________________________________
2023-03-21 01:01:30,359 : [INFO]  _____________________________________________________ Batch number 2: training Round 2 ____________________________________________________________
2023-03-21 01:01:30,911 : [INFO]  _____________________________________________________ Batch number 2: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:30,913 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:30,913 : [INFO]  Batch 2, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:30,913 : [INFO]  ____________________________________Batch 2: round 2 finished ____________________________________
2023-03-21 01:01:30,913 : [INFO]  ____________________________________ Batch number 2: sent the final model to clients ____________________________________
2023-03-21 01:01:31,937 : [INFO]  Batch number 2 model fetched from the server
2023-03-21 01:01:31,938 : [INFO]  _____________________________________________________ Batch number 2: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:31,938 : [INFO]  Batch 2: Training set : loss - 0.5569884181022644, accuracy - 0.7771739363670349, recall - 0.95652174949646, AUC - 0.8744682669639587, F1 - 0.8110599090290043, precision - 0.7039999961853027
2023-03-21 01:01:31,938 : [INFO]  Batch 2: Testing set : loss - 0.5796688199043274, accuracy - 0.7303921580314636, recall - 0.9411764740943909, AUC - 0.8545751571655273, F1 - 0.7773279347185498, precision - 0.6620689630508423
2023-03-21 01:01:32,004 : [INFO]  Batch 3 initialized 
2023-03-21 01:01:32,378 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:32,597 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:32,597 : [INFO]  _____________________________________________________ Batch number 3: training Round 1 ____________________________________________________________
2023-03-21 01:01:34,537 : [INFO]  _____________________________________________________ Batch number 3: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:34,539 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:34,540 : [INFO]  Batch 3, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:34,540 : [INFO]  ____________________________________Batch 3: round 1 finished ____________________________________
2023-03-21 01:01:34,541 : [INFO]  _____________________________________________________ Batch number 3: training Round 2 ____________________________________________________________
2023-03-21 01:01:35,108 : [INFO]  _____________________________________________________ Batch number 3: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:35,110 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:35,111 : [INFO]  Batch 3, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:35,111 : [INFO]  ____________________________________Batch 3: round 2 finished ____________________________________
2023-03-21 01:01:35,111 : [INFO]  ____________________________________ Batch number 3: sent the final model to clients ____________________________________
2023-03-21 01:01:36,081 : [INFO]  Batch number 3 model fetched from the server
2023-03-21 01:01:36,081 : [INFO]  _____________________________________________________ Batch number 3: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:36,081 : [INFO]  Batch 3: Training set : loss - 0.5518504977226257, accuracy - 0.739130437374115, recall - 0.945652186870575, AUC - 0.8910680413246155, F1 - 0.7837837813165838, precision - 0.6692307591438293
2023-03-21 01:01:36,082 : [INFO]  Batch 3: Testing set : loss - 0.5792639255523682, accuracy - 0.7254902124404907, recall - 0.9411764740943909, AUC - 0.8447231650352478, F1 - 0.7741935461775072, precision - 0.6575342416763306
2023-03-21 01:01:36,178 : [INFO]  Batch 4 initialized 
2023-03-21 01:01:36,525 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:36,694 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:36,694 : [INFO]  _____________________________________________________ Batch number 4: training Round 1 ____________________________________________________________
2023-03-21 01:01:38,847 : [INFO]  _____________________________________________________ Batch number 4: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:38,849 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:38,850 : [INFO]  Batch 4, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:38,850 : [INFO]  ____________________________________Batch 4: round 1 finished ____________________________________
2023-03-21 01:01:38,851 : [INFO]  _____________________________________________________ Batch number 4: training Round 2 ____________________________________________________________
2023-03-21 01:01:39,440 : [INFO]  _____________________________________________________ Batch number 4: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:39,442 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:39,442 : [INFO]  Batch 4, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:39,442 : [INFO]  ____________________________________Batch 4: round 2 finished ____________________________________
2023-03-21 01:01:39,442 : [INFO]  ____________________________________ Batch number 4: sent the final model to clients ____________________________________
2023-03-21 01:01:40,398 : [INFO]  Batch number 4 model fetched from the server
2023-03-21 01:01:40,398 : [INFO]  _____________________________________________________ Batch number 4: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:40,398 : [INFO]  Batch 4: Training set : loss - 0.5561304688453674, accuracy - 0.77173912525177, recall - 0.95652174949646, AUC - 0.8870510458946228, F1 - 0.8073394652438799, precision - 0.6984127163887024
2023-03-21 01:01:40,398 : [INFO]  Batch 4: Testing set : loss - 0.5828931927680969, accuracy - 0.7254902124404907, recall - 0.9215686321258545, AUC - 0.8355439901351929, F1 - 0.7704917889902326, precision - 0.6619718074798584
2023-03-21 01:01:40,502 : [INFO]  Batch 5 initialized 
2023-03-21 01:01:40,938 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:41,138 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:41,138 : [INFO]  _____________________________________________________ Batch number 5: training Round 1 ____________________________________________________________
2023-03-21 01:01:43,518 : [INFO]  _____________________________________________________ Batch number 5: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:43,520 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:43,521 : [INFO]  Batch 5, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:43,521 : [INFO]  ____________________________________Batch 5: round 1 finished ____________________________________
2023-03-21 01:01:43,522 : [INFO]  _____________________________________________________ Batch number 5: training Round 2 ____________________________________________________________
2023-03-21 01:01:44,166 : [INFO]  _____________________________________________________ Batch number 5: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:44,168 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:44,169 : [INFO]  Batch 5, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:44,169 : [INFO]  ____________________________________Batch 5: round 2 finished ____________________________________
2023-03-21 01:01:44,169 : [INFO]  ____________________________________ Batch number 5: sent the final model to clients ____________________________________
2023-03-21 01:01:45,090 : [INFO]  Batch number 5 model fetched from the server
2023-03-21 01:01:45,091 : [INFO]  _____________________________________________________ Batch number 5: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:45,091 : [INFO]  Batch 5: Training set : loss - 0.5460129380226135, accuracy - 0.760869562625885, recall - 0.9021739363670349, AUC - 0.8917179107666016, F1 - 0.7904761949634334, precision - 0.7033898234367371
2023-03-21 01:01:45,091 : [INFO]  Batch 5: Testing set : loss - 0.5868687629699707, accuracy - 0.720588207244873, recall - 0.9117646813392639, AUC - 0.8308823108673096, F1 - 0.7654320773073966, precision - 0.6595744490623474
2023-03-21 01:01:45,192 : [INFO]  Batch 6 initialized 
2023-03-21 01:01:45,546 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:45,727 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:45,727 : [INFO]  _____________________________________________________ Batch number 6: training Round 1 ____________________________________________________________
2023-03-21 01:01:48,301 : [INFO]  _____________________________________________________ Batch number 6: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:48,306 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:48,306 : [INFO]  Batch 6, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:48,306 : [INFO]  ____________________________________Batch 6: round 1 finished ____________________________________
2023-03-21 01:01:48,309 : [INFO]  _____________________________________________________ Batch number 6: training Round 2 ____________________________________________________________
2023-03-21 01:01:49,055 : [INFO]  _____________________________________________________ Batch number 6: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:49,058 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:49,058 : [INFO]  Batch 6, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:49,058 : [INFO]  ____________________________________Batch 6: round 2 finished ____________________________________
2023-03-21 01:01:49,058 : [INFO]  ____________________________________ Batch number 6: sent the final model to clients ____________________________________
2023-03-21 01:01:50,094 : [INFO]  Batch number 6 model fetched from the server
2023-03-21 01:01:50,094 : [INFO]  _____________________________________________________ Batch number 6: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:50,094 : [INFO]  Batch 6: Training set : loss - 0.5710691213607788, accuracy - 0.717391312122345, recall - 0.8913043737411499, AUC - 0.8618265390396118, F1 - 0.7592592851369959, precision - 0.6612903475761414
2023-03-21 01:01:50,094 : [INFO]  Batch 6: Testing set : loss - 0.5912925004959106, accuracy - 0.7107843160629272, recall - 0.9019607901573181, AUC - 0.8265570998191833, F1 - 0.7572016492883455, precision - 0.652482271194458
2023-03-21 01:01:50,183 : [INFO]  Batch 7 initialized 
2023-03-21 01:01:50,536 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:50,737 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:50,737 : [INFO]  _____________________________________________________ Batch number 7: training Round 1 ____________________________________________________________
2023-03-21 01:01:54,573 : [INFO]  _____________________________________________________ Batch number 7: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:54,576 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:54,576 : [INFO]  Batch 7, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:54,576 : [INFO]  ____________________________________Batch 7: round 1 finished ____________________________________
2023-03-21 01:01:54,578 : [INFO]  _____________________________________________________ Batch number 7: training Round 2 ____________________________________________________________
2023-03-21 01:01:55,264 : [INFO]  _____________________________________________________ Batch number 7: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:55,266 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:55,267 : [INFO]  Batch 7, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:55,267 : [INFO]  ____________________________________Batch 7: round 2 finished ____________________________________
2023-03-21 01:01:55,267 : [INFO]  ____________________________________ Batch number 7: sent the final model to clients ____________________________________
2023-03-21 01:01:56,238 : [INFO]  Batch number 7 model fetched from the server
2023-03-21 01:01:56,238 : [INFO]  _____________________________________________________ Batch number 7: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:01:56,238 : [INFO]  Batch 7: Training set : loss - 0.5669398307800293, accuracy - 0.7554348111152649, recall - 0.95652174949646, AUC - 0.8932538032531738, F1 - 0.7963801126671847, precision - 0.682170569896698
2023-03-21 01:01:56,238 : [INFO]  Batch 7: Testing set : loss - 0.5867429971694946, accuracy - 0.7303921580314636, recall - 0.9803921580314636, AUC - 0.859573245048523, F1 - 0.7843137407302855, precision - 0.6535947918891907
2023-03-21 01:01:56,352 : [INFO]  Batch 8 initialized 
2023-03-21 01:01:56,737 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:01:56,966 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:01:56,967 : [INFO]  _____________________________________________________ Batch number 8: training Round 1 ____________________________________________________________
2023-03-21 01:01:59,081 : [INFO]  _____________________________________________________ Batch number 8: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:01:59,084 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:59,084 : [INFO]  Batch 8, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:59,084 : [INFO]  ____________________________________Batch 8: round 1 finished ____________________________________
2023-03-21 01:01:59,085 : [INFO]  _____________________________________________________ Batch number 8: training Round 2 ____________________________________________________________
2023-03-21 01:01:59,694 : [INFO]  _____________________________________________________ Batch number 8: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:01:59,697 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:01:59,697 : [INFO]  Batch 8, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:01:59,697 : [INFO]  ____________________________________Batch 8: round 2 finished ____________________________________
2023-03-21 01:01:59,697 : [INFO]  ____________________________________ Batch number 8: sent the final model to clients ____________________________________
2023-03-21 01:02:00,723 : [INFO]  Batch number 8 model fetched from the server
2023-03-21 01:02:00,724 : [INFO]  _____________________________________________________ Batch number 8: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:00,724 : [INFO]  Batch 8: Training set : loss - 0.5412639379501343, accuracy - 0.804347813129425, recall - 0.989130437374115, AUC - 0.9273393154144287, F1 - 0.8348623773945509, precision - 0.7222222089767456
2023-03-21 01:02:00,724 : [INFO]  Batch 8: Testing set : loss - 0.5960653424263, accuracy - 0.7107843160629272, recall - 0.970588207244873, AUC - 0.8451076745986938, F1 - 0.7704279972159815, precision - 0.6387096643447876
2023-03-21 01:02:00,806 : [INFO]  Batch 9 initialized 
2023-03-21 01:02:01,292 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:01,497 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:01,497 : [INFO]  _____________________________________________________ Batch number 9: training Round 1 ____________________________________________________________
2023-03-21 01:02:04,325 : [INFO]  _____________________________________________________ Batch number 9: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:04,328 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:04,328 : [INFO]  Batch 9, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:04,328 : [INFO]  ____________________________________Batch 9: round 1 finished ____________________________________
2023-03-21 01:02:04,330 : [INFO]  _____________________________________________________ Batch number 9: training Round 2 ____________________________________________________________
2023-03-21 01:02:05,017 : [INFO]  _____________________________________________________ Batch number 9: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:05,020 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:05,020 : [INFO]  Batch 9, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:05,020 : [INFO]  ____________________________________Batch 9: round 2 finished ____________________________________
2023-03-21 01:02:05,020 : [INFO]  ____________________________________ Batch number 9: sent the final model to clients ____________________________________
2023-03-21 01:02:06,098 : [INFO]  Batch number 9 model fetched from the server
2023-03-21 01:02:06,098 : [INFO]  _____________________________________________________ Batch number 9: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:06,098 : [INFO]  Batch 9: Training set : loss - 0.5458518862724304, accuracy - 0.804347813129425, recall - 0.95652174949646, AUC - 0.9056592583656311, F1 - 0.8301886933348109, precision - 0.7333333492279053
2023-03-21 01:02:06,098 : [INFO]  Batch 9: Testing set : loss - 0.5770911574363708, accuracy - 0.7303921580314636, recall - 0.9313725233078003, AUC - 0.8537581562995911, F1 - 0.7755101977244657, precision - 0.6643356680870056
2023-03-21 01:02:06,177 : [INFO]  Batch 10 initialized 
2023-03-21 01:02:06,543 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:06,792 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:06,792 : [INFO]  _____________________________________________________ Batch number 10: training Round 1 ____________________________________________________________
2023-03-21 01:02:09,152 : [INFO]  _____________________________________________________ Batch number 10: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:09,156 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:09,156 : [INFO]  Batch 10, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:09,156 : [INFO]  ____________________________________Batch 10: round 1 finished ____________________________________
2023-03-21 01:02:09,159 : [INFO]  _____________________________________________________ Batch number 10: training Round 2 ____________________________________________________________
2023-03-21 01:02:09,971 : [INFO]  _____________________________________________________ Batch number 10: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:09,973 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:09,974 : [INFO]  Batch 10, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:09,974 : [INFO]  ____________________________________Batch 10: round 2 finished ____________________________________
2023-03-21 01:02:09,974 : [INFO]  ____________________________________ Batch number 10: sent the final model to clients ____________________________________
2023-03-21 01:02:11,015 : [INFO]  Batch number 10 model fetched from the server
2023-03-21 01:02:11,015 : [INFO]  _____________________________________________________ Batch number 10: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:11,015 : [INFO]  Batch 10: Training set : loss - 0.5444540977478027, accuracy - 0.7663043737411499, recall - 0.967391312122345, AUC - 0.9192461967468262, F1 - 0.8054298474267754, precision - 0.6899224519729614
2023-03-21 01:02:11,015 : [INFO]  Batch 10: Testing set : loss - 0.5943863987922668, accuracy - 0.7009803652763367, recall - 0.9215686321258545, AUC - 0.8234813213348389, F1 - 0.7550200909345861, precision - 0.6394557952880859
2023-03-21 01:02:11,192 : [INFO]  Batch 11 initialized 
2023-03-21 01:02:11,909 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:12,284 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:12,284 : [INFO]  _____________________________________________________ Batch number 11: training Round 1 ____________________________________________________________
2023-03-21 01:02:14,881 : [INFO]  _____________________________________________________ Batch number 11: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:14,883 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:14,884 : [INFO]  Batch 11, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:14,884 : [INFO]  ____________________________________Batch 11: round 1 finished ____________________________________
2023-03-21 01:02:14,885 : [INFO]  _____________________________________________________ Batch number 11: training Round 2 ____________________________________________________________
2023-03-21 01:02:15,445 : [INFO]  _____________________________________________________ Batch number 11: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:15,447 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:15,448 : [INFO]  Batch 11, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:15,448 : [INFO]  ____________________________________Batch 11: round 2 finished ____________________________________
2023-03-21 01:02:15,448 : [INFO]  ____________________________________ Batch number 11: sent the final model to clients ____________________________________
2023-03-21 01:02:16,337 : [INFO]  Batch number 11 model fetched from the server
2023-03-21 01:02:16,337 : [INFO]  _____________________________________________________ Batch number 11: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:16,337 : [INFO]  Batch 11: Training set : loss - 0.547334611415863, accuracy - 0.782608687877655, recall - 0.967391312122345, AUC - 0.9025284051895142, F1 - 0.8165137560196409, precision - 0.7063491940498352
2023-03-21 01:02:16,337 : [INFO]  Batch 11: Testing set : loss - 0.5894553661346436, accuracy - 0.7156862616539001, recall - 0.9509803652763367, AUC - 0.8463091254234314, F1 - 0.7698412463913699, precision - 0.6466666460037231
2023-03-21 01:02:16,418 : [INFO]  Batch 12 initialized 
2023-03-21 01:02:16,767 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:16,961 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:16,961 : [INFO]  _____________________________________________________ Batch number 12: training Round 1 ____________________________________________________________
2023-03-21 01:02:18,942 : [INFO]  _____________________________________________________ Batch number 12: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:18,944 : [INFO]  Batch 12: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:18,945 : [INFO]  Batch 12, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:18,945 : [INFO]  ____________________________________Batch 12: round 1 finished ____________________________________
2023-03-21 01:02:18,946 : [INFO]  _____________________________________________________ Batch number 12: training Round 2 ____________________________________________________________
2023-03-21 01:02:19,571 : [INFO]  _____________________________________________________ Batch number 12: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:19,574 : [INFO]  Batch 12: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:19,574 : [INFO]  Batch 12, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:19,574 : [INFO]  ____________________________________Batch 12: round 2 finished ____________________________________
2023-03-21 01:02:19,574 : [INFO]  ____________________________________ Batch number 12: sent the final model to clients ____________________________________
2023-03-21 01:02:20,497 : [INFO]  Batch number 12 model fetched from the server
2023-03-21 01:02:20,498 : [INFO]  _____________________________________________________ Batch number 12: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:20,498 : [INFO]  Batch 12: Training set : loss - 0.5843387246131897, accuracy - 0.760869562625885, recall - 0.945652186870575, AUC - 0.8456403613090515, F1 - 0.7981651346447309, precision - 0.6904761791229248
2023-03-21 01:02:20,498 : [INFO]  Batch 12: Testing set : loss - 0.6116136908531189, accuracy - 0.656862735748291, recall - 0.9019607901573181, AUC - 0.8069011569023132, F1 - 0.7244094619379061, precision - 0.6052631735801697
2023-03-21 01:02:20,566 : [INFO]  Batch 13 initialized 
2023-03-21 01:02:20,903 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:21,105 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:21,105 : [INFO]  _____________________________________________________ Batch number 13: training Round 1 ____________________________________________________________
2023-03-21 01:02:23,052 : [INFO]  _____________________________________________________ Batch number 13: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:23,055 : [INFO]  Batch 13: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:23,055 : [INFO]  Batch 13, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:23,055 : [INFO]  ____________________________________Batch 13: round 1 finished ____________________________________
2023-03-21 01:02:23,057 : [INFO]  _____________________________________________________ Batch number 13: training Round 2 ____________________________________________________________
2023-03-21 01:02:23,638 : [INFO]  _____________________________________________________ Batch number 13: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:23,640 : [INFO]  Batch 13: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:23,641 : [INFO]  Batch 13, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:23,641 : [INFO]  ____________________________________Batch 13: round 2 finished ____________________________________
2023-03-21 01:02:23,641 : [INFO]  ____________________________________ Batch number 13: sent the final model to clients ____________________________________
2023-03-21 01:02:24,752 : [INFO]  Batch number 13 model fetched from the server
2023-03-21 01:02:24,752 : [INFO]  _____________________________________________________ Batch number 13: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:24,752 : [INFO]  Batch 13: Training set : loss - 0.5469793081283569, accuracy - 0.77173912525177, recall - 0.95652174949646, AUC - 0.9107986688613892, F1 - 0.8073394652438799, precision - 0.6984127163887024
2023-03-21 01:02:24,752 : [INFO]  Batch 13: Testing set : loss - 0.5742411613464355, accuracy - 0.7401960492134094, recall - 0.9411764740943909, AUC - 0.8568819761276245, F1 - 0.7836734654912348, precision - 0.6713286638259888
2023-03-21 01:02:24,853 : [INFO]  Batch 14 initialized 
2023-03-21 01:02:25,422 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:25,695 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:25,695 : [INFO]  _____________________________________________________ Batch number 14: training Round 1 ____________________________________________________________
2023-03-21 01:02:29,097 : [INFO]  _____________________________________________________ Batch number 14: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:29,102 : [INFO]  Batch 14: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:29,103 : [INFO]  Batch 14, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:29,103 : [INFO]  ____________________________________Batch 14: round 1 finished ____________________________________
2023-03-21 01:02:29,107 : [INFO]  _____________________________________________________ Batch number 14: training Round 2 ____________________________________________________________
2023-03-21 01:02:30,041 : [INFO]  _____________________________________________________ Batch number 14: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:30,046 : [INFO]  Batch 14: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:30,047 : [INFO]  Batch 14, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:30,047 : [INFO]  ____________________________________Batch 14: round 2 finished ____________________________________
2023-03-21 01:02:30,047 : [INFO]  ____________________________________ Batch number 14: sent the final model to clients ____________________________________
2023-03-21 01:02:31,966 : [INFO]  Batch number 14 model fetched from the server
2023-03-21 01:02:31,967 : [INFO]  _____________________________________________________ Batch number 14: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:31,967 : [INFO]  Batch 14: Training set : loss - 0.5327144861221313, accuracy - 0.804347813129425, recall - 0.967391312122345, AUC - 0.9226134419441223, F1 - 0.8317757196869534, precision - 0.7295082211494446
2023-03-21 01:02:31,967 : [INFO]  Batch 14: Testing set : loss - 0.573850691318512, accuracy - 0.7549019455909729, recall - 0.9117646813392639, AUC - 0.8570742607116699, F1 - 0.7881355949497464, precision - 0.6940298676490784
2023-03-21 01:02:32,104 : [INFO]  Batch 15 initialized 
2023-03-21 01:02:32,469 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:32,666 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:32,666 : [INFO]  _____________________________________________________ Batch number 15: training Round 1 ____________________________________________________________
2023-03-21 01:02:35,940 : [INFO]  _____________________________________________________ Batch number 15: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:35,945 : [INFO]  Batch 15: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:35,945 : [INFO]  Batch 15, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:35,945 : [INFO]  ____________________________________Batch 15: round 1 finished ____________________________________
2023-03-21 01:02:35,947 : [INFO]  _____________________________________________________ Batch number 15: training Round 2 ____________________________________________________________
2023-03-21 01:02:36,929 : [INFO]  _____________________________________________________ Batch number 15: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:36,935 : [INFO]  Batch 15: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:36,936 : [INFO]  Batch 15, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:36,936 : [INFO]  ____________________________________Batch 15: round 2 finished ____________________________________
2023-03-21 01:02:36,936 : [INFO]  ____________________________________ Batch number 15: sent the final model to clients ____________________________________
2023-03-21 01:02:38,219 : [INFO]  Batch number 15 model fetched from the server
2023-03-21 01:02:38,219 : [INFO]  _____________________________________________________ Batch number 15: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:38,219 : [INFO]  Batch 15: Training set : loss - 0.5541124939918518, accuracy - 0.79347825050354, recall - 0.967391312122345, AUC - 0.8842154741287231, F1 - 0.8240740578851578, precision - 0.7177419066429138
2023-03-21 01:02:38,219 : [INFO]  Batch 15: Testing set : loss - 0.6005237698554993, accuracy - 0.7058823704719543, recall - 0.9509803652763367, AUC - 0.8188678026199341, F1 - 0.7637795256300062, precision - 0.6381579041481018
2023-03-21 01:02:38,287 : [INFO]  Batch 16 initialized 
2023-03-21 01:02:38,711 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:38,916 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:38,917 : [INFO]  _____________________________________________________ Batch number 16: training Round 1 ____________________________________________________________
2023-03-21 01:02:40,935 : [INFO]  _____________________________________________________ Batch number 16: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:40,937 : [INFO]  Batch 16: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:40,939 : [INFO]  Batch 16, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:40,939 : [INFO]  ____________________________________Batch 16: round 1 finished ____________________________________
2023-03-21 01:02:40,941 : [INFO]  _____________________________________________________ Batch number 16: training Round 2 ____________________________________________________________
2023-03-21 01:02:41,503 : [INFO]  _____________________________________________________ Batch number 16: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:41,506 : [INFO]  Batch 16: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:41,506 : [INFO]  Batch 16, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:41,506 : [INFO]  ____________________________________Batch 16: round 2 finished ____________________________________
2023-03-21 01:02:41,506 : [INFO]  ____________________________________ Batch number 16: sent the final model to clients ____________________________________
2023-03-21 01:02:42,391 : [INFO]  Batch number 16 model fetched from the server
2023-03-21 01:02:42,391 : [INFO]  _____________________________________________________ Batch number 16: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:42,391 : [INFO]  Batch 16: Training set : loss - 0.5315766334533691, accuracy - 0.782608687877655, recall - 0.967391312122345, AUC - 0.9298204183578491, F1 - 0.8165137560196409, precision - 0.7063491940498352
2023-03-21 01:02:42,391 : [INFO]  Batch 16: Testing set : loss - 0.5656106472015381, accuracy - 0.7598039507865906, recall - 0.970588207244873, AUC - 0.893886923789978, F1 - 0.8016194295815959, precision - 0.682758629322052
2023-03-21 01:02:42,459 : [INFO]  Batch 17 initialized 
2023-03-21 01:02:42,801 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:43,006 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:43,006 : [INFO]  _____________________________________________________ Batch number 17: training Round 1 ____________________________________________________________
2023-03-21 01:02:44,956 : [INFO]  _____________________________________________________ Batch number 17: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:44,959 : [INFO]  Batch 17: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:44,959 : [INFO]  Batch 17, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:44,959 : [INFO]  ____________________________________Batch 17: round 1 finished ____________________________________
2023-03-21 01:02:44,961 : [INFO]  _____________________________________________________ Batch number 17: training Round 2 ____________________________________________________________
2023-03-21 01:02:45,536 : [INFO]  _____________________________________________________ Batch number 17: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:45,538 : [INFO]  Batch 17: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:45,539 : [INFO]  Batch 17, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:45,539 : [INFO]  ____________________________________Batch 17: round 2 finished ____________________________________
2023-03-21 01:02:45,539 : [INFO]  ____________________________________ Batch number 17: sent the final model to clients ____________________________________
2023-03-21 01:02:46,420 : [INFO]  Batch number 17 model fetched from the server
2023-03-21 01:02:46,420 : [INFO]  _____________________________________________________ Batch number 17: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:46,420 : [INFO]  Batch 17: Training set : loss - 0.533200740814209, accuracy - 0.8097826242446899, recall - 0.967391312122345, AUC - 0.9031781554222107, F1 - 0.835680741993051, precision - 0.7355371713638306
2023-03-21 01:02:46,420 : [INFO]  Batch 17: Testing set : loss - 0.561633825302124, accuracy - 0.7549019455909729, recall - 0.970588207244873, AUC - 0.8939350247383118, F1 - 0.7983870708716028, precision - 0.6780821681022644
2023-03-21 01:02:46,507 : [INFO]  Batch 18 initialized 
2023-03-21 01:02:46,841 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:47,056 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:47,057 : [INFO]  _____________________________________________________ Batch number 18: training Round 1 ____________________________________________________________
2023-03-21 01:02:48,986 : [INFO]  _____________________________________________________ Batch number 18: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:48,989 : [INFO]  Batch 18: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:48,989 : [INFO]  Batch 18, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:48,989 : [INFO]  ____________________________________Batch 18: round 1 finished ____________________________________
2023-03-21 01:02:48,990 : [INFO]  _____________________________________________________ Batch number 18: training Round 2 ____________________________________________________________
2023-03-21 01:02:49,540 : [INFO]  _____________________________________________________ Batch number 18: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:49,542 : [INFO]  Batch 18: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:49,543 : [INFO]  Batch 18, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:49,543 : [INFO]  ____________________________________Batch 18: round 2 finished ____________________________________
2023-03-21 01:02:49,543 : [INFO]  ____________________________________ Batch number 18: sent the final model to clients ____________________________________
2023-03-21 01:02:50,407 : [INFO]  Batch number 18 model fetched from the server
2023-03-21 01:02:50,407 : [INFO]  _____________________________________________________ Batch number 18: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:50,407 : [INFO]  Batch 18: Training set : loss - 0.529130756855011, accuracy - 0.820652186870575, recall - 0.97826087474823, AUC - 0.9087311029434204, F1 - 0.8450704247870211, precision - 0.7438016533851624
2023-03-21 01:02:50,407 : [INFO]  Batch 18: Testing set : loss - 0.5675526261329651, accuracy - 0.7598039507865906, recall - 0.970588207244873, AUC - 0.8634659051895142, F1 - 0.8016194295815959, precision - 0.682758629322052
2023-03-21 01:02:50,521 : [INFO]  Batch 19 initialized 
2023-03-21 01:02:50,857 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:51,071 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:51,071 : [INFO]  _____________________________________________________ Batch number 19: training Round 1 ____________________________________________________________
2023-03-21 01:02:53,050 : [INFO]  _____________________________________________________ Batch number 19: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:53,052 : [INFO]  Batch 19: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:53,053 : [INFO]  Batch 19, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:53,053 : [INFO]  ____________________________________Batch 19: round 1 finished ____________________________________
2023-03-21 01:02:53,054 : [INFO]  _____________________________________________________ Batch number 19: training Round 2 ____________________________________________________________
2023-03-21 01:02:53,682 : [INFO]  _____________________________________________________ Batch number 19: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:53,684 : [INFO]  Batch 19: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:53,684 : [INFO]  Batch 19, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:53,685 : [INFO]  ____________________________________Batch 19: round 2 finished ____________________________________
2023-03-21 01:02:53,685 : [INFO]  ____________________________________ Batch number 19: sent the final model to clients ____________________________________
2023-03-21 01:02:54,748 : [INFO]  Batch number 19 model fetched from the server
2023-03-21 01:02:54,748 : [INFO]  _____________________________________________________ Batch number 19: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:54,748 : [INFO]  Batch 19: Training set : loss - 0.575848400592804, accuracy - 0.717391312122345, recall - 0.9239130616188049, AUC - 0.8497164249420166, F1 - 0.7657657657077138, precision - 0.6538461446762085
2023-03-21 01:02:54,748 : [INFO]  Batch 19: Testing set : loss - 0.6272262334823608, accuracy - 0.6666666865348816, recall - 0.9019607901573181, AUC - 0.7628796696662903, F1 - 0.7301587399576797, precision - 0.6133333444595337
2023-03-21 01:02:54,844 : [INFO]  Batch 20 initialized 
2023-03-21 01:02:55,260 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:02:55,531 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:02:55,532 : [INFO]  _____________________________________________________ Batch number 20: training Round 1 ____________________________________________________________
2023-03-21 01:02:57,750 : [INFO]  _____________________________________________________ Batch number 20: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:02:57,752 : [INFO]  Batch 20: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:57,752 : [INFO]  Batch 20, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:57,752 : [INFO]  ____________________________________Batch 20: round 1 finished ____________________________________
2023-03-21 01:02:57,754 : [INFO]  _____________________________________________________ Batch number 20: training Round 2 ____________________________________________________________
2023-03-21 01:02:58,332 : [INFO]  _____________________________________________________ Batch number 20: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:02:58,337 : [INFO]  Batch 20: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:02:58,337 : [INFO]  Batch 20, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:02:58,337 : [INFO]  ____________________________________Batch 20: round 2 finished ____________________________________
2023-03-21 01:02:58,337 : [INFO]  ____________________________________ Batch number 20: sent the final model to clients ____________________________________
2023-03-21 01:02:59,299 : [INFO]  Batch number 20 model fetched from the server
2023-03-21 01:02:59,299 : [INFO]  _____________________________________________________ Batch number 20: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:02:59,299 : [INFO]  Batch 20: Training set : loss - 0.5532551407814026, accuracy - 0.739130437374115, recall - 0.97826087474823, AUC - 0.9265713691711426, F1 - 0.7894736684333654, precision - 0.6617646813392639
2023-03-21 01:02:59,299 : [INFO]  Batch 20: Testing set : loss - 0.590204656124115, accuracy - 0.7254902124404907, recall - 0.9411764740943909, AUC - 0.8321318626403809, F1 - 0.7741935461775072, precision - 0.6575342416763306
2023-03-21 01:02:59,363 : [INFO]  Batch 21 initialized 
2023-03-21 01:02:59,948 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:00,381 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:00,383 : [INFO]  _____________________________________________________ Batch number 21: training Round 1 ____________________________________________________________
2023-03-21 01:03:03,589 : [INFO]  _____________________________________________________ Batch number 21: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:03,592 : [INFO]  Batch 21: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:03,592 : [INFO]  Batch 21, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:03,592 : [INFO]  ____________________________________Batch 21: round 1 finished ____________________________________
2023-03-21 01:03:03,594 : [INFO]  _____________________________________________________ Batch number 21: training Round 2 ____________________________________________________________
2023-03-21 01:03:04,323 : [INFO]  _____________________________________________________ Batch number 21: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:04,329 : [INFO]  Batch 21: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:04,330 : [INFO]  Batch 21, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:04,330 : [INFO]  ____________________________________Batch 21: round 2 finished ____________________________________
2023-03-21 01:03:04,331 : [INFO]  ____________________________________ Batch number 21: sent the final model to clients ____________________________________
2023-03-21 01:03:06,824 : [INFO]  Batch number 21 model fetched from the server
2023-03-21 01:03:06,824 : [INFO]  _____________________________________________________ Batch number 21: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:06,824 : [INFO]  Batch 21: Training set : loss - 0.5591514110565186, accuracy - 0.7554348111152649, recall - 0.97826087474823, AUC - 0.896916389465332, F1 - 0.7999999888926375, precision - 0.6766917109489441
2023-03-21 01:03:06,824 : [INFO]  Batch 21: Testing set : loss - 0.59290611743927, accuracy - 0.7107843160629272, recall - 0.9411764740943909, AUC - 0.8215590715408325, F1 - 0.764940221312197, precision - 0.6442952752113342
2023-03-21 01:03:06,947 : [INFO]  Batch 22 initialized 
2023-03-21 01:03:07,507 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:07,811 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:07,811 : [INFO]  _____________________________________________________ Batch number 22: training Round 1 ____________________________________________________________
2023-03-21 01:03:10,408 : [INFO]  _____________________________________________________ Batch number 22: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:10,414 : [INFO]  Batch 22: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:10,415 : [INFO]  Batch 22, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:10,415 : [INFO]  ____________________________________Batch 22: round 1 finished ____________________________________
2023-03-21 01:03:10,419 : [INFO]  _____________________________________________________ Batch number 22: training Round 2 ____________________________________________________________
2023-03-21 01:03:11,597 : [INFO]  _____________________________________________________ Batch number 22: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:11,600 : [INFO]  Batch 22: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:11,601 : [INFO]  Batch 22, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:11,601 : [INFO]  ____________________________________Batch 22: round 2 finished ____________________________________
2023-03-21 01:03:11,601 : [INFO]  ____________________________________ Batch number 22: sent the final model to clients ____________________________________
2023-03-21 01:03:13,679 : [INFO]  Batch number 22 model fetched from the server
2023-03-21 01:03:13,679 : [INFO]  _____________________________________________________ Batch number 22: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:13,679 : [INFO]  Batch 22: Training set : loss - 0.5631184577941895, accuracy - 0.7445651888847351, recall - 0.9239130616188049, AUC - 0.8804347515106201, F1 - 0.7834101495168839, precision - 0.6800000071525574
2023-03-21 01:03:13,679 : [INFO]  Batch 22: Testing set : loss - 0.5926259160041809, accuracy - 0.7058823704719543, recall - 0.9117646813392639, AUC - 0.8277105093002319, F1 - 0.7560975389208274, precision - 0.6458333134651184
2023-03-21 01:03:13,770 : [INFO]  Batch 23 initialized 
2023-03-21 01:03:14,213 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:14,438 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:14,438 : [INFO]  _____________________________________________________ Batch number 23: training Round 1 ____________________________________________________________
2023-03-21 01:03:16,541 : [INFO]  _____________________________________________________ Batch number 23: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:16,544 : [INFO]  Batch 23: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:16,544 : [INFO]  Batch 23, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:16,544 : [INFO]  ____________________________________Batch 23: round 1 finished ____________________________________
2023-03-21 01:03:16,546 : [INFO]  _____________________________________________________ Batch number 23: training Round 2 ____________________________________________________________
2023-03-21 01:03:17,726 : [INFO]  _____________________________________________________ Batch number 23: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:17,731 : [INFO]  Batch 23: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:17,732 : [INFO]  Batch 23, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:17,732 : [INFO]  ____________________________________Batch 23: round 2 finished ____________________________________
2023-03-21 01:03:17,732 : [INFO]  ____________________________________ Batch number 23: sent the final model to clients ____________________________________
2023-03-21 01:03:18,791 : [INFO]  Batch number 23 model fetched from the server
2023-03-21 01:03:18,791 : [INFO]  _____________________________________________________ Batch number 23: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:18,791 : [INFO]  Batch 23: Training set : loss - 0.550952136516571, accuracy - 0.75, recall - 0.9347826242446899, AUC - 0.9036507606506348, F1 - 0.78899084386897, precision - 0.682539701461792
2023-03-21 01:03:18,791 : [INFO]  Batch 23: Testing set : loss - 0.5498919486999512, accuracy - 0.7549019455909729, recall - 0.9411764740943909, AUC - 0.9032102823257446, F1 - 0.7933884435367342, precision - 0.6857143044471741
2023-03-21 01:03:18,895 : [INFO]  Batch 24 initialized 
2023-03-21 01:03:19,226 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:19,443 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:19,443 : [INFO]  _____________________________________________________ Batch number 24: training Round 1 ____________________________________________________________
2023-03-21 01:03:22,805 : [INFO]  _____________________________________________________ Batch number 24: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:22,808 : [INFO]  Batch 24: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:22,808 : [INFO]  Batch 24, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:22,808 : [INFO]  ____________________________________Batch 24: round 1 finished ____________________________________
2023-03-21 01:03:22,810 : [INFO]  _____________________________________________________ Batch number 24: training Round 2 ____________________________________________________________
2023-03-21 01:03:23,474 : [INFO]  _____________________________________________________ Batch number 24: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:23,477 : [INFO]  Batch 24: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:23,477 : [INFO]  Batch 24, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:23,477 : [INFO]  ____________________________________Batch 24: round 2 finished ____________________________________
2023-03-21 01:03:23,478 : [INFO]  ____________________________________ Batch number 24: sent the final model to clients ____________________________________
2023-03-21 01:03:25,202 : [INFO]  Batch number 24 model fetched from the server
2023-03-21 01:03:25,202 : [INFO]  _____________________________________________________ Batch number 24: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:25,202 : [INFO]  Batch 24: Training set : loss - 0.5453453063964844, accuracy - 0.7663043737411499, recall - 0.9347826242446899, AUC - 0.907608687877655, F1 - 0.7999999983985078, precision - 0.6991869807243347
2023-03-21 01:03:25,202 : [INFO]  Batch 24: Testing set : loss - 0.569404125213623, accuracy - 0.7254902124404907, recall - 0.9313725233078003, AUC - 0.8811033964157104, F1 - 0.7723577056592026, precision - 0.6597222089767456
2023-03-21 01:03:25,307 : [INFO]  Batch 25 initialized 
2023-03-21 01:03:25,664 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:25,895 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:25,896 : [INFO]  _____________________________________________________ Batch number 25: training Round 1 ____________________________________________________________
2023-03-21 01:03:27,853 : [INFO]  _____________________________________________________ Batch number 25: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:27,858 : [INFO]  Batch 25: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:27,858 : [INFO]  Batch 25, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:27,858 : [INFO]  ____________________________________Batch 25: round 1 finished ____________________________________
2023-03-21 01:03:27,860 : [INFO]  _____________________________________________________ Batch number 25: training Round 2 ____________________________________________________________
2023-03-21 01:03:28,451 : [INFO]  _____________________________________________________ Batch number 25: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:28,454 : [INFO]  Batch 25: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:28,454 : [INFO]  Batch 25, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:28,454 : [INFO]  ____________________________________Batch 25: round 2 finished ____________________________________
2023-03-21 01:03:28,454 : [INFO]  ____________________________________ Batch number 25: sent the final model to clients ____________________________________
2023-03-21 01:03:29,422 : [INFO]  Batch number 25 model fetched from the server
2023-03-21 01:03:29,422 : [INFO]  _____________________________________________________ Batch number 25: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:29,422 : [INFO]  Batch 25: Training set : loss - 0.5739431977272034, accuracy - 0.7336956262588501, recall - 0.945652186870575, AUC - 0.8696833848953247, F1 - 0.7802690812345651, precision - 0.6641221642494202
2023-03-21 01:03:29,422 : [INFO]  Batch 25: Testing set : loss - 0.62028968334198, accuracy - 0.6323529481887817, recall - 0.8627451062202454, AUC - 0.7783544659614563, F1 - 0.7011952080107272, precision - 0.5906040072441101
2023-03-21 01:03:29,485 : [INFO]  Batch 26 initialized 
2023-03-21 01:03:29,848 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:30,080 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:30,080 : [INFO]  _____________________________________________________ Batch number 26: training Round 1 ____________________________________________________________
2023-03-21 01:03:32,276 : [INFO]  _____________________________________________________ Batch number 26: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:32,279 : [INFO]  Batch 26: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:32,279 : [INFO]  Batch 26, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:32,280 : [INFO]  ____________________________________Batch 26: round 1 finished ____________________________________
2023-03-21 01:03:32,281 : [INFO]  _____________________________________________________ Batch number 26: training Round 2 ____________________________________________________________
2023-03-21 01:03:32,882 : [INFO]  _____________________________________________________ Batch number 26: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:32,886 : [INFO]  Batch 26: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:32,887 : [INFO]  Batch 26, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:32,887 : [INFO]  ____________________________________Batch 26: round 2 finished ____________________________________
2023-03-21 01:03:32,887 : [INFO]  ____________________________________ Batch number 26: sent the final model to clients ____________________________________
2023-03-21 01:03:33,845 : [INFO]  Batch number 26 model fetched from the server
2023-03-21 01:03:33,845 : [INFO]  _____________________________________________________ Batch number 26: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:33,845 : [INFO]  Batch 26: Training set : loss - 0.5735825896263123, accuracy - 0.739130437374115, recall - 0.945652186870575, AUC - 0.8586365580558777, F1 - 0.7837837813165838, precision - 0.6692307591438293
2023-03-21 01:03:33,845 : [INFO]  Batch 26: Testing set : loss - 0.5747478604316711, accuracy - 0.7401960492134094, recall - 0.9901960492134094, AUC - 0.8739907741546631, F1 - 0.7921568679809563, precision - 0.6601307392120361
2023-03-21 01:03:33,946 : [INFO]  Batch 27 initialized 
2023-03-21 01:03:34,488 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:34,899 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:34,900 : [INFO]  _____________________________________________________ Batch number 27: training Round 1 ____________________________________________________________
2023-03-21 01:03:38,707 : [INFO]  _____________________________________________________ Batch number 27: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:38,709 : [INFO]  Batch 27: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:38,710 : [INFO]  Batch 27, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:38,710 : [INFO]  ____________________________________Batch 27: round 1 finished ____________________________________
2023-03-21 01:03:38,712 : [INFO]  _____________________________________________________ Batch number 27: training Round 2 ____________________________________________________________
2023-03-21 01:03:39,361 : [INFO]  _____________________________________________________ Batch number 27: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:39,364 : [INFO]  Batch 27: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:39,364 : [INFO]  Batch 27, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:39,365 : [INFO]  ____________________________________Batch 27: round 2 finished ____________________________________
2023-03-21 01:03:39,365 : [INFO]  ____________________________________ Batch number 27: sent the final model to clients ____________________________________
2023-03-21 01:03:40,290 : [INFO]  Batch number 27 model fetched from the server
2023-03-21 01:03:40,290 : [INFO]  _____________________________________________________ Batch number 27: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:40,290 : [INFO]  Batch 27: Training set : loss - 0.5459553599357605, accuracy - 0.75, recall - 0.989130437374115, AUC - 0.9298204183578491, F1 - 0.7982456024040181, precision - 0.6691176295280457
2023-03-21 01:03:40,290 : [INFO]  Batch 27: Testing set : loss - 0.5523977279663086, accuracy - 0.7352941036224365, recall - 0.9803921580314636, AUC - 0.9181084036827087, F1 - 0.7874015706863677, precision - 0.6578947305679321
2023-03-21 01:03:40,373 : [INFO]  Batch 28 initialized 
2023-03-21 01:03:40,706 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:40,932 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:40,933 : [INFO]  _____________________________________________________ Batch number 28: training Round 1 ____________________________________________________________
2023-03-21 01:03:42,920 : [INFO]  _____________________________________________________ Batch number 28: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:42,922 : [INFO]  Batch 28: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:42,922 : [INFO]  Batch 28, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:42,922 : [INFO]  ____________________________________Batch 28: round 1 finished ____________________________________
2023-03-21 01:03:42,924 : [INFO]  _____________________________________________________ Batch number 28: training Round 2 ____________________________________________________________
2023-03-21 01:03:44,122 : [INFO]  _____________________________________________________ Batch number 28: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:44,125 : [INFO]  Batch 28: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:44,125 : [INFO]  Batch 28, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:44,125 : [INFO]  ____________________________________Batch 28: round 2 finished ____________________________________
2023-03-21 01:03:44,125 : [INFO]  ____________________________________ Batch number 28: sent the final model to clients ____________________________________
2023-03-21 01:03:45,151 : [INFO]  Batch number 28 model fetched from the server
2023-03-21 01:03:45,151 : [INFO]  _____________________________________________________ Batch number 28: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:45,151 : [INFO]  Batch 28: Training set : loss - 0.5628076791763306, accuracy - 0.7445651888847351, recall - 0.945652186870575, AUC - 0.8838610649108887, F1 - 0.7873303372908623, precision - 0.6744186282157898
2023-03-21 01:03:45,151 : [INFO]  Batch 28: Testing set : loss - 0.5963807106018066, accuracy - 0.7058823704719543, recall - 0.9411764740943909, AUC - 0.834534764289856, F1 - 0.7619047529167597, precision - 0.6399999856948853
2023-03-21 01:03:45,220 : [INFO]  Batch 29 initialized 
2023-03-21 01:03:45,564 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:45,798 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:45,799 : [INFO]  _____________________________________________________ Batch number 29: training Round 1 ____________________________________________________________
2023-03-21 01:03:50,579 : [INFO]  _____________________________________________________ Batch number 29: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:50,583 : [INFO]  Batch 29: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:50,583 : [INFO]  Batch 29, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:50,583 : [INFO]  ____________________________________Batch 29: round 1 finished ____________________________________
2023-03-21 01:03:50,586 : [INFO]  _____________________________________________________ Batch number 29: training Round 2 ____________________________________________________________
2023-03-21 01:03:51,482 : [INFO]  _____________________________________________________ Batch number 29: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:51,484 : [INFO]  Batch 29: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:51,485 : [INFO]  Batch 29, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:51,485 : [INFO]  ____________________________________Batch 29: round 2 finished ____________________________________
2023-03-21 01:03:51,485 : [INFO]  ____________________________________ Batch number 29: sent the final model to clients ____________________________________
2023-03-21 01:03:52,726 : [INFO]  Batch number 29 model fetched from the server
2023-03-21 01:03:52,726 : [INFO]  _____________________________________________________ Batch number 29: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:03:52,726 : [INFO]  Batch 29: Training set : loss - 0.5536330938339233, accuracy - 0.7880434989929199, recall - 0.97826087474823, AUC - 0.8989839553833008, F1 - 0.8219178233064445, precision - 0.7086614370346069
2023-03-21 01:03:52,726 : [INFO]  Batch 29: Testing set : loss - 0.578275203704834, accuracy - 0.7107843160629272, recall - 0.9411764740943909, AUC - 0.8605824708938599, F1 - 0.764940221312197, precision - 0.6442952752113342
2023-03-21 01:03:52,797 : [INFO]  Batch 30 initialized 
2023-03-21 01:03:53,598 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:03:53,907 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:03:53,908 : [INFO]  _____________________________________________________ Batch number 30: training Round 1 ____________________________________________________________
2023-03-21 01:03:57,553 : [INFO]  _____________________________________________________ Batch number 30: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:03:57,556 : [INFO]  Batch 30: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:57,557 : [INFO]  Batch 30, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:57,557 : [INFO]  ____________________________________Batch 30: round 1 finished ____________________________________
2023-03-21 01:03:57,560 : [INFO]  _____________________________________________________ Batch number 30: training Round 2 ____________________________________________________________
2023-03-21 01:03:58,600 : [INFO]  _____________________________________________________ Batch number 30: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:03:58,604 : [INFO]  Batch 30: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:03:58,605 : [INFO]  Batch 30, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:03:58,606 : [INFO]  ____________________________________Batch 30: round 2 finished ____________________________________
2023-03-21 01:03:58,606 : [INFO]  ____________________________________ Batch number 30: sent the final model to clients ____________________________________
2023-03-21 01:04:00,483 : [INFO]  Batch number 30 model fetched from the server
2023-03-21 01:04:00,483 : [INFO]  _____________________________________________________ Batch number 30: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:00,483 : [INFO]  Batch 30: Training set : loss - 0.5523395538330078, accuracy - 0.77173912525177, recall - 0.95652174949646, AUC - 0.8934900760650635, F1 - 0.8073394652438799, precision - 0.6984127163887024
2023-03-21 01:04:00,484 : [INFO]  Batch 30: Testing set : loss - 0.606349766254425, accuracy - 0.6617646813392639, recall - 0.9411764740943909, AUC - 0.8283833265304565, F1 - 0.735632191656886, precision - 0.6037735939025879
2023-03-21 01:04:00,576 : [INFO]  Batch 31 initialized 
2023-03-21 01:04:01,311 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:01,630 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:01,631 : [INFO]  _____________________________________________________ Batch number 31: training Round 1 ____________________________________________________________
2023-03-21 01:04:04,719 : [INFO]  _____________________________________________________ Batch number 31: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:04,721 : [INFO]  Batch 31: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:04,722 : [INFO]  Batch 31, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:04,722 : [INFO]  ____________________________________Batch 31: round 1 finished ____________________________________
2023-03-21 01:04:04,723 : [INFO]  _____________________________________________________ Batch number 31: training Round 2 ____________________________________________________________
2023-03-21 01:04:05,431 : [INFO]  _____________________________________________________ Batch number 31: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:05,434 : [INFO]  Batch 31: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:05,435 : [INFO]  Batch 31, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:05,435 : [INFO]  ____________________________________Batch 31: round 2 finished ____________________________________
2023-03-21 01:04:05,435 : [INFO]  ____________________________________ Batch number 31: sent the final model to clients ____________________________________
2023-03-21 01:04:06,579 : [INFO]  Batch number 31 model fetched from the server
2023-03-21 01:04:06,579 : [INFO]  _____________________________________________________ Batch number 31: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:06,579 : [INFO]  Batch 31: Training set : loss - 0.5361939668655396, accuracy - 0.8097826242446899, recall - 0.97826087474823, AUC - 0.9084357023239136, F1 - 0.8372093156429804, precision - 0.7317073345184326
2023-03-21 01:04:06,579 : [INFO]  Batch 31: Testing set : loss - 0.6162563562393188, accuracy - 0.6764705777168274, recall - 0.8921568393707275, AUC - 0.7796039581298828, F1 - 0.733870964361651, precision - 0.6232876777648926
2023-03-21 01:04:06,641 : [INFO]  Batch 32 initialized 
2023-03-21 01:04:07,255 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:07,552 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:07,554 : [INFO]  _____________________________________________________ Batch number 32: training Round 1 ____________________________________________________________
2023-03-21 01:04:10,070 : [INFO]  _____________________________________________________ Batch number 32: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:10,078 : [INFO]  Batch 32: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:10,079 : [INFO]  Batch 32, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:10,080 : [INFO]  ____________________________________Batch 32: round 1 finished ____________________________________
2023-03-21 01:04:10,084 : [INFO]  _____________________________________________________ Batch number 32: training Round 2 ____________________________________________________________
2023-03-21 01:04:10,992 : [INFO]  _____________________________________________________ Batch number 32: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:10,997 : [INFO]  Batch 32: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:11,000 : [INFO]  Batch 32, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:11,000 : [INFO]  ____________________________________Batch 32: round 2 finished ____________________________________
2023-03-21 01:04:11,000 : [INFO]  ____________________________________ Batch number 32: sent the final model to clients ____________________________________
2023-03-21 01:04:12,456 : [INFO]  Batch number 32 model fetched from the server
2023-03-21 01:04:12,456 : [INFO]  _____________________________________________________ Batch number 32: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:12,456 : [INFO]  Batch 32: Training set : loss - 0.5678127408027649, accuracy - 0.7445651888847351, recall - 0.9239130616188049, AUC - 0.8598180413246155, F1 - 0.7834101495168839, precision - 0.6800000071525574
2023-03-21 01:04:12,456 : [INFO]  Batch 32: Testing set : loss - 0.5930227637290955, accuracy - 0.6960784196853638, recall - 0.9509803652763367, AUC - 0.8282391428947449, F1 - 0.7578124819410732, precision - 0.6298701167106628
2023-03-21 01:04:12,539 : [INFO]  Batch 33 initialized 
2023-03-21 01:04:12,985 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:13,264 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:13,266 : [INFO]  _____________________________________________________ Batch number 33: training Round 1 ____________________________________________________________
2023-03-21 01:04:15,871 : [INFO]  _____________________________________________________ Batch number 33: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:15,873 : [INFO]  Batch 33: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:15,874 : [INFO]  Batch 33, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:15,874 : [INFO]  ____________________________________Batch 33: round 1 finished ____________________________________
2023-03-21 01:04:15,875 : [INFO]  _____________________________________________________ Batch number 33: training Round 2 ____________________________________________________________
2023-03-21 01:04:16,570 : [INFO]  _____________________________________________________ Batch number 33: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:16,572 : [INFO]  Batch 33: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:16,573 : [INFO]  Batch 33, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:16,573 : [INFO]  ____________________________________Batch 33: round 2 finished ____________________________________
2023-03-21 01:04:16,573 : [INFO]  ____________________________________ Batch number 33: sent the final model to clients ____________________________________
2023-03-21 01:04:17,919 : [INFO]  Batch number 33 model fetched from the server
2023-03-21 01:04:17,919 : [INFO]  _____________________________________________________ Batch number 33: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:17,919 : [INFO]  Batch 33: Training set : loss - 0.5615299344062805, accuracy - 0.7119565010070801, recall - 0.95652174949646, AUC - 0.9067226052284241, F1 - 0.7685589596712399, precision - 0.6423357725143433
2023-03-21 01:04:17,919 : [INFO]  Batch 33: Testing set : loss - 0.5916540622711182, accuracy - 0.7009803652763367, recall - 0.9803921580314636, AUC - 0.8496251702308655, F1 - 0.7662835174703679, precision - 0.6289308071136475
2023-03-21 01:04:18,008 : [INFO]  Batch 34 initialized 
2023-03-21 01:04:18,448 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:18,717 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:18,719 : [INFO]  _____________________________________________________ Batch number 34: training Round 1 ____________________________________________________________
2023-03-21 01:04:21,775 : [INFO]  _____________________________________________________ Batch number 34: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:21,778 : [INFO]  Batch 34: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:21,778 : [INFO]  Batch 34, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:21,778 : [INFO]  ____________________________________Batch 34: round 1 finished ____________________________________
2023-03-21 01:04:21,780 : [INFO]  _____________________________________________________ Batch number 34: training Round 2 ____________________________________________________________
2023-03-21 01:04:22,344 : [INFO]  _____________________________________________________ Batch number 34: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:22,346 : [INFO]  Batch 34: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:22,347 : [INFO]  Batch 34, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:22,347 : [INFO]  ____________________________________Batch 34: round 2 finished ____________________________________
2023-03-21 01:04:22,347 : [INFO]  ____________________________________ Batch number 34: sent the final model to clients ____________________________________
2023-03-21 01:04:23,280 : [INFO]  Batch number 34 model fetched from the server
2023-03-21 01:04:23,280 : [INFO]  _____________________________________________________ Batch number 34: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:23,280 : [INFO]  Batch 34: Training set : loss - 0.5570438504219055, accuracy - 0.77173912525177, recall - 0.989130437374115, AUC - 0.909735381603241, F1 - 0.8124999996198683, precision - 0.689393937587738
2023-03-21 01:04:23,280 : [INFO]  Batch 34: Testing set : loss - 0.5878989100456238, accuracy - 0.7156862616539001, recall - 0.9607843160629272, AUC - 0.8495290279388428, F1 - 0.7716535328266616, precision - 0.6447368264198303
2023-03-21 01:04:23,387 : [INFO]  Batch 35 initialized 
2023-03-21 01:04:23,729 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:23,969 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:23,971 : [INFO]  _____________________________________________________ Batch number 35: training Round 1 ____________________________________________________________
2023-03-21 01:04:27,613 : [INFO]  _____________________________________________________ Batch number 35: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:27,620 : [INFO]  Batch 35: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:27,621 : [INFO]  Batch 35, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:27,621 : [INFO]  ____________________________________Batch 35: round 1 finished ____________________________________
2023-03-21 01:04:27,624 : [INFO]  _____________________________________________________ Batch number 35: training Round 2 ____________________________________________________________
2023-03-21 01:04:28,724 : [INFO]  _____________________________________________________ Batch number 35: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:28,731 : [INFO]  Batch 35: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:28,732 : [INFO]  Batch 35, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:28,732 : [INFO]  ____________________________________Batch 35: round 2 finished ____________________________________
2023-03-21 01:04:28,732 : [INFO]  ____________________________________ Batch number 35: sent the final model to clients ____________________________________
2023-03-21 01:04:30,046 : [INFO]  Batch number 35 model fetched from the server
2023-03-21 01:04:30,046 : [INFO]  _____________________________________________________ Batch number 35: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:30,046 : [INFO]  Batch 35: Training set : loss - 0.5300220847129822, accuracy - 0.7989130616188049, recall - 0.945652186870575, AUC - 0.9230269193649292, F1 - 0.8246445648861002, precision - 0.7310924530029297
2023-03-21 01:04:30,046 : [INFO]  Batch 35: Testing set : loss - 0.5707408785820007, accuracy - 0.7254902124404907, recall - 0.9411764740943909, AUC - 0.8665417432785034, F1 - 0.7741935461775072, precision - 0.6575342416763306
2023-03-21 01:04:30,143 : [INFO]  Batch 36 initialized 
2023-03-21 01:04:30,515 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:30,788 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:30,789 : [INFO]  _____________________________________________________ Batch number 36: training Round 1 ____________________________________________________________
2023-03-21 01:04:33,774 : [INFO]  _____________________________________________________ Batch number 36: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:33,780 : [INFO]  Batch 36: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:33,781 : [INFO]  Batch 36, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:33,781 : [INFO]  ____________________________________Batch 36: round 1 finished ____________________________________
2023-03-21 01:04:33,788 : [INFO]  _____________________________________________________ Batch number 36: training Round 2 ____________________________________________________________
2023-03-21 01:04:34,598 : [INFO]  _____________________________________________________ Batch number 36: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:34,600 : [INFO]  Batch 36: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:34,601 : [INFO]  Batch 36, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:34,601 : [INFO]  ____________________________________Batch 36: round 2 finished ____________________________________
2023-03-21 01:04:34,601 : [INFO]  ____________________________________ Batch number 36: sent the final model to clients ____________________________________
2023-03-21 01:04:35,892 : [INFO]  Batch number 36 model fetched from the server
2023-03-21 01:04:35,892 : [INFO]  _____________________________________________________ Batch number 36: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:35,892 : [INFO]  Batch 36: Training set : loss - 0.5420899391174316, accuracy - 0.77173912525177, recall - 0.967391312122345, AUC - 0.9149338603019714, F1 - 0.8090909118100631, precision - 0.6953125
2023-03-21 01:04:35,892 : [INFO]  Batch 36: Testing set : loss - 0.5869531631469727, accuracy - 0.686274528503418, recall - 0.9313725233078003, AUC - 0.8602460622787476, F1 - 0.7480314877703004, precision - 0.625
2023-03-21 01:04:36,033 : [INFO]  Batch 37 initialized 
2023-03-21 01:04:36,767 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:37,226 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:37,228 : [INFO]  _____________________________________________________ Batch number 37: training Round 1 ____________________________________________________________
2023-03-21 01:04:40,573 : [INFO]  _____________________________________________________ Batch number 37: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:40,577 : [INFO]  Batch 37: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:40,577 : [INFO]  Batch 37, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:40,577 : [INFO]  ____________________________________Batch 37: round 1 finished ____________________________________
2023-03-21 01:04:40,580 : [INFO]  _____________________________________________________ Batch number 37: training Round 2 ____________________________________________________________
2023-03-21 01:04:41,879 : [INFO]  _____________________________________________________ Batch number 37: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:41,882 : [INFO]  Batch 37: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:41,882 : [INFO]  Batch 37, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:41,882 : [INFO]  ____________________________________Batch 37: round 2 finished ____________________________________
2023-03-21 01:04:41,883 : [INFO]  ____________________________________ Batch number 37: sent the final model to clients ____________________________________
2023-03-21 01:04:45,064 : [INFO]  Batch number 37 model fetched from the server
2023-03-21 01:04:45,064 : [INFO]  _____________________________________________________ Batch number 37: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:45,064 : [INFO]  Batch 37: Training set : loss - 0.5220478177070618, accuracy - 0.8260869383811951, recall - 0.989130437374115, AUC - 0.9395084977149963, F1 - 0.85046729385327, precision - 0.7459016442298889
2023-03-21 01:04:45,065 : [INFO]  Batch 37: Testing set : loss - 0.5618001222610474, accuracy - 0.7450980544090271, recall - 0.9215686321258545, AUC - 0.8823049068450928, F1 - 0.7833333458751439, precision - 0.6811594367027283
2023-03-21 01:04:45,203 : [INFO]  Batch 38 initialized 
2023-03-21 01:04:45,970 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:46,285 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:46,287 : [INFO]  _____________________________________________________ Batch number 38: training Round 1 ____________________________________________________________
2023-03-21 01:04:52,645 : [INFO]  _____________________________________________________ Batch number 38: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:04:52,651 : [INFO]  Batch 38: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:52,652 : [INFO]  Batch 38, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:52,652 : [INFO]  ____________________________________Batch 38: round 1 finished ____________________________________
2023-03-21 01:04:52,657 : [INFO]  _____________________________________________________ Batch number 38: training Round 2 ____________________________________________________________
2023-03-21 01:04:54,012 : [INFO]  _____________________________________________________ Batch number 38: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:04:54,018 : [INFO]  Batch 38: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:04:54,019 : [INFO]  Batch 38, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:04:54,019 : [INFO]  ____________________________________Batch 38: round 2 finished ____________________________________
2023-03-21 01:04:54,019 : [INFO]  ____________________________________ Batch number 38: sent the final model to clients ____________________________________
2023-03-21 01:04:56,287 : [INFO]  Batch number 38 model fetched from the server
2023-03-21 01:04:56,287 : [INFO]  _____________________________________________________ Batch number 38: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:04:56,287 : [INFO]  Batch 38: Training set : loss - 0.5579647421836853, accuracy - 0.760869562625885, recall - 0.967391312122345, AUC - 0.8925448656082153, F1 - 0.8018017969254538, precision - 0.6846153736114502
2023-03-21 01:04:56,287 : [INFO]  Batch 38: Testing set : loss - 0.5700263381004333, accuracy - 0.7303921580314636, recall - 0.970588207244873, AUC - 0.8886005282402039, F1 - 0.7826087000324987, precision - 0.6556291580200195
2023-03-21 01:04:56,405 : [INFO]  Batch 39 initialized 
2023-03-21 01:04:57,497 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:04:57,919 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:04:57,921 : [INFO]  _____________________________________________________ Batch number 39: training Round 1 ____________________________________________________________
2023-03-21 01:05:03,997 : [INFO]  _____________________________________________________ Batch number 39: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:04,003 : [INFO]  Batch 39: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:04,004 : [INFO]  Batch 39, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:04,004 : [INFO]  ____________________________________Batch 39: round 1 finished ____________________________________
2023-03-21 01:05:04,008 : [INFO]  _____________________________________________________ Batch number 39: training Round 2 ____________________________________________________________
2023-03-21 01:05:05,567 : [INFO]  _____________________________________________________ Batch number 39: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:05,572 : [INFO]  Batch 39: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:05,573 : [INFO]  Batch 39, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:05,573 : [INFO]  ____________________________________Batch 39: round 2 finished ____________________________________
2023-03-21 01:05:05,574 : [INFO]  ____________________________________ Batch number 39: sent the final model to clients ____________________________________
2023-03-21 01:05:08,698 : [INFO]  Batch number 39 model fetched from the server
2023-03-21 01:05:08,699 : [INFO]  _____________________________________________________ Batch number 39: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:08,699 : [INFO]  Batch 39: Training set : loss - 0.5388087630271912, accuracy - 0.7663043737411499, recall - 0.945652186870575, AUC - 0.9236177206039429, F1 - 0.8018433093396824, precision - 0.6959999799728394
2023-03-21 01:05:08,699 : [INFO]  Batch 39: Testing set : loss - 0.6189493536949158, accuracy - 0.6470588445663452, recall - 0.9509803652763367, AUC - 0.8202133774757385, F1 - 0.7293232793663494, precision - 0.5914633870124817
2023-03-21 01:05:08,843 : [INFO]  Batch 40 initialized 
2023-03-21 01:05:09,422 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:09,685 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:09,687 : [INFO]  _____________________________________________________ Batch number 40: training Round 1 ____________________________________________________________
2023-03-21 01:05:11,897 : [INFO]  _____________________________________________________ Batch number 40: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:11,900 : [INFO]  Batch 40: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:11,900 : [INFO]  Batch 40, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:11,900 : [INFO]  ____________________________________Batch 40: round 1 finished ____________________________________
2023-03-21 01:05:11,901 : [INFO]  _____________________________________________________ Batch number 40: training Round 2 ____________________________________________________________
2023-03-21 01:05:13,662 : [INFO]  _____________________________________________________ Batch number 40: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:13,665 : [INFO]  Batch 40: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:13,665 : [INFO]  Batch 40, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:13,665 : [INFO]  ____________________________________Batch 40: round 2 finished ____________________________________
2023-03-21 01:05:13,666 : [INFO]  ____________________________________ Batch number 40: sent the final model to clients ____________________________________
2023-03-21 01:05:14,674 : [INFO]  Batch number 40 model fetched from the server
2023-03-21 01:05:14,675 : [INFO]  _____________________________________________________ Batch number 40: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:14,678 : [INFO]  Batch 40: Training set : loss - 0.5561450123786926, accuracy - 0.7771739363670349, recall - 0.945652186870575, AUC - 0.8935490846633911, F1 - 0.8093023179556109, precision - 0.707317054271698
2023-03-21 01:05:14,678 : [INFO]  Batch 40: Testing set : loss - 0.5791916251182556, accuracy - 0.7156862616539001, recall - 0.9607843160629272, AUC - 0.8725008964538574, F1 - 0.7716535328266616, precision - 0.6447368264198303
2023-03-21 01:05:14,774 : [INFO]  Batch 41 initialized 
2023-03-21 01:05:15,270 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:15,550 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:15,553 : [INFO]  _____________________________________________________ Batch number 41: training Round 1 ____________________________________________________________
2023-03-21 01:05:18,728 : [INFO]  _____________________________________________________ Batch number 41: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:18,730 : [INFO]  Batch 41: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:18,730 : [INFO]  Batch 41, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:18,730 : [INFO]  ____________________________________Batch 41: round 1 finished ____________________________________
2023-03-21 01:05:18,732 : [INFO]  _____________________________________________________ Batch number 41: training Round 2 ____________________________________________________________
2023-03-21 01:05:19,296 : [INFO]  _____________________________________________________ Batch number 41: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:19,298 : [INFO]  Batch 41: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:19,298 : [INFO]  Batch 41, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:19,299 : [INFO]  ____________________________________Batch 41: round 2 finished ____________________________________
2023-03-21 01:05:19,299 : [INFO]  ____________________________________ Batch number 41: sent the final model to clients ____________________________________
2023-03-21 01:05:20,229 : [INFO]  Batch number 41 model fetched from the server
2023-03-21 01:05:20,229 : [INFO]  _____________________________________________________ Batch number 41: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:20,229 : [INFO]  Batch 41: Training set : loss - 0.5235222578048706, accuracy - 0.804347813129425, recall - 0.95652174949646, AUC - 0.9379726052284241, F1 - 0.8301886933348109, precision - 0.7333333492279053
2023-03-21 01:05:20,229 : [INFO]  Batch 41: Testing set : loss - 0.5861942172050476, accuracy - 0.6960784196853638, recall - 0.970588207244873, AUC - 0.8752883672714233, F1 - 0.7615384428740959, precision - 0.6265822649002075
2023-03-21 01:05:20,313 : [INFO]  Batch 42 initialized 
2023-03-21 01:05:20,653 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:20,908 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:20,910 : [INFO]  _____________________________________________________ Batch number 42: training Round 1 ____________________________________________________________
2023-03-21 01:05:22,905 : [INFO]  _____________________________________________________ Batch number 42: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:22,907 : [INFO]  Batch 42: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:22,907 : [INFO]  Batch 42, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:22,908 : [INFO]  ____________________________________Batch 42: round 1 finished ____________________________________
2023-03-21 01:05:22,909 : [INFO]  _____________________________________________________ Batch number 42: training Round 2 ____________________________________________________________
2023-03-21 01:05:23,471 : [INFO]  _____________________________________________________ Batch number 42: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:23,473 : [INFO]  Batch 42: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:23,474 : [INFO]  Batch 42, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:23,474 : [INFO]  ____________________________________Batch 42: round 2 finished ____________________________________
2023-03-21 01:05:23,474 : [INFO]  ____________________________________ Batch number 42: sent the final model to clients ____________________________________
2023-03-21 01:05:24,365 : [INFO]  Batch number 42 model fetched from the server
2023-03-21 01:05:24,365 : [INFO]  _____________________________________________________ Batch number 42: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:24,365 : [INFO]  Batch 42: Training set : loss - 0.5409555435180664, accuracy - 0.782608687877655, recall - 0.9347826242446899, AUC - 0.9128071665763855, F1 - 0.8113207427493694, precision - 0.7166666388511658
2023-03-21 01:05:24,365 : [INFO]  Batch 42: Testing set : loss - 0.6014391183853149, accuracy - 0.686274528503418, recall - 0.8529411554336548, AUC - 0.7976258993148804, F1 - 0.7310924384058735, precision - 0.6397058963775635
2023-03-21 01:05:24,459 : [INFO]  Batch 43 initialized 
2023-03-21 01:05:24,794 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:25,050 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:25,052 : [INFO]  _____________________________________________________ Batch number 43: training Round 1 ____________________________________________________________
2023-03-21 01:05:27,045 : [INFO]  _____________________________________________________ Batch number 43: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:27,047 : [INFO]  Batch 43: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:27,048 : [INFO]  Batch 43, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:27,048 : [INFO]  ____________________________________Batch 43: round 1 finished ____________________________________
2023-03-21 01:05:27,049 : [INFO]  _____________________________________________________ Batch number 43: training Round 2 ____________________________________________________________
2023-03-21 01:05:27,609 : [INFO]  _____________________________________________________ Batch number 43: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:27,611 : [INFO]  Batch 43: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:27,612 : [INFO]  Batch 43, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:27,612 : [INFO]  ____________________________________Batch 43: round 2 finished ____________________________________
2023-03-21 01:05:27,612 : [INFO]  ____________________________________ Batch number 43: sent the final model to clients ____________________________________
2023-03-21 01:05:28,489 : [INFO]  Batch number 43 model fetched from the server
2023-03-21 01:05:28,489 : [INFO]  _____________________________________________________ Batch number 43: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:28,489 : [INFO]  Batch 43: Training set : loss - 0.5495008826255798, accuracy - 0.77173912525177, recall - 0.945652186870575, AUC - 0.9017603993415833, F1 - 0.805555551385683, precision - 0.7016128897666931
2023-03-21 01:05:28,489 : [INFO]  Batch 43: Testing set : loss - 0.5959976315498352, accuracy - 0.6715686321258545, recall - 0.9313725233078003, AUC - 0.8532295227050781, F1 - 0.7392996111873288, precision - 0.6129032373428345
2023-03-21 01:05:28,555 : [INFO]  Batch 44 initialized 
2023-03-21 01:05:28,929 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:29,188 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:29,190 : [INFO]  _____________________________________________________ Batch number 44: training Round 1 ____________________________________________________________
2023-03-21 01:05:31,193 : [INFO]  _____________________________________________________ Batch number 44: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:31,195 : [INFO]  Batch 44: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:31,196 : [INFO]  Batch 44, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:31,196 : [INFO]  ____________________________________Batch 44: round 1 finished ____________________________________
2023-03-21 01:05:31,197 : [INFO]  _____________________________________________________ Batch number 44: training Round 2 ____________________________________________________________
2023-03-21 01:05:31,798 : [INFO]  _____________________________________________________ Batch number 44: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:31,800 : [INFO]  Batch 44: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:31,800 : [INFO]  Batch 44, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:31,801 : [INFO]  ____________________________________Batch 44: round 2 finished ____________________________________
2023-03-21 01:05:31,801 : [INFO]  ____________________________________ Batch number 44: sent the final model to clients ____________________________________
2023-03-21 01:05:32,755 : [INFO]  Batch number 44 model fetched from the server
2023-03-21 01:05:32,755 : [INFO]  _____________________________________________________ Batch number 44: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:32,755 : [INFO]  Batch 44: Training set : loss - 0.5371602177619934, accuracy - 0.7989130616188049, recall - 0.95652174949646, AUC - 0.9158790111541748, F1 - 0.8262910976690323, precision - 0.7272727489471436
2023-03-21 01:05:32,755 : [INFO]  Batch 44: Testing set : loss - 0.5765030384063721, accuracy - 0.7401960492134094, recall - 0.9803921580314636, AUC - 0.8806228041648865, F1 - 0.7905138312786024, precision - 0.6622516512870789
2023-03-21 01:05:32,827 : [INFO]  Batch 45 initialized 
2023-03-21 01:05:33,199 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:33,462 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:33,465 : [INFO]  _____________________________________________________ Batch number 45: training Round 1 ____________________________________________________________
2023-03-21 01:05:35,443 : [INFO]  _____________________________________________________ Batch number 45: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:35,445 : [INFO]  Batch 45: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:35,445 : [INFO]  Batch 45, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:35,445 : [INFO]  ____________________________________Batch 45: round 1 finished ____________________________________
2023-03-21 01:05:35,447 : [INFO]  _____________________________________________________ Batch number 45: training Round 2 ____________________________________________________________
2023-03-21 01:05:35,980 : [INFO]  _____________________________________________________ Batch number 45: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:35,982 : [INFO]  Batch 45: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:35,982 : [INFO]  Batch 45, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:35,983 : [INFO]  ____________________________________Batch 45: round 2 finished ____________________________________
2023-03-21 01:05:35,983 : [INFO]  ____________________________________ Batch number 45: sent the final model to clients ____________________________________
2023-03-21 01:05:36,876 : [INFO]  Batch number 45 model fetched from the server
2023-03-21 01:05:36,876 : [INFO]  _____________________________________________________ Batch number 45: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:36,876 : [INFO]  Batch 45: Training set : loss - 0.5291523933410645, accuracy - 0.7663043737411499, recall - 0.95652174949646, AUC - 0.9529773592948914, F1 - 0.8036529900037883, precision - 0.6929134130477905
2023-03-21 01:05:36,876 : [INFO]  Batch 45: Testing set : loss - 0.5603643655776978, accuracy - 0.7107843160629272, recall - 0.9215686321258545, AUC - 0.8971068859100342, F1 - 0.7611335980335105, precision - 0.6482758522033691
2023-03-21 01:05:36,946 : [INFO]  Batch 46 initialized 
2023-03-21 01:05:37,298 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:37,554 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:37,557 : [INFO]  _____________________________________________________ Batch number 46: training Round 1 ____________________________________________________________
2023-03-21 01:05:39,633 : [INFO]  _____________________________________________________ Batch number 46: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:39,635 : [INFO]  Batch 46: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:39,636 : [INFO]  Batch 46, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:39,636 : [INFO]  ____________________________________Batch 46: round 1 finished ____________________________________
2023-03-21 01:05:39,637 : [INFO]  _____________________________________________________ Batch number 46: training Round 2 ____________________________________________________________
2023-03-21 01:05:40,194 : [INFO]  _____________________________________________________ Batch number 46: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:40,197 : [INFO]  Batch 46: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:40,197 : [INFO]  Batch 46, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:40,197 : [INFO]  ____________________________________Batch 46: round 2 finished ____________________________________
2023-03-21 01:05:40,197 : [INFO]  ____________________________________ Batch number 46: sent the final model to clients ____________________________________
2023-03-21 01:05:41,290 : [INFO]  Batch number 46 model fetched from the server
2023-03-21 01:05:41,290 : [INFO]  _____________________________________________________ Batch number 46: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:41,290 : [INFO]  Batch 46: Training set : loss - 0.5351237058639526, accuracy - 0.782608687877655, recall - 0.97826087474823, AUC - 0.9399220943450928, F1 - 0.8181818199945875, precision - 0.703125
2023-03-21 01:05:41,290 : [INFO]  Batch 46: Testing set : loss - 0.5799485445022583, accuracy - 0.6960784196853638, recall - 0.9215686321258545, AUC - 0.870242178440094, F1 - 0.7519999868774412, precision - 0.6351351141929626
2023-03-21 01:05:41,381 : [INFO]  Batch 47 initialized 
2023-03-21 01:05:41,731 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:41,997 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:42,000 : [INFO]  _____________________________________________________ Batch number 47: training Round 1 ____________________________________________________________
2023-03-21 01:05:44,683 : [INFO]  _____________________________________________________ Batch number 47: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:44,686 : [INFO]  Batch 47: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:44,687 : [INFO]  Batch 47, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:44,687 : [INFO]  ____________________________________Batch 47: round 1 finished ____________________________________
2023-03-21 01:05:44,689 : [INFO]  _____________________________________________________ Batch number 47: training Round 2 ____________________________________________________________
2023-03-21 01:05:45,571 : [INFO]  _____________________________________________________ Batch number 47: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:45,577 : [INFO]  Batch 47: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:45,578 : [INFO]  Batch 47, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:45,578 : [INFO]  ____________________________________Batch 47: round 2 finished ____________________________________
2023-03-21 01:05:45,578 : [INFO]  ____________________________________ Batch number 47: sent the final model to clients ____________________________________
2023-03-21 01:05:47,012 : [INFO]  Batch number 47 model fetched from the server
2023-03-21 01:05:47,012 : [INFO]  _____________________________________________________ Batch number 47: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:47,012 : [INFO]  Batch 47: Training set : loss - 0.5423442721366882, accuracy - 0.7771739363670349, recall - 0.945652186870575, AUC - 0.9208411574363708, F1 - 0.8093023179556109, precision - 0.707317054271698
2023-03-21 01:05:47,012 : [INFO]  Batch 47: Testing set : loss - 0.5712680816650391, accuracy - 0.7156862616539001, recall - 0.9509803652763367, AUC - 0.9061899185180664, F1 - 0.7698412463913699, precision - 0.6466666460037231
2023-03-21 01:05:47,129 : [INFO]  Batch 48 initialized 
2023-03-21 01:05:47,688 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:47,953 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:47,956 : [INFO]  _____________________________________________________ Batch number 48: training Round 1 ____________________________________________________________
2023-03-21 01:05:51,448 : [INFO]  _____________________________________________________ Batch number 48: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:51,451 : [INFO]  Batch 48: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:51,451 : [INFO]  Batch 48, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:51,451 : [INFO]  ____________________________________Batch 48: round 1 finished ____________________________________
2023-03-21 01:05:51,453 : [INFO]  _____________________________________________________ Batch number 48: training Round 2 ____________________________________________________________
2023-03-21 01:05:52,254 : [INFO]  _____________________________________________________ Batch number 48: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:52,257 : [INFO]  Batch 48: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:52,257 : [INFO]  Batch 48, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:52,257 : [INFO]  ____________________________________Batch 48: round 2 finished ____________________________________
2023-03-21 01:05:52,258 : [INFO]  ____________________________________ Batch number 48: sent the final model to clients ____________________________________
2023-03-21 01:05:54,140 : [INFO]  Batch number 48 model fetched from the server
2023-03-21 01:05:54,140 : [INFO]  _____________________________________________________ Batch number 48: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:05:54,141 : [INFO]  Batch 48: Training set : loss - 0.555657148361206, accuracy - 0.717391312122345, recall - 0.9347826242446899, AUC - 0.9255080223083496, F1 - 0.7678571305408765, precision - 0.6515151262283325
2023-03-21 01:05:54,141 : [INFO]  Batch 48: Testing set : loss - 0.5664631724357605, accuracy - 0.7352941036224365, recall - 0.9313725233078003, AUC - 0.8853325843811035, F1 - 0.7786885235649829, precision - 0.6690140962600708
2023-03-21 01:05:54,263 : [INFO]  Batch 49 initialized 
2023-03-21 01:05:54,714 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:05:54,982 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:05:54,984 : [INFO]  _____________________________________________________ Batch number 49: training Round 1 ____________________________________________________________
2023-03-21 01:05:58,172 : [INFO]  _____________________________________________________ Batch number 49: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:05:58,176 : [INFO]  Batch 49: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:58,177 : [INFO]  Batch 49, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:58,177 : [INFO]  ____________________________________Batch 49: round 1 finished ____________________________________
2023-03-21 01:05:58,178 : [INFO]  _____________________________________________________ Batch number 49: training Round 2 ____________________________________________________________
2023-03-21 01:05:59,163 : [INFO]  _____________________________________________________ Batch number 49: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:05:59,167 : [INFO]  Batch 49: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:05:59,168 : [INFO]  Batch 49, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:05:59,168 : [INFO]  ____________________________________Batch 49: round 2 finished ____________________________________
2023-03-21 01:05:59,168 : [INFO]  ____________________________________ Batch number 49: sent the final model to clients ____________________________________
2023-03-21 01:06:00,547 : [INFO]  Batch number 49 model fetched from the server
2023-03-21 01:06:00,547 : [INFO]  _____________________________________________________ Batch number 49: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:00,547 : [INFO]  Batch 49: Training set : loss - 0.5600430965423584, accuracy - 0.7336956262588501, recall - 0.9239130616188049, AUC - 0.8877007961273193, F1 - 0.7762556999604265, precision - 0.6692913174629211
2023-03-21 01:06:00,547 : [INFO]  Batch 49: Testing set : loss - 0.6011492609977722, accuracy - 0.6617646813392639, recall - 0.8725489974021912, AUC - 0.8143502473831177, F1 - 0.7206477461564007, precision - 0.6137930750846863
2023-03-21 01:06:00,644 : [INFO]  Batch 50 initialized 
2023-03-21 01:06:01,194 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:01,567 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:01,571 : [INFO]  _____________________________________________________ Batch number 50: training Round 1 ____________________________________________________________
2023-03-21 01:06:04,926 : [INFO]  _____________________________________________________ Batch number 50: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:04,929 : [INFO]  Batch 50: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:04,929 : [INFO]  Batch 50, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:04,929 : [INFO]  ____________________________________Batch 50: round 1 finished ____________________________________
2023-03-21 01:06:04,930 : [INFO]  _____________________________________________________ Batch number 50: training Round 2 ____________________________________________________________
2023-03-21 01:06:05,622 : [INFO]  _____________________________________________________ Batch number 50: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:05,625 : [INFO]  Batch 50: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:05,626 : [INFO]  Batch 50, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:05,626 : [INFO]  ____________________________________Batch 50: round 2 finished ____________________________________
2023-03-21 01:06:05,626 : [INFO]  ____________________________________ Batch number 50: sent the final model to clients ____________________________________
2023-03-21 01:06:07,559 : [INFO]  Batch number 50 model fetched from the server
2023-03-21 01:06:07,560 : [INFO]  _____________________________________________________ Batch number 50: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:07,560 : [INFO]  Batch 50: Training set : loss - 0.5449814796447754, accuracy - 0.782608687877655, recall - 0.97826087474823, AUC - 0.9198960065841675, F1 - 0.8181818199945875, precision - 0.703125
2023-03-21 01:06:07,560 : [INFO]  Batch 50: Testing set : loss - 0.5754119157791138, accuracy - 0.7156862616539001, recall - 0.9509803652763367, AUC - 0.8887927532196045, F1 - 0.7698412463913699, precision - 0.6466666460037231
2023-03-21 01:06:07,652 : [INFO]  Batch 51 initialized 
2023-03-21 01:06:08,200 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:08,467 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:08,470 : [INFO]  _____________________________________________________ Batch number 51: training Round 1 ____________________________________________________________
2023-03-21 01:06:10,661 : [INFO]  _____________________________________________________ Batch number 51: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:10,663 : [INFO]  Batch 51: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:10,664 : [INFO]  Batch 51, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:10,664 : [INFO]  ____________________________________Batch 51: round 1 finished ____________________________________
2023-03-21 01:06:10,665 : [INFO]  _____________________________________________________ Batch number 51: training Round 2 ____________________________________________________________
2023-03-21 01:06:11,264 : [INFO]  _____________________________________________________ Batch number 51: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:11,267 : [INFO]  Batch 51: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:11,267 : [INFO]  Batch 51, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:11,267 : [INFO]  ____________________________________Batch 51: round 2 finished ____________________________________
2023-03-21 01:06:11,267 : [INFO]  ____________________________________ Batch number 51: sent the final model to clients ____________________________________
2023-03-21 01:06:12,228 : [INFO]  Batch number 51 model fetched from the server
2023-03-21 01:06:12,229 : [INFO]  _____________________________________________________ Batch number 51: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:12,229 : [INFO]  Batch 51: Training set : loss - 0.5558502078056335, accuracy - 0.7554348111152649, recall - 0.9130434989929199, AUC - 0.8810255527496338, F1 - 0.7887324049631039, precision - 0.6942148804664612
2023-03-21 01:06:12,229 : [INFO]  Batch 51: Testing set : loss - 0.5669739842414856, accuracy - 0.7303921580314636, recall - 0.9607843160629272, AUC - 0.9103710055351257, F1 - 0.780876495641719, precision - 0.6577181220054626
2023-03-21 01:06:12,297 : [INFO]  Batch 52 initialized 
2023-03-21 01:06:12,690 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:12,953 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:12,956 : [INFO]  _____________________________________________________ Batch number 52: training Round 1 ____________________________________________________________
2023-03-21 01:06:15,535 : [INFO]  _____________________________________________________ Batch number 52: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:15,538 : [INFO]  Batch 52: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:15,538 : [INFO]  Batch 52, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:15,538 : [INFO]  ____________________________________Batch 52: round 1 finished ____________________________________
2023-03-21 01:06:15,540 : [INFO]  _____________________________________________________ Batch number 52: training Round 2 ____________________________________________________________
2023-03-21 01:06:16,137 : [INFO]  _____________________________________________________ Batch number 52: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:16,139 : [INFO]  Batch 52: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:16,139 : [INFO]  Batch 52, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:16,140 : [INFO]  ____________________________________Batch 52: round 2 finished ____________________________________
2023-03-21 01:06:16,140 : [INFO]  ____________________________________ Batch number 52: sent the final model to clients ____________________________________
2023-03-21 01:06:17,112 : [INFO]  Batch number 52 model fetched from the server
2023-03-21 01:06:17,112 : [INFO]  _____________________________________________________ Batch number 52: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:17,112 : [INFO]  Batch 52: Training set : loss - 0.5851117968559265, accuracy - 0.70652174949646, recall - 0.9239130616188049, AUC - 0.8643667697906494, F1 - 0.7589285650043459, precision - 0.6439393758773804
2023-03-21 01:06:17,112 : [INFO]  Batch 52: Testing set : loss - 0.6014034152030945, accuracy - 0.6666666865348816, recall - 0.8529411554336548, AUC - 0.8075740337371826, F1 - 0.7190082421695898, precision - 0.6214285492897034
2023-03-21 01:06:17,180 : [INFO]  Batch 53 initialized 
2023-03-21 01:06:17,530 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:17,791 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:17,794 : [INFO]  _____________________________________________________ Batch number 53: training Round 1 ____________________________________________________________
2023-03-21 01:06:20,748 : [INFO]  _____________________________________________________ Batch number 53: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:20,750 : [INFO]  Batch 53: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:20,751 : [INFO]  Batch 53, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:20,751 : [INFO]  ____________________________________Batch 53: round 1 finished ____________________________________
2023-03-21 01:06:20,752 : [INFO]  _____________________________________________________ Batch number 53: training Round 2 ____________________________________________________________
2023-03-21 01:06:21,378 : [INFO]  _____________________________________________________ Batch number 53: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:21,380 : [INFO]  Batch 53: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:21,381 : [INFO]  Batch 53, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:21,381 : [INFO]  ____________________________________Batch 53: round 2 finished ____________________________________
2023-03-21 01:06:21,381 : [INFO]  ____________________________________ Batch number 53: sent the final model to clients ____________________________________
2023-03-21 01:06:23,430 : [INFO]  Batch number 53 model fetched from the server
2023-03-21 01:06:23,431 : [INFO]  _____________________________________________________ Batch number 53: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:23,431 : [INFO]  Batch 53: Training set : loss - 0.5401004552841187, accuracy - 0.7989130616188049, recall - 0.967391312122345, AUC - 0.9253307580947876, F1 - 0.827906996085877, precision - 0.7235772609710693
2023-03-21 01:06:23,431 : [INFO]  Batch 53: Testing set : loss - 0.6008845567703247, accuracy - 0.6715686321258545, recall - 0.9313725233078003, AUC - 0.8420799970626831, F1 - 0.7392996111873288, precision - 0.6129032373428345
2023-03-21 01:06:23,506 : [INFO]  Batch 54 initialized 
2023-03-21 01:06:24,051 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:24,345 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:24,348 : [INFO]  _____________________________________________________ Batch number 54: training Round 1 ____________________________________________________________
2023-03-21 01:06:26,752 : [INFO]  _____________________________________________________ Batch number 54: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:26,755 : [INFO]  Batch 54: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:26,756 : [INFO]  Batch 54, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:26,756 : [INFO]  ____________________________________Batch 54: round 1 finished ____________________________________
2023-03-21 01:06:26,758 : [INFO]  _____________________________________________________ Batch number 54: training Round 2 ____________________________________________________________
2023-03-21 01:06:27,593 : [INFO]  _____________________________________________________ Batch number 54: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:27,596 : [INFO]  Batch 54: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:27,597 : [INFO]  Batch 54, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:27,597 : [INFO]  ____________________________________Batch 54: round 2 finished ____________________________________
2023-03-21 01:06:27,597 : [INFO]  ____________________________________ Batch number 54: sent the final model to clients ____________________________________
2023-03-21 01:06:28,621 : [INFO]  Batch number 54 model fetched from the server
2023-03-21 01:06:28,622 : [INFO]  _____________________________________________________ Batch number 54: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:28,622 : [INFO]  Batch 54: Training set : loss - 0.5491732954978943, accuracy - 0.804347813129425, recall - 0.967391312122345, AUC - 0.8950259685516357, F1 - 0.8317757196869534, precision - 0.7295082211494446
2023-03-21 01:06:28,622 : [INFO]  Batch 54: Testing set : loss - 0.6139985918998718, accuracy - 0.6421568393707275, recall - 0.8529411554336548, AUC - 0.8063244819641113, F1 - 0.7044534505534195, precision - 0.6000000238418579
2023-03-21 01:06:28,711 : [INFO]  Batch 55 initialized 
2023-03-21 01:06:29,068 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:29,331 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:29,334 : [INFO]  _____________________________________________________ Batch number 55: training Round 1 ____________________________________________________________
2023-03-21 01:06:31,324 : [INFO]  _____________________________________________________ Batch number 55: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:31,326 : [INFO]  Batch 55: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:31,326 : [INFO]  Batch 55, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:31,326 : [INFO]  ____________________________________Batch 55: round 1 finished ____________________________________
2023-03-21 01:06:31,328 : [INFO]  _____________________________________________________ Batch number 55: training Round 2 ____________________________________________________________
2023-03-21 01:06:31,894 : [INFO]  _____________________________________________________ Batch number 55: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:31,896 : [INFO]  Batch 55: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:31,896 : [INFO]  Batch 55, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:31,896 : [INFO]  ____________________________________Batch 55: round 2 finished ____________________________________
2023-03-21 01:06:31,896 : [INFO]  ____________________________________ Batch number 55: sent the final model to clients ____________________________________
2023-03-21 01:06:32,825 : [INFO]  Batch number 55 model fetched from the server
2023-03-21 01:06:32,825 : [INFO]  _____________________________________________________ Batch number 55: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:32,825 : [INFO]  Batch 55: Training set : loss - 0.5330624580383301, accuracy - 0.782608687877655, recall - 0.9347826242446899, AUC - 0.9202504754066467, F1 - 0.8113207427493694, precision - 0.7166666388511658
2023-03-21 01:06:32,825 : [INFO]  Batch 55: Testing set : loss - 0.5876731276512146, accuracy - 0.7058823704719543, recall - 0.8921568393707275, AUC - 0.8459727168083191, F1 - 0.7520660914388578, precision - 0.6499999761581421
2023-03-21 01:06:32,939 : [INFO]  Batch 56 initialized 
2023-03-21 01:06:33,281 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:33,577 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:33,579 : [INFO]  _____________________________________________________ Batch number 56: training Round 1 ____________________________________________________________
2023-03-21 01:06:35,792 : [INFO]  _____________________________________________________ Batch number 56: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:35,797 : [INFO]  Batch 56: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:35,797 : [INFO]  Batch 56, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:35,797 : [INFO]  ____________________________________Batch 56: round 1 finished ____________________________________
2023-03-21 01:06:35,798 : [INFO]  _____________________________________________________ Batch number 56: training Round 2 ____________________________________________________________
2023-03-21 01:06:36,402 : [INFO]  _____________________________________________________ Batch number 56: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:36,405 : [INFO]  Batch 56: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:36,405 : [INFO]  Batch 56, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:36,405 : [INFO]  ____________________________________Batch 56: round 2 finished ____________________________________
2023-03-21 01:06:36,405 : [INFO]  ____________________________________ Batch number 56: sent the final model to clients ____________________________________
2023-03-21 01:06:37,369 : [INFO]  Batch number 56 model fetched from the server
2023-03-21 01:06:37,369 : [INFO]  _____________________________________________________ Batch number 56: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:37,369 : [INFO]  Batch 56: Training set : loss - 0.552510678768158, accuracy - 0.7445651888847351, recall - 0.945652186870575, AUC - 0.9067226052284241, F1 - 0.7873303372908623, precision - 0.6744186282157898
2023-03-21 01:06:37,369 : [INFO]  Batch 56: Testing set : loss - 0.5723622441291809, accuracy - 0.7107843160629272, recall - 0.9411764740943909, AUC - 0.8846597075462341, F1 - 0.764940221312197, precision - 0.6442952752113342
2023-03-21 01:06:37,460 : [INFO]  Batch 57 initialized 
2023-03-21 01:06:37,981 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:38,282 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:38,284 : [INFO]  _____________________________________________________ Batch number 57: training Round 1 ____________________________________________________________
2023-03-21 01:06:41,897 : [INFO]  _____________________________________________________ Batch number 57: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:41,913 : [INFO]  Batch 57: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:41,915 : [INFO]  Batch 57, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:41,916 : [INFO]  ____________________________________Batch 57: round 1 finished ____________________________________
2023-03-21 01:06:41,926 : [INFO]  _____________________________________________________ Batch number 57: training Round 2 ____________________________________________________________
2023-03-21 01:06:43,264 : [INFO]  _____________________________________________________ Batch number 57: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:43,267 : [INFO]  Batch 57: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:43,268 : [INFO]  Batch 57, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:43,268 : [INFO]  ____________________________________Batch 57: round 2 finished ____________________________________
2023-03-21 01:06:43,268 : [INFO]  ____________________________________ Batch number 57: sent the final model to clients ____________________________________
2023-03-21 01:06:45,166 : [INFO]  Batch number 57 model fetched from the server
2023-03-21 01:06:45,166 : [INFO]  _____________________________________________________ Batch number 57: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:45,166 : [INFO]  Batch 57: Training set : loss - 0.5699291229248047, accuracy - 0.72826087474823, recall - 0.9021739363670349, AUC - 0.8555647134780884, F1 - 0.7685185383867335, precision - 0.6693548560142517
2023-03-21 01:06:45,166 : [INFO]  Batch 57: Testing set : loss - 0.5842256546020508, accuracy - 0.7107843160629272, recall - 0.9215686321258545, AUC - 0.8503940105438232, F1 - 0.7611335980335105, precision - 0.6482758522033691
2023-03-21 01:06:45,277 : [INFO]  Batch 58 initialized 
2023-03-21 01:06:45,757 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:46,032 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:46,034 : [INFO]  _____________________________________________________ Batch number 58: training Round 1 ____________________________________________________________
2023-03-21 01:06:48,507 : [INFO]  _____________________________________________________ Batch number 58: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:48,513 : [INFO]  Batch 58: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:48,514 : [INFO]  Batch 58, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:48,515 : [INFO]  ____________________________________Batch 58: round 1 finished ____________________________________
2023-03-21 01:06:48,519 : [INFO]  _____________________________________________________ Batch number 58: training Round 2 ____________________________________________________________
2023-03-21 01:06:49,627 : [INFO]  _____________________________________________________ Batch number 58: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:49,631 : [INFO]  Batch 58: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:49,632 : [INFO]  Batch 58, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:49,632 : [INFO]  ____________________________________Batch 58: round 2 finished ____________________________________
2023-03-21 01:06:49,632 : [INFO]  ____________________________________ Batch number 58: sent the final model to clients ____________________________________
2023-03-21 01:06:50,640 : [INFO]  Batch number 58 model fetched from the server
2023-03-21 01:06:50,640 : [INFO]  _____________________________________________________ Batch number 58: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:50,640 : [INFO]  Batch 58: Training set : loss - 0.553846001625061, accuracy - 0.7445651888847351, recall - 0.9130434989929199, AUC - 0.8913634419441223, F1 - 0.7813953592843014, precision - 0.6829268336296082
2023-03-21 01:06:50,640 : [INFO]  Batch 58: Testing set : loss - 0.5832532048225403, accuracy - 0.7009803652763367, recall - 0.8921568393707275, AUC - 0.8327085375785828, F1 - 0.7489712002654927, precision - 0.6453900933265686
2023-03-21 01:06:50,742 : [INFO]  Batch 59 initialized 
2023-03-21 01:06:51,079 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:51,387 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:51,390 : [INFO]  _____________________________________________________ Batch number 59: training Round 1 ____________________________________________________________
2023-03-21 01:06:54,367 : [INFO]  _____________________________________________________ Batch number 59: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:54,370 : [INFO]  Batch 59: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:54,370 : [INFO]  Batch 59, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:54,370 : [INFO]  ____________________________________Batch 59: round 1 finished ____________________________________
2023-03-21 01:06:54,372 : [INFO]  _____________________________________________________ Batch number 59: training Round 2 ____________________________________________________________
2023-03-21 01:06:54,974 : [INFO]  _____________________________________________________ Batch number 59: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:54,976 : [INFO]  Batch 59: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:54,977 : [INFO]  Batch 59, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:54,977 : [INFO]  ____________________________________Batch 59: round 2 finished ____________________________________
2023-03-21 01:06:54,977 : [INFO]  ____________________________________ Batch number 59: sent the final model to clients ____________________________________
2023-03-21 01:06:55,973 : [INFO]  Batch number 59 model fetched from the server
2023-03-21 01:06:55,973 : [INFO]  _____________________________________________________ Batch number 59: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:06:55,973 : [INFO]  Batch 59: Training set : loss - 0.555042028427124, accuracy - 0.77173912525177, recall - 0.9239130616188049, AUC - 0.8952032327651978, F1 - 0.8018867865539009, precision - 0.7083333134651184
2023-03-21 01:06:55,973 : [INFO]  Batch 59: Testing set : loss - 0.579312264919281, accuracy - 0.6911764740943909, recall - 0.843137264251709, AUC - 0.8424163460731506, F1 - 0.731914882498016, precision - 0.646616518497467
2023-03-21 01:06:56,049 : [INFO]  Batch 60 initialized 
2023-03-21 01:06:56,415 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:06:56,710 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:06:56,713 : [INFO]  _____________________________________________________ Batch number 60: training Round 1 ____________________________________________________________
2023-03-21 01:06:59,279 : [INFO]  _____________________________________________________ Batch number 60: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:06:59,282 : [INFO]  Batch 60: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:59,282 : [INFO]  Batch 60, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:59,282 : [INFO]  ____________________________________Batch 60: round 1 finished ____________________________________
2023-03-21 01:06:59,284 : [INFO]  _____________________________________________________ Batch number 60: training Round 2 ____________________________________________________________
2023-03-21 01:06:59,939 : [INFO]  _____________________________________________________ Batch number 60: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:06:59,941 : [INFO]  Batch 60: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:06:59,942 : [INFO]  Batch 60, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:06:59,942 : [INFO]  ____________________________________Batch 60: round 2 finished ____________________________________
2023-03-21 01:06:59,942 : [INFO]  ____________________________________ Batch number 60: sent the final model to clients ____________________________________
2023-03-21 01:07:01,213 : [INFO]  Batch number 60 model fetched from the server
2023-03-21 01:07:01,214 : [INFO]  _____________________________________________________ Batch number 60: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:01,214 : [INFO]  Batch 60: Training set : loss - 0.5455500483512878, accuracy - 0.7771739363670349, recall - 0.9347826242446899, AUC - 0.9068998098373413, F1 - 0.8075117320810924, precision - 0.71074378490448
2023-03-21 01:07:01,214 : [INFO]  Batch 60: Testing set : loss - 0.6036866307258606, accuracy - 0.656862735748291, recall - 0.843137264251709, AUC - 0.8072856664657593, F1 - 0.710743800415285, precision - 0.6142857074737549
2023-03-21 01:07:01,293 : [INFO]  Batch 61 initialized 
2023-03-21 01:07:01,683 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:01,961 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:01,963 : [INFO]  _____________________________________________________ Batch number 61: training Round 1 ____________________________________________________________
2023-03-21 01:07:04,050 : [INFO]  _____________________________________________________ Batch number 61: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:04,053 : [INFO]  Batch 61: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:04,053 : [INFO]  Batch 61, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:04,053 : [INFO]  ____________________________________Batch 61: round 1 finished ____________________________________
2023-03-21 01:07:04,055 : [INFO]  _____________________________________________________ Batch number 61: training Round 2 ____________________________________________________________
2023-03-21 01:07:04,614 : [INFO]  _____________________________________________________ Batch number 61: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:04,616 : [INFO]  Batch 61: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:04,617 : [INFO]  Batch 61, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:04,617 : [INFO]  ____________________________________Batch 61: round 2 finished ____________________________________
2023-03-21 01:07:04,617 : [INFO]  ____________________________________ Batch number 61: sent the final model to clients ____________________________________
2023-03-21 01:07:05,670 : [INFO]  Batch number 61 model fetched from the server
2023-03-21 01:07:05,671 : [INFO]  _____________________________________________________ Batch number 61: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:05,671 : [INFO]  Batch 61: Training set : loss - 0.5441147685050964, accuracy - 0.782608687877655, recall - 0.97826087474823, AUC - 0.9268076419830322, F1 - 0.8181818199945875, precision - 0.703125
2023-03-21 01:07:05,671 : [INFO]  Batch 61: Testing set : loss - 0.576740026473999, accuracy - 0.7107843160629272, recall - 0.9215686321258545, AUC - 0.8611111044883728, F1 - 0.7611335980335105, precision - 0.6482758522033691
2023-03-21 01:07:05,767 : [INFO]  Batch 62 initialized 
2023-03-21 01:07:06,294 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:06,606 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:06,608 : [INFO]  _____________________________________________________ Batch number 62: training Round 1 ____________________________________________________________
2023-03-21 01:07:08,799 : [INFO]  _____________________________________________________ Batch number 62: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:08,801 : [INFO]  Batch 62: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:08,802 : [INFO]  Batch 62, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:08,802 : [INFO]  ____________________________________Batch 62: round 1 finished ____________________________________
2023-03-21 01:07:08,803 : [INFO]  _____________________________________________________ Batch number 62: training Round 2 ____________________________________________________________
2023-03-21 01:07:09,388 : [INFO]  _____________________________________________________ Batch number 62: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:09,390 : [INFO]  Batch 62: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:09,391 : [INFO]  Batch 62, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:09,391 : [INFO]  ____________________________________Batch 62: round 2 finished ____________________________________
2023-03-21 01:07:09,391 : [INFO]  ____________________________________ Batch number 62: sent the final model to clients ____________________________________
2023-03-21 01:07:10,786 : [INFO]  Batch number 62 model fetched from the server
2023-03-21 01:07:10,787 : [INFO]  _____________________________________________________ Batch number 62: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:10,787 : [INFO]  Batch 62: Training set : loss - 0.5638139843940735, accuracy - 0.7554348111152649, recall - 0.9347826242446899, AUC - 0.8788397908210754, F1 - 0.7926267492062055, precision - 0.6880000233650208
2023-03-21 01:07:10,787 : [INFO]  Batch 62: Testing set : loss - 0.608303427696228, accuracy - 0.656862735748291, recall - 0.9019607901573181, AUC - 0.8028642535209656, F1 - 0.7244094619379061, precision - 0.6052631735801697
2023-03-21 01:07:10,989 : [INFO]  Batch 63 initialized 
2023-03-21 01:07:11,691 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:11,975 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:11,978 : [INFO]  _____________________________________________________ Batch number 63: training Round 1 ____________________________________________________________
2023-03-21 01:07:14,843 : [INFO]  _____________________________________________________ Batch number 63: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:14,847 : [INFO]  Batch 63: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:14,848 : [INFO]  Batch 63, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:14,848 : [INFO]  ____________________________________Batch 63: round 1 finished ____________________________________
2023-03-21 01:07:14,850 : [INFO]  _____________________________________________________ Batch number 63: training Round 2 ____________________________________________________________
2023-03-21 01:07:15,606 : [INFO]  _____________________________________________________ Batch number 63: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:15,608 : [INFO]  Batch 63: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:15,609 : [INFO]  Batch 63, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:15,609 : [INFO]  ____________________________________Batch 63: round 2 finished ____________________________________
2023-03-21 01:07:15,609 : [INFO]  ____________________________________ Batch number 63: sent the final model to clients ____________________________________
2023-03-21 01:07:16,601 : [INFO]  Batch number 63 model fetched from the server
2023-03-21 01:07:16,601 : [INFO]  _____________________________________________________ Batch number 63: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:16,601 : [INFO]  Batch 63: Training set : loss - 0.565497875213623, accuracy - 0.7771739363670349, recall - 0.9347826242446899, AUC - 0.8640122413635254, F1 - 0.8075117320810924, precision - 0.71074378490448
2023-03-21 01:07:16,601 : [INFO]  Batch 63: Testing set : loss - 0.5643764734268188, accuracy - 0.7401960492134094, recall - 0.9117646813392639, AUC - 0.889657735824585, F1 - 0.778242666882332, precision - 0.6788321137428284
2023-03-21 01:07:16,704 : [INFO]  Batch 64 initialized 
2023-03-21 01:07:17,055 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:17,332 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:17,335 : [INFO]  _____________________________________________________ Batch number 64: training Round 1 ____________________________________________________________
2023-03-21 01:07:19,412 : [INFO]  _____________________________________________________ Batch number 64: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:19,417 : [INFO]  Batch 64: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:19,417 : [INFO]  Batch 64, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:19,417 : [INFO]  ____________________________________Batch 64: round 1 finished ____________________________________
2023-03-21 01:07:19,420 : [INFO]  _____________________________________________________ Batch number 64: training Round 2 ____________________________________________________________
2023-03-21 01:07:20,114 : [INFO]  _____________________________________________________ Batch number 64: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:20,117 : [INFO]  Batch 64: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:20,117 : [INFO]  Batch 64, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:20,117 : [INFO]  ____________________________________Batch 64: round 2 finished ____________________________________
2023-03-21 01:07:20,117 : [INFO]  ____________________________________ Batch number 64: sent the final model to clients ____________________________________
2023-03-21 01:07:21,326 : [INFO]  Batch number 64 model fetched from the server
2023-03-21 01:07:21,326 : [INFO]  _____________________________________________________ Batch number 64: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:21,326 : [INFO]  Batch 64: Training set : loss - 0.5830347537994385, accuracy - 0.717391312122345, recall - 0.8913043737411499, AUC - 0.8451087474822998, F1 - 0.7592592851369959, precision - 0.6612903475761414
2023-03-21 01:07:21,326 : [INFO]  Batch 64: Testing set : loss - 0.5911273956298828, accuracy - 0.6715686321258545, recall - 0.8823529481887817, AUC - 0.8415032625198364, F1 - 0.7287449246634321, precision - 0.6206896305084229
2023-03-21 01:07:21,392 : [INFO]  Batch 65 initialized 
2023-03-21 01:07:21,811 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:22,110 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:22,113 : [INFO]  _____________________________________________________ Batch number 65: training Round 1 ____________________________________________________________
2023-03-21 01:07:24,329 : [INFO]  _____________________________________________________ Batch number 65: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:24,332 : [INFO]  Batch 65: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:24,332 : [INFO]  Batch 65, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:24,332 : [INFO]  ____________________________________Batch 65: round 1 finished ____________________________________
2023-03-21 01:07:24,334 : [INFO]  _____________________________________________________ Batch number 65: training Round 2 ____________________________________________________________
2023-03-21 01:07:25,102 : [INFO]  _____________________________________________________ Batch number 65: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:25,104 : [INFO]  Batch 65: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:25,104 : [INFO]  Batch 65, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:25,105 : [INFO]  ____________________________________Batch 65: round 2 finished ____________________________________
2023-03-21 01:07:25,105 : [INFO]  ____________________________________ Batch number 65: sent the final model to clients ____________________________________
2023-03-21 01:07:26,176 : [INFO]  Batch number 65 model fetched from the server
2023-03-21 01:07:26,176 : [INFO]  _____________________________________________________ Batch number 65: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:26,176 : [INFO]  Batch 65: Training set : loss - 0.5535233020782471, accuracy - 0.739130437374115, recall - 0.9347826242446899, AUC - 0.9018194079399109, F1 - 0.7818181872564899, precision - 0.671875
2023-03-21 01:07:26,176 : [INFO]  Batch 65: Testing set : loss - 0.5840568542480469, accuracy - 0.7156862616539001, recall - 0.8725489974021912, AUC - 0.8416954874992371, F1 - 0.7542372683672616, precision - 0.6641790866851807
2023-03-21 01:07:26,262 : [INFO]  Batch 66 initialized 
2023-03-21 01:07:26,638 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:26,918 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:26,921 : [INFO]  _____________________________________________________ Batch number 66: training Round 1 ____________________________________________________________
2023-03-21 01:07:30,049 : [INFO]  _____________________________________________________ Batch number 66: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:30,051 : [INFO]  Batch 66: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:30,052 : [INFO]  Batch 66, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:30,052 : [INFO]  ____________________________________Batch 66: round 1 finished ____________________________________
2023-03-21 01:07:30,053 : [INFO]  _____________________________________________________ Batch number 66: training Round 2 ____________________________________________________________
2023-03-21 01:07:30,667 : [INFO]  _____________________________________________________ Batch number 66: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:30,670 : [INFO]  Batch 66: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:30,670 : [INFO]  Batch 66, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:30,670 : [INFO]  ____________________________________Batch 66: round 2 finished ____________________________________
2023-03-21 01:07:30,670 : [INFO]  ____________________________________ Batch number 66: sent the final model to clients ____________________________________
2023-03-21 01:07:31,651 : [INFO]  Batch number 66 model fetched from the server
2023-03-21 01:07:31,652 : [INFO]  _____________________________________________________ Batch number 66: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:31,652 : [INFO]  Batch 66: Training set : loss - 0.5739294290542603, accuracy - 0.75, recall - 0.9130434989929199, AUC - 0.8599952459335327, F1 - 0.7850467455273622, precision - 0.688524603843689
2023-03-21 01:07:31,652 : [INFO]  Batch 66: Testing set : loss - 0.5717856287956238, accuracy - 0.7401960492134094, recall - 0.9411764740943909, AUC - 0.8770664930343628, F1 - 0.7836734654912348, precision - 0.6713286638259888
2023-03-21 01:07:31,742 : [INFO]  Batch 67 initialized 
2023-03-21 01:07:32,079 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:32,366 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:32,369 : [INFO]  _____________________________________________________ Batch number 67: training Round 1 ____________________________________________________________
2023-03-21 01:07:34,823 : [INFO]  _____________________________________________________ Batch number 67: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:34,825 : [INFO]  Batch 67: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:34,825 : [INFO]  Batch 67, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:34,825 : [INFO]  ____________________________________Batch 67: round 1 finished ____________________________________
2023-03-21 01:07:34,827 : [INFO]  _____________________________________________________ Batch number 67: training Round 2 ____________________________________________________________
2023-03-21 01:07:35,433 : [INFO]  _____________________________________________________ Batch number 67: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:35,436 : [INFO]  Batch 67: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:35,436 : [INFO]  Batch 67, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:35,436 : [INFO]  ____________________________________Batch 67: round 2 finished ____________________________________
2023-03-21 01:07:35,436 : [INFO]  ____________________________________ Batch number 67: sent the final model to clients ____________________________________
2023-03-21 01:07:37,090 : [INFO]  Batch number 67 model fetched from the server
2023-03-21 01:07:37,090 : [INFO]  _____________________________________________________ Batch number 67: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:37,090 : [INFO]  Batch 67: Training set : loss - 0.5750075578689575, accuracy - 0.7336956262588501, recall - 0.8695651888847351, AUC - 0.8372519016265869, F1 - 0.7655502400013228, precision - 0.6837607026100159
2023-03-21 01:07:37,091 : [INFO]  Batch 67: Testing set : loss - 0.6048029065132141, accuracy - 0.6813725233078003, recall - 0.8627451062202454, AUC - 0.7914744019508362, F1 - 0.730290466494777, precision - 0.633093535900116
2023-03-21 01:07:37,179 : [INFO]  Batch 68 initialized 
2023-03-21 01:07:37,690 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:38,024 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:38,026 : [INFO]  _____________________________________________________ Batch number 68: training Round 1 ____________________________________________________________
2023-03-21 01:07:41,838 : [INFO]  _____________________________________________________ Batch number 68: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:41,841 : [INFO]  Batch 68: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:41,841 : [INFO]  Batch 68, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:41,842 : [INFO]  ____________________________________Batch 68: round 1 finished ____________________________________
2023-03-21 01:07:41,843 : [INFO]  _____________________________________________________ Batch number 68: training Round 2 ____________________________________________________________
2023-03-21 01:07:42,617 : [INFO]  _____________________________________________________ Batch number 68: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:42,619 : [INFO]  Batch 68: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:42,620 : [INFO]  Batch 68, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:42,620 : [INFO]  ____________________________________Batch 68: round 2 finished ____________________________________
2023-03-21 01:07:42,620 : [INFO]  ____________________________________ Batch number 68: sent the final model to clients ____________________________________
2023-03-21 01:07:43,764 : [INFO]  Batch number 68 model fetched from the server
2023-03-21 01:07:43,764 : [INFO]  _____________________________________________________ Batch number 68: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:43,764 : [INFO]  Batch 68: Training set : loss - 0.5731803774833679, accuracy - 0.7663043737411499, recall - 0.9021739363670349, AUC - 0.8431592583656311, F1 - 0.7942583931007926, precision - 0.7094017267227173
2023-03-21 01:07:43,764 : [INFO]  Batch 68: Testing set : loss - 0.598622739315033, accuracy - 0.7058823704719543, recall - 0.8333333134651184, AUC - 0.8056997060775757, F1 - 0.739130426967527, precision - 0.6640625
2023-03-21 01:07:43,880 : [INFO]  Batch 69 initialized 
2023-03-21 01:07:44,352 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:44,680 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:44,685 : [INFO]  _____________________________________________________ Batch number 69: training Round 1 ____________________________________________________________
2023-03-21 01:07:46,998 : [INFO]  _____________________________________________________ Batch number 69: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:47,001 : [INFO]  Batch 69: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:47,001 : [INFO]  Batch 69, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:47,001 : [INFO]  ____________________________________Batch 69: round 1 finished ____________________________________
2023-03-21 01:07:47,002 : [INFO]  _____________________________________________________ Batch number 69: training Round 2 ____________________________________________________________
2023-03-21 01:07:47,839 : [INFO]  _____________________________________________________ Batch number 69: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:47,843 : [INFO]  Batch 69: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:47,844 : [INFO]  Batch 69, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:47,845 : [INFO]  ____________________________________Batch 69: round 2 finished ____________________________________
2023-03-21 01:07:47,845 : [INFO]  ____________________________________ Batch number 69: sent the final model to clients ____________________________________
2023-03-21 01:07:48,964 : [INFO]  Batch number 69 model fetched from the server
2023-03-21 01:07:48,964 : [INFO]  _____________________________________________________ Batch number 69: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:48,964 : [INFO]  Batch 69: Training set : loss - 0.5486248135566711, accuracy - 0.75, recall - 0.95652174949646, AUC - 0.9187145233154297, F1 - 0.7927928095600761, precision - 0.6769230961799622
2023-03-21 01:07:48,964 : [INFO]  Batch 69: Testing set : loss - 0.5720582008361816, accuracy - 0.7450980544090271, recall - 0.970588207244873, AUC - 0.890426754951477, F1 - 0.7919999827575683, precision - 0.6689189076423645
2023-03-21 01:07:49,078 : [INFO]  Batch 70 initialized 
2023-03-21 01:07:49,602 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:49,938 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:49,943 : [INFO]  _____________________________________________________ Batch number 70: training Round 1 ____________________________________________________________
2023-03-21 01:07:52,996 : [INFO]  _____________________________________________________ Batch number 70: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:52,999 : [INFO]  Batch 70: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:52,999 : [INFO]  Batch 70, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:53,000 : [INFO]  ____________________________________Batch 70: round 1 finished ____________________________________
2023-03-21 01:07:53,001 : [INFO]  _____________________________________________________ Batch number 70: training Round 2 ____________________________________________________________
2023-03-21 01:07:53,673 : [INFO]  _____________________________________________________ Batch number 70: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:53,676 : [INFO]  Batch 70: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:53,676 : [INFO]  Batch 70, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:53,676 : [INFO]  ____________________________________Batch 70: round 2 finished ____________________________________
2023-03-21 01:07:53,676 : [INFO]  ____________________________________ Batch number 70: sent the final model to clients ____________________________________
2023-03-21 01:07:54,784 : [INFO]  Batch number 70 model fetched from the server
2023-03-21 01:07:54,784 : [INFO]  _____________________________________________________ Batch number 70: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:07:54,784 : [INFO]  Batch 70: Training set : loss - 0.5411263108253479, accuracy - 0.77173912525177, recall - 0.967391312122345, AUC - 0.9224362373352051, F1 - 0.8090909118100631, precision - 0.6953125
2023-03-21 01:07:54,785 : [INFO]  Batch 70: Testing set : loss - 0.5639936327934265, accuracy - 0.75, recall - 0.9019607901573181, AUC - 0.8751441240310669, F1 - 0.7829787152706091, precision - 0.6917293071746826
2023-03-21 01:07:54,869 : [INFO]  Batch 71 initialized 
2023-03-21 01:07:55,292 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:07:55,630 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:07:55,634 : [INFO]  _____________________________________________________ Batch number 71: training Round 1 ____________________________________________________________
2023-03-21 01:07:58,483 : [INFO]  _____________________________________________________ Batch number 71: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:07:58,486 : [INFO]  Batch 71: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:58,487 : [INFO]  Batch 71, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:58,487 : [INFO]  ____________________________________Batch 71: round 1 finished ____________________________________
2023-03-21 01:07:58,489 : [INFO]  _____________________________________________________ Batch number 71: training Round 2 ____________________________________________________________
2023-03-21 01:07:59,313 : [INFO]  _____________________________________________________ Batch number 71: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:07:59,317 : [INFO]  Batch 71: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:07:59,318 : [INFO]  Batch 71, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:07:59,318 : [INFO]  ____________________________________Batch 71: round 2 finished ____________________________________
2023-03-21 01:07:59,318 : [INFO]  ____________________________________ Batch number 71: sent the final model to clients ____________________________________
2023-03-21 01:08:00,609 : [INFO]  Batch number 71 model fetched from the server
2023-03-21 01:08:00,609 : [INFO]  _____________________________________________________ Batch number 71: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:00,609 : [INFO]  Batch 71: Training set : loss - 0.5345174074172974, accuracy - 0.79347825050354, recall - 0.97826087474823, AUC - 0.9301748275756836, F1 - 0.8256880866187899, precision - 0.7142857313156128
2023-03-21 01:08:00,609 : [INFO]  Batch 71: Testing set : loss - 0.577735424041748, accuracy - 0.7254902124404907, recall - 0.8725489974021912, AUC - 0.8463090658187866, F1 - 0.7606837602918823, precision - 0.6742424368858337
2023-03-21 01:08:00,690 : [INFO]  Batch 72 initialized 
2023-03-21 01:08:01,186 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:01,514 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:01,518 : [INFO]  _____________________________________________________ Batch number 72: training Round 1 ____________________________________________________________
2023-03-21 01:08:03,590 : [INFO]  _____________________________________________________ Batch number 72: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:03,592 : [INFO]  Batch 72: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:03,593 : [INFO]  Batch 72, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:03,593 : [INFO]  ____________________________________Batch 72: round 1 finished ____________________________________
2023-03-21 01:08:03,594 : [INFO]  _____________________________________________________ Batch number 72: training Round 2 ____________________________________________________________
2023-03-21 01:08:04,165 : [INFO]  _____________________________________________________ Batch number 72: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:04,167 : [INFO]  Batch 72: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:04,168 : [INFO]  Batch 72, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:04,168 : [INFO]  ____________________________________Batch 72: round 2 finished ____________________________________
2023-03-21 01:08:04,168 : [INFO]  ____________________________________ Batch number 72: sent the final model to clients ____________________________________
2023-03-21 01:08:05,142 : [INFO]  Batch number 72 model fetched from the server
2023-03-21 01:08:05,142 : [INFO]  _____________________________________________________ Batch number 72: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:05,142 : [INFO]  Batch 72: Training set : loss - 0.5422530174255371, accuracy - 0.79347825050354, recall - 0.9239130616188049, AUC - 0.9118620157241821, F1 - 0.8173077121906026, precision - 0.732758641242981
2023-03-21 01:08:05,142 : [INFO]  Batch 72: Testing set : loss - 0.5723373293876648, accuracy - 0.6960784196853638, recall - 0.9117646813392639, AUC - 0.8854286670684814, F1 - 0.7500000013180003, precision - 0.6369863152503967
2023-03-21 01:08:05,215 : [INFO]  Batch 73 initialized 
2023-03-21 01:08:05,574 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:05,870 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:05,873 : [INFO]  _____________________________________________________ Batch number 73: training Round 1 ____________________________________________________________
2023-03-21 01:08:07,908 : [INFO]  _____________________________________________________ Batch number 73: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:07,911 : [INFO]  Batch 73: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:07,911 : [INFO]  Batch 73, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:07,911 : [INFO]  ____________________________________Batch 73: round 1 finished ____________________________________
2023-03-21 01:08:07,913 : [INFO]  _____________________________________________________ Batch number 73: training Round 2 ____________________________________________________________
2023-03-21 01:08:08,473 : [INFO]  _____________________________________________________ Batch number 73: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:08,475 : [INFO]  Batch 73: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:08,475 : [INFO]  Batch 73, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:08,475 : [INFO]  ____________________________________Batch 73: round 2 finished ____________________________________
2023-03-21 01:08:08,475 : [INFO]  ____________________________________ Batch number 73: sent the final model to clients ____________________________________
2023-03-21 01:08:09,576 : [INFO]  Batch number 73 model fetched from the server
2023-03-21 01:08:09,576 : [INFO]  _____________________________________________________ Batch number 73: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:09,576 : [INFO]  Batch 73: Training set : loss - 0.5193779468536377, accuracy - 0.8152173757553101, recall - 0.967391312122345, AUC - 0.9413397908210754, F1 - 0.8396226495302798, precision - 0.7416666746139526
2023-03-21 01:08:09,577 : [INFO]  Batch 73: Testing set : loss - 0.5588123202323914, accuracy - 0.7303921580314636, recall - 0.9215686321258545, AUC - 0.8911476135253906, F1 - 0.7736625664664047, precision - 0.6666666865348816
2023-03-21 01:08:09,676 : [INFO]  Batch 74 initialized 
2023-03-21 01:08:10,153 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:10,474 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:10,476 : [INFO]  _____________________________________________________ Batch number 74: training Round 1 ____________________________________________________________
2023-03-21 01:08:13,572 : [INFO]  _____________________________________________________ Batch number 74: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:13,580 : [INFO]  Batch 74: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:13,581 : [INFO]  Batch 74, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:13,581 : [INFO]  ____________________________________Batch 74: round 1 finished ____________________________________
2023-03-21 01:08:13,585 : [INFO]  _____________________________________________________ Batch number 74: training Round 2 ____________________________________________________________
2023-03-21 01:08:15,343 : [INFO]  _____________________________________________________ Batch number 74: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:15,346 : [INFO]  Batch 74: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:15,346 : [INFO]  Batch 74, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:15,346 : [INFO]  ____________________________________Batch 74: round 2 finished ____________________________________
2023-03-21 01:08:15,346 : [INFO]  ____________________________________ Batch number 74: sent the final model to clients ____________________________________
2023-03-21 01:08:16,361 : [INFO]  Batch number 74 model fetched from the server
2023-03-21 01:08:16,361 : [INFO]  _____________________________________________________ Batch number 74: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:16,361 : [INFO]  Batch 74: Training set : loss - 0.5655049681663513, accuracy - 0.7445651888847351, recall - 0.9130434989929199, AUC - 0.8651347160339355, F1 - 0.7813953592843014, precision - 0.6829268336296082
2023-03-21 01:08:16,361 : [INFO]  Batch 74: Testing set : loss - 0.6025750041007996, accuracy - 0.6960784196853638, recall - 0.9117646813392639, AUC - 0.8169934749603271, F1 - 0.7500000013180003, precision - 0.6369863152503967
2023-03-21 01:08:16,426 : [INFO]  Batch 75 initialized 
2023-03-21 01:08:16,784 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:17,109 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:17,112 : [INFO]  _____________________________________________________ Batch number 75: training Round 1 ____________________________________________________________
2023-03-21 01:08:20,247 : [INFO]  _____________________________________________________ Batch number 75: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:20,250 : [INFO]  Batch 75: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:20,250 : [INFO]  Batch 75, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:20,250 : [INFO]  ____________________________________Batch 75: round 1 finished ____________________________________
2023-03-21 01:08:20,252 : [INFO]  _____________________________________________________ Batch number 75: training Round 2 ____________________________________________________________
2023-03-21 01:08:22,082 : [INFO]  _____________________________________________________ Batch number 75: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:22,089 : [INFO]  Batch 75: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:22,090 : [INFO]  Batch 75, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:22,090 : [INFO]  ____________________________________Batch 75: round 2 finished ____________________________________
2023-03-21 01:08:22,090 : [INFO]  ____________________________________ Batch number 75: sent the final model to clients ____________________________________
2023-03-21 01:08:23,023 : [INFO]  Batch number 75 model fetched from the server
2023-03-21 01:08:23,023 : [INFO]  _____________________________________________________ Batch number 75: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:23,024 : [INFO]  Batch 75: Training set : loss - 0.5574545860290527, accuracy - 0.7554348111152649, recall - 0.945652186870575, AUC - 0.8953213691711426, F1 - 0.7945205332630825, precision - 0.6850393414497375
2023-03-21 01:08:23,024 : [INFO]  Batch 75: Testing set : loss - 0.5804072618484497, accuracy - 0.7450980544090271, recall - 0.9411764740943909, AUC - 0.8519319295883179, F1 - 0.786885238597227, precision - 0.6760563254356384
2023-03-21 01:08:23,098 : [INFO]  Batch 76 initialized 
2023-03-21 01:08:23,444 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:23,739 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:23,742 : [INFO]  _____________________________________________________ Batch number 76: training Round 1 ____________________________________________________________
2023-03-21 01:08:25,706 : [INFO]  _____________________________________________________ Batch number 76: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:25,708 : [INFO]  Batch 76: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:25,708 : [INFO]  Batch 76, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:25,708 : [INFO]  ____________________________________Batch 76: round 1 finished ____________________________________
2023-03-21 01:08:25,710 : [INFO]  _____________________________________________________ Batch number 76: training Round 2 ____________________________________________________________
2023-03-21 01:08:26,241 : [INFO]  _____________________________________________________ Batch number 76: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:26,243 : [INFO]  Batch 76: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:26,243 : [INFO]  Batch 76, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:26,244 : [INFO]  ____________________________________Batch 76: round 2 finished ____________________________________
2023-03-21 01:08:26,244 : [INFO]  ____________________________________ Batch number 76: sent the final model to clients ____________________________________
2023-03-21 01:08:27,100 : [INFO]  Batch number 76 model fetched from the server
2023-03-21 01:08:27,100 : [INFO]  _____________________________________________________ Batch number 76: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:27,103 : [INFO]  Batch 76: Training set : loss - 0.5304399728775024, accuracy - 0.7989130616188049, recall - 0.9347826242446899, AUC - 0.9178875088691711, F1 - 0.8229665231012615, precision - 0.7350427508354187
2023-03-21 01:08:27,103 : [INFO]  Batch 76: Testing set : loss - 0.568876326084137, accuracy - 0.7401960492134094, recall - 0.9509803652763367, AUC - 0.8844194412231445, F1 - 0.7854250928965569, precision - 0.6689655184745789
2023-03-21 01:08:27,161 : [INFO]  Batch 77 initialized 
2023-03-21 01:08:27,500 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:27,794 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:27,797 : [INFO]  _____________________________________________________ Batch number 77: training Round 1 ____________________________________________________________
2023-03-21 01:08:29,779 : [INFO]  _____________________________________________________ Batch number 77: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:29,782 : [INFO]  Batch 77: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:29,782 : [INFO]  Batch 77, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:29,782 : [INFO]  ____________________________________Batch 77: round 1 finished ____________________________________
2023-03-21 01:08:29,783 : [INFO]  _____________________________________________________ Batch number 77: training Round 2 ____________________________________________________________
2023-03-21 01:08:30,350 : [INFO]  _____________________________________________________ Batch number 77: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:30,352 : [INFO]  Batch 77: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:30,353 : [INFO]  Batch 77, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:30,353 : [INFO]  ____________________________________Batch 77: round 2 finished ____________________________________
2023-03-21 01:08:30,353 : [INFO]  ____________________________________ Batch number 77: sent the final model to clients ____________________________________
2023-03-21 01:08:31,250 : [INFO]  Batch number 77 model fetched from the server
2023-03-21 01:08:31,250 : [INFO]  _____________________________________________________ Batch number 77: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:31,250 : [INFO]  Batch 77: Training set : loss - 0.5444563627243042, accuracy - 0.7989130616188049, recall - 0.9130434989929199, AUC - 0.892781138420105, F1 - 0.81951221084538, precision - 0.7433628439903259
2023-03-21 01:08:31,250 : [INFO]  Batch 77: Testing set : loss - 0.6111340522766113, accuracy - 0.6470588445663452, recall - 0.813725471496582, AUC - 0.7811899185180664, F1 - 0.6974789755684989, precision - 0.6102941036224365
2023-03-21 01:08:31,352 : [INFO]  Batch 78 initialized 
2023-03-21 01:08:31,681 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:31,973 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:31,976 : [INFO]  _____________________________________________________ Batch number 78: training Round 1 ____________________________________________________________
2023-03-21 01:08:33,957 : [INFO]  _____________________________________________________ Batch number 78: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:33,959 : [INFO]  Batch 78: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:33,959 : [INFO]  Batch 78, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:33,959 : [INFO]  ____________________________________Batch 78: round 1 finished ____________________________________
2023-03-21 01:08:33,961 : [INFO]  _____________________________________________________ Batch number 78: training Round 2 ____________________________________________________________
2023-03-21 01:08:34,514 : [INFO]  _____________________________________________________ Batch number 78: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:34,516 : [INFO]  Batch 78: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:34,517 : [INFO]  Batch 78, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:34,517 : [INFO]  ____________________________________Batch 78: round 2 finished ____________________________________
2023-03-21 01:08:34,517 : [INFO]  ____________________________________ Batch number 78: sent the final model to clients ____________________________________
2023-03-21 01:08:35,407 : [INFO]  Batch number 78 model fetched from the server
2023-03-21 01:08:35,407 : [INFO]  _____________________________________________________ Batch number 78: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:35,407 : [INFO]  Batch 78: Training set : loss - 0.6013931632041931, accuracy - 0.695652186870575, recall - 0.8913043737411499, AUC - 0.809014618396759, F1 - 0.7454545545183922, precision - 0.640625
2023-03-21 01:08:35,407 : [INFO]  Batch 78: Testing set : loss - 0.6092262864112854, accuracy - 0.6666666865348816, recall - 0.8725489974021912, AUC - 0.8025278449058533, F1 - 0.7235772462915189, precision - 0.6180555820465088
2023-03-21 01:08:35,527 : [INFO]  Batch 79 initialized 
2023-03-21 01:08:35,867 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:36,165 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:36,168 : [INFO]  _____________________________________________________ Batch number 79: training Round 1 ____________________________________________________________
2023-03-21 01:08:38,145 : [INFO]  _____________________________________________________ Batch number 79: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:38,148 : [INFO]  Batch 79: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:38,148 : [INFO]  Batch 79, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:38,148 : [INFO]  ____________________________________Batch 79: round 1 finished ____________________________________
2023-03-21 01:08:38,149 : [INFO]  _____________________________________________________ Batch number 79: training Round 2 ____________________________________________________________
2023-03-21 01:08:38,718 : [INFO]  _____________________________________________________ Batch number 79: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:38,720 : [INFO]  Batch 79: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:38,721 : [INFO]  Batch 79, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:38,721 : [INFO]  ____________________________________Batch 79: round 2 finished ____________________________________
2023-03-21 01:08:38,721 : [INFO]  ____________________________________ Batch number 79: sent the final model to clients ____________________________________
2023-03-21 01:08:39,580 : [INFO]  Batch number 79 model fetched from the server
2023-03-21 01:08:39,580 : [INFO]  _____________________________________________________ Batch number 79: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:39,580 : [INFO]  Batch 79: Training set : loss - 0.5527394413948059, accuracy - 0.739130437374115, recall - 0.9347826242446899, AUC - 0.8983341455459595, F1 - 0.7818181872564899, precision - 0.671875
2023-03-21 01:08:39,580 : [INFO]  Batch 79: Testing set : loss - 0.5876641273498535, accuracy - 0.6960784196853638, recall - 0.9411764740943909, AUC - 0.8622645139694214, F1 - 0.7559054949669554, precision - 0.6315789222717285
2023-03-21 01:08:39,681 : [INFO]  Batch 80 initialized 
2023-03-21 01:08:40,019 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:40,311 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:40,314 : [INFO]  _____________________________________________________ Batch number 80: training Round 1 ____________________________________________________________
2023-03-21 01:08:42,275 : [INFO]  _____________________________________________________ Batch number 80: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:42,278 : [INFO]  Batch 80: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:42,278 : [INFO]  Batch 80, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:42,278 : [INFO]  ____________________________________Batch 80: round 1 finished ____________________________________
2023-03-21 01:08:42,279 : [INFO]  _____________________________________________________ Batch number 80: training Round 2 ____________________________________________________________
2023-03-21 01:08:42,813 : [INFO]  _____________________________________________________ Batch number 80: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:42,815 : [INFO]  Batch 80: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:42,815 : [INFO]  Batch 80, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:42,816 : [INFO]  ____________________________________Batch 80: round 2 finished ____________________________________
2023-03-21 01:08:42,816 : [INFO]  ____________________________________ Batch number 80: sent the final model to clients ____________________________________
2023-03-21 01:08:43,693 : [INFO]  Batch number 80 model fetched from the server
2023-03-21 01:08:43,694 : [INFO]  _____________________________________________________ Batch number 80: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:43,694 : [INFO]  Batch 80: Training set : loss - 0.5420934557914734, accuracy - 0.7771739363670349, recall - 0.95652174949646, AUC - 0.9086129665374756, F1 - 0.8110599090290043, precision - 0.7039999961853027
2023-03-21 01:08:43,694 : [INFO]  Batch 80: Testing set : loss - 0.5770341753959656, accuracy - 0.720588207244873, recall - 0.9607843160629272, AUC - 0.8699058294296265, F1 - 0.7747035456984308, precision - 0.6490066051483154
2023-03-21 01:08:43,756 : [INFO]  Batch 81 initialized 
2023-03-21 01:08:44,107 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:44,403 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:44,406 : [INFO]  _____________________________________________________ Batch number 81: training Round 1 ____________________________________________________________
2023-03-21 01:08:46,615 : [INFO]  _____________________________________________________ Batch number 81: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:46,618 : [INFO]  Batch 81: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:46,618 : [INFO]  Batch 81, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:46,618 : [INFO]  ____________________________________Batch 81: round 1 finished ____________________________________
2023-03-21 01:08:46,620 : [INFO]  _____________________________________________________ Batch number 81: training Round 2 ____________________________________________________________
2023-03-21 01:08:47,398 : [INFO]  _____________________________________________________ Batch number 81: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:47,401 : [INFO]  Batch 81: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:47,401 : [INFO]  Batch 81, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:47,401 : [INFO]  ____________________________________Batch 81: round 2 finished ____________________________________
2023-03-21 01:08:47,401 : [INFO]  ____________________________________ Batch number 81: sent the final model to clients ____________________________________
2023-03-21 01:08:48,664 : [INFO]  Batch number 81 model fetched from the server
2023-03-21 01:08:48,664 : [INFO]  _____________________________________________________ Batch number 81: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:48,664 : [INFO]  Batch 81: Training set : loss - 0.554735004901886, accuracy - 0.7445651888847351, recall - 0.945652186870575, AUC - 0.9083175659179688, F1 - 0.7873303372908623, precision - 0.6744186282157898
2023-03-21 01:08:48,664 : [INFO]  Batch 81: Testing set : loss - 0.577451765537262, accuracy - 0.7058823704719543, recall - 0.8823529481887817, AUC - 0.8520280718803406, F1 - 0.7500000179558991, precision - 0.6521739363670349
2023-03-21 01:08:48,750 : [INFO]  Batch 82 initialized 
2023-03-21 01:08:49,161 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:49,463 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:49,466 : [INFO]  _____________________________________________________ Batch number 82: training Round 1 ____________________________________________________________
2023-03-21 01:08:51,520 : [INFO]  _____________________________________________________ Batch number 82: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:51,522 : [INFO]  Batch 82: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:51,523 : [INFO]  Batch 82, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:51,523 : [INFO]  ____________________________________Batch 82: round 1 finished ____________________________________
2023-03-21 01:08:51,524 : [INFO]  _____________________________________________________ Batch number 82: training Round 2 ____________________________________________________________
2023-03-21 01:08:52,110 : [INFO]  _____________________________________________________ Batch number 82: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:52,112 : [INFO]  Batch 82: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:52,113 : [INFO]  Batch 82, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:52,113 : [INFO]  ____________________________________Batch 82: round 2 finished ____________________________________
2023-03-21 01:08:52,113 : [INFO]  ____________________________________ Batch number 82: sent the final model to clients ____________________________________
2023-03-21 01:08:53,056 : [INFO]  Batch number 82 model fetched from the server
2023-03-21 01:08:53,056 : [INFO]  _____________________________________________________ Batch number 82: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:53,056 : [INFO]  Batch 82: Training set : loss - 0.5336099863052368, accuracy - 0.7880434989929199, recall - 0.9239130616188049, AUC - 0.905363917350769, F1 - 0.8133971464344385, precision - 0.7264957427978516
2023-03-21 01:08:53,056 : [INFO]  Batch 82: Testing set : loss - 0.5791300535202026, accuracy - 0.7254902124404907, recall - 0.8921568393707275, AUC - 0.8553920984268188, F1 - 0.7647058623177665, precision - 0.6691176295280457
2023-03-21 01:08:53,141 : [INFO]  Batch 83 initialized 
2023-03-21 01:08:53,493 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:53,796 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:53,798 : [INFO]  _____________________________________________________ Batch number 83: training Round 1 ____________________________________________________________
2023-03-21 01:08:55,991 : [INFO]  _____________________________________________________ Batch number 83: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:08:55,993 : [INFO]  Batch 83: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:55,993 : [INFO]  Batch 83, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:55,994 : [INFO]  ____________________________________Batch 83: round 1 finished ____________________________________
2023-03-21 01:08:55,995 : [INFO]  _____________________________________________________ Batch number 83: training Round 2 ____________________________________________________________
2023-03-21 01:08:56,586 : [INFO]  _____________________________________________________ Batch number 83: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:08:56,590 : [INFO]  Batch 83: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:08:56,590 : [INFO]  Batch 83, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:08:56,590 : [INFO]  ____________________________________Batch 83: round 2 finished ____________________________________
2023-03-21 01:08:56,591 : [INFO]  ____________________________________ Batch number 83: sent the final model to clients ____________________________________
2023-03-21 01:08:57,619 : [INFO]  Batch number 83 model fetched from the server
2023-03-21 01:08:57,619 : [INFO]  _____________________________________________________ Batch number 83: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:08:57,619 : [INFO]  Batch 83: Training set : loss - 0.5418283939361572, accuracy - 0.782608687877655, recall - 0.9239130616188049, AUC - 0.8988066911697388, F1 - 0.8095238273322177, precision - 0.7203390002250671
2023-03-21 01:08:57,619 : [INFO]  Batch 83: Testing set : loss - 0.581507682800293, accuracy - 0.7009803652763367, recall - 0.8921568393707275, AUC - 0.8492406606674194, F1 - 0.7489712002654927, precision - 0.6453900933265686
2023-03-21 01:08:57,716 : [INFO]  Batch 84 initialized 
2023-03-21 01:08:58,080 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:08:58,404 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:08:58,407 : [INFO]  _____________________________________________________ Batch number 84: training Round 1 ____________________________________________________________
2023-03-21 01:09:00,644 : [INFO]  _____________________________________________________ Batch number 84: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:00,650 : [INFO]  Batch 84: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:00,651 : [INFO]  Batch 84, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:00,651 : [INFO]  ____________________________________Batch 84: round 1 finished ____________________________________
2023-03-21 01:09:00,655 : [INFO]  _____________________________________________________ Batch number 84: training Round 2 ____________________________________________________________
2023-03-21 01:09:02,453 : [INFO]  _____________________________________________________ Batch number 84: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:02,456 : [INFO]  Batch 84: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:02,456 : [INFO]  Batch 84, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:02,456 : [INFO]  ____________________________________Batch 84: round 2 finished ____________________________________
2023-03-21 01:09:02,456 : [INFO]  ____________________________________ Batch number 84: sent the final model to clients ____________________________________
2023-03-21 01:09:03,839 : [INFO]  Batch number 84 model fetched from the server
2023-03-21 01:09:03,839 : [INFO]  _____________________________________________________ Batch number 84: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:03,839 : [INFO]  Batch 84: Training set : loss - 0.545829713344574, accuracy - 0.760869562625885, recall - 0.8913043737411499, AUC - 0.8907135725021362, F1 - 0.7884615434873735, precision - 0.7068965435028076
2023-03-21 01:09:03,839 : [INFO]  Batch 84: Testing set : loss - 0.5775490999221802, accuracy - 0.720588207244873, recall - 0.8921568393707275, AUC - 0.8484717607498169, F1 - 0.7615062602020729, precision - 0.6642335653305054
2023-03-21 01:09:03,929 : [INFO]  Batch 85 initialized 
2023-03-21 01:09:04,694 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:05,157 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:05,164 : [INFO]  _____________________________________________________ Batch number 85: training Round 1 ____________________________________________________________
2023-03-21 01:09:09,476 : [INFO]  _____________________________________________________ Batch number 85: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:09,481 : [INFO]  Batch 85: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:09,483 : [INFO]  Batch 85, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:09,484 : [INFO]  ____________________________________Batch 85: round 1 finished ____________________________________
2023-03-21 01:09:09,489 : [INFO]  _____________________________________________________ Batch number 85: training Round 2 ____________________________________________________________
2023-03-21 01:09:10,539 : [INFO]  _____________________________________________________ Batch number 85: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:10,542 : [INFO]  Batch 85: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:10,543 : [INFO]  Batch 85, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:10,543 : [INFO]  ____________________________________Batch 85: round 2 finished ____________________________________
2023-03-21 01:09:10,543 : [INFO]  ____________________________________ Batch number 85: sent the final model to clients ____________________________________
2023-03-21 01:09:11,717 : [INFO]  Batch number 85 model fetched from the server
2023-03-21 01:09:11,717 : [INFO]  _____________________________________________________ Batch number 85: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:11,717 : [INFO]  Batch 85: Training set : loss - 0.5532735586166382, accuracy - 0.7880434989929199, recall - 0.8913043737411499, AUC - 0.8698606491088867, F1 - 0.8078817702371864, precision - 0.7387387156486511
2023-03-21 01:09:11,717 : [INFO]  Batch 85: Testing set : loss - 0.6147506833076477, accuracy - 0.6813725233078003, recall - 0.8823529481887817, AUC - 0.7893117666244507, F1 - 0.7346938802658742, precision - 0.6293706297874451
2023-03-21 01:09:11,816 : [INFO]  Batch 86 initialized 
2023-03-21 01:09:12,160 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:12,461 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:12,464 : [INFO]  _____________________________________________________ Batch number 86: training Round 1 ____________________________________________________________
2023-03-21 01:09:14,516 : [INFO]  _____________________________________________________ Batch number 86: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:14,518 : [INFO]  Batch 86: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:14,519 : [INFO]  Batch 86, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:14,519 : [INFO]  ____________________________________Batch 86: round 1 finished ____________________________________
2023-03-21 01:09:14,520 : [INFO]  _____________________________________________________ Batch number 86: training Round 2 ____________________________________________________________
2023-03-21 01:09:15,065 : [INFO]  _____________________________________________________ Batch number 86: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:15,067 : [INFO]  Batch 86: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:15,068 : [INFO]  Batch 86, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:15,068 : [INFO]  ____________________________________Batch 86: round 2 finished ____________________________________
2023-03-21 01:09:15,068 : [INFO]  ____________________________________ Batch number 86: sent the final model to clients ____________________________________
2023-03-21 01:09:15,947 : [INFO]  Batch number 86 model fetched from the server
2023-03-21 01:09:15,947 : [INFO]  _____________________________________________________ Batch number 86: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:15,947 : [INFO]  Batch 86: Training set : loss - 0.5663245916366577, accuracy - 0.7336956262588501, recall - 0.8586956262588501, AUC - 0.8599362373352051, F1 - 0.7632850158361739, precision - 0.686956524848938
2023-03-21 01:09:15,947 : [INFO]  Batch 86: Testing set : loss - 0.5903177261352539, accuracy - 0.656862735748291, recall - 0.8529411554336548, AUC - 0.8416475057601929, F1 - 0.713114765511504, precision - 0.6126760840415955
2023-03-21 01:09:16,070 : [INFO]  Batch 87 initialized 
2023-03-21 01:09:16,405 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:16,713 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:16,715 : [INFO]  _____________________________________________________ Batch number 87: training Round 1 ____________________________________________________________
2023-03-21 01:09:19,114 : [INFO]  _____________________________________________________ Batch number 87: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:19,117 : [INFO]  Batch 87: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:19,117 : [INFO]  Batch 87, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:19,117 : [INFO]  ____________________________________Batch 87: round 1 finished ____________________________________
2023-03-21 01:09:19,119 : [INFO]  _____________________________________________________ Batch number 87: training Round 2 ____________________________________________________________
2023-03-21 01:09:19,800 : [INFO]  _____________________________________________________ Batch number 87: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:19,807 : [INFO]  Batch 87: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:19,808 : [INFO]  Batch 87, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:19,808 : [INFO]  ____________________________________Batch 87: round 2 finished ____________________________________
2023-03-21 01:09:19,808 : [INFO]  ____________________________________ Batch number 87: sent the final model to clients ____________________________________
2023-03-21 01:09:20,672 : [INFO]  Batch number 87 model fetched from the server
2023-03-21 01:09:20,673 : [INFO]  _____________________________________________________ Batch number 87: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:20,673 : [INFO]  Batch 87: Training set : loss - 0.5275575518608093, accuracy - 0.804347813129425, recall - 0.95652174949646, AUC - 0.92527174949646, F1 - 0.8301886933348109, precision - 0.7333333492279053
2023-03-21 01:09:20,673 : [INFO]  Batch 87: Testing set : loss - 0.5899633169174194, accuracy - 0.6813725233078003, recall - 0.9313725233078003, AUC - 0.866878092288971, F1 - 0.745098047256469, precision - 0.6209150552749634
2023-03-21 01:09:20,868 : [INFO]  Batch 88 initialized 
2023-03-21 01:09:21,196 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:21,498 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:21,500 : [INFO]  _____________________________________________________ Batch number 88: training Round 1 ____________________________________________________________
2023-03-21 01:09:23,544 : [INFO]  _____________________________________________________ Batch number 88: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:23,547 : [INFO]  Batch 88: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:23,547 : [INFO]  Batch 88, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:23,547 : [INFO]  ____________________________________Batch 88: round 1 finished ____________________________________
2023-03-21 01:09:23,548 : [INFO]  _____________________________________________________ Batch number 88: training Round 2 ____________________________________________________________
2023-03-21 01:09:24,107 : [INFO]  _____________________________________________________ Batch number 88: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:24,109 : [INFO]  Batch 88: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:24,110 : [INFO]  Batch 88, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:24,110 : [INFO]  ____________________________________Batch 88: round 2 finished ____________________________________
2023-03-21 01:09:24,110 : [INFO]  ____________________________________ Batch number 88: sent the final model to clients ____________________________________
2023-03-21 01:09:24,979 : [INFO]  Batch number 88 model fetched from the server
2023-03-21 01:09:24,979 : [INFO]  _____________________________________________________ Batch number 88: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:24,979 : [INFO]  Batch 88: Training set : loss - 0.5869424939155579, accuracy - 0.695652186870575, recall - 0.8804348111152649, AUC - 0.8201204538345337, F1 - 0.7431192705200008, precision - 0.6428571343421936
2023-03-21 01:09:24,979 : [INFO]  Batch 88: Testing set : loss - 0.5809964537620544, accuracy - 0.6813725233078003, recall - 0.8921568393707275, AUC - 0.8647634983062744, F1 - 0.7368420828414398, precision - 0.6275861859321594
2023-03-21 01:09:25,149 : [INFO]  Batch 89 initialized 
2023-03-21 01:09:25,477 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:25,784 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:25,787 : [INFO]  _____________________________________________________ Batch number 89: training Round 1 ____________________________________________________________
2023-03-21 01:09:27,802 : [INFO]  _____________________________________________________ Batch number 89: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:27,804 : [INFO]  Batch 89: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:27,805 : [INFO]  Batch 89, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:27,805 : [INFO]  ____________________________________Batch 89: round 1 finished ____________________________________
2023-03-21 01:09:27,806 : [INFO]  _____________________________________________________ Batch number 89: training Round 2 ____________________________________________________________
2023-03-21 01:09:28,363 : [INFO]  _____________________________________________________ Batch number 89: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:28,368 : [INFO]  Batch 89: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:28,368 : [INFO]  Batch 89, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:28,368 : [INFO]  ____________________________________Batch 89: round 2 finished ____________________________________
2023-03-21 01:09:28,368 : [INFO]  ____________________________________ Batch number 89: sent the final model to clients ____________________________________
2023-03-21 01:09:29,256 : [INFO]  Batch number 89 model fetched from the server
2023-03-21 01:09:29,256 : [INFO]  _____________________________________________________ Batch number 89: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:29,256 : [INFO]  Batch 89: Training set : loss - 0.5529412627220154, accuracy - 0.7554348111152649, recall - 0.9021739363670349, AUC - 0.8758269548416138, F1 - 0.7867298781589309, precision - 0.6974790096282959
2023-03-21 01:09:29,256 : [INFO]  Batch 89: Testing set : loss - 0.5949552059173584, accuracy - 0.6911764740943909, recall - 0.8529411554336548, AUC - 0.8143022060394287, F1 - 0.7341772211493822, precision - 0.644444465637207
2023-03-21 01:09:29,434 : [INFO]  Batch 90 initialized 
2023-03-21 01:09:29,767 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:30,073 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:30,076 : [INFO]  _____________________________________________________ Batch number 90: training Round 1 ____________________________________________________________
2023-03-21 01:09:32,084 : [INFO]  _____________________________________________________ Batch number 90: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:32,087 : [INFO]  Batch 90: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:32,087 : [INFO]  Batch 90, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:32,087 : [INFO]  ____________________________________Batch 90: round 1 finished ____________________________________
2023-03-21 01:09:32,088 : [INFO]  _____________________________________________________ Batch number 90: training Round 2 ____________________________________________________________
2023-03-21 01:09:32,628 : [INFO]  _____________________________________________________ Batch number 90: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:32,630 : [INFO]  Batch 90: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:32,631 : [INFO]  Batch 90, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:32,631 : [INFO]  ____________________________________Batch 90: round 2 finished ____________________________________
2023-03-21 01:09:32,631 : [INFO]  ____________________________________ Batch number 90: sent the final model to clients ____________________________________
2023-03-21 01:09:33,491 : [INFO]  Batch number 90 model fetched from the server
2023-03-21 01:09:33,492 : [INFO]  _____________________________________________________ Batch number 90: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:33,492 : [INFO]  Batch 90: Training set : loss - 0.5635309219360352, accuracy - 0.7010869383811951, recall - 0.9347826242446899, AUC - 0.8923085927963257, F1 - 0.7577092574586568, precision - 0.6370370388031006
2023-03-21 01:09:33,492 : [INFO]  Batch 90: Testing set : loss - 0.5773304104804993, accuracy - 0.6764705777168274, recall - 0.9607843160629272, AUC - 0.9089772701263428, F1 - 0.7480916126535305, precision - 0.612500011920929
2023-03-21 01:09:33,698 : [INFO]  Batch 91 initialized 
2023-03-21 01:09:34,026 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:34,340 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:34,342 : [INFO]  _____________________________________________________ Batch number 91: training Round 1 ____________________________________________________________
2023-03-21 01:09:36,324 : [INFO]  _____________________________________________________ Batch number 91: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:36,326 : [INFO]  Batch 91: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:36,327 : [INFO]  Batch 91, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:36,327 : [INFO]  ____________________________________Batch 91: round 1 finished ____________________________________
2023-03-21 01:09:36,328 : [INFO]  _____________________________________________________ Batch number 91: training Round 2 ____________________________________________________________
2023-03-21 01:09:36,885 : [INFO]  _____________________________________________________ Batch number 91: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:36,887 : [INFO]  Batch 91: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:36,888 : [INFO]  Batch 91, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:36,888 : [INFO]  ____________________________________Batch 91: round 2 finished ____________________________________
2023-03-21 01:09:36,888 : [INFO]  ____________________________________ Batch number 91: sent the final model to clients ____________________________________
2023-03-21 01:09:37,780 : [INFO]  Batch number 91 model fetched from the server
2023-03-21 01:09:37,780 : [INFO]  _____________________________________________________ Batch number 91: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:37,780 : [INFO]  Batch 91: Training set : loss - 0.5663346648216248, accuracy - 0.7336956262588501, recall - 0.8695651888847351, AUC - 0.8754726052284241, F1 - 0.7655502400013228, precision - 0.6837607026100159
2023-03-21 01:09:37,780 : [INFO]  Batch 91: Testing set : loss - 0.6133546829223633, accuracy - 0.686274528503418, recall - 0.8921568393707275, AUC - 0.8002210855484009, F1 - 0.7398373721824523, precision - 0.6319444179534912
2023-03-21 01:09:37,914 : [INFO]  Batch 92 initialized 
2023-03-21 01:09:38,248 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:38,565 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:38,568 : [INFO]  _____________________________________________________ Batch number 92: training Round 1 ____________________________________________________________
2023-03-21 01:09:40,578 : [INFO]  _____________________________________________________ Batch number 92: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:40,580 : [INFO]  Batch 92: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:40,581 : [INFO]  Batch 92, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:40,581 : [INFO]  ____________________________________Batch 92: round 1 finished ____________________________________
2023-03-21 01:09:40,582 : [INFO]  _____________________________________________________ Batch number 92: training Round 2 ____________________________________________________________
2023-03-21 01:09:41,124 : [INFO]  _____________________________________________________ Batch number 92: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:41,126 : [INFO]  Batch 92: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:41,126 : [INFO]  Batch 92, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:41,126 : [INFO]  ____________________________________Batch 92: round 2 finished ____________________________________
2023-03-21 01:09:41,126 : [INFO]  ____________________________________ Batch number 92: sent the final model to clients ____________________________________
2023-03-21 01:09:41,991 : [INFO]  Batch number 92 model fetched from the server
2023-03-21 01:09:41,991 : [INFO]  _____________________________________________________ Batch number 92: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:41,991 : [INFO]  Batch 92: Training set : loss - 0.5629388689994812, accuracy - 0.7336956262588501, recall - 0.945652186870575, AUC - 0.8878780603408813, F1 - 0.7802690812345651, precision - 0.6641221642494202
2023-03-21 01:09:41,991 : [INFO]  Batch 92: Testing set : loss - 0.613036572933197, accuracy - 0.6372548937797546, recall - 0.9019607901573181, AUC - 0.8256438970565796, F1 - 0.7131783142806774, precision - 0.5897436141967773
2023-03-21 01:09:42,084 : [INFO]  Batch 93 initialized 
2023-03-21 01:09:42,415 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:42,735 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:42,738 : [INFO]  _____________________________________________________ Batch number 93: training Round 1 ____________________________________________________________
2023-03-21 01:09:44,727 : [INFO]  _____________________________________________________ Batch number 93: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:44,729 : [INFO]  Batch 93: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:44,729 : [INFO]  Batch 93, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:44,729 : [INFO]  ____________________________________Batch 93: round 1 finished ____________________________________
2023-03-21 01:09:44,731 : [INFO]  _____________________________________________________ Batch number 93: training Round 2 ____________________________________________________________
2023-03-21 01:09:45,283 : [INFO]  _____________________________________________________ Batch number 93: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:45,286 : [INFO]  Batch 93: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:45,286 : [INFO]  Batch 93, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:45,286 : [INFO]  ____________________________________Batch 93: round 2 finished ____________________________________
2023-03-21 01:09:45,286 : [INFO]  ____________________________________ Batch number 93: sent the final model to clients ____________________________________
2023-03-21 01:09:46,154 : [INFO]  Batch number 93 model fetched from the server
2023-03-21 01:09:46,154 : [INFO]  _____________________________________________________ Batch number 93: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:46,154 : [INFO]  Batch 93: Training set : loss - 0.5294760465621948, accuracy - 0.804347813129425, recall - 0.967391312122345, AUC - 0.9354324340820312, F1 - 0.8317757196869534, precision - 0.7295082211494446
2023-03-21 01:09:46,154 : [INFO]  Batch 93: Testing set : loss - 0.5956023931503296, accuracy - 0.6715686321258545, recall - 0.9215686321258545, AUC - 0.8461649417877197, F1 - 0.7372549200057982, precision - 0.6143791079521179
2023-03-21 01:09:46,229 : [INFO]  Batch 94 initialized 
2023-03-21 01:09:46,560 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:46,872 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:46,875 : [INFO]  _____________________________________________________ Batch number 94: training Round 1 ____________________________________________________________
2023-03-21 01:09:48,856 : [INFO]  _____________________________________________________ Batch number 94: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:48,858 : [INFO]  Batch 94: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:48,858 : [INFO]  Batch 94, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:48,858 : [INFO]  ____________________________________Batch 94: round 1 finished ____________________________________
2023-03-21 01:09:48,860 : [INFO]  _____________________________________________________ Batch number 94: training Round 2 ____________________________________________________________
2023-03-21 01:09:49,395 : [INFO]  _____________________________________________________ Batch number 94: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:49,398 : [INFO]  Batch 94: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:49,398 : [INFO]  Batch 94, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:49,398 : [INFO]  ____________________________________Batch 94: round 2 finished ____________________________________
2023-03-21 01:09:49,398 : [INFO]  ____________________________________ Batch number 94: sent the final model to clients ____________________________________
2023-03-21 01:09:50,252 : [INFO]  Batch number 94 model fetched from the server
2023-03-21 01:09:50,252 : [INFO]  _____________________________________________________ Batch number 94: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:50,252 : [INFO]  Batch 94: Training set : loss - 0.5381485223770142, accuracy - 0.760869562625885, recall - 0.9347826242446899, AUC - 0.9282253980636597, F1 - 0.7962962981359457, precision - 0.6935483813285828
2023-03-21 01:09:50,252 : [INFO]  Batch 94: Testing set : loss - 0.5745435357093811, accuracy - 0.7303921580314636, recall - 0.9117646813392639, AUC - 0.8579392433166504, F1 - 0.7717842315605781, precision - 0.6690647602081299
2023-03-21 01:09:50,320 : [INFO]  Batch 95 initialized 
2023-03-21 01:09:50,657 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:50,978 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:50,981 : [INFO]  _____________________________________________________ Batch number 95: training Round 1 ____________________________________________________________
2023-03-21 01:09:53,140 : [INFO]  _____________________________________________________ Batch number 95: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:53,143 : [INFO]  Batch 95: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:53,143 : [INFO]  Batch 95, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:53,143 : [INFO]  ____________________________________Batch 95: round 1 finished ____________________________________
2023-03-21 01:09:53,145 : [INFO]  _____________________________________________________ Batch number 95: training Round 2 ____________________________________________________________
2023-03-21 01:09:53,742 : [INFO]  _____________________________________________________ Batch number 95: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:53,747 : [INFO]  Batch 95: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:53,748 : [INFO]  Batch 95, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:53,748 : [INFO]  ____________________________________Batch 95: round 2 finished ____________________________________
2023-03-21 01:09:53,748 : [INFO]  ____________________________________ Batch number 95: sent the final model to clients ____________________________________
2023-03-21 01:09:54,725 : [INFO]  Batch number 95 model fetched from the server
2023-03-21 01:09:54,726 : [INFO]  _____________________________________________________ Batch number 95: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:09:54,726 : [INFO]  Batch 95: Training set : loss - 0.5271894335746765, accuracy - 0.820652186870575, recall - 0.97826087474823, AUC - 0.9357868432998657, F1 - 0.8450704247870211, precision - 0.7438016533851624
2023-03-21 01:09:54,726 : [INFO]  Batch 95: Testing set : loss - 0.5864519476890564, accuracy - 0.7107843160629272, recall - 0.9117646813392639, AUC - 0.8468858599662781, F1 - 0.7591836828532086, precision - 0.6503496766090393
2023-03-21 01:09:54,829 : [INFO]  Batch 96 initialized 
2023-03-21 01:09:55,195 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:09:55,511 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:09:55,514 : [INFO]  _____________________________________________________ Batch number 96: training Round 1 ____________________________________________________________
2023-03-21 01:09:58,938 : [INFO]  _____________________________________________________ Batch number 96: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:09:58,943 : [INFO]  Batch 96: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:58,943 : [INFO]  Batch 96, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:58,943 : [INFO]  ____________________________________Batch 96: round 1 finished ____________________________________
2023-03-21 01:09:58,945 : [INFO]  _____________________________________________________ Batch number 96: training Round 2 ____________________________________________________________
2023-03-21 01:09:59,526 : [INFO]  _____________________________________________________ Batch number 96: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:09:59,528 : [INFO]  Batch 96: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:09:59,529 : [INFO]  Batch 96, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:09:59,529 : [INFO]  ____________________________________Batch 96: round 2 finished ____________________________________
2023-03-21 01:09:59,529 : [INFO]  ____________________________________ Batch number 96: sent the final model to clients ____________________________________
2023-03-21 01:10:00,578 : [INFO]  Batch number 96 model fetched from the server
2023-03-21 01:10:00,578 : [INFO]  _____________________________________________________ Batch number 96: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:10:00,578 : [INFO]  Batch 96: Training set : loss - 0.5493987798690796, accuracy - 0.717391312122345, recall - 0.97826087474823, AUC - 0.9330103993415833, F1 - 0.775862064394174, precision - 0.6428571343421936
2023-03-21 01:10:00,578 : [INFO]  Batch 96: Testing set : loss - 0.5750955939292908, accuracy - 0.7058823704719543, recall - 0.9215686321258545, AUC - 0.8971549272537231, F1 - 0.7580645092211578, precision - 0.6438356041908264
2023-03-21 01:10:00,691 : [INFO]  Batch 97 initialized 
2023-03-21 01:10:01,052 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:10:01,380 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:10:01,382 : [INFO]  _____________________________________________________ Batch number 97: training Round 1 ____________________________________________________________
2023-03-21 01:10:03,461 : [INFO]  _____________________________________________________ Batch number 97: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:10:03,464 : [INFO]  Batch 97: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:03,464 : [INFO]  Batch 97, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:03,464 : [INFO]  ____________________________________Batch 97: round 1 finished ____________________________________
2023-03-21 01:10:03,466 : [INFO]  _____________________________________________________ Batch number 97: training Round 2 ____________________________________________________________
2023-03-21 01:10:04,009 : [INFO]  _____________________________________________________ Batch number 97: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:10:04,011 : [INFO]  Batch 97: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:04,011 : [INFO]  Batch 97, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:04,012 : [INFO]  ____________________________________Batch 97: round 2 finished ____________________________________
2023-03-21 01:10:04,012 : [INFO]  ____________________________________ Batch number 97: sent the final model to clients ____________________________________
2023-03-21 01:10:05,200 : [INFO]  Batch number 97 model fetched from the server
2023-03-21 01:10:05,200 : [INFO]  _____________________________________________________ Batch number 97: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:10:05,200 : [INFO]  Batch 97: Training set : loss - 0.5510247945785522, accuracy - 0.760869562625885, recall - 0.8913043737411499, AUC - 0.8786035776138306, F1 - 0.7884615434873735, precision - 0.7068965435028076
2023-03-21 01:10:05,200 : [INFO]  Batch 97: Testing set : loss - 0.5759353637695312, accuracy - 0.7009803652763367, recall - 0.9019607901573181, AUC - 0.8623605966567993, F1 - 0.7510203951371304, precision - 0.6433566212654114
2023-03-21 01:10:05,410 : [INFO]  Batch 98 initialized 
2023-03-21 01:10:05,742 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:10:06,056 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:10:06,059 : [INFO]  _____________________________________________________ Batch number 98: training Round 1 ____________________________________________________________
2023-03-21 01:10:08,037 : [INFO]  _____________________________________________________ Batch number 98: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:10:08,039 : [INFO]  Batch 98: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:08,039 : [INFO]  Batch 98, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:08,039 : [INFO]  ____________________________________Batch 98: round 1 finished ____________________________________
2023-03-21 01:10:08,041 : [INFO]  _____________________________________________________ Batch number 98: training Round 2 ____________________________________________________________
2023-03-21 01:10:08,562 : [INFO]  _____________________________________________________ Batch number 98: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:10:08,564 : [INFO]  Batch 98: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:08,564 : [INFO]  Batch 98, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:08,564 : [INFO]  ____________________________________Batch 98: round 2 finished ____________________________________
2023-03-21 01:10:08,565 : [INFO]  ____________________________________ Batch number 98: sent the final model to clients ____________________________________
2023-03-21 01:10:09,420 : [INFO]  Batch number 98 model fetched from the server
2023-03-21 01:10:09,420 : [INFO]  _____________________________________________________ Batch number 98: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:10:09,420 : [INFO]  Batch 98: Training set : loss - 0.544709324836731, accuracy - 0.7554348111152649, recall - 0.8913043737411499, AUC - 0.8848062753677368, F1 - 0.7846890164339696, precision - 0.7008547186851501
2023-03-21 01:10:09,420 : [INFO]  Batch 98: Testing set : loss - 0.5765953063964844, accuracy - 0.75, recall - 0.9117646813392639, AUC - 0.8614955544471741, F1 - 0.7848101295238307, precision - 0.6888889074325562
2023-03-21 01:10:09,640 : [INFO]  Batch 99 initialized 
2023-03-21 01:10:09,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:10:10,294 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:10:10,297 : [INFO]  _____________________________________________________ Batch number 99: training Round 1 ____________________________________________________________
2023-03-21 01:10:12,505 : [INFO]  _____________________________________________________ Batch number 99: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:10:12,508 : [INFO]  Batch 99: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:12,509 : [INFO]  Batch 99, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:12,509 : [INFO]  ____________________________________Batch 99: round 1 finished ____________________________________
2023-03-21 01:10:12,512 : [INFO]  _____________________________________________________ Batch number 99: training Round 2 ____________________________________________________________
2023-03-21 01:10:13,240 : [INFO]  _____________________________________________________ Batch number 99: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:10:13,243 : [INFO]  Batch 99: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:13,243 : [INFO]  Batch 99, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:13,243 : [INFO]  ____________________________________Batch 99: round 2 finished ____________________________________
2023-03-21 01:10:13,243 : [INFO]  ____________________________________ Batch number 99: sent the final model to clients ____________________________________
2023-03-21 01:10:14,335 : [INFO]  Batch number 99 model fetched from the server
2023-03-21 01:10:14,336 : [INFO]  _____________________________________________________ Batch number 99: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:10:14,336 : [INFO]  Batch 99: Training set : loss - 0.5230275988578796, accuracy - 0.8152173757553101, recall - 0.9130434989929199, AUC - 0.9149929285049438, F1 - 0.8316831692049703, precision - 0.7636363506317139
2023-03-21 01:10:14,336 : [INFO]  Batch 99: Testing set : loss - 0.5603644251823425, accuracy - 0.7107843160629272, recall - 0.9019607901573181, AUC - 0.8818243145942688, F1 - 0.7572016492883455, precision - 0.652482271194458
2023-03-21 01:10:14,560 : [INFO]  Batch 100 initialized 
2023-03-21 01:10:14,918 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:10:15,253 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:10:15,256 : [INFO]  _____________________________________________________ Batch number 100: training Round 1 ____________________________________________________________
2023-03-21 01:10:17,969 : [INFO]  _____________________________________________________ Batch number 100: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:10:17,971 : [INFO]  Batch 100: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:17,971 : [INFO]  Batch 100, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:17,971 : [INFO]  ____________________________________Batch 100: round 1 finished ____________________________________
2023-03-21 01:10:17,973 : [INFO]  _____________________________________________________ Batch number 100: training Round 2 ____________________________________________________________
2023-03-21 01:10:18,530 : [INFO]  _____________________________________________________ Batch number 100: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:10:18,533 : [INFO]  Batch 100: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:18,533 : [INFO]  Batch 100, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:18,533 : [INFO]  ____________________________________Batch 100: round 2 finished ____________________________________
2023-03-21 01:10:18,533 : [INFO]  ____________________________________ Batch number 100: sent the final model to clients ____________________________________
2023-03-21 01:10:19,591 : [INFO]  Batch number 100 model fetched from the server
2023-03-21 01:10:19,591 : [INFO]  _____________________________________________________ Batch number 100: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:10:19,592 : [INFO]  Batch 100: Training set : loss - 0.5721519589424133, accuracy - 0.739130437374115, recall - 0.8913043737411499, AUC - 0.8653119802474976, F1 - 0.7735849179674951, precision - 0.6833333373069763
2023-03-21 01:10:19,592 : [INFO]  Batch 100: Testing set : loss - 0.5745394229888916, accuracy - 0.6911764740943909, recall - 0.8725489974021912, AUC - 0.8653882741928101, F1 - 0.7385891951041141, precision - 0.6402877569198608
2023-03-21 01:10:19,740 : [INFO]  Batch 101 initialized 
2023-03-21 01:10:20,207 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:10:20,540 : [INFO]  _____________________________________________________ Next batch processing started: transfer learning is on ____________________________________________________________
2023-03-21 01:10:20,547 : [INFO]  _____________________________________________________ Batch number 101: training Round 1 ____________________________________________________________
2023-03-21 01:10:23,213 : [INFO]  _____________________________________________________ Batch number 101: Sent local model to the server, round 1 ____________________________________________________________
2023-03-21 01:10:23,216 : [INFO]  Batch 101: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:23,216 : [INFO]  Batch 101, round 1: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:23,216 : [INFO]  ____________________________________Batch 101: round 1 finished ____________________________________
2023-03-21 01:10:23,218 : [INFO]  _____________________________________________________ Batch number 101: training Round 2 ____________________________________________________________
2023-03-21 01:10:23,732 : [INFO]  _____________________________________________________ Batch number 101: Sent local model to the server, round 2 ____________________________________________________________
2023-03-21 01:10:23,734 : [INFO]  Batch 101: recieved model from client-0 at 127.0.0.1:53686
2023-03-21 01:10:23,734 : [INFO]  Batch 101, round 2: aggregated global model sent to client-0 at 127.0.0.1:53686
2023-03-21 01:10:23,734 : [INFO]  ____________________________________Batch 101: round 2 finished ____________________________________
2023-03-21 01:10:23,735 : [INFO]  ____________________________________ Batch number 101: sent the final model to clients ____________________________________
2023-03-21 01:10:23,735 : [INFO]  Distributed training done!
2023-03-21 01:10:23,735 : [INFO]  Training report : Total elapsed time 678.0887904110001 seconds, graph ID 1, number of clients 1, training rounds 2, rounds 2, number of timestamps 101
2023-03-21 01:10:25,427 : [INFO]  Batch number 101 model fetched from the server
2023-03-21 01:10:25,427 : [INFO]  _____________________________________________________ Batch number 101: Final global model evalution after 2 rounds ____________________________________________________________
2023-03-21 01:10:25,427 : [INFO]  Batch 101: Training set : loss - 0.5234717130661011, accuracy - 0.7880434989929199, recall - 0.945652186870575, AUC - 0.9284617304801941, F1 - 0.8169014148750625, precision - 0.7190082669258118
2023-03-21 01:10:25,427 : [INFO]  Batch 101: Testing set : loss - 0.5659312009811401, accuracy - 0.720588207244873, recall - 0.8921568393707275, AUC - 0.8764897584915161, F1 - 0.7615062602020729, precision - 0.6642335653305054
2023-03-21 01:25:52,727 : [WARNING]  ####################################### New Training Session #######################################
2023-03-21 01:25:52,727 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 2, number of timestamps 101
2023-03-21 01:25:53,955 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-21 01:25:53,955 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-21 01:25:55,356 : [INFO]  Model initialized for training
2023-03-21 01:26:07,102 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:26:07,328 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:26:07,952 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:26:08,086 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-21 01:26:08,086 : [INFO]  Connected to the server
2023-03-21 01:26:08,086 : [INFO]  Accepted new connection at 127.0.0.1:58014
2023-03-21 01:26:08,086 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:58014
2023-03-21 01:26:08,173 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:26:08,180 : [INFO]  ################################## Initial model training started ##################################
2023-03-21 01:26:08,180 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-21 01:26:40,630 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-21 01:26:40,632 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:26:40,632 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:26:40,632 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-21 01:26:40,634 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-21 01:27:13,445 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-21 01:27:13,448 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:13,448 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:13,448 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-21 01:27:13,448 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-21 01:27:43,301 : [INFO]  ################ Initial trained model: Final global model evalution after 2 rounds ################
2023-03-21 01:27:43,301 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.72, recall - 0.91, AUC - 0.84, F1 - 0.77, precision - 0.66, training time - -65.0 seconds
2023-03-21 01:27:43,301 : [INFO]  Initially trained model: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.91, AUC - 0.81, F1 - 0.75, precision - 0.64
2023-03-21 01:27:43,350 : [INFO]  Batch 1 initialized 
2023-03-21 01:27:43,716 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:27:43,830 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-21 01:27:43,830 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-21 01:27:45,968 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-21 01:27:45,971 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:45,971 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:45,971 : [INFO]  ____________________________________ Batch 1: round 1 finished ____________________________________
2023-03-21 01:27:45,973 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-21 01:27:46,539 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-21 01:27:46,541 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:46,542 : [INFO]  Batch 1, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:46,542 : [INFO]  ____________________________________ Batch 1: round 2 finished ____________________________________
2023-03-21 01:27:46,542 : [INFO]  #################################### Batch 1: sent the final model to clients ####################################
2023-03-21 01:27:47,427 : [INFO]  Batch number 1 model fetched from the server
2023-03-21 01:27:47,427 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-21 01:27:47,427 : [INFO]  Batch 1: Training set : loss - 0.58, accuracy - 0.72, recall - 0.92, AUC - 0.84, F1 - 0.77, precision - 0.66, training time - -3.0 seconds
2023-03-21 01:27:47,427 : [INFO]  Batch 1: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.66
2023-03-21 01:27:47,545 : [INFO]  Batch 2 initialized 
2023-03-21 01:27:47,886 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:27:48,061 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-21 01:27:49,996 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-21 01:27:49,999 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:49,999 : [INFO]  Batch 2, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:49,999 : [INFO]  ____________________________________ Batch 2: round 1 finished ____________________________________
2023-03-21 01:27:50,000 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-21 01:27:50,564 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-21 01:27:50,566 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:50,567 : [INFO]  Batch 2, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:50,567 : [INFO]  ____________________________________ Batch 2: round 2 finished ____________________________________
2023-03-21 01:27:50,567 : [INFO]  #################################### Batch 2: sent the final model to clients ####################################
2023-03-21 01:27:51,435 : [INFO]  Batch number 2 model fetched from the server
2023-03-21 01:27:51,435 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-21 01:27:51,435 : [INFO]  Batch 2: Training set : loss - 0.56, accuracy - 0.78, recall - 0.96, AUC - 0.87, F1 - 0.81, precision - 0.7, training time - -3.0 seconds
2023-03-21 01:27:51,435 : [INFO]  Batch 2: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.94, AUC - 0.85, F1 - 0.78, precision - 0.66
2023-03-21 01:27:51,505 : [INFO]  Batch 3 initialized 
2023-03-21 01:27:51,845 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:27:52,024 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-21 01:27:53,916 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-21 01:27:53,918 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:53,919 : [INFO]  Batch 3, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:53,919 : [INFO]  ____________________________________ Batch 3: round 1 finished ____________________________________
2023-03-21 01:27:53,920 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-21 01:27:54,466 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-21 01:27:54,471 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:54,471 : [INFO]  Batch 3, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:54,471 : [INFO]  ____________________________________ Batch 3: round 2 finished ____________________________________
2023-03-21 01:27:54,471 : [INFO]  #################################### Batch 3: sent the final model to clients ####################################
2023-03-21 01:27:55,330 : [INFO]  Batch number 3 model fetched from the server
2023-03-21 01:27:55,330 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-21 01:27:55,330 : [INFO]  Batch 3: Training set : loss - 0.55, accuracy - 0.74, recall - 0.95, AUC - 0.89, F1 - 0.78, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:27:55,330 : [INFO]  Batch 3: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.94, AUC - 0.84, F1 - 0.77, precision - 0.66
2023-03-21 01:27:55,429 : [INFO]  Batch 4 initialized 
2023-03-21 01:27:55,768 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:27:55,948 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-21 01:27:57,872 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-21 01:27:57,874 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:57,875 : [INFO]  Batch 4, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:57,875 : [INFO]  ____________________________________ Batch 4: round 1 finished ____________________________________
2023-03-21 01:27:57,876 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-21 01:27:58,437 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-21 01:27:58,440 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:27:58,440 : [INFO]  Batch 4, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:27:58,440 : [INFO]  ____________________________________ Batch 4: round 2 finished ____________________________________
2023-03-21 01:27:58,440 : [INFO]  #################################### Batch 4: sent the final model to clients ####################################
2023-03-21 01:27:59,308 : [INFO]  Batch number 4 model fetched from the server
2023-03-21 01:27:59,308 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-21 01:27:59,308 : [INFO]  Batch 4: Training set : loss - 0.56, accuracy - 0.77, recall - 0.96, AUC - 0.89, F1 - 0.81, precision - 0.7, training time - -2.0 seconds
2023-03-21 01:27:59,308 : [INFO]  Batch 4: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.92, AUC - 0.84, F1 - 0.77, precision - 0.66
2023-03-21 01:27:59,424 : [INFO]  Batch 5 initialized 
2023-03-21 01:27:59,757 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:27:59,938 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-21 01:28:01,847 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:01,849 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:01,850 : [INFO]  Batch 5, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:01,850 : [INFO]  ____________________________________ Batch 5: round 1 finished ____________________________________
2023-03-21 01:28:01,851 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-21 01:28:02,392 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-21 01:28:02,394 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:02,395 : [INFO]  Batch 5, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:02,395 : [INFO]  ____________________________________ Batch 5: round 2 finished ____________________________________
2023-03-21 01:28:02,395 : [INFO]  #################################### Batch 5: sent the final model to clients ####################################
2023-03-21 01:28:03,276 : [INFO]  Batch number 5 model fetched from the server
2023-03-21 01:28:03,276 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-21 01:28:03,276 : [INFO]  Batch 5: Training set : loss - 0.55, accuracy - 0.76, recall - 0.9, AUC - 0.89, F1 - 0.79, precision - 0.7, training time - -2.0 seconds
2023-03-21 01:28:03,276 : [INFO]  Batch 5: Testing set : loss - 0.59, accuracy - 0.72, recall - 0.91, AUC - 0.83, F1 - 0.77, precision - 0.66
2023-03-21 01:28:03,347 : [INFO]  Batch 6 initialized 
2023-03-21 01:28:03,685 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:28:03,882 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-21 01:28:05,940 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:05,942 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:05,943 : [INFO]  Batch 6, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:05,943 : [INFO]  ____________________________________ Batch 6: round 1 finished ____________________________________
2023-03-21 01:28:05,944 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-21 01:28:06,534 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-21 01:28:06,537 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:06,538 : [INFO]  Batch 6, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:06,538 : [INFO]  ____________________________________ Batch 6: round 2 finished ____________________________________
2023-03-21 01:28:06,538 : [INFO]  #################################### Batch 6: sent the final model to clients ####################################
2023-03-21 01:28:07,727 : [INFO]  Batch number 6 model fetched from the server
2023-03-21 01:28:07,727 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-21 01:28:07,727 : [INFO]  Batch 6: Training set : loss - 0.57, accuracy - 0.72, recall - 0.89, AUC - 0.86, F1 - 0.76, precision - 0.66, training time - -3.0 seconds
2023-03-21 01:28:07,727 : [INFO]  Batch 6: Testing set : loss - 0.59, accuracy - 0.71, recall - 0.9, AUC - 0.83, F1 - 0.76, precision - 0.65
2023-03-21 01:28:07,794 : [INFO]  Batch 7 initialized 
2023-03-21 01:28:08,319 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:28:08,577 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-21 01:28:11,420 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:11,422 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:11,423 : [INFO]  Batch 7, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:11,423 : [INFO]  ____________________________________ Batch 7: round 1 finished ____________________________________
2023-03-21 01:28:11,424 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-21 01:28:12,085 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-21 01:28:12,087 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:12,088 : [INFO]  Batch 7, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:12,088 : [INFO]  ____________________________________ Batch 7: round 2 finished ____________________________________
2023-03-21 01:28:12,088 : [INFO]  #################################### Batch 7: sent the final model to clients ####################################
2023-03-21 01:28:12,983 : [INFO]  Batch number 7 model fetched from the server
2023-03-21 01:28:12,983 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-21 01:28:12,983 : [INFO]  Batch 7: Training set : loss - 0.57, accuracy - 0.76, recall - 0.96, AUC - 0.89, F1 - 0.8, precision - 0.68, training time - -4.0 seconds
2023-03-21 01:28:12,983 : [INFO]  Batch 7: Testing set : loss - 0.59, accuracy - 0.73, recall - 0.98, AUC - 0.86, F1 - 0.78, precision - 0.65
2023-03-21 01:28:13,081 : [INFO]  Batch 8 initialized 
2023-03-21 01:28:13,417 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:28:13,609 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-21 01:28:15,711 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:15,713 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:15,714 : [INFO]  Batch 8, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:15,714 : [INFO]  ____________________________________ Batch 8: round 1 finished ____________________________________
2023-03-21 01:28:15,715 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-21 01:28:16,273 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-21 01:28:16,275 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:16,276 : [INFO]  Batch 8, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:16,276 : [INFO]  ____________________________________ Batch 8: round 2 finished ____________________________________
2023-03-21 01:28:16,276 : [INFO]  #################################### Batch 8: sent the final model to clients ####################################
2023-03-21 01:28:17,140 : [INFO]  Batch number 8 model fetched from the server
2023-03-21 01:28:17,140 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-21 01:28:17,140 : [INFO]  Batch 8: Training set : loss - 0.54, accuracy - 0.8, recall - 0.99, AUC - 0.93, F1 - 0.83, precision - 0.72, training time - -3.0 seconds
2023-03-21 01:28:17,140 : [INFO]  Batch 8: Testing set : loss - 0.6, accuracy - 0.71, recall - 0.97, AUC - 0.85, F1 - 0.77, precision - 0.64
2023-03-21 01:28:17,229 : [INFO]  Batch 9 initialized 
2023-03-21 01:28:17,560 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:28:17,751 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-21 01:28:19,691 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:19,693 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:19,694 : [INFO]  Batch 9, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:19,694 : [INFO]  ____________________________________ Batch 9: round 1 finished ____________________________________
2023-03-21 01:28:19,695 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-21 01:28:20,249 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-21 01:28:20,252 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:20,252 : [INFO]  Batch 9, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:20,252 : [INFO]  ____________________________________ Batch 9: round 2 finished ____________________________________
2023-03-21 01:28:20,252 : [INFO]  #################################### Batch 9: sent the final model to clients ####################################
2023-03-21 01:28:21,122 : [INFO]  Batch number 9 model fetched from the server
2023-03-21 01:28:21,123 : [INFO]  ################ Batch 9: final global model evalution after 2 rounds ################
2023-03-21 01:28:21,123 : [INFO]  Batch 9: Training set : loss - 0.55, accuracy - 0.8, recall - 0.96, AUC - 0.91, F1 - 0.83, precision - 0.73, training time - -3.0 seconds
2023-03-21 01:28:21,123 : [INFO]  Batch 9: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.93, AUC - 0.85, F1 - 0.78, precision - 0.66
2023-03-21 01:28:21,189 : [INFO]  Batch 10 initialized 
2023-03-21 01:28:21,522 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:28:21,717 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-21 01:28:23,625 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:23,627 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:23,627 : [INFO]  Batch 10, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:23,627 : [INFO]  ____________________________________ Batch 10: round 1 finished ____________________________________
2023-03-21 01:28:23,628 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-21 01:28:24,171 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-21 01:28:24,173 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:24,174 : [INFO]  Batch 10, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:24,174 : [INFO]  ____________________________________ Batch 10: round 2 finished ____________________________________
2023-03-21 01:28:24,174 : [INFO]  #################################### Batch 10: sent the final model to clients ####################################
2023-03-21 01:28:25,050 : [INFO]  Batch number 10 model fetched from the server
2023-03-21 01:28:25,051 : [INFO]  ################ Batch 10: final global model evalution after 2 rounds ################
2023-03-21 01:28:25,051 : [INFO]  Batch 10: Training set : loss - 0.54, accuracy - 0.77, recall - 0.97, AUC - 0.92, F1 - 0.81, precision - 0.69, training time - -2.0 seconds
2023-03-21 01:28:25,051 : [INFO]  Batch 10: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.92, AUC - 0.82, F1 - 0.76, precision - 0.64
2023-03-21 01:28:25,134 : [INFO]  Batch 11 initialized 
2023-03-21 01:28:25,470 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:28:25,664 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-21 01:28:27,727 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:27,729 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:27,730 : [INFO]  Batch 11, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:27,730 : [INFO]  ____________________________________ Batch 11: round 1 finished ____________________________________
2023-03-21 01:28:27,731 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-21 01:28:28,282 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-21 01:28:28,284 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:28,285 : [INFO]  Batch 11, round 2: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:28,285 : [INFO]  ____________________________________ Batch 11: round 2 finished ____________________________________
2023-03-21 01:28:28,285 : [INFO]  #################################### Batch 11: sent the final model to clients ####################################
2023-03-21 01:28:29,165 : [INFO]  Batch number 11 model fetched from the server
2023-03-21 01:28:29,165 : [INFO]  ################ Batch 11: final global model evalution after 2 rounds ################
2023-03-21 01:28:29,165 : [INFO]  Batch 11: Training set : loss - 0.55, accuracy - 0.78, recall - 0.97, AUC - 0.9, F1 - 0.82, precision - 0.71, training time - -3.0 seconds
2023-03-21 01:28:29,165 : [INFO]  Batch 11: Testing set : loss - 0.59, accuracy - 0.72, recall - 0.95, AUC - 0.85, F1 - 0.77, precision - 0.65
2023-03-21 01:28:29,226 : [INFO]  Batch 12 initialized 
2023-03-21 01:28:29,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:28:29,837 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-21 01:28:31,978 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-21 01:28:31,980 : [INFO]  Batch 12: recieved model from client-0 at 127.0.0.1:58014
2023-03-21 01:28:31,981 : [INFO]  Batch 12, round 1: aggregated global model sent to client-0 at 127.0.0.1:58014
2023-03-21 01:28:31,981 : [INFO]  ____________________________________ Batch 12: round 1 finished ____________________________________
2023-03-21 01:28:31,982 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-21 01:28:32,356 : [ERROR]  Client-0 closed connection at 127.0.0.1:58014
2023-03-21 01:31:05,259 : [WARNING]  ####################################### New Training Session #######################################
2023-03-21 01:31:05,259 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 2, number of timestamps 101
2023-03-21 01:31:06,347 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-21 01:31:06,347 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-21 01:31:07,762 : [INFO]  Model initialized for training
2023-03-21 01:31:18,989 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:31:19,190 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:31:20,048 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:31:20,180 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-21 01:31:20,180 : [INFO]  Connected to the server
2023-03-21 01:31:20,180 : [INFO]  Accepted new connection at 127.0.0.1:46600
2023-03-21 01:31:20,181 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:46600
2023-03-21 01:31:20,267 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:31:20,280 : [INFO]  ################################## Initial model training started ##################################
2023-03-21 01:31:20,280 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-21 01:31:52,787 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-21 01:31:52,789 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:46600
2023-03-21 01:31:52,789 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:46600
2023-03-21 01:31:52,789 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-21 01:31:52,791 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-21 01:32:24,003 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-21 01:32:24,005 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:46600
2023-03-21 01:32:24,005 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:46600
2023-03-21 01:32:24,005 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-21 01:32:24,005 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-21 01:32:24,007 : [INFO]  ################ Initial trained model: Final global model evalution after 2 rounds ################
2023-03-21 01:32:57,766 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.72, recall - 0.91, AUC - 0.84, F1 - 0.77, precision - 0.66, training time - -64.0 seconds
2023-03-21 01:32:57,766 : [INFO]  Initially trained model: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.91, AUC - 0.81, F1 - 0.75, precision - 0.64
2023-03-21 01:32:57,820 : [INFO]  Batch 1 initialized 
2023-03-21 01:32:58,195 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:32:58,312 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-21 01:32:58,312 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-21 01:33:00,887 : [ERROR]  Client-0 closed connection at 127.0.0.1:46600
2023-03-21 01:33:06,258 : [WARNING]  ####################################### New Training Session #######################################
2023-03-21 01:33:06,258 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 2, number of timestamps 101
2023-03-21 01:33:07,675 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-21 01:33:07,676 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-21 01:33:09,661 : [INFO]  Model initialized for training
2023-03-21 01:33:24,555 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:33:24,877 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:33:26,328 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:33:26,477 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-21 01:33:26,477 : [INFO]  Connected to the server
2023-03-21 01:33:26,477 : [INFO]  Accepted new connection at 127.0.0.1:54348
2023-03-21 01:33:26,478 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:54348
2023-03-21 01:33:26,570 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:33:26,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:33:26,577 : [INFO]  ################################## Initial model training started ##################################
2023-03-21 01:33:26,578 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-21 01:34:13,570 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-21 01:34:13,573 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:54348
2023-03-21 01:34:13,573 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:54348
2023-03-21 01:34:13,573 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-21 01:34:13,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:34:13,575 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-21 01:34:50,593 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-21 01:34:50,595 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:54348
2023-03-21 01:34:50,596 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:54348
2023-03-21 01:34:50,596 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:34:50,596 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-21 01:34:50,596 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-21 01:34:50,597 : [INFO]  ################ Initial trained model: Final global model evalution after 2 rounds ################
2023-03-21 01:35:22,041 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.72, recall - 0.91, AUC - 0.84, F1 - 0.77, precision - 0.66, training time - -84.0 seconds
2023-03-21 01:35:22,041 : [INFO]  Initially trained model: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.91, AUC - 0.81, F1 - 0.75, precision - 0.64
2023-03-21 01:35:22,094 : [INFO]  Batch 1 initialized 
2023-03-21 01:35:22,566 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:35:22,684 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-21 01:35:22,684 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-21 01:35:24,655 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-21 01:35:24,657 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:54348
2023-03-21 01:35:24,657 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:54348
2023-03-21 01:35:24,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:35:24,657 : [INFO]  ____________________________________ Batch 1: round 1 finished ____________________________________
2023-03-21 01:35:24,659 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-21 01:35:25,227 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-21 01:35:25,229 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:54348
2023-03-21 01:35:25,229 : [INFO]  Batch 1, round 2: aggregated global model sent to client-0 at 127.0.0.1:54348
2023-03-21 01:35:25,230 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:35:25,230 : [INFO]  ____________________________________ Batch 1: round 2 finished ____________________________________
2023-03-21 01:35:25,230 : [INFO]  #################################### Batch 1: sent the final model to clients ####################################
2023-03-21 01:35:25,231 : [INFO]  Batch number 1 model fetched from the server
2023-03-21 01:35:25,231 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-21 01:35:26,168 : [INFO]  Batch 1: Training set : loss - 0.58, accuracy - 0.72, recall - 0.92, AUC - 0.84, F1 - 0.77, precision - 0.66, training time - -3.0 seconds
2023-03-21 01:35:26,168 : [INFO]  Batch 1: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.66
2023-03-21 01:35:26,220 : [INFO]  Batch 2 initialized 
2023-03-21 01:35:26,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:35:26,738 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-21 01:35:28,619 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-21 01:35:28,621 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:54348
2023-03-21 01:35:28,622 : [INFO]  Batch 2, round 1: aggregated global model sent to client-0 at 127.0.0.1:54348
2023-03-21 01:35:28,622 : [INFO]  ____________________________________ Batch 2: round 1 finished ____________________________________
2023-03-21 01:35:28,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:35:28,623 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-21 01:35:29,171 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-21 01:35:29,173 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:54348
2023-03-21 01:35:29,173 : [INFO]  Batch 2, round 2: aggregated global model sent to client-0 at 127.0.0.1:54348
2023-03-21 01:35:29,173 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:35:29,173 : [INFO]  ____________________________________ Batch 2: round 2 finished ____________________________________
2023-03-21 01:35:29,174 : [INFO]  #################################### Batch 2: sent the final model to clients ####################################
2023-03-21 01:35:29,175 : [INFO]  Batch number 2 model fetched from the server
2023-03-21 01:35:29,175 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-21 01:35:30,122 : [INFO]  Batch 2: Training set : loss - 0.56, accuracy - 0.78, recall - 0.96, AUC - 0.87, F1 - 0.81, precision - 0.7, training time - -2.0 seconds
2023-03-21 01:35:30,122 : [INFO]  Batch 2: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.94, AUC - 0.85, F1 - 0.78, precision - 0.66
2023-03-21 01:35:30,175 : [INFO]  Batch 3 initialized 
2023-03-21 01:35:30,535 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:35:30,711 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-21 01:35:32,675 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-21 01:35:32,678 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:54348
2023-03-21 01:35:32,678 : [INFO]  Batch 3, round 1: aggregated global model sent to client-0 at 127.0.0.1:54348
2023-03-21 01:35:32,678 : [INFO]  ____________________________________ Batch 3: round 1 finished ____________________________________
2023-03-21 01:35:32,678 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:35:32,680 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-21 01:35:33,433 : [ERROR]  Client-0 closed connection at 127.0.0.1:54348
2023-03-21 01:36:07,152 : [WARNING]  ####################################### New Training Session #######################################
2023-03-21 01:36:07,152 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 2, number of timestamps 101
2023-03-21 01:36:08,286 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-21 01:36:08,286 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 2, epochs 2
2023-03-21 01:36:09,748 : [INFO]  Model initialized for training
2023-03-21 01:36:21,914 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:36:22,120 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:36:23,118 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:36:23,250 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-21 01:36:23,251 : [INFO]  Connected to the server
2023-03-21 01:36:23,251 : [INFO]  Accepted new connection at 127.0.0.1:57672
2023-03-21 01:36:23,251 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:57672
2023-03-21 01:36:23,338 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:36:23,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:36:23,345 : [INFO]  ################################## Initial model training started ##################################
2023-03-21 01:36:23,346 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-21 01:37:04,008 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-21 01:37:04,011 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:57672
2023-03-21 01:37:04,011 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:57672
2023-03-21 01:37:04,011 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-21 01:37:04,011 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:37:04,013 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-21 01:37:39,061 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-21 01:37:39,064 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:57672
2023-03-21 01:37:39,064 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:57672
2023-03-21 01:37:39,064 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-21 01:37:39,064 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:37:39,064 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-21 01:37:39,066 : [INFO]  ################ Initial trained model: Final global model evalution after 2 rounds ################
2023-03-21 01:38:09,567 : [INFO]  Initially trained model: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.91, AUC - 0.81, F1 - 0.7536599248408582, precision - 0.64
2023-03-21 01:38:09,617 : [INFO]  Batch 1 initialized 
2023-03-21 01:38:09,983 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:38:10,098 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-21 01:38:10,098 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-21 01:38:12,067 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-21 01:38:12,070 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:57672
2023-03-21 01:38:12,070 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:57672
2023-03-21 01:38:12,070 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:38:12,070 : [INFO]  ____________________________________ Batch 1: round 1 finished ____________________________________
2023-03-21 01:38:12,072 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-21 01:38:12,647 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-21 01:38:12,650 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:57672
2023-03-21 01:38:12,650 : [INFO]  Batch 1, round 2: aggregated global model sent to client-0 at 127.0.0.1:57672
2023-03-21 01:38:12,650 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:38:12,650 : [INFO]  ____________________________________ Batch 1: round 2 finished ____________________________________
2023-03-21 01:38:12,650 : [INFO]  #################################### Batch 1: sent the final model to clients ####################################
2023-03-21 01:38:12,652 : [INFO]  Batch number 1 model fetched from the server
2023-03-21 01:38:12,652 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-21 01:38:13,698 : [INFO]  Batch 2 initialized 
2023-03-21 01:38:14,480 : [ERROR]  Client-0 closed connection at 127.0.0.1:57672
2023-03-21 01:42:20,539 : [WARNING]  ####################################### New Training Session #######################################
2023-03-21 01:42:20,539 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 1, number of timestamps 101
2023-03-21 01:42:21,134 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-21 01:42:21,134 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 1, epochs 2
2023-03-21 01:42:22,579 : [INFO]  Model initialized for training
2023-03-21 01:42:34,440 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:42:34,667 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:42:35,156 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:42:35,288 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-21 01:42:35,289 : [INFO]  Connected to the server
2023-03-21 01:42:35,289 : [INFO]  Accepted new connection at 127.0.0.1:53366
2023-03-21 01:42:35,289 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:53366
2023-03-21 01:42:35,381 : [INFO]  Distributed training for streaming graphs started!
2023-03-21 01:42:35,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:42:35,388 : [INFO]  ################################## Initial model training started ##################################
2023-03-21 01:42:35,388 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-21 01:42:52,997 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-21 01:42:52,999 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:42:53,000 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:42:53,000 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:42:53,000 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-21 01:42:53,000 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-21 01:42:53,001 : [INFO]  ################ Initial trained model: Final global model evalution after 1 rounds ################
2023-03-21 01:43:21,431 : [INFO]  Initially trained model: Training set : loss - 0.62, accuracy - 0.67, recall - 0.84, AUC - 0.76, F1 - 0.72, precision - 0.63, training time - -18.0 seconds
2023-03-21 01:43:21,431 : [INFO]  Initially trained model: Testing set : loss - 0.63, accuracy - 0.65, recall - 0.83, AUC - 0.74, F1 - 0.7, precision - 0.61
2023-03-21 01:43:21,479 : [INFO]  Batch 1 initialized 
2023-03-21 01:43:21,817 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:21,928 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-21 01:43:21,928 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-21 01:43:23,843 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:23,845 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:23,845 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:23,845 : [INFO]  ____________________________________ Batch 1: round 1 finished ____________________________________
2023-03-21 01:43:23,845 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:23,845 : [INFO]  #################################### Batch 1: sent the final model to clients ####################################
2023-03-21 01:43:23,847 : [INFO]  Batch number 1 model fetched from the server
2023-03-21 01:43:23,847 : [INFO]  ################ Batch 1: final global model evalution after 1 rounds ################
2023-03-21 01:43:24,732 : [INFO]  Batch 1: Training set : loss - 0.6, accuracy - 0.67, recall - 0.89, AUC - 0.82, F1 - 0.73, precision - 0.62, training time - -2.0 seconds
2023-03-21 01:43:24,732 : [INFO]  Batch 1: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.84, AUC - 0.81, F1 - 0.72, precision - 0.63
2023-03-21 01:43:24,781 : [INFO]  Batch 2 initialized 
2023-03-21 01:43:25,117 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:25,291 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-21 01:43:27,426 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:27,428 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:27,429 : [INFO]  Batch 2, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:27,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:27,429 : [INFO]  ____________________________________ Batch 2: round 1 finished ____________________________________
2023-03-21 01:43:27,429 : [INFO]  #################################### Batch 2: sent the final model to clients ####################################
2023-03-21 01:43:27,431 : [INFO]  Batch number 2 model fetched from the server
2023-03-21 01:43:27,431 : [INFO]  ################ Batch 2: final global model evalution after 1 rounds ################
2023-03-21 01:43:28,344 : [INFO]  Batch 2: Training set : loss - 0.59, accuracy - 0.73, recall - 0.9, AUC - 0.82, F1 - 0.77, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:43:28,344 : [INFO]  Batch 2: Testing set : loss - 0.6, accuracy - 0.71, recall - 0.89, AUC - 0.82, F1 - 0.75, precision - 0.65
2023-03-21 01:43:28,394 : [INFO]  Batch 3 initialized 
2023-03-21 01:43:28,737 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:28,916 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-21 01:43:30,826 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:30,828 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:30,829 : [INFO]  Batch 3, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:30,829 : [INFO]  ____________________________________ Batch 3: round 1 finished ____________________________________
2023-03-21 01:43:30,829 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:30,829 : [INFO]  #################################### Batch 3: sent the final model to clients ####################################
2023-03-21 01:43:30,830 : [INFO]  Batch number 3 model fetched from the server
2023-03-21 01:43:30,831 : [INFO]  ################ Batch 3: final global model evalution after 1 rounds ################
2023-03-21 01:43:31,726 : [INFO]  Batch 3: Training set : loss - 0.58, accuracy - 0.7, recall - 0.89, AUC - 0.84, F1 - 0.75, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:43:31,726 : [INFO]  Batch 3: Testing set : loss - 0.6, accuracy - 0.69, recall - 0.91, AUC - 0.8, F1 - 0.75, precision - 0.63
2023-03-21 01:43:31,780 : [INFO]  Batch 4 initialized 
2023-03-21 01:43:32,116 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:32,284 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-21 01:43:34,247 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:34,250 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:34,250 : [INFO]  Batch 4, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:34,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:34,250 : [INFO]  ____________________________________ Batch 4: round 1 finished ____________________________________
2023-03-21 01:43:34,250 : [INFO]  #################################### Batch 4: sent the final model to clients ####################################
2023-03-21 01:43:34,252 : [INFO]  Batch number 4 model fetched from the server
2023-03-21 01:43:34,252 : [INFO]  ################ Batch 4: final global model evalution after 1 rounds ################
2023-03-21 01:43:35,108 : [INFO]  Batch 4: Training set : loss - 0.57, accuracy - 0.76, recall - 0.93, AUC - 0.86, F1 - 0.8, precision - 0.69, training time - -2.0 seconds
2023-03-21 01:43:35,108 : [INFO]  Batch 4: Testing set : loss - 0.6, accuracy - 0.72, recall - 0.91, AUC - 0.81, F1 - 0.77, precision - 0.66
2023-03-21 01:43:35,154 : [INFO]  Batch 5 initialized 
2023-03-21 01:43:35,484 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:35,656 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-21 01:43:37,548 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:37,550 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:37,551 : [INFO]  Batch 5, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:37,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:37,551 : [INFO]  ____________________________________ Batch 5: round 1 finished ____________________________________
2023-03-21 01:43:37,551 : [INFO]  #################################### Batch 5: sent the final model to clients ####################################
2023-03-21 01:43:37,552 : [INFO]  Batch number 5 model fetched from the server
2023-03-21 01:43:37,552 : [INFO]  ################ Batch 5: final global model evalution after 1 rounds ################
2023-03-21 01:43:38,401 : [INFO]  Batch 5: Training set : loss - 0.58, accuracy - 0.72, recall - 0.91, AUC - 0.85, F1 - 0.76, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:43:38,401 : [INFO]  Batch 5: Testing set : loss - 0.6, accuracy - 0.71, recall - 0.89, AUC - 0.8, F1 - 0.76, precision - 0.65
2023-03-21 01:43:38,449 : [INFO]  Batch 6 initialized 
2023-03-21 01:43:38,778 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:38,952 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-21 01:43:40,885 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:40,888 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:40,888 : [INFO]  Batch 6, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:40,888 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:40,888 : [INFO]  ____________________________________ Batch 6: round 1 finished ____________________________________
2023-03-21 01:43:40,888 : [INFO]  #################################### Batch 6: sent the final model to clients ####################################
2023-03-21 01:43:40,890 : [INFO]  Batch number 6 model fetched from the server
2023-03-21 01:43:40,890 : [INFO]  ################ Batch 6: final global model evalution after 1 rounds ################
2023-03-21 01:43:41,962 : [INFO]  Batch 6: Training set : loss - 0.6, accuracy - 0.71, recall - 0.89, AUC - 0.81, F1 - 0.75, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:43:41,962 : [INFO]  Batch 6: Testing set : loss - 0.62, accuracy - 0.68, recall - 0.9, AUC - 0.77, F1 - 0.74, precision - 0.62
2023-03-21 01:43:42,015 : [INFO]  Batch 7 initialized 
2023-03-21 01:43:42,351 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:42,525 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-21 01:43:44,493 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:44,495 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:44,496 : [INFO]  Batch 7, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:44,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:44,496 : [INFO]  ____________________________________ Batch 7: round 1 finished ____________________________________
2023-03-21 01:43:44,496 : [INFO]  #################################### Batch 7: sent the final model to clients ####################################
2023-03-21 01:43:44,497 : [INFO]  Batch number 7 model fetched from the server
2023-03-21 01:43:44,497 : [INFO]  ################ Batch 7: final global model evalution after 1 rounds ################
2023-03-21 01:43:45,354 : [INFO]  Batch 7: Training set : loss - 0.6, accuracy - 0.69, recall - 0.93, AUC - 0.81, F1 - 0.75, precision - 0.63, training time - -2.0 seconds
2023-03-21 01:43:45,354 : [INFO]  Batch 7: Testing set : loss - 0.6, accuracy - 0.72, recall - 0.95, AUC - 0.83, F1 - 0.77, precision - 0.65
2023-03-21 01:43:45,398 : [INFO]  Batch 8 initialized 
2023-03-21 01:43:45,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:45,957 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-21 01:43:48,034 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:48,037 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:48,037 : [INFO]  Batch 8, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:48,037 : [INFO]  ____________________________________ Batch 8: round 1 finished ____________________________________
2023-03-21 01:43:48,037 : [INFO]  #################################### Batch 8: sent the final model to clients ####################################
2023-03-21 01:43:48,037 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:48,040 : [INFO]  Batch number 8 model fetched from the server
2023-03-21 01:43:48,040 : [INFO]  ################ Batch 8: final global model evalution after 1 rounds ################
2023-03-21 01:43:49,071 : [INFO]  Batch 8: Training set : loss - 0.57, accuracy - 0.74, recall - 0.97, AUC - 0.89, F1 - 0.79, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:43:49,072 : [INFO]  Batch 8: Testing set : loss - 0.62, accuracy - 0.67, recall - 0.92, AUC - 0.79, F1 - 0.73, precision - 0.61
2023-03-21 01:43:49,130 : [INFO]  Batch 9 initialized 
2023-03-21 01:43:49,504 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:49,683 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-21 01:43:51,783 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:51,787 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:51,788 : [INFO]  Batch 9, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:51,788 : [INFO]  ____________________________________ Batch 9: round 1 finished ____________________________________
2023-03-21 01:43:51,788 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:51,788 : [INFO]  #################################### Batch 9: sent the final model to clients ####################################
2023-03-21 01:43:51,789 : [INFO]  Batch number 9 model fetched from the server
2023-03-21 01:43:51,789 : [INFO]  ################ Batch 9: final global model evalution after 1 rounds ################
2023-03-21 01:43:52,797 : [INFO]  Batch 9: Training set : loss - 0.58, accuracy - 0.74, recall - 0.98, AUC - 0.88, F1 - 0.79, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:43:52,797 : [INFO]  Batch 9: Testing set : loss - 0.6, accuracy - 0.73, recall - 0.91, AUC - 0.82, F1 - 0.77, precision - 0.67
2023-03-21 01:43:52,846 : [INFO]  Batch 10 initialized 
2023-03-21 01:43:53,234 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:53,462 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-21 01:43:55,592 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:55,595 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:55,595 : [INFO]  Batch 10, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:55,595 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:55,595 : [INFO]  ____________________________________ Batch 10: round 1 finished ____________________________________
2023-03-21 01:43:55,595 : [INFO]  #################################### Batch 10: sent the final model to clients ####################################
2023-03-21 01:43:55,597 : [INFO]  Batch number 10 model fetched from the server
2023-03-21 01:43:55,597 : [INFO]  ################ Batch 10: final global model evalution after 1 rounds ################
2023-03-21 01:43:56,513 : [INFO]  Batch 10: Training set : loss - 0.57, accuracy - 0.75, recall - 0.98, AUC - 0.88, F1 - 0.8, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:43:56,513 : [INFO]  Batch 10: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.9, AUC - 0.8, F1 - 0.74, precision - 0.62
2023-03-21 01:43:56,564 : [INFO]  Batch 11 initialized 
2023-03-21 01:43:56,909 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:43:57,092 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-21 01:43:59,167 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-21 01:43:59,169 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:43:59,170 : [INFO]  Batch 11, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:43:59,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:43:59,170 : [INFO]  ____________________________________ Batch 11: round 1 finished ____________________________________
2023-03-21 01:43:59,170 : [INFO]  #################################### Batch 11: sent the final model to clients ####################################
2023-03-21 01:43:59,171 : [INFO]  Batch number 11 model fetched from the server
2023-03-21 01:43:59,171 : [INFO]  ################ Batch 11: final global model evalution after 1 rounds ################
2023-03-21 01:44:00,116 : [INFO]  Batch 11: Training set : loss - 0.58, accuracy - 0.73, recall - 0.92, AUC - 0.87, F1 - 0.78, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:44:00,116 : [INFO]  Batch 11: Testing set : loss - 0.6, accuracy - 0.67, recall - 0.89, AUC - 0.82, F1 - 0.73, precision - 0.62
2023-03-21 01:44:00,157 : [INFO]  Batch 12 initialized 
2023-03-21 01:44:00,545 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:00,755 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-21 01:44:02,863 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:02,868 : [INFO]  Batch 12: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:02,868 : [INFO]  Batch 12, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:02,868 : [INFO]  ____________________________________ Batch 12: round 1 finished ____________________________________
2023-03-21 01:44:02,868 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:02,868 : [INFO]  #################################### Batch 12: sent the final model to clients ####################################
2023-03-21 01:44:02,870 : [INFO]  Batch number 12 model fetched from the server
2023-03-21 01:44:02,870 : [INFO]  ################ Batch 12: final global model evalution after 1 rounds ################
2023-03-21 01:44:03,875 : [INFO]  Batch 12: Training set : loss - 0.6, accuracy - 0.7, recall - 0.87, AUC - 0.81, F1 - 0.74, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:44:03,875 : [INFO]  Batch 12: Testing set : loss - 0.62, accuracy - 0.66, recall - 0.91, AUC - 0.77, F1 - 0.73, precision - 0.6
2023-03-21 01:44:03,943 : [INFO]  Batch 13 initialized 
2023-03-21 01:44:04,284 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:04,472 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-21 01:44:06,525 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:06,527 : [INFO]  Batch 13: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:06,528 : [INFO]  Batch 13, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:06,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:06,528 : [INFO]  ____________________________________ Batch 13: round 1 finished ____________________________________
2023-03-21 01:44:06,528 : [INFO]  #################################### Batch 13: sent the final model to clients ####################################
2023-03-21 01:44:06,529 : [INFO]  Batch number 13 model fetched from the server
2023-03-21 01:44:06,529 : [INFO]  ################ Batch 13: final global model evalution after 1 rounds ################
2023-03-21 01:44:07,479 : [INFO]  Batch 13: Training set : loss - 0.58, accuracy - 0.72, recall - 0.93, AUC - 0.87, F1 - 0.77, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:44:07,479 : [INFO]  Batch 13: Testing set : loss - 0.61, accuracy - 0.67, recall - 0.85, AUC - 0.78, F1 - 0.72, precision - 0.62
2023-03-21 01:44:07,544 : [INFO]  Batch 14 initialized 
2023-03-21 01:44:07,920 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:08,124 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-21 01:44:10,112 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:10,115 : [INFO]  Batch 14: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:10,115 : [INFO]  Batch 14, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:10,115 : [INFO]  ____________________________________ Batch 14: round 1 finished ____________________________________
2023-03-21 01:44:10,115 : [INFO]  #################################### Batch 14: sent the final model to clients ####################################
2023-03-21 01:44:10,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:10,117 : [INFO]  Batch number 14 model fetched from the server
2023-03-21 01:44:10,117 : [INFO]  ################ Batch 14: final global model evalution after 1 rounds ################
2023-03-21 01:44:11,106 : [INFO]  Batch 14: Training set : loss - 0.57, accuracy - 0.72, recall - 0.95, AUC - 0.88, F1 - 0.77, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:44:11,106 : [INFO]  Batch 14: Testing set : loss - 0.59, accuracy - 0.71, recall - 0.9, AUC - 0.83, F1 - 0.76, precision - 0.65
2023-03-21 01:44:11,228 : [INFO]  Batch 15 initialized 
2023-03-21 01:44:11,711 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:11,929 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-21 01:44:14,635 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:14,638 : [INFO]  Batch 15: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:14,638 : [INFO]  Batch 15, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:14,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:14,638 : [INFO]  ____________________________________ Batch 15: round 1 finished ____________________________________
2023-03-21 01:44:14,638 : [INFO]  #################################### Batch 15: sent the final model to clients ####################################
2023-03-21 01:44:14,640 : [INFO]  Batch number 15 model fetched from the server
2023-03-21 01:44:14,640 : [INFO]  ################ Batch 15: final global model evalution after 1 rounds ################
2023-03-21 01:44:15,621 : [INFO]  Batch 15: Training set : loss - 0.57, accuracy - 0.77, recall - 0.95, AUC - 0.86, F1 - 0.8, precision - 0.7, training time - -3.0 seconds
2023-03-21 01:44:15,621 : [INFO]  Batch 15: Testing set : loss - 0.64, accuracy - 0.64, recall - 0.89, AUC - 0.74, F1 - 0.71, precision - 0.59
2023-03-21 01:44:15,713 : [INFO]  Batch 16 initialized 
2023-03-21 01:44:16,056 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:16,255 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-21 01:44:18,698 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:18,701 : [INFO]  Batch 16: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:18,701 : [INFO]  Batch 16, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:18,701 : [INFO]  ____________________________________ Batch 16: round 1 finished ____________________________________
2023-03-21 01:44:18,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:18,701 : [INFO]  #################################### Batch 16: sent the final model to clients ####################################
2023-03-21 01:44:18,703 : [INFO]  Batch number 16 model fetched from the server
2023-03-21 01:44:18,703 : [INFO]  ################ Batch 16: final global model evalution after 1 rounds ################
2023-03-21 01:44:20,072 : [INFO]  Batch 16: Training set : loss - 0.56, accuracy - 0.76, recall - 0.97, AUC - 0.89, F1 - 0.8, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:44:20,073 : [INFO]  Batch 16: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.91, AUC - 0.84, F1 - 0.75, precision - 0.64
2023-03-21 01:44:20,183 : [INFO]  Batch 17 initialized 
2023-03-21 01:44:20,642 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:20,872 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-21 01:44:22,981 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:22,983 : [INFO]  Batch 17: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:22,984 : [INFO]  Batch 17, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:22,984 : [INFO]  ____________________________________ Batch 17: round 1 finished ____________________________________
2023-03-21 01:44:22,984 : [INFO]  #################################### Batch 17: sent the final model to clients ####################################
2023-03-21 01:44:22,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:22,985 : [INFO]  Batch number 17 model fetched from the server
2023-03-21 01:44:22,985 : [INFO]  ################ Batch 17: final global model evalution after 1 rounds ################
2023-03-21 01:44:23,997 : [INFO]  Batch 17: Training set : loss - 0.56, accuracy - 0.76, recall - 0.91, AUC - 0.87, F1 - 0.79, precision - 0.7, training time - -2.0 seconds
2023-03-21 01:44:23,997 : [INFO]  Batch 17: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.93, AUC - 0.85, F1 - 0.75, precision - 0.63
2023-03-21 01:44:24,117 : [INFO]  Batch 18 initialized 
2023-03-21 01:44:24,984 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:25,263 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-21 01:44:29,181 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:29,184 : [INFO]  Batch 18: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:29,185 : [INFO]  Batch 18, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:29,185 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:29,185 : [INFO]  ____________________________________ Batch 18: round 1 finished ____________________________________
2023-03-21 01:44:29,185 : [INFO]  #################################### Batch 18: sent the final model to clients ####################################
2023-03-21 01:44:29,187 : [INFO]  Batch number 18 model fetched from the server
2023-03-21 01:44:29,187 : [INFO]  ################ Batch 18: final global model evalution after 1 rounds ################
2023-03-21 01:44:30,186 : [INFO]  Batch 18: Training set : loss - 0.57, accuracy - 0.75, recall - 0.96, AUC - 0.87, F1 - 0.79, precision - 0.68, training time - -4.0 seconds
2023-03-21 01:44:30,186 : [INFO]  Batch 18: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.95, AUC - 0.85, F1 - 0.76, precision - 0.64
2023-03-21 01:44:30,242 : [INFO]  Batch 19 initialized 
2023-03-21 01:44:30,684 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:30,915 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-21 01:44:34,824 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:34,829 : [INFO]  Batch 19: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:34,829 : [INFO]  Batch 19, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:34,830 : [INFO]  ____________________________________ Batch 19: round 1 finished ____________________________________
2023-03-21 01:44:34,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:34,830 : [INFO]  #################################### Batch 19: sent the final model to clients ####################################
2023-03-21 01:44:34,833 : [INFO]  Batch number 19 model fetched from the server
2023-03-21 01:44:34,833 : [INFO]  ################ Batch 19: final global model evalution after 1 rounds ################
2023-03-21 01:44:36,176 : [INFO]  Batch 19: Training set : loss - 0.61, accuracy - 0.72, recall - 0.96, AUC - 0.8, F1 - 0.78, precision - 0.65, training time - -4.0 seconds
2023-03-21 01:44:36,176 : [INFO]  Batch 19: Testing set : loss - 0.64, accuracy - 0.64, recall - 0.9, AUC - 0.74, F1 - 0.72, precision - 0.59
2023-03-21 01:44:36,287 : [INFO]  Batch 20 initialized 
2023-03-21 01:44:36,847 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:37,075 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-21 01:44:39,900 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:39,904 : [INFO]  Batch 20: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:39,905 : [INFO]  Batch 20, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:39,905 : [INFO]  ____________________________________ Batch 20: round 1 finished ____________________________________
2023-03-21 01:44:39,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:39,905 : [INFO]  #################################### Batch 20: sent the final model to clients ####################################
2023-03-21 01:44:39,908 : [INFO]  Batch number 20 model fetched from the server
2023-03-21 01:44:39,908 : [INFO]  ################ Batch 20: final global model evalution after 1 rounds ################
2023-03-21 01:44:41,639 : [INFO]  Batch 20: Training set : loss - 0.57, accuracy - 0.71, recall - 0.95, AUC - 0.89, F1 - 0.76, precision - 0.64, training time - -3.0 seconds
2023-03-21 01:44:41,640 : [INFO]  Batch 20: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.89, AUC - 0.81, F1 - 0.75, precision - 0.65
2023-03-21 01:44:41,753 : [INFO]  Batch 21 initialized 
2023-03-21 01:44:42,252 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:42,457 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-21 01:44:44,419 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:44,422 : [INFO]  Batch 21: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:44,422 : [INFO]  Batch 21, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:44,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:44,422 : [INFO]  ____________________________________ Batch 21: round 1 finished ____________________________________
2023-03-21 01:44:44,422 : [INFO]  #################################### Batch 21: sent the final model to clients ####################################
2023-03-21 01:44:44,424 : [INFO]  Batch number 21 model fetched from the server
2023-03-21 01:44:44,424 : [INFO]  ################ Batch 21: final global model evalution after 1 rounds ################
2023-03-21 01:44:45,389 : [INFO]  Batch 21: Training set : loss - 0.58, accuracy - 0.72, recall - 0.92, AUC - 0.84, F1 - 0.77, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:44:45,389 : [INFO]  Batch 21: Testing set : loss - 0.61, accuracy - 0.68, recall - 0.88, AUC - 0.79, F1 - 0.73, precision - 0.63
2023-03-21 01:44:45,472 : [INFO]  Batch 22 initialized 
2023-03-21 01:44:45,807 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:46,016 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-21 01:44:47,949 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:47,951 : [INFO]  Batch 22: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:47,951 : [INFO]  Batch 22, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:47,951 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:47,951 : [INFO]  ____________________________________ Batch 22: round 1 finished ____________________________________
2023-03-21 01:44:47,951 : [INFO]  #################################### Batch 22: sent the final model to clients ####################################
2023-03-21 01:44:47,952 : [INFO]  Batch number 22 model fetched from the server
2023-03-21 01:44:47,952 : [INFO]  ################ Batch 22: final global model evalution after 1 rounds ################
2023-03-21 01:44:48,825 : [INFO]  Batch 22: Training set : loss - 0.58, accuracy - 0.75, recall - 0.93, AUC - 0.86, F1 - 0.79, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:44:48,825 : [INFO]  Batch 22: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.9, AUC - 0.83, F1 - 0.75, precision - 0.64
2023-03-21 01:44:48,893 : [INFO]  Batch 23 initialized 
2023-03-21 01:44:49,232 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:49,442 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-21 01:44:51,358 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:51,360 : [INFO]  Batch 23: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:51,361 : [INFO]  Batch 23, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:51,361 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:51,361 : [INFO]  ____________________________________ Batch 23: round 1 finished ____________________________________
2023-03-21 01:44:51,361 : [INFO]  #################################### Batch 23: sent the final model to clients ####################################
2023-03-21 01:44:51,362 : [INFO]  Batch number 23 model fetched from the server
2023-03-21 01:44:51,362 : [INFO]  ################ Batch 23: final global model evalution after 1 rounds ################
2023-03-21 01:44:52,717 : [INFO]  Batch 23: Training set : loss - 0.56, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.79, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:44:52,718 : [INFO]  Batch 23: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.89, AUC - 0.86, F1 - 0.75, precision - 0.65
2023-03-21 01:44:52,915 : [INFO]  Batch 24 initialized 
2023-03-21 01:44:53,881 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:54,167 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-21 01:44:56,983 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-21 01:44:56,985 : [INFO]  Batch 24: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:44:56,985 : [INFO]  Batch 24, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:44:56,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:44:56,985 : [INFO]  ____________________________________ Batch 24: round 1 finished ____________________________________
2023-03-21 01:44:56,985 : [INFO]  #################################### Batch 24: sent the final model to clients ####################################
2023-03-21 01:44:56,987 : [INFO]  Batch number 24 model fetched from the server
2023-03-21 01:44:56,987 : [INFO]  ################ Batch 24: final global model evalution after 1 rounds ################
2023-03-21 01:44:58,418 : [INFO]  Batch 24: Training set : loss - 0.55, accuracy - 0.77, recall - 0.91, AUC - 0.89, F1 - 0.8, precision - 0.71, training time - -3.0 seconds
2023-03-21 01:44:58,419 : [INFO]  Batch 24: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.92, AUC - 0.84, F1 - 0.75, precision - 0.64
2023-03-21 01:44:58,634 : [INFO]  Batch 25 initialized 
2023-03-21 01:44:59,311 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:44:59,588 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-21 01:45:03,364 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:03,367 : [INFO]  Batch 25: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:03,367 : [INFO]  Batch 25, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:03,367 : [INFO]  ____________________________________ Batch 25: round 1 finished ____________________________________
2023-03-21 01:45:03,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:03,367 : [INFO]  #################################### Batch 25: sent the final model to clients ####################################
2023-03-21 01:45:03,370 : [INFO]  Batch number 25 model fetched from the server
2023-03-21 01:45:03,370 : [INFO]  ################ Batch 25: final global model evalution after 1 rounds ################
2023-03-21 01:45:04,457 : [INFO]  Batch 25: Training set : loss - 0.59, accuracy - 0.68, recall - 0.89, AUC - 0.83, F1 - 0.74, precision - 0.63, training time - -4.0 seconds
2023-03-21 01:45:04,457 : [INFO]  Batch 25: Testing set : loss - 0.64, accuracy - 0.61, recall - 0.81, AUC - 0.72, F1 - 0.68, precision - 0.58
2023-03-21 01:45:04,530 : [INFO]  Batch 26 initialized 
2023-03-21 01:45:04,872 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:05,087 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-21 01:45:07,031 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:07,034 : [INFO]  Batch 26: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:07,034 : [INFO]  Batch 26, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:07,034 : [INFO]  ____________________________________ Batch 26: round 1 finished ____________________________________
2023-03-21 01:45:07,034 : [INFO]  #################################### Batch 26: sent the final model to clients ####################################
2023-03-21 01:45:07,034 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:07,036 : [INFO]  Batch number 26 model fetched from the server
2023-03-21 01:45:07,036 : [INFO]  ################ Batch 26: final global model evalution after 1 rounds ################
2023-03-21 01:45:07,922 : [INFO]  Batch 26: Training set : loss - 0.59, accuracy - 0.7, recall - 0.88, AUC - 0.82, F1 - 0.75, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:45:07,922 : [INFO]  Batch 26: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.89, AUC - 0.83, F1 - 0.75, precision - 0.65
2023-03-21 01:45:07,987 : [INFO]  Batch 27 initialized 
2023-03-21 01:45:08,336 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:08,548 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-21 01:45:10,462 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:10,464 : [INFO]  Batch 27: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:10,464 : [INFO]  Batch 27, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:10,464 : [INFO]  ____________________________________ Batch 27: round 1 finished ____________________________________
2023-03-21 01:45:10,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:10,464 : [INFO]  #################################### Batch 27: sent the final model to clients ####################################
2023-03-21 01:45:10,466 : [INFO]  Batch number 27 model fetched from the server
2023-03-21 01:45:10,466 : [INFO]  ################ Batch 27: final global model evalution after 1 rounds ################
2023-03-21 01:45:11,329 : [INFO]  Batch 27: Training set : loss - 0.57, accuracy - 0.71, recall - 0.97, AUC - 0.89, F1 - 0.77, precision - 0.64, training time - -2.0 seconds
2023-03-21 01:45:11,329 : [INFO]  Batch 27: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.93, AUC - 0.87, F1 - 0.76, precision - 0.64
2023-03-21 01:45:11,414 : [INFO]  Batch 28 initialized 
2023-03-21 01:45:11,761 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:11,986 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-21 01:45:14,097 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:14,099 : [INFO]  Batch 28: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:14,100 : [INFO]  Batch 28, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:14,100 : [INFO]  ____________________________________ Batch 28: round 1 finished ____________________________________
2023-03-21 01:45:14,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:14,100 : [INFO]  #################################### Batch 28: sent the final model to clients ####################################
2023-03-21 01:45:14,102 : [INFO]  Batch number 28 model fetched from the server
2023-03-21 01:45:14,102 : [INFO]  ################ Batch 28: final global model evalution after 1 rounds ################
2023-03-21 01:45:15,065 : [INFO]  Batch 28: Training set : loss - 0.6, accuracy - 0.71, recall - 0.92, AUC - 0.81, F1 - 0.76, precision - 0.64, training time - -2.0 seconds
2023-03-21 01:45:15,065 : [INFO]  Batch 28: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.96, AUC - 0.84, F1 - 0.76, precision - 0.63
2023-03-21 01:45:15,190 : [INFO]  Batch 29 initialized 
2023-03-21 01:45:15,533 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:15,765 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-21 01:45:18,311 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:18,317 : [INFO]  Batch 29: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:18,318 : [INFO]  Batch 29, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:18,318 : [INFO]  ____________________________________ Batch 29: round 1 finished ____________________________________
2023-03-21 01:45:18,318 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:18,318 : [INFO]  #################################### Batch 29: sent the final model to clients ####################################
2023-03-21 01:45:18,321 : [INFO]  Batch number 29 model fetched from the server
2023-03-21 01:45:18,322 : [INFO]  ################ Batch 29: final global model evalution after 1 rounds ################
2023-03-21 01:45:19,737 : [INFO]  Batch 29: Training set : loss - 0.61, accuracy - 0.72, recall - 0.9, AUC - 0.8, F1 - 0.76, precision - 0.66, training time - -3.0 seconds
2023-03-21 01:45:19,738 : [INFO]  Batch 29: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.93, AUC - 0.84, F1 - 0.75, precision - 0.63
2023-03-21 01:45:19,847 : [INFO]  Batch 30 initialized 
2023-03-21 01:45:20,192 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:20,427 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-21 01:45:22,875 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:22,877 : [INFO]  Batch 30: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:22,878 : [INFO]  Batch 30, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:22,878 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:22,878 : [INFO]  ____________________________________ Batch 30: round 1 finished ____________________________________
2023-03-21 01:45:22,878 : [INFO]  #################################### Batch 30: sent the final model to clients ####################################
2023-03-21 01:45:22,879 : [INFO]  Batch number 30 model fetched from the server
2023-03-21 01:45:22,879 : [INFO]  ################ Batch 30: final global model evalution after 1 rounds ################
2023-03-21 01:45:23,840 : [INFO]  Batch 30: Training set : loss - 0.57, accuracy - 0.76, recall - 0.96, AUC - 0.87, F1 - 0.8, precision - 0.69, training time - -2.0 seconds
2023-03-21 01:45:23,841 : [INFO]  Batch 30: Testing set : loss - 0.62, accuracy - 0.66, recall - 0.94, AUC - 0.8, F1 - 0.74, precision - 0.6
2023-03-21 01:45:23,900 : [INFO]  Batch 31 initialized 
2023-03-21 01:45:24,269 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:24,503 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-21 01:45:26,500 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:26,502 : [INFO]  Batch 31: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:26,503 : [INFO]  Batch 31, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:26,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:26,503 : [INFO]  ____________________________________ Batch 31: round 1 finished ____________________________________
2023-03-21 01:45:26,503 : [INFO]  #################################### Batch 31: sent the final model to clients ####################################
2023-03-21 01:45:26,504 : [INFO]  Batch number 31 model fetched from the server
2023-03-21 01:45:26,504 : [INFO]  ################ Batch 31: final global model evalution after 1 rounds ################
2023-03-21 01:45:27,439 : [INFO]  Batch 31: Training set : loss - 0.58, accuracy - 0.72, recall - 0.88, AUC - 0.83, F1 - 0.76, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:45:27,439 : [INFO]  Batch 31: Testing set : loss - 0.63, accuracy - 0.63, recall - 0.81, AUC - 0.73, F1 - 0.69, precision - 0.6
2023-03-21 01:45:27,497 : [INFO]  Batch 32 initialized 
2023-03-21 01:45:27,837 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:28,131 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-21 01:45:31,158 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:31,161 : [INFO]  Batch 32: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:31,162 : [INFO]  Batch 32, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:31,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:31,162 : [INFO]  ____________________________________ Batch 32: round 1 finished ____________________________________
2023-03-21 01:45:31,162 : [INFO]  #################################### Batch 32: sent the final model to clients ####################################
2023-03-21 01:45:31,164 : [INFO]  Batch number 32 model fetched from the server
2023-03-21 01:45:31,164 : [INFO]  ################ Batch 32: final global model evalution after 1 rounds ################
2023-03-21 01:45:32,726 : [INFO]  Batch 32: Training set : loss - 0.59, accuracy - 0.71, recall - 0.87, AUC - 0.81, F1 - 0.75, precision - 0.66, training time - -3.0 seconds
2023-03-21 01:45:32,726 : [INFO]  Batch 32: Testing set : loss - 0.62, accuracy - 0.66, recall - 0.92, AUC - 0.77, F1 - 0.73, precision - 0.61
2023-03-21 01:45:32,857 : [INFO]  Batch 33 initialized 
2023-03-21 01:45:33,418 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:33,652 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-21 01:45:35,805 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:35,807 : [INFO]  Batch 33: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:35,808 : [INFO]  Batch 33, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:35,808 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:35,808 : [INFO]  ____________________________________ Batch 33: round 1 finished ____________________________________
2023-03-21 01:45:35,808 : [INFO]  #################################### Batch 33: sent the final model to clients ####################################
2023-03-21 01:45:35,809 : [INFO]  Batch number 33 model fetched from the server
2023-03-21 01:45:35,809 : [INFO]  ################ Batch 33: final global model evalution after 1 rounds ################
2023-03-21 01:45:36,754 : [INFO]  Batch 33: Training set : loss - 0.58, accuracy - 0.71, recall - 0.91, AUC - 0.85, F1 - 0.76, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:45:36,754 : [INFO]  Batch 33: Testing set : loss - 0.61, accuracy - 0.67, recall - 0.95, AUC - 0.8, F1 - 0.74, precision - 0.61
2023-03-21 01:45:36,818 : [INFO]  Batch 34 initialized 
2023-03-21 01:45:37,191 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:37,425 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-21 01:45:39,516 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:39,519 : [INFO]  Batch 34: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:39,520 : [INFO]  Batch 34, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:39,520 : [INFO]  ____________________________________ Batch 34: round 1 finished ____________________________________
2023-03-21 01:45:39,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:39,520 : [INFO]  #################################### Batch 34: sent the final model to clients ####################################
2023-03-21 01:45:39,522 : [INFO]  Batch number 34 model fetched from the server
2023-03-21 01:45:39,522 : [INFO]  ################ Batch 34: final global model evalution after 1 rounds ################
2023-03-21 01:45:41,076 : [INFO]  Batch 34: Training set : loss - 0.6, accuracy - 0.72, recall - 0.96, AUC - 0.82, F1 - 0.77, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:45:41,076 : [INFO]  Batch 34: Testing set : loss - 0.61, accuracy - 0.65, recall - 0.91, AUC - 0.8, F1 - 0.72, precision - 0.6
2023-03-21 01:45:41,183 : [INFO]  Batch 35 initialized 
2023-03-21 01:45:41,650 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:41,986 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-21 01:45:45,453 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:45,457 : [INFO]  Batch 35: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:45,458 : [INFO]  Batch 35, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:45,458 : [INFO]  ____________________________________ Batch 35: round 1 finished ____________________________________
2023-03-21 01:45:45,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:45,458 : [INFO]  #################################### Batch 35: sent the final model to clients ####################################
2023-03-21 01:45:45,460 : [INFO]  Batch number 35 model fetched from the server
2023-03-21 01:45:45,461 : [INFO]  ################ Batch 35: final global model evalution after 1 rounds ################
2023-03-21 01:45:46,722 : [INFO]  Batch 35: Training set : loss - 0.56, accuracy - 0.74, recall - 0.9, AUC - 0.88, F1 - 0.78, precision - 0.69, training time - -3.0 seconds
2023-03-21 01:45:46,723 : [INFO]  Batch 35: Testing set : loss - 0.6, accuracy - 0.67, recall - 0.94, AUC - 0.81, F1 - 0.74, precision - 0.61
2023-03-21 01:45:46,841 : [INFO]  Batch 36 initialized 
2023-03-21 01:45:47,375 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:47,638 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-21 01:45:50,128 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:50,130 : [INFO]  Batch 36: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:50,131 : [INFO]  Batch 36, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:50,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:50,131 : [INFO]  ____________________________________ Batch 36: round 1 finished ____________________________________
2023-03-21 01:45:50,131 : [INFO]  #################################### Batch 36: sent the final model to clients ####################################
2023-03-21 01:45:50,132 : [INFO]  Batch number 36 model fetched from the server
2023-03-21 01:45:50,132 : [INFO]  ################ Batch 36: final global model evalution after 1 rounds ################
2023-03-21 01:45:51,408 : [INFO]  Batch 36: Training set : loss - 0.58, accuracy - 0.73, recall - 0.99, AUC - 0.89, F1 - 0.78, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:45:51,408 : [INFO]  Batch 36: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.94, AUC - 0.84, F1 - 0.74, precision - 0.62
2023-03-21 01:45:51,476 : [INFO]  Batch 37 initialized 
2023-03-21 01:45:51,879 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:52,113 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-21 01:45:54,707 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:54,710 : [INFO]  Batch 37: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:54,710 : [INFO]  Batch 37, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:54,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:54,710 : [INFO]  ____________________________________ Batch 37: round 1 finished ____________________________________
2023-03-21 01:45:54,710 : [INFO]  #################################### Batch 37: sent the final model to clients ####################################
2023-03-21 01:45:54,712 : [INFO]  Batch number 37 model fetched from the server
2023-03-21 01:45:54,712 : [INFO]  ################ Batch 37: final global model evalution after 1 rounds ################
2023-03-21 01:45:55,735 : [INFO]  Batch 37: Training set : loss - 0.55, accuracy - 0.76, recall - 0.97, AUC - 0.91, F1 - 0.8, precision - 0.68, training time - -3.0 seconds
2023-03-21 01:45:55,735 : [INFO]  Batch 37: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.91, AUC - 0.86, F1 - 0.77, precision - 0.66
2023-03-21 01:45:55,841 : [INFO]  Batch 38 initialized 
2023-03-21 01:45:56,296 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:45:56,535 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-21 01:45:58,662 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-21 01:45:58,664 : [INFO]  Batch 38: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:45:58,665 : [INFO]  Batch 38, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:45:58,665 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:45:58,665 : [INFO]  ____________________________________ Batch 38: round 1 finished ____________________________________
2023-03-21 01:45:58,665 : [INFO]  #################################### Batch 38: sent the final model to clients ####################################
2023-03-21 01:45:58,666 : [INFO]  Batch number 38 model fetched from the server
2023-03-21 01:45:58,666 : [INFO]  ################ Batch 38: final global model evalution after 1 rounds ################
2023-03-21 01:45:59,588 : [INFO]  Batch 38: Training set : loss - 0.58, accuracy - 0.75, recall - 0.93, AUC - 0.84, F1 - 0.79, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:45:59,588 : [INFO]  Batch 38: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.95, AUC - 0.88, F1 - 0.78, precision - 0.66
2023-03-21 01:45:59,724 : [INFO]  Batch 39 initialized 
2023-03-21 01:46:00,053 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:00,286 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-21 01:46:02,470 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:02,472 : [INFO]  Batch 39: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:02,472 : [INFO]  Batch 39, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:02,473 : [INFO]  ____________________________________ Batch 39: round 1 finished ____________________________________
2023-03-21 01:46:02,473 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:02,473 : [INFO]  #################################### Batch 39: sent the final model to clients ####################################
2023-03-21 01:46:02,474 : [INFO]  Batch number 39 model fetched from the server
2023-03-21 01:46:02,474 : [INFO]  ################ Batch 39: final global model evalution after 1 rounds ################
2023-03-21 01:46:03,433 : [INFO]  Batch 39: Training set : loss - 0.57, accuracy - 0.74, recall - 0.98, AUC - 0.88, F1 - 0.79, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:46:03,433 : [INFO]  Batch 39: Testing set : loss - 0.62, accuracy - 0.65, recall - 0.93, AUC - 0.81, F1 - 0.73, precision - 0.59
2023-03-21 01:46:03,543 : [INFO]  Batch 40 initialized 
2023-03-21 01:46:03,873 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:04,106 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-21 01:46:06,237 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:06,242 : [INFO]  Batch 40: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:06,243 : [INFO]  Batch 40, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:06,243 : [INFO]  ____________________________________ Batch 40: round 1 finished ____________________________________
2023-03-21 01:46:06,243 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:06,243 : [INFO]  #################################### Batch 40: sent the final model to clients ####################################
2023-03-21 01:46:06,246 : [INFO]  Batch number 40 model fetched from the server
2023-03-21 01:46:06,246 : [INFO]  ################ Batch 40: final global model evalution after 1 rounds ################
2023-03-21 01:46:07,396 : [INFO]  Batch 40: Training set : loss - 0.59, accuracy - 0.71, recall - 0.92, AUC - 0.85, F1 - 0.76, precision - 0.64, training time - -2.0 seconds
2023-03-21 01:46:07,396 : [INFO]  Batch 40: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.97, AUC - 0.86, F1 - 0.76, precision - 0.63
2023-03-21 01:46:07,461 : [INFO]  Batch 41 initialized 
2023-03-21 01:46:07,928 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:08,202 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-21 01:46:10,466 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:10,469 : [INFO]  Batch 41: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:10,469 : [INFO]  Batch 41, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:10,469 : [INFO]  ____________________________________ Batch 41: round 1 finished ____________________________________
2023-03-21 01:46:10,469 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:10,469 : [INFO]  #################################### Batch 41: sent the final model to clients ####################################
2023-03-21 01:46:10,471 : [INFO]  Batch number 41 model fetched from the server
2023-03-21 01:46:10,471 : [INFO]  ################ Batch 41: final global model evalution after 1 rounds ################
2023-03-21 01:46:11,706 : [INFO]  Batch 41: Training set : loss - 0.56, accuracy - 0.77, recall - 0.98, AUC - 0.91, F1 - 0.81, precision - 0.69, training time - -2.0 seconds
2023-03-21 01:46:11,706 : [INFO]  Batch 41: Testing set : loss - 0.61, accuracy - 0.69, recall - 0.97, AUC - 0.83, F1 - 0.76, precision - 0.62
2023-03-21 01:46:11,786 : [INFO]  Batch 42 initialized 
2023-03-21 01:46:12,350 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:12,625 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-21 01:46:16,131 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:16,134 : [INFO]  Batch 42: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:16,135 : [INFO]  Batch 42, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:16,135 : [INFO]  ____________________________________ Batch 42: round 1 finished ____________________________________
2023-03-21 01:46:16,135 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:16,135 : [INFO]  #################################### Batch 42: sent the final model to clients ####################################
2023-03-21 01:46:16,138 : [INFO]  Batch number 42 model fetched from the server
2023-03-21 01:46:16,138 : [INFO]  ################ Batch 42: final global model evalution after 1 rounds ################
2023-03-21 01:46:17,564 : [INFO]  Batch 42: Training set : loss - 0.56, accuracy - 0.76, recall - 0.9, AUC - 0.87, F1 - 0.79, precision - 0.7, training time - -4.0 seconds
2023-03-21 01:46:17,564 : [INFO]  Batch 42: Testing set : loss - 0.61, accuracy - 0.68, recall - 0.87, AUC - 0.79, F1 - 0.73, precision - 0.63
2023-03-21 01:46:17,622 : [INFO]  Batch 43 initialized 
2023-03-21 01:46:17,982 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:18,217 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-21 01:46:21,984 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:21,987 : [INFO]  Batch 43: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:21,988 : [INFO]  Batch 43, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:21,988 : [INFO]  ____________________________________ Batch 43: round 1 finished ____________________________________
2023-03-21 01:46:21,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:21,988 : [INFO]  #################################### Batch 43: sent the final model to clients ####################################
2023-03-21 01:46:21,990 : [INFO]  Batch number 43 model fetched from the server
2023-03-21 01:46:21,991 : [INFO]  ################ Batch 43: final global model evalution after 1 rounds ################
2023-03-21 01:46:23,912 : [INFO]  Batch 43: Training set : loss - 0.55, accuracy - 0.78, recall - 0.95, AUC - 0.88, F1 - 0.81, precision - 0.71, training time - -4.0 seconds
2023-03-21 01:46:23,912 : [INFO]  Batch 43: Testing set : loss - 0.6, accuracy - 0.67, recall - 0.89, AUC - 0.82, F1 - 0.73, precision - 0.62
2023-03-21 01:46:24,035 : [INFO]  Batch 44 initialized 
2023-03-21 01:46:24,448 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:24,682 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-21 01:46:26,700 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:26,702 : [INFO]  Batch 44: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:26,702 : [INFO]  Batch 44, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:26,703 : [INFO]  ____________________________________ Batch 44: round 1 finished ____________________________________
2023-03-21 01:46:26,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:26,703 : [INFO]  #################################### Batch 44: sent the final model to clients ####################################
2023-03-21 01:46:26,704 : [INFO]  Batch number 44 model fetched from the server
2023-03-21 01:46:26,704 : [INFO]  ################ Batch 44: final global model evalution after 1 rounds ################
2023-03-21 01:46:27,650 : [INFO]  Batch 44: Training set : loss - 0.55, accuracy - 0.77, recall - 0.96, AUC - 0.91, F1 - 0.81, precision - 0.7, training time - -2.0 seconds
2023-03-21 01:46:27,650 : [INFO]  Batch 44: Testing set : loss - 0.58, accuracy - 0.73, recall - 0.92, AUC - 0.86, F1 - 0.77, precision - 0.66
2023-03-21 01:46:27,755 : [INFO]  Batch 45 initialized 
2023-03-21 01:46:28,098 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:28,341 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-21 01:46:30,338 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:30,340 : [INFO]  Batch 45: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:30,341 : [INFO]  Batch 45, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:30,341 : [INFO]  ____________________________________ Batch 45: round 1 finished ____________________________________
2023-03-21 01:46:30,341 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:30,341 : [INFO]  #################################### Batch 45: sent the final model to clients ####################################
2023-03-21 01:46:30,342 : [INFO]  Batch number 45 model fetched from the server
2023-03-21 01:46:30,342 : [INFO]  ################ Batch 45: final global model evalution after 1 rounds ################
2023-03-21 01:46:31,237 : [INFO]  Batch 45: Training set : loss - 0.54, accuracy - 0.78, recall - 0.97, AUC - 0.95, F1 - 0.82, precision - 0.71, training time - -2.0 seconds
2023-03-21 01:46:31,238 : [INFO]  Batch 45: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.9, AUC - 0.88, F1 - 0.76, precision - 0.66
2023-03-21 01:46:31,362 : [INFO]  Batch 46 initialized 
2023-03-21 01:46:31,713 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:31,978 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-21 01:46:34,031 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:34,034 : [INFO]  Batch 46: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:34,034 : [INFO]  Batch 46, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:34,034 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:34,034 : [INFO]  ____________________________________ Batch 46: round 1 finished ____________________________________
2023-03-21 01:46:34,034 : [INFO]  #################################### Batch 46: sent the final model to clients ####################################
2023-03-21 01:46:34,036 : [INFO]  Batch number 46 model fetched from the server
2023-03-21 01:46:34,036 : [INFO]  ################ Batch 46: final global model evalution after 1 rounds ################
2023-03-21 01:46:34,954 : [INFO]  Batch 46: Training set : loss - 0.56, accuracy - 0.74, recall - 0.97, AUC - 0.91, F1 - 0.79, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:46:34,954 : [INFO]  Batch 46: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.66
2023-03-21 01:46:35,101 : [INFO]  Batch 47 initialized 
2023-03-21 01:46:35,439 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:35,698 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-21 01:46:37,806 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:37,808 : [INFO]  Batch 47: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:37,808 : [INFO]  Batch 47, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:37,808 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:37,809 : [INFO]  ____________________________________ Batch 47: round 1 finished ____________________________________
2023-03-21 01:46:37,809 : [INFO]  #################################### Batch 47: sent the final model to clients ####################################
2023-03-21 01:46:37,810 : [INFO]  Batch number 47 model fetched from the server
2023-03-21 01:46:37,810 : [INFO]  ################ Batch 47: final global model evalution after 1 rounds ################
2023-03-21 01:46:38,767 : [INFO]  Batch 47: Training set : loss - 0.55, accuracy - 0.75, recall - 0.93, AUC - 0.91, F1 - 0.79, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:46:38,767 : [INFO]  Batch 47: Testing set : loss - 0.57, accuracy - 0.7, recall - 0.91, AUC - 0.9, F1 - 0.75, precision - 0.64
2023-03-21 01:46:38,925 : [INFO]  Batch 48 initialized 
2023-03-21 01:46:39,522 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:39,946 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-21 01:46:43,682 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:43,685 : [INFO]  Batch 48: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:43,686 : [INFO]  Batch 48, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:43,686 : [INFO]  ____________________________________ Batch 48: round 1 finished ____________________________________
2023-03-21 01:46:43,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:43,686 : [INFO]  #################################### Batch 48: sent the final model to clients ####################################
2023-03-21 01:46:43,688 : [INFO]  Batch number 48 model fetched from the server
2023-03-21 01:46:43,688 : [INFO]  ################ Batch 48: final global model evalution after 1 rounds ################
2023-03-21 01:46:45,556 : [INFO]  Batch 48: Training set : loss - 0.56, accuracy - 0.74, recall - 0.96, AUC - 0.92, F1 - 0.79, precision - 0.67, training time - -4.0 seconds
2023-03-21 01:46:45,556 : [INFO]  Batch 48: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.9, AUC - 0.88, F1 - 0.75, precision - 0.65
2023-03-21 01:46:45,640 : [INFO]  Batch 49 initialized 
2023-03-21 01:46:46,078 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:46,334 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-21 01:46:48,379 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:48,381 : [INFO]  Batch 49: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:48,382 : [INFO]  Batch 49, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:48,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:48,382 : [INFO]  ____________________________________ Batch 49: round 1 finished ____________________________________
2023-03-21 01:46:48,382 : [INFO]  #################################### Batch 49: sent the final model to clients ####################################
2023-03-21 01:46:48,383 : [INFO]  Batch number 49 model fetched from the server
2023-03-21 01:46:48,383 : [INFO]  ################ Batch 49: final global model evalution after 1 rounds ################
2023-03-21 01:46:49,382 : [INFO]  Batch 49: Training set : loss - 0.58, accuracy - 0.72, recall - 0.92, AUC - 0.86, F1 - 0.77, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:46:49,383 : [INFO]  Batch 49: Testing set : loss - 0.59, accuracy - 0.66, recall - 0.91, AUC - 0.85, F1 - 0.73, precision - 0.6
2023-03-21 01:46:49,464 : [INFO]  Batch 50 initialized 
2023-03-21 01:46:49,815 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:50,063 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-21 01:46:52,086 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:52,088 : [INFO]  Batch 50: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:52,089 : [INFO]  Batch 50, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:52,089 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:52,089 : [INFO]  ____________________________________ Batch 50: round 1 finished ____________________________________
2023-03-21 01:46:52,089 : [INFO]  #################################### Batch 50: sent the final model to clients ####################################
2023-03-21 01:46:52,090 : [INFO]  Batch number 50 model fetched from the server
2023-03-21 01:46:52,090 : [INFO]  ################ Batch 50: final global model evalution after 1 rounds ################
2023-03-21 01:46:52,964 : [INFO]  Batch 50: Training set : loss - 0.58, accuracy - 0.68, recall - 0.9, AUC - 0.88, F1 - 0.74, precision - 0.62, training time - -2.0 seconds
2023-03-21 01:46:52,964 : [INFO]  Batch 50: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.91, AUC - 0.85, F1 - 0.76, precision - 0.65
2023-03-21 01:46:53,026 : [INFO]  Batch 51 initialized 
2023-03-21 01:46:53,370 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:53,616 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-21 01:46:55,684 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-21 01:46:55,686 : [INFO]  Batch 51: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:46:55,686 : [INFO]  Batch 51, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:46:55,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:46:55,686 : [INFO]  ____________________________________ Batch 51: round 1 finished ____________________________________
2023-03-21 01:46:55,686 : [INFO]  #################################### Batch 51: sent the final model to clients ####################################
2023-03-21 01:46:55,688 : [INFO]  Batch number 51 model fetched from the server
2023-03-21 01:46:55,688 : [INFO]  ################ Batch 51: final global model evalution after 1 rounds ################
2023-03-21 01:46:56,800 : [INFO]  Batch 51: Training set : loss - 0.58, accuracy - 0.72, recall - 0.9, AUC - 0.86, F1 - 0.76, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:46:56,800 : [INFO]  Batch 51: Testing set : loss - 0.58, accuracy - 0.7, recall - 0.93, AUC - 0.89, F1 - 0.75, precision - 0.63
2023-03-21 01:46:56,925 : [INFO]  Batch 52 initialized 
2023-03-21 01:46:57,844 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:46:58,266 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-21 01:47:02,528 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:02,533 : [INFO]  Batch 52: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:02,533 : [INFO]  Batch 52, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:02,533 : [INFO]  ____________________________________ Batch 52: round 1 finished ____________________________________
2023-03-21 01:47:02,533 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:02,533 : [INFO]  #################################### Batch 52: sent the final model to clients ####################################
2023-03-21 01:47:02,535 : [INFO]  Batch number 52 model fetched from the server
2023-03-21 01:47:02,536 : [INFO]  ################ Batch 52: final global model evalution after 1 rounds ################
2023-03-21 01:47:04,305 : [INFO]  Batch 52: Training set : loss - 0.61, accuracy - 0.65, recall - 0.89, AUC - 0.82, F1 - 0.72, precision - 0.6, training time - -4.0 seconds
2023-03-21 01:47:04,305 : [INFO]  Batch 52: Testing set : loss - 0.61, accuracy - 0.67, recall - 0.86, AUC - 0.81, F1 - 0.72, precision - 0.62
2023-03-21 01:47:04,500 : [INFO]  Batch 53 initialized 
2023-03-21 01:47:05,394 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:05,691 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-21 01:47:09,092 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:09,095 : [INFO]  Batch 53: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:09,095 : [INFO]  Batch 53, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:09,095 : [INFO]  ____________________________________ Batch 53: round 1 finished ____________________________________
2023-03-21 01:47:09,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:09,095 : [INFO]  #################################### Batch 53: sent the final model to clients ####################################
2023-03-21 01:47:09,098 : [INFO]  Batch number 53 model fetched from the server
2023-03-21 01:47:09,099 : [INFO]  ################ Batch 53: final global model evalution after 1 rounds ################
2023-03-21 01:47:11,038 : [INFO]  Batch 53: Training set : loss - 0.55, accuracy - 0.74, recall - 0.91, AUC - 0.9, F1 - 0.78, precision - 0.68, training time - -3.0 seconds
2023-03-21 01:47:11,038 : [INFO]  Batch 53: Testing set : loss - 0.61, accuracy - 0.68, recall - 0.92, AUC - 0.82, F1 - 0.74, precision - 0.62
2023-03-21 01:47:11,161 : [INFO]  Batch 54 initialized 
2023-03-21 01:47:11,943 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:12,218 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-21 01:47:15,124 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:15,126 : [INFO]  Batch 54: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:15,127 : [INFO]  Batch 54, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:15,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:15,127 : [INFO]  ____________________________________ Batch 54: round 1 finished ____________________________________
2023-03-21 01:47:15,127 : [INFO]  #################################### Batch 54: sent the final model to clients ####################################
2023-03-21 01:47:15,128 : [INFO]  Batch number 54 model fetched from the server
2023-03-21 01:47:15,128 : [INFO]  ################ Batch 54: final global model evalution after 1 rounds ################
2023-03-21 01:47:16,043 : [INFO]  Batch 54: Training set : loss - 0.59, accuracy - 0.67, recall - 0.89, AUC - 0.83, F1 - 0.73, precision - 0.62, training time - -3.0 seconds
2023-03-21 01:47:16,043 : [INFO]  Batch 54: Testing set : loss - 0.61, accuracy - 0.64, recall - 0.85, AUC - 0.81, F1 - 0.7, precision - 0.6
2023-03-21 01:47:16,161 : [INFO]  Batch 55 initialized 
2023-03-21 01:47:16,489 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:16,740 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-21 01:47:18,713 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:18,715 : [INFO]  Batch 55: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:18,716 : [INFO]  Batch 55, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:18,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:18,716 : [INFO]  ____________________________________ Batch 55: round 1 finished ____________________________________
2023-03-21 01:47:18,716 : [INFO]  #################################### Batch 55: sent the final model to clients ####################################
2023-03-21 01:47:18,717 : [INFO]  Batch number 55 model fetched from the server
2023-03-21 01:47:18,717 : [INFO]  ################ Batch 55: final global model evalution after 1 rounds ################
2023-03-21 01:47:19,620 : [INFO]  Batch 55: Training set : loss - 0.56, accuracy - 0.71, recall - 0.92, AUC - 0.9, F1 - 0.76, precision - 0.65, training time - -2.0 seconds
2023-03-21 01:47:19,620 : [INFO]  Batch 55: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.94, AUC - 0.85, F1 - 0.76, precision - 0.64
2023-03-21 01:47:19,690 : [INFO]  Batch 56 initialized 
2023-03-21 01:47:20,077 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:20,341 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-21 01:47:22,454 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:22,457 : [INFO]  Batch 56: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:22,457 : [INFO]  Batch 56, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:22,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:22,457 : [INFO]  ____________________________________ Batch 56: round 1 finished ____________________________________
2023-03-21 01:47:22,457 : [INFO]  #################################### Batch 56: sent the final model to clients ####################################
2023-03-21 01:47:22,459 : [INFO]  Batch number 56 model fetched from the server
2023-03-21 01:47:22,459 : [INFO]  ################ Batch 56: final global model evalution after 1 rounds ################
2023-03-21 01:47:23,341 : [INFO]  Batch 56: Training set : loss - 0.56, accuracy - 0.71, recall - 0.92, AUC - 0.89, F1 - 0.76, precision - 0.64, training time - -2.0 seconds
2023-03-21 01:47:23,341 : [INFO]  Batch 56: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.93, AUC - 0.88, F1 - 0.76, precision - 0.65
2023-03-21 01:47:23,448 : [INFO]  Batch 57 initialized 
2023-03-21 01:47:23,797 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:24,063 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-21 01:47:26,397 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:26,399 : [INFO]  Batch 57: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:26,400 : [INFO]  Batch 57, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:26,400 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:26,400 : [INFO]  ____________________________________ Batch 57: round 1 finished ____________________________________
2023-03-21 01:47:26,400 : [INFO]  #################################### Batch 57: sent the final model to clients ####################################
2023-03-21 01:47:26,402 : [INFO]  Batch number 57 model fetched from the server
2023-03-21 01:47:26,402 : [INFO]  ################ Batch 57: final global model evalution after 1 rounds ################
2023-03-21 01:47:27,297 : [INFO]  Batch 57: Training set : loss - 0.58, accuracy - 0.76, recall - 0.89, AUC - 0.85, F1 - 0.78, precision - 0.7, training time - -2.0 seconds
2023-03-21 01:47:27,297 : [INFO]  Batch 57: Testing set : loss - 0.58, accuracy - 0.74, recall - 0.91, AUC - 0.85, F1 - 0.78, precision - 0.67
2023-03-21 01:47:27,418 : [INFO]  Batch 58 initialized 
2023-03-21 01:47:27,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:28,045 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-21 01:47:30,040 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:30,043 : [INFO]  Batch 58: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:30,043 : [INFO]  Batch 58, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:30,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:30,043 : [INFO]  ____________________________________ Batch 58: round 1 finished ____________________________________
2023-03-21 01:47:30,043 : [INFO]  #################################### Batch 58: sent the final model to clients ####################################
2023-03-21 01:47:30,044 : [INFO]  Batch number 58 model fetched from the server
2023-03-21 01:47:30,044 : [INFO]  ################ Batch 58: final global model evalution after 1 rounds ################
2023-03-21 01:47:30,999 : [INFO]  Batch 58: Training set : loss - 0.57, accuracy - 0.72, recall - 0.91, AUC - 0.89, F1 - 0.77, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:47:30,999 : [INFO]  Batch 58: Testing set : loss - 0.59, accuracy - 0.73, recall - 0.92, AUC - 0.84, F1 - 0.77, precision - 0.66
2023-03-21 01:47:31,085 : [INFO]  Batch 59 initialized 
2023-03-21 01:47:31,474 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:31,727 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-21 01:47:33,785 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:33,788 : [INFO]  Batch 59: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:33,788 : [INFO]  Batch 59, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:33,788 : [INFO]  ____________________________________ Batch 59: round 1 finished ____________________________________
2023-03-21 01:47:33,788 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:33,788 : [INFO]  #################################### Batch 59: sent the final model to clients ####################################
2023-03-21 01:47:33,790 : [INFO]  Batch number 59 model fetched from the server
2023-03-21 01:47:33,790 : [INFO]  ################ Batch 59: final global model evalution after 1 rounds ################
2023-03-21 01:47:34,727 : [INFO]  Batch 59: Training set : loss - 0.56, accuracy - 0.75, recall - 0.95, AUC - 0.89, F1 - 0.79, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:47:34,727 : [INFO]  Batch 59: Testing set : loss - 0.59, accuracy - 0.68, recall - 0.85, AUC - 0.84, F1 - 0.73, precision - 0.63
2023-03-21 01:47:34,855 : [INFO]  Batch 60 initialized 
2023-03-21 01:47:35,184 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:35,441 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-21 01:47:37,459 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:37,461 : [INFO]  Batch 60: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:37,462 : [INFO]  Batch 60, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:37,462 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:37,462 : [INFO]  ____________________________________ Batch 60: round 1 finished ____________________________________
2023-03-21 01:47:37,462 : [INFO]  #################################### Batch 60: sent the final model to clients ####################################
2023-03-21 01:47:37,463 : [INFO]  Batch number 60 model fetched from the server
2023-03-21 01:47:37,463 : [INFO]  ################ Batch 60: final global model evalution after 1 rounds ################
2023-03-21 01:47:38,317 : [INFO]  Batch 60: Training set : loss - 0.58, accuracy - 0.72, recall - 0.91, AUC - 0.86, F1 - 0.76, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:47:38,317 : [INFO]  Batch 60: Testing set : loss - 0.6, accuracy - 0.66, recall - 0.85, AUC - 0.81, F1 - 0.71, precision - 0.61
2023-03-21 01:47:38,378 : [INFO]  Batch 61 initialized 
2023-03-21 01:47:38,718 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:38,975 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-21 01:47:40,935 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:40,937 : [INFO]  Batch 61: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:40,937 : [INFO]  Batch 61, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:40,938 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:40,938 : [INFO]  ____________________________________ Batch 61: round 1 finished ____________________________________
2023-03-21 01:47:40,938 : [INFO]  #################################### Batch 61: sent the final model to clients ####################################
2023-03-21 01:47:40,939 : [INFO]  Batch number 61 model fetched from the server
2023-03-21 01:47:40,939 : [INFO]  ################ Batch 61: final global model evalution after 1 rounds ################
2023-03-21 01:47:41,863 : [INFO]  Batch 61: Training set : loss - 0.57, accuracy - 0.73, recall - 0.97, AUC - 0.9, F1 - 0.78, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:47:41,863 : [INFO]  Batch 61: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.95, AUC - 0.88, F1 - 0.77, precision - 0.65
2023-03-21 01:47:41,937 : [INFO]  Batch 62 initialized 
2023-03-21 01:47:42,306 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:42,583 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-21 01:47:44,680 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:44,682 : [INFO]  Batch 62: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:44,683 : [INFO]  Batch 62, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:44,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:44,683 : [INFO]  ____________________________________ Batch 62: round 1 finished ____________________________________
2023-03-21 01:47:44,683 : [INFO]  #################################### Batch 62: sent the final model to clients ####################################
2023-03-21 01:47:44,684 : [INFO]  Batch number 62 model fetched from the server
2023-03-21 01:47:44,684 : [INFO]  ################ Batch 62: final global model evalution after 1 rounds ################
2023-03-21 01:47:45,716 : [INFO]  Batch 62: Training set : loss - 0.56, accuracy - 0.72, recall - 0.92, AUC - 0.88, F1 - 0.77, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:47:45,716 : [INFO]  Batch 62: Testing set : loss - 0.62, accuracy - 0.67, recall - 0.89, AUC - 0.78, F1 - 0.73, precision - 0.62
2023-03-21 01:47:45,798 : [INFO]  Batch 63 initialized 
2023-03-21 01:47:46,195 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:46,476 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-21 01:47:48,784 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:48,787 : [INFO]  Batch 63: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:48,787 : [INFO]  Batch 63, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:48,787 : [INFO]  ____________________________________ Batch 63: round 1 finished ____________________________________
2023-03-21 01:47:48,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:48,787 : [INFO]  #################################### Batch 63: sent the final model to clients ####################################
2023-03-21 01:47:48,789 : [INFO]  Batch number 63 model fetched from the server
2023-03-21 01:47:48,789 : [INFO]  ################ Batch 63: final global model evalution after 1 rounds ################
2023-03-21 01:47:49,776 : [INFO]  Batch 63: Training set : loss - 0.58, accuracy - 0.75, recall - 0.95, AUC - 0.86, F1 - 0.79, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:47:49,776 : [INFO]  Batch 63: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.9, AUC - 0.86, F1 - 0.76, precision - 0.66
2023-03-21 01:47:49,860 : [INFO]  Batch 64 initialized 
2023-03-21 01:47:50,218 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:50,491 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-21 01:47:52,593 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:52,595 : [INFO]  Batch 64: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:52,595 : [INFO]  Batch 64, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:52,595 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:52,595 : [INFO]  ____________________________________ Batch 64: round 1 finished ____________________________________
2023-03-21 01:47:52,595 : [INFO]  #################################### Batch 64: sent the final model to clients ####################################
2023-03-21 01:47:52,597 : [INFO]  Batch number 64 model fetched from the server
2023-03-21 01:47:52,597 : [INFO]  ################ Batch 64: final global model evalution after 1 rounds ################
2023-03-21 01:47:53,528 : [INFO]  Batch 64: Training set : loss - 0.59, accuracy - 0.73, recall - 0.89, AUC - 0.84, F1 - 0.77, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:47:53,528 : [INFO]  Batch 64: Testing set : loss - 0.6, accuracy - 0.65, recall - 0.87, AUC - 0.81, F1 - 0.71, precision - 0.61
2023-03-21 01:47:53,606 : [INFO]  Batch 65 initialized 
2023-03-21 01:47:53,944 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:47:54,204 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-21 01:47:57,483 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-21 01:47:57,487 : [INFO]  Batch 65: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:47:57,488 : [INFO]  Batch 65, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:47:57,488 : [INFO]  ____________________________________ Batch 65: round 1 finished ____________________________________
2023-03-21 01:47:57,488 : [INFO]  #################################### Batch 65: sent the final model to clients ####################################
2023-03-21 01:47:57,488 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:47:57,490 : [INFO]  Batch number 65 model fetched from the server
2023-03-21 01:47:57,490 : [INFO]  ################ Batch 65: final global model evalution after 1 rounds ################
2023-03-21 01:47:59,449 : [INFO]  Batch 65: Training set : loss - 0.57, accuracy - 0.76, recall - 0.89, AUC - 0.87, F1 - 0.79, precision - 0.71, training time - -3.0 seconds
2023-03-21 01:47:59,449 : [INFO]  Batch 65: Testing set : loss - 0.62, accuracy - 0.66, recall - 0.83, AUC - 0.78, F1 - 0.71, precision - 0.62
2023-03-21 01:47:59,570 : [INFO]  Batch 66 initialized 
2023-03-21 01:47:59,929 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:00,193 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-21 01:48:03,558 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:03,561 : [INFO]  Batch 66: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:03,562 : [INFO]  Batch 66, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:03,562 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:03,562 : [INFO]  ____________________________________ Batch 66: round 1 finished ____________________________________
2023-03-21 01:48:03,562 : [INFO]  #################################### Batch 66: sent the final model to clients ####################################
2023-03-21 01:48:03,564 : [INFO]  Batch number 66 model fetched from the server
2023-03-21 01:48:03,564 : [INFO]  ################ Batch 66: final global model evalution after 1 rounds ################
2023-03-21 01:48:05,049 : [INFO]  Batch 66: Training set : loss - 0.58, accuracy - 0.73, recall - 0.89, AUC - 0.86, F1 - 0.77, precision - 0.67, training time - -3.0 seconds
2023-03-21 01:48:05,049 : [INFO]  Batch 66: Testing set : loss - 0.57, accuracy - 0.74, recall - 0.92, AUC - 0.87, F1 - 0.78, precision - 0.67
2023-03-21 01:48:05,142 : [INFO]  Batch 67 initialized 
2023-03-21 01:48:05,659 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:06,143 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-21 01:48:08,790 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:08,792 : [INFO]  Batch 67: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:08,792 : [INFO]  Batch 67, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:08,792 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:08,793 : [INFO]  ____________________________________ Batch 67: round 1 finished ____________________________________
2023-03-21 01:48:08,793 : [INFO]  #################################### Batch 67: sent the final model to clients ####################################
2023-03-21 01:48:08,794 : [INFO]  Batch number 67 model fetched from the server
2023-03-21 01:48:08,794 : [INFO]  ################ Batch 67: final global model evalution after 1 rounds ################
2023-03-21 01:48:09,837 : [INFO]  Batch 67: Training set : loss - 0.59, accuracy - 0.72, recall - 0.88, AUC - 0.83, F1 - 0.76, precision - 0.66, training time - -3.0 seconds
2023-03-21 01:48:09,837 : [INFO]  Batch 67: Testing set : loss - 0.61, accuracy - 0.67, recall - 0.82, AUC - 0.78, F1 - 0.71, precision - 0.63
2023-03-21 01:48:09,915 : [INFO]  Batch 68 initialized 
2023-03-21 01:48:10,286 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:10,555 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-21 01:48:12,727 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:12,730 : [INFO]  Batch 68: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:12,731 : [INFO]  Batch 68, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:12,731 : [INFO]  ____________________________________ Batch 68: round 1 finished ____________________________________
2023-03-21 01:48:12,731 : [INFO]  #################################### Batch 68: sent the final model to clients ####################################
2023-03-21 01:48:12,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:12,733 : [INFO]  Batch number 68 model fetched from the server
2023-03-21 01:48:12,733 : [INFO]  ################ Batch 68: final global model evalution after 1 rounds ################
2023-03-21 01:48:13,743 : [INFO]  Batch 68: Training set : loss - 0.6, accuracy - 0.71, recall - 0.87, AUC - 0.81, F1 - 0.75, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:48:13,743 : [INFO]  Batch 68: Testing set : loss - 0.6, accuracy - 0.71, recall - 0.85, AUC - 0.8, F1 - 0.74, precision - 0.66
2023-03-21 01:48:13,821 : [INFO]  Batch 69 initialized 
2023-03-21 01:48:14,206 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:14,511 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-21 01:48:16,698 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:16,702 : [INFO]  Batch 69: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:16,702 : [INFO]  Batch 69, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:16,703 : [INFO]  ____________________________________ Batch 69: round 1 finished ____________________________________
2023-03-21 01:48:16,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:16,703 : [INFO]  #################################### Batch 69: sent the final model to clients ####################################
2023-03-21 01:48:16,705 : [INFO]  Batch number 69 model fetched from the server
2023-03-21 01:48:16,705 : [INFO]  ################ Batch 69: final global model evalution after 1 rounds ################
2023-03-21 01:48:18,525 : [INFO]  Batch 69: Training set : loss - 0.56, accuracy - 0.77, recall - 0.95, AUC - 0.9, F1 - 0.8, precision - 0.7, training time - -2.0 seconds
2023-03-21 01:48:18,525 : [INFO]  Batch 69: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.96, AUC - 0.87, F1 - 0.77, precision - 0.65
2023-03-21 01:48:18,643 : [INFO]  Batch 70 initialized 
2023-03-21 01:48:19,048 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:19,324 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-21 01:48:21,626 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:21,628 : [INFO]  Batch 70: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:21,629 : [INFO]  Batch 70, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:21,629 : [INFO]  ____________________________________ Batch 70: round 1 finished ____________________________________
2023-03-21 01:48:21,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:21,629 : [INFO]  #################################### Batch 70: sent the final model to clients ####################################
2023-03-21 01:48:21,630 : [INFO]  Batch number 70 model fetched from the server
2023-03-21 01:48:21,630 : [INFO]  ################ Batch 70: final global model evalution after 1 rounds ################
2023-03-21 01:48:22,637 : [INFO]  Batch 70: Training set : loss - 0.54, accuracy - 0.78, recall - 0.95, AUC - 0.91, F1 - 0.81, precision - 0.71, training time - -2.0 seconds
2023-03-21 01:48:22,637 : [INFO]  Batch 70: Testing set : loss - 0.58, accuracy - 0.7, recall - 0.91, AUC - 0.85, F1 - 0.75, precision - 0.64
2023-03-21 01:48:22,721 : [INFO]  Batch 71 initialized 
2023-03-21 01:48:23,222 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:23,793 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-21 01:48:26,569 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:26,571 : [INFO]  Batch 71: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:26,572 : [INFO]  Batch 71, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:26,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:26,572 : [INFO]  ____________________________________ Batch 71: round 1 finished ____________________________________
2023-03-21 01:48:26,572 : [INFO]  #################################### Batch 71: sent the final model to clients ####################################
2023-03-21 01:48:26,574 : [INFO]  Batch number 71 model fetched from the server
2023-03-21 01:48:26,574 : [INFO]  ################ Batch 71: final global model evalution after 1 rounds ################
2023-03-21 01:48:27,870 : [INFO]  Batch 71: Training set : loss - 0.56, accuracy - 0.77, recall - 0.97, AUC - 0.89, F1 - 0.81, precision - 0.69, training time - -3.0 seconds
2023-03-21 01:48:27,870 : [INFO]  Batch 71: Testing set : loss - 0.58, accuracy - 0.74, recall - 0.87, AUC - 0.85, F1 - 0.77, precision - 0.68
2023-03-21 01:48:27,982 : [INFO]  Batch 72 initialized 
2023-03-21 01:48:28,417 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:28,769 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-21 01:48:31,806 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:31,808 : [INFO]  Batch 72: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:31,809 : [INFO]  Batch 72, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:31,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:31,809 : [INFO]  ____________________________________ Batch 72: round 1 finished ____________________________________
2023-03-21 01:48:31,809 : [INFO]  #################################### Batch 72: sent the final model to clients ####################################
2023-03-21 01:48:31,810 : [INFO]  Batch number 72 model fetched from the server
2023-03-21 01:48:31,810 : [INFO]  ################ Batch 72: final global model evalution after 1 rounds ################
2023-03-21 01:48:33,788 : [INFO]  Batch 72: Training set : loss - 0.57, accuracy - 0.72, recall - 0.93, AUC - 0.88, F1 - 0.77, precision - 0.65, training time - -3.0 seconds
2023-03-21 01:48:33,788 : [INFO]  Batch 72: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.94, AUC - 0.88, F1 - 0.77, precision - 0.65
2023-03-21 01:48:33,890 : [INFO]  Batch 73 initialized 
2023-03-21 01:48:34,406 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:34,684 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-21 01:48:36,810 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:36,812 : [INFO]  Batch 73: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:36,813 : [INFO]  Batch 73, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:36,813 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:36,813 : [INFO]  ____________________________________ Batch 73: round 1 finished ____________________________________
2023-03-21 01:48:36,813 : [INFO]  #################################### Batch 73: sent the final model to clients ####################################
2023-03-21 01:48:36,815 : [INFO]  Batch number 73 model fetched from the server
2023-03-21 01:48:36,815 : [INFO]  ################ Batch 73: final global model evalution after 1 rounds ################
2023-03-21 01:48:38,133 : [INFO]  Batch 73: Training set : loss - 0.53, accuracy - 0.79, recall - 0.95, AUC - 0.92, F1 - 0.82, precision - 0.72, training time - -2.0 seconds
2023-03-21 01:48:38,134 : [INFO]  Batch 73: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.92, AUC - 0.89, F1 - 0.78, precision - 0.67
2023-03-21 01:48:38,372 : [INFO]  Batch 74 initialized 
2023-03-21 01:48:39,170 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:39,463 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-21 01:48:41,855 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:41,858 : [INFO]  Batch 74: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:41,858 : [INFO]  Batch 74, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:41,858 : [INFO]  ____________________________________ Batch 74: round 1 finished ____________________________________
2023-03-21 01:48:41,858 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:41,858 : [INFO]  #################################### Batch 74: sent the final model to clients ####################################
2023-03-21 01:48:41,860 : [INFO]  Batch number 74 model fetched from the server
2023-03-21 01:48:41,860 : [INFO]  ################ Batch 74: final global model evalution after 1 rounds ################
2023-03-21 01:48:42,873 : [INFO]  Batch 74: Training set : loss - 0.58, accuracy - 0.72, recall - 0.91, AUC - 0.84, F1 - 0.76, precision - 0.66, training time - -2.0 seconds
2023-03-21 01:48:42,873 : [INFO]  Batch 74: Testing set : loss - 0.61, accuracy - 0.68, recall - 0.9, AUC - 0.79, F1 - 0.74, precision - 0.62
2023-03-21 01:48:42,954 : [INFO]  Batch 75 initialized 
2023-03-21 01:48:43,307 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:43,594 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-21 01:48:45,736 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:45,738 : [INFO]  Batch 75: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:45,739 : [INFO]  Batch 75, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:45,739 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:45,739 : [INFO]  ____________________________________ Batch 75: round 1 finished ____________________________________
2023-03-21 01:48:45,739 : [INFO]  #################################### Batch 75: sent the final model to clients ####################################
2023-03-21 01:48:45,740 : [INFO]  Batch number 75 model fetched from the server
2023-03-21 01:48:45,740 : [INFO]  ################ Batch 75: final global model evalution after 1 rounds ################
2023-03-21 01:48:46,724 : [INFO]  Batch 75: Training set : loss - 0.58, accuracy - 0.74, recall - 0.92, AUC - 0.84, F1 - 0.78, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:48:46,724 : [INFO]  Batch 75: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.91, AUC - 0.81, F1 - 0.75, precision - 0.64
2023-03-21 01:48:46,839 : [INFO]  Batch 76 initialized 
2023-03-21 01:48:47,255 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:47,554 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-21 01:48:50,888 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:50,894 : [INFO]  Batch 76: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:50,895 : [INFO]  Batch 76, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:50,896 : [INFO]  ____________________________________ Batch 76: round 1 finished ____________________________________
2023-03-21 01:48:50,896 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:50,896 : [INFO]  #################################### Batch 76: sent the final model to clients ####################################
2023-03-21 01:48:50,902 : [INFO]  Batch number 76 model fetched from the server
2023-03-21 01:48:50,902 : [INFO]  ################ Batch 76: final global model evalution after 1 rounds ################
2023-03-21 01:48:52,517 : [INFO]  Batch 76: Training set : loss - 0.54, accuracy - 0.76, recall - 0.89, AUC - 0.9, F1 - 0.79, precision - 0.71, training time - -3.0 seconds
2023-03-21 01:48:52,517 : [INFO]  Batch 76: Testing set : loss - 0.58, accuracy - 0.74, recall - 0.92, AUC - 0.86, F1 - 0.78, precision - 0.67
2023-03-21 01:48:52,579 : [INFO]  Batch 77 initialized 
2023-03-21 01:48:53,057 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:53,358 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-21 01:48:55,859 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-21 01:48:55,866 : [INFO]  Batch 77: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:48:55,866 : [INFO]  Batch 77, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:48:55,867 : [INFO]  ____________________________________ Batch 77: round 1 finished ____________________________________
2023-03-21 01:48:55,866 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:48:55,867 : [INFO]  #################################### Batch 77: sent the final model to clients ####################################
2023-03-21 01:48:55,869 : [INFO]  Batch number 77 model fetched from the server
2023-03-21 01:48:55,869 : [INFO]  ################ Batch 77: final global model evalution after 1 rounds ################
2023-03-21 01:48:57,092 : [INFO]  Batch 77: Training set : loss - 0.59, accuracy - 0.69, recall - 0.85, AUC - 0.83, F1 - 0.73, precision - 0.64, training time - -3.0 seconds
2023-03-21 01:48:57,092 : [INFO]  Batch 77: Testing set : loss - 0.61, accuracy - 0.67, recall - 0.84, AUC - 0.78, F1 - 0.72, precision - 0.62
2023-03-21 01:48:57,157 : [INFO]  Batch 78 initialized 
2023-03-21 01:48:57,532 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:48:57,827 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-21 01:49:00,363 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:00,365 : [INFO]  Batch 78: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:00,366 : [INFO]  Batch 78, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:00,366 : [INFO]  ____________________________________ Batch 78: round 1 finished ____________________________________
2023-03-21 01:49:00,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:00,366 : [INFO]  #################################### Batch 78: sent the final model to clients ####################################
2023-03-21 01:49:00,367 : [INFO]  Batch number 78 model fetched from the server
2023-03-21 01:49:00,367 : [INFO]  ################ Batch 78: final global model evalution after 1 rounds ################
2023-03-21 01:49:01,753 : [INFO]  Batch 78: Training set : loss - 0.62, accuracy - 0.66, recall - 0.83, AUC - 0.78, F1 - 0.71, precision - 0.62, training time - -3.0 seconds
2023-03-21 01:49:01,753 : [INFO]  Batch 78: Testing set : loss - 0.6, accuracy - 0.67, recall - 0.83, AUC - 0.82, F1 - 0.72, precision - 0.63
2023-03-21 01:49:01,876 : [INFO]  Batch 79 initialized 
2023-03-21 01:49:02,504 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:02,789 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-21 01:49:05,507 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:05,510 : [INFO]  Batch 79: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:05,510 : [INFO]  Batch 79, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:05,510 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:05,510 : [INFO]  ____________________________________ Batch 79: round 1 finished ____________________________________
2023-03-21 01:49:05,511 : [INFO]  #################################### Batch 79: sent the final model to clients ####################################
2023-03-21 01:49:05,512 : [INFO]  Batch number 79 model fetched from the server
2023-03-21 01:49:05,512 : [INFO]  ################ Batch 79: final global model evalution after 1 rounds ################
2023-03-21 01:49:06,692 : [INFO]  Batch 79: Training set : loss - 0.58, accuracy - 0.68, recall - 0.88, AUC - 0.87, F1 - 0.74, precision - 0.63, training time - -3.0 seconds
2023-03-21 01:49:06,692 : [INFO]  Batch 79: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.93, AUC - 0.85, F1 - 0.75, precision - 0.63
2023-03-21 01:49:06,754 : [INFO]  Batch 80 initialized 
2023-03-21 01:49:07,119 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:07,405 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-21 01:49:09,843 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:09,845 : [INFO]  Batch 80: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:09,845 : [INFO]  Batch 80, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:09,846 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:09,846 : [INFO]  ____________________________________ Batch 80: round 1 finished ____________________________________
2023-03-21 01:49:09,846 : [INFO]  #################################### Batch 80: sent the final model to clients ####################################
2023-03-21 01:49:09,847 : [INFO]  Batch number 80 model fetched from the server
2023-03-21 01:49:09,847 : [INFO]  ################ Batch 80: final global model evalution after 1 rounds ################
2023-03-21 01:49:11,005 : [INFO]  Batch 80: Training set : loss - 0.57, accuracy - 0.74, recall - 0.88, AUC - 0.86, F1 - 0.78, precision - 0.69, training time - -2.0 seconds
2023-03-21 01:49:11,005 : [INFO]  Batch 80: Testing set : loss - 0.58, accuracy - 0.74, recall - 0.89, AUC - 0.86, F1 - 0.77, precision - 0.68
2023-03-21 01:49:11,068 : [INFO]  Batch 81 initialized 
2023-03-21 01:49:11,441 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:11,748 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-21 01:49:13,905 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:13,907 : [INFO]  Batch 81: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:13,907 : [INFO]  Batch 81, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:13,908 : [INFO]  ____________________________________ Batch 81: round 1 finished ____________________________________
2023-03-21 01:49:13,908 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:13,908 : [INFO]  #################################### Batch 81: sent the final model to clients ####################################
2023-03-21 01:49:13,909 : [INFO]  Batch number 81 model fetched from the server
2023-03-21 01:49:13,909 : [INFO]  ################ Batch 81: final global model evalution after 1 rounds ################
2023-03-21 01:49:14,839 : [INFO]  Batch 81: Training set : loss - 0.58, accuracy - 0.7, recall - 0.89, AUC - 0.86, F1 - 0.75, precision - 0.64, training time - -2.0 seconds
2023-03-21 01:49:14,839 : [INFO]  Batch 81: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.83, AUC - 0.81, F1 - 0.72, precision - 0.63
2023-03-21 01:49:14,964 : [INFO]  Batch 82 initialized 
2023-03-21 01:49:15,494 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:15,837 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-21 01:49:18,731 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:18,734 : [INFO]  Batch 82: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:18,735 : [INFO]  Batch 82, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:18,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:18,735 : [INFO]  ____________________________________ Batch 82: round 1 finished ____________________________________
2023-03-21 01:49:18,735 : [INFO]  #################################### Batch 82: sent the final model to clients ####################################
2023-03-21 01:49:18,737 : [INFO]  Batch number 82 model fetched from the server
2023-03-21 01:49:18,737 : [INFO]  ################ Batch 82: final global model evalution after 1 rounds ################
2023-03-21 01:49:20,317 : [INFO]  Batch 82: Training set : loss - 0.55, accuracy - 0.76, recall - 0.88, AUC - 0.87, F1 - 0.79, precision - 0.71, training time - -3.0 seconds
2023-03-21 01:49:20,317 : [INFO]  Batch 82: Testing set : loss - 0.59, accuracy - 0.71, recall - 0.88, AUC - 0.83, F1 - 0.75, precision - 0.66
2023-03-21 01:49:20,428 : [INFO]  Batch 83 initialized 
2023-03-21 01:49:20,861 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:21,272 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-21 01:49:24,096 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:24,098 : [INFO]  Batch 83: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:24,099 : [INFO]  Batch 83, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:24,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:24,099 : [INFO]  ____________________________________ Batch 83: round 1 finished ____________________________________
2023-03-21 01:49:24,099 : [INFO]  #################################### Batch 83: sent the final model to clients ####################################
2023-03-21 01:49:24,100 : [INFO]  Batch number 83 model fetched from the server
2023-03-21 01:49:24,100 : [INFO]  ################ Batch 83: final global model evalution after 1 rounds ################
2023-03-21 01:49:25,132 : [INFO]  Batch 83: Training set : loss - 0.56, accuracy - 0.75, recall - 0.89, AUC - 0.86, F1 - 0.78, precision - 0.69, training time - -3.0 seconds
2023-03-21 01:49:25,132 : [INFO]  Batch 83: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.9, AUC - 0.85, F1 - 0.74, precision - 0.63
2023-03-21 01:49:25,198 : [INFO]  Batch 84 initialized 
2023-03-21 01:49:25,574 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:25,859 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-21 01:49:28,098 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:28,102 : [INFO]  Batch 84: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:28,102 : [INFO]  Batch 84, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:28,102 : [INFO]  ____________________________________ Batch 84: round 1 finished ____________________________________
2023-03-21 01:49:28,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:28,102 : [INFO]  #################################### Batch 84: sent the final model to clients ####################################
2023-03-21 01:49:28,104 : [INFO]  Batch number 84 model fetched from the server
2023-03-21 01:49:28,104 : [INFO]  ################ Batch 84: final global model evalution after 1 rounds ################
2023-03-21 01:49:29,885 : [INFO]  Batch 84: Training set : loss - 0.57, accuracy - 0.71, recall - 0.85, AUC - 0.87, F1 - 0.75, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:49:29,885 : [INFO]  Batch 84: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.85, AUC - 0.82, F1 - 0.73, precision - 0.63
2023-03-21 01:49:29,962 : [INFO]  Batch 85 initialized 
2023-03-21 01:49:30,573 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:30,876 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-21 01:49:34,603 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:34,606 : [INFO]  Batch 85: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:34,606 : [INFO]  Batch 85, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:34,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:34,607 : [INFO]  ____________________________________ Batch 85: round 1 finished ____________________________________
2023-03-21 01:49:34,607 : [INFO]  #################################### Batch 85: sent the final model to clients ####################################
2023-03-21 01:49:34,608 : [INFO]  Batch number 85 model fetched from the server
2023-03-21 01:49:34,608 : [INFO]  ################ Batch 85: final global model evalution after 1 rounds ################
2023-03-21 01:49:35,572 : [INFO]  Batch 85: Training set : loss - 0.59, accuracy - 0.68, recall - 0.86, AUC - 0.81, F1 - 0.73, precision - 0.63, training time - -4.0 seconds
2023-03-21 01:49:35,572 : [INFO]  Batch 85: Testing set : loss - 0.63, accuracy - 0.62, recall - 0.78, AUC - 0.73, F1 - 0.68, precision - 0.59
2023-03-21 01:49:35,658 : [INFO]  Batch 86 initialized 
2023-03-21 01:49:35,995 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:36,281 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-21 01:49:39,766 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:39,775 : [INFO]  Batch 86: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:39,776 : [INFO]  Batch 86, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:39,776 : [INFO]  ____________________________________ Batch 86: round 1 finished ____________________________________
2023-03-21 01:49:39,776 : [INFO]  #################################### Batch 86: sent the final model to clients ####################################
2023-03-21 01:49:39,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:39,788 : [INFO]  Batch number 86 model fetched from the server
2023-03-21 01:49:39,789 : [INFO]  ################ Batch 86: final global model evalution after 1 rounds ################
2023-03-21 01:49:41,390 : [INFO]  Batch 86: Training set : loss - 0.59, accuracy - 0.66, recall - 0.86, AUC - 0.84, F1 - 0.72, precision - 0.62, training time - -4.0 seconds
2023-03-21 01:49:41,390 : [INFO]  Batch 86: Testing set : loss - 0.6, accuracy - 0.66, recall - 0.81, AUC - 0.83, F1 - 0.7, precision - 0.62
2023-03-21 01:49:41,459 : [INFO]  Batch 87 initialized 
2023-03-21 01:49:41,918 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:42,313 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-21 01:49:45,263 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:45,265 : [INFO]  Batch 87: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:45,266 : [INFO]  Batch 87, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:45,266 : [INFO]  ____________________________________ Batch 87: round 1 finished ____________________________________
2023-03-21 01:49:45,266 : [INFO]  #################################### Batch 87: sent the final model to clients ####################################
2023-03-21 01:49:45,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:45,268 : [INFO]  Batch number 87 model fetched from the server
2023-03-21 01:49:45,268 : [INFO]  ################ Batch 87: final global model evalution after 1 rounds ################
2023-03-21 01:49:46,218 : [INFO]  Batch 87: Training set : loss - 0.54, accuracy - 0.78, recall - 0.93, AUC - 0.91, F1 - 0.81, precision - 0.72, training time - -3.0 seconds
2023-03-21 01:49:46,218 : [INFO]  Batch 87: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.87, AUC - 0.85, F1 - 0.75, precision - 0.66
2023-03-21 01:49:46,283 : [INFO]  Batch 88 initialized 
2023-03-21 01:49:46,691 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:46,998 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-21 01:49:50,508 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:50,513 : [INFO]  Batch 88: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:50,513 : [INFO]  Batch 88, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:50,513 : [INFO]  ____________________________________ Batch 88: round 1 finished ____________________________________
2023-03-21 01:49:50,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:50,513 : [INFO]  #################################### Batch 88: sent the final model to clients ####################################
2023-03-21 01:49:50,514 : [INFO]  Batch number 88 model fetched from the server
2023-03-21 01:49:50,514 : [INFO]  ################ Batch 88: final global model evalution after 1 rounds ################
2023-03-21 01:49:51,521 : [INFO]  Batch 88: Training set : loss - 0.6, accuracy - 0.72, recall - 0.84, AUC - 0.81, F1 - 0.75, precision - 0.68, training time - -4.0 seconds
2023-03-21 01:49:51,521 : [INFO]  Batch 88: Testing set : loss - 0.59, accuracy - 0.72, recall - 0.83, AUC - 0.82, F1 - 0.75, precision - 0.68
2023-03-21 01:49:51,579 : [INFO]  Batch 89 initialized 
2023-03-21 01:49:51,940 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:52,230 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-21 01:49:55,197 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-21 01:49:55,200 : [INFO]  Batch 89: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:49:55,200 : [INFO]  Batch 89, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:49:55,200 : [INFO]  ____________________________________ Batch 89: round 1 finished ____________________________________
2023-03-21 01:49:55,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:49:55,200 : [INFO]  #################################### Batch 89: sent the final model to clients ####################################
2023-03-21 01:49:55,202 : [INFO]  Batch number 89 model fetched from the server
2023-03-21 01:49:55,202 : [INFO]  ################ Batch 89: final global model evalution after 1 rounds ################
2023-03-21 01:49:56,448 : [INFO]  Batch 89: Training set : loss - 0.58, accuracy - 0.71, recall - 0.9, AUC - 0.84, F1 - 0.76, precision - 0.65, training time - -3.0 seconds
2023-03-21 01:49:56,448 : [INFO]  Batch 89: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.85, AUC - 0.84, F1 - 0.75, precision - 0.66
2023-03-21 01:49:56,571 : [INFO]  Batch 90 initialized 
2023-03-21 01:49:57,113 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:49:57,435 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-21 01:50:00,754 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:00,756 : [INFO]  Batch 90: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:00,757 : [INFO]  Batch 90, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:00,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:00,757 : [INFO]  ____________________________________ Batch 90: round 1 finished ____________________________________
2023-03-21 01:50:00,757 : [INFO]  #################################### Batch 90: sent the final model to clients ####################################
2023-03-21 01:50:00,758 : [INFO]  Batch number 90 model fetched from the server
2023-03-21 01:50:00,758 : [INFO]  ################ Batch 90: final global model evalution after 1 rounds ################
2023-03-21 01:50:01,750 : [INFO]  Batch 90: Training set : loss - 0.59, accuracy - 0.68, recall - 0.93, AUC - 0.87, F1 - 0.75, precision - 0.62, training time - -3.0 seconds
2023-03-21 01:50:01,750 : [INFO]  Batch 90: Testing set : loss - 0.6, accuracy - 0.64, recall - 0.92, AUC - 0.86, F1 - 0.72, precision - 0.59
2023-03-21 01:50:01,874 : [INFO]  Batch 91 initialized 
2023-03-21 01:50:02,251 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:02,645 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-21 01:50:05,217 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:05,219 : [INFO]  Batch 91: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:05,219 : [INFO]  Batch 91, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:05,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:05,219 : [INFO]  ____________________________________ Batch 91: round 1 finished ____________________________________
2023-03-21 01:50:05,219 : [INFO]  #################################### Batch 91: sent the final model to clients ####################################
2023-03-21 01:50:05,221 : [INFO]  Batch number 91 model fetched from the server
2023-03-21 01:50:05,221 : [INFO]  ################ Batch 91: final global model evalution after 1 rounds ################
2023-03-21 01:50:06,228 : [INFO]  Batch 91: Training set : loss - 0.58, accuracy - 0.71, recall - 0.9, AUC - 0.86, F1 - 0.75, precision - 0.65, training time - -3.0 seconds
2023-03-21 01:50:06,229 : [INFO]  Batch 91: Testing set : loss - 0.62, accuracy - 0.66, recall - 0.83, AUC - 0.78, F1 - 0.71, precision - 0.62
2023-03-21 01:50:06,328 : [INFO]  Batch 92 initialized 
2023-03-21 01:50:06,821 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:07,180 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-21 01:50:10,889 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:10,893 : [INFO]  Batch 92: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:10,893 : [INFO]  Batch 92, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:10,894 : [INFO]  ____________________________________ Batch 92: round 1 finished ____________________________________
2023-03-21 01:50:10,894 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:10,894 : [INFO]  #################################### Batch 92: sent the final model to clients ####################################
2023-03-21 01:50:10,897 : [INFO]  Batch number 92 model fetched from the server
2023-03-21 01:50:10,897 : [INFO]  ################ Batch 92: final global model evalution after 1 rounds ################
2023-03-21 01:50:12,788 : [INFO]  Batch 92: Training set : loss - 0.57, accuracy - 0.71, recall - 0.91, AUC - 0.88, F1 - 0.76, precision - 0.65, training time - -4.0 seconds
2023-03-21 01:50:12,788 : [INFO]  Batch 92: Testing set : loss - 0.6, accuracy - 0.66, recall - 0.91, AUC - 0.85, F1 - 0.73, precision - 0.6
2023-03-21 01:50:12,897 : [INFO]  Batch 93 initialized 
2023-03-21 01:50:13,428 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:13,775 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-21 01:50:17,380 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:17,382 : [INFO]  Batch 93: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:17,382 : [INFO]  Batch 93, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:17,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:17,383 : [INFO]  ____________________________________ Batch 93: round 1 finished ____________________________________
2023-03-21 01:50:17,383 : [INFO]  #################################### Batch 93: sent the final model to clients ####################################
2023-03-21 01:50:17,384 : [INFO]  Batch number 93 model fetched from the server
2023-03-21 01:50:17,384 : [INFO]  ################ Batch 93: final global model evalution after 1 rounds ################
2023-03-21 01:50:18,330 : [INFO]  Batch 93: Training set : loss - 0.54, accuracy - 0.77, recall - 0.9, AUC - 0.91, F1 - 0.8, precision - 0.72, training time - -4.0 seconds
2023-03-21 01:50:18,330 : [INFO]  Batch 93: Testing set : loss - 0.6, accuracy - 0.64, recall - 0.86, AUC - 0.83, F1 - 0.71, precision - 0.6
2023-03-21 01:50:18,395 : [INFO]  Batch 94 initialized 
2023-03-21 01:50:18,739 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:19,029 : [INFO]  ------------------------- Batch 94 training: round 1 -------------------------
2023-03-21 01:50:21,103 : [INFO]  ------------------------- Batch 94, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:21,106 : [INFO]  Batch 94: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:21,106 : [INFO]  Batch 94, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:21,107 : [INFO]  ____________________________________ Batch 94: round 1 finished ____________________________________
2023-03-21 01:50:21,107 : [INFO]  #################################### Batch 94: sent the final model to clients ####################################
2023-03-21 01:50:21,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:21,109 : [INFO]  Batch number 94 model fetched from the server
2023-03-21 01:50:21,110 : [INFO]  ################ Batch 94: final global model evalution after 1 rounds ################
2023-03-21 01:50:22,882 : [INFO]  Batch 94: Training set : loss - 0.55, accuracy - 0.74, recall - 0.92, AUC - 0.92, F1 - 0.78, precision - 0.67, training time - -2.0 seconds
2023-03-21 01:50:22,882 : [INFO]  Batch 94: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.88, AUC - 0.86, F1 - 0.75, precision - 0.66
2023-03-21 01:50:22,960 : [INFO]  Batch 95 initialized 
2023-03-21 01:50:23,407 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:23,719 : [INFO]  ------------------------- Batch 95 training: round 1 -------------------------
2023-03-21 01:50:26,874 : [INFO]  ------------------------- Batch 95, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:26,879 : [INFO]  Batch 95: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:26,880 : [INFO]  Batch 95, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:26,880 : [INFO]  ____________________________________ Batch 95: round 1 finished ____________________________________
2023-03-21 01:50:26,881 : [INFO]  #################################### Batch 95: sent the final model to clients ####################################
2023-03-21 01:50:26,881 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:26,884 : [INFO]  Batch number 95 model fetched from the server
2023-03-21 01:50:26,884 : [INFO]  ################ Batch 95: final global model evalution after 1 rounds ################
2023-03-21 01:50:28,709 : [INFO]  Batch 95: Training set : loss - 0.55, accuracy - 0.77, recall - 0.93, AUC - 0.92, F1 - 0.8, precision - 0.7, training time - -3.0 seconds
2023-03-21 01:50:28,709 : [INFO]  Batch 95: Testing set : loss - 0.58, accuracy - 0.68, recall - 0.89, AUC - 0.85, F1 - 0.74, precision - 0.63
2023-03-21 01:50:28,792 : [INFO]  Batch 96 initialized 
2023-03-21 01:50:29,321 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:29,679 : [INFO]  ------------------------- Batch 96 training: round 1 -------------------------
2023-03-21 01:50:33,201 : [INFO]  ------------------------- Batch 96, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:33,207 : [INFO]  Batch 96: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:33,208 : [INFO]  Batch 96, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:33,208 : [INFO]  ____________________________________ Batch 96: round 1 finished ____________________________________
2023-03-21 01:50:33,208 : [INFO]  #################################### Batch 96: sent the final model to clients ####################################
2023-03-21 01:50:33,221 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:33,225 : [INFO]  Batch number 96 model fetched from the server
2023-03-21 01:50:33,225 : [INFO]  ################ Batch 96: final global model evalution after 1 rounds ################
2023-03-21 01:50:35,418 : [INFO]  Batch 96: Training set : loss - 0.55, accuracy - 0.76, recall - 0.98, AUC - 0.94, F1 - 0.8, precision - 0.68, training time - -4.0 seconds
2023-03-21 01:50:35,418 : [INFO]  Batch 96: Testing set : loss - 0.57, accuracy - 0.7, recall - 0.91, AUC - 0.89, F1 - 0.75, precision - 0.64
2023-03-21 01:50:35,523 : [INFO]  Batch 97 initialized 
2023-03-21 01:50:35,950 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:36,244 : [INFO]  ------------------------- Batch 97 training: round 1 -------------------------
2023-03-21 01:50:38,232 : [INFO]  ------------------------- Batch 97, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:38,234 : [INFO]  Batch 97: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:38,235 : [INFO]  Batch 97, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:38,235 : [INFO]  ____________________________________ Batch 97: round 1 finished ____________________________________
2023-03-21 01:50:38,235 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:38,235 : [INFO]  #################################### Batch 97: sent the final model to clients ####################################
2023-03-21 01:50:38,236 : [INFO]  Batch number 97 model fetched from the server
2023-03-21 01:50:38,236 : [INFO]  ################ Batch 97: final global model evalution after 1 rounds ################
2023-03-21 01:50:39,096 : [INFO]  Batch 97: Training set : loss - 0.57, accuracy - 0.73, recall - 0.88, AUC - 0.86, F1 - 0.76, precision - 0.68, training time - -2.0 seconds
2023-03-21 01:50:39,096 : [INFO]  Batch 97: Testing set : loss - 0.59, accuracy - 0.68, recall - 0.87, AUC - 0.84, F1 - 0.73, precision - 0.63
2023-03-21 01:50:39,157 : [INFO]  Batch 98 initialized 
2023-03-21 01:50:39,486 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:39,782 : [INFO]  ------------------------- Batch 98 training: round 1 -------------------------
2023-03-21 01:50:42,964 : [INFO]  ------------------------- Batch 98, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:42,967 : [INFO]  Batch 98: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:42,967 : [INFO]  Batch 98, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:42,967 : [INFO]  ____________________________________ Batch 98: round 1 finished ____________________________________
2023-03-21 01:50:42,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:42,967 : [INFO]  #################################### Batch 98: sent the final model to clients ####################################
2023-03-21 01:50:42,969 : [INFO]  Batch number 98 model fetched from the server
2023-03-21 01:50:42,969 : [INFO]  ################ Batch 98: final global model evalution after 1 rounds ################
2023-03-21 01:50:44,740 : [INFO]  Batch 98: Training set : loss - 0.56, accuracy - 0.74, recall - 0.89, AUC - 0.9, F1 - 0.77, precision - 0.68, training time - -3.0 seconds
2023-03-21 01:50:44,740 : [INFO]  Batch 98: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.87, AUC - 0.85, F1 - 0.74, precision - 0.64
2023-03-21 01:50:44,849 : [INFO]  Batch 99 initialized 
2023-03-21 01:50:45,430 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:45,755 : [INFO]  ------------------------- Batch 99 training: round 1 -------------------------
2023-03-21 01:50:49,241 : [INFO]  ------------------------- Batch 99, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:49,245 : [INFO]  Batch 99: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:49,246 : [INFO]  Batch 99, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:49,246 : [INFO]  ____________________________________ Batch 99: round 1 finished ____________________________________
2023-03-21 01:50:49,246 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:49,246 : [INFO]  #################################### Batch 99: sent the final model to clients ####################################
2023-03-21 01:50:49,249 : [INFO]  Batch number 99 model fetched from the server
2023-03-21 01:50:49,249 : [INFO]  ################ Batch 99: final global model evalution after 1 rounds ################
2023-03-21 01:50:50,313 : [INFO]  Batch 99: Training set : loss - 0.55, accuracy - 0.75, recall - 0.9, AUC - 0.89, F1 - 0.78, precision - 0.69, training time - -3.0 seconds
2023-03-21 01:50:50,314 : [INFO]  Batch 99: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.87, AUC - 0.88, F1 - 0.76, precision - 0.68
2023-03-21 01:50:50,429 : [INFO]  Batch 100 initialized 
2023-03-21 01:50:50,757 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:51,066 : [INFO]  ------------------------- Batch 100 training: round 1 -------------------------
2023-03-21 01:50:54,255 : [INFO]  ------------------------- Batch 100, round 1: Sent local model to the server -------------------------
2023-03-21 01:50:54,258 : [INFO]  Batch 100: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:50:54,259 : [INFO]  Batch 100, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:50:54,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:50:54,259 : [INFO]  ____________________________________ Batch 100: round 1 finished ____________________________________
2023-03-21 01:50:54,259 : [INFO]  #################################### Batch 100: sent the final model to clients ####################################
2023-03-21 01:50:54,261 : [INFO]  Batch number 100 model fetched from the server
2023-03-21 01:50:54,261 : [INFO]  ################ Batch 100: final global model evalution after 1 rounds ################
2023-03-21 01:50:55,701 : [INFO]  Batch 100: Training set : loss - 0.58, accuracy - 0.73, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.67, training time - -3.0 seconds
2023-03-21 01:50:55,701 : [INFO]  Batch 100: Testing set : loss - 0.58, accuracy - 0.7, recall - 0.89, AUC - 0.85, F1 - 0.75, precision - 0.65
2023-03-21 01:50:55,816 : [INFO]  Batch 101 initialized 
2023-03-21 01:50:56,282 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-21 01:50:56,740 : [INFO]  ------------------------- Batch 101 training: round 1 -------------------------
2023-03-21 01:51:00,087 : [INFO]  ------------------------- Batch 101, round 1: Sent local model to the server -------------------------
2023-03-21 01:51:00,089 : [INFO]  Batch 101: recieved model from client-0 at 127.0.0.1:53366
2023-03-21 01:51:00,089 : [INFO]  Batch 101, round 1: aggregated global model sent to client-0 at 127.0.0.1:53366
2023-03-21 01:51:00,089 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-21 01:51:00,089 : [INFO]  ____________________________________ Batch 101: round 1 finished ____________________________________
2023-03-21 01:51:00,089 : [INFO]  #################################### Batch 101: sent the final model to clients ####################################
2023-03-21 01:51:00,090 : [INFO]  Distributed training done!
2023-03-21 01:51:00,090 : [INFO]  Training report : Total elapsed time 505.0 seconds, graph ID 1, number of clients 1, training rounds 1, rounds 1, number of timestamps 101
2023-03-21 01:51:00,091 : [INFO]  Batch number 101 model fetched from the server
2023-03-21 01:51:00,091 : [INFO]  ################ Batch 101: final global model evalution after 1 rounds ################
2023-03-21 01:51:01,369 : [INFO]  Batch 101: Training set : loss - 0.53, accuracy - 0.77, recall - 0.91, AUC - 0.93, F1 - 0.8, precision - 0.71, training time - -3.0 seconds
2023-03-21 01:51:01,369 : [INFO]  Batch 101: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.89, AUC - 0.87, F1 - 0.76, precision - 0.66
2023-03-22 09:48:08,858 : [WARNING]  ####################################### New Training Session #######################################
2023-03-22 09:48:08,858 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 1, number of timestamps 101
2023-03-22 09:48:15,519 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-22 09:48:15,519 : [INFO]  Client started, graph name elliptic, graph ID 1, partition ID 0, training epochs 1, epochs 2
2023-03-22 09:48:17,541 : [INFO]  Model initialized for training
2023-03-22 09:48:30,429 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:48:30,682 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 09:48:35,153 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:48:35,292 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-22 09:48:35,293 : [INFO]  Connected to the server
2023-03-22 09:48:35,293 : [INFO]  Accepted new connection at 127.0.0.1:57638
2023-03-22 09:48:35,296 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:57638
2023-03-22 09:48:35,386 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 09:48:35,386 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:48:35,392 : [INFO]  ################################## Initial model training started ##################################
2023-03-22 09:48:35,393 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-22 09:49:00,577 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-22 09:49:00,580 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:49:00,581 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:49:00,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:49:00,581 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-22 09:49:00,581 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-22 09:49:00,583 : [INFO]  ################ Initial trained model: Final global model evalution after 1 rounds ################
2023-03-22 09:49:43,571 : [INFO]  Initially trained model: Training set : loss - 0.62, accuracy - 0.67, recall - 0.84, AUC - 0.76, F1 - 0.72, precision - 0.63, training time - -25.0 seconds
2023-03-22 09:49:43,572 : [INFO]  Initially trained model: Testing set : loss - 0.63, accuracy - 0.65, recall - 0.83, AUC - 0.74, F1 - 0.7, precision - 0.61
2023-03-22 09:49:43,671 : [INFO]  Batch 1 initialized 
2023-03-22 09:49:44,122 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:49:44,237 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-22 09:49:44,237 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-22 09:49:46,845 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-22 09:49:46,848 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:49:46,849 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:49:46,849 : [INFO]  ____________________________________ Batch 1: round 1 finished ____________________________________
2023-03-22 09:49:46,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:49:46,849 : [INFO]  #################################### Batch 1: sent the final model to clients ####################################
2023-03-22 09:49:46,851 : [INFO]  Batch number 1 model fetched from the server
2023-03-22 09:49:46,851 : [INFO]  ################ Batch 1: final global model evalution after 1 rounds ################
2023-03-22 09:49:48,088 : [INFO]  Batch 1: Training set : loss - 0.6, accuracy - 0.67, recall - 0.89, AUC - 0.82, F1 - 0.73, precision - 0.62, training time - -3.0 seconds
2023-03-22 09:49:48,089 : [INFO]  Batch 1: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.84, AUC - 0.81, F1 - 0.72, precision - 0.63
2023-03-22 09:49:48,197 : [INFO]  Batch 2 initialized 
2023-03-22 09:49:48,647 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:49:48,866 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-22 09:49:51,448 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-22 09:49:51,451 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:49:51,451 : [INFO]  Batch 2, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:49:51,451 : [INFO]  ____________________________________ Batch 2: round 1 finished ____________________________________
2023-03-22 09:49:51,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:49:51,451 : [INFO]  #################################### Batch 2: sent the final model to clients ####################################
2023-03-22 09:49:51,453 : [INFO]  Batch number 2 model fetched from the server
2023-03-22 09:49:51,453 : [INFO]  ################ Batch 2: final global model evalution after 1 rounds ################
2023-03-22 09:49:52,685 : [INFO]  Batch 2: Training set : loss - 0.59, accuracy - 0.73, recall - 0.9, AUC - 0.82, F1 - 0.77, precision - 0.67, training time - -3.0 seconds
2023-03-22 09:49:52,685 : [INFO]  Batch 2: Testing set : loss - 0.6, accuracy - 0.71, recall - 0.89, AUC - 0.82, F1 - 0.75, precision - 0.65
2023-03-22 09:49:52,796 : [INFO]  Batch 3 initialized 
2023-03-22 09:49:53,246 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:49:53,417 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-22 09:49:56,705 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-22 09:49:56,709 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:49:56,710 : [INFO]  Batch 3, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:49:56,710 : [INFO]  ____________________________________ Batch 3: round 1 finished ____________________________________
2023-03-22 09:49:56,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:49:56,710 : [INFO]  #################################### Batch 3: sent the final model to clients ####################################
2023-03-22 09:49:56,713 : [INFO]  Batch number 3 model fetched from the server
2023-03-22 09:49:56,713 : [INFO]  ################ Batch 3: final global model evalution after 1 rounds ################
2023-03-22 09:49:58,353 : [INFO]  Batch 3: Training set : loss - 0.58, accuracy - 0.7, recall - 0.89, AUC - 0.84, F1 - 0.75, precision - 0.65, training time - -3.0 seconds
2023-03-22 09:49:58,353 : [INFO]  Batch 3: Testing set : loss - 0.6, accuracy - 0.69, recall - 0.91, AUC - 0.8, F1 - 0.75, precision - 0.63
2023-03-22 09:49:58,484 : [INFO]  Batch 4 initialized 
2023-03-22 09:49:58,918 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:49:59,096 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-22 09:50:01,640 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:01,643 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:01,644 : [INFO]  Batch 4, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:01,644 : [INFO]  ____________________________________ Batch 4: round 1 finished ____________________________________
2023-03-22 09:50:01,644 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:01,644 : [INFO]  #################################### Batch 4: sent the final model to clients ####################################
2023-03-22 09:50:01,646 : [INFO]  Batch number 4 model fetched from the server
2023-03-22 09:50:01,646 : [INFO]  ################ Batch 4: final global model evalution after 1 rounds ################
2023-03-22 09:50:03,224 : [INFO]  Batch 4: Training set : loss - 0.57, accuracy - 0.76, recall - 0.93, AUC - 0.86, F1 - 0.8, precision - 0.69, training time - -3.0 seconds
2023-03-22 09:50:03,224 : [INFO]  Batch 4: Testing set : loss - 0.6, accuracy - 0.72, recall - 0.91, AUC - 0.81, F1 - 0.77, precision - 0.66
2023-03-22 09:50:03,353 : [INFO]  Batch 5 initialized 
2023-03-22 09:50:03,916 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:04,139 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-22 09:50:07,149 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:07,154 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:07,155 : [INFO]  Batch 5, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:07,155 : [INFO]  ____________________________________ Batch 5: round 1 finished ____________________________________
2023-03-22 09:50:07,155 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:07,155 : [INFO]  #################################### Batch 5: sent the final model to clients ####################################
2023-03-22 09:50:07,158 : [INFO]  Batch number 5 model fetched from the server
2023-03-22 09:50:07,158 : [INFO]  ################ Batch 5: final global model evalution after 1 rounds ################
2023-03-22 09:50:08,379 : [INFO]  Batch 5: Training set : loss - 0.58, accuracy - 0.72, recall - 0.91, AUC - 0.85, F1 - 0.76, precision - 0.66, training time - -3.0 seconds
2023-03-22 09:50:08,379 : [INFO]  Batch 5: Testing set : loss - 0.6, accuracy - 0.71, recall - 0.89, AUC - 0.8, F1 - 0.76, precision - 0.65
2023-03-22 09:50:08,516 : [INFO]  Batch 6 initialized 
2023-03-22 09:50:08,945 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:09,125 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-22 09:50:11,783 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:11,786 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:11,787 : [INFO]  Batch 6, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:11,787 : [INFO]  ____________________________________ Batch 6: round 1 finished ____________________________________
2023-03-22 09:50:11,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:11,788 : [INFO]  #################################### Batch 6: sent the final model to clients ####################################
2023-03-22 09:50:11,790 : [INFO]  Batch number 6 model fetched from the server
2023-03-22 09:50:11,790 : [INFO]  ################ Batch 6: final global model evalution after 1 rounds ################
2023-03-22 09:50:13,268 : [INFO]  Batch 6: Training set : loss - 0.6, accuracy - 0.71, recall - 0.89, AUC - 0.81, F1 - 0.75, precision - 0.65, training time - -3.0 seconds
2023-03-22 09:50:13,268 : [INFO]  Batch 6: Testing set : loss - 0.62, accuracy - 0.68, recall - 0.9, AUC - 0.77, F1 - 0.74, precision - 0.62
2023-03-22 09:50:13,367 : [INFO]  Batch 7 initialized 
2023-03-22 09:50:13,827 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:14,026 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-22 09:50:17,170 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:17,174 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:17,174 : [INFO]  Batch 7, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:17,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:17,174 : [INFO]  ____________________________________ Batch 7: round 1 finished ____________________________________
2023-03-22 09:50:17,174 : [INFO]  #################################### Batch 7: sent the final model to clients ####################################
2023-03-22 09:50:17,177 : [INFO]  Batch number 7 model fetched from the server
2023-03-22 09:50:17,177 : [INFO]  ################ Batch 7: final global model evalution after 1 rounds ################
2023-03-22 09:50:18,692 : [INFO]  Batch 7: Training set : loss - 0.6, accuracy - 0.69, recall - 0.93, AUC - 0.81, F1 - 0.75, precision - 0.63, training time - -3.0 seconds
2023-03-22 09:50:18,692 : [INFO]  Batch 7: Testing set : loss - 0.6, accuracy - 0.72, recall - 0.95, AUC - 0.83, F1 - 0.77, precision - 0.65
2023-03-22 09:50:18,805 : [INFO]  Batch 8 initialized 
2023-03-22 09:50:20,294 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:20,557 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-22 09:50:23,893 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:23,897 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:23,898 : [INFO]  Batch 8, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:23,898 : [INFO]  ____________________________________ Batch 8: round 1 finished ____________________________________
2023-03-22 09:50:23,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:23,898 : [INFO]  #################################### Batch 8: sent the final model to clients ####################################
2023-03-22 09:50:23,900 : [INFO]  Batch number 8 model fetched from the server
2023-03-22 09:50:23,900 : [INFO]  ################ Batch 8: final global model evalution after 1 rounds ################
2023-03-22 09:50:25,421 : [INFO]  Batch 8: Training set : loss - 0.57, accuracy - 0.74, recall - 0.97, AUC - 0.89, F1 - 0.79, precision - 0.67, training time - -3.0 seconds
2023-03-22 09:50:25,421 : [INFO]  Batch 8: Testing set : loss - 0.62, accuracy - 0.67, recall - 0.92, AUC - 0.79, F1 - 0.73, precision - 0.61
2023-03-22 09:50:25,509 : [INFO]  Batch 9 initialized 
2023-03-22 09:50:26,277 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:26,540 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-22 09:50:30,019 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:30,022 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:30,023 : [INFO]  Batch 9, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:30,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:30,023 : [INFO]  ____________________________________ Batch 9: round 1 finished ____________________________________
2023-03-22 09:50:30,023 : [INFO]  #################################### Batch 9: sent the final model to clients ####################################
2023-03-22 09:50:30,025 : [INFO]  Batch number 9 model fetched from the server
2023-03-22 09:50:30,025 : [INFO]  ################ Batch 9: final global model evalution after 1 rounds ################
2023-03-22 09:50:31,340 : [INFO]  Batch 9: Training set : loss - 0.58, accuracy - 0.74, recall - 0.98, AUC - 0.88, F1 - 0.79, precision - 0.67, training time - -3.0 seconds
2023-03-22 09:50:31,341 : [INFO]  Batch 9: Testing set : loss - 0.6, accuracy - 0.73, recall - 0.91, AUC - 0.82, F1 - 0.77, precision - 0.67
2023-03-22 09:50:31,435 : [INFO]  Batch 10 initialized 
2023-03-22 09:50:31,862 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:32,045 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-22 09:50:35,344 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:35,348 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:35,348 : [INFO]  Batch 10, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:35,348 : [INFO]  ____________________________________ Batch 10: round 1 finished ____________________________________
2023-03-22 09:50:35,348 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:35,348 : [INFO]  #################################### Batch 10: sent the final model to clients ####################################
2023-03-22 09:50:35,351 : [INFO]  Batch number 10 model fetched from the server
2023-03-22 09:50:35,351 : [INFO]  ################ Batch 10: final global model evalution after 1 rounds ################
2023-03-22 09:50:36,588 : [INFO]  Batch 10: Training set : loss - 0.57, accuracy - 0.75, recall - 0.98, AUC - 0.88, F1 - 0.8, precision - 0.67, training time - -3.0 seconds
2023-03-22 09:50:36,588 : [INFO]  Batch 10: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.9, AUC - 0.8, F1 - 0.74, precision - 0.62
2023-03-22 09:50:36,681 : [INFO]  Batch 11 initialized 
2023-03-22 09:50:37,129 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:37,313 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-22 09:50:39,894 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:39,896 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:39,897 : [INFO]  Batch 11, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:39,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:39,897 : [INFO]  ____________________________________ Batch 11: round 1 finished ____________________________________
2023-03-22 09:50:39,897 : [INFO]  #################################### Batch 11: sent the final model to clients ####################################
2023-03-22 09:50:39,899 : [INFO]  Batch number 11 model fetched from the server
2023-03-22 09:50:39,899 : [INFO]  ################ Batch 11: final global model evalution after 1 rounds ################
2023-03-22 09:50:41,100 : [INFO]  Batch 11: Training set : loss - 0.58, accuracy - 0.73, recall - 0.92, AUC - 0.87, F1 - 0.78, precision - 0.67, training time - -3.0 seconds
2023-03-22 09:50:41,100 : [INFO]  Batch 11: Testing set : loss - 0.6, accuracy - 0.67, recall - 0.89, AUC - 0.82, F1 - 0.73, precision - 0.62
2023-03-22 09:50:41,172 : [INFO]  Batch 12 initialized 
2023-03-22 09:50:41,587 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:41,774 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-22 09:50:44,517 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:44,520 : [INFO]  Batch 12: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:44,521 : [INFO]  Batch 12, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:44,521 : [INFO]  ____________________________________ Batch 12: round 1 finished ____________________________________
2023-03-22 09:50:44,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:44,521 : [INFO]  #################################### Batch 12: sent the final model to clients ####################################
2023-03-22 09:50:44,523 : [INFO]  Batch number 12 model fetched from the server
2023-03-22 09:50:44,523 : [INFO]  ################ Batch 12: final global model evalution after 1 rounds ################
2023-03-22 09:50:46,011 : [INFO]  Batch 12: Training set : loss - 0.6, accuracy - 0.7, recall - 0.87, AUC - 0.81, F1 - 0.74, precision - 0.65, training time - -3.0 seconds
2023-03-22 09:50:46,011 : [INFO]  Batch 12: Testing set : loss - 0.62, accuracy - 0.66, recall - 0.91, AUC - 0.77, F1 - 0.73, precision - 0.6
2023-03-22 09:50:46,111 : [INFO]  Batch 13 initialized 
2023-03-22 09:50:46,553 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:46,748 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-22 09:50:49,324 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:49,328 : [INFO]  Batch 13: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:49,328 : [INFO]  Batch 13, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:49,328 : [INFO]  ____________________________________ Batch 13: round 1 finished ____________________________________
2023-03-22 09:50:49,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:49,328 : [INFO]  #################################### Batch 13: sent the final model to clients ####################################
2023-03-22 09:50:49,330 : [INFO]  Batch number 13 model fetched from the server
2023-03-22 09:50:49,330 : [INFO]  ################ Batch 13: final global model evalution after 1 rounds ################
2023-03-22 09:50:50,635 : [INFO]  Batch 13: Training set : loss - 0.58, accuracy - 0.72, recall - 0.93, AUC - 0.87, F1 - 0.77, precision - 0.66, training time - -3.0 seconds
2023-03-22 09:50:50,636 : [INFO]  Batch 13: Testing set : loss - 0.61, accuracy - 0.67, recall - 0.85, AUC - 0.78, F1 - 0.72, precision - 0.62
2023-03-22 09:50:50,717 : [INFO]  Batch 14 initialized 
2023-03-22 09:50:51,143 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:51,332 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-22 09:50:53,896 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:53,900 : [INFO]  Batch 14: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:53,900 : [INFO]  Batch 14, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:53,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:53,900 : [INFO]  ____________________________________ Batch 14: round 1 finished ____________________________________
2023-03-22 09:50:53,901 : [INFO]  #################################### Batch 14: sent the final model to clients ####################################
2023-03-22 09:50:53,903 : [INFO]  Batch number 14 model fetched from the server
2023-03-22 09:50:53,903 : [INFO]  ################ Batch 14: final global model evalution after 1 rounds ################
2023-03-22 09:50:55,152 : [INFO]  Batch 14: Training set : loss - 0.57, accuracy - 0.72, recall - 0.95, AUC - 0.88, F1 - 0.77, precision - 0.65, training time - -3.0 seconds
2023-03-22 09:50:55,152 : [INFO]  Batch 14: Testing set : loss - 0.59, accuracy - 0.71, recall - 0.9, AUC - 0.83, F1 - 0.76, precision - 0.65
2023-03-22 09:50:55,227 : [INFO]  Batch 15 initialized 
2023-03-22 09:50:55,646 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:50:55,836 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-22 09:50:58,425 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-22 09:50:58,428 : [INFO]  Batch 15: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:50:58,429 : [INFO]  Batch 15, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:50:58,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:50:58,429 : [INFO]  ____________________________________ Batch 15: round 1 finished ____________________________________
2023-03-22 09:50:58,429 : [INFO]  #################################### Batch 15: sent the final model to clients ####################################
2023-03-22 09:50:58,431 : [INFO]  Batch number 15 model fetched from the server
2023-03-22 09:50:58,431 : [INFO]  ################ Batch 15: final global model evalution after 1 rounds ################
2023-03-22 09:50:59,696 : [INFO]  Batch 15: Training set : loss - 0.57, accuracy - 0.77, recall - 0.95, AUC - 0.86, F1 - 0.8, precision - 0.7, training time - -3.0 seconds
2023-03-22 09:50:59,697 : [INFO]  Batch 15: Testing set : loss - 0.64, accuracy - 0.64, recall - 0.89, AUC - 0.74, F1 - 0.71, precision - 0.59
2023-03-22 09:50:59,817 : [INFO]  Batch 16 initialized 
2023-03-22 09:51:00,242 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:00,436 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-22 09:51:02,992 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:02,995 : [INFO]  Batch 16: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:02,996 : [INFO]  Batch 16, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:02,996 : [INFO]  ____________________________________ Batch 16: round 1 finished ____________________________________
2023-03-22 09:51:02,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:02,996 : [INFO]  #################################### Batch 16: sent the final model to clients ####################################
2023-03-22 09:51:02,998 : [INFO]  Batch number 16 model fetched from the server
2023-03-22 09:51:02,998 : [INFO]  ################ Batch 16: final global model evalution after 1 rounds ################
2023-03-22 09:51:04,273 : [INFO]  Batch 16: Training set : loss - 0.56, accuracy - 0.76, recall - 0.97, AUC - 0.89, F1 - 0.8, precision - 0.68, training time - -3.0 seconds
2023-03-22 09:51:04,273 : [INFO]  Batch 16: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.91, AUC - 0.84, F1 - 0.75, precision - 0.64
2023-03-22 09:51:04,386 : [INFO]  Batch 17 initialized 
2023-03-22 09:51:04,810 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:05,007 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-22 09:51:07,578 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:07,581 : [INFO]  Batch 17: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:07,582 : [INFO]  Batch 17, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:07,582 : [INFO]  ____________________________________ Batch 17: round 1 finished ____________________________________
2023-03-22 09:51:07,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:07,582 : [INFO]  #################################### Batch 17: sent the final model to clients ####################################
2023-03-22 09:51:07,584 : [INFO]  Batch number 17 model fetched from the server
2023-03-22 09:51:07,584 : [INFO]  ################ Batch 17: final global model evalution after 1 rounds ################
2023-03-22 09:51:08,851 : [INFO]  Batch 17: Training set : loss - 0.56, accuracy - 0.76, recall - 0.91, AUC - 0.87, F1 - 0.79, precision - 0.7, training time - -3.0 seconds
2023-03-22 09:51:08,851 : [INFO]  Batch 17: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.93, AUC - 0.85, F1 - 0.75, precision - 0.63
2023-03-22 09:51:08,978 : [INFO]  Batch 18 initialized 
2023-03-22 09:51:09,413 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:09,617 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-22 09:51:12,208 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:12,211 : [INFO]  Batch 18: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:12,211 : [INFO]  Batch 18, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:12,211 : [INFO]  ____________________________________ Batch 18: round 1 finished ____________________________________
2023-03-22 09:51:12,211 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:12,212 : [INFO]  #################################### Batch 18: sent the final model to clients ####################################
2023-03-22 09:51:12,213 : [INFO]  Batch number 18 model fetched from the server
2023-03-22 09:51:12,213 : [INFO]  ################ Batch 18: final global model evalution after 1 rounds ################
2023-03-22 09:51:13,424 : [INFO]  Batch 18: Training set : loss - 0.57, accuracy - 0.75, recall - 0.96, AUC - 0.87, F1 - 0.79, precision - 0.68, training time - -3.0 seconds
2023-03-22 09:51:13,424 : [INFO]  Batch 18: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.95, AUC - 0.85, F1 - 0.76, precision - 0.64
2023-03-22 09:51:13,559 : [INFO]  Batch 19 initialized 
2023-03-22 09:51:13,986 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:14,188 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-22 09:51:16,812 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:16,815 : [INFO]  Batch 19: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:16,816 : [INFO]  Batch 19, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:16,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:16,816 : [INFO]  ____________________________________ Batch 19: round 1 finished ____________________________________
2023-03-22 09:51:16,816 : [INFO]  #################################### Batch 19: sent the final model to clients ####################################
2023-03-22 09:51:16,818 : [INFO]  Batch number 19 model fetched from the server
2023-03-22 09:51:16,818 : [INFO]  ################ Batch 19: final global model evalution after 1 rounds ################
2023-03-22 09:51:18,111 : [INFO]  Batch 19: Training set : loss - 0.61, accuracy - 0.72, recall - 0.96, AUC - 0.8, F1 - 0.78, precision - 0.65, training time - -3.0 seconds
2023-03-22 09:51:18,111 : [INFO]  Batch 19: Testing set : loss - 0.64, accuracy - 0.64, recall - 0.9, AUC - 0.74, F1 - 0.72, precision - 0.59
2023-03-22 09:51:18,193 : [INFO]  Batch 20 initialized 
2023-03-22 09:51:18,612 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:18,812 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-22 09:51:21,358 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:21,361 : [INFO]  Batch 20: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:21,362 : [INFO]  Batch 20, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:21,362 : [INFO]  ____________________________________ Batch 20: round 1 finished ____________________________________
2023-03-22 09:51:21,362 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:21,362 : [INFO]  #################################### Batch 20: sent the final model to clients ####################################
2023-03-22 09:51:21,364 : [INFO]  Batch number 20 model fetched from the server
2023-03-22 09:51:21,364 : [INFO]  ################ Batch 20: final global model evalution after 1 rounds ################
2023-03-22 09:51:22,598 : [INFO]  Batch 20: Training set : loss - 0.57, accuracy - 0.71, recall - 0.95, AUC - 0.89, F1 - 0.76, precision - 0.64, training time - -3.0 seconds
2023-03-22 09:51:22,598 : [INFO]  Batch 20: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.89, AUC - 0.81, F1 - 0.75, precision - 0.65
2023-03-22 09:51:22,722 : [INFO]  Batch 21 initialized 
2023-03-22 09:51:23,163 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:23,367 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-22 09:51:26,040 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:26,043 : [INFO]  Batch 21: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:26,044 : [INFO]  Batch 21, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:26,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:26,044 : [INFO]  ____________________________________ Batch 21: round 1 finished ____________________________________
2023-03-22 09:51:26,044 : [INFO]  #################################### Batch 21: sent the final model to clients ####################################
2023-03-22 09:51:26,046 : [INFO]  Batch number 21 model fetched from the server
2023-03-22 09:51:26,046 : [INFO]  ################ Batch 21: final global model evalution after 1 rounds ################
2023-03-22 09:51:27,289 : [INFO]  Batch 21: Training set : loss - 0.58, accuracy - 0.72, recall - 0.92, AUC - 0.84, F1 - 0.77, precision - 0.65, training time - -3.0 seconds
2023-03-22 09:51:27,290 : [INFO]  Batch 21: Testing set : loss - 0.61, accuracy - 0.68, recall - 0.88, AUC - 0.79, F1 - 0.73, precision - 0.63
2023-03-22 09:51:27,406 : [INFO]  Batch 22 initialized 
2023-03-22 09:51:27,833 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:28,037 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-22 09:51:30,637 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:30,640 : [INFO]  Batch 22: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:30,640 : [INFO]  Batch 22, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:30,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:30,640 : [INFO]  ____________________________________ Batch 22: round 1 finished ____________________________________
2023-03-22 09:51:30,640 : [INFO]  #################################### Batch 22: sent the final model to clients ####################################
2023-03-22 09:51:30,642 : [INFO]  Batch number 22 model fetched from the server
2023-03-22 09:51:30,642 : [INFO]  ################ Batch 22: final global model evalution after 1 rounds ################
2023-03-22 09:51:31,971 : [INFO]  Batch 22: Training set : loss - 0.58, accuracy - 0.75, recall - 0.93, AUC - 0.86, F1 - 0.79, precision - 0.68, training time - -3.0 seconds
2023-03-22 09:51:31,971 : [INFO]  Batch 22: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.9, AUC - 0.83, F1 - 0.75, precision - 0.64
2023-03-22 09:51:32,077 : [INFO]  Batch 23 initialized 
2023-03-22 09:51:32,511 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:32,714 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-22 09:51:35,284 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:35,288 : [INFO]  Batch 23: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:35,288 : [INFO]  Batch 23, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:35,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:35,288 : [INFO]  ____________________________________ Batch 23: round 1 finished ____________________________________
2023-03-22 09:51:35,289 : [INFO]  #################################### Batch 23: sent the final model to clients ####################################
2023-03-22 09:51:35,291 : [INFO]  Batch number 23 model fetched from the server
2023-03-22 09:51:35,291 : [INFO]  ################ Batch 23: final global model evalution after 1 rounds ################
2023-03-22 09:51:36,582 : [INFO]  Batch 23: Training set : loss - 0.56, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.79, precision - 0.68, training time - -3.0 seconds
2023-03-22 09:51:36,582 : [INFO]  Batch 23: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.89, AUC - 0.86, F1 - 0.75, precision - 0.65
2023-03-22 09:51:36,701 : [INFO]  Batch 24 initialized 
2023-03-22 09:51:37,168 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:37,375 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-22 09:51:40,049 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:40,053 : [INFO]  Batch 24: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:40,053 : [INFO]  Batch 24, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:40,053 : [INFO]  ____________________________________ Batch 24: round 1 finished ____________________________________
2023-03-22 09:51:40,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:40,053 : [INFO]  #################################### Batch 24: sent the final model to clients ####################################
2023-03-22 09:51:40,055 : [INFO]  Batch number 24 model fetched from the server
2023-03-22 09:51:40,055 : [INFO]  ################ Batch 24: final global model evalution after 1 rounds ################
2023-03-22 09:51:41,453 : [INFO]  Batch 24: Training set : loss - 0.55, accuracy - 0.77, recall - 0.91, AUC - 0.89, F1 - 0.8, precision - 0.71, training time - -3.0 seconds
2023-03-22 09:51:41,453 : [INFO]  Batch 24: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.92, AUC - 0.84, F1 - 0.75, precision - 0.64
2023-03-22 09:51:41,654 : [INFO]  Batch 25 initialized 
2023-03-22 09:51:42,099 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:42,307 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-22 09:51:45,383 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:45,386 : [INFO]  Batch 25: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:45,386 : [INFO]  Batch 25, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:45,386 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:45,386 : [INFO]  ____________________________________ Batch 25: round 1 finished ____________________________________
2023-03-22 09:51:45,386 : [INFO]  #################################### Batch 25: sent the final model to clients ####################################
2023-03-22 09:51:45,388 : [INFO]  Batch number 25 model fetched from the server
2023-03-22 09:51:45,388 : [INFO]  ################ Batch 25: final global model evalution after 1 rounds ################
2023-03-22 09:51:46,836 : [INFO]  Batch 25: Training set : loss - 0.59, accuracy - 0.68, recall - 0.89, AUC - 0.83, F1 - 0.74, precision - 0.63, training time - -3.0 seconds
2023-03-22 09:51:46,837 : [INFO]  Batch 25: Testing set : loss - 0.64, accuracy - 0.61, recall - 0.81, AUC - 0.72, F1 - 0.68, precision - 0.58
2023-03-22 09:51:46,955 : [INFO]  Batch 26 initialized 
2023-03-22 09:51:47,466 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:47,685 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-22 09:51:50,655 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:50,658 : [INFO]  Batch 26: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:50,658 : [INFO]  Batch 26, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:50,658 : [INFO]  ____________________________________ Batch 26: round 1 finished ____________________________________
2023-03-22 09:51:50,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:50,658 : [INFO]  #################################### Batch 26: sent the final model to clients ####################################
2023-03-22 09:51:50,660 : [INFO]  Batch number 26 model fetched from the server
2023-03-22 09:51:50,660 : [INFO]  ################ Batch 26: final global model evalution after 1 rounds ################
2023-03-22 09:51:52,043 : [INFO]  Batch 26: Training set : loss - 0.59, accuracy - 0.7, recall - 0.88, AUC - 0.82, F1 - 0.75, precision - 0.65, training time - -3.0 seconds
2023-03-22 09:51:52,043 : [INFO]  Batch 26: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.89, AUC - 0.83, F1 - 0.75, precision - 0.65
2023-03-22 09:51:52,152 : [INFO]  Batch 27 initialized 
2023-03-22 09:51:52,694 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:52,910 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-22 09:51:56,420 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-22 09:51:56,427 : [INFO]  Batch 27: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:51:56,428 : [INFO]  Batch 27, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:51:56,428 : [INFO]  ____________________________________ Batch 27: round 1 finished ____________________________________
2023-03-22 09:51:56,429 : [INFO]  #################################### Batch 27: sent the final model to clients ####################################
2023-03-22 09:51:56,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:51:56,434 : [INFO]  Batch number 27 model fetched from the server
2023-03-22 09:51:56,435 : [INFO]  ################ Batch 27: final global model evalution after 1 rounds ################
2023-03-22 09:51:58,721 : [INFO]  Batch 27: Training set : loss - 0.57, accuracy - 0.71, recall - 0.97, AUC - 0.89, F1 - 0.77, precision - 0.64, training time - -4.0 seconds
2023-03-22 09:51:58,722 : [INFO]  Batch 27: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.93, AUC - 0.87, F1 - 0.76, precision - 0.64
2023-03-22 09:51:58,807 : [INFO]  Batch 28 initialized 
2023-03-22 09:51:59,341 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:51:59,539 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-22 09:52:05,517 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-22 09:52:05,525 : [INFO]  Batch 28: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:52:05,526 : [INFO]  Batch 28, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:52:05,526 : [INFO]  ____________________________________ Batch 28: round 1 finished ____________________________________
2023-03-22 09:52:05,526 : [INFO]  #################################### Batch 28: sent the final model to clients ####################################
2023-03-22 09:52:05,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:52:05,531 : [INFO]  Batch number 28 model fetched from the server
2023-03-22 09:52:05,531 : [INFO]  ################ Batch 28: final global model evalution after 1 rounds ################
2023-03-22 09:52:08,242 : [INFO]  Batch 28: Training set : loss - 0.6, accuracy - 0.71, recall - 0.92, AUC - 0.81, F1 - 0.76, precision - 0.64, training time - -6.0 seconds
2023-03-22 09:52:08,243 : [INFO]  Batch 28: Testing set : loss - 0.6, accuracy - 0.7, recall - 0.96, AUC - 0.84, F1 - 0.76, precision - 0.63
2023-03-22 09:52:08,462 : [INFO]  Batch 29 initialized 
2023-03-22 09:52:09,224 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:52:09,437 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-22 09:52:12,986 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-22 09:52:12,991 : [INFO]  Batch 29: recieved model from client-0 at 127.0.0.1:57638
2023-03-22 09:52:12,991 : [INFO]  Batch 29, round 1: aggregated global model sent to client-0 at 127.0.0.1:57638
2023-03-22 09:52:12,992 : [INFO]  ____________________________________ Batch 29: round 1 finished ____________________________________
2023-03-22 09:52:12,992 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 09:52:12,992 : [INFO]  #################################### Batch 29: sent the final model to clients ####################################
2023-03-22 09:52:12,994 : [INFO]  Batch number 29 model fetched from the server
2023-03-22 09:52:12,994 : [INFO]  ################ Batch 29: final global model evalution after 1 rounds ################
2023-03-22 09:52:14,414 : [INFO]  Batch 29: Training set : loss - 0.61, accuracy - 0.72, recall - 0.9, AUC - 0.8, F1 - 0.76, precision - 0.66, training time - -4.0 seconds
2023-03-22 09:52:14,414 : [INFO]  Batch 29: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.93, AUC - 0.84, F1 - 0.75, precision - 0.63
2023-03-22 09:52:14,636 : [INFO]  Batch 30 initialized 
2023-03-22 09:52:15,135 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 09:52:15,362 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-22 09:52:17,152 : [ERROR]  Client-0 closed connection at 127.0.0.1:57638
2023-03-22 20:17:27,413 : [WARNING]  ####################################### New Training Session #######################################
2023-03-22 20:17:27,413 : [INFO]  Server started , graph ID 1, number of clients 4, number of rounds 5, number of timestamps 47
2023-03-22 20:17:29,502 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:17:29,655 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 20:19:31,839 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-22 20:19:31,839 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-22 20:19:31,844 : [INFO]  Model initialized for training
2023-03-22 20:19:33,573 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:19:33,595 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-22 20:19:33,595 : [INFO]  Connected to the server
2023-03-22 20:19:33,595 : [INFO]  Accepted new connection at 127.0.0.1:35252
2023-03-22 20:19:33,596 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:35252
2023-03-22 20:19:33,679 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 20:19:33,679 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:19:33,686 : [INFO]  ################################## Initial model training started ##################################
2023-03-22 20:19:33,686 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-22 20:20:00,632 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-22 20:20:00,634 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:20:22,035 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-22 20:20:22,035 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 1, training epochs 10, epochs 4
2023-03-22 20:20:22,048 : [INFO]  Model initialized for training
2023-03-22 20:20:23,788 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:20:23,810 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-22 20:20:23,810 : [INFO]  Connected to the server
2023-03-22 20:20:23,810 : [INFO]  Accepted new connection at 127.0.0.1:40914
2023-03-22 20:20:23,811 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:40914
2023-03-22 20:20:23,897 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 20:20:23,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:20:23,904 : [INFO]  ################################## Initial model training started ##################################
2023-03-22 20:20:23,904 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-22 20:20:27,207 : [WARNING]  ####################################### New Training Session: Client 2 #######################################
2023-03-22 20:20:27,208 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 2, training epochs 10, epochs 4
2023-03-22 20:20:27,213 : [INFO]  Model initialized for training
2023-03-22 20:20:29,233 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:20:29,260 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-22 20:20:29,261 : [INFO]  Connected to the server
2023-03-22 20:20:29,261 : [INFO]  Accepted new connection at 127.0.0.1:39802
2023-03-22 20:20:29,261 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:39802
2023-03-22 20:20:29,342 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 20:20:29,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:20:29,347 : [INFO]  ################################## Initial model training started ##################################
2023-03-22 20:20:29,347 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-22 20:20:31,577 : [WARNING]  ####################################### New Training Session: Client 3 #######################################
2023-03-22 20:20:31,578 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 3, training epochs 10, epochs 4
2023-03-22 20:20:31,588 : [INFO]  Model initialized for training
2023-03-22 20:20:33,763 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:20:33,799 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-22 20:20:33,800 : [INFO]  Connected to the server
2023-03-22 20:20:33,800 : [INFO]  Accepted new connection at 127.0.0.1:39816
2023-03-22 20:20:33,800 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:39816
2023-03-22 20:20:33,879 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 20:20:33,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:20:33,883 : [INFO]  ################################## Initial model training started ##################################
2023-03-22 20:20:33,884 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-22 20:21:02,838 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-22 20:21:02,841 : [INFO]  Initial training: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:21:08,817 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-22 20:21:08,821 : [INFO]  Initial training: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:21:12,196 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-22 20:21:12,198 : [INFO]  Initial training: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:21:12,203 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:21:12,204 : [INFO]  Initial training round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:21:12,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:21:12,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:21:12,204 : [INFO]  Initial training round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:21:12,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:21:12,204 : [INFO]  Initial training round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:21:12,205 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-22 20:21:12,205 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:21:12,208 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-22 20:21:12,208 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-22 20:21:12,208 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-22 20:21:12,209 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-22 20:22:09,095 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-22 20:22:09,103 : [INFO]  Initial training: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:22:11,568 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-22 20:22:11,571 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:22:11,976 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-22 20:22:11,979 : [INFO]  Initial training: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:22:12,509 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-22 20:22:12,513 : [INFO]  Initial training: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:22:12,534 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:22:12,534 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:22:12,534 : [INFO]  Initial training round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:22:12,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:22:12,535 : [INFO]  Initial training round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:22:12,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:22:12,535 : [INFO]  Initial training round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:22:12,536 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-22 20:22:12,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:22:12,541 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-22 20:22:12,542 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-22 20:22:12,543 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-22 20:22:12,545 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-22 20:23:06,663 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-22 20:23:06,672 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:23:09,481 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-22 20:23:09,484 : [INFO]  Initial training: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:23:10,222 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-22 20:23:10,224 : [INFO]  Initial training: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:23:11,438 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-22 20:23:11,440 : [INFO]  Initial training: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:23:11,445 : [INFO]  Initial training round 3: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:23:11,445 : [INFO]  Initial training round 3: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:23:11,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:23:11,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:23:11,445 : [INFO]  Initial training round 3: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:23:11,445 : [INFO]  Initial training round 3: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:23:11,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:23:11,445 : [INFO]  ____________________________________ Initial training: round 3 finished ____________________________________
2023-03-22 20:23:11,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:23:11,447 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-22 20:23:11,447 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-22 20:23:11,447 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-22 20:23:11,447 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-22 20:24:03,936 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-22 20:24:03,939 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:24:04,372 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-22 20:24:04,376 : [INFO]  Initial training: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:24:04,520 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-22 20:24:04,523 : [INFO]  Initial training: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:24:05,065 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-22 20:24:05,067 : [INFO]  Initial training: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:24:05,072 : [INFO]  Initial training round 4: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:24:05,072 : [INFO]  Initial training round 4: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:24:05,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:24:05,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:24:05,072 : [INFO]  Initial training round 4: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:24:05,072 : [INFO]  Initial training round 4: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:24:05,072 : [INFO]  ____________________________________ Initial training: round 4 finished ____________________________________
2023-03-22 20:24:05,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:24:05,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:24:05,074 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-22 20:24:05,074 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-22 20:24:05,075 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-22 20:24:05,075 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-22 20:24:55,431 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-22 20:24:55,435 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:24:55,965 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-22 20:24:55,968 : [INFO]  Initial training: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:00,026 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-22 20:25:00,029 : [INFO]  Initial training: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:00,541 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-22 20:25:00,543 : [INFO]  Initial training: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:00,548 : [INFO]  Initial training round 5: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:00,548 : [INFO]  Initial training round 5: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:00,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:00,548 : [INFO]  Initial training round 5: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:00,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:00,548 : [INFO]  Initial training round 5: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:00,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:00,549 : [INFO]  ____________________________________ Initial training: round 5 finished ____________________________________
2023-03-22 20:25:00,549 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-22 20:25:00,549 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:00,550 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-22 20:25:00,550 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-22 20:25:00,551 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-22 20:25:00,551 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-22 20:25:11,859 : [INFO]  Initially trained model: Training set : loss - 0.57, accuracy - 0.72, recall - 0.92, AUC - 0.87, F1 - 0.77, precision - 0.66, training time - -271.0 seconds
2023-03-22 20:25:11,859 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.92, AUC - 0.88, F1 - 0.77, precision - 0.66
2023-03-22 20:25:11,865 : [INFO]  Initially trained model: Training set : loss - 0.56, accuracy - 0.73, recall - 0.93, AUC - 0.88, F1 - 0.78, precision - 0.67, training time - -327.0 seconds
2023-03-22 20:25:11,865 : [INFO]  Initially trained model: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.78, precision - 0.67
2023-03-22 20:25:11,872 : [INFO]  Batch 1 initialized 
2023-03-22 20:25:11,873 : [INFO]  Batch 1 initialized 
2023-03-22 20:25:12,288 : [INFO]  Initially trained model: Training set : loss - 0.57, accuracy - 0.73, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.67, training time - -277.0 seconds
2023-03-22 20:25:12,289 : [INFO]  Initially trained model: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.78, precision - 0.68
2023-03-22 20:25:12,301 : [INFO]  Batch 1 initialized 
2023-03-22 20:25:12,411 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:12,492 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:12,508 : [INFO]  Initially trained model: Training set : loss - 0.57, accuracy - 0.72, recall - 0.92, AUC - 0.88, F1 - 0.77, precision - 0.66, training time - -267.0 seconds
2023-03-22 20:25:12,509 : [INFO]  Initially trained model: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.94, AUC - 0.9, F1 - 0.79, precision - 0.68
2023-03-22 20:25:12,515 : [INFO]  Batch 1 initialized 
2023-03-22 20:25:12,547 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-22 20:25:12,548 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-22 20:25:12,621 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-22 20:25:12,622 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-22 20:25:12,850 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:12,981 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-22 20:25:12,981 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-22 20:25:13,038 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:13,165 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-22 20:25:13,166 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-22 20:25:17,331 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:17,334 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:17,408 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:17,413 : [INFO]  Batch 1: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:17,758 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:17,761 : [INFO]  Batch 1: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:17,863 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:17,865 : [INFO]  Batch 1: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:17,866 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:17,866 : [INFO]  Batch 1, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:17,866 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:17,866 : [INFO]  Batch 1, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:17,866 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:17,866 : [INFO]  Batch 1, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:17,866 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:17,866 : [INFO]  ____________________________________ Batch 1: round 1 finished ____________________________________
2023-03-22 20:25:17,866 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:17,868 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-22 20:25:17,868 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-22 20:25:17,869 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-22 20:25:17,869 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-22 20:25:20,148 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:20,152 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:20,229 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:20,232 : [INFO]  Batch 1: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:20,237 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:20,240 : [INFO]  Batch 1: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:20,292 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:20,296 : [INFO]  Batch 1: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:20,297 : [INFO]  Batch 1, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:20,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:20,297 : [INFO]  Batch 1, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:20,298 : [INFO]  Batch 1, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:20,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:20,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:20,298 : [INFO]  Batch 1, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:20,298 : [INFO]  ____________________________________ Batch 1: round 2 finished ____________________________________
2023-03-22 20:25:20,298 : [INFO]  #################################### Batch 1: sent the final model to clients ####################################
2023-03-22 20:25:20,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:20,304 : [INFO]  Batch number 1 model fetched from the server
2023-03-22 20:25:20,304 : [INFO]  Batch number 1 model fetched from the server
2023-03-22 20:25:20,304 : [INFO]  Batch number 1 model fetched from the server
2023-03-22 20:25:20,304 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-22 20:25:20,304 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-22 20:25:20,304 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-22 20:25:20,304 : [INFO]  Batch number 1 model fetched from the server
2023-03-22 20:25:20,304 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-22 20:25:22,275 : [INFO]  Batch 1: Training set : loss - 0.51, accuracy - 0.79, recall - 0.98, AUC - 0.93, F1 - 0.83, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:25:22,275 : [INFO]  Batch 1: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.91, AUC - 0.88, F1 - 0.78, precision - 0.67
2023-03-22 20:25:22,278 : [INFO]  Batch 1: Training set : loss - 0.57, accuracy - 0.73, recall - 0.96, AUC - 0.86, F1 - 0.78, precision - 0.66, training time - -8.0 seconds
2023-03-22 20:25:22,278 : [INFO]  Batch 1: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.95, AUC - 0.89, F1 - 0.78, precision - 0.66
2023-03-22 20:25:22,279 : [INFO]  Batch 1: Training set : loss - 0.55, accuracy - 0.75, recall - 0.92, AUC - 0.9, F1 - 0.79, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:25:22,279 : [INFO]  Batch 1: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.89, AUC - 0.87, F1 - 0.75, precision - 0.65
2023-03-22 20:25:22,285 : [INFO]  Batch 2 initialized 
2023-03-22 20:25:22,285 : [INFO]  Batch 2 initialized 
2023-03-22 20:25:22,286 : [INFO]  Batch 2 initialized 
2023-03-22 20:25:22,296 : [INFO]  Batch 1: Training set : loss - 0.54, accuracy - 0.76, recall - 0.9, AUC - 0.9, F1 - 0.79, precision - 0.7, training time - -8.0 seconds
2023-03-22 20:25:22,296 : [INFO]  Batch 1: Testing set : loss - 0.56, accuracy - 0.75, recall - 0.97, AUC - 0.89, F1 - 0.79, precision - 0.67
2023-03-22 20:25:22,301 : [INFO]  Batch 2 initialized 
2023-03-22 20:25:22,793 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:22,800 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:22,840 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:22,844 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:23,076 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-22 20:25:23,079 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-22 20:25:23,115 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-22 20:25:23,117 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-22 20:25:27,706 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:27,710 : [INFO]  Batch 2: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:27,718 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:27,723 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:27,787 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:27,790 : [INFO]  Batch 2: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:27,830 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:27,833 : [INFO]  Batch 2: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:27,834 : [INFO]  Batch 2, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:27,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:27,834 : [INFO]  Batch 2, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:27,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:27,834 : [INFO]  Batch 2, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:27,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:27,834 : [INFO]  Batch 2, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:27,834 : [INFO]  ____________________________________ Batch 2: round 1 finished ____________________________________
2023-03-22 20:25:27,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:27,836 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-22 20:25:27,836 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-22 20:25:27,837 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-22 20:25:27,837 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-22 20:25:30,042 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:30,046 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:30,075 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:30,078 : [INFO]  Batch 2: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:30,125 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:30,129 : [INFO]  Batch 2: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:30,176 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:30,179 : [INFO]  Batch 2: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:30,179 : [INFO]  Batch 2, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:30,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:30,179 : [INFO]  Batch 2, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:30,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:30,180 : [INFO]  Batch 2, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:30,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:30,180 : [INFO]  Batch 2, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:30,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:30,180 : [INFO]  ____________________________________ Batch 2: round 2 finished ____________________________________
2023-03-22 20:25:30,180 : [INFO]  #################################### Batch 2: sent the final model to clients ####################################
2023-03-22 20:25:30,182 : [INFO]  Batch number 2 model fetched from the server
2023-03-22 20:25:30,182 : [INFO]  Batch number 2 model fetched from the server
2023-03-22 20:25:30,182 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-22 20:25:30,182 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-22 20:25:30,183 : [INFO]  Batch number 2 model fetched from the server
2023-03-22 20:25:30,183 : [INFO]  Batch number 2 model fetched from the server
2023-03-22 20:25:30,183 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-22 20:25:30,183 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-22 20:25:32,059 : [INFO]  Batch 2: Training set : loss - 0.55, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:25:32,059 : [INFO]  Batch 2: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.95, AUC - 0.88, F1 - 0.77, precision - 0.65
2023-03-22 20:25:32,071 : [INFO]  Batch 3 initialized 
2023-03-22 20:25:32,095 : [INFO]  Batch 2: Training set : loss - 0.57, accuracy - 0.73, recall - 0.92, AUC - 0.86, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:25:32,095 : [INFO]  Batch 2: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.96, AUC - 0.91, F1 - 0.8, precision - 0.68
2023-03-22 20:25:32,102 : [INFO]  Batch 3 initialized 
2023-03-22 20:25:32,143 : [INFO]  Batch 2: Training set : loss - 0.58, accuracy - 0.71, recall - 0.95, AUC - 0.86, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:25:32,143 : [INFO]  Batch 2: Testing set : loss - 0.54, accuracy - 0.76, recall - 0.97, AUC - 0.92, F1 - 0.8, precision - 0.69
2023-03-22 20:25:32,148 : [INFO]  Batch 2: Training set : loss - 0.56, accuracy - 0.72, recall - 0.96, AUC - 0.92, F1 - 0.78, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:25:32,148 : [INFO]  Batch 2: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.97, AUC - 0.93, F1 - 0.78, precision - 0.65
2023-03-22 20:25:32,149 : [INFO]  Batch 3 initialized 
2023-03-22 20:25:32,158 : [INFO]  Batch 3 initialized 
2023-03-22 20:25:32,611 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:32,636 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:32,690 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:32,698 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:32,883 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-22 20:25:32,915 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-22 20:25:32,959 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-22 20:25:32,963 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-22 20:25:37,533 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:37,536 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:37,550 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:37,554 : [INFO]  Batch 3: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:37,572 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:37,572 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:37,575 : [INFO]  Batch 3: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:37,575 : [INFO]  Batch 3: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:37,576 : [INFO]  Batch 3, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:37,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:37,576 : [INFO]  Batch 3, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:37,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:37,576 : [INFO]  Batch 3, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:37,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:37,576 : [INFO]  Batch 3, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:37,577 : [INFO]  ____________________________________ Batch 3: round 1 finished ____________________________________
2023-03-22 20:25:37,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:37,579 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-22 20:25:37,580 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-22 20:25:37,580 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-22 20:25:37,580 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-22 20:25:39,804 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:39,808 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:39,815 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:39,820 : [INFO]  Batch 3: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:39,899 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:39,902 : [INFO]  Batch 3: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:39,987 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:39,990 : [INFO]  Batch 3: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:39,991 : [INFO]  Batch 3, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:39,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:39,991 : [INFO]  Batch 3, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:39,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:39,991 : [INFO]  Batch 3, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:39,991 : [INFO]  Batch 3, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:39,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:39,991 : [INFO]  ____________________________________ Batch 3: round 2 finished ____________________________________
2023-03-22 20:25:39,991 : [INFO]  #################################### Batch 3: sent the final model to clients ####################################
2023-03-22 20:25:39,992 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:39,993 : [INFO]  Batch number 3 model fetched from the server
2023-03-22 20:25:39,993 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-22 20:25:39,994 : [INFO]  Batch number 3 model fetched from the server
2023-03-22 20:25:39,994 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-22 20:25:39,994 : [INFO]  Batch number 3 model fetched from the server
2023-03-22 20:25:39,994 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-22 20:25:39,995 : [INFO]  Batch number 3 model fetched from the server
2023-03-22 20:25:39,995 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-22 20:25:41,860 : [INFO]  Batch 3: Training set : loss - 0.54, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:25:41,861 : [INFO]  Batch 3: Testing set : loss - 0.53, accuracy - 0.76, recall - 0.99, AUC - 0.94, F1 - 0.81, precision - 0.68
2023-03-22 20:25:41,872 : [INFO]  Batch 4 initialized 
2023-03-22 20:25:41,949 : [INFO]  Batch 3: Training set : loss - 0.56, accuracy - 0.74, recall - 0.95, AUC - 0.87, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:25:41,949 : [INFO]  Batch 3: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.95, AUC - 0.92, F1 - 0.79, precision - 0.67
2023-03-22 20:25:41,956 : [INFO]  Batch 4 initialized 
2023-03-22 20:25:41,972 : [INFO]  Batch 3: Training set : loss - 0.57, accuracy - 0.73, recall - 0.97, AUC - 0.87, F1 - 0.78, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:25:41,973 : [INFO]  Batch 3: Testing set : loss - 0.53, accuracy - 0.76, recall - 0.94, AUC - 0.93, F1 - 0.8, precision - 0.7
2023-03-22 20:25:41,977 : [INFO]  Batch 3: Training set : loss - 0.54, accuracy - 0.74, recall - 0.99, AUC - 0.95, F1 - 0.79, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:25:41,977 : [INFO]  Batch 3: Testing set : loss - 0.6, accuracy - 0.65, recall - 0.9, AUC - 0.83, F1 - 0.72, precision - 0.6
2023-03-22 20:25:41,978 : [INFO]  Batch 4 initialized 
2023-03-22 20:25:41,984 : [INFO]  Batch 4 initialized 
2023-03-22 20:25:42,415 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:42,465 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:42,502 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:42,530 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:42,687 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-22 20:25:42,746 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-22 20:25:42,771 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-22 20:25:42,790 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-22 20:25:47,406 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:47,410 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:47,431 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:47,437 : [INFO]  Batch 4: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:47,490 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:47,494 : [INFO]  Batch 4: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:47,560 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:47,563 : [INFO]  Batch 4: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:47,563 : [INFO]  Batch 4, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:47,564 : [INFO]  Batch 4, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:47,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:47,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:47,564 : [INFO]  Batch 4, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:47,564 : [INFO]  Batch 4, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:47,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:47,564 : [INFO]  ____________________________________ Batch 4: round 1 finished ____________________________________
2023-03-22 20:25:47,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:47,566 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-22 20:25:47,566 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-22 20:25:47,567 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-22 20:25:47,567 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-22 20:25:49,830 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:49,831 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:49,834 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:49,834 : [INFO]  Batch 4: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:49,877 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:49,880 : [INFO]  Batch 4: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:49,978 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:49,981 : [INFO]  Batch 4: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:49,981 : [INFO]  Batch 4, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:49,981 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:49,981 : [INFO]  Batch 4, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:49,981 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:49,982 : [INFO]  Batch 4, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:49,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:49,982 : [INFO]  Batch 4, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:49,982 : [INFO]  ____________________________________ Batch 4: round 2 finished ____________________________________
2023-03-22 20:25:49,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:49,982 : [INFO]  #################################### Batch 4: sent the final model to clients ####################################
2023-03-22 20:25:49,984 : [INFO]  Batch number 4 model fetched from the server
2023-03-22 20:25:49,984 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-22 20:25:49,984 : [INFO]  Batch number 4 model fetched from the server
2023-03-22 20:25:49,984 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-22 20:25:49,984 : [INFO]  Batch number 4 model fetched from the server
2023-03-22 20:25:49,985 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-22 20:25:49,985 : [INFO]  Batch number 4 model fetched from the server
2023-03-22 20:25:49,985 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-22 20:25:51,846 : [INFO]  Batch 4: Training set : loss - 0.56, accuracy - 0.76, recall - 0.96, AUC - 0.89, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:25:51,847 : [INFO]  Batch 4: Testing set : loss - 0.55, accuracy - 0.76, recall - 0.96, AUC - 0.91, F1 - 0.8, precision - 0.69
2023-03-22 20:25:51,857 : [INFO]  Batch 5 initialized 
2023-03-22 20:25:51,951 : [INFO]  Batch 4: Training set : loss - 0.53, accuracy - 0.77, recall - 0.92, AUC - 0.92, F1 - 0.8, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:25:51,951 : [INFO]  Batch 4: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.97, AUC - 0.92, F1 - 0.79, precision - 0.66
2023-03-22 20:25:51,958 : [INFO]  Batch 4: Training set : loss - 0.57, accuracy - 0.7, recall - 0.96, AUC - 0.89, F1 - 0.76, precision - 0.63, training time - -7.0 seconds
2023-03-22 20:25:51,959 : [INFO]  Batch 4: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.96, AUC - 0.92, F1 - 0.78, precision - 0.66
2023-03-22 20:25:51,959 : [INFO]  Batch 4: Training set : loss - 0.56, accuracy - 0.71, recall - 0.95, AUC - 0.89, F1 - 0.77, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:25:51,959 : [INFO]  Batch 4: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.97, AUC - 0.89, F1 - 0.77, precision - 0.63
2023-03-22 20:25:51,960 : [INFO]  Batch 5 initialized 
2023-03-22 20:25:51,965 : [INFO]  Batch 5 initialized 
2023-03-22 20:25:51,966 : [INFO]  Batch 5 initialized 
2023-03-22 20:25:52,371 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:52,475 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:52,477 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:52,477 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:25:52,631 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-22 20:25:52,755 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-22 20:25:52,759 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-22 20:25:52,762 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-22 20:25:57,393 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:57,393 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:57,398 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:57,398 : [INFO]  Batch 5: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:57,451 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:57,454 : [INFO]  Batch 5: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:57,457 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-22 20:25:57,460 : [INFO]  Batch 5: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:57,460 : [INFO]  Batch 5, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:57,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:57,460 : [INFO]  Batch 5, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:57,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:57,461 : [INFO]  Batch 5, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:57,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:57,461 : [INFO]  Batch 5, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:57,461 : [INFO]  ____________________________________ Batch 5: round 1 finished ____________________________________
2023-03-22 20:25:57,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:57,463 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-22 20:25:57,463 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-22 20:25:57,464 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-22 20:25:57,464 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-22 20:25:59,815 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:59,820 : [INFO]  Batch 5: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:25:59,835 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:59,837 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:59,840 : [INFO]  Batch 5: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:25:59,842 : [INFO]  Batch 5: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:25:59,909 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-22 20:25:59,912 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:25:59,912 : [INFO]  Batch 5, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:25:59,912 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:59,912 : [INFO]  Batch 5, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:25:59,913 : [INFO]  Batch 5, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:25:59,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:59,913 : [INFO]  Batch 5, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:25:59,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:59,913 : [INFO]  ____________________________________ Batch 5: round 2 finished ____________________________________
2023-03-22 20:25:59,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:25:59,913 : [INFO]  #################################### Batch 5: sent the final model to clients ####################################
2023-03-22 20:25:59,915 : [INFO]  Batch number 5 model fetched from the server
2023-03-22 20:25:59,915 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-22 20:25:59,915 : [INFO]  Batch number 5 model fetched from the server
2023-03-22 20:25:59,915 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-22 20:25:59,915 : [INFO]  Batch number 5 model fetched from the server
2023-03-22 20:25:59,915 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-22 20:25:59,915 : [INFO]  Batch number 5 model fetched from the server
2023-03-22 20:25:59,916 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-22 20:26:01,834 : [INFO]  Batch 5: Training set : loss - 0.58, accuracy - 0.68, recall - 0.91, AUC - 0.86, F1 - 0.74, precision - 0.62, training time - -7.0 seconds
2023-03-22 20:26:01,835 : [INFO]  Batch 5: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.95, AUC - 0.94, F1 - 0.8, precision - 0.68
2023-03-22 20:26:01,840 : [INFO]  Batch 6 initialized 
2023-03-22 20:26:01,859 : [INFO]  Batch 5: Training set : loss - 0.55, accuracy - 0.76, recall - 0.95, AUC - 0.92, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:26:01,860 : [INFO]  Batch 5: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.94, AUC - 0.9, F1 - 0.78, precision - 0.67
2023-03-22 20:26:01,866 : [INFO]  Batch 6 initialized 
2023-03-22 20:26:01,924 : [INFO]  Batch 5: Training set : loss - 0.57, accuracy - 0.72, recall - 0.96, AUC - 0.91, F1 - 0.78, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:26:01,924 : [INFO]  Batch 5: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.92, AUC - 0.87, F1 - 0.78, precision - 0.67
2023-03-22 20:26:01,931 : [INFO]  Batch 6 initialized 
2023-03-22 20:26:01,956 : [INFO]  Batch 5: Training set : loss - 0.55, accuracy - 0.76, recall - 0.93, AUC - 0.92, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:26:01,957 : [INFO]  Batch 5: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.92, AUC - 0.9, F1 - 0.78, precision - 0.68
2023-03-22 20:26:01,963 : [INFO]  Batch 6 initialized 
2023-03-22 20:26:02,389 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:02,411 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:02,502 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:02,523 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:02,670 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-22 20:26:02,701 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-22 20:26:02,769 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-22 20:26:02,788 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-22 20:26:07,280 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:07,284 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:07,455 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:07,459 : [INFO]  Batch 6: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:07,469 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:07,473 : [INFO]  Batch 6: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:07,544 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:07,547 : [INFO]  Batch 6: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:07,548 : [INFO]  Batch 6, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:07,548 : [INFO]  Batch 6, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:07,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:07,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:07,548 : [INFO]  Batch 6, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:07,548 : [INFO]  Batch 6, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:07,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:07,548 : [INFO]  ____________________________________ Batch 6: round 1 finished ____________________________________
2023-03-22 20:26:07,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:07,550 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-22 20:26:07,550 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-22 20:26:07,551 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-22 20:26:07,551 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-22 20:26:09,877 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:09,881 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:09,889 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:09,893 : [INFO]  Batch 6: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:09,893 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:09,896 : [INFO]  Batch 6: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:09,928 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:09,931 : [INFO]  Batch 6: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:09,931 : [INFO]  Batch 6, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:09,931 : [INFO]  Batch 6, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:09,931 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:09,932 : [INFO]  Batch 6, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:09,932 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:09,932 : [INFO]  Batch 6, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:09,932 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:09,932 : [INFO]  ____________________________________ Batch 6: round 2 finished ____________________________________
2023-03-22 20:26:09,932 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:09,932 : [INFO]  #################################### Batch 6: sent the final model to clients ####################################
2023-03-22 20:26:09,934 : [INFO]  Batch number 6 model fetched from the server
2023-03-22 20:26:09,934 : [INFO]  Batch number 6 model fetched from the server
2023-03-22 20:26:09,934 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-22 20:26:09,934 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-22 20:26:09,935 : [INFO]  Batch number 6 model fetched from the server
2023-03-22 20:26:09,935 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-22 20:26:09,935 : [INFO]  Batch number 6 model fetched from the server
2023-03-22 20:26:09,935 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-22 20:26:11,864 : [INFO]  Batch 6: Training set : loss - 0.56, accuracy - 0.7, recall - 0.92, AUC - 0.9, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:26:11,864 : [INFO]  Batch 6: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.93, AUC - 0.86, F1 - 0.78, precision - 0.66
2023-03-22 20:26:11,876 : [INFO]  Batch 7 initialized 
2023-03-22 20:26:11,905 : [INFO]  Batch 6: Training set : loss - 0.54, accuracy - 0.75, recall - 0.92, AUC - 0.91, F1 - 0.79, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:26:11,905 : [INFO]  Batch 6: Testing set : loss - 0.55, accuracy - 0.72, recall - 0.92, AUC - 0.9, F1 - 0.77, precision - 0.66
2023-03-22 20:26:11,914 : [INFO]  Batch 7 initialized 
2023-03-22 20:26:11,978 : [INFO]  Batch 6: Training set : loss - 0.55, accuracy - 0.73, recall - 0.9, AUC - 0.89, F1 - 0.77, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:26:11,978 : [INFO]  Batch 6: Testing set : loss - 0.56, accuracy - 0.71, recall - 0.92, AUC - 0.89, F1 - 0.76, precision - 0.65
2023-03-22 20:26:11,985 : [INFO]  Batch 7 initialized 
2023-03-22 20:26:11,991 : [INFO]  Batch 6: Training set : loss - 0.54, accuracy - 0.76, recall - 0.97, AUC - 0.92, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:26:11,991 : [INFO]  Batch 6: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.91, AUC - 0.9, F1 - 0.76, precision - 0.65
2023-03-22 20:26:11,996 : [INFO]  Batch 7 initialized 
2023-03-22 20:26:12,396 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:12,433 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:12,523 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:12,543 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:12,675 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-22 20:26:12,724 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-22 20:26:12,799 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-22 20:26:12,812 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-22 20:26:17,373 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:17,378 : [INFO]  Batch 7: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:17,418 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:17,419 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:17,421 : [INFO]  Batch 7: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:17,422 : [INFO]  Batch 7: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:17,471 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:17,474 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:17,474 : [INFO]  Batch 7, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:17,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:17,474 : [INFO]  Batch 7, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:17,474 : [INFO]  Batch 7, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:17,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:17,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:17,474 : [INFO]  Batch 7, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:17,475 : [INFO]  ____________________________________ Batch 7: round 1 finished ____________________________________
2023-03-22 20:26:17,475 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:17,476 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-22 20:26:17,477 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-22 20:26:17,478 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-22 20:26:17,478 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-22 20:26:19,795 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:19,798 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:19,837 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:19,840 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:19,840 : [INFO]  Batch 7: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:19,843 : [INFO]  Batch 7: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:19,920 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:19,923 : [INFO]  Batch 7: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:19,924 : [INFO]  Batch 7, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:19,924 : [INFO]  Batch 7, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:19,924 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:19,924 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:19,924 : [INFO]  Batch 7, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:19,924 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:19,924 : [INFO]  Batch 7, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:19,924 : [INFO]  ____________________________________ Batch 7: round 2 finished ____________________________________
2023-03-22 20:26:19,924 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:19,924 : [INFO]  #################################### Batch 7: sent the final model to clients ####################################
2023-03-22 20:26:19,926 : [INFO]  Batch number 7 model fetched from the server
2023-03-22 20:26:19,926 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-22 20:26:19,926 : [INFO]  Batch number 7 model fetched from the server
2023-03-22 20:26:19,926 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-22 20:26:19,927 : [INFO]  Batch number 7 model fetched from the server
2023-03-22 20:26:19,927 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-22 20:26:19,927 : [INFO]  Batch number 7 model fetched from the server
2023-03-22 20:26:19,927 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-22 20:26:21,793 : [INFO]  Batch 7: Training set : loss - 0.56, accuracy - 0.71, recall - 0.96, AUC - 0.93, F1 - 0.77, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:26:21,793 : [INFO]  Batch 7: Testing set : loss - 0.56, accuracy - 0.73, recall - 0.95, AUC - 0.9, F1 - 0.78, precision - 0.66
2023-03-22 20:26:21,805 : [INFO]  Batch 8 initialized 
2023-03-22 20:26:21,837 : [INFO]  Batch 7: Training set : loss - 0.57, accuracy - 0.69, recall - 0.95, AUC - 0.92, F1 - 0.75, precision - 0.63, training time - -7.0 seconds
2023-03-22 20:26:21,837 : [INFO]  Batch 7: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.95, AUC - 0.9, F1 - 0.79, precision - 0.67
2023-03-22 20:26:21,841 : [INFO]  Batch 8 initialized 
2023-03-22 20:26:21,860 : [INFO]  Batch 7: Training set : loss - 0.57, accuracy - 0.7, recall - 0.92, AUC - 0.88, F1 - 0.75, precision - 0.63, training time - -7.0 seconds
2023-03-22 20:26:21,860 : [INFO]  Batch 7: Testing set : loss - 0.56, accuracy - 0.73, recall - 0.88, AUC - 0.86, F1 - 0.76, precision - 0.67
2023-03-22 20:26:21,864 : [INFO]  Batch 8 initialized 
2023-03-22 20:26:21,892 : [INFO]  Batch 7: Training set : loss - 0.57, accuracy - 0.7, recall - 0.93, AUC - 0.88, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:26:21,893 : [INFO]  Batch 7: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.94, AUC - 0.89, F1 - 0.78, precision - 0.66
2023-03-22 20:26:21,897 : [INFO]  Batch 8 initialized 
2023-03-22 20:26:22,341 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:22,360 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:22,377 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:22,417 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:22,641 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-22 20:26:22,671 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-22 20:26:22,683 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-22 20:26:22,709 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-22 20:26:27,283 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:27,288 : [INFO]  Batch 8: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:27,352 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:27,355 : [INFO]  Batch 8: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:27,376 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:27,380 : [INFO]  Batch 8: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:27,409 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:27,412 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:27,413 : [INFO]  Batch 8, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:27,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:27,413 : [INFO]  Batch 8, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:27,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:27,413 : [INFO]  Batch 8, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:27,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:27,413 : [INFO]  Batch 8, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:27,413 : [INFO]  ____________________________________ Batch 8: round 1 finished ____________________________________
2023-03-22 20:26:27,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:27,415 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-22 20:26:27,415 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-22 20:26:27,415 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-22 20:26:27,416 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-22 20:26:29,695 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:29,699 : [INFO]  Batch 8: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:29,726 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:29,729 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:29,753 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:29,756 : [INFO]  Batch 8: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:29,790 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:29,793 : [INFO]  Batch 8: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:29,793 : [INFO]  Batch 8, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:29,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:29,793 : [INFO]  Batch 8, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:29,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:29,794 : [INFO]  Batch 8, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:29,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:29,794 : [INFO]  Batch 8, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:29,794 : [INFO]  ____________________________________ Batch 8: round 2 finished ____________________________________
2023-03-22 20:26:29,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:29,794 : [INFO]  #################################### Batch 8: sent the final model to clients ####################################
2023-03-22 20:26:29,796 : [INFO]  Batch number 8 model fetched from the server
2023-03-22 20:26:29,796 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-22 20:26:29,796 : [INFO]  Batch number 8 model fetched from the server
2023-03-22 20:26:29,796 : [INFO]  Batch number 8 model fetched from the server
2023-03-22 20:26:29,796 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-22 20:26:29,796 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-22 20:26:29,796 : [INFO]  Batch number 8 model fetched from the server
2023-03-22 20:26:29,796 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-22 20:26:31,742 : [INFO]  Batch 8: Training set : loss - 0.55, accuracy - 0.76, recall - 0.97, AUC - 0.92, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:26:31,742 : [INFO]  Batch 8: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.94, AUC - 0.87, F1 - 0.77, precision - 0.65
2023-03-22 20:26:31,751 : [INFO]  Batch 9 initialized 
2023-03-22 20:26:31,781 : [INFO]  Batch 8: Training set : loss - 0.58, accuracy - 0.72, recall - 0.97, AUC - 0.87, F1 - 0.77, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:26:31,782 : [INFO]  Batch 8: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.97, AUC - 0.92, F1 - 0.78, precision - 0.65
2023-03-22 20:26:31,786 : [INFO]  Batch 8: Training set : loss - 0.57, accuracy - 0.71, recall - 0.92, AUC - 0.88, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:26:31,786 : [INFO]  Batch 8: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.92, AUC - 0.89, F1 - 0.76, precision - 0.65
2023-03-22 20:26:31,786 : [INFO]  Batch 9 initialized 
2023-03-22 20:26:31,791 : [INFO]  Batch 9 initialized 
2023-03-22 20:26:31,833 : [INFO]  Batch 8: Training set : loss - 0.5, accuracy - 0.77, recall - 0.99, AUC - 0.98, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:26:31,834 : [INFO]  Batch 8: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.94, AUC - 0.91, F1 - 0.78, precision - 0.67
2023-03-22 20:26:31,838 : [INFO]  Batch 9 initialized 
2023-03-22 20:26:32,256 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:32,289 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:32,298 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:32,378 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:32,550 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-22 20:26:32,588 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-22 20:26:32,600 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-22 20:26:32,650 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-22 20:26:37,286 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:37,292 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:37,335 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:37,340 : [INFO]  Batch 9: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:37,361 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:37,364 : [INFO]  Batch 9: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:37,501 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:37,506 : [INFO]  Batch 9: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:37,507 : [INFO]  Batch 9, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:37,507 : [INFO]  Batch 9, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:37,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:37,508 : [INFO]  Batch 9, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:37,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:37,508 : [INFO]  Batch 9, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:37,508 : [INFO]  ____________________________________ Batch 9: round 1 finished ____________________________________
2023-03-22 20:26:37,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:37,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:37,511 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-22 20:26:37,511 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-22 20:26:37,511 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-22 20:26:37,511 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-22 20:26:39,784 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:39,787 : [INFO]  Batch 9: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:39,841 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:39,844 : [INFO]  Batch 9: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:39,869 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:39,873 : [INFO]  Batch 9: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:39,953 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:39,956 : [INFO]  Batch 9: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:39,956 : [INFO]  Batch 9, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:39,956 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:39,957 : [INFO]  Batch 9, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:39,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:39,957 : [INFO]  Batch 9, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:39,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:39,957 : [INFO]  Batch 9, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:39,957 : [INFO]  ____________________________________ Batch 9: round 2 finished ____________________________________
2023-03-22 20:26:39,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:39,957 : [INFO]  #################################### Batch 9: sent the final model to clients ####################################
2023-03-22 20:26:39,960 : [INFO]  Batch number 9 model fetched from the server
2023-03-22 20:26:39,960 : [INFO]  Batch number 9 model fetched from the server
2023-03-22 20:26:39,960 : [INFO]  ################ Batch 9: final global model evalution after 2 rounds ################
2023-03-22 20:26:39,960 : [INFO]  ################ Batch 9: final global model evalution after 2 rounds ################
2023-03-22 20:26:39,960 : [INFO]  Batch number 9 model fetched from the server
2023-03-22 20:26:39,960 : [INFO]  Batch number 9 model fetched from the server
2023-03-22 20:26:39,960 : [INFO]  ################ Batch 9: final global model evalution after 2 rounds ################
2023-03-22 20:26:39,960 : [INFO]  ################ Batch 9: final global model evalution after 2 rounds ################
2023-03-22 20:26:41,919 : [INFO]  Batch 9: Training set : loss - 0.57, accuracy - 0.74, recall - 0.93, AUC - 0.86, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:26:41,919 : [INFO]  Batch 9: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.94, AUC - 0.9, F1 - 0.78, precision - 0.67
2023-03-22 20:26:41,928 : [INFO]  Batch 10 initialized 
2023-03-22 20:26:41,939 : [INFO]  Batch 9: Training set : loss - 0.58, accuracy - 0.7, recall - 0.91, AUC - 0.88, F1 - 0.75, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:26:41,940 : [INFO]  Batch 9: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.94, AUC - 0.89, F1 - 0.77, precision - 0.66
2023-03-22 20:26:41,946 : [INFO]  Batch 10 initialized 
2023-03-22 20:26:42,012 : [INFO]  Batch 9: Training set : loss - 0.57, accuracy - 0.71, recall - 0.9, AUC - 0.89, F1 - 0.75, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:26:42,012 : [INFO]  Batch 9: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.94, AUC - 0.91, F1 - 0.79, precision - 0.68
2023-03-22 20:26:42,021 : [INFO]  Batch 10 initialized 
2023-03-22 20:26:42,119 : [INFO]  Batch 9: Training set : loss - 0.52, accuracy - 0.79, recall - 0.95, AUC - 0.93, F1 - 0.82, precision - 0.73, training time - -7.0 seconds
2023-03-22 20:26:42,119 : [INFO]  Batch 9: Testing set : loss - 0.53, accuracy - 0.76, recall - 0.96, AUC - 0.92, F1 - 0.8, precision - 0.69
2023-03-22 20:26:42,150 : [INFO]  Batch 10 initialized 
2023-03-22 20:26:42,458 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:42,459 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:42,574 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:42,738 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-22 20:26:42,740 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-22 20:26:42,758 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:42,832 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-22 20:26:42,981 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-22 20:26:47,384 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:47,389 : [INFO]  Batch 10: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:47,463 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:47,466 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:47,544 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:47,548 : [INFO]  Batch 10: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:47,689 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:47,691 : [INFO]  Batch 10: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:47,692 : [INFO]  Batch 10, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:47,692 : [INFO]  Batch 10, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:47,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:47,692 : [INFO]  Batch 10, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:47,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:47,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:47,692 : [INFO]  Batch 10, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:47,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:47,692 : [INFO]  ____________________________________ Batch 10: round 1 finished ____________________________________
2023-03-22 20:26:47,694 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-22 20:26:47,694 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-22 20:26:47,694 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-22 20:26:47,694 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-22 20:26:49,987 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:49,992 : [INFO]  Batch 10: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:50,015 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:50,018 : [INFO]  Batch 10: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:50,051 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:50,054 : [INFO]  Batch 10: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:50,073 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:50,076 : [INFO]  Batch 10: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:50,077 : [INFO]  Batch 10, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:50,077 : [INFO]  Batch 10, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:50,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:50,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:50,077 : [INFO]  Batch 10, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:50,077 : [INFO]  Batch 10, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:50,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:50,077 : [INFO]  ____________________________________ Batch 10: round 2 finished ____________________________________
2023-03-22 20:26:50,077 : [INFO]  #################################### Batch 10: sent the final model to clients ####################################
2023-03-22 20:26:50,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:50,079 : [INFO]  Batch number 10 model fetched from the server
2023-03-22 20:26:50,079 : [INFO]  Batch number 10 model fetched from the server
2023-03-22 20:26:50,080 : [INFO]  ################ Batch 10: final global model evalution after 2 rounds ################
2023-03-22 20:26:50,080 : [INFO]  ################ Batch 10: final global model evalution after 2 rounds ################
2023-03-22 20:26:50,080 : [INFO]  Batch number 10 model fetched from the server
2023-03-22 20:26:50,080 : [INFO]  Batch number 10 model fetched from the server
2023-03-22 20:26:50,080 : [INFO]  ################ Batch 10: final global model evalution after 2 rounds ################
2023-03-22 20:26:50,080 : [INFO]  ################ Batch 10: final global model evalution after 2 rounds ################
2023-03-22 20:26:51,936 : [INFO]  Batch 10: Training set : loss - 0.57, accuracy - 0.72, recall - 0.88, AUC - 0.86, F1 - 0.76, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:26:51,936 : [INFO]  Batch 10: Testing set : loss - 0.57, accuracy - 0.69, recall - 0.88, AUC - 0.86, F1 - 0.74, precision - 0.63
2023-03-22 20:26:51,945 : [INFO]  Batch 11 initialized 
2023-03-22 20:26:51,976 : [INFO]  Batch 10: Training set : loss - 0.54, accuracy - 0.74, recall - 0.97, AUC - 0.91, F1 - 0.79, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:26:51,976 : [INFO]  Batch 10: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.98, AUC - 0.9, F1 - 0.79, precision - 0.66
2023-03-22 20:26:51,985 : [INFO]  Batch 11 initialized 
2023-03-22 20:26:52,047 : [INFO]  Batch 10: Training set : loss - 0.55, accuracy - 0.71, recall - 0.91, AUC - 0.9, F1 - 0.76, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:26:52,047 : [INFO]  Batch 10: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.96, AUC - 0.91, F1 - 0.78, precision - 0.65
2023-03-22 20:26:52,054 : [INFO]  Batch 11 initialized 
2023-03-22 20:26:52,062 : [INFO]  Batch 10: Training set : loss - 0.53, accuracy - 0.77, recall - 0.98, AUC - 0.92, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:26:52,063 : [INFO]  Batch 10: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.97, AUC - 0.91, F1 - 0.78, precision - 0.66
2023-03-22 20:26:52,068 : [INFO]  Batch 11 initialized 
2023-03-22 20:26:52,519 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:52,553 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:52,582 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:52,587 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:26:52,823 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-22 20:26:52,877 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-22 20:26:52,903 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-22 20:26:52,902 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-22 20:26:57,586 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:57,590 : [INFO]  Batch 11: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:26:57,639 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:57,643 : [INFO]  Batch 11: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:57,650 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:57,653 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:57,657 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-22 20:26:57,660 : [INFO]  Batch 11: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:26:57,660 : [INFO]  Batch 11, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:26:57,660 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:57,661 : [INFO]  Batch 11, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:26:57,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:57,661 : [INFO]  Batch 11, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:26:57,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:57,661 : [INFO]  Batch 11, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:26:57,661 : [INFO]  ____________________________________ Batch 11: round 1 finished ____________________________________
2023-03-22 20:26:57,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:26:57,663 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-22 20:26:57,663 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-22 20:26:57,663 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-22 20:26:57,663 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-22 20:26:59,955 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:59,961 : [INFO]  Batch 11: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:26:59,968 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:59,971 : [INFO]  Batch 11: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:26:59,987 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-22 20:26:59,990 : [INFO]  Batch 11: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:00,040 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:00,043 : [INFO]  Batch 11: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:00,044 : [INFO]  Batch 11, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:00,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:00,044 : [INFO]  Batch 11, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:00,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:00,044 : [INFO]  Batch 11, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:00,045 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:00,045 : [INFO]  Batch 11, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:00,045 : [INFO]  ____________________________________ Batch 11: round 2 finished ____________________________________
2023-03-22 20:27:00,045 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:00,045 : [INFO]  #################################### Batch 11: sent the final model to clients ####################################
2023-03-22 20:27:00,046 : [INFO]  Batch number 11 model fetched from the server
2023-03-22 20:27:00,047 : [INFO]  ################ Batch 11: final global model evalution after 2 rounds ################
2023-03-22 20:27:00,047 : [INFO]  Batch number 11 model fetched from the server
2023-03-22 20:27:00,047 : [INFO]  ################ Batch 11: final global model evalution after 2 rounds ################
2023-03-22 20:27:00,047 : [INFO]  Batch number 11 model fetched from the server
2023-03-22 20:27:00,047 : [INFO]  ################ Batch 11: final global model evalution after 2 rounds ################
2023-03-22 20:27:00,047 : [INFO]  Batch number 11 model fetched from the server
2023-03-22 20:27:00,047 : [INFO]  ################ Batch 11: final global model evalution after 2 rounds ################
2023-03-22 20:27:01,949 : [INFO]  Batch 11: Training set : loss - 0.54, accuracy - 0.76, recall - 0.97, AUC - 0.9, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:27:01,950 : [INFO]  Batch 11: Testing set : loss - 0.56, accuracy - 0.71, recall - 0.94, AUC - 0.87, F1 - 0.76, precision - 0.64
2023-03-22 20:27:01,962 : [INFO]  Batch 12 initialized 
2023-03-22 20:27:01,966 : [INFO]  Batch 11: Training set : loss - 0.56, accuracy - 0.73, recall - 0.93, AUC - 0.88, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:27:01,967 : [INFO]  Batch 11: Testing set : loss - 0.59, accuracy - 0.68, recall - 0.89, AUC - 0.83, F1 - 0.73, precision - 0.62
2023-03-22 20:27:01,976 : [INFO]  Batch 12 initialized 
2023-03-22 20:27:02,016 : [INFO]  Batch 11: Training set : loss - 0.55, accuracy - 0.76, recall - 0.99, AUC - 0.95, F1 - 0.8, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:27:02,017 : [INFO]  Batch 11: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.92, AUC - 0.86, F1 - 0.77, precision - 0.67
2023-03-22 20:27:02,023 : [INFO]  Batch 12 initialized 
2023-03-22 20:27:02,087 : [INFO]  Batch 11: Training set : loss - 0.52, accuracy - 0.78, recall - 0.96, AUC - 0.94, F1 - 0.81, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:27:02,087 : [INFO]  Batch 11: Testing set : loss - 0.56, accuracy - 0.75, recall - 0.96, AUC - 0.9, F1 - 0.79, precision - 0.67
2023-03-22 20:27:02,097 : [INFO]  Batch 12 initialized 
2023-03-22 20:27:02,477 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:02,497 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:02,532 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:02,659 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:02,776 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-22 20:27:02,799 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-22 20:27:02,840 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-22 20:27:02,922 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-22 20:27:07,367 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:07,372 : [INFO]  Batch 12: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:07,469 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:07,472 : [INFO]  Batch 12: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:07,571 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:07,574 : [INFO]  Batch 12: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:07,649 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:07,652 : [INFO]  Batch 12: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:07,653 : [INFO]  Batch 12, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:07,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:07,653 : [INFO]  Batch 12, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:07,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:07,653 : [INFO]  Batch 12, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:07,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:07,653 : [INFO]  Batch 12, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:07,653 : [INFO]  ____________________________________ Batch 12: round 1 finished ____________________________________
2023-03-22 20:27:07,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:07,655 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-22 20:27:07,656 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-22 20:27:07,656 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-22 20:27:07,657 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-22 20:27:09,930 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:09,935 : [INFO]  Batch 12: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:09,940 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:09,945 : [INFO]  Batch 12: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:09,951 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:09,954 : [INFO]  Batch 12: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:09,974 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:09,977 : [INFO]  Batch 12: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:09,978 : [INFO]  Batch 12, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:09,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:09,978 : [INFO]  Batch 12, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:09,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:09,978 : [INFO]  Batch 12, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:09,978 : [INFO]  Batch 12, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:09,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:09,978 : [INFO]  ____________________________________ Batch 12: round 2 finished ____________________________________
2023-03-22 20:27:09,978 : [INFO]  #################################### Batch 12: sent the final model to clients ####################################
2023-03-22 20:27:09,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:09,980 : [INFO]  Batch number 12 model fetched from the server
2023-03-22 20:27:09,980 : [INFO]  Batch number 12 model fetched from the server
2023-03-22 20:27:09,980 : [INFO]  ################ Batch 12: final global model evalution after 2 rounds ################
2023-03-22 20:27:09,980 : [INFO]  ################ Batch 12: final global model evalution after 2 rounds ################
2023-03-22 20:27:09,982 : [INFO]  Batch number 12 model fetched from the server
2023-03-22 20:27:09,982 : [INFO]  Batch number 12 model fetched from the server
2023-03-22 20:27:09,982 : [INFO]  ################ Batch 12: final global model evalution after 2 rounds ################
2023-03-22 20:27:09,982 : [INFO]  ################ Batch 12: final global model evalution after 2 rounds ################
2023-03-22 20:27:11,899 : [INFO]  Batch 12: Training set : loss - 0.55, accuracy - 0.73, recall - 0.93, AUC - 0.9, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:27:11,899 : [INFO]  Batch 12: Testing set : loss - 0.58, accuracy - 0.69, recall - 0.9, AUC - 0.87, F1 - 0.74, precision - 0.63
2023-03-22 20:27:11,902 : [INFO]  Batch 12: Training set : loss - 0.53, accuracy - 0.8, recall - 0.96, AUC - 0.92, F1 - 0.83, precision - 0.73, training time - -7.0 seconds
2023-03-22 20:27:11,903 : [INFO]  Batch 12: Testing set : loss - 0.53, accuracy - 0.8, recall - 0.97, AUC - 0.91, F1 - 0.83, precision - 0.73
2023-03-22 20:27:11,908 : [INFO]  Batch 13 initialized 
2023-03-22 20:27:11,911 : [INFO]  Batch 13 initialized 
2023-03-22 20:27:11,981 : [INFO]  Batch 12: Training set : loss - 0.57, accuracy - 0.71, recall - 0.93, AUC - 0.89, F1 - 0.76, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:27:11,981 : [INFO]  Batch 12: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.91, AUC - 0.9, F1 - 0.77, precision - 0.67
2023-03-22 20:27:11,986 : [INFO]  Batch 12: Training set : loss - 0.54, accuracy - 0.76, recall - 0.92, AUC - 0.9, F1 - 0.79, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:27:11,987 : [INFO]  Batch 12: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.96, AUC - 0.94, F1 - 0.79, precision - 0.68
2023-03-22 20:27:11,987 : [INFO]  Batch 13 initialized 
2023-03-22 20:27:11,995 : [INFO]  Batch 13 initialized 
2023-03-22 20:27:12,419 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:12,446 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:12,510 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:12,558 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:12,718 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-22 20:27:12,756 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-22 20:27:12,829 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-22 20:27:12,863 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-22 20:27:17,525 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:17,529 : [INFO]  Batch 13: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:17,540 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:17,542 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:17,543 : [INFO]  Batch 13: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:17,546 : [INFO]  Batch 13: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:17,553 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:17,557 : [INFO]  Batch 13: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:17,557 : [INFO]  Batch 13, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:17,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:17,557 : [INFO]  Batch 13, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:17,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:17,558 : [INFO]  Batch 13, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:17,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:17,558 : [INFO]  Batch 13, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:17,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:17,558 : [INFO]  ____________________________________ Batch 13: round 1 finished ____________________________________
2023-03-22 20:27:17,560 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-22 20:27:17,560 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-22 20:27:17,560 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-22 20:27:17,560 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-22 20:27:19,786 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:19,790 : [INFO]  Batch 13: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:19,916 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:19,918 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:19,920 : [INFO]  Batch 13: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:19,921 : [INFO]  Batch 13: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:19,981 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:19,983 : [INFO]  Batch 13: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:19,984 : [INFO]  Batch 13, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:19,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:19,984 : [INFO]  Batch 13, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:19,984 : [INFO]  Batch 13, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:19,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:19,984 : [INFO]  Batch 13, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:19,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:19,984 : [INFO]  ____________________________________ Batch 13: round 2 finished ____________________________________
2023-03-22 20:27:19,984 : [INFO]  #################################### Batch 13: sent the final model to clients ####################################
2023-03-22 20:27:19,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:19,986 : [INFO]  Batch number 13 model fetched from the server
2023-03-22 20:27:19,986 : [INFO]  ################ Batch 13: final global model evalution after 2 rounds ################
2023-03-22 20:27:19,987 : [INFO]  Batch number 13 model fetched from the server
2023-03-22 20:27:19,987 : [INFO]  ################ Batch 13: final global model evalution after 2 rounds ################
2023-03-22 20:27:19,987 : [INFO]  Batch number 13 model fetched from the server
2023-03-22 20:27:19,987 : [INFO]  Batch number 13 model fetched from the server
2023-03-22 20:27:19,988 : [INFO]  ################ Batch 13: final global model evalution after 2 rounds ################
2023-03-22 20:27:19,988 : [INFO]  ################ Batch 13: final global model evalution after 2 rounds ################
2023-03-22 20:27:21,876 : [INFO]  Batch 13: Training set : loss - 0.55, accuracy - 0.72, recall - 0.93, AUC - 0.91, F1 - 0.77, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:27:21,876 : [INFO]  Batch 13: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.92, AUC - 0.9, F1 - 0.77, precision - 0.66
2023-03-22 20:27:21,888 : [INFO]  Batch 14 initialized 
2023-03-22 20:27:21,906 : [INFO]  Batch 13: Training set : loss - 0.54, accuracy - 0.74, recall - 0.93, AUC - 0.92, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:27:21,906 : [INFO]  Batch 13: Testing set : loss - 0.53, accuracy - 0.78, recall - 0.96, AUC - 0.95, F1 - 0.82, precision - 0.71
2023-03-22 20:27:21,911 : [INFO]  Batch 14 initialized 
2023-03-22 20:27:21,955 : [INFO]  Batch 13: Training set : loss - 0.55, accuracy - 0.74, recall - 0.96, AUC - 0.93, F1 - 0.79, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:27:21,956 : [INFO]  Batch 13: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.94, AUC - 0.89, F1 - 0.77, precision - 0.65
2023-03-22 20:27:21,962 : [INFO]  Batch 14 initialized 
2023-03-22 20:27:22,073 : [INFO]  Batch 13: Training set : loss - 0.55, accuracy - 0.74, recall - 0.91, AUC - 0.87, F1 - 0.78, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:27:22,073 : [INFO]  Batch 13: Testing set : loss - 0.58, accuracy - 0.68, recall - 0.91, AUC - 0.86, F1 - 0.74, precision - 0.62
2023-03-22 20:27:22,098 : [INFO]  Batch 14 initialized 
2023-03-22 20:27:22,422 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:22,459 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:22,525 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:22,687 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:22,712 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-22 20:27:22,757 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-22 20:27:22,818 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-22 20:27:22,933 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-22 20:27:27,418 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:27,421 : [INFO]  Batch 14: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:27,447 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:27,450 : [INFO]  Batch 14: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:27,494 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:27,498 : [INFO]  Batch 14: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:27,623 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:27,626 : [INFO]  Batch 14: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:27,626 : [INFO]  Batch 14, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:27,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:27,626 : [INFO]  Batch 14, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:27,626 : [INFO]  Batch 14, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:27,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:27,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:27,627 : [INFO]  Batch 14, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:27,627 : [INFO]  ____________________________________ Batch 14: round 1 finished ____________________________________
2023-03-22 20:27:27,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:27,629 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-22 20:27:27,629 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-22 20:27:27,629 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-22 20:27:27,629 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-22 20:27:29,778 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:29,781 : [INFO]  Batch 14: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:29,903 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:29,906 : [INFO]  Batch 14: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:29,921 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:29,924 : [INFO]  Batch 14: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:30,010 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:30,013 : [INFO]  Batch 14: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:30,013 : [INFO]  Batch 14, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:30,014 : [INFO]  Batch 14, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:30,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:30,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:30,014 : [INFO]  Batch 14, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:30,014 : [INFO]  Batch 14, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:30,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:30,014 : [INFO]  ____________________________________ Batch 14: round 2 finished ____________________________________
2023-03-22 20:27:30,014 : [INFO]  #################################### Batch 14: sent the final model to clients ####################################
2023-03-22 20:27:30,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:30,017 : [INFO]  Batch number 14 model fetched from the server
2023-03-22 20:27:30,017 : [INFO]  Batch number 14 model fetched from the server
2023-03-22 20:27:30,017 : [INFO]  ################ Batch 14: final global model evalution after 2 rounds ################
2023-03-22 20:27:30,017 : [INFO]  ################ Batch 14: final global model evalution after 2 rounds ################
2023-03-22 20:27:30,017 : [INFO]  Batch number 14 model fetched from the server
2023-03-22 20:27:30,017 : [INFO]  ################ Batch 14: final global model evalution after 2 rounds ################
2023-03-22 20:27:30,017 : [INFO]  Batch number 14 model fetched from the server
2023-03-22 20:27:30,017 : [INFO]  ################ Batch 14: final global model evalution after 2 rounds ################
2023-03-22 20:27:31,853 : [INFO]  Batch 14: Training set : loss - 0.56, accuracy - 0.72, recall - 0.91, AUC - 0.9, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:27:31,854 : [INFO]  Batch 14: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.87, AUC - 0.85, F1 - 0.73, precision - 0.63
2023-03-22 20:27:31,864 : [INFO]  Batch 15 initialized 
2023-03-22 20:27:31,894 : [INFO]  Batch 14: Training set : loss - 0.57, accuracy - 0.7, recall - 0.89, AUC - 0.85, F1 - 0.75, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:27:31,894 : [INFO]  Batch 14: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.92, AUC - 0.89, F1 - 0.78, precision - 0.68
2023-03-22 20:27:31,900 : [INFO]  Batch 15 initialized 
2023-03-22 20:27:31,923 : [INFO]  Batch 14: Training set : loss - 0.55, accuracy - 0.76, recall - 0.93, AUC - 0.9, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:27:31,923 : [INFO]  Batch 14: Testing set : loss - 0.54, accuracy - 0.77, recall - 0.96, AUC - 0.93, F1 - 0.81, precision - 0.7
2023-03-22 20:27:31,928 : [INFO]  Batch 15 initialized 
2023-03-22 20:27:32,056 : [INFO]  Batch 14: Training set : loss - 0.56, accuracy - 0.72, recall - 0.88, AUC - 0.87, F1 - 0.76, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:27:32,056 : [INFO]  Batch 14: Testing set : loss - 0.56, accuracy - 0.73, recall - 0.94, AUC - 0.87, F1 - 0.78, precision - 0.66
2023-03-22 20:27:32,066 : [INFO]  Batch 15 initialized 
2023-03-22 20:27:32,400 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:32,460 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:32,464 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:32,662 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:32,682 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-22 20:27:32,769 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-22 20:27:32,770 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-22 20:27:32,920 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-22 20:27:37,394 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:37,397 : [INFO]  Batch 15: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:37,418 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:37,421 : [INFO]  Batch 15: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:37,592 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:37,595 : [INFO]  Batch 15: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:37,660 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:37,663 : [INFO]  Batch 15: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:37,663 : [INFO]  Batch 15, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:37,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:37,664 : [INFO]  Batch 15, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:37,664 : [INFO]  Batch 15, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:37,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:37,664 : [INFO]  Batch 15, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:37,664 : [INFO]  ____________________________________ Batch 15: round 1 finished ____________________________________
2023-03-22 20:27:37,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:37,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:37,666 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-22 20:27:37,666 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-22 20:27:37,667 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-22 20:27:37,667 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-22 20:27:39,942 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:39,948 : [INFO]  Batch 15: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:39,957 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:39,961 : [INFO]  Batch 15: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:39,978 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:39,981 : [INFO]  Batch 15: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:40,036 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:40,039 : [INFO]  Batch 15: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:40,039 : [INFO]  Batch 15, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:40,039 : [INFO]  Batch 15, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:40,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:40,040 : [INFO]  Batch 15, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:40,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:40,040 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:40,040 : [INFO]  Batch 15, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:40,040 : [INFO]  ____________________________________ Batch 15: round 2 finished ____________________________________
2023-03-22 20:27:40,040 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:40,040 : [INFO]  #################################### Batch 15: sent the final model to clients ####################################
2023-03-22 20:27:40,043 : [INFO]  Batch number 15 model fetched from the server
2023-03-22 20:27:40,043 : [INFO]  Batch number 15 model fetched from the server
2023-03-22 20:27:40,043 : [INFO]  Batch number 15 model fetched from the server
2023-03-22 20:27:40,043 : [INFO]  Batch number 15 model fetched from the server
2023-03-22 20:27:40,043 : [INFO]  ################ Batch 15: final global model evalution after 2 rounds ################
2023-03-22 20:27:40,043 : [INFO]  ################ Batch 15: final global model evalution after 2 rounds ################
2023-03-22 20:27:40,043 : [INFO]  ################ Batch 15: final global model evalution after 2 rounds ################
2023-03-22 20:27:40,043 : [INFO]  ################ Batch 15: final global model evalution after 2 rounds ################
2023-03-22 20:27:41,915 : [INFO]  Batch 15: Training set : loss - 0.56, accuracy - 0.71, recall - 0.93, AUC - 0.9, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:27:41,915 : [INFO]  Batch 15: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.95, AUC - 0.91, F1 - 0.77, precision - 0.65
2023-03-22 20:27:41,926 : [INFO]  Batch 16 initialized 
2023-03-22 20:27:41,947 : [INFO]  Batch 15: Training set : loss - 0.54, accuracy - 0.78, recall - 0.93, AUC - 0.9, F1 - 0.81, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:27:41,947 : [INFO]  Batch 15: Testing set : loss - 0.52, accuracy - 0.78, recall - 0.95, AUC - 0.93, F1 - 0.82, precision - 0.71
2023-03-22 20:27:41,954 : [INFO]  Batch 16 initialized 
2023-03-22 20:27:42,019 : [INFO]  Batch 15: Training set : loss - 0.54, accuracy - 0.79, recall - 0.96, AUC - 0.93, F1 - 0.82, precision - 0.72, training time - -7.0 seconds
2023-03-22 20:27:42,019 : [INFO]  Batch 15: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.95, AUC - 0.87, F1 - 0.77, precision - 0.65
2023-03-22 20:27:42,024 : [INFO]  Batch 16 initialized 
2023-03-22 20:27:42,078 : [INFO]  Batch 15: Training set : loss - 0.54, accuracy - 0.78, recall - 0.95, AUC - 0.91, F1 - 0.81, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:27:42,078 : [INFO]  Batch 15: Testing set : loss - 0.56, accuracy - 0.73, recall - 0.96, AUC - 0.91, F1 - 0.78, precision - 0.65
2023-03-22 20:27:42,084 : [INFO]  Batch 16 initialized 
2023-03-22 20:27:42,500 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:42,520 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:42,560 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:42,643 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:42,813 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-22 20:27:42,844 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-22 20:27:42,878 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-22 20:27:42,932 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-22 20:27:47,463 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:47,466 : [INFO]  Batch 16: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:47,538 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:47,542 : [INFO]  Batch 16: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:47,569 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:47,574 : [INFO]  Batch 16: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:47,731 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:47,734 : [INFO]  Batch 16: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:47,735 : [INFO]  Batch 16, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:47,735 : [INFO]  Batch 16, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:47,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:47,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:47,735 : [INFO]  Batch 16, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:47,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:47,735 : [INFO]  Batch 16, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:47,735 : [INFO]  ____________________________________ Batch 16: round 1 finished ____________________________________
2023-03-22 20:27:47,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:47,737 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-22 20:27:47,737 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-22 20:27:47,737 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-22 20:27:47,737 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-22 20:27:49,968 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:49,972 : [INFO]  Batch 16: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:49,979 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:49,982 : [INFO]  Batch 16: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:50,012 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:50,015 : [INFO]  Batch 16: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:50,075 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:50,078 : [INFO]  Batch 16: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:50,079 : [INFO]  Batch 16, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:50,079 : [INFO]  Batch 16, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:50,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:50,079 : [INFO]  Batch 16, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:50,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:50,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:50,079 : [INFO]  Batch 16, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:50,079 : [INFO]  ____________________________________ Batch 16: round 2 finished ____________________________________
2023-03-22 20:27:50,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:50,079 : [INFO]  #################################### Batch 16: sent the final model to clients ####################################
2023-03-22 20:27:50,081 : [INFO]  Batch number 16 model fetched from the server
2023-03-22 20:27:50,081 : [INFO]  ################ Batch 16: final global model evalution after 2 rounds ################
2023-03-22 20:27:50,082 : [INFO]  Batch number 16 model fetched from the server
2023-03-22 20:27:50,082 : [INFO]  ################ Batch 16: final global model evalution after 2 rounds ################
2023-03-22 20:27:50,082 : [INFO]  Batch number 16 model fetched from the server
2023-03-22 20:27:50,082 : [INFO]  Batch number 16 model fetched from the server
2023-03-22 20:27:50,082 : [INFO]  ################ Batch 16: final global model evalution after 2 rounds ################
2023-03-22 20:27:50,082 : [INFO]  ################ Batch 16: final global model evalution after 2 rounds ################
2023-03-22 20:27:51,982 : [INFO]  Batch 16: Training set : loss - 0.56, accuracy - 0.72, recall - 0.97, AUC - 0.91, F1 - 0.78, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:27:51,983 : [INFO]  Batch 16: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.92, AUC - 0.88, F1 - 0.76, precision - 0.65
2023-03-22 20:27:51,992 : [INFO]  Batch 17 initialized 
2023-03-22 20:27:51,999 : [INFO]  Batch 16: Training set : loss - 0.59, accuracy - 0.7, recall - 0.92, AUC - 0.88, F1 - 0.75, precision - 0.63, training time - -7.0 seconds
2023-03-22 20:27:51,999 : [INFO]  Batch 16: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.99, AUC - 0.94, F1 - 0.79, precision - 0.66
2023-03-22 20:27:52,005 : [INFO]  Batch 17 initialized 
2023-03-22 20:27:52,050 : [INFO]  Batch 16: Training set : loss - 0.57, accuracy - 0.73, recall - 0.95, AUC - 0.89, F1 - 0.78, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:27:52,050 : [INFO]  Batch 16: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.87, AUC - 0.87, F1 - 0.76, precision - 0.67
2023-03-22 20:27:52,057 : [INFO]  Batch 17 initialized 
2023-03-22 20:27:52,088 : [INFO]  Batch 16: Training set : loss - 0.54, accuracy - 0.73, recall - 0.96, AUC - 0.93, F1 - 0.78, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:27:52,088 : [INFO]  Batch 16: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.92, AUC - 0.91, F1 - 0.77, precision - 0.66
2023-03-22 20:27:52,096 : [INFO]  Batch 17 initialized 
2023-03-22 20:27:52,501 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:52,521 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:52,640 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:52,693 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:27:52,804 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-22 20:27:52,837 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-22 20:27:52,937 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-22 20:27:52,979 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-22 20:27:57,524 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:57,527 : [INFO]  Batch 17: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:27:57,552 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:57,555 : [INFO]  Batch 17: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:27:57,611 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:57,614 : [INFO]  Batch 17: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:27:57,648 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-22 20:27:57,651 : [INFO]  Batch 17: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:27:57,652 : [INFO]  Batch 17, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:27:57,652 : [INFO]  Batch 17, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:27:57,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:57,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:57,652 : [INFO]  Batch 17, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:27:57,652 : [INFO]  Batch 17, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:27:57,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:57,652 : [INFO]  ____________________________________ Batch 17: round 1 finished ____________________________________
2023-03-22 20:27:57,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:27:57,654 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-22 20:27:57,654 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-22 20:27:57,655 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-22 20:27:57,655 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-22 20:27:59,823 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-22 20:27:59,828 : [INFO]  Batch 17: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:00,008 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:00,012 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:00,013 : [INFO]  Batch 17: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:00,015 : [INFO]  Batch 17: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:00,020 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:00,023 : [INFO]  Batch 17: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:00,024 : [INFO]  Batch 17, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:00,024 : [INFO]  Batch 17, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:00,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:00,024 : [INFO]  Batch 17, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:00,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:00,024 : [INFO]  Batch 17, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:00,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:00,024 : [INFO]  ____________________________________ Batch 17: round 2 finished ____________________________________
2023-03-22 20:28:00,024 : [INFO]  #################################### Batch 17: sent the final model to clients ####################################
2023-03-22 20:28:00,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:00,026 : [INFO]  Batch number 17 model fetched from the server
2023-03-22 20:28:00,026 : [INFO]  ################ Batch 17: final global model evalution after 2 rounds ################
2023-03-22 20:28:00,027 : [INFO]  Batch number 17 model fetched from the server
2023-03-22 20:28:00,027 : [INFO]  ################ Batch 17: final global model evalution after 2 rounds ################
2023-03-22 20:28:00,027 : [INFO]  Batch number 17 model fetched from the server
2023-03-22 20:28:00,027 : [INFO]  Batch number 17 model fetched from the server
2023-03-22 20:28:00,027 : [INFO]  ################ Batch 17: final global model evalution after 2 rounds ################
2023-03-22 20:28:00,027 : [INFO]  ################ Batch 17: final global model evalution after 2 rounds ################
2023-03-22 20:28:01,883 : [INFO]  Batch 17: Training set : loss - 0.55, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.79, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:28:01,883 : [INFO]  Batch 17: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.94, AUC - 0.88, F1 - 0.77, precision - 0.65
2023-03-22 20:28:01,895 : [INFO]  Batch 18 initialized 
2023-03-22 20:28:01,939 : [INFO]  Batch 17: Training set : loss - 0.55, accuracy - 0.74, recall - 0.88, AUC - 0.88, F1 - 0.77, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:28:01,940 : [INFO]  Batch 17: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.88, AUC - 0.85, F1 - 0.76, precision - 0.66
2023-03-22 20:28:01,946 : [INFO]  Batch 18 initialized 
2023-03-22 20:28:01,997 : [INFO]  Batch 17: Training set : loss - 0.58, accuracy - 0.68, recall - 0.91, AUC - 0.88, F1 - 0.74, precision - 0.62, training time - -7.0 seconds
2023-03-22 20:28:01,998 : [INFO]  Batch 17: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.94, AUC - 0.91, F1 - 0.78, precision - 0.67
2023-03-22 20:28:02,002 : [INFO]  Batch 18 initialized 
2023-03-22 20:28:02,029 : [INFO]  Batch 17: Training set : loss - 0.55, accuracy - 0.74, recall - 0.92, AUC - 0.89, F1 - 0.78, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:28:02,029 : [INFO]  Batch 17: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.93, AUC - 0.91, F1 - 0.77, precision - 0.66
2023-03-22 20:28:02,034 : [INFO]  Batch 18 initialized 
2023-03-22 20:28:02,433 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:02,493 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:02,523 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:02,588 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:02,735 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-22 20:28:02,816 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-22 20:28:02,842 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-22 20:28:02,891 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-22 20:28:07,472 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:07,476 : [INFO]  Batch 18: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:07,505 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:07,510 : [INFO]  Batch 18: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:07,586 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:07,589 : [INFO]  Batch 18: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:07,624 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:07,627 : [INFO]  Batch 18: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:07,628 : [INFO]  Batch 18, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:07,628 : [INFO]  Batch 18, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:07,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:07,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:07,628 : [INFO]  Batch 18, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:07,628 : [INFO]  Batch 18, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:07,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:07,628 : [INFO]  ____________________________________ Batch 18: round 1 finished ____________________________________
2023-03-22 20:28:07,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:07,630 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-22 20:28:07,630 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-22 20:28:07,631 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-22 20:28:07,631 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-22 20:28:09,878 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:09,883 : [INFO]  Batch 18: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:09,915 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:09,918 : [INFO]  Batch 18: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:09,949 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:09,952 : [INFO]  Batch 18: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:10,018 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:10,021 : [INFO]  Batch 18: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:10,022 : [INFO]  Batch 18, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:10,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:10,022 : [INFO]  Batch 18, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:10,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:10,022 : [INFO]  Batch 18, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:10,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:10,022 : [INFO]  Batch 18, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:10,023 : [INFO]  ____________________________________ Batch 18: round 2 finished ____________________________________
2023-03-22 20:28:10,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:10,023 : [INFO]  #################################### Batch 18: sent the final model to clients ####################################
2023-03-22 20:28:10,024 : [INFO]  Batch number 18 model fetched from the server
2023-03-22 20:28:10,024 : [INFO]  ################ Batch 18: final global model evalution after 2 rounds ################
2023-03-22 20:28:10,025 : [INFO]  Batch number 18 model fetched from the server
2023-03-22 20:28:10,025 : [INFO]  ################ Batch 18: final global model evalution after 2 rounds ################
2023-03-22 20:28:10,026 : [INFO]  Batch number 18 model fetched from the server
2023-03-22 20:28:10,026 : [INFO]  ################ Batch 18: final global model evalution after 2 rounds ################
2023-03-22 20:28:10,026 : [INFO]  Batch number 18 model fetched from the server
2023-03-22 20:28:10,026 : [INFO]  ################ Batch 18: final global model evalution after 2 rounds ################
2023-03-22 20:28:11,902 : [INFO]  Batch 18: Training set : loss - 0.52, accuracy - 0.78, recall - 0.93, AUC - 0.93, F1 - 0.81, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:28:11,902 : [INFO]  Batch 18: Testing set : loss - 0.55, accuracy - 0.77, recall - 0.99, AUC - 0.91, F1 - 0.81, precision - 0.69
2023-03-22 20:28:11,911 : [INFO]  Batch 19 initialized 
2023-03-22 20:28:11,947 : [INFO]  Batch 18: Training set : loss - 0.59, accuracy - 0.68, recall - 0.92, AUC - 0.86, F1 - 0.75, precision - 0.62, training time - -7.0 seconds
2023-03-22 20:28:11,947 : [INFO]  Batch 18: Testing set : loss - 0.58, accuracy - 0.71, recall - 0.91, AUC - 0.86, F1 - 0.76, precision - 0.65
2023-03-22 20:28:11,953 : [INFO]  Batch 19 initialized 
2023-03-22 20:28:11,994 : [INFO]  Batch 18: Training set : loss - 0.54, accuracy - 0.74, recall - 0.91, AUC - 0.92, F1 - 0.78, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:28:11,994 : [INFO]  Batch 18: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.91, AUC - 0.86, F1 - 0.77, precision - 0.66
2023-03-22 20:28:12,001 : [INFO]  Batch 19 initialized 
2023-03-22 20:28:12,101 : [INFO]  Batch 18: Training set : loss - 0.54, accuracy - 0.73, recall - 0.99, AUC - 0.93, F1 - 0.78, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:28:12,102 : [INFO]  Batch 18: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.92, AUC - 0.91, F1 - 0.77, precision - 0.66
2023-03-22 20:28:12,108 : [INFO]  Batch 19 initialized 
2023-03-22 20:28:12,434 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:12,459 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:12,584 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:12,726 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-22 20:28:12,728 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:12,754 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-22 20:28:12,879 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-22 20:28:12,980 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-22 20:28:17,339 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:17,343 : [INFO]  Batch 19: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:17,440 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:17,445 : [INFO]  Batch 19: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:17,585 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:17,588 : [INFO]  Batch 19: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:17,605 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:17,608 : [INFO]  Batch 19: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:17,609 : [INFO]  Batch 19, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:17,609 : [INFO]  Batch 19, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:17,609 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:17,609 : [INFO]  Batch 19, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:17,609 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:17,609 : [INFO]  Batch 19, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:17,609 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:17,609 : [INFO]  ____________________________________ Batch 19: round 1 finished ____________________________________
2023-03-22 20:28:17,609 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:17,611 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-22 20:28:17,611 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-22 20:28:17,612 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-22 20:28:17,612 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-22 20:28:19,743 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:19,746 : [INFO]  Batch 19: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:19,855 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:19,860 : [INFO]  Batch 19: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:19,897 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:19,901 : [INFO]  Batch 19: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:19,915 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:19,918 : [INFO]  Batch 19: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:19,919 : [INFO]  Batch 19, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:19,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:19,919 : [INFO]  Batch 19, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:19,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:19,919 : [INFO]  Batch 19, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:19,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:19,919 : [INFO]  Batch 19, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:19,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:19,919 : [INFO]  ____________________________________ Batch 19: round 2 finished ____________________________________
2023-03-22 20:28:19,919 : [INFO]  #################################### Batch 19: sent the final model to clients ####################################
2023-03-22 20:28:19,921 : [INFO]  Batch number 19 model fetched from the server
2023-03-22 20:28:19,921 : [INFO]  ################ Batch 19: final global model evalution after 2 rounds ################
2023-03-22 20:28:19,921 : [INFO]  Batch number 19 model fetched from the server
2023-03-22 20:28:19,921 : [INFO]  Batch number 19 model fetched from the server
2023-03-22 20:28:19,921 : [INFO]  Batch number 19 model fetched from the server
2023-03-22 20:28:19,921 : [INFO]  ################ Batch 19: final global model evalution after 2 rounds ################
2023-03-22 20:28:19,921 : [INFO]  ################ Batch 19: final global model evalution after 2 rounds ################
2023-03-22 20:28:19,921 : [INFO]  ################ Batch 19: final global model evalution after 2 rounds ################
2023-03-22 20:28:21,815 : [INFO]  Batch 19: Training set : loss - 0.56, accuracy - 0.73, recall - 0.92, AUC - 0.88, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:28:21,815 : [INFO]  Batch 19: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.92, AUC - 0.9, F1 - 0.78, precision - 0.68
2023-03-22 20:28:21,827 : [INFO]  Batch 20 initialized 
2023-03-22 20:28:21,883 : [INFO]  Batch 19: Training set : loss - 0.53, accuracy - 0.78, recall - 0.97, AUC - 0.93, F1 - 0.82, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:28:21,883 : [INFO]  Batch 19: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.84, AUC - 0.81, F1 - 0.72, precision - 0.63
2023-03-22 20:28:21,893 : [INFO]  Batch 20 initialized 
2023-03-22 20:28:21,944 : [INFO]  Batch 19: Training set : loss - 0.56, accuracy - 0.71, recall - 0.87, AUC - 0.89, F1 - 0.75, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:28:21,944 : [INFO]  Batch 19: Testing set : loss - 0.52, accuracy - 0.78, recall - 0.95, AUC - 0.94, F1 - 0.81, precision - 0.71
2023-03-22 20:28:21,950 : [INFO]  Batch 20 initialized 
2023-03-22 20:28:22,016 : [INFO]  Batch 19: Training set : loss - 0.56, accuracy - 0.73, recall - 0.97, AUC - 0.89, F1 - 0.78, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:28:22,016 : [INFO]  Batch 19: Testing set : loss - 0.55, accuracy - 0.7, recall - 0.98, AUC - 0.93, F1 - 0.77, precision - 0.63
2023-03-22 20:28:22,023 : [INFO]  Batch 20 initialized 
2023-03-22 20:28:22,420 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:22,460 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:22,491 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:22,563 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:22,750 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-22 20:28:22,795 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-22 20:28:22,824 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-22 20:28:22,869 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-22 20:28:27,478 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:27,483 : [INFO]  Batch 20: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:27,512 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:27,515 : [INFO]  Batch 20: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:27,546 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:27,549 : [INFO]  Batch 20: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:27,750 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:27,753 : [INFO]  Batch 20: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:27,753 : [INFO]  Batch 20, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:27,753 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:27,754 : [INFO]  Batch 20, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:27,754 : [INFO]  Batch 20, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:27,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:27,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:27,754 : [INFO]  Batch 20, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:27,754 : [INFO]  ____________________________________ Batch 20: round 1 finished ____________________________________
2023-03-22 20:28:27,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:27,756 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-22 20:28:27,756 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-22 20:28:27,756 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-22 20:28:27,757 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-22 20:28:29,949 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:29,952 : [INFO]  Batch 20: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:30,051 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:30,054 : [INFO]  Batch 20: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:30,081 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:30,084 : [INFO]  Batch 20: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:30,134 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:30,136 : [INFO]  Batch 20: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:30,137 : [INFO]  Batch 20, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:30,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:30,137 : [INFO]  Batch 20, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:30,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:30,137 : [INFO]  Batch 20, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:30,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:30,138 : [INFO]  Batch 20, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:30,138 : [INFO]  ____________________________________ Batch 20: round 2 finished ____________________________________
2023-03-22 20:28:30,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:30,138 : [INFO]  #################################### Batch 20: sent the final model to clients ####################################
2023-03-22 20:28:30,139 : [INFO]  Batch number 20 model fetched from the server
2023-03-22 20:28:30,139 : [INFO]  ################ Batch 20: final global model evalution after 2 rounds ################
2023-03-22 20:28:30,140 : [INFO]  Batch number 20 model fetched from the server
2023-03-22 20:28:30,140 : [INFO]  ################ Batch 20: final global model evalution after 2 rounds ################
2023-03-22 20:28:30,140 : [INFO]  Batch number 20 model fetched from the server
2023-03-22 20:28:30,140 : [INFO]  ################ Batch 20: final global model evalution after 2 rounds ################
2023-03-22 20:28:30,140 : [INFO]  Batch number 20 model fetched from the server
2023-03-22 20:28:30,140 : [INFO]  ################ Batch 20: final global model evalution after 2 rounds ################
2023-03-22 20:28:32,053 : [INFO]  Batch 20: Training set : loss - 0.54, accuracy - 0.76, recall - 0.99, AUC - 0.95, F1 - 0.81, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:28:32,053 : [INFO]  Batch 20: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.97, AUC - 0.92, F1 - 0.79, precision - 0.66
2023-03-22 20:28:32,054 : [INFO]  Batch 20: Training set : loss - 0.56, accuracy - 0.7, recall - 0.93, AUC - 0.93, F1 - 0.75, precision - 0.63, training time - -7.0 seconds
2023-03-22 20:28:32,054 : [INFO]  Batch 20: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.95, AUC - 0.92, F1 - 0.79, precision - 0.67
2023-03-22 20:28:32,063 : [INFO]  Batch 21 initialized 
2023-03-22 20:28:32,064 : [INFO]  Batch 21 initialized 
2023-03-22 20:28:32,092 : [INFO]  Batch 20: Training set : loss - 0.53, accuracy - 0.75, recall - 0.97, AUC - 0.93, F1 - 0.79, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:28:32,093 : [INFO]  Batch 20: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.94, AUC - 0.92, F1 - 0.79, precision - 0.68
2023-03-22 20:28:32,097 : [INFO]  Batch 21 initialized 
2023-03-22 20:28:32,135 : [INFO]  Batch 20: Training set : loss - 0.55, accuracy - 0.72, recall - 0.95, AUC - 0.92, F1 - 0.77, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:28:32,135 : [INFO]  Batch 20: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.87, AUC - 0.89, F1 - 0.76, precision - 0.67
2023-03-22 20:28:32,142 : [INFO]  Batch 21 initialized 
2023-03-22 20:28:32,570 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:32,600 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:32,655 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:32,728 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:32,891 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-22 20:28:32,930 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-22 20:28:32,980 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-22 20:28:33,031 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-22 20:28:37,647 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:37,651 : [INFO]  Batch 21: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:37,736 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:37,739 : [INFO]  Batch 21: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:37,745 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:37,750 : [INFO]  Batch 21: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:37,807 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:37,811 : [INFO]  Batch 21: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:37,811 : [INFO]  Batch 21, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:37,811 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:37,811 : [INFO]  Batch 21, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:37,811 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:37,812 : [INFO]  Batch 21, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:37,812 : [INFO]  Batch 21, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:37,812 : [INFO]  ____________________________________ Batch 21: round 1 finished ____________________________________
2023-03-22 20:28:37,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:37,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:37,814 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-22 20:28:37,814 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-22 20:28:37,815 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-22 20:28:37,816 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-22 20:28:40,115 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:40,119 : [INFO]  Batch 21: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:40,135 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:40,138 : [INFO]  Batch 21: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:40,149 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:40,153 : [INFO]  Batch 21: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:40,166 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:40,169 : [INFO]  Batch 21: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:40,170 : [INFO]  Batch 21, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:40,170 : [INFO]  Batch 21, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:40,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:40,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:40,170 : [INFO]  Batch 21, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:40,171 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:40,171 : [INFO]  Batch 21, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:40,171 : [INFO]  ____________________________________ Batch 21: round 2 finished ____________________________________
2023-03-22 20:28:40,171 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:40,171 : [INFO]  #################################### Batch 21: sent the final model to clients ####################################
2023-03-22 20:28:40,172 : [INFO]  Batch number 21 model fetched from the server
2023-03-22 20:28:40,173 : [INFO]  ################ Batch 21: final global model evalution after 2 rounds ################
2023-03-22 20:28:40,173 : [INFO]  Batch number 21 model fetched from the server
2023-03-22 20:28:40,173 : [INFO]  ################ Batch 21: final global model evalution after 2 rounds ################
2023-03-22 20:28:40,173 : [INFO]  Batch number 21 model fetched from the server
2023-03-22 20:28:40,173 : [INFO]  ################ Batch 21: final global model evalution after 2 rounds ################
2023-03-22 20:28:40,173 : [INFO]  Batch number 21 model fetched from the server
2023-03-22 20:28:40,173 : [INFO]  ################ Batch 21: final global model evalution after 2 rounds ################
2023-03-22 20:28:42,052 : [INFO]  Batch 21: Training set : loss - 0.58, accuracy - 0.7, recall - 0.96, AUC - 0.87, F1 - 0.76, precision - 0.63, training time - -7.0 seconds
2023-03-22 20:28:42,052 : [INFO]  Batch 21: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.94, AUC - 0.85, F1 - 0.77, precision - 0.65
2023-03-22 20:28:42,062 : [INFO]  Batch 22 initialized 
2023-03-22 20:28:42,101 : [INFO]  Batch 21: Training set : loss - 0.56, accuracy - 0.75, recall - 0.95, AUC - 0.87, F1 - 0.79, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:28:42,101 : [INFO]  Batch 21: Testing set : loss - 0.56, accuracy - 0.71, recall - 0.96, AUC - 0.9, F1 - 0.77, precision - 0.64
2023-03-22 20:28:42,106 : [INFO]  Batch 22 initialized 
2023-03-22 20:28:42,144 : [INFO]  Batch 21: Training set : loss - 0.54, accuracy - 0.77, recall - 0.98, AUC - 0.91, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:28:42,144 : [INFO]  Batch 21: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.95, AUC - 0.86, F1 - 0.76, precision - 0.63
2023-03-22 20:28:42,151 : [INFO]  Batch 22 initialized 
2023-03-22 20:28:42,170 : [INFO]  Batch 21: Training set : loss - 0.53, accuracy - 0.77, recall - 0.97, AUC - 0.93, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:28:42,170 : [INFO]  Batch 21: Testing set : loss - 0.54, accuracy - 0.74, recall - 0.98, AUC - 0.94, F1 - 0.79, precision - 0.66
2023-03-22 20:28:42,174 : [INFO]  Batch 22 initialized 
2023-03-22 20:28:42,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:42,667 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:42,704 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:42,709 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:42,878 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-22 20:28:42,994 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-22 20:28:43,034 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-22 20:28:43,044 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-22 20:28:47,629 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:47,634 : [INFO]  Batch 22: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:47,679 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:47,682 : [INFO]  Batch 22: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:47,790 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:47,793 : [INFO]  Batch 22: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:47,804 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:47,808 : [INFO]  Batch 22: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:47,809 : [INFO]  Batch 22, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:47,809 : [INFO]  Batch 22, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:47,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:47,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:47,809 : [INFO]  Batch 22, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:47,809 : [INFO]  Batch 22, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:47,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:47,809 : [INFO]  ____________________________________ Batch 22: round 1 finished ____________________________________
2023-03-22 20:28:47,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:47,811 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-22 20:28:47,812 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-22 20:28:47,812 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-22 20:28:47,812 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-22 20:28:50,027 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:50,033 : [INFO]  Batch 22: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:50,063 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:50,066 : [INFO]  Batch 22: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:50,161 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:50,166 : [INFO]  Batch 22: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:50,205 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-22 20:28:50,208 : [INFO]  Batch 22: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:50,209 : [INFO]  Batch 22, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:50,209 : [INFO]  Batch 22, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:50,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:50,209 : [INFO]  Batch 22, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:50,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:50,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:50,209 : [INFO]  Batch 22, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:50,209 : [INFO]  ____________________________________ Batch 22: round 2 finished ____________________________________
2023-03-22 20:28:50,209 : [INFO]  #################################### Batch 22: sent the final model to clients ####################################
2023-03-22 20:28:50,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:50,211 : [INFO]  Batch number 22 model fetched from the server
2023-03-22 20:28:50,211 : [INFO]  ################ Batch 22: final global model evalution after 2 rounds ################
2023-03-22 20:28:50,212 : [INFO]  Batch number 22 model fetched from the server
2023-03-22 20:28:50,212 : [INFO]  ################ Batch 22: final global model evalution after 2 rounds ################
2023-03-22 20:28:50,212 : [INFO]  Batch number 22 model fetched from the server
2023-03-22 20:28:50,212 : [INFO]  Batch number 22 model fetched from the server
2023-03-22 20:28:50,212 : [INFO]  ################ Batch 22: final global model evalution after 2 rounds ################
2023-03-22 20:28:50,212 : [INFO]  ################ Batch 22: final global model evalution after 2 rounds ################
2023-03-22 20:28:51,994 : [INFO]  Batch 22: Training set : loss - 0.56, accuracy - 0.74, recall - 0.95, AUC - 0.88, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:28:51,994 : [INFO]  Batch 22: Testing set : loss - 0.54, accuracy - 0.76, recall - 0.95, AUC - 0.92, F1 - 0.8, precision - 0.69
2023-03-22 20:28:52,005 : [INFO]  Batch 23 initialized 
2023-03-22 20:28:52,130 : [INFO]  Batch 22: Training set : loss - 0.53, accuracy - 0.77, recall - 0.93, AUC - 0.91, F1 - 0.8, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:28:52,130 : [INFO]  Batch 22: Testing set : loss - 0.57, accuracy - 0.7, recall - 0.92, AUC - 0.88, F1 - 0.76, precision - 0.64
2023-03-22 20:28:52,141 : [INFO]  Batch 23 initialized 
2023-03-22 20:28:52,158 : [INFO]  Batch 22: Training set : loss - 0.55, accuracy - 0.73, recall - 0.93, AUC - 0.92, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:28:52,158 : [INFO]  Batch 22: Training set : loss - 0.55, accuracy - 0.77, recall - 0.98, AUC - 0.92, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:28:52,159 : [INFO]  Batch 22: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.94, AUC - 0.92, F1 - 0.79, precision - 0.68
2023-03-22 20:28:52,159 : [INFO]  Batch 22: Testing set : loss - 0.54, accuracy - 0.78, recall - 0.97, AUC - 0.9, F1 - 0.81, precision - 0.7
2023-03-22 20:28:52,163 : [INFO]  Batch 23 initialized 
2023-03-22 20:28:52,163 : [INFO]  Batch 23 initialized 
2023-03-22 20:28:52,533 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:52,682 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:52,697 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:52,703 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:28:52,815 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-22 20:28:53,010 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-22 20:28:53,027 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-22 20:28:53,034 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-22 20:28:57,602 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:57,605 : [INFO]  Batch 23: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:28:57,708 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:57,711 : [INFO]  Batch 23: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:28:57,745 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:57,748 : [INFO]  Batch 23: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:28:57,811 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-22 20:28:57,814 : [INFO]  Batch 23: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:28:57,815 : [INFO]  Batch 23, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:28:57,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:57,815 : [INFO]  Batch 23, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:28:57,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:57,816 : [INFO]  Batch 23, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:28:57,816 : [INFO]  Batch 23, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:28:57,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:57,816 : [INFO]  ____________________________________ Batch 23: round 1 finished ____________________________________
2023-03-22 20:28:57,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:28:57,819 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-22 20:28:57,819 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-22 20:28:57,820 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-22 20:28:57,820 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-22 20:29:00,038 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:00,041 : [INFO]  Batch 23: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:00,120 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:00,123 : [INFO]  Batch 23: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:00,186 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:00,189 : [INFO]  Batch 23: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:00,215 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:00,218 : [INFO]  Batch 23: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:00,218 : [INFO]  Batch 23, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:00,219 : [INFO]  Batch 23, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:00,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:00,219 : [INFO]  Batch 23, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:00,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:00,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:00,219 : [INFO]  Batch 23, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:00,219 : [INFO]  ____________________________________ Batch 23: round 2 finished ____________________________________
2023-03-22 20:29:00,219 : [INFO]  #################################### Batch 23: sent the final model to clients ####################################
2023-03-22 20:29:00,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:00,222 : [INFO]  Batch number 23 model fetched from the server
2023-03-22 20:29:00,222 : [INFO]  Batch number 23 model fetched from the server
2023-03-22 20:29:00,222 : [INFO]  Batch number 23 model fetched from the server
2023-03-22 20:29:00,222 : [INFO]  ################ Batch 23: final global model evalution after 2 rounds ################
2023-03-22 20:29:00,222 : [INFO]  ################ Batch 23: final global model evalution after 2 rounds ################
2023-03-22 20:29:00,222 : [INFO]  ################ Batch 23: final global model evalution after 2 rounds ################
2023-03-22 20:29:00,222 : [INFO]  Batch number 23 model fetched from the server
2023-03-22 20:29:00,222 : [INFO]  ################ Batch 23: final global model evalution after 2 rounds ################
2023-03-22 20:29:02,091 : [INFO]  Batch 23: Training set : loss - 0.57, accuracy - 0.68, recall - 0.96, AUC - 0.9, F1 - 0.75, precision - 0.62, training time - -7.0 seconds
2023-03-22 20:29:02,091 : [INFO]  Batch 23: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.95, AUC - 0.88, F1 - 0.77, precision - 0.65
2023-03-22 20:29:02,102 : [INFO]  Batch 24 initialized 
2023-03-22 20:29:02,120 : [INFO]  Batch 23: Training set : loss - 0.55, accuracy - 0.74, recall - 0.97, AUC - 0.91, F1 - 0.79, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:29:02,121 : [INFO]  Batch 23: Testing set : loss - 0.53, accuracy - 0.78, recall - 0.98, AUC - 0.93, F1 - 0.82, precision - 0.7
2023-03-22 20:29:02,131 : [INFO]  Batch 24 initialized 
2023-03-22 20:29:02,210 : [INFO]  Batch 23: Training set : loss - 0.57, accuracy - 0.71, recall - 0.89, AUC - 0.88, F1 - 0.75, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:29:02,211 : [INFO]  Batch 23: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.94, AUC - 0.88, F1 - 0.76, precision - 0.64
2023-03-22 20:29:02,215 : [INFO]  Batch 24 initialized 
2023-03-22 20:29:02,253 : [INFO]  Batch 23: Training set : loss - 0.56, accuracy - 0.73, recall - 0.93, AUC - 0.87, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:29:02,254 : [INFO]  Batch 23: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.98, AUC - 0.92, F1 - 0.79, precision - 0.66
2023-03-22 20:29:02,259 : [INFO]  Batch 24 initialized 
2023-03-22 20:29:02,712 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:02,728 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:02,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:02,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:03,060 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-22 20:29:03,085 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-22 20:29:03,093 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-22 20:29:03,123 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-22 20:29:07,777 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:07,780 : [INFO]  Batch 24: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:07,828 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:07,828 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:07,831 : [INFO]  Batch 24: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:07,832 : [INFO]  Batch 24: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:07,899 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:07,902 : [INFO]  Batch 24: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:07,902 : [INFO]  Batch 24, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:07,902 : [INFO]  Batch 24, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:07,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:07,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:07,902 : [INFO]  Batch 24, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:07,902 : [INFO]  Batch 24, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:07,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:07,903 : [INFO]  ____________________________________ Batch 24: round 1 finished ____________________________________
2023-03-22 20:29:07,903 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:07,904 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-22 20:29:07,905 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-22 20:29:07,905 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-22 20:29:07,906 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-22 20:29:10,141 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:10,147 : [INFO]  Batch 24: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:10,199 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:10,203 : [INFO]  Batch 24: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:10,262 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:10,265 : [INFO]  Batch 24: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:10,331 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:10,334 : [INFO]  Batch 24: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:10,334 : [INFO]  Batch 24, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:10,334 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:10,334 : [INFO]  Batch 24, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:10,334 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:10,334 : [INFO]  Batch 24, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:10,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:10,335 : [INFO]  Batch 24, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:10,335 : [INFO]  ____________________________________ Batch 24: round 2 finished ____________________________________
2023-03-22 20:29:10,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:10,335 : [INFO]  #################################### Batch 24: sent the final model to clients ####################################
2023-03-22 20:29:10,337 : [INFO]  Batch number 24 model fetched from the server
2023-03-22 20:29:10,337 : [INFO]  ################ Batch 24: final global model evalution after 2 rounds ################
2023-03-22 20:29:10,337 : [INFO]  Batch number 24 model fetched from the server
2023-03-22 20:29:10,337 : [INFO]  ################ Batch 24: final global model evalution after 2 rounds ################
2023-03-22 20:29:10,337 : [INFO]  Batch number 24 model fetched from the server
2023-03-22 20:29:10,338 : [INFO]  ################ Batch 24: final global model evalution after 2 rounds ################
2023-03-22 20:29:10,338 : [INFO]  Batch number 24 model fetched from the server
2023-03-22 20:29:10,338 : [INFO]  ################ Batch 24: final global model evalution after 2 rounds ################
2023-03-22 20:29:12,207 : [INFO]  Batch 24: Training set : loss - 0.54, accuracy - 0.76, recall - 0.95, AUC - 0.92, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:29:12,207 : [INFO]  Batch 24: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.94, AUC - 0.9, F1 - 0.78, precision - 0.67
2023-03-22 20:29:12,209 : [INFO]  Batch 24: Training set : loss - 0.53, accuracy - 0.79, recall - 0.99, AUC - 0.93, F1 - 0.82, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:29:12,210 : [INFO]  Batch 24: Testing set : loss - 0.55, accuracy - 0.71, recall - 0.88, AUC - 0.9, F1 - 0.75, precision - 0.66
2023-03-22 20:29:12,217 : [INFO]  Batch 25 initialized 
2023-03-22 20:29:12,217 : [INFO]  Batch 25 initialized 
2023-03-22 20:29:12,311 : [INFO]  Batch 24: Training set : loss - 0.57, accuracy - 0.73, recall - 0.93, AUC - 0.89, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:29:12,311 : [INFO]  Batch 24: Testing set : loss - 0.54, accuracy - 0.72, recall - 0.95, AUC - 0.93, F1 - 0.77, precision - 0.65
2023-03-22 20:29:12,316 : [INFO]  Batch 25 initialized 
2023-03-22 20:29:12,361 : [INFO]  Batch 24: Training set : loss - 0.52, accuracy - 0.79, recall - 0.99, AUC - 0.96, F1 - 0.82, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:29:12,361 : [INFO]  Batch 24: Testing set : loss - 0.53, accuracy - 0.76, recall - 0.97, AUC - 0.94, F1 - 0.8, precision - 0.69
2023-03-22 20:29:12,367 : [INFO]  Batch 25 initialized 
2023-03-22 20:29:12,748 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:12,779 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:12,868 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:12,964 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:13,065 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-22 20:29:13,111 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-22 20:29:13,205 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-22 20:29:13,264 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-22 20:29:17,859 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:17,862 : [INFO]  Batch 25: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:17,878 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:17,881 : [INFO]  Batch 25: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:17,967 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:17,970 : [INFO]  Batch 25: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:18,102 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:18,104 : [INFO]  Batch 25: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:18,105 : [INFO]  Batch 25, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:18,105 : [INFO]  Batch 25, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:18,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:18,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:18,105 : [INFO]  Batch 25, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:18,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:18,105 : [INFO]  Batch 25, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:18,105 : [INFO]  ____________________________________ Batch 25: round 1 finished ____________________________________
2023-03-22 20:29:18,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:18,107 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-22 20:29:18,107 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-22 20:29:18,107 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-22 20:29:18,107 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-22 20:29:20,342 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:20,346 : [INFO]  Batch 25: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:20,418 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:20,421 : [INFO]  Batch 25: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:20,480 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:20,485 : [INFO]  Batch 25: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:20,533 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:20,536 : [INFO]  Batch 25: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:20,537 : [INFO]  Batch 25, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:20,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:20,537 : [INFO]  Batch 25, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:20,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:20,537 : [INFO]  Batch 25, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:20,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:20,537 : [INFO]  Batch 25, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:20,537 : [INFO]  ____________________________________ Batch 25: round 2 finished ____________________________________
2023-03-22 20:29:20,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:20,538 : [INFO]  #################################### Batch 25: sent the final model to clients ####################################
2023-03-22 20:29:20,539 : [INFO]  Batch number 25 model fetched from the server
2023-03-22 20:29:20,539 : [INFO]  ################ Batch 25: final global model evalution after 2 rounds ################
2023-03-22 20:29:20,539 : [INFO]  Batch number 25 model fetched from the server
2023-03-22 20:29:20,540 : [INFO]  ################ Batch 25: final global model evalution after 2 rounds ################
2023-03-22 20:29:20,540 : [INFO]  Batch number 25 model fetched from the server
2023-03-22 20:29:20,540 : [INFO]  ################ Batch 25: final global model evalution after 2 rounds ################
2023-03-22 20:29:20,540 : [INFO]  Batch number 25 model fetched from the server
2023-03-22 20:29:20,540 : [INFO]  ################ Batch 25: final global model evalution after 2 rounds ################
2023-03-22 20:29:22,463 : [INFO]  Batch 25: Training set : loss - 0.55, accuracy - 0.72, recall - 0.92, AUC - 0.88, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:29:22,463 : [INFO]  Batch 25: Testing set : loss - 0.57, accuracy - 0.75, recall - 0.93, AUC - 0.87, F1 - 0.79, precision - 0.68
2023-03-22 20:29:22,470 : [INFO]  Batch 26 initialized 
2023-03-22 20:29:22,470 : [INFO]  Batch 25: Training set : loss - 0.57, accuracy - 0.72, recall - 0.96, AUC - 0.89, F1 - 0.78, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:29:22,470 : [INFO]  Batch 25: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.93, AUC - 0.89, F1 - 0.76, precision - 0.65
2023-03-22 20:29:22,475 : [INFO]  Batch 26 initialized 
2023-03-22 20:29:22,509 : [INFO]  Batch 25: Training set : loss - 0.55, accuracy - 0.72, recall - 0.91, AUC - 0.91, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:29:22,509 : [INFO]  Batch 25: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.93, AUC - 0.91, F1 - 0.79, precision - 0.68
2023-03-22 20:29:22,511 : [INFO]  Batch 25: Training set : loss - 0.51, accuracy - 0.76, recall - 0.98, AUC - 0.96, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:29:22,511 : [INFO]  Batch 25: Testing set : loss - 0.51, accuracy - 0.78, recall - 0.97, AUC - 0.96, F1 - 0.81, precision - 0.7
2023-03-22 20:29:22,514 : [INFO]  Batch 26 initialized 
2023-03-22 20:29:22,518 : [INFO]  Batch 26 initialized 
2023-03-22 20:29:22,975 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:22,995 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:23,020 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:23,050 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:23,324 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-22 20:29:23,352 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-22 20:29:23,374 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-22 20:29:23,403 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-22 20:29:28,036 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:28,041 : [INFO]  Batch 26: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:28,055 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:28,058 : [INFO]  Batch 26: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:28,080 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:28,083 : [INFO]  Batch 26: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:28,166 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:28,169 : [INFO]  Batch 26: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:28,170 : [INFO]  Batch 26, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:28,170 : [INFO]  Batch 26, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:28,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:28,170 : [INFO]  Batch 26, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:28,170 : [INFO]  Batch 26, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:28,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:28,170 : [INFO]  ____________________________________ Batch 26: round 1 finished ____________________________________
2023-03-22 20:29:28,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:28,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:28,172 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-22 20:29:28,172 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-22 20:29:28,173 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-22 20:29:28,174 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-22 20:29:30,481 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:30,484 : [INFO]  Batch 26: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:30,536 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:30,540 : [INFO]  Batch 26: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:30,557 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:30,561 : [INFO]  Batch 26: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:30,608 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:30,611 : [INFO]  Batch 26: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:30,612 : [INFO]  Batch 26, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:30,612 : [INFO]  Batch 26, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:30,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:30,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:30,612 : [INFO]  Batch 26, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:30,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:30,612 : [INFO]  Batch 26, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:30,612 : [INFO]  ____________________________________ Batch 26: round 2 finished ____________________________________
2023-03-22 20:29:30,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:30,612 : [INFO]  #################################### Batch 26: sent the final model to clients ####################################
2023-03-22 20:29:30,614 : [INFO]  Batch number 26 model fetched from the server
2023-03-22 20:29:30,614 : [INFO]  ################ Batch 26: final global model evalution after 2 rounds ################
2023-03-22 20:29:30,614 : [INFO]  Batch number 26 model fetched from the server
2023-03-22 20:29:30,614 : [INFO]  ################ Batch 26: final global model evalution after 2 rounds ################
2023-03-22 20:29:30,614 : [INFO]  Batch number 26 model fetched from the server
2023-03-22 20:29:30,615 : [INFO]  ################ Batch 26: final global model evalution after 2 rounds ################
2023-03-22 20:29:30,615 : [INFO]  Batch number 26 model fetched from the server
2023-03-22 20:29:30,615 : [INFO]  ################ Batch 26: final global model evalution after 2 rounds ################
2023-03-22 20:29:32,461 : [INFO]  Batch 26: Training set : loss - 0.54, accuracy - 0.78, recall - 0.97, AUC - 0.92, F1 - 0.81, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:29:32,461 : [INFO]  Batch 26: Testing set : loss - 0.56, accuracy - 0.73, recall - 0.93, AUC - 0.9, F1 - 0.78, precision - 0.66
2023-03-22 20:29:32,472 : [INFO]  Batch 27 initialized 
2023-03-22 20:29:32,558 : [INFO]  Batch 26: Training set : loss - 0.53, accuracy - 0.75, recall - 0.98, AUC - 0.95, F1 - 0.8, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:29:32,558 : [INFO]  Batch 26: Testing set : loss - 0.54, accuracy - 0.73, recall - 0.97, AUC - 0.91, F1 - 0.78, precision - 0.66
2023-03-22 20:29:32,566 : [INFO]  Batch 27 initialized 
2023-03-22 20:29:32,616 : [INFO]  Batch 26: Training set : loss - 0.56, accuracy - 0.74, recall - 0.92, AUC - 0.87, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:29:32,616 : [INFO]  Batch 26: Testing set : loss - 0.56, accuracy - 0.75, recall - 0.98, AUC - 0.9, F1 - 0.79, precision - 0.67
2023-03-22 20:29:32,617 : [INFO]  Batch 26: Training set : loss - 0.58, accuracy - 0.7, recall - 0.93, AUC - 0.86, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:29:32,617 : [INFO]  Batch 26: Testing set : loss - 0.56, accuracy - 0.75, recall - 0.96, AUC - 0.89, F1 - 0.79, precision - 0.68
2023-03-22 20:29:32,622 : [INFO]  Batch 27 initialized 
2023-03-22 20:29:32,623 : [INFO]  Batch 27 initialized 
2023-03-22 20:29:32,992 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:33,092 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:33,147 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:33,153 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:33,297 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-22 20:29:33,427 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-22 20:29:33,490 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-22 20:29:33,495 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-22 20:29:38,076 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:38,081 : [INFO]  Batch 27: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:38,104 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:38,109 : [INFO]  Batch 27: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:38,198 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:38,201 : [INFO]  Batch 27: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:38,215 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:38,218 : [INFO]  Batch 27: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:38,218 : [INFO]  Batch 27, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:38,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:38,218 : [INFO]  Batch 27, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:38,219 : [INFO]  Batch 27, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:38,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:38,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:38,219 : [INFO]  Batch 27, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:38,219 : [INFO]  ____________________________________ Batch 27: round 1 finished ____________________________________
2023-03-22 20:29:38,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:38,221 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-22 20:29:38,221 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-22 20:29:38,222 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-22 20:29:38,222 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-22 20:29:40,488 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:40,491 : [INFO]  Batch 27: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:40,492 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:40,496 : [INFO]  Batch 27: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:40,524 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:40,529 : [INFO]  Batch 27: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:40,613 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:40,616 : [INFO]  Batch 27: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:40,617 : [INFO]  Batch 27, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:40,617 : [INFO]  Batch 27, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:40,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:40,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:40,617 : [INFO]  Batch 27, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:40,617 : [INFO]  Batch 27, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:40,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:40,617 : [INFO]  ____________________________________ Batch 27: round 2 finished ____________________________________
2023-03-22 20:29:40,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:40,618 : [INFO]  #################################### Batch 27: sent the final model to clients ####################################
2023-03-22 20:29:40,619 : [INFO]  Batch number 27 model fetched from the server
2023-03-22 20:29:40,620 : [INFO]  ################ Batch 27: final global model evalution after 2 rounds ################
2023-03-22 20:29:40,620 : [INFO]  Batch number 27 model fetched from the server
2023-03-22 20:29:40,620 : [INFO]  ################ Batch 27: final global model evalution after 2 rounds ################
2023-03-22 20:29:40,621 : [INFO]  Batch number 27 model fetched from the server
2023-03-22 20:29:40,621 : [INFO]  Batch number 27 model fetched from the server
2023-03-22 20:29:40,621 : [INFO]  ################ Batch 27: final global model evalution after 2 rounds ################
2023-03-22 20:29:40,621 : [INFO]  ################ Batch 27: final global model evalution after 2 rounds ################
2023-03-22 20:29:42,519 : [INFO]  Batch 27: Training set : loss - 0.52, accuracy - 0.78, recall - 0.97, AUC - 0.94, F1 - 0.82, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:29:42,519 : [INFO]  Batch 27: Testing set : loss - 0.53, accuracy - 0.75, recall - 0.96, AUC - 0.92, F1 - 0.8, precision - 0.68
2023-03-22 20:29:42,529 : [INFO]  Batch 28 initialized 
2023-03-22 20:29:42,571 : [INFO]  Batch 27: Training set : loss - 0.52, accuracy - 0.78, recall - 0.98, AUC - 0.92, F1 - 0.82, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:29:42,571 : [INFO]  Batch 27: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.98, AUC - 0.92, F1 - 0.78, precision - 0.64
2023-03-22 20:29:42,578 : [INFO]  Batch 28 initialized 
2023-03-22 20:29:42,594 : [INFO]  Batch 27: Training set : loss - 0.56, accuracy - 0.74, recall - 0.95, AUC - 0.91, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:29:42,594 : [INFO]  Batch 27: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.96, AUC - 0.89, F1 - 0.79, precision - 0.67
2023-03-22 20:29:42,595 : [INFO]  Batch 27: Training set : loss - 0.55, accuracy - 0.76, recall - 0.97, AUC - 0.92, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:29:42,595 : [INFO]  Batch 27: Testing set : loss - 0.54, accuracy - 0.78, recall - 0.97, AUC - 0.92, F1 - 0.81, precision - 0.7
2023-03-22 20:29:42,599 : [INFO]  Batch 28 initialized 
2023-03-22 20:29:42,601 : [INFO]  Batch 28 initialized 
2023-03-22 20:29:43,051 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:43,093 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:43,117 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:43,142 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:43,394 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-22 20:29:43,447 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-22 20:29:43,474 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-22 20:29:43,489 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-22 20:29:48,124 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:48,127 : [INFO]  Batch 28: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:48,151 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:48,154 : [INFO]  Batch 28: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:48,168 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:48,171 : [INFO]  Batch 28: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:48,219 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:48,222 : [INFO]  Batch 28: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:48,222 : [INFO]  Batch 28, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:48,222 : [INFO]  Batch 28, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:48,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:48,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:48,222 : [INFO]  Batch 28, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:48,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:48,223 : [INFO]  Batch 28, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:48,223 : [INFO]  ____________________________________ Batch 28: round 1 finished ____________________________________
2023-03-22 20:29:48,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:48,224 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-22 20:29:48,225 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-22 20:29:48,225 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-22 20:29:48,226 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-22 20:29:50,389 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:50,392 : [INFO]  Batch 28: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:50,515 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:50,518 : [INFO]  Batch 28: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:50,563 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:50,563 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-22 20:29:50,568 : [INFO]  Batch 28: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:50,568 : [INFO]  Batch 28: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:50,568 : [INFO]  Batch 28, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:50,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:50,568 : [INFO]  Batch 28, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:50,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:50,568 : [INFO]  Batch 28, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:50,569 : [INFO]  Batch 28, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:50,569 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:50,569 : [INFO]  ____________________________________ Batch 28: round 2 finished ____________________________________
2023-03-22 20:29:50,569 : [INFO]  #################################### Batch 28: sent the final model to clients ####################################
2023-03-22 20:29:50,569 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:50,571 : [INFO]  Batch number 28 model fetched from the server
2023-03-22 20:29:50,571 : [INFO]  ################ Batch 28: final global model evalution after 2 rounds ################
2023-03-22 20:29:50,571 : [INFO]  Batch number 28 model fetched from the server
2023-03-22 20:29:50,571 : [INFO]  ################ Batch 28: final global model evalution after 2 rounds ################
2023-03-22 20:29:50,571 : [INFO]  Batch number 28 model fetched from the server
2023-03-22 20:29:50,571 : [INFO]  Batch number 28 model fetched from the server
2023-03-22 20:29:50,572 : [INFO]  ################ Batch 28: final global model evalution after 2 rounds ################
2023-03-22 20:29:50,572 : [INFO]  ################ Batch 28: final global model evalution after 2 rounds ################
2023-03-22 20:29:52,492 : [INFO]  Batch 28: Training set : loss - 0.54, accuracy - 0.78, recall - 0.96, AUC - 0.9, F1 - 0.81, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:29:52,493 : [INFO]  Batch 28: Testing set : loss - 0.54, accuracy - 0.76, recall - 0.89, AUC - 0.89, F1 - 0.79, precision - 0.71
2023-03-22 20:29:52,494 : [INFO]  Batch 28: Training set : loss - 0.52, accuracy - 0.8, recall - 0.96, AUC - 0.93, F1 - 0.83, precision - 0.73, training time - -7.0 seconds
2023-03-22 20:29:52,494 : [INFO]  Batch 28: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.9, AUC - 0.85, F1 - 0.74, precision - 0.63
2023-03-22 20:29:52,503 : [INFO]  Batch 29 initialized 
2023-03-22 20:29:52,504 : [INFO]  Batch 29 initialized 
2023-03-22 20:29:52,520 : [INFO]  Batch 28: Training set : loss - 0.56, accuracy - 0.73, recall - 0.93, AUC - 0.89, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:29:52,520 : [INFO]  Batch 28: Testing set : loss - 0.58, accuracy - 0.7, recall - 0.87, AUC - 0.87, F1 - 0.74, precision - 0.64
2023-03-22 20:29:52,524 : [INFO]  Batch 29 initialized 
2023-03-22 20:29:52,988 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:52,992 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:52,996 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:53,113 : [INFO]  Batch 28: Training set : loss - 0.57, accuracy - 0.71, recall - 0.93, AUC - 0.88, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:29:53,113 : [INFO]  Batch 28: Testing set : loss - 0.54, accuracy - 0.78, recall - 0.95, AUC - 0.93, F1 - 0.81, precision - 0.71
2023-03-22 20:29:53,128 : [INFO]  Batch 29 initialized 
2023-03-22 20:29:53,304 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-22 20:29:53,318 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-22 20:29:53,321 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-22 20:29:53,672 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:29:53,899 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-22 20:29:57,956 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:57,961 : [INFO]  Batch 29: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:29:58,073 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:58,076 : [INFO]  Batch 29: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:29:58,101 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:58,104 : [INFO]  Batch 29: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:29:58,478 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-22 20:29:58,480 : [INFO]  Batch 29: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:29:58,481 : [INFO]  Batch 29, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:29:58,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:58,481 : [INFO]  Batch 29, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:29:58,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:58,481 : [INFO]  Batch 29, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:29:58,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:58,481 : [INFO]  Batch 29, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:29:58,481 : [INFO]  ____________________________________ Batch 29: round 1 finished ____________________________________
2023-03-22 20:29:58,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:29:58,482 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-22 20:29:58,483 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-22 20:29:58,483 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-22 20:29:58,483 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-22 20:30:00,693 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:00,697 : [INFO]  Batch 29: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:00,703 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:00,707 : [INFO]  Batch 29: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:00,761 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:00,764 : [INFO]  Batch 29: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:00,795 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:00,798 : [INFO]  Batch 29: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:00,798 : [INFO]  Batch 29, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:00,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:00,799 : [INFO]  Batch 29, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:00,799 : [INFO]  Batch 29, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:00,799 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:00,799 : [INFO]  Batch 29, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:00,799 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:00,799 : [INFO]  ____________________________________ Batch 29: round 2 finished ____________________________________
2023-03-22 20:30:00,799 : [INFO]  #################################### Batch 29: sent the final model to clients ####################################
2023-03-22 20:30:00,799 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:00,800 : [INFO]  Batch number 29 model fetched from the server
2023-03-22 20:30:00,801 : [INFO]  ################ Batch 29: final global model evalution after 2 rounds ################
2023-03-22 20:30:00,801 : [INFO]  Batch number 29 model fetched from the server
2023-03-22 20:30:00,801 : [INFO]  ################ Batch 29: final global model evalution after 2 rounds ################
2023-03-22 20:30:00,802 : [INFO]  Batch number 29 model fetched from the server
2023-03-22 20:30:00,802 : [INFO]  Batch number 29 model fetched from the server
2023-03-22 20:30:00,802 : [INFO]  ################ Batch 29: final global model evalution after 2 rounds ################
2023-03-22 20:30:00,802 : [INFO]  ################ Batch 29: final global model evalution after 2 rounds ################
2023-03-22 20:30:02,693 : [INFO]  Batch 29: Training set : loss - 0.53, accuracy - 0.77, recall - 0.93, AUC - 0.93, F1 - 0.8, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:30:02,693 : [INFO]  Batch 29: Testing set : loss - 0.53, accuracy - 0.78, recall - 0.97, AUC - 0.94, F1 - 0.82, precision - 0.71
2023-03-22 20:30:02,704 : [INFO]  Batch 30 initialized 
2023-03-22 20:30:02,722 : [INFO]  Batch 29: Training set : loss - 0.54, accuracy - 0.75, recall - 0.98, AUC - 0.95, F1 - 0.8, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:30:02,722 : [INFO]  Batch 29: Testing set : loss - 0.54, accuracy - 0.76, recall - 0.98, AUC - 0.94, F1 - 0.81, precision - 0.68
2023-03-22 20:30:02,730 : [INFO]  Batch 30 initialized 
2023-03-22 20:30:02,841 : [INFO]  Batch 29: Training set : loss - 0.57, accuracy - 0.71, recall - 0.96, AUC - 0.89, F1 - 0.77, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:30:02,841 : [INFO]  Batch 29: Testing set : loss - 0.55, accuracy - 0.77, recall - 0.96, AUC - 0.93, F1 - 0.81, precision - 0.7
2023-03-22 20:30:02,848 : [INFO]  Batch 30 initialized 
2023-03-22 20:30:02,858 : [INFO]  Batch 29: Training set : loss - 0.52, accuracy - 0.78, recall - 0.97, AUC - 0.93, F1 - 0.82, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:30:02,858 : [INFO]  Batch 29: Testing set : loss - 0.57, accuracy - 0.7, recall - 0.98, AUC - 0.93, F1 - 0.76, precision - 0.62
2023-03-22 20:30:02,863 : [INFO]  Batch 30 initialized 
2023-03-22 20:30:03,216 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:03,278 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:03,395 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:03,402 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:03,547 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-22 20:30:03,621 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-22 20:30:03,727 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-22 20:30:03,732 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-22 20:30:08,351 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:08,357 : [INFO]  Batch 30: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:08,423 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:08,427 : [INFO]  Batch 30: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:08,470 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:08,473 : [INFO]  Batch 30: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:08,550 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:08,553 : [INFO]  Batch 30: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:08,554 : [INFO]  Batch 30, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:08,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:08,554 : [INFO]  Batch 30, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:08,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:08,554 : [INFO]  Batch 30, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:08,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:08,554 : [INFO]  Batch 30, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:08,555 : [INFO]  ____________________________________ Batch 30: round 1 finished ____________________________________
2023-03-22 20:30:08,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:08,556 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-22 20:30:08,556 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-22 20:30:08,557 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-22 20:30:08,557 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-22 20:30:10,785 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:10,786 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:10,788 : [INFO]  Batch 30: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:10,791 : [INFO]  Batch 30: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:10,897 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:10,900 : [INFO]  Batch 30: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:10,929 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:10,932 : [INFO]  Batch 30: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:10,933 : [INFO]  Batch 30, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:10,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:10,933 : [INFO]  Batch 30, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:10,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:10,933 : [INFO]  Batch 30, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:10,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:10,933 : [INFO]  Batch 30, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:10,933 : [INFO]  ____________________________________ Batch 30: round 2 finished ____________________________________
2023-03-22 20:30:10,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:10,933 : [INFO]  #################################### Batch 30: sent the final model to clients ####################################
2023-03-22 20:30:10,935 : [INFO]  Batch number 30 model fetched from the server
2023-03-22 20:30:10,935 : [INFO]  ################ Batch 30: final global model evalution after 2 rounds ################
2023-03-22 20:30:10,935 : [INFO]  Batch number 30 model fetched from the server
2023-03-22 20:30:10,935 : [INFO]  ################ Batch 30: final global model evalution after 2 rounds ################
2023-03-22 20:30:10,936 : [INFO]  Batch number 30 model fetched from the server
2023-03-22 20:30:10,936 : [INFO]  ################ Batch 30: final global model evalution after 2 rounds ################
2023-03-22 20:30:10,936 : [INFO]  Batch number 30 model fetched from the server
2023-03-22 20:30:10,937 : [INFO]  ################ Batch 30: final global model evalution after 2 rounds ################
2023-03-22 20:30:12,832 : [INFO]  Batch 30: Training set : loss - 0.55, accuracy - 0.74, recall - 0.97, AUC - 0.92, F1 - 0.79, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:30:12,832 : [INFO]  Batch 30: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.9, AUC - 0.85, F1 - 0.76, precision - 0.66
2023-03-22 20:30:12,844 : [INFO]  Batch 31 initialized 
2023-03-22 20:30:12,877 : [INFO]  Batch 30: Training set : loss - 0.55, accuracy - 0.76, recall - 0.98, AUC - 0.92, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:30:12,877 : [INFO]  Batch 30: Testing set : loss - 0.55, accuracy - 0.76, recall - 0.93, AUC - 0.9, F1 - 0.8, precision - 0.7
2023-03-22 20:30:12,882 : [INFO]  Batch 31 initialized 
2023-03-22 20:30:12,927 : [INFO]  Batch 30: Training set : loss - 0.54, accuracy - 0.73, recall - 0.97, AUC - 0.91, F1 - 0.78, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:30:12,927 : [INFO]  Batch 30: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.96, AUC - 0.92, F1 - 0.79, precision - 0.67
2023-03-22 20:30:12,934 : [INFO]  Batch 31 initialized 
2023-03-22 20:30:12,990 : [INFO]  Batch 30: Training set : loss - 0.53, accuracy - 0.76, recall - 0.99, AUC - 0.96, F1 - 0.81, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:30:12,990 : [INFO]  Batch 30: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.95, AUC - 0.93, F1 - 0.79, precision - 0.68
2023-03-22 20:30:12,997 : [INFO]  Batch 31 initialized 
2023-03-22 20:30:13,400 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:13,408 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:13,485 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:13,559 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:13,756 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-22 20:30:13,767 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-22 20:30:13,836 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-22 20:30:13,884 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-22 20:30:18,494 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:18,497 : [INFO]  Batch 31: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:18,579 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:18,582 : [INFO]  Batch 31: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:18,603 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:18,607 : [INFO]  Batch 31: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:18,610 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:18,614 : [INFO]  Batch 31: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:18,614 : [INFO]  Batch 31, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:18,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:18,614 : [INFO]  Batch 31, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:18,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:18,615 : [INFO]  Batch 31, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:18,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:18,615 : [INFO]  Batch 31, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:18,615 : [INFO]  ____________________________________ Batch 31: round 1 finished ____________________________________
2023-03-22 20:30:18,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:18,617 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-22 20:30:18,617 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-22 20:30:18,617 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-22 20:30:18,617 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-22 20:30:20,788 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:20,792 : [INFO]  Batch 31: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:20,834 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:20,837 : [INFO]  Batch 31: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:20,971 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:20,976 : [INFO]  Batch 31: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:20,991 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:20,994 : [INFO]  Batch 31: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:20,995 : [INFO]  Batch 31, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:20,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:20,995 : [INFO]  Batch 31, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:20,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:20,995 : [INFO]  Batch 31, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:20,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:20,995 : [INFO]  Batch 31, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:20,995 : [INFO]  ____________________________________ Batch 31: round 2 finished ____________________________________
2023-03-22 20:30:20,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:20,995 : [INFO]  #################################### Batch 31: sent the final model to clients ####################################
2023-03-22 20:30:20,997 : [INFO]  Batch number 31 model fetched from the server
2023-03-22 20:30:20,997 : [INFO]  ################ Batch 31: final global model evalution after 2 rounds ################
2023-03-22 20:30:20,997 : [INFO]  Batch number 31 model fetched from the server
2023-03-22 20:30:20,998 : [INFO]  ################ Batch 31: final global model evalution after 2 rounds ################
2023-03-22 20:30:20,998 : [INFO]  Batch number 31 model fetched from the server
2023-03-22 20:30:20,999 : [INFO]  ################ Batch 31: final global model evalution after 2 rounds ################
2023-03-22 20:30:20,999 : [INFO]  Batch number 31 model fetched from the server
2023-03-22 20:30:20,999 : [INFO]  ################ Batch 31: final global model evalution after 2 rounds ################
2023-03-22 20:30:22,916 : [INFO]  Batch 31: Training set : loss - 0.53, accuracy - 0.76, recall - 0.93, AUC - 0.93, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:30:22,916 : [INFO]  Batch 31: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.98, AUC - 0.95, F1 - 0.78, precision - 0.65
2023-03-22 20:30:22,927 : [INFO]  Batch 32 initialized 
2023-03-22 20:30:22,932 : [INFO]  Batch 31: Training set : loss - 0.57, accuracy - 0.74, recall - 0.89, AUC - 0.86, F1 - 0.77, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:30:22,932 : [INFO]  Batch 31: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.96, AUC - 0.9, F1 - 0.79, precision - 0.67
2023-03-22 20:30:22,937 : [INFO]  Batch 32 initialized 
2023-03-22 20:30:22,981 : [INFO]  Batch 31: Training set : loss - 0.59, accuracy - 0.68, recall - 0.9, AUC - 0.83, F1 - 0.74, precision - 0.62, training time - -7.0 seconds
2023-03-22 20:30:22,981 : [INFO]  Batch 31: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.94, AUC - 0.89, F1 - 0.78, precision - 0.66
2023-03-22 20:30:22,987 : [INFO]  Batch 32 initialized 
2023-03-22 20:30:23,037 : [INFO]  Batch 31: Training set : loss - 0.53, accuracy - 0.77, recall - 0.96, AUC - 0.93, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:30:23,037 : [INFO]  Batch 31: Testing set : loss - 0.56, accuracy - 0.73, recall - 0.97, AUC - 0.91, F1 - 0.78, precision - 0.65
2023-03-22 20:30:23,042 : [INFO]  Batch 32 initialized 
2023-03-22 20:30:23,439 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:23,484 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:23,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:23,577 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:23,788 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-22 20:30:23,839 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-22 20:30:23,920 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-22 20:30:23,921 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-22 20:30:28,427 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:28,432 : [INFO]  Batch 32: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:28,627 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:28,630 : [INFO]  Batch 32: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:28,634 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:28,638 : [INFO]  Batch 32: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:28,663 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:28,666 : [INFO]  Batch 32: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:28,667 : [INFO]  Batch 32, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:28,667 : [INFO]  Batch 32, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:28,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:28,667 : [INFO]  Batch 32, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:28,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:28,667 : [INFO]  Batch 32, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:28,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:28,667 : [INFO]  ____________________________________ Batch 32: round 1 finished ____________________________________
2023-03-22 20:30:28,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:28,669 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-22 20:30:28,669 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-22 20:30:28,670 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-22 20:30:28,670 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-22 20:30:30,927 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:30,930 : [INFO]  Batch 32: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:30,942 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:30,946 : [INFO]  Batch 32: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:30,955 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:30,959 : [INFO]  Batch 32: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:31,051 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:31,054 : [INFO]  Batch 32: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:31,054 : [INFO]  Batch 32, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:31,054 : [INFO]  Batch 32, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:31,054 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:31,054 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:31,054 : [INFO]  Batch 32, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:31,054 : [INFO]  Batch 32, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:31,054 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:31,054 : [INFO]  ____________________________________ Batch 32: round 2 finished ____________________________________
2023-03-22 20:30:31,055 : [INFO]  #################################### Batch 32: sent the final model to clients ####################################
2023-03-22 20:30:31,055 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:31,057 : [INFO]  Batch number 32 model fetched from the server
2023-03-22 20:30:31,057 : [INFO]  Batch number 32 model fetched from the server
2023-03-22 20:30:31,057 : [INFO]  ################ Batch 32: final global model evalution after 2 rounds ################
2023-03-22 20:30:31,057 : [INFO]  ################ Batch 32: final global model evalution after 2 rounds ################
2023-03-22 20:30:31,057 : [INFO]  Batch number 32 model fetched from the server
2023-03-22 20:30:31,057 : [INFO]  Batch number 32 model fetched from the server
2023-03-22 20:30:31,057 : [INFO]  ################ Batch 32: final global model evalution after 2 rounds ################
2023-03-22 20:30:31,058 : [INFO]  ################ Batch 32: final global model evalution after 2 rounds ################
2023-03-22 20:30:32,971 : [INFO]  Batch 32: Training set : loss - 0.53, accuracy - 0.79, recall - 0.97, AUC - 0.93, F1 - 0.82, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:30:32,971 : [INFO]  Batch 32: Testing set : loss - 0.54, accuracy - 0.77, recall - 0.95, AUC - 0.91, F1 - 0.81, precision - 0.7
2023-03-22 20:30:32,982 : [INFO]  Batch 33 initialized 
2023-03-22 20:30:33,005 : [INFO]  Batch 32: Training set : loss - 0.55, accuracy - 0.72, recall - 0.95, AUC - 0.91, F1 - 0.77, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:30:33,005 : [INFO]  Batch 32: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.96, AUC - 0.9, F1 - 0.79, precision - 0.67
2023-03-22 20:30:33,011 : [INFO]  Batch 33 initialized 
2023-03-22 20:30:33,047 : [INFO]  Batch 32: Training set : loss - 0.57, accuracy - 0.73, recall - 0.93, AUC - 0.89, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:30:33,047 : [INFO]  Batch 32: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.98, AUC - 0.89, F1 - 0.78, precision - 0.65
2023-03-22 20:30:33,055 : [INFO]  Batch 33 initialized 
2023-03-22 20:30:33,066 : [INFO]  Batch 32: Training set : loss - 0.53, accuracy - 0.74, recall - 0.88, AUC - 0.91, F1 - 0.78, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:30:33,066 : [INFO]  Batch 32: Testing set : loss - 0.59, accuracy - 0.68, recall - 0.89, AUC - 0.86, F1 - 0.73, precision - 0.62
2023-03-22 20:30:33,073 : [INFO]  Batch 33 initialized 
2023-03-22 20:30:33,519 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:33,562 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:33,582 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:33,648 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:33,869 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-22 20:30:33,922 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-22 20:30:33,942 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-22 20:30:33,991 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-22 20:30:38,562 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:38,565 : [INFO]  Batch 33: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:38,631 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:38,634 : [INFO]  Batch 33: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:38,729 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:38,729 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:38,732 : [INFO]  Batch 33: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:38,733 : [INFO]  Batch 33: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:38,733 : [INFO]  Batch 33, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:38,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:38,733 : [INFO]  Batch 33, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:38,733 : [INFO]  Batch 33, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:38,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:38,734 : [INFO]  Batch 33, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:38,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:38,734 : [INFO]  ____________________________________ Batch 33: round 1 finished ____________________________________
2023-03-22 20:30:38,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:38,736 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-22 20:30:38,736 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-22 20:30:38,736 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-22 20:30:38,737 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-22 20:30:40,947 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:40,952 : [INFO]  Batch 33: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:41,037 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:41,040 : [INFO]  Batch 33: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:41,080 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:41,083 : [INFO]  Batch 33: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:41,112 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:41,115 : [INFO]  Batch 33: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:41,115 : [INFO]  Batch 33, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:41,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:41,115 : [INFO]  Batch 33, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:41,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:41,116 : [INFO]  Batch 33, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:41,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:41,116 : [INFO]  Batch 33, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:41,116 : [INFO]  ____________________________________ Batch 33: round 2 finished ____________________________________
2023-03-22 20:30:41,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:41,116 : [INFO]  #################################### Batch 33: sent the final model to clients ####################################
2023-03-22 20:30:41,118 : [INFO]  Batch number 33 model fetched from the server
2023-03-22 20:30:41,118 : [INFO]  Batch number 33 model fetched from the server
2023-03-22 20:30:41,118 : [INFO]  ################ Batch 33: final global model evalution after 2 rounds ################
2023-03-22 20:30:41,118 : [INFO]  ################ Batch 33: final global model evalution after 2 rounds ################
2023-03-22 20:30:41,118 : [INFO]  Batch number 33 model fetched from the server
2023-03-22 20:30:41,118 : [INFO]  ################ Batch 33: final global model evalution after 2 rounds ################
2023-03-22 20:30:41,118 : [INFO]  Batch number 33 model fetched from the server
2023-03-22 20:30:41,118 : [INFO]  ################ Batch 33: final global model evalution after 2 rounds ################
2023-03-22 20:30:43,035 : [INFO]  Batch 33: Training set : loss - 0.56, accuracy - 0.73, recall - 0.95, AUC - 0.91, F1 - 0.78, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:30:43,035 : [INFO]  Batch 33: Testing set : loss - 0.52, accuracy - 0.78, recall - 0.94, AUC - 0.93, F1 - 0.81, precision - 0.72
2023-03-22 20:30:43,036 : [INFO]  Batch 33: Training set : loss - 0.57, accuracy - 0.74, recall - 0.93, AUC - 0.87, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:30:43,036 : [INFO]  Batch 33: Testing set : loss - 0.6, accuracy - 0.64, recall - 0.9, AUC - 0.86, F1 - 0.72, precision - 0.59
2023-03-22 20:30:43,046 : [INFO]  Batch 34 initialized 
2023-03-22 20:30:43,047 : [INFO]  Batch 34 initialized 
2023-03-22 20:30:43,136 : [INFO]  Batch 33: Training set : loss - 0.54, accuracy - 0.78, recall - 0.98, AUC - 0.92, F1 - 0.81, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:30:43,137 : [INFO]  Batch 33: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.94, AUC - 0.88, F1 - 0.78, precision - 0.67
2023-03-22 20:30:43,143 : [INFO]  Batch 34 initialized 
2023-03-22 20:30:43,207 : [INFO]  Batch 33: Training set : loss - 0.53, accuracy - 0.77, recall - 0.95, AUC - 0.92, F1 - 0.81, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:30:43,208 : [INFO]  Batch 33: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.93, AUC - 0.86, F1 - 0.76, precision - 0.64
2023-03-22 20:30:43,216 : [INFO]  Batch 34 initialized 
2023-03-22 20:30:43,595 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:43,605 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:43,651 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:43,825 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:43,944 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-22 20:30:43,966 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-22 20:30:44,011 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-22 20:30:44,138 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-22 20:30:48,646 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:48,649 : [INFO]  Batch 34: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:48,714 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:48,718 : [INFO]  Batch 34: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:48,719 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:48,722 : [INFO]  Batch 34: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:48,897 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:48,900 : [INFO]  Batch 34: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:48,900 : [INFO]  Batch 34, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:48,901 : [INFO]  Batch 34, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:48,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:48,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:48,901 : [INFO]  Batch 34, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:48,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:48,901 : [INFO]  Batch 34, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:48,901 : [INFO]  ____________________________________ Batch 34: round 1 finished ____________________________________
2023-03-22 20:30:48,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:48,903 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-22 20:30:48,903 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-22 20:30:48,903 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-22 20:30:48,904 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-22 20:30:51,059 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:51,063 : [INFO]  Batch 34: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:51,133 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:51,136 : [INFO]  Batch 34: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:51,204 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:51,207 : [INFO]  Batch 34: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:51,235 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-22 20:30:51,238 : [INFO]  Batch 34: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:51,239 : [INFO]  Batch 34, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:51,239 : [INFO]  Batch 34, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:51,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:51,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:51,239 : [INFO]  Batch 34, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:51,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:51,239 : [INFO]  Batch 34, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:51,239 : [INFO]  ____________________________________ Batch 34: round 2 finished ____________________________________
2023-03-22 20:30:51,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:51,239 : [INFO]  #################################### Batch 34: sent the final model to clients ####################################
2023-03-22 20:30:51,241 : [INFO]  Batch number 34 model fetched from the server
2023-03-22 20:30:51,241 : [INFO]  ################ Batch 34: final global model evalution after 2 rounds ################
2023-03-22 20:30:51,241 : [INFO]  Batch number 34 model fetched from the server
2023-03-22 20:30:51,241 : [INFO]  ################ Batch 34: final global model evalution after 2 rounds ################
2023-03-22 20:30:51,241 : [INFO]  Batch number 34 model fetched from the server
2023-03-22 20:30:51,241 : [INFO]  ################ Batch 34: final global model evalution after 2 rounds ################
2023-03-22 20:30:51,241 : [INFO]  Batch number 34 model fetched from the server
2023-03-22 20:30:51,242 : [INFO]  ################ Batch 34: final global model evalution after 2 rounds ################
2023-03-22 20:30:53,097 : [INFO]  Batch 34: Training set : loss - 0.53, accuracy - 0.78, recall - 0.95, AUC - 0.93, F1 - 0.81, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:30:53,097 : [INFO]  Batch 34: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.94, AUC - 0.89, F1 - 0.79, precision - 0.68
2023-03-22 20:30:53,109 : [INFO]  Batch 35 initialized 
2023-03-22 20:30:53,160 : [INFO]  Batch 34: Training set : loss - 0.55, accuracy - 0.76, recall - 0.98, AUC - 0.91, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:30:53,160 : [INFO]  Batch 34: Testing set : loss - 0.58, accuracy - 0.69, recall - 0.93, AUC - 0.9, F1 - 0.75, precision - 0.63
2023-03-22 20:30:53,167 : [INFO]  Batch 35 initialized 
2023-03-22 20:30:53,216 : [INFO]  Batch 34: Training set : loss - 0.53, accuracy - 0.75, recall - 0.96, AUC - 0.92, F1 - 0.79, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:30:53,216 : [INFO]  Batch 34: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.98, AUC - 0.89, F1 - 0.78, precision - 0.64
2023-03-22 20:30:53,223 : [INFO]  Batch 35 initialized 
2023-03-22 20:30:53,280 : [INFO]  Batch 34: Training set : loss - 0.55, accuracy - 0.74, recall - 0.98, AUC - 0.92, F1 - 0.79, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:30:53,280 : [INFO]  Batch 34: Testing set : loss - 0.54, accuracy - 0.73, recall - 0.97, AUC - 0.94, F1 - 0.78, precision - 0.66
2023-03-22 20:30:53,286 : [INFO]  Batch 35 initialized 
2023-03-22 20:30:53,629 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:53,715 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:53,742 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:53,849 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:30:53,963 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-22 20:30:54,067 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-22 20:30:54,096 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-22 20:30:54,166 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-22 20:30:58,759 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:58,762 : [INFO]  Batch 35: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:30:58,842 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:58,847 : [INFO]  Batch 35: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:30:58,866 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:58,869 : [INFO]  Batch 35: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:30:58,987 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-22 20:30:58,990 : [INFO]  Batch 35: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:30:58,990 : [INFO]  Batch 35, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:30:58,990 : [INFO]  Batch 35, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:30:58,990 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:58,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:58,991 : [INFO]  Batch 35, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:30:58,991 : [INFO]  Batch 35, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:30:58,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:58,991 : [INFO]  ____________________________________ Batch 35: round 1 finished ____________________________________
2023-03-22 20:30:58,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:30:58,992 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-22 20:30:58,993 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-22 20:30:58,993 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-22 20:30:58,994 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-22 20:31:01,325 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:01,329 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:01,330 : [INFO]  Batch 35: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:01,334 : [INFO]  Batch 35: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:01,500 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:01,503 : [INFO]  Batch 35: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:01,534 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:01,537 : [INFO]  Batch 35: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:01,538 : [INFO]  Batch 35, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:01,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:01,538 : [INFO]  Batch 35, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:01,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:01,538 : [INFO]  Batch 35, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:01,538 : [INFO]  Batch 35, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:01,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:01,538 : [INFO]  ____________________________________ Batch 35: round 2 finished ____________________________________
2023-03-22 20:31:01,538 : [INFO]  #################################### Batch 35: sent the final model to clients ####################################
2023-03-22 20:31:01,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:01,541 : [INFO]  Batch number 35 model fetched from the server
2023-03-22 20:31:01,542 : [INFO]  Batch number 35 model fetched from the server
2023-03-22 20:31:01,542 : [INFO]  ################ Batch 35: final global model evalution after 2 rounds ################
2023-03-22 20:31:01,542 : [INFO]  ################ Batch 35: final global model evalution after 2 rounds ################
2023-03-22 20:31:01,542 : [INFO]  Batch number 35 model fetched from the server
2023-03-22 20:31:01,542 : [INFO]  ################ Batch 35: final global model evalution after 2 rounds ################
2023-03-22 20:31:01,542 : [INFO]  Batch number 35 model fetched from the server
2023-03-22 20:31:01,542 : [INFO]  ################ Batch 35: final global model evalution after 2 rounds ################
2023-03-22 20:31:03,479 : [INFO]  Batch 35: Training set : loss - 0.53, accuracy - 0.76, recall - 0.98, AUC - 0.94, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:31:03,479 : [INFO]  Batch 35: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.94, AUC - 0.91, F1 - 0.79, precision - 0.69
2023-03-22 20:31:03,483 : [INFO]  Batch 35: Training set : loss - 0.56, accuracy - 0.74, recall - 0.95, AUC - 0.89, F1 - 0.79, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:31:03,483 : [INFO]  Batch 35: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.95, AUC - 0.92, F1 - 0.79, precision - 0.67
2023-03-22 20:31:03,490 : [INFO]  Batch 36 initialized 
2023-03-22 20:31:03,490 : [INFO]  Batch 36 initialized 
2023-03-22 20:31:03,518 : [INFO]  Batch 35: Training set : loss - 0.52, accuracy - 0.81, recall - 0.99, AUC - 0.92, F1 - 0.84, precision - 0.73, training time - -8.0 seconds
2023-03-22 20:31:03,518 : [INFO]  Batch 35: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.89, AUC - 0.85, F1 - 0.76, precision - 0.65
2023-03-22 20:31:03,523 : [INFO]  Batch 36 initialized 
2023-03-22 20:31:03,554 : [INFO]  Batch 35: Training set : loss - 0.56, accuracy - 0.72, recall - 0.95, AUC - 0.9, F1 - 0.77, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:31:03,554 : [INFO]  Batch 35: Testing set : loss - 0.54, accuracy - 0.77, recall - 0.97, AUC - 0.94, F1 - 0.81, precision - 0.69
2023-03-22 20:31:03,561 : [INFO]  Batch 36 initialized 
2023-03-22 20:31:04,010 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:04,025 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:04,055 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:04,110 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:04,407 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-22 20:31:04,430 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-22 20:31:04,456 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-22 20:31:04,518 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-22 20:31:09,176 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:09,181 : [INFO]  Batch 36: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:09,207 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:09,212 : [INFO]  Batch 36: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:09,218 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:09,221 : [INFO]  Batch 36: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:09,336 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:09,338 : [INFO]  Batch 36: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:09,339 : [INFO]  Batch 36, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:09,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:09,339 : [INFO]  Batch 36, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:09,339 : [INFO]  Batch 36, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:09,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:09,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:09,339 : [INFO]  Batch 36, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:09,339 : [INFO]  ____________________________________ Batch 36: round 1 finished ____________________________________
2023-03-22 20:31:09,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:09,341 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-22 20:31:09,341 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-22 20:31:09,342 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-22 20:31:09,342 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-22 20:31:11,657 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:11,661 : [INFO]  Batch 36: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:11,684 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:11,689 : [INFO]  Batch 36: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:11,703 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:11,706 : [INFO]  Batch 36: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:11,760 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:11,763 : [INFO]  Batch 36: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:11,764 : [INFO]  Batch 36, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:11,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:11,764 : [INFO]  Batch 36, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:11,764 : [INFO]  Batch 36, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:11,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:11,764 : [INFO]  Batch 36, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:11,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:11,764 : [INFO]  ____________________________________ Batch 36: round 2 finished ____________________________________
2023-03-22 20:31:11,764 : [INFO]  #################################### Batch 36: sent the final model to clients ####################################
2023-03-22 20:31:11,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:11,767 : [INFO]  Batch number 36 model fetched from the server
2023-03-22 20:31:11,767 : [INFO]  ################ Batch 36: final global model evalution after 2 rounds ################
2023-03-22 20:31:11,767 : [INFO]  Batch number 36 model fetched from the server
2023-03-22 20:31:11,767 : [INFO]  ################ Batch 36: final global model evalution after 2 rounds ################
2023-03-22 20:31:11,767 : [INFO]  Batch number 36 model fetched from the server
2023-03-22 20:31:11,767 : [INFO]  Batch number 36 model fetched from the server
2023-03-22 20:31:11,767 : [INFO]  ################ Batch 36: final global model evalution after 2 rounds ################
2023-03-22 20:31:11,767 : [INFO]  ################ Batch 36: final global model evalution after 2 rounds ################
2023-03-22 20:31:13,638 : [INFO]  Batch 36: Training set : loss - 0.56, accuracy - 0.71, recall - 0.96, AUC - 0.91, F1 - 0.77, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:31:13,639 : [INFO]  Batch 36: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.98, AUC - 0.95, F1 - 0.79, precision - 0.67
2023-03-22 20:31:13,649 : [INFO]  Batch 37 initialized 
2023-03-22 20:31:13,696 : [INFO]  Batch 36: Training set : loss - 0.55, accuracy - 0.74, recall - 0.97, AUC - 0.91, F1 - 0.79, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:31:13,696 : [INFO]  Batch 36: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.94, AUC - 0.92, F1 - 0.78, precision - 0.67
2023-03-22 20:31:13,704 : [INFO]  Batch 37 initialized 
2023-03-22 20:31:13,760 : [INFO]  Batch 36: Training set : loss - 0.53, accuracy - 0.77, recall - 0.98, AUC - 0.94, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:31:13,760 : [INFO]  Batch 36: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.96, AUC - 0.93, F1 - 0.79, precision - 0.68
2023-03-22 20:31:13,767 : [INFO]  Batch 37 initialized 
2023-03-22 20:31:13,814 : [INFO]  Batch 36: Training set : loss - 0.53, accuracy - 0.77, recall - 0.97, AUC - 0.94, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:31:13,815 : [INFO]  Batch 36: Testing set : loss - 0.54, accuracy - 0.76, recall - 0.96, AUC - 0.92, F1 - 0.8, precision - 0.69
2023-03-22 20:31:13,824 : [INFO]  Batch 37 initialized 
2023-03-22 20:31:14,173 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:14,236 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:14,330 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:14,389 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:14,511 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-22 20:31:14,584 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-22 20:31:14,675 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-22 20:31:14,717 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-22 20:31:19,211 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:19,215 : [INFO]  Batch 37: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:19,391 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:19,395 : [INFO]  Batch 37: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:19,401 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:19,404 : [INFO]  Batch 37: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:19,452 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:19,455 : [INFO]  Batch 37: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:19,456 : [INFO]  Batch 37, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:19,456 : [INFO]  Batch 37, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:19,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:19,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:19,456 : [INFO]  Batch 37, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:19,456 : [INFO]  Batch 37, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:19,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:19,456 : [INFO]  ____________________________________ Batch 37: round 1 finished ____________________________________
2023-03-22 20:31:19,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:19,459 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-22 20:31:19,459 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-22 20:31:19,459 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-22 20:31:19,459 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-22 20:31:21,692 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:21,695 : [INFO]  Batch 37: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:21,767 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:21,770 : [INFO]  Batch 37: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:21,773 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:21,776 : [INFO]  Batch 37: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:21,855 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:21,858 : [INFO]  Batch 37: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:21,858 : [INFO]  Batch 37, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:21,859 : [INFO]  Batch 37, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:21,859 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:21,859 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:21,859 : [INFO]  Batch 37, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:21,859 : [INFO]  Batch 37, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:21,859 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:21,859 : [INFO]  ____________________________________ Batch 37: round 2 finished ____________________________________
2023-03-22 20:31:21,859 : [INFO]  #################################### Batch 37: sent the final model to clients ####################################
2023-03-22 20:31:21,859 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:21,861 : [INFO]  Batch number 37 model fetched from the server
2023-03-22 20:31:21,861 : [INFO]  ################ Batch 37: final global model evalution after 2 rounds ################
2023-03-22 20:31:21,861 : [INFO]  Batch number 37 model fetched from the server
2023-03-22 20:31:21,861 : [INFO]  ################ Batch 37: final global model evalution after 2 rounds ################
2023-03-22 20:31:21,862 : [INFO]  Batch number 37 model fetched from the server
2023-03-22 20:31:21,862 : [INFO]  ################ Batch 37: final global model evalution after 2 rounds ################
2023-03-22 20:31:21,862 : [INFO]  Batch number 37 model fetched from the server
2023-03-22 20:31:21,862 : [INFO]  ################ Batch 37: final global model evalution after 2 rounds ################
2023-03-22 20:31:23,723 : [INFO]  Batch 37: Training set : loss - 0.53, accuracy - 0.78, recall - 0.93, AUC - 0.91, F1 - 0.81, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:31:23,723 : [INFO]  Batch 37: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.95, AUC - 0.9, F1 - 0.77, precision - 0.65
2023-03-22 20:31:23,731 : [INFO]  Batch 38 initialized 
2023-03-22 20:31:23,818 : [INFO]  Batch 37: Training set : loss - 0.54, accuracy - 0.73, recall - 0.97, AUC - 0.94, F1 - 0.78, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:31:23,818 : [INFO]  Batch 37: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.97, AUC - 0.92, F1 - 0.79, precision - 0.66
2023-03-22 20:31:23,820 : [INFO]  Batch 37: Training set : loss - 0.53, accuracy - 0.79, recall - 0.95, AUC - 0.91, F1 - 0.82, precision - 0.72, training time - -7.0 seconds
2023-03-22 20:31:23,820 : [INFO]  Batch 37: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.91, AUC - 0.89, F1 - 0.77, precision - 0.67
2023-03-22 20:31:23,823 : [INFO]  Batch 38 initialized 
2023-03-22 20:31:23,825 : [INFO]  Batch 38 initialized 
2023-03-22 20:31:23,926 : [INFO]  Batch 37: Training set : loss - 0.54, accuracy - 0.78, recall - 0.93, AUC - 0.93, F1 - 0.81, precision - 0.72, training time - -7.0 seconds
2023-03-22 20:31:23,926 : [INFO]  Batch 37: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.97, AUC - 0.92, F1 - 0.8, precision - 0.68
2023-03-22 20:31:23,969 : [INFO]  Batch 38 initialized 
2023-03-22 20:31:24,270 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:24,332 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:24,356 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:24,601 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:24,601 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-22 20:31:24,683 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-22 20:31:24,711 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-22 20:31:24,888 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-22 20:31:29,298 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:29,301 : [INFO]  Batch 38: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:29,361 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:29,364 : [INFO]  Batch 38: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:29,491 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:29,494 : [INFO]  Batch 38: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:29,560 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:29,564 : [INFO]  Batch 38: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:29,564 : [INFO]  Batch 38, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:29,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:29,564 : [INFO]  Batch 38, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:29,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:29,564 : [INFO]  Batch 38, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:29,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:29,565 : [INFO]  Batch 38, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:29,565 : [INFO]  ____________________________________ Batch 38: round 1 finished ____________________________________
2023-03-22 20:31:29,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:29,566 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-22 20:31:29,567 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-22 20:31:29,568 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-22 20:31:29,568 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-22 20:31:31,820 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:31,821 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:31,826 : [INFO]  Batch 38: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:31,826 : [INFO]  Batch 38: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:31,882 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:31,885 : [INFO]  Batch 38: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:31,894 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:31,897 : [INFO]  Batch 38: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:31,898 : [INFO]  Batch 38, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:31,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:31,898 : [INFO]  Batch 38, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:31,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:31,898 : [INFO]  Batch 38, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:31,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:31,898 : [INFO]  Batch 38, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:31,898 : [INFO]  ____________________________________ Batch 38: round 2 finished ____________________________________
2023-03-22 20:31:31,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:31,898 : [INFO]  #################################### Batch 38: sent the final model to clients ####################################
2023-03-22 20:31:31,901 : [INFO]  Batch number 38 model fetched from the server
2023-03-22 20:31:31,901 : [INFO]  ################ Batch 38: final global model evalution after 2 rounds ################
2023-03-22 20:31:31,901 : [INFO]  Batch number 38 model fetched from the server
2023-03-22 20:31:31,901 : [INFO]  Batch number 38 model fetched from the server
2023-03-22 20:31:31,901 : [INFO]  Batch number 38 model fetched from the server
2023-03-22 20:31:31,901 : [INFO]  ################ Batch 38: final global model evalution after 2 rounds ################
2023-03-22 20:31:31,901 : [INFO]  ################ Batch 38: final global model evalution after 2 rounds ################
2023-03-22 20:31:31,901 : [INFO]  ################ Batch 38: final global model evalution after 2 rounds ################
2023-03-22 20:31:33,771 : [INFO]  Batch 38: Training set : loss - 0.56, accuracy - 0.73, recall - 0.93, AUC - 0.89, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:31:33,771 : [INFO]  Batch 38: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.94, AUC - 0.9, F1 - 0.77, precision - 0.65
2023-03-22 20:31:33,782 : [INFO]  Batch 39 initialized 
2023-03-22 20:31:33,822 : [INFO]  Batch 38: Training set : loss - 0.56, accuracy - 0.7, recall - 0.95, AUC - 0.91, F1 - 0.76, precision - 0.64, training time - -7.0 seconds
2023-03-22 20:31:33,822 : [INFO]  Batch 38: Testing set : loss - 0.52, accuracy - 0.8, recall - 0.98, AUC - 0.93, F1 - 0.83, precision - 0.72
2023-03-22 20:31:33,829 : [INFO]  Batch 39 initialized 
2023-03-22 20:31:33,876 : [INFO]  Batch 38: Training set : loss - 0.55, accuracy - 0.77, recall - 0.99, AUC - 0.91, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:31:33,877 : [INFO]  Batch 38: Testing set : loss - 0.57, accuracy - 0.74, recall - 0.97, AUC - 0.88, F1 - 0.79, precision - 0.66
2023-03-22 20:31:33,881 : [INFO]  Batch 39 initialized 
2023-03-22 20:31:33,969 : [INFO]  Batch 38: Training set : loss - 0.53, accuracy - 0.79, recall - 0.96, AUC - 0.93, F1 - 0.82, precision - 0.72, training time - -7.0 seconds
2023-03-22 20:31:33,969 : [INFO]  Batch 38: Testing set : loss - 0.57, accuracy - 0.7, recall - 0.96, AUC - 0.87, F1 - 0.76, precision - 0.63
2023-03-22 20:31:33,976 : [INFO]  Batch 39 initialized 
2023-03-22 20:31:34,309 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:34,378 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:34,401 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:34,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:34,647 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-22 20:31:34,749 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-22 20:31:34,778 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-22 20:31:34,879 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-22 20:31:39,446 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:39,450 : [INFO]  Batch 39: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:39,546 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:39,550 : [INFO]  Batch 39: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:39,553 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:39,556 : [INFO]  Batch 39: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:39,571 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:39,574 : [INFO]  Batch 39: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:39,574 : [INFO]  Batch 39, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:39,574 : [INFO]  Batch 39, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:39,574 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:39,575 : [INFO]  Batch 39, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:39,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:39,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:39,575 : [INFO]  Batch 39, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:39,575 : [INFO]  ____________________________________ Batch 39: round 1 finished ____________________________________
2023-03-22 20:31:39,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:39,577 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-22 20:31:39,577 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-22 20:31:39,578 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-22 20:31:39,578 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-22 20:31:41,900 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:41,904 : [INFO]  Batch 39: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:41,915 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:41,919 : [INFO]  Batch 39: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:41,941 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:41,944 : [INFO]  Batch 39: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:42,009 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:42,012 : [INFO]  Batch 39: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:42,012 : [INFO]  Batch 39, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:42,012 : [INFO]  Batch 39, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:42,012 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:42,012 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:42,012 : [INFO]  Batch 39, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:42,013 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:42,013 : [INFO]  Batch 39, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:42,013 : [INFO]  ____________________________________ Batch 39: round 2 finished ____________________________________
2023-03-22 20:31:42,013 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:42,013 : [INFO]  #################################### Batch 39: sent the final model to clients ####################################
2023-03-22 20:31:42,015 : [INFO]  Batch number 39 model fetched from the server
2023-03-22 20:31:42,015 : [INFO]  Batch number 39 model fetched from the server
2023-03-22 20:31:42,015 : [INFO]  ################ Batch 39: final global model evalution after 2 rounds ################
2023-03-22 20:31:42,015 : [INFO]  ################ Batch 39: final global model evalution after 2 rounds ################
2023-03-22 20:31:42,016 : [INFO]  Batch number 39 model fetched from the server
2023-03-22 20:31:42,016 : [INFO]  Batch number 39 model fetched from the server
2023-03-22 20:31:42,016 : [INFO]  ################ Batch 39: final global model evalution after 2 rounds ################
2023-03-22 20:31:42,016 : [INFO]  ################ Batch 39: final global model evalution after 2 rounds ################
2023-03-22 20:31:43,914 : [INFO]  Batch 39: Training set : loss - 0.54, accuracy - 0.76, recall - 0.92, AUC - 0.91, F1 - 0.79, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:31:43,915 : [INFO]  Batch 39: Testing set : loss - 0.57, accuracy - 0.7, recall - 0.93, AUC - 0.88, F1 - 0.76, precision - 0.64
2023-03-22 20:31:43,927 : [INFO]  Batch 40 initialized 
2023-03-22 20:31:43,928 : [INFO]  Batch 39: Training set : loss - 0.53, accuracy - 0.77, recall - 0.98, AUC - 0.93, F1 - 0.81, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:31:43,928 : [INFO]  Batch 39: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.94, AUC - 0.89, F1 - 0.78, precision - 0.67
2023-03-22 20:31:43,933 : [INFO]  Batch 40 initialized 
2023-03-22 20:31:43,991 : [INFO]  Batch 39: Training set : loss - 0.54, accuracy - 0.75, recall - 0.98, AUC - 0.92, F1 - 0.8, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:31:43,991 : [INFO]  Batch 39: Testing set : loss - 0.55, accuracy - 0.76, recall - 1.0, AUC - 0.94, F1 - 0.81, precision - 0.68
2023-03-22 20:31:44,001 : [INFO]  Batch 40 initialized 
2023-03-22 20:31:44,065 : [INFO]  Batch 39: Training set : loss - 0.54, accuracy - 0.76, recall - 0.97, AUC - 0.93, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:31:44,065 : [INFO]  Batch 39: Testing set : loss - 0.56, accuracy - 0.74, recall - 0.95, AUC - 0.9, F1 - 0.79, precision - 0.67
2023-03-22 20:31:44,070 : [INFO]  Batch 40 initialized 
2023-03-22 20:31:44,427 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:44,438 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:44,563 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:44,640 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:44,784 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-22 20:31:44,802 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-22 20:31:44,910 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-22 20:31:44,975 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-22 20:31:49,486 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:49,491 : [INFO]  Batch 40: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:49,588 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:49,591 : [INFO]  Batch 40: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:49,660 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:49,663 : [INFO]  Batch 40: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:49,722 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:49,725 : [INFO]  Batch 40: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:49,725 : [INFO]  Batch 40, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:49,726 : [INFO]  Batch 40, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:49,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:49,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:49,726 : [INFO]  Batch 40, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:49,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:49,726 : [INFO]  Batch 40, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:49,726 : [INFO]  ____________________________________ Batch 40: round 1 finished ____________________________________
2023-03-22 20:31:49,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:49,728 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-22 20:31:49,728 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-22 20:31:49,728 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-22 20:31:49,728 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-22 20:31:51,895 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:51,899 : [INFO]  Batch 40: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:52,020 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:52,025 : [INFO]  Batch 40: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:52,050 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:52,053 : [INFO]  Batch 40: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:52,098 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-22 20:31:52,102 : [INFO]  Batch 40: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:52,102 : [INFO]  Batch 40, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:52,102 : [INFO]  Batch 40, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:52,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:52,102 : [INFO]  Batch 40, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:52,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:52,103 : [INFO]  Batch 40, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:52,103 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:52,103 : [INFO]  ____________________________________ Batch 40: round 2 finished ____________________________________
2023-03-22 20:31:52,103 : [INFO]  #################################### Batch 40: sent the final model to clients ####################################
2023-03-22 20:31:52,103 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:52,105 : [INFO]  Batch number 40 model fetched from the server
2023-03-22 20:31:52,105 : [INFO]  Batch number 40 model fetched from the server
2023-03-22 20:31:52,105 : [INFO]  ################ Batch 40: final global model evalution after 2 rounds ################
2023-03-22 20:31:52,105 : [INFO]  ################ Batch 40: final global model evalution after 2 rounds ################
2023-03-22 20:31:52,106 : [INFO]  Batch number 40 model fetched from the server
2023-03-22 20:31:52,106 : [INFO]  Batch number 40 model fetched from the server
2023-03-22 20:31:52,106 : [INFO]  ################ Batch 40: final global model evalution after 2 rounds ################
2023-03-22 20:31:52,106 : [INFO]  ################ Batch 40: final global model evalution after 2 rounds ################
2023-03-22 20:31:54,017 : [INFO]  Batch 40: Training set : loss - 0.57, accuracy - 0.73, recall - 0.95, AUC - 0.88, F1 - 0.78, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:31:54,017 : [INFO]  Batch 40: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.95, AUC - 0.91, F1 - 0.79, precision - 0.67
2023-03-22 20:31:54,020 : [INFO]  Batch 40: Training set : loss - 0.53, accuracy - 0.74, recall - 0.98, AUC - 0.95, F1 - 0.79, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:31:54,020 : [INFO]  Batch 40: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.97, AUC - 0.92, F1 - 0.79, precision - 0.67
2023-03-22 20:31:54,028 : [INFO]  Batch 41 initialized 
2023-03-22 20:31:54,029 : [INFO]  Batch 41 initialized 
2023-03-22 20:31:54,059 : [INFO]  Batch 40: Training set : loss - 0.51, accuracy - 0.77, recall - 0.96, AUC - 0.95, F1 - 0.81, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:31:54,059 : [INFO]  Batch 40: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.92, AUC - 0.92, F1 - 0.79, precision - 0.69
2023-03-22 20:31:54,066 : [INFO]  Batch 41 initialized 
2023-03-22 20:31:54,124 : [INFO]  Batch 40: Training set : loss - 0.54, accuracy - 0.74, recall - 0.97, AUC - 0.93, F1 - 0.79, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:31:54,124 : [INFO]  Batch 40: Testing set : loss - 0.55, accuracy - 0.72, recall - 0.96, AUC - 0.92, F1 - 0.77, precision - 0.64
2023-03-22 20:31:54,131 : [INFO]  Batch 41 initialized 
2023-03-22 20:31:54,579 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:54,581 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:54,634 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:54,704 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:31:54,957 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-22 20:31:54,960 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-22 20:31:55,018 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-22 20:31:55,063 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-22 20:31:59,583 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:59,587 : [INFO]  Batch 41: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:31:59,768 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:59,771 : [INFO]  Batch 41: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:31:59,810 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:59,816 : [INFO]  Batch 41: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:31:59,823 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-22 20:31:59,826 : [INFO]  Batch 41: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:31:59,827 : [INFO]  Batch 41, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:31:59,827 : [INFO]  Batch 41, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:31:59,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:59,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:59,827 : [INFO]  Batch 41, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:31:59,827 : [INFO]  Batch 41, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:31:59,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:59,827 : [INFO]  ____________________________________ Batch 41: round 1 finished ____________________________________
2023-03-22 20:31:59,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:31:59,829 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-22 20:31:59,829 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-22 20:31:59,830 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-22 20:31:59,830 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-22 20:32:02,069 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:02,072 : [INFO]  Batch 41: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:02,174 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:02,178 : [INFO]  Batch 41: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:02,264 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:02,267 : [INFO]  Batch 41: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:02,298 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:02,301 : [INFO]  Batch 41: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:02,302 : [INFO]  Batch 41, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:02,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:02,302 : [INFO]  Batch 41, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:02,302 : [INFO]  Batch 41, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:02,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:02,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:02,302 : [INFO]  Batch 41, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:02,303 : [INFO]  ____________________________________ Batch 41: round 2 finished ____________________________________
2023-03-22 20:32:02,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:02,303 : [INFO]  #################################### Batch 41: sent the final model to clients ####################################
2023-03-22 20:32:02,304 : [INFO]  Batch number 41 model fetched from the server
2023-03-22 20:32:02,304 : [INFO]  ################ Batch 41: final global model evalution after 2 rounds ################
2023-03-22 20:32:02,305 : [INFO]  Batch number 41 model fetched from the server
2023-03-22 20:32:02,305 : [INFO]  ################ Batch 41: final global model evalution after 2 rounds ################
2023-03-22 20:32:02,306 : [INFO]  Batch number 41 model fetched from the server
2023-03-22 20:32:02,306 : [INFO]  Batch number 41 model fetched from the server
2023-03-22 20:32:02,306 : [INFO]  ################ Batch 41: final global model evalution after 2 rounds ################
2023-03-22 20:32:02,306 : [INFO]  ################ Batch 41: final global model evalution after 2 rounds ################
2023-03-22 20:32:04,139 : [INFO]  Batch 41: Training set : loss - 0.57, accuracy - 0.73, recall - 0.93, AUC - 0.9, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:32:04,140 : [INFO]  Batch 41: Testing set : loss - 0.54, accuracy - 0.75, recall - 0.91, AUC - 0.9, F1 - 0.78, precision - 0.68
2023-03-22 20:32:04,151 : [INFO]  Batch 42 initialized 
2023-03-22 20:32:04,199 : [INFO]  Batch 41: Training set : loss - 0.57, accuracy - 0.7, recall - 0.96, AUC - 0.91, F1 - 0.76, precision - 0.63, training time - -7.0 seconds
2023-03-22 20:32:04,199 : [INFO]  Batch 41: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.95, AUC - 0.88, F1 - 0.77, precision - 0.65
2023-03-22 20:32:04,206 : [INFO]  Batch 42 initialized 
2023-03-22 20:32:04,365 : [INFO]  Batch 41: Training set : loss - 0.56, accuracy - 0.73, recall - 0.89, AUC - 0.9, F1 - 0.77, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:32:04,366 : [INFO]  Batch 41: Testing set : loss - 0.51, accuracy - 0.8, recall - 0.94, AUC - 0.95, F1 - 0.82, precision - 0.73
2023-03-22 20:32:04,373 : [INFO]  Batch 42 initialized 
2023-03-22 20:32:04,434 : [INFO]  Batch 41: Training set : loss - 0.55, accuracy - 0.77, recall - 0.96, AUC - 0.9, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:32:04,434 : [INFO]  Batch 41: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.94, AUC - 0.88, F1 - 0.77, precision - 0.65
2023-03-22 20:32:04,441 : [INFO]  Batch 42 initialized 
2023-03-22 20:32:04,684 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:04,821 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:05,005 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:05,067 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-22 20:32:05,146 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:05,200 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-22 20:32:05,347 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-22 20:32:05,449 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-22 20:32:09,973 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:09,978 : [INFO]  Batch 42: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:09,988 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:09,991 : [INFO]  Batch 42: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:10,002 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:10,005 : [INFO]  Batch 42: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:10,112 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:10,115 : [INFO]  Batch 42: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:10,115 : [INFO]  Batch 42, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:10,115 : [INFO]  Batch 42, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:10,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:10,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:10,115 : [INFO]  Batch 42, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:10,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:10,115 : [INFO]  Batch 42, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:10,116 : [INFO]  ____________________________________ Batch 42: round 1 finished ____________________________________
2023-03-22 20:32:10,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:10,117 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-22 20:32:10,118 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-22 20:32:10,118 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-22 20:32:10,119 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-22 20:32:12,359 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:12,363 : [INFO]  Batch 42: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:12,452 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:12,456 : [INFO]  Batch 42: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:12,458 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:12,461 : [INFO]  Batch 42: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:12,487 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:12,490 : [INFO]  Batch 42: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:12,491 : [INFO]  Batch 42, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:12,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:12,491 : [INFO]  Batch 42, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:12,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:12,491 : [INFO]  Batch 42, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:12,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:12,491 : [INFO]  Batch 42, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:12,492 : [INFO]  ____________________________________ Batch 42: round 2 finished ____________________________________
2023-03-22 20:32:12,492 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:12,492 : [INFO]  #################################### Batch 42: sent the final model to clients ####################################
2023-03-22 20:32:12,493 : [INFO]  Batch number 42 model fetched from the server
2023-03-22 20:32:12,493 : [INFO]  ################ Batch 42: final global model evalution after 2 rounds ################
2023-03-22 20:32:12,493 : [INFO]  Batch number 42 model fetched from the server
2023-03-22 20:32:12,494 : [INFO]  ################ Batch 42: final global model evalution after 2 rounds ################
2023-03-22 20:32:12,494 : [INFO]  Batch number 42 model fetched from the server
2023-03-22 20:32:12,494 : [INFO]  ################ Batch 42: final global model evalution after 2 rounds ################
2023-03-22 20:32:12,494 : [INFO]  Batch number 42 model fetched from the server
2023-03-22 20:32:12,494 : [INFO]  ################ Batch 42: final global model evalution after 2 rounds ################
2023-03-22 20:32:14,354 : [INFO]  Batch 42: Training set : loss - 0.51, accuracy - 0.8, recall - 0.98, AUC - 0.94, F1 - 0.83, precision - 0.73, training time - -7.0 seconds
2023-03-22 20:32:14,354 : [INFO]  Batch 42: Testing set : loss - 0.55, accuracy - 0.74, recall - 0.94, AUC - 0.91, F1 - 0.78, precision - 0.67
2023-03-22 20:32:14,366 : [INFO]  Batch 43 initialized 
2023-03-22 20:32:14,402 : [INFO]  Batch 42: Training set : loss - 0.56, accuracy - 0.72, recall - 0.91, AUC - 0.89, F1 - 0.77, precision - 0.66, training time - -7.0 seconds
2023-03-22 20:32:14,402 : [INFO]  Batch 42: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.98, AUC - 0.94, F1 - 0.78, precision - 0.64
2023-03-22 20:32:14,407 : [INFO]  Batch 43 initialized 
2023-03-22 20:32:14,444 : [INFO]  Batch 42: Training set : loss - 0.55, accuracy - 0.76, recall - 0.97, AUC - 0.92, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:32:14,444 : [INFO]  Batch 42: Testing set : loss - 0.54, accuracy - 0.74, recall - 0.96, AUC - 0.94, F1 - 0.79, precision - 0.67
2023-03-22 20:32:14,454 : [INFO]  Batch 43 initialized 
2023-03-22 20:32:14,535 : [INFO]  Batch 42: Training set : loss - 0.52, accuracy - 0.81, recall - 0.97, AUC - 0.93, F1 - 0.84, precision - 0.74, training time - -7.0 seconds
2023-03-22 20:32:14,535 : [INFO]  Batch 42: Testing set : loss - 0.54, accuracy - 0.77, recall - 0.95, AUC - 0.93, F1 - 0.81, precision - 0.7
2023-03-22 20:32:14,545 : [INFO]  Batch 43 initialized 
2023-03-22 20:32:14,880 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:14,963 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:15,030 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:15,108 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:15,213 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-22 20:32:15,328 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-22 20:32:15,389 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-22 20:32:15,454 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-22 20:32:19,934 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:19,939 : [INFO]  Batch 43: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:20,024 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:20,027 : [INFO]  Batch 43: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:20,205 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:20,209 : [INFO]  Batch 43: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:20,219 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:20,222 : [INFO]  Batch 43: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:20,222 : [INFO]  Batch 43, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:20,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:20,223 : [INFO]  Batch 43, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:20,223 : [INFO]  Batch 43, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:20,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:20,223 : [INFO]  Batch 43, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:20,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:20,223 : [INFO]  ____________________________________ Batch 43: round 1 finished ____________________________________
2023-03-22 20:32:20,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:20,225 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-22 20:32:20,225 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-22 20:32:20,226 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-22 20:32:20,226 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-22 20:32:22,329 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:22,332 : [INFO]  Batch 43: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:22,528 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:22,531 : [INFO]  Batch 43: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:22,590 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:22,594 : [INFO]  Batch 43: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:22,670 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:22,673 : [INFO]  Batch 43: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:22,673 : [INFO]  Batch 43, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:22,673 : [INFO]  Batch 43, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:22,673 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:22,673 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:22,674 : [INFO]  Batch 43, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:22,674 : [INFO]  Batch 43, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:22,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:22,674 : [INFO]  ____________________________________ Batch 43: round 2 finished ____________________________________
2023-03-22 20:32:22,674 : [INFO]  #################################### Batch 43: sent the final model to clients ####################################
2023-03-22 20:32:22,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:22,675 : [INFO]  Batch number 43 model fetched from the server
2023-03-22 20:32:22,675 : [INFO]  ################ Batch 43: final global model evalution after 2 rounds ################
2023-03-22 20:32:22,676 : [INFO]  Batch number 43 model fetched from the server
2023-03-22 20:32:22,676 : [INFO]  ################ Batch 43: final global model evalution after 2 rounds ################
2023-03-22 20:32:22,676 : [INFO]  Batch number 43 model fetched from the server
2023-03-22 20:32:22,677 : [INFO]  ################ Batch 43: final global model evalution after 2 rounds ################
2023-03-22 20:32:22,677 : [INFO]  Batch number 43 model fetched from the server
2023-03-22 20:32:22,677 : [INFO]  ################ Batch 43: final global model evalution after 2 rounds ################
2023-03-22 20:32:24,548 : [INFO]  Batch 43: Training set : loss - 0.53, accuracy - 0.77, recall - 0.95, AUC - 0.91, F1 - 0.81, precision - 0.7, training time - -7.0 seconds
2023-03-22 20:32:24,549 : [INFO]  Batch 43: Testing set : loss - 0.53, accuracy - 0.77, recall - 0.94, AUC - 0.9, F1 - 0.81, precision - 0.71
2023-03-22 20:32:24,560 : [INFO]  Batch 44 initialized 
2023-03-22 20:32:24,575 : [INFO]  Batch 43: Training set : loss - 0.56, accuracy - 0.76, recall - 0.96, AUC - 0.9, F1 - 0.8, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:32:24,575 : [INFO]  Batch 43: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.95, AUC - 0.9, F1 - 0.77, precision - 0.65
2023-03-22 20:32:24,580 : [INFO]  Batch 44 initialized 
2023-03-22 20:32:24,644 : [INFO]  Batch 43: Training set : loss - 0.53, accuracy - 0.79, recall - 0.98, AUC - 0.92, F1 - 0.82, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:32:24,644 : [INFO]  Batch 43: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.91, AUC - 0.9, F1 - 0.76, precision - 0.65
2023-03-22 20:32:24,650 : [INFO]  Batch 44 initialized 
2023-03-22 20:32:24,653 : [INFO]  Batch 43: Training set : loss - 0.53, accuracy - 0.79, recall - 0.96, AUC - 0.94, F1 - 0.82, precision - 0.72, training time - -7.0 seconds
2023-03-22 20:32:24,653 : [INFO]  Batch 43: Testing set : loss - 0.55, accuracy - 0.76, recall - 0.97, AUC - 0.93, F1 - 0.8, precision - 0.68
2023-03-22 20:32:24,659 : [INFO]  Batch 44 initialized 
2023-03-22 20:32:25,109 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:25,110 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:25,197 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:25,203 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:25,498 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-22 20:32:25,502 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-22 20:32:25,576 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-22 20:32:25,581 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-22 20:32:30,221 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:30,226 : [INFO]  Batch 44: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:30,239 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:30,244 : [INFO]  Batch 44: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:30,302 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:30,306 : [INFO]  Batch 44: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:30,342 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:30,345 : [INFO]  Batch 44: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:30,345 : [INFO]  Batch 44, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:30,345 : [INFO]  Batch 44, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:30,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:30,345 : [INFO]  Batch 44, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:30,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:30,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:30,345 : [INFO]  Batch 44, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:30,346 : [INFO]  ____________________________________ Batch 44: round 1 finished ____________________________________
2023-03-22 20:32:30,346 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:30,348 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-22 20:32:30,348 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-22 20:32:30,348 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-22 20:32:30,349 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-22 20:32:32,620 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:32,623 : [INFO]  Batch 44: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:32,664 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:32,668 : [INFO]  Batch 44: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:32,691 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:32,694 : [INFO]  Batch 44: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:32,702 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:32,705 : [INFO]  Batch 44: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:32,706 : [INFO]  Batch 44, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:32,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:32,706 : [INFO]  Batch 44, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:32,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:32,706 : [INFO]  Batch 44, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:32,706 : [INFO]  Batch 44, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:32,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:32,706 : [INFO]  ____________________________________ Batch 44: round 2 finished ____________________________________
2023-03-22 20:32:32,706 : [INFO]  #################################### Batch 44: sent the final model to clients ####################################
2023-03-22 20:32:32,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:32,708 : [INFO]  Batch number 44 model fetched from the server
2023-03-22 20:32:32,708 : [INFO]  ################ Batch 44: final global model evalution after 2 rounds ################
2023-03-22 20:32:32,709 : [INFO]  Batch number 44 model fetched from the server
2023-03-22 20:32:32,709 : [INFO]  ################ Batch 44: final global model evalution after 2 rounds ################
2023-03-22 20:32:32,709 : [INFO]  Batch number 44 model fetched from the server
2023-03-22 20:32:32,709 : [INFO]  ################ Batch 44: final global model evalution after 2 rounds ################
2023-03-22 20:32:32,710 : [INFO]  Batch number 44 model fetched from the server
2023-03-22 20:32:32,710 : [INFO]  ################ Batch 44: final global model evalution after 2 rounds ################
2023-03-22 20:32:34,577 : [INFO]  Batch 44: Training set : loss - 0.56, accuracy - 0.74, recall - 0.93, AUC - 0.89, F1 - 0.79, precision - 0.68, training time - -7.0 seconds
2023-03-22 20:32:34,578 : [INFO]  Batch 44: Testing set : loss - 0.54, accuracy - 0.74, recall - 0.98, AUC - 0.93, F1 - 0.79, precision - 0.66
2023-03-22 20:32:34,590 : [INFO]  Batch 45 initialized 
2023-03-22 20:32:34,609 : [INFO]  Batch 44: Training set : loss - 0.54, accuracy - 0.76, recall - 0.95, AUC - 0.9, F1 - 0.8, precision - 0.69, training time - -7.0 seconds
2023-03-22 20:32:34,610 : [INFO]  Batch 44: Testing set : loss - 0.55, accuracy - 0.72, recall - 0.96, AUC - 0.91, F1 - 0.77, precision - 0.64
2023-03-22 20:32:34,614 : [INFO]  Batch 45 initialized 
2023-03-22 20:32:34,699 : [INFO]  Batch 44: Training set : loss - 0.55, accuracy - 0.74, recall - 0.93, AUC - 0.92, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:32:34,699 : [INFO]  Batch 44: Testing set : loss - 0.56, accuracy - 0.72, recall - 0.95, AUC - 0.91, F1 - 0.77, precision - 0.65
2023-03-22 20:32:34,704 : [INFO]  Batch 45 initialized 
2023-03-22 20:32:34,816 : [INFO]  Batch 44: Training set : loss - 0.56, accuracy - 0.75, recall - 0.97, AUC - 0.92, F1 - 0.79, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:32:34,816 : [INFO]  Batch 44: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.91, AUC - 0.86, F1 - 0.78, precision - 0.69
2023-03-22 20:32:34,845 : [INFO]  Batch 45 initialized 
2023-03-22 20:32:35,121 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:35,133 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:35,240 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:35,463 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:35,475 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-22 20:32:35,484 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-22 20:32:35,588 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-22 20:32:35,747 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-22 20:32:40,207 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:40,211 : [INFO]  Batch 45: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:40,352 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:40,356 : [INFO]  Batch 45: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:40,365 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:40,369 : [INFO]  Batch 45: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:40,417 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:40,421 : [INFO]  Batch 45: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:40,421 : [INFO]  Batch 45, round 1: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:40,421 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:40,421 : [INFO]  Batch 45, round 1: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:40,421 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:40,422 : [INFO]  Batch 45, round 1: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:40,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:40,422 : [INFO]  Batch 45, round 1: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:40,422 : [INFO]  ____________________________________ Batch 45: round 1 finished ____________________________________
2023-03-22 20:32:40,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:40,424 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-22 20:32:40,424 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-22 20:32:40,425 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-22 20:32:40,425 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-22 20:32:42,738 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:42,742 : [INFO]  Batch 45: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:42,749 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:42,753 : [INFO]  Batch 45: recieved model from client-3 at 127.0.0.1:39816
2023-03-22 20:32:42,765 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:42,768 : [INFO]  Batch 45: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:42,781 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-22 20:32:42,785 : [INFO]  Batch 45: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:32:42,785 : [INFO]  Batch 45, round 2: aggregated global model sent to client-0 at 127.0.0.1:35252
2023-03-22 20:32:42,785 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:42,785 : [INFO]  Batch 45, round 2: aggregated global model sent to client-1 at 127.0.0.1:40914
2023-03-22 20:32:42,785 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:42,785 : [INFO]  Batch 45, round 2: aggregated global model sent to client-2 at 127.0.0.1:39802
2023-03-22 20:32:42,785 : [INFO]  Batch 45, round 2: aggregated global model sent to client-3 at 127.0.0.1:39816
2023-03-22 20:32:42,785 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:42,786 : [INFO]  ____________________________________ Batch 45: round 2 finished ____________________________________
2023-03-22 20:32:42,786 : [INFO]  #################################### Batch 45: sent the final model to clients ####################################
2023-03-22 20:32:42,786 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 20:32:42,788 : [INFO]  Batch number 45 model fetched from the server
2023-03-22 20:32:42,788 : [INFO]  Batch number 45 model fetched from the server
2023-03-22 20:32:42,788 : [INFO]  ################ Batch 45: final global model evalution after 2 rounds ################
2023-03-22 20:32:42,788 : [INFO]  ################ Batch 45: final global model evalution after 2 rounds ################
2023-03-22 20:32:42,788 : [INFO]  Batch number 45 model fetched from the server
2023-03-22 20:32:42,789 : [INFO]  ################ Batch 45: final global model evalution after 2 rounds ################
2023-03-22 20:32:42,789 : [INFO]  Batch number 45 model fetched from the server
2023-03-22 20:32:42,789 : [INFO]  ################ Batch 45: final global model evalution after 2 rounds ################
2023-03-22 20:32:44,680 : [INFO]  Batch 45: Training set : loss - 0.53, accuracy - 0.78, recall - 0.95, AUC - 0.93, F1 - 0.81, precision - 0.71, training time - -7.0 seconds
2023-03-22 20:32:44,681 : [INFO]  Batch 45: Testing set : loss - 0.58, accuracy - 0.72, recall - 0.9, AUC - 0.85, F1 - 0.76, precision - 0.66
2023-03-22 20:32:44,692 : [INFO]  Batch 46 initialized 
2023-03-22 20:32:44,701 : [INFO]  Batch 45: Training set : loss - 0.56, accuracy - 0.73, recall - 0.99, AUC - 0.91, F1 - 0.78, precision - 0.65, training time - -7.0 seconds
2023-03-22 20:32:44,702 : [INFO]  Batch 45: Testing set : loss - 0.55, accuracy - 0.73, recall - 0.97, AUC - 0.92, F1 - 0.78, precision - 0.65
2023-03-22 20:32:44,709 : [INFO]  Batch 46 initialized 
2023-03-22 20:32:44,709 : [INFO]  Batch 45: Training set : loss - 0.56, accuracy - 0.74, recall - 0.98, AUC - 0.89, F1 - 0.79, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:32:44,709 : [INFO]  Batch 45: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.91, AUC - 0.88, F1 - 0.77, precision - 0.66
2023-03-22 20:32:44,833 : [INFO]  Batch 45: Training set : loss - 0.53, accuracy - 0.74, recall - 0.93, AUC - 0.94, F1 - 0.78, precision - 0.67, training time - -7.0 seconds
2023-03-22 20:32:44,833 : [INFO]  Batch 45: Testing set : loss - 0.54, accuracy - 0.76, recall - 0.96, AUC - 0.92, F1 - 0.8, precision - 0.69
2023-03-22 20:32:44,860 : [INFO]  Batch 46 initialized 
2023-03-22 20:32:45,081 : [ERROR]  Client-3 closed connection at 127.0.0.1:39816
2023-03-22 20:32:45,225 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:45,248 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:45,463 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 20:32:45,613 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-22 20:32:45,646 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-22 20:32:45,816 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-22 20:32:49,701 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:49,704 : [INFO]  Batch 46: recieved model from client-2 at 127.0.0.1:39802
2023-03-22 20:32:49,716 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:49,719 : [INFO]  Batch 46: recieved model from client-0 at 127.0.0.1:35252
2023-03-22 20:32:49,972 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-22 20:32:49,975 : [INFO]  Batch 46: recieved model from client-1 at 127.0.0.1:40914
2023-03-22 20:51:06,907 : [ERROR]  Client-2 closed connection at 127.0.0.1:39802
2023-03-22 20:51:08,942 : [ERROR]  Client-1 closed connection at 127.0.0.1:40914
2023-03-22 20:51:10,948 : [ERROR]  Client-0 closed connection at 127.0.0.1:35252
2023-03-22 21:07:59,060 : [WARNING]  ####################################### New Training Session #######################################
2023-03-22 21:07:59,060 : [INFO]  Server started , graph ID 1, number of clients 4, number of rounds 5, number of timestamps 134
2023-03-22 21:08:01,129 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:08:01,240 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 21:08:06,694 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-22 21:08:06,694 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-22 21:08:06,706 : [INFO]  Model initialized for training
2023-03-22 21:08:08,410 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:08:08,431 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-22 21:08:08,431 : [INFO]  Connected to the server
2023-03-22 21:08:08,431 : [INFO]  Accepted new connection at 127.0.0.1:41792
2023-03-22 21:08:08,432 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:41792
2023-03-22 21:08:08,520 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 21:08:08,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:08:08,528 : [INFO]  ################################## Initial model training started ##################################
2023-03-22 21:08:08,528 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-22 21:08:35,458 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-22 21:08:35,460 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:41792
2023-03-22 21:09:10,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:09:14,995 : [WARNING]  ####################################### New Training Session #######################################
2023-03-22 21:09:14,995 : [INFO]  Server started , graph ID 1, number of clients 4, number of rounds 5, number of timestamps 134
2023-03-22 21:09:16,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:09:16,848 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 21:09:27,246 : [WARNING]  ####################################### New Training Session #######################################
2023-03-22 21:09:27,246 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 5, number of timestamps 134
2023-03-22 21:09:29,417 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:09:29,526 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 21:09:30,290 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-22 21:09:30,291 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-22 21:09:30,295 : [INFO]  Model initialized for training
2023-03-22 21:09:32,027 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:09:32,050 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-22 21:09:32,050 : [INFO]  Connected to the server
2023-03-22 21:09:32,050 : [INFO]  Accepted new connection at 127.0.0.1:56240
2023-03-22 21:09:32,050 : [INFO]  Randomly initialized global model sent to client-new at 127.0.0.1:56240
2023-03-22 21:09:32,139 : [INFO]  Distributed training for streaming graphs started!
2023-03-22 21:09:32,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:09:32,146 : [INFO]  ################################## Initial model training started ##################################
2023-03-22 21:09:32,146 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-22 21:10:01,423 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-22 21:10:01,425 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:10:01,425 : [INFO]  Initial training round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:10:01,425 : [INFO]  ____________________________________ Initial training: round 1 finished ____________________________________
2023-03-22 21:10:01,425 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:10:01,427 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-22 21:10:27,912 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-22 21:10:27,919 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:10:27,919 : [INFO]  Initial training round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:10:27,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:10:27,919 : [INFO]  ____________________________________ Initial training: round 2 finished ____________________________________
2023-03-22 21:10:27,921 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-22 21:10:55,217 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-22 21:10:55,219 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:10:55,219 : [INFO]  Initial training round 3: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:10:55,220 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:10:55,220 : [INFO]  ____________________________________ Initial training: round 3 finished ____________________________________
2023-03-22 21:10:55,221 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-22 21:11:23,528 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-22 21:11:23,531 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:11:23,531 : [INFO]  Initial training round 4: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:11:23,531 : [INFO]  ____________________________________ Initial training: round 4 finished ____________________________________
2023-03-22 21:11:23,531 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:11:23,533 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-22 21:11:51,439 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-22 21:11:51,443 : [INFO]  Initial training: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:11:51,443 : [INFO]  Initial training round 5: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:11:51,443 : [INFO]  ____________________________________ Initial training: round 5 finished ____________________________________
2023-03-22 21:11:51,443 : [INFO]  #################################### Initial Trained final model sent to clients ####################################
2023-03-22 21:11:51,443 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:11:51,445 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-22 21:11:57,627 : [INFO]  Initially trained model: Training set : loss - 0.55, accuracy - 0.74, recall - 0.91, AUC - 0.89, F1 - 0.78, precision - 0.68, training time - -139.0 seconds
2023-03-22 21:11:57,627 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.9, AUC - 0.87, F1 - 0.76, precision - 0.65
2023-03-22 21:11:57,630 : [INFO]  Batch 1 initialized 
2023-03-22 21:11:57,950 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:11:58,068 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-22 21:11:58,068 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-22 21:12:00,751 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:00,754 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:00,754 : [INFO]  Batch 1, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:00,754 : [INFO]  ____________________________________ Batch 1: round 1 finished ____________________________________
2023-03-22 21:12:00,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:00,756 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-22 21:12:02,074 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:02,076 : [INFO]  Batch 1: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:02,077 : [INFO]  Batch 1, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:02,077 : [INFO]  ____________________________________ Batch 1: round 2 finished ____________________________________
2023-03-22 21:12:02,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:02,077 : [INFO]  #################################### Batch 1: sent the final model to clients ####################################
2023-03-22 21:12:02,078 : [INFO]  Batch number 1 model fetched from the server
2023-03-22 21:12:02,078 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-22 21:12:03,163 : [INFO]  Batch 1: Training set : loss - 0.53, accuracy - 0.76, recall - 0.95, AUC - 0.92, F1 - 0.8, precision - 0.69, training time - -4.0 seconds
2023-03-22 21:12:03,164 : [INFO]  Batch 1: Testing set : loss - 0.59, accuracy - 0.68, recall - 0.91, AUC - 0.86, F1 - 0.74, precision - 0.62
2023-03-22 21:12:03,166 : [INFO]  Batch 2 initialized 
2023-03-22 21:12:03,488 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:03,667 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-22 21:12:06,310 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:06,313 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:06,313 : [INFO]  Batch 2, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:06,313 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:06,313 : [INFO]  ____________________________________ Batch 2: round 1 finished ____________________________________
2023-03-22 21:12:06,315 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-22 21:12:07,598 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:07,600 : [INFO]  Batch 2: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:07,600 : [INFO]  Batch 2, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:07,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:07,600 : [INFO]  ____________________________________ Batch 2: round 2 finished ____________________________________
2023-03-22 21:12:07,600 : [INFO]  #################################### Batch 2: sent the final model to clients ####################################
2023-03-22 21:12:07,602 : [INFO]  Batch number 2 model fetched from the server
2023-03-22 21:12:07,602 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-22 21:12:08,694 : [INFO]  Batch 2: Training set : loss - 0.51, accuracy - 0.8, recall - 0.98, AUC - 0.94, F1 - 0.83, precision - 0.73, training time - -4.0 seconds
2023-03-22 21:12:08,694 : [INFO]  Batch 2: Testing set : loss - 0.58, accuracy - 0.69, recall - 0.96, AUC - 0.89, F1 - 0.76, precision - 0.62
2023-03-22 21:12:08,697 : [INFO]  Batch 3 initialized 
2023-03-22 21:12:09,020 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:09,193 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-22 21:12:11,808 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:11,811 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:11,811 : [INFO]  Batch 3, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:11,811 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:11,811 : [INFO]  ____________________________________ Batch 3: round 1 finished ____________________________________
2023-03-22 21:12:11,813 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-22 21:12:13,104 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:13,107 : [INFO]  Batch 3: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:13,107 : [INFO]  Batch 3, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:13,107 : [INFO]  ____________________________________ Batch 3: round 2 finished ____________________________________
2023-03-22 21:12:13,107 : [INFO]  #################################### Batch 3: sent the final model to clients ####################################
2023-03-22 21:12:13,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:13,109 : [INFO]  Batch number 3 model fetched from the server
2023-03-22 21:12:13,109 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-22 21:12:14,209 : [INFO]  Batch 3: Training set : loss - 0.54, accuracy - 0.76, recall - 0.88, AUC - 0.91, F1 - 0.78, precision - 0.7, training time - -4.0 seconds
2023-03-22 21:12:14,209 : [INFO]  Batch 3: Testing set : loss - 0.58, accuracy - 0.69, recall - 0.88, AUC - 0.86, F1 - 0.74, precision - 0.63
2023-03-22 21:12:14,212 : [INFO]  Batch 4 initialized 
2023-03-22 21:12:14,528 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:14,701 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-22 21:12:17,316 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:17,318 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:17,319 : [INFO]  Batch 4, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:17,319 : [INFO]  ____________________________________ Batch 4: round 1 finished ____________________________________
2023-03-22 21:12:17,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:17,322 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-22 21:12:18,604 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:18,607 : [INFO]  Batch 4: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:18,608 : [INFO]  Batch 4, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:18,608 : [INFO]  ____________________________________ Batch 4: round 2 finished ____________________________________
2023-03-22 21:12:18,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:18,608 : [INFO]  #################################### Batch 4: sent the final model to clients ####################################
2023-03-22 21:12:18,609 : [INFO]  Batch number 4 model fetched from the server
2023-03-22 21:12:18,609 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-22 21:12:19,705 : [INFO]  Batch 4: Training set : loss - 0.54, accuracy - 0.76, recall - 0.97, AUC - 0.89, F1 - 0.8, precision - 0.68, training time - -4.0 seconds
2023-03-22 21:12:19,705 : [INFO]  Batch 4: Testing set : loss - 0.58, accuracy - 0.69, recall - 0.89, AUC - 0.85, F1 - 0.74, precision - 0.64
2023-03-22 21:12:19,708 : [INFO]  Batch 5 initialized 
2023-03-22 21:12:20,037 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:20,219 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-22 21:12:22,819 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:22,822 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:22,822 : [INFO]  Batch 5, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:22,822 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:22,822 : [INFO]  ____________________________________ Batch 5: round 1 finished ____________________________________
2023-03-22 21:12:22,823 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-22 21:12:24,113 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:24,115 : [INFO]  Batch 5: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:24,115 : [INFO]  Batch 5, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:24,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:24,115 : [INFO]  ____________________________________ Batch 5: round 2 finished ____________________________________
2023-03-22 21:12:24,115 : [INFO]  #################################### Batch 5: sent the final model to clients ####################################
2023-03-22 21:12:24,117 : [INFO]  Batch number 5 model fetched from the server
2023-03-22 21:12:24,117 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-22 21:12:25,230 : [INFO]  Batch 5: Training set : loss - 0.55, accuracy - 0.77, recall - 0.96, AUC - 0.88, F1 - 0.81, precision - 0.7, training time - -4.0 seconds
2023-03-22 21:12:25,231 : [INFO]  Batch 5: Testing set : loss - 0.55, accuracy - 0.75, recall - 0.98, AUC - 0.91, F1 - 0.8, precision - 0.68
2023-03-22 21:12:25,234 : [INFO]  Batch 6 initialized 
2023-03-22 21:12:25,556 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:25,738 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-22 21:12:28,355 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:28,358 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:28,358 : [INFO]  Batch 6, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:28,359 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:28,359 : [INFO]  ____________________________________ Batch 6: round 1 finished ____________________________________
2023-03-22 21:12:28,360 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-22 21:12:29,610 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:29,612 : [INFO]  Batch 6: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:29,612 : [INFO]  Batch 6, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:29,613 : [INFO]  ____________________________________ Batch 6: round 2 finished ____________________________________
2023-03-22 21:12:29,613 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:29,613 : [INFO]  #################################### Batch 6: sent the final model to clients ####################################
2023-03-22 21:12:29,614 : [INFO]  Batch number 6 model fetched from the server
2023-03-22 21:12:29,614 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-22 21:12:30,727 : [INFO]  Batch 6: Training set : loss - 0.56, accuracy - 0.73, recall - 0.88, AUC - 0.86, F1 - 0.76, precision - 0.68, training time - -4.0 seconds
2023-03-22 21:12:30,727 : [INFO]  Batch 6: Testing set : loss - 0.57, accuracy - 0.71, recall - 0.92, AUC - 0.9, F1 - 0.76, precision - 0.64
2023-03-22 21:12:30,730 : [INFO]  Batch 7 initialized 
2023-03-22 21:12:31,057 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:31,246 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-22 21:12:33,896 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:33,898 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:33,898 : [INFO]  Batch 7, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:33,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:33,898 : [INFO]  ____________________________________ Batch 7: round 1 finished ____________________________________
2023-03-22 21:12:33,900 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-22 21:12:35,371 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:35,387 : [INFO]  Batch 7: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:35,388 : [INFO]  Batch 7, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:35,388 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:35,388 : [INFO]  ____________________________________ Batch 7: round 2 finished ____________________________________
2023-03-22 21:12:35,388 : [INFO]  #################################### Batch 7: sent the final model to clients ####################################
2023-03-22 21:12:35,393 : [INFO]  Batch number 7 model fetched from the server
2023-03-22 21:12:35,393 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-22 21:12:36,754 : [INFO]  Batch 7: Training set : loss - 0.53, accuracy - 0.8, recall - 0.93, AUC - 0.91, F1 - 0.83, precision - 0.74, training time - -4.0 seconds
2023-03-22 21:12:36,754 : [INFO]  Batch 7: Testing set : loss - 0.57, accuracy - 0.69, recall - 0.87, AUC - 0.87, F1 - 0.74, precision - 0.64
2023-03-22 21:12:36,757 : [INFO]  Batch 8 initialized 
2023-03-22 21:12:37,175 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:37,523 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-22 21:12:40,723 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-22 21:12:40,725 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:40,725 : [INFO]  Batch 8, round 1: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:40,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:40,726 : [INFO]  ____________________________________ Batch 8: round 1 finished ____________________________________
2023-03-22 21:12:40,727 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-22 21:12:41,962 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-22 21:12:41,964 : [INFO]  Batch 8: recieved model from client-0 at 127.0.0.1:56240
2023-03-22 21:12:41,965 : [INFO]  Batch 8, round 2: aggregated global model sent to client-0 at 127.0.0.1:56240
2023-03-22 21:12:41,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-22 21:12:41,965 : [INFO]  ____________________________________ Batch 8: round 2 finished ____________________________________
2023-03-22 21:12:41,965 : [INFO]  #################################### Batch 8: sent the final model to clients ####################################
2023-03-22 21:12:41,966 : [INFO]  Batch number 8 model fetched from the server
2023-03-22 21:12:41,966 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-22 21:12:43,114 : [INFO]  Batch 8: Training set : loss - 0.54, accuracy - 0.79, recall - 0.95, AUC - 0.89, F1 - 0.82, precision - 0.73, training time - -4.0 seconds
2023-03-22 21:12:43,115 : [INFO]  Batch 8: Testing set : loss - 0.58, accuracy - 0.69, recall - 0.85, AUC - 0.83, F1 - 0.73, precision - 0.64
2023-03-22 21:12:43,118 : [INFO]  Batch 9 initialized 
2023-03-22 21:12:43,462 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-22 21:12:43,648 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-22 21:12:47,278 : [ERROR]  Client-0 closed connection at 127.0.0.1:56240
2023-03-23 11:15:34,177 : [WARNING]  ####################################### New Training Session #######################################
2023-03-23 11:17:27,100 : [WARNING]  ####################################### New Training Session #######################################
2023-03-23 11:19:16,201 : [WARNING]  ####################################### New Training Session #######################################
2023-03-23 11:19:16,201 : [INFO]  Server started , graph ID 1, number of clients 1, number of rounds 5, number of timestamps 45
2023-03-23 11:19:18,040 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:19:18,155 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:22:51,035 : [WARNING]  ####################################### New Training Session #######################################
2023-03-23 11:22:52,908 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:22:53,024 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:23:22,278 : [WARNING]  ####################################### New Training Session #######################################
2023-03-23 11:23:24,020 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:23:24,133 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:23:40,874 : [WARNING]  ####################################### New Training Session #######################################
2023-03-23 11:23:42,647 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:23:42,761 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:24:03,735 : [INFO]  ####################################### New Training Session #######################################
2023-03-23 11:24:05,464 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:24:05,575 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:24:41,958 : [INFO]  ####################################### New Training Session #######################################
2023-03-23 11:24:43,664 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:24:43,770 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:25:32,560 : [INFO]  ####################################### New Training Session #######################################
2023-03-23 11:25:34,280 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:25:34,389 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:26:11,272 : [INFO]  ####################################### New Training Session #######################################
2023-03-23 11:26:13,045 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:26:13,157 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:36:09,349 : [INFO]  ####################################### New Training Session #######################################
2023-03-23 11:36:11,094 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:36:11,208 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:36:49,747 : [INFO]  ####################################### New Training Session #######################################
2023-03-23 11:36:51,465 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:36:51,580 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:38:47,862 : [INFO]  ####################################### New Training Session #######################################
2023-03-23 11:38:49,647 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:38:49,757 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:39:08,410 : [INFO]  rSADasASSa
2023-03-23 11:39:10,156 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:39:10,267 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:39:23,577 : [INFO]  rSADasASSa
2023-03-23 11:39:25,300 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:39:25,415 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:39:25,416 : [INFO]  Distributed training done!
2023-03-23 11:40:26,071 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:40:26,072 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:40:26,086 : [INFO]  Model initialized for training
2023-03-23 11:40:27,816 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-23 11:40:27,838 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-23 11:43:50,157 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:43:50,158 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:44:04,367 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:44:04,367 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:44:28,768 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:44:28,769 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:44:44,848 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:44:44,848 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:45:24,776 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:45:24,776 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:45:36,658 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:45:36,658 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:45:48,608 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:45:48,608 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:46:09,351 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:46:09,351 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:46:26,750 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:46:26,750 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:46:45,217 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:46:45,218 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:48:26,713 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:48:26,713 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:48:33,464 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:48:33,464 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:48:57,453 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-23 11:48:57,453 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 10, epochs 4
2023-03-23 11:51:38,397 : [INFO]  Connected to the server
2023-03-23 11:51:38,504 : [INFO]  Distributed training for streaming graphs started!
2023-03-23 11:51:38,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-23 11:51:38,511 : [INFO]  ################################## Initial model training started ##################################
2023-03-23 11:51:38,511 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-23 11:52:06,458 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-23 11:52:06,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-23 11:52:06,465 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-23 11:52:36,586 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-23 11:52:36,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-23 11:52:36,591 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-23 11:53:07,887 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-23 11:53:07,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-23 11:53:07,891 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-23 11:53:35,190 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-23 11:53:35,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-23 11:53:35,198 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-23 11:54:21,035 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-23 11:54:21,049 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
