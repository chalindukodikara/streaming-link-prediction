2023-03-25 19:49:52,565 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 19:49:52,566 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 6, epochs 6
2023-03-25 19:49:55,390 : [INFO]  Model initialized for training
2023-03-25 19:50:06,485 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:50:06,594 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 19:50:06,595 : [INFO]  Connected to the server
2023-03-25 19:50:06,668 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 19:50:06,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:50:06,675 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 19:50:06,675 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 19:52:21,978 : [INFO]  ------------------------- Training round 1, loss: 0.6208 -------------------------
2023-03-25 19:52:21,978 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 19:52:24,983 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:52:24,986 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 19:55:11,907 : [INFO]  ------------------------- Training round 2, loss: 0.5945 -------------------------
2023-03-25 19:55:11,907 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 19:55:11,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:55:11,913 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 19:57:50,398 : [INFO]  ------------------------- Training round 3, loss: 0.5912 -------------------------
2023-03-25 19:57:50,399 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 19:58:04,928 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:58:04,931 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 20:00:54,260 : [INFO]  ------------------------- Training round 4, loss: 0.589 -------------------------
2023-03-25 20:00:54,260 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 20:00:54,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:00:54,270 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 20:03:37,639 : [INFO]  ------------------------- Training round 5, loss: 0.5887 -------------------------
2023-03-25 20:03:37,639 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 20:03:37,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:03:37,651 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-25 20:06:41,991 : [INFO]  ------------------------- Training round 6, loss: 0.5866 -------------------------
2023-03-25 20:06:41,991 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-25 20:06:41,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:06:41,996 : [INFO]  ------------------------- Initial model training: round 7 -------------------------
2023-03-25 20:09:21,206 : [INFO]  ------------------------- Training round 7, loss: 0.5864 -------------------------
2023-03-25 20:09:21,206 : [INFO]  ------------------------- Training, round 7: Sent local model to the server -------------------------
2023-03-25 20:09:21,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:09:21,212 : [INFO]  ------------------------- Initial model training: round 8 -------------------------
2023-03-25 20:11:59,354 : [INFO]  ------------------------- Training round 8, loss: 0.5857 -------------------------
2023-03-25 20:11:59,354 : [INFO]  ------------------------- Training, round 8: Sent local model to the server -------------------------
2023-03-25 20:11:59,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:11:59,359 : [INFO]  ################ Initial trained model: Final global model evalution after 8 rounds ################
2023-03-25 20:12:50,767 : [INFO]  Initially trained model: Training set : loss - 0.58, accuracy - 0.71, recall - 0.89, AUC - 0.84, F1 - 0.75, precision - 0.66, training time - -1313.0 seconds
2023-03-25 20:12:50,767 : [INFO]  Initially trained model: Testing set : loss - 0.58, accuracy - 0.7, recall - 0.88, AUC - 0.84, F1 - 0.75, precision - 0.65
2023-03-25 20:12:50,779 : [INFO]  Batch 1 initialized 
2023-03-25 20:12:51,309 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:12:51,457 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 20:12:51,457 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 20:12:56,124 : [INFO]  ------------------------- Batch round 1, loss: 0.5873 -------------------------
2023-03-25 20:12:56,124 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 20:12:56,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:12:56,129 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 20:12:58,460 : [INFO]  ------------------------- Batch round 2, loss: 0.5781 -------------------------
2023-03-25 20:12:58,460 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 20:12:58,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:12:58,583 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 20:13:01,111 : [INFO]  ------------------------- Batch round 3, loss: 0.5665 -------------------------
2023-03-25 20:13:01,111 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:01,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:01,117 : [INFO]  ------------------------- Batch 1 training: round 4 -------------------------
2023-03-25 20:13:03,512 : [INFO]  ------------------------- Batch round 4, loss: 0.5684 -------------------------
2023-03-25 20:13:03,512 : [INFO]  ------------------------- Batch 1, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:03,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:03,625 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 20:13:03,625 : [INFO]  ################ Batch 1: final global model evalution after 4 rounds ################
2023-03-25 20:13:05,080 : [INFO]  Batch 1: Training set : loss - 0.5608, accuracy - 0.7663, recall - 0.913, AUC - 0.8755, F1 - 0.7962, precision - 0.7059, training time - -12.0 seconds
2023-03-25 20:13:05,080 : [INFO]  Batch 1: Testing set : loss - 0.5615, accuracy - 0.7255, recall - 0.902, AUC - 0.8869, F1 - 0.7667, precision - 0.6667
2023-03-25 20:13:05,093 : [INFO]  Batch 2 initialized 
2023-03-25 20:13:05,605 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:05,794 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 20:13:10,214 : [INFO]  ------------------------- Batch round 1, loss: 0.5531 -------------------------
2023-03-25 20:13:10,214 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:10,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:10,219 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 20:13:12,539 : [INFO]  ------------------------- Batch round 2, loss: 0.5379 -------------------------
2023-03-25 20:13:12,540 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 20:13:12,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:12,546 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 20:13:14,913 : [INFO]  ------------------------- Batch round 3, loss: 0.538 -------------------------
2023-03-25 20:13:14,913 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:14,935 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:14,937 : [INFO]  ------------------------- Batch 2 training: round 4 -------------------------
2023-03-25 20:13:17,138 : [INFO]  ------------------------- Batch round 4, loss: 0.5365 -------------------------
2023-03-25 20:13:17,138 : [INFO]  ------------------------- Batch 2, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:17,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:17,404 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 20:13:17,404 : [INFO]  ################ Batch 2: final global model evalution after 4 rounds ################
2023-03-25 20:13:18,845 : [INFO]  Batch 2: Training set : loss - 0.523, accuracy - 0.7989, recall - 0.9348, AUC - 0.8973, F1 - 0.823, precision - 0.735, training time - -12.0 seconds
2023-03-25 20:13:18,845 : [INFO]  Batch 2: Testing set : loss - 0.5391, accuracy - 0.7794, recall - 0.9412, AUC - 0.9185, F1 - 0.8101, precision - 0.7111
2023-03-25 20:13:18,858 : [INFO]  Batch 3 initialized 
2023-03-25 20:13:19,348 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:19,618 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 20:13:24,062 : [INFO]  ------------------------- Batch round 1, loss: 0.5584 -------------------------
2023-03-25 20:13:24,062 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:24,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:24,068 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 20:13:26,644 : [INFO]  ------------------------- Batch round 2, loss: 0.5497 -------------------------
2023-03-25 20:13:26,645 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 20:13:26,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:26,649 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 20:13:29,306 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 20:13:29,306 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:29,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:29,311 : [INFO]  ------------------------- Batch 3 training: round 4 -------------------------
2023-03-25 20:13:32,103 : [INFO]  ------------------------- Batch round 4, loss: 0.5404 -------------------------
2023-03-25 20:13:32,104 : [INFO]  ------------------------- Batch 3, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:32,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:32,113 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 20:13:32,113 : [INFO]  ################ Batch 3: final global model evalution after 4 rounds ################
2023-03-25 20:13:34,203 : [INFO]  Batch 3: Training set : loss - 0.5436, accuracy - 0.7554, recall - 0.9565, AUC - 0.9259, F1 - 0.7964, precision - 0.6822, training time - -12.0 seconds
2023-03-25 20:13:34,204 : [INFO]  Batch 3: Testing set : loss - 0.5731, accuracy - 0.6961, recall - 0.902, AUC - 0.8956, F1 - 0.748, precision - 0.6389
2023-03-25 20:13:34,213 : [INFO]  Batch 4 initialized 
2023-03-25 20:13:34,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:35,026 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 20:13:40,404 : [INFO]  ------------------------- Batch round 1, loss: 0.565 -------------------------
2023-03-25 20:13:40,405 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:40,408 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:40,410 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 20:13:43,010 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 20:13:43,010 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 20:13:43,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:43,026 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 20:13:45,355 : [INFO]  ------------------------- Batch round 3, loss: 0.5528 -------------------------
2023-03-25 20:13:45,355 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:45,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:45,415 : [INFO]  ------------------------- Batch 4 training: round 4 -------------------------
2023-03-25 20:13:48,484 : [INFO]  ------------------------- Batch round 4, loss: 0.5484 -------------------------
2023-03-25 20:13:48,485 : [INFO]  ------------------------- Batch 4, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:48,488 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:48,491 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 20:13:48,491 : [INFO]  ################ Batch 4: final global model evalution after 4 rounds ################
2023-03-25 20:13:50,720 : [INFO]  Batch 4: Training set : loss - 0.549, accuracy - 0.75, recall - 0.9239, AUC - 0.8911, F1 - 0.787, precision - 0.6855, training time - -13.0 seconds
2023-03-25 20:13:50,720 : [INFO]  Batch 4: Testing set : loss - 0.5556, accuracy - 0.7206, recall - 0.951, AUC - 0.9234, F1 - 0.7729, precision - 0.651
2023-03-25 20:13:50,727 : [INFO]  Batch 5 initialized 
2023-03-25 20:13:51,345 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:51,623 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 20:13:56,937 : [INFO]  ------------------------- Batch round 1, loss: 0.5542 -------------------------
2023-03-25 20:13:56,937 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:56,999 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:57,006 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 20:14:00,101 : [INFO]  ------------------------- Batch round 2, loss: 0.5485 -------------------------
2023-03-25 20:14:00,101 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:00,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:00,110 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 20:14:02,823 : [INFO]  ------------------------- Batch round 3, loss: 0.5401 -------------------------
2023-03-25 20:14:02,823 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:02,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:02,903 : [INFO]  ------------------------- Batch 5 training: round 4 -------------------------
2023-03-25 20:14:05,480 : [INFO]  ------------------------- Batch round 4, loss: 0.5307 -------------------------
2023-03-25 20:14:05,481 : [INFO]  ------------------------- Batch 5, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:05,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:05,538 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 20:14:05,538 : [INFO]  ################ Batch 5: final global model evalution after 4 rounds ################
2023-03-25 20:14:07,167 : [INFO]  Batch 5: Training set : loss - 0.5286, accuracy - 0.7826, recall - 0.9348, AUC - 0.9015, F1 - 0.8113, precision - 0.7167, training time - -14.0 seconds
2023-03-25 20:14:07,167 : [INFO]  Batch 5: Testing set : loss - 0.5437, accuracy - 0.7647, recall - 0.902, AUC - 0.8985, F1 - 0.7931, precision - 0.7077
2023-03-25 20:14:07,181 : [INFO]  Batch 6 initialized 
2023-03-25 20:14:07,712 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:08,007 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 20:14:13,009 : [INFO]  ------------------------- Batch round 1, loss: 0.5437 -------------------------
2023-03-25 20:14:13,009 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 20:14:13,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:13,179 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 20:14:15,611 : [INFO]  ------------------------- Batch round 2, loss: 0.5288 -------------------------
2023-03-25 20:14:15,612 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:15,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:15,651 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 20:14:18,007 : [INFO]  ------------------------- Batch round 3, loss: 0.5284 -------------------------
2023-03-25 20:14:18,007 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:18,331 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:18,334 : [INFO]  ------------------------- Batch 6 training: round 4 -------------------------
2023-03-25 20:14:21,179 : [INFO]  ------------------------- Batch round 4, loss: 0.5146 -------------------------
2023-03-25 20:14:21,179 : [INFO]  ------------------------- Batch 6, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:21,236 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:21,238 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 20:14:21,239 : [INFO]  ################ Batch 6: final global model evalution after 4 rounds ################
2023-03-25 20:14:22,850 : [INFO]  Batch 6: Training set : loss - 0.5139, accuracy - 0.8043, recall - 0.9457, AUC - 0.9125, F1 - 0.8286, precision - 0.7373, training time - -13.0 seconds
2023-03-25 20:14:22,850 : [INFO]  Batch 6: Testing set : loss - 0.5549, accuracy - 0.7255, recall - 0.9118, AUC - 0.8883, F1 - 0.7686, precision - 0.6643
2023-03-25 20:14:22,861 : [INFO]  Batch 7 initialized 
2023-03-25 20:14:23,402 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:23,705 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 20:14:28,535 : [INFO]  ------------------------- Batch round 1, loss: 0.5484 -------------------------
2023-03-25 20:14:28,536 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 20:14:28,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:28,775 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 20:14:31,426 : [INFO]  ------------------------- Batch round 2, loss: 0.5325 -------------------------
2023-03-25 20:14:31,427 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:31,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:31,486 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 20:14:33,982 : [INFO]  ------------------------- Batch round 3, loss: 0.5244 -------------------------
2023-03-25 20:14:33,982 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:34,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:34,050 : [INFO]  ------------------------- Batch 7 training: round 4 -------------------------
2023-03-25 20:14:37,271 : [INFO]  ------------------------- Batch round 4, loss: 0.5202 -------------------------
2023-03-25 20:14:37,271 : [INFO]  ------------------------- Batch 7, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:37,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:37,281 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 20:14:37,281 : [INFO]  ################ Batch 7: final global model evalution after 4 rounds ################
2023-03-25 20:14:39,767 : [INFO]  Batch 7: Training set : loss - 0.5147, accuracy - 0.8043, recall - 0.9457, AUC - 0.9201, F1 - 0.8286, precision - 0.7373, training time - -14.0 seconds
2023-03-25 20:14:39,767 : [INFO]  Batch 7: Testing set : loss - 0.5708, accuracy - 0.7304, recall - 0.9118, AUC - 0.8738, F1 - 0.7718, precision - 0.6691
2023-03-25 20:14:39,786 : [INFO]  Batch 8 initialized 
2023-03-25 20:14:40,421 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:40,756 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 20:14:46,188 : [INFO]  ------------------------- Batch round 1, loss: 0.5537 -------------------------
2023-03-25 20:14:46,188 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 20:14:46,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:46,231 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 20:14:49,524 : [INFO]  ------------------------- Batch round 2, loss: 0.5487 -------------------------
2023-03-25 20:14:49,525 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:49,531 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:49,537 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 20:14:53,210 : [INFO]  ------------------------- Batch round 3, loss: 0.5493 -------------------------
2023-03-25 20:14:53,210 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:53,613 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:53,614 : [INFO]  ------------------------- Batch 8 training: round 4 -------------------------
2023-03-25 20:14:56,092 : [INFO]  ------------------------- Batch round 4, loss: 0.5439 -------------------------
2023-03-25 20:14:56,092 : [INFO]  ------------------------- Batch 8, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:56,096 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:56,097 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 20:14:56,097 : [INFO]  ################ Batch 8: final global model evalution after 4 rounds ################
2023-03-25 20:14:57,549 : [INFO]  Batch 8: Training set : loss - 0.5423, accuracy - 0.788, recall - 0.9348, AUC - 0.8954, F1 - 0.8152, precision - 0.7227, training time - -15.0 seconds
2023-03-25 20:14:57,549 : [INFO]  Batch 8: Testing set : loss - 0.5833, accuracy - 0.6961, recall - 0.8824, AUC - 0.8594, F1 - 0.7438, precision - 0.6429
2023-03-25 20:14:57,564 : [INFO]  Batch 9 initialized 
2023-03-25 20:14:58,024 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:58,439 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 20:15:04,181 : [INFO]  ------------------------- Batch round 1, loss: 0.595 -------------------------
2023-03-25 20:15:04,182 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:04,186 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:04,189 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 20:15:06,896 : [INFO]  ------------------------- Batch round 2, loss: 0.5848 -------------------------
2023-03-25 20:15:06,896 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:07,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:07,003 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 20:15:09,778 : [INFO]  ------------------------- Batch round 3, loss: 0.5796 -------------------------
2023-03-25 20:15:09,778 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:09,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:09,783 : [INFO]  ------------------------- Batch 9 training: round 4 -------------------------
2023-03-25 20:15:12,340 : [INFO]  ------------------------- Batch round 4, loss: 0.5614 -------------------------
2023-03-25 20:15:12,340 : [INFO]  ------------------------- Batch 9, round 4: Sent local model to the server -------------------------
2023-03-25 20:15:12,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:12,345 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 20:15:12,345 : [INFO]  ################ Batch 9: final global model evalution after 4 rounds ################
2023-03-25 20:15:13,984 : [INFO]  Batch 9: Training set : loss - 0.5671, accuracy - 0.7554, recall - 0.9239, AUC - 0.8627, F1 - 0.7907, precision - 0.6911, training time - -14.0 seconds
2023-03-25 20:15:13,985 : [INFO]  Batch 9: Testing set : loss - 0.6129, accuracy - 0.6716, recall - 0.8529, AUC - 0.8057, F1 - 0.722, precision - 0.6259
2023-03-25 20:15:13,996 : [INFO]  Batch 10 initialized 
2023-03-25 20:15:14,561 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:15:14,900 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 20:15:20,928 : [INFO]  ------------------------- Batch round 1, loss: 0.5558 -------------------------
2023-03-25 20:15:20,928 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:20,931 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:20,933 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 20:15:23,544 : [INFO]  ------------------------- Batch round 2, loss: 0.5476 -------------------------
2023-03-25 20:15:23,544 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:23,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:23,551 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 20:15:25,867 : [INFO]  ------------------------- Batch round 3, loss: 0.5402 -------------------------
2023-03-25 20:15:25,867 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:25,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:25,872 : [INFO]  ------------------------- Batch 10 training: round 4 -------------------------
2023-03-25 20:15:28,194 : [INFO]  ------------------------- Batch round 4, loss: 0.5281 -------------------------
2023-03-25 20:15:28,194 : [INFO]  ------------------------- Batch 10, round 4: Sent local model to the server -------------------------
2023-03-25 20:15:28,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:28,199 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 20:15:28,199 : [INFO]  ################ Batch 10: final global model evalution after 4 rounds ################
2023-03-25 20:15:29,984 : [INFO]  Batch 10: Training set : loss - 0.5253, accuracy - 0.7935, recall - 0.913, AUC - 0.8899, F1 - 0.8155, precision - 0.7368, training time - -13.0 seconds
2023-03-25 20:15:29,984 : [INFO]  Batch 10: Testing set : loss - 0.5668, accuracy - 0.701, recall - 0.8529, AUC - 0.87, F1 - 0.7404, precision - 0.6541
2023-03-25 20:15:29,996 : [INFO]  Batch 11 initialized 
2023-03-25 20:15:30,566 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:15:30,851 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 20:15:36,272 : [INFO]  ------------------------- Batch round 1, loss: 0.5595 -------------------------
2023-03-25 20:15:36,273 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:36,282 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:36,287 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 20:15:38,909 : [INFO]  ------------------------- Batch round 2, loss: 0.5526 -------------------------
2023-03-25 20:15:38,909 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:39,111 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:39,113 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 20:15:41,679 : [INFO]  ------------------------- Batch round 3, loss: 0.5582 -------------------------
2023-03-25 20:15:41,679 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:41,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:41,693 : [INFO]  ------------------------- Batch 11 training: round 4 -------------------------
2023-03-25 20:15:44,536 : [INFO]  ------------------------- Batch round 4, loss: 0.552 -------------------------
2023-03-25 20:15:44,536 : [INFO]  ------------------------- Batch 11, round 4: Sent local model to the server -------------------------
2023-03-25 20:15:44,540 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:44,541 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 20:15:44,542 : [INFO]  ################ Batch 11: final global model evalution after 4 rounds ################
2023-03-25 20:15:46,228 : [INFO]  Batch 11: Training set : loss - 0.5502, accuracy - 0.7554, recall - 0.9022, AUC - 0.8788, F1 - 0.7867, precision - 0.6975, training time - -14.0 seconds
2023-03-25 20:15:46,229 : [INFO]  Batch 11: Testing set : loss - 0.5753, accuracy - 0.6961, recall - 0.9118, AUC - 0.8825, F1 - 0.75, precision - 0.637
2023-03-25 20:15:46,245 : [INFO]  Batch 12 initialized 
2023-03-25 20:15:46,831 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:15:47,217 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 20:15:52,544 : [INFO]  ------------------------- Batch round 1, loss: 0.5451 -------------------------
2023-03-25 20:15:52,544 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:52,666 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:52,670 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 20:15:55,246 : [INFO]  ------------------------- Batch round 2, loss: 0.5419 -------------------------
2023-03-25 20:15:55,246 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:55,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:55,405 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 20:15:57,972 : [INFO]  ------------------------- Batch round 3, loss: 0.5352 -------------------------
2023-03-25 20:15:57,972 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:58,114 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:58,116 : [INFO]  ------------------------- Batch 12 training: round 4 -------------------------
2023-03-25 20:16:00,472 : [INFO]  ------------------------- Batch round 4, loss: 0.5398 -------------------------
2023-03-25 20:16:00,472 : [INFO]  ------------------------- Batch 12, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:00,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:00,610 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 20:16:00,610 : [INFO]  ################ Batch 12: final global model evalution after 4 rounds ################
2023-03-25 20:16:02,163 : [INFO]  Batch 12: Training set : loss - 0.5279, accuracy - 0.8043, recall - 0.9022, AUC - 0.8976, F1 - 0.8218, precision - 0.7545, training time - -13.0 seconds
2023-03-25 20:16:02,163 : [INFO]  Batch 12: Testing set : loss - 0.5749, accuracy - 0.7059, recall - 0.8725, AUC - 0.8544, F1 - 0.7479, precision - 0.6544
2023-03-25 20:16:02,174 : [INFO]  Batch 13 initialized 
2023-03-25 20:16:02,691 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:03,003 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 20:16:09,193 : [INFO]  ------------------------- Batch round 1, loss: 0.5518 -------------------------
2023-03-25 20:16:09,194 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:09,199 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:09,204 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 20:16:12,013 : [INFO]  ------------------------- Batch round 2, loss: 0.5356 -------------------------
2023-03-25 20:16:12,013 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:12,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:12,023 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 20:16:15,011 : [INFO]  ------------------------- Batch round 3, loss: 0.526 -------------------------
2023-03-25 20:16:15,011 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 20:16:15,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:15,158 : [INFO]  ------------------------- Batch 13 training: round 4 -------------------------
2023-03-25 20:16:17,770 : [INFO]  ------------------------- Batch round 4, loss: 0.5294 -------------------------
2023-03-25 20:16:17,770 : [INFO]  ------------------------- Batch 13, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:17,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:17,776 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 20:16:17,776 : [INFO]  ################ Batch 13: final global model evalution after 4 rounds ################
2023-03-25 20:16:19,532 : [INFO]  Batch 13: Training set : loss - 0.5197, accuracy - 0.788, recall - 0.9565, AUC - 0.9158, F1 - 0.8186, precision - 0.7154, training time - -15.0 seconds
2023-03-25 20:16:19,532 : [INFO]  Batch 13: Testing set : loss - 0.5584, accuracy - 0.6961, recall - 0.9118, AUC - 0.8978, F1 - 0.75, precision - 0.637
2023-03-25 20:16:19,553 : [INFO]  Batch 14 initialized 
2023-03-25 20:16:20,208 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:20,535 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 20:16:25,508 : [INFO]  ------------------------- Batch round 1, loss: 0.5446 -------------------------
2023-03-25 20:16:25,508 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:25,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:25,513 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 20:16:28,038 : [INFO]  ------------------------- Batch round 2, loss: 0.532 -------------------------
2023-03-25 20:16:28,038 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:28,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:28,103 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 20:16:30,478 : [INFO]  ------------------------- Batch round 3, loss: 0.5286 -------------------------
2023-03-25 20:16:30,478 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 20:16:30,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:30,571 : [INFO]  ------------------------- Batch 14 training: round 4 -------------------------
2023-03-25 20:16:33,015 : [INFO]  ------------------------- Batch round 4, loss: 0.5229 -------------------------
2023-03-25 20:16:33,015 : [INFO]  ------------------------- Batch 14, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:33,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:33,078 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 20:16:33,078 : [INFO]  ################ Batch 14: final global model evalution after 4 rounds ################
2023-03-25 20:16:34,631 : [INFO]  Batch 14: Training set : loss - 0.5195, accuracy - 0.7935, recall - 0.9674, AUC - 0.9062, F1 - 0.8241, precision - 0.7177, training time - -13.0 seconds
2023-03-25 20:16:34,631 : [INFO]  Batch 14: Testing set : loss - 0.5621, accuracy - 0.7059, recall - 0.902, AUC - 0.8908, F1 - 0.7541, precision - 0.6479
2023-03-25 20:16:34,647 : [INFO]  Batch 15 initialized 
2023-03-25 20:16:35,271 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:35,673 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 20:16:40,380 : [INFO]  ------------------------- Batch round 1, loss: 0.5952 -------------------------
2023-03-25 20:16:40,380 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:40,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:40,869 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 20:16:43,445 : [INFO]  ------------------------- Batch round 2, loss: 0.5783 -------------------------
2023-03-25 20:16:43,446 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:43,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:43,624 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 20:16:45,954 : [INFO]  ------------------------- Batch round 3, loss: 0.5802 -------------------------
2023-03-25 20:16:45,954 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 20:16:46,301 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:46,303 : [INFO]  ------------------------- Batch 15 training: round 4 -------------------------
2023-03-25 20:16:48,802 : [INFO]  ------------------------- Batch round 4, loss: 0.5677 -------------------------
2023-03-25 20:16:48,802 : [INFO]  ------------------------- Batch 15, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:48,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:48,894 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 20:16:48,894 : [INFO]  ################ Batch 15: final global model evalution after 4 rounds ################
2023-03-25 20:16:50,531 : [INFO]  Batch 15: Training set : loss - 0.5653, accuracy - 0.7391, recall - 0.9457, AUC - 0.8728, F1 - 0.7838, precision - 0.6692, training time - -13.0 seconds
2023-03-25 20:16:50,531 : [INFO]  Batch 15: Testing set : loss - 0.5613, accuracy - 0.701, recall - 0.9216, AUC - 0.8959, F1 - 0.755, precision - 0.6395
2023-03-25 20:16:50,541 : [INFO]  Batch 16 initialized 
2023-03-25 20:16:51,084 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:51,414 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 20:16:56,301 : [INFO]  ------------------------- Batch round 1, loss: 0.5845 -------------------------
2023-03-25 20:16:56,301 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:56,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:56,414 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 20:16:58,961 : [INFO]  ------------------------- Batch round 2, loss: 0.5703 -------------------------
2023-03-25 20:16:58,961 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:58,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:58,969 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 20:17:01,718 : [INFO]  ------------------------- Batch round 3, loss: 0.5621 -------------------------
2023-03-25 20:17:01,718 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:01,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:01,724 : [INFO]  ------------------------- Batch 16 training: round 4 -------------------------
2023-03-25 20:17:04,576 : [INFO]  ------------------------- Batch round 4, loss: 0.5624 -------------------------
2023-03-25 20:17:04,576 : [INFO]  ------------------------- Batch 16, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:04,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:04,582 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 20:17:04,582 : [INFO]  ################ Batch 16: final global model evalution after 4 rounds ################
2023-03-25 20:17:06,559 : [INFO]  Batch 16: Training set : loss - 0.5588, accuracy - 0.7663, recall - 0.8913, AUC - 0.8442, F1 - 0.7923, precision - 0.713, training time - -13.0 seconds
2023-03-25 20:17:06,559 : [INFO]  Batch 16: Testing set : loss - 0.5752, accuracy - 0.6765, recall - 0.8627, AUC - 0.8614, F1 - 0.7273, precision - 0.6286
2023-03-25 20:17:06,568 : [INFO]  Batch 17 initialized 
2023-03-25 20:17:07,230 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:07,521 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 20:17:11,771 : [INFO]  ------------------------- Batch round 1, loss: 0.5315 -------------------------
2023-03-25 20:17:11,771 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:11,775 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:11,777 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 20:17:14,200 : [INFO]  ------------------------- Batch round 2, loss: 0.5181 -------------------------
2023-03-25 20:17:14,200 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:14,203 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:14,205 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 20:17:16,368 : [INFO]  ------------------------- Batch round 3, loss: 0.5148 -------------------------
2023-03-25 20:17:16,369 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:16,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:16,373 : [INFO]  ------------------------- Batch 17 training: round 4 -------------------------
2023-03-25 20:17:18,669 : [INFO]  ------------------------- Batch round 4, loss: 0.5045 -------------------------
2023-03-25 20:17:18,669 : [INFO]  ------------------------- Batch 17, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:18,672 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:18,674 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 20:17:18,674 : [INFO]  ################ Batch 17: final global model evalution after 4 rounds ################
2023-03-25 20:17:20,231 : [INFO]  Batch 17: Training set : loss - 0.4996, accuracy - 0.8424, recall - 0.9565, AUC - 0.9206, F1 - 0.8585, precision - 0.7788, training time - -11.0 seconds
2023-03-25 20:17:20,231 : [INFO]  Batch 17: Testing set : loss - 0.5538, accuracy - 0.7402, recall - 0.9902, AUC - 0.9274, F1 - 0.7922, precision - 0.6601
2023-03-25 20:17:20,237 : [INFO]  Batch 18 initialized 
2023-03-25 20:17:20,808 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:21,088 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 20:17:25,281 : [INFO]  ------------------------- Batch round 1, loss: 0.5939 -------------------------
2023-03-25 20:17:25,281 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:25,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:25,286 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 20:17:27,549 : [INFO]  ------------------------- Batch round 2, loss: 0.5897 -------------------------
2023-03-25 20:17:27,549 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:27,678 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:27,681 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 20:17:29,919 : [INFO]  ------------------------- Batch round 3, loss: 0.5765 -------------------------
2023-03-25 20:17:29,920 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:29,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:29,924 : [INFO]  ------------------------- Batch 18 training: round 4 -------------------------
2023-03-25 20:17:32,144 : [INFO]  ------------------------- Batch round 4, loss: 0.5676 -------------------------
2023-03-25 20:17:32,144 : [INFO]  ------------------------- Batch 18, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:32,147 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:32,149 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 20:17:32,149 : [INFO]  ################ Batch 18: final global model evalution after 4 rounds ################
2023-03-25 20:17:33,723 : [INFO]  Batch 18: Training set : loss - 0.5808, accuracy - 0.6793, recall - 0.8696, AUC - 0.8329, F1 - 0.7306, precision - 0.6299, training time - -11.0 seconds
2023-03-25 20:17:33,723 : [INFO]  Batch 18: Testing set : loss - 0.5935, accuracy - 0.6912, recall - 0.8431, AUC - 0.8095, F1 - 0.7319, precision - 0.6466
2023-03-25 20:17:33,756 : [INFO]  Batch 19 initialized 
2023-03-25 20:17:34,418 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:34,679 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 20:17:39,153 : [INFO]  ------------------------- Batch round 1, loss: 0.5696 -------------------------
2023-03-25 20:17:39,153 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:39,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:39,167 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 20:17:41,289 : [INFO]  ------------------------- Batch round 2, loss: 0.5553 -------------------------
2023-03-25 20:17:41,289 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:41,292 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:41,294 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 20:17:43,561 : [INFO]  ------------------------- Batch round 3, loss: 0.5491 -------------------------
2023-03-25 20:17:43,561 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:43,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:43,566 : [INFO]  ------------------------- Batch 19 training: round 4 -------------------------
2023-03-25 20:17:45,791 : [INFO]  ------------------------- Batch round 4, loss: 0.5344 -------------------------
2023-03-25 20:17:45,792 : [INFO]  ------------------------- Batch 19, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:45,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:45,797 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 20:17:45,797 : [INFO]  ################ Batch 19: final global model evalution after 4 rounds ################
2023-03-25 20:17:47,211 : [INFO]  Batch 19: Training set : loss - 0.5346, accuracy - 0.8152, recall - 0.9565, AUC - 0.872, F1 - 0.8381, precision - 0.7458, training time - -11.0 seconds
2023-03-25 20:17:47,211 : [INFO]  Batch 19: Testing set : loss - 0.5987, accuracy - 0.6765, recall - 0.8725, AUC - 0.8237, F1 - 0.7295, precision - 0.6268
2023-03-25 20:17:47,217 : [INFO]  Batch 20 initialized 
2023-03-25 20:17:47,784 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:48,146 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 20:17:52,933 : [INFO]  ------------------------- Batch round 1, loss: 0.5664 -------------------------
2023-03-25 20:17:52,933 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:52,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:52,937 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 20:17:55,334 : [INFO]  ------------------------- Batch round 2, loss: 0.5578 -------------------------
2023-03-25 20:17:55,334 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:55,337 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:55,340 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 20:17:57,729 : [INFO]  ------------------------- Batch round 3, loss: 0.5486 -------------------------
2023-03-25 20:17:57,729 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:57,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:57,734 : [INFO]  ------------------------- Batch 20 training: round 4 -------------------------
2023-03-25 20:18:00,118 : [INFO]  ------------------------- Batch round 4, loss: 0.5447 -------------------------
2023-03-25 20:18:00,119 : [INFO]  ------------------------- Batch 20, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:00,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:00,124 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 20:18:00,124 : [INFO]  ################ Batch 20: final global model evalution after 4 rounds ################
2023-03-25 20:18:01,460 : [INFO]  Batch 20: Training set : loss - 0.5393, accuracy - 0.7663, recall - 0.913, AUC - 0.8886, F1 - 0.7962, precision - 0.7059, training time - -12.0 seconds
2023-03-25 20:18:01,460 : [INFO]  Batch 20: Testing set : loss - 0.5733, accuracy - 0.7402, recall - 0.9314, AUC - 0.856, F1 - 0.7819, precision - 0.6738
2023-03-25 20:18:01,469 : [INFO]  Batch 21 initialized 
2023-03-25 20:18:01,911 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:02,189 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 20:18:06,502 : [INFO]  ------------------------- Batch round 1, loss: 0.5945 -------------------------
2023-03-25 20:18:06,502 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:06,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:06,511 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 20:18:08,927 : [INFO]  ------------------------- Batch round 2, loss: 0.5908 -------------------------
2023-03-25 20:18:08,927 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:08,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:08,931 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 20:18:11,234 : [INFO]  ------------------------- Batch round 3, loss: 0.5907 -------------------------
2023-03-25 20:18:11,234 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:11,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:11,240 : [INFO]  ------------------------- Batch 21 training: round 4 -------------------------
2023-03-25 20:18:13,479 : [INFO]  ------------------------- Batch round 4, loss: 0.5819 -------------------------
2023-03-25 20:18:13,479 : [INFO]  ------------------------- Batch 21, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:13,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:13,484 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 20:18:13,484 : [INFO]  ################ Batch 21: final global model evalution after 4 rounds ################
2023-03-25 20:18:14,810 : [INFO]  Batch 21: Training set : loss - 0.5819, accuracy - 0.7228, recall - 0.9348, AUC - 0.8591, F1 - 0.7713, precision - 0.6565, training time - -11.0 seconds
2023-03-25 20:18:14,810 : [INFO]  Batch 21: Testing set : loss - 0.5465, accuracy - 0.75, recall - 0.9706, AUC - 0.9479, F1 - 0.7952, precision - 0.6735
2023-03-25 20:18:14,816 : [INFO]  Batch 22 initialized 
2023-03-25 20:18:15,245 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:15,524 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 20:18:19,739 : [INFO]  ------------------------- Batch round 1, loss: 0.5941 -------------------------
2023-03-25 20:18:19,739 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:19,742 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:19,744 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 20:18:22,215 : [INFO]  ------------------------- Batch round 2, loss: 0.5851 -------------------------
2023-03-25 20:18:22,215 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:22,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:22,299 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 20:18:25,337 : [INFO]  ------------------------- Batch round 3, loss: 0.5683 -------------------------
2023-03-25 20:18:25,337 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:25,532 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:25,534 : [INFO]  ------------------------- Batch 22 training: round 4 -------------------------
2023-03-25 20:18:28,200 : [INFO]  ------------------------- Batch round 4, loss: 0.5617 -------------------------
2023-03-25 20:18:28,200 : [INFO]  ------------------------- Batch 22, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:28,206 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:28,208 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 20:18:28,208 : [INFO]  ################ Batch 22: final global model evalution after 4 rounds ################
2023-03-25 20:18:29,664 : [INFO]  Batch 22: Training set : loss - 0.5667, accuracy - 0.7283, recall - 0.913, AUC - 0.8532, F1 - 0.7706, precision - 0.6667, training time - -13.0 seconds
2023-03-25 20:18:29,664 : [INFO]  Batch 22: Testing set : loss - 0.5943, accuracy - 0.6863, recall - 0.8235, AUC - 0.8245, F1 - 0.7241, precision - 0.6462
2023-03-25 20:18:29,676 : [INFO]  Batch 23 initialized 
2023-03-25 20:18:30,144 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:30,434 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 20:18:35,469 : [INFO]  ------------------------- Batch round 1, loss: 0.5821 -------------------------
2023-03-25 20:18:35,470 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:35,472 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:35,474 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 20:18:37,866 : [INFO]  ------------------------- Batch round 2, loss: 0.582 -------------------------
2023-03-25 20:18:37,866 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:37,934 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:37,936 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 20:18:40,273 : [INFO]  ------------------------- Batch round 3, loss: 0.5701 -------------------------
2023-03-25 20:18:40,273 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:40,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:40,407 : [INFO]  ------------------------- Batch 23 training: round 4 -------------------------
2023-03-25 20:18:42,671 : [INFO]  ------------------------- Batch round 4, loss: 0.567 -------------------------
2023-03-25 20:18:42,672 : [INFO]  ------------------------- Batch 23, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:42,791 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:42,793 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 20:18:42,793 : [INFO]  ################ Batch 23: final global model evalution after 4 rounds ################
2023-03-25 20:18:44,192 : [INFO]  Batch 23: Training set : loss - 0.5587, accuracy - 0.7337, recall - 0.8913, AUC - 0.8505, F1 - 0.77, precision - 0.6777, training time - -12.0 seconds
2023-03-25 20:18:44,192 : [INFO]  Batch 23: Testing set : loss - 0.6074, accuracy - 0.6324, recall - 0.7941, AUC - 0.7799, F1 - 0.6835, precision - 0.6
2023-03-25 20:18:44,198 : [INFO]  Batch 24 initialized 
2023-03-25 20:18:44,640 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:44,918 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 20:18:49,118 : [INFO]  ------------------------- Batch round 1, loss: 0.587 -------------------------
2023-03-25 20:18:49,119 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:49,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:49,236 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 20:18:51,558 : [INFO]  ------------------------- Batch round 2, loss: 0.5745 -------------------------
2023-03-25 20:18:51,558 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:51,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:51,645 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 20:18:54,005 : [INFO]  ------------------------- Batch round 3, loss: 0.5805 -------------------------
2023-03-25 20:18:54,005 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:54,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:54,155 : [INFO]  ------------------------- Batch 24 training: round 4 -------------------------
2023-03-25 20:18:56,475 : [INFO]  ------------------------- Batch round 4, loss: 0.5755 -------------------------
2023-03-25 20:18:56,475 : [INFO]  ------------------------- Batch 24, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:56,509 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:56,511 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 20:18:56,511 : [INFO]  ################ Batch 24: final global model evalution after 4 rounds ################
2023-03-25 20:18:57,852 : [INFO]  Batch 24: Training set : loss - 0.5715, accuracy - 0.712, recall - 0.8587, AUC - 0.8076, F1 - 0.7488, precision - 0.6639, training time - -12.0 seconds
2023-03-25 20:18:57,852 : [INFO]  Batch 24: Testing set : loss - 0.5916, accuracy - 0.6618, recall - 0.8333, AUC - 0.8131, F1 - 0.7113, precision - 0.6204
2023-03-25 20:18:57,865 : [INFO]  Batch 25 initialized 
2023-03-25 20:18:58,327 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:58,631 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 20:19:03,488 : [INFO]  ------------------------- Batch round 1, loss: 0.6455 -------------------------
2023-03-25 20:19:03,488 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:03,620 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:03,622 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 20:19:06,321 : [INFO]  ------------------------- Batch round 2, loss: 0.606 -------------------------
2023-03-25 20:19:06,321 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:06,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:06,506 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 20:19:08,667 : [INFO]  ------------------------- Batch round 3, loss: 0.596 -------------------------
2023-03-25 20:19:08,667 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:08,852 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:08,854 : [INFO]  ------------------------- Batch 25 training: round 4 -------------------------
2023-03-25 20:19:10,994 : [INFO]  ------------------------- Batch round 4, loss: 0.587 -------------------------
2023-03-25 20:19:10,994 : [INFO]  ------------------------- Batch 25, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:11,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:11,099 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 20:19:11,099 : [INFO]  ################ Batch 25: final global model evalution after 4 rounds ################
2023-03-25 20:19:12,454 : [INFO]  Batch 25: Training set : loss - 0.5861, accuracy - 0.6848, recall - 0.8696, AUC - 0.8233, F1 - 0.7339, precision - 0.6349, training time - -12.0 seconds
2023-03-25 20:19:12,455 : [INFO]  Batch 25: Testing set : loss - 0.6023, accuracy - 0.6765, recall - 0.8627, AUC - 0.8093, F1 - 0.7273, precision - 0.6286
2023-03-25 20:19:12,463 : [INFO]  Batch 26 initialized 
2023-03-25 20:19:12,907 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:13,208 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 20:19:17,533 : [INFO]  ------------------------- Batch round 1, loss: 0.5818 -------------------------
2023-03-25 20:19:17,533 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:17,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:17,586 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 20:19:19,670 : [INFO]  ------------------------- Batch round 2, loss: 0.5693 -------------------------
2023-03-25 20:19:19,670 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:19,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:19,773 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 20:19:21,900 : [INFO]  ------------------------- Batch round 3, loss: 0.5602 -------------------------
2023-03-25 20:19:21,900 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:21,983 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:21,985 : [INFO]  ------------------------- Batch 26 training: round 4 -------------------------
2023-03-25 20:19:24,130 : [INFO]  ------------------------- Batch round 4, loss: 0.562 -------------------------
2023-03-25 20:19:24,130 : [INFO]  ------------------------- Batch 26, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:24,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:24,469 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 20:19:24,469 : [INFO]  ################ Batch 26: final global model evalution after 4 rounds ################
2023-03-25 20:19:25,799 : [INFO]  Batch 26: Training set : loss - 0.5504, accuracy - 0.7554, recall - 0.8696, AUC - 0.8658, F1 - 0.7805, precision - 0.708, training time - -11.0 seconds
2023-03-25 20:19:25,799 : [INFO]  Batch 26: Testing set : loss - 0.545, accuracy - 0.7745, recall - 0.9412, AUC - 0.9262, F1 - 0.8067, precision - 0.7059
2023-03-25 20:19:25,811 : [INFO]  Batch 27 initialized 
2023-03-25 20:19:26,260 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:26,554 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 20:19:30,812 : [INFO]  ------------------------- Batch round 1, loss: 0.5887 -------------------------
2023-03-25 20:19:30,812 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:30,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:30,818 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 20:19:33,136 : [INFO]  ------------------------- Batch round 2, loss: 0.5785 -------------------------
2023-03-25 20:19:33,136 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:33,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:33,156 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 20:19:36,517 : [INFO]  ------------------------- Batch round 3, loss: 0.5669 -------------------------
2023-03-25 20:19:36,518 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:36,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:36,522 : [INFO]  ------------------------- Batch 27 training: round 4 -------------------------
2023-03-25 20:19:38,798 : [INFO]  ------------------------- Batch round 4, loss: 0.5562 -------------------------
2023-03-25 20:19:38,798 : [INFO]  ------------------------- Batch 27, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:38,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:38,803 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 20:19:38,803 : [INFO]  ################ Batch 27: final global model evalution after 4 rounds ################
2023-03-25 20:19:40,301 : [INFO]  Batch 27: Training set : loss - 0.5577, accuracy - 0.7391, recall - 0.9565, AUC - 0.8908, F1 - 0.7857, precision - 0.6667, training time - -12.0 seconds
2023-03-25 20:19:40,301 : [INFO]  Batch 27: Testing set : loss - 0.6095, accuracy - 0.6814, recall - 0.8039, AUC - 0.785, F1 - 0.7162, precision - 0.6457
2023-03-25 20:19:40,307 : [INFO]  Batch 28 initialized 
2023-03-25 20:19:40,778 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:41,107 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 20:19:46,220 : [INFO]  ------------------------- Batch round 1, loss: 0.589 -------------------------
2023-03-25 20:19:46,220 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:46,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:46,227 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 20:19:48,524 : [INFO]  ------------------------- Batch round 2, loss: 0.577 -------------------------
2023-03-25 20:19:48,524 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:48,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:48,530 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 20:19:50,888 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-25 20:19:50,888 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:50,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:50,893 : [INFO]  ------------------------- Batch 28 training: round 4 -------------------------
2023-03-25 20:19:53,148 : [INFO]  ------------------------- Batch round 4, loss: 0.5587 -------------------------
2023-03-25 20:19:53,148 : [INFO]  ------------------------- Batch 28, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:53,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:53,161 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 20:19:53,161 : [INFO]  ################ Batch 28: final global model evalution after 4 rounds ################
2023-03-25 20:19:54,596 : [INFO]  Batch 28: Training set : loss - 0.5518, accuracy - 0.75, recall - 0.8804, AUC - 0.866, F1 - 0.7788, precision - 0.6983, training time - -12.0 seconds
2023-03-25 20:19:54,596 : [INFO]  Batch 28: Testing set : loss - 0.6079, accuracy - 0.6176, recall - 0.8627, AUC - 0.8282, F1 - 0.6929, precision - 0.5789
2023-03-25 20:19:54,602 : [INFO]  Batch 29 initialized 
2023-03-25 20:19:55,125 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:55,454 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 20:20:00,119 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 20:20:00,119 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:00,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:00,125 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 20:20:02,428 : [INFO]  ------------------------- Batch round 2, loss: 0.5598 -------------------------
2023-03-25 20:20:02,428 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:02,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:02,433 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 20:20:04,876 : [INFO]  ------------------------- Batch round 3, loss: 0.5596 -------------------------
2023-03-25 20:20:04,876 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:04,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:04,881 : [INFO]  ------------------------- Batch 29 training: round 4 -------------------------
2023-03-25 20:20:07,518 : [INFO]  ------------------------- Batch round 4, loss: 0.5527 -------------------------
2023-03-25 20:20:07,518 : [INFO]  ------------------------- Batch 29, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:07,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:07,524 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 20:20:07,524 : [INFO]  ################ Batch 29: final global model evalution after 4 rounds ################
2023-03-25 20:20:09,216 : [INFO]  Batch 29: Training set : loss - 0.5483, accuracy - 0.7663, recall - 0.9022, AUC - 0.8915, F1 - 0.7943, precision - 0.7094, training time - -12.0 seconds
2023-03-25 20:20:09,216 : [INFO]  Batch 29: Testing set : loss - 0.5776, accuracy - 0.6863, recall - 0.8824, AUC - 0.8568, F1 - 0.7377, precision - 0.6338
2023-03-25 20:20:09,231 : [INFO]  Batch 30 initialized 
2023-03-25 20:20:10,002 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:10,313 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 20:20:14,822 : [INFO]  ------------------------- Batch round 1, loss: 0.6061 -------------------------
2023-03-25 20:20:14,822 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:14,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:14,827 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 20:20:17,083 : [INFO]  ------------------------- Batch round 2, loss: 0.591 -------------------------
2023-03-25 20:20:17,083 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:17,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:17,089 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 20:20:19,535 : [INFO]  ------------------------- Batch round 3, loss: 0.5796 -------------------------
2023-03-25 20:20:19,535 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:19,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:19,542 : [INFO]  ------------------------- Batch 30 training: round 4 -------------------------
2023-03-25 20:20:22,134 : [INFO]  ------------------------- Batch round 4, loss: 0.5759 -------------------------
2023-03-25 20:20:22,134 : [INFO]  ------------------------- Batch 30, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:22,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:22,140 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 20:20:22,140 : [INFO]  ################ Batch 30: final global model evalution after 4 rounds ################
2023-03-25 20:20:23,563 : [INFO]  Batch 30: Training set : loss - 0.5766, accuracy - 0.7228, recall - 0.8804, AUC - 0.802, F1 - 0.7606, precision - 0.6694, training time - -12.0 seconds
2023-03-25 20:20:23,563 : [INFO]  Batch 30: Testing set : loss - 0.5776, accuracy - 0.6863, recall - 0.8824, AUC - 0.8478, F1 - 0.7377, precision - 0.6338
2023-03-25 20:20:23,574 : [INFO]  Batch 31 initialized 
2023-03-25 20:20:24,083 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:24,395 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 20:20:28,729 : [INFO]  ------------------------- Batch round 1, loss: 0.5676 -------------------------
2023-03-25 20:20:28,730 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:28,748 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:28,751 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 20:20:31,508 : [INFO]  ------------------------- Batch round 2, loss: 0.5558 -------------------------
2023-03-25 20:20:31,508 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:31,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:31,734 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 20:20:34,173 : [INFO]  ------------------------- Batch round 3, loss: 0.5426 -------------------------
2023-03-25 20:20:34,173 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:34,235 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:34,237 : [INFO]  ------------------------- Batch 31 training: round 4 -------------------------
2023-03-25 20:20:36,396 : [INFO]  ------------------------- Batch round 4, loss: 0.5327 -------------------------
2023-03-25 20:20:36,397 : [INFO]  ------------------------- Batch 31, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:36,505 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:36,507 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 20:20:36,507 : [INFO]  ################ Batch 31: final global model evalution after 4 rounds ################
2023-03-25 20:20:37,903 : [INFO]  Batch 31: Training set : loss - 0.5268, accuracy - 0.7989, recall - 0.9239, AUC - 0.9135, F1 - 0.8213, precision - 0.7391, training time - -12.0 seconds
2023-03-25 20:20:37,903 : [INFO]  Batch 31: Testing set : loss - 0.568, accuracy - 0.7304, recall - 0.8725, AUC - 0.8579, F1 - 0.7639, precision - 0.6794
2023-03-25 20:20:37,915 : [INFO]  Batch 32 initialized 
2023-03-25 20:20:38,374 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:38,690 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 20:20:42,903 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 20:20:42,904 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:43,035 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:43,039 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 20:20:45,303 : [INFO]  ------------------------- Batch round 2, loss: 0.5624 -------------------------
2023-03-25 20:20:45,303 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:45,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:45,533 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 20:20:47,628 : [INFO]  ------------------------- Batch round 3, loss: 0.5559 -------------------------
2023-03-25 20:20:47,628 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:47,838 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:47,840 : [INFO]  ------------------------- Batch 32 training: round 4 -------------------------
2023-03-25 20:20:49,938 : [INFO]  ------------------------- Batch round 4, loss: 0.5531 -------------------------
2023-03-25 20:20:49,938 : [INFO]  ------------------------- Batch 32, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:50,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:50,121 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 20:20:50,121 : [INFO]  ################ Batch 32: final global model evalution after 4 rounds ################
2023-03-25 20:20:51,475 : [INFO]  Batch 32: Training set : loss - 0.5419, accuracy - 0.7717, recall - 0.9457, AUC - 0.8637, F1 - 0.8056, precision - 0.7016, training time - -11.0 seconds
2023-03-25 20:20:51,476 : [INFO]  Batch 32: Testing set : loss - 0.5686, accuracy - 0.7059, recall - 0.9412, AUC - 0.8931, F1 - 0.7619, precision - 0.64
2023-03-25 20:20:51,487 : [INFO]  Batch 33 initialized 
2023-03-25 20:20:51,943 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:52,255 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 20:20:56,414 : [INFO]  ------------------------- Batch round 1, loss: 0.5664 -------------------------
2023-03-25 20:20:56,414 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:56,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:56,521 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 20:20:58,489 : [INFO]  ------------------------- Batch round 2, loss: 0.5645 -------------------------
2023-03-25 20:20:58,489 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:58,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:58,626 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 20:21:00,593 : [INFO]  ------------------------- Batch round 3, loss: 0.5658 -------------------------
2023-03-25 20:21:00,594 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:00,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:00,717 : [INFO]  ------------------------- Batch 33 training: round 4 -------------------------
2023-03-25 20:21:02,719 : [INFO]  ------------------------- Batch round 4, loss: 0.5607 -------------------------
2023-03-25 20:21:02,719 : [INFO]  ------------------------- Batch 33, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:02,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:02,827 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 20:21:02,827 : [INFO]  ################ Batch 33: final global model evalution after 4 rounds ################
2023-03-25 20:21:04,192 : [INFO]  Batch 33: Training set : loss - 0.5795, accuracy - 0.712, recall - 0.9783, AUC - 0.8723, F1 - 0.7725, precision - 0.6383, training time - -11.0 seconds
2023-03-25 20:21:04,192 : [INFO]  Batch 33: Testing set : loss - 0.5813, accuracy - 0.6765, recall - 0.9706, AUC - 0.8901, F1 - 0.75, precision - 0.6111
2023-03-25 20:21:04,203 : [INFO]  Batch 34 initialized 
2023-03-25 20:21:04,694 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:05,010 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 20:21:08,955 : [INFO]  ------------------------- Batch round 1, loss: 0.5796 -------------------------
2023-03-25 20:21:08,955 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:08,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:08,959 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 20:21:11,069 : [INFO]  ------------------------- Batch round 2, loss: 0.5599 -------------------------
2023-03-25 20:21:11,069 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:11,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:11,074 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 20:21:13,319 : [INFO]  ------------------------- Batch round 3, loss: 0.5515 -------------------------
2023-03-25 20:21:13,319 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:13,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:13,326 : [INFO]  ------------------------- Batch 34 training: round 4 -------------------------
2023-03-25 20:21:15,811 : [INFO]  ------------------------- Batch round 4, loss: 0.5453 -------------------------
2023-03-25 20:21:15,811 : [INFO]  ------------------------- Batch 34, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:15,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:15,816 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 20:21:15,816 : [INFO]  ################ Batch 34: final global model evalution after 4 rounds ################
2023-03-25 20:21:17,301 : [INFO]  Batch 34: Training set : loss - 0.5415, accuracy - 0.7989, recall - 0.9674, AUC - 0.9108, F1 - 0.8279, precision - 0.7236, training time - -11.0 seconds
2023-03-25 20:21:17,302 : [INFO]  Batch 34: Testing set : loss - 0.5502, accuracy - 0.75, recall - 0.951, AUC - 0.9217, F1 - 0.7918, precision - 0.6783
2023-03-25 20:21:17,314 : [INFO]  Batch 35 initialized 
2023-03-25 20:21:17,756 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:18,086 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 20:21:22,077 : [INFO]  ------------------------- Batch round 1, loss: 0.5684 -------------------------
2023-03-25 20:21:22,077 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:22,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:22,083 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 20:21:24,198 : [INFO]  ------------------------- Batch round 2, loss: 0.559 -------------------------
2023-03-25 20:21:24,198 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:24,225 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:24,228 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 20:21:26,320 : [INFO]  ------------------------- Batch round 3, loss: 0.5513 -------------------------
2023-03-25 20:21:26,320 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:26,340 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:26,343 : [INFO]  ------------------------- Batch 35 training: round 4 -------------------------
2023-03-25 20:21:28,502 : [INFO]  ------------------------- Batch round 4, loss: 0.5436 -------------------------
2023-03-25 20:21:28,502 : [INFO]  ------------------------- Batch 35, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:28,510 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:28,512 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 20:21:28,512 : [INFO]  ################ Batch 35: final global model evalution after 4 rounds ################
2023-03-25 20:21:29,825 : [INFO]  Batch 35: Training set : loss - 0.5402, accuracy - 0.7717, recall - 0.913, AUC - 0.898, F1 - 0.8, precision - 0.7119, training time - -10.0 seconds
2023-03-25 20:21:29,825 : [INFO]  Batch 35: Testing set : loss - 0.5731, accuracy - 0.7206, recall - 0.9412, AUC - 0.894, F1 - 0.7711, precision - 0.6531
2023-03-25 20:21:29,831 : [INFO]  Batch 36 initialized 
2023-03-25 20:21:30,294 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:30,627 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 20:21:34,941 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-25 20:21:34,941 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:34,944 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:34,946 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 20:21:37,162 : [INFO]  ------------------------- Batch round 2, loss: 0.5576 -------------------------
2023-03-25 20:21:37,162 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:37,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:37,417 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 20:21:39,658 : [INFO]  ------------------------- Batch round 3, loss: 0.5433 -------------------------
2023-03-25 20:21:39,658 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:39,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:39,689 : [INFO]  ------------------------- Batch 36 training: round 4 -------------------------
2023-03-25 20:21:41,942 : [INFO]  ------------------------- Batch round 4, loss: 0.5414 -------------------------
2023-03-25 20:21:41,943 : [INFO]  ------------------------- Batch 36, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:41,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:41,948 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 20:21:41,948 : [INFO]  ################ Batch 36: final global model evalution after 4 rounds ################
2023-03-25 20:21:43,355 : [INFO]  Batch 36: Training set : loss - 0.5333, accuracy - 0.7609, recall - 0.9565, AUC - 0.917, F1 - 0.8, precision - 0.6875, training time - -11.0 seconds
2023-03-25 20:21:43,356 : [INFO]  Batch 36: Testing set : loss - 0.5407, accuracy - 0.7304, recall - 0.9608, AUC - 0.9492, F1 - 0.7809, precision - 0.6577
2023-03-25 20:21:43,365 : [INFO]  Batch 37 initialized 
2023-03-25 20:21:43,818 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:44,137 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 20:21:48,066 : [INFO]  ------------------------- Batch round 1, loss: 0.5964 -------------------------
2023-03-25 20:21:48,066 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:48,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:48,071 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 20:21:50,278 : [INFO]  ------------------------- Batch round 2, loss: 0.5896 -------------------------
2023-03-25 20:21:50,278 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:50,281 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:50,283 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 20:21:52,427 : [INFO]  ------------------------- Batch round 3, loss: 0.5732 -------------------------
2023-03-25 20:21:52,427 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:52,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:52,487 : [INFO]  ------------------------- Batch 37 training: round 4 -------------------------
2023-03-25 20:21:54,665 : [INFO]  ------------------------- Batch round 4, loss: 0.5736 -------------------------
2023-03-25 20:21:54,666 : [INFO]  ------------------------- Batch 37, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:54,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:54,670 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 20:21:54,670 : [INFO]  ################ Batch 37: final global model evalution after 4 rounds ################
2023-03-25 20:21:55,989 : [INFO]  Batch 37: Training set : loss - 0.5725, accuracy - 0.7337, recall - 0.8913, AUC - 0.8569, F1 - 0.77, precision - 0.6777, training time - -11.0 seconds
2023-03-25 20:21:55,990 : [INFO]  Batch 37: Testing set : loss - 0.5526, accuracy - 0.7647, recall - 0.8431, AUC - 0.871, F1 - 0.7818, precision - 0.7288
2023-03-25 20:21:55,999 : [INFO]  Batch 38 initialized 
2023-03-25 20:21:56,433 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:56,760 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 20:22:00,693 : [INFO]  ------------------------- Batch round 1, loss: 0.5753 -------------------------
2023-03-25 20:22:00,693 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 20:22:00,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:00,698 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 20:22:02,866 : [INFO]  ------------------------- Batch round 2, loss: 0.5683 -------------------------
2023-03-25 20:22:02,866 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 20:22:02,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:02,966 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 20:22:05,237 : [INFO]  ------------------------- Batch round 3, loss: 0.5626 -------------------------
2023-03-25 20:22:05,237 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 20:22:05,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:05,371 : [INFO]  ------------------------- Batch 38 training: round 4 -------------------------
2023-03-25 20:22:07,781 : [INFO]  ------------------------- Batch round 4, loss: 0.5539 -------------------------
2023-03-25 20:22:07,781 : [INFO]  ------------------------- Batch 38, round 4: Sent local model to the server -------------------------
2023-03-25 20:22:07,784 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:07,786 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 20:22:07,786 : [INFO]  ################ Batch 38: final global model evalution after 4 rounds ################
2023-03-25 20:22:09,097 : [INFO]  Batch 38: Training set : loss - 0.5485, accuracy - 0.7609, recall - 0.9457, AUC - 0.9083, F1 - 0.7982, precision - 0.6905, training time - -11.0 seconds
2023-03-25 20:22:09,097 : [INFO]  Batch 38: Testing set : loss - 0.5657, accuracy - 0.7059, recall - 0.902, AUC - 0.8881, F1 - 0.7541, precision - 0.6479
2023-03-25 20:22:09,112 : [INFO]  Batch 39 initialized 
2023-03-25 20:22:09,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:22:09,894 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 20:22:13,795 : [INFO]  ------------------------- Batch round 1, loss: 0.5555 -------------------------
2023-03-25 20:22:13,795 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 20:22:13,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:13,800 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 20:22:15,873 : [INFO]  ------------------------- Batch round 2, loss: 0.5514 -------------------------
2023-03-25 20:22:15,873 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 20:22:15,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:15,917 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 20:22:17,943 : [INFO]  ------------------------- Batch round 3, loss: 0.5502 -------------------------
2023-03-25 20:22:17,943 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 20:22:17,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:17,965 : [INFO]  ------------------------- Batch 39 training: round 4 -------------------------
2023-03-25 20:22:20,001 : [INFO]  ------------------------- Batch round 4, loss: 0.5447 -------------------------
2023-03-25 20:22:20,001 : [INFO]  ------------------------- Batch 39, round 4: Sent local model to the server -------------------------
2023-03-25 20:22:20,028 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:20,030 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 20:22:20,031 : [INFO]  ################ Batch 39: final global model evalution after 4 rounds ################
2023-03-25 20:22:21,340 : [INFO]  Batch 39: Training set : loss - 0.5509, accuracy - 0.7391, recall - 0.9783, AUC - 0.915, F1 - 0.7895, precision - 0.6618, training time - -10.0 seconds
2023-03-25 20:22:21,341 : [INFO]  Batch 39: Testing set : loss - 0.5281, accuracy - 0.7647, recall - 0.9902, AUC - 0.9444, F1 - 0.808, precision - 0.6824
2023-03-25 20:22:21,355 : [INFO]  Batch 40 initialized 
2023-03-25 20:22:21,792 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:22:22,125 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 20:22:26,073 : [INFO]  ------------------------- Batch round 1, loss: 0.5659 -------------------------
2023-03-25 20:22:26,073 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 20:22:26,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:26,335 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 20:22:28,435 : [INFO]  ------------------------- Batch round 2, loss: 0.5504 -------------------------
2023-03-25 20:22:28,436 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 20:22:28,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:28,485 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
