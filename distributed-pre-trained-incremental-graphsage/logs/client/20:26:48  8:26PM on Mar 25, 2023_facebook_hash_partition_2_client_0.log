2023-03-25 20:26:48,144 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 20:26:48,144 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 6, epochs 3
2023-03-25 20:26:51,264 : [INFO]  Model initialized for training
2023-03-25 20:27:05,358 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:27:05,588 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 20:27:05,589 : [INFO]  Connected to the server
2023-03-25 20:27:05,730 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 20:27:05,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:27:05,743 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 20:27:05,743 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 20:29:39,790 : [INFO]  ------------------------- Training round 1, loss: 0.6222 -------------------------
2023-03-25 20:29:39,790 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 20:29:39,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:29:39,795 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 20:31:50,611 : [INFO]  ------------------------- Training round 2, loss: 0.5953 -------------------------
2023-03-25 20:31:50,611 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 20:31:50,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:31:50,615 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 20:34:01,431 : [INFO]  ------------------------- Training round 3, loss: 0.5918 -------------------------
2023-03-25 20:34:01,431 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 20:34:01,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:34:01,435 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 20:36:12,541 : [INFO]  ------------------------- Training round 4, loss: 0.5905 -------------------------
2023-03-25 20:36:12,541 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 20:36:12,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:36:12,545 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 20:38:19,252 : [INFO]  ------------------------- Training round 5, loss: 0.5888 -------------------------
2023-03-25 20:38:19,253 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 20:38:36,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:38:36,829 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-25 20:40:48,072 : [INFO]  ------------------------- Training round 6, loss: 0.5881 -------------------------
2023-03-25 20:40:48,072 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-25 20:40:48,075 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:40:48,076 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-25 20:41:31,821 : [INFO]  Initially trained model: Training set : loss - 0.58, accuracy - 0.7, recall - 0.87, AUC - 0.84, F1 - 0.75, precision - 0.65, training time - -822.0 seconds
2023-03-25 20:41:31,821 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.88, AUC - 0.84, F1 - 0.74, precision - 0.64
2023-03-25 20:41:31,834 : [INFO]  Batch 1 initialized 
2023-03-25 20:41:32,281 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:41:32,386 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 20:41:32,386 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 20:41:35,322 : [INFO]  ------------------------- Batch round 1, loss: 0.6049 -------------------------
2023-03-25 20:41:35,322 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 20:41:35,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:35,326 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 20:41:36,453 : [INFO]  ------------------------- Batch round 2, loss: 0.5931 -------------------------
2023-03-25 20:41:36,454 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 20:41:36,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:36,459 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 20:41:37,576 : [INFO]  ------------------------- Batch round 3, loss: 0.5778 -------------------------
2023-03-25 20:41:37,577 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 20:41:37,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:37,582 : [INFO]  ------------------------- Batch 1 training: round 4 -------------------------
2023-03-25 20:41:38,694 : [INFO]  ------------------------- Batch round 4, loss: 0.5761 -------------------------
2023-03-25 20:41:38,694 : [INFO]  ------------------------- Batch 1, round 4: Sent local model to the server -------------------------
2023-03-25 20:41:38,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:38,699 : [INFO]  ------------------------- Batch 1 training: round 5 -------------------------
2023-03-25 20:41:39,820 : [INFO]  ------------------------- Batch round 5, loss: 0.5791 -------------------------
2023-03-25 20:41:39,821 : [INFO]  ------------------------- Batch 1, round 5: Sent local model to the server -------------------------
2023-03-25 20:41:39,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:39,826 : [INFO]  ------------------------- Batch 1 training: round 6 -------------------------
2023-03-25 20:41:40,940 : [INFO]  ------------------------- Batch round 6, loss: 0.5754 -------------------------
2023-03-25 20:41:40,940 : [INFO]  ------------------------- Batch 1, round 6: Sent local model to the server -------------------------
2023-03-25 20:41:40,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:40,945 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 20:41:40,945 : [INFO]  ################ Batch 1: final global model evalution after 6 rounds ################
2023-03-25 20:41:42,244 : [INFO]  Batch 1: Training set : loss - 0.5698, accuracy - 0.7609, recall - 0.9239, AUC - 0.8659, F1 - 0.7944, precision - 0.6967, training time - -9.0 seconds
2023-03-25 20:41:42,244 : [INFO]  Batch 1: Testing set : loss - 0.5646, accuracy - 0.7549, recall - 0.8922, AUC - 0.8722, F1 - 0.7845, precision - 0.7
2023-03-25 20:41:42,254 : [INFO]  Batch 2 initialized 
2023-03-25 20:41:42,678 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:41:42,829 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 20:41:45,652 : [INFO]  ------------------------- Batch round 1, loss: 0.5573 -------------------------
2023-03-25 20:41:45,653 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 20:41:45,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:45,657 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 20:41:46,748 : [INFO]  ------------------------- Batch round 2, loss: 0.5551 -------------------------
2023-03-25 20:41:46,748 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 20:41:46,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:46,753 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 20:41:47,784 : [INFO]  ------------------------- Batch round 3, loss: 0.5529 -------------------------
2023-03-25 20:41:47,784 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 20:41:47,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:47,789 : [INFO]  ------------------------- Batch 2 training: round 4 -------------------------
2023-03-25 20:41:48,878 : [INFO]  ------------------------- Batch round 4, loss: 0.5473 -------------------------
2023-03-25 20:41:48,878 : [INFO]  ------------------------- Batch 2, round 4: Sent local model to the server -------------------------
2023-03-25 20:41:48,896 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:48,898 : [INFO]  ------------------------- Batch 2 training: round 5 -------------------------
2023-03-25 20:41:49,950 : [INFO]  ------------------------- Batch round 5, loss: 0.5388 -------------------------
2023-03-25 20:41:49,951 : [INFO]  ------------------------- Batch 2, round 5: Sent local model to the server -------------------------
2023-03-25 20:41:49,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:49,955 : [INFO]  ------------------------- Batch 2 training: round 6 -------------------------
2023-03-25 20:41:51,008 : [INFO]  ------------------------- Batch round 6, loss: 0.5515 -------------------------
2023-03-25 20:41:51,008 : [INFO]  ------------------------- Batch 2, round 6: Sent local model to the server -------------------------
2023-03-25 20:41:51,012 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:51,014 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 20:41:51,014 : [INFO]  ################ Batch 2: final global model evalution after 6 rounds ################
2023-03-25 20:41:52,306 : [INFO]  Batch 2: Training set : loss - 0.5419, accuracy - 0.7772, recall - 0.9565, AUC - 0.8902, F1 - 0.8111, precision - 0.704, training time - -8.0 seconds
2023-03-25 20:41:52,306 : [INFO]  Batch 2: Testing set : loss - 0.5668, accuracy - 0.7206, recall - 0.9216, AUC - 0.8726, F1 - 0.7673, precision - 0.6573
2023-03-25 20:41:52,317 : [INFO]  Batch 3 initialized 
2023-03-25 20:41:52,732 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:41:52,954 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 20:41:55,691 : [INFO]  ------------------------- Batch round 1, loss: 0.5451 -------------------------
2023-03-25 20:41:55,691 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 20:41:55,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:55,703 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 20:41:57,055 : [INFO]  ------------------------- Batch round 2, loss: 0.5451 -------------------------
2023-03-25 20:41:57,055 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 20:41:57,058 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:57,059 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 20:41:58,106 : [INFO]  ------------------------- Batch round 3, loss: 0.5415 -------------------------
2023-03-25 20:41:58,107 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 20:41:58,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:58,123 : [INFO]  ------------------------- Batch 3 training: round 4 -------------------------
2023-03-25 20:41:59,444 : [INFO]  ------------------------- Batch round 4, loss: 0.5394 -------------------------
2023-03-25 20:41:59,444 : [INFO]  ------------------------- Batch 3, round 4: Sent local model to the server -------------------------
2023-03-25 20:41:59,447 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:59,449 : [INFO]  ------------------------- Batch 3 training: round 5 -------------------------
2023-03-25 20:42:00,496 : [INFO]  ------------------------- Batch round 5, loss: 0.5222 -------------------------
2023-03-25 20:42:00,496 : [INFO]  ------------------------- Batch 3, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:00,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:00,519 : [INFO]  ------------------------- Batch 3 training: round 6 -------------------------
2023-03-25 20:42:01,615 : [INFO]  ------------------------- Batch round 6, loss: 0.5307 -------------------------
2023-03-25 20:42:01,615 : [INFO]  ------------------------- Batch 3, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:01,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:01,626 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 20:42:01,626 : [INFO]  ################ Batch 3: final global model evalution after 6 rounds ################
2023-03-25 20:42:02,917 : [INFO]  Batch 3: Training set : loss - 0.5275, accuracy - 0.7772, recall - 0.8913, AUC - 0.8948, F1 - 0.8, precision - 0.7257, training time - -9.0 seconds
2023-03-25 20:42:02,918 : [INFO]  Batch 3: Testing set : loss - 0.5612, accuracy - 0.7206, recall - 0.9314, AUC - 0.8697, F1 - 0.7692, precision - 0.6552
2023-03-25 20:42:02,929 : [INFO]  Batch 4 initialized 
2023-03-25 20:42:03,350 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:03,563 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 20:42:06,312 : [INFO]  ------------------------- Batch round 1, loss: 0.5608 -------------------------
2023-03-25 20:42:06,312 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:06,330 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:06,333 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 20:42:07,425 : [INFO]  ------------------------- Batch round 2, loss: 0.5582 -------------------------
2023-03-25 20:42:07,425 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:07,428 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:07,431 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 20:42:08,502 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 20:42:08,502 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:08,505 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:08,507 : [INFO]  ------------------------- Batch 4 training: round 4 -------------------------
2023-03-25 20:42:09,567 : [INFO]  ------------------------- Batch round 4, loss: 0.5589 -------------------------
2023-03-25 20:42:09,567 : [INFO]  ------------------------- Batch 4, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:09,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:09,572 : [INFO]  ------------------------- Batch 4 training: round 5 -------------------------
2023-03-25 20:42:10,656 : [INFO]  ------------------------- Batch round 5, loss: 0.5474 -------------------------
2023-03-25 20:42:10,656 : [INFO]  ------------------------- Batch 4, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:10,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:10,661 : [INFO]  ------------------------- Batch 4 training: round 6 -------------------------
2023-03-25 20:42:11,737 : [INFO]  ------------------------- Batch round 6, loss: 0.5372 -------------------------
2023-03-25 20:42:11,737 : [INFO]  ------------------------- Batch 4, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:11,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:11,743 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 20:42:11,744 : [INFO]  ################ Batch 4: final global model evalution after 6 rounds ################
2023-03-25 20:42:12,993 : [INFO]  Batch 4: Training set : loss - 0.5428, accuracy - 0.7663, recall - 0.9348, AUC - 0.9222, F1 - 0.8, precision - 0.6992, training time - -8.0 seconds
2023-03-25 20:42:12,993 : [INFO]  Batch 4: Testing set : loss - 0.5696, accuracy - 0.7353, recall - 0.951, AUC - 0.884, F1 - 0.7823, precision - 0.6644
2023-03-25 20:42:13,004 : [INFO]  Batch 5 initialized 
2023-03-25 20:42:13,421 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:13,636 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 20:42:16,490 : [INFO]  ------------------------- Batch round 1, loss: 0.5443 -------------------------
2023-03-25 20:42:16,490 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:16,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:16,495 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 20:42:17,588 : [INFO]  ------------------------- Batch round 2, loss: 0.5427 -------------------------
2023-03-25 20:42:17,588 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:17,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:17,593 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 20:42:18,761 : [INFO]  ------------------------- Batch round 3, loss: 0.5313 -------------------------
2023-03-25 20:42:18,761 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:18,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:18,766 : [INFO]  ------------------------- Batch 5 training: round 4 -------------------------
2023-03-25 20:42:19,792 : [INFO]  ------------------------- Batch round 4, loss: 0.5236 -------------------------
2023-03-25 20:42:19,792 : [INFO]  ------------------------- Batch 5, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:20,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:20,053 : [INFO]  ------------------------- Batch 5 training: round 5 -------------------------
2023-03-25 20:42:21,098 : [INFO]  ------------------------- Batch round 5, loss: 0.5244 -------------------------
2023-03-25 20:42:21,098 : [INFO]  ------------------------- Batch 5, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:21,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:21,103 : [INFO]  ------------------------- Batch 5 training: round 6 -------------------------
2023-03-25 20:42:22,189 : [INFO]  ------------------------- Batch round 6, loss: 0.5211 -------------------------
2023-03-25 20:42:22,189 : [INFO]  ------------------------- Batch 5, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:22,192 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:22,194 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 20:42:22,194 : [INFO]  ################ Batch 5: final global model evalution after 6 rounds ################
2023-03-25 20:42:23,491 : [INFO]  Batch 5: Training set : loss - 0.5205, accuracy - 0.8207, recall - 0.9565, AUC - 0.936, F1 - 0.8421, precision - 0.7521, training time - -9.0 seconds
2023-03-25 20:42:23,491 : [INFO]  Batch 5: Testing set : loss - 0.5842, accuracy - 0.7059, recall - 0.8824, AUC - 0.8335, F1 - 0.75, precision - 0.6522
2023-03-25 20:42:23,498 : [INFO]  Batch 6 initialized 
2023-03-25 20:42:23,932 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:24,165 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 20:42:26,963 : [INFO]  ------------------------- Batch round 1, loss: 0.5757 -------------------------
2023-03-25 20:42:26,963 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:26,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:26,968 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 20:42:28,040 : [INFO]  ------------------------- Batch round 2, loss: 0.571 -------------------------
2023-03-25 20:42:28,040 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:28,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:28,049 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 20:42:29,139 : [INFO]  ------------------------- Batch round 3, loss: 0.5665 -------------------------
2023-03-25 20:42:29,139 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:29,142 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:29,144 : [INFO]  ------------------------- Batch 6 training: round 4 -------------------------
2023-03-25 20:42:30,221 : [INFO]  ------------------------- Batch round 4, loss: 0.5531 -------------------------
2023-03-25 20:42:30,221 : [INFO]  ------------------------- Batch 6, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:30,236 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:30,238 : [INFO]  ------------------------- Batch 6 training: round 5 -------------------------
2023-03-25 20:42:31,298 : [INFO]  ------------------------- Batch round 5, loss: 0.5545 -------------------------
2023-03-25 20:42:31,298 : [INFO]  ------------------------- Batch 6, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:31,301 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:31,303 : [INFO]  ------------------------- Batch 6 training: round 6 -------------------------
2023-03-25 20:42:32,360 : [INFO]  ------------------------- Batch round 6, loss: 0.5561 -------------------------
2023-03-25 20:42:32,360 : [INFO]  ------------------------- Batch 6, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:32,363 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:32,365 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 20:42:32,365 : [INFO]  ################ Batch 6: final global model evalution after 6 rounds ################
2023-03-25 20:42:33,643 : [INFO]  Batch 6: Training set : loss - 0.559, accuracy - 0.7554, recall - 0.9457, AUC - 0.8793, F1 - 0.7945, precision - 0.685, training time - -8.0 seconds
2023-03-25 20:42:33,643 : [INFO]  Batch 6: Testing set : loss - 0.5696, accuracy - 0.7157, recall - 0.8922, AUC - 0.8777, F1 - 0.7583, precision - 0.6594
2023-03-25 20:42:33,667 : [INFO]  Batch 7 initialized 
2023-03-25 20:42:34,087 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:34,324 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 20:42:37,142 : [INFO]  ------------------------- Batch round 1, loss: 0.5735 -------------------------
2023-03-25 20:42:37,142 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:37,443 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:37,449 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 20:42:38,518 : [INFO]  ------------------------- Batch round 2, loss: 0.5671 -------------------------
2023-03-25 20:42:38,518 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:38,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:38,523 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 20:42:39,641 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 20:42:39,642 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:39,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:39,646 : [INFO]  ------------------------- Batch 7 training: round 4 -------------------------
2023-03-25 20:42:40,727 : [INFO]  ------------------------- Batch round 4, loss: 0.5563 -------------------------
2023-03-25 20:42:40,727 : [INFO]  ------------------------- Batch 7, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:40,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:40,732 : [INFO]  ------------------------- Batch 7 training: round 5 -------------------------
2023-03-25 20:42:41,882 : [INFO]  ------------------------- Batch round 5, loss: 0.5536 -------------------------
2023-03-25 20:42:41,883 : [INFO]  ------------------------- Batch 7, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:41,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:41,887 : [INFO]  ------------------------- Batch 7 training: round 6 -------------------------
2023-03-25 20:42:42,989 : [INFO]  ------------------------- Batch round 6, loss: 0.5585 -------------------------
2023-03-25 20:42:42,989 : [INFO]  ------------------------- Batch 7, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:42,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:42,995 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 20:42:42,995 : [INFO]  ################ Batch 7: final global model evalution after 6 rounds ################
2023-03-25 20:42:44,340 : [INFO]  Batch 7: Training set : loss - 0.5554, accuracy - 0.7609, recall - 0.9565, AUC - 0.8714, F1 - 0.8, precision - 0.6875, training time - -9.0 seconds
2023-03-25 20:42:44,340 : [INFO]  Batch 7: Testing set : loss - 0.5824, accuracy - 0.6912, recall - 0.8529, AUC - 0.8292, F1 - 0.7342, precision - 0.6444
2023-03-25 20:42:44,346 : [INFO]  Batch 8 initialized 
2023-03-25 20:42:44,770 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:45,008 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 20:42:47,794 : [INFO]  ------------------------- Batch round 1, loss: 0.58 -------------------------
2023-03-25 20:42:47,794 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:47,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:47,801 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 20:42:48,908 : [INFO]  ------------------------- Batch round 2, loss: 0.5728 -------------------------
2023-03-25 20:42:48,908 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:48,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:48,913 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 20:42:49,990 : [INFO]  ------------------------- Batch round 3, loss: 0.5702 -------------------------
2023-03-25 20:42:49,990 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:50,010 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:50,012 : [INFO]  ------------------------- Batch 8 training: round 4 -------------------------
2023-03-25 20:42:51,128 : [INFO]  ------------------------- Batch round 4, loss: 0.5611 -------------------------
2023-03-25 20:42:51,128 : [INFO]  ------------------------- Batch 8, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:51,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:51,133 : [INFO]  ------------------------- Batch 8 training: round 5 -------------------------
2023-03-25 20:42:52,224 : [INFO]  ------------------------- Batch round 5, loss: 0.5515 -------------------------
2023-03-25 20:42:52,224 : [INFO]  ------------------------- Batch 8, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:52,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:52,229 : [INFO]  ------------------------- Batch 8 training: round 6 -------------------------
2023-03-25 20:42:53,296 : [INFO]  ------------------------- Batch round 6, loss: 0.5534 -------------------------
2023-03-25 20:42:53,296 : [INFO]  ------------------------- Batch 8, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:53,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:53,572 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 20:42:53,572 : [INFO]  ################ Batch 8: final global model evalution after 6 rounds ################
2023-03-25 20:42:54,831 : [INFO]  Batch 8: Training set : loss - 0.5515, accuracy - 0.7391, recall - 0.8804, AUC - 0.8868, F1 - 0.7714, precision - 0.6864, training time - -9.0 seconds
2023-03-25 20:42:54,832 : [INFO]  Batch 8: Testing set : loss - 0.5712, accuracy - 0.7157, recall - 0.8627, AUC - 0.852, F1 - 0.7521, precision - 0.6667
2023-03-25 20:42:54,838 : [INFO]  Batch 9 initialized 
2023-03-25 20:42:55,258 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:55,503 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 20:42:58,290 : [INFO]  ------------------------- Batch round 1, loss: 0.5605 -------------------------
2023-03-25 20:42:58,290 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:58,359 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:58,361 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 20:42:59,451 : [INFO]  ------------------------- Batch round 2, loss: 0.5576 -------------------------
2023-03-25 20:42:59,451 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:59,498 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:59,499 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 20:43:00,582 : [INFO]  ------------------------- Batch round 3, loss: 0.5393 -------------------------
2023-03-25 20:43:00,583 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:00,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:00,639 : [INFO]  ------------------------- Batch 9 training: round 4 -------------------------
2023-03-25 20:43:01,774 : [INFO]  ------------------------- Batch round 4, loss: 0.542 -------------------------
2023-03-25 20:43:01,774 : [INFO]  ------------------------- Batch 9, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:01,811 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:01,813 : [INFO]  ------------------------- Batch 9 training: round 5 -------------------------
2023-03-25 20:43:02,925 : [INFO]  ------------------------- Batch round 5, loss: 0.54 -------------------------
2023-03-25 20:43:02,926 : [INFO]  ------------------------- Batch 9, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:02,951 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:02,953 : [INFO]  ------------------------- Batch 9 training: round 6 -------------------------
2023-03-25 20:43:04,031 : [INFO]  ------------------------- Batch round 6, loss: 0.5308 -------------------------
2023-03-25 20:43:04,032 : [INFO]  ------------------------- Batch 9, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:04,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:04,094 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 20:43:04,094 : [INFO]  ################ Batch 9: final global model evalution after 6 rounds ################
2023-03-25 20:43:05,370 : [INFO]  Batch 9: Training set : loss - 0.5283, accuracy - 0.788, recall - 0.9348, AUC - 0.9116, F1 - 0.8152, precision - 0.7227, training time - -9.0 seconds
2023-03-25 20:43:05,370 : [INFO]  Batch 9: Testing set : loss - 0.5606, accuracy - 0.7108, recall - 0.8725, AUC - 0.8675, F1 - 0.7511, precision - 0.6593
2023-03-25 20:43:05,384 : [INFO]  Batch 10 initialized 
2023-03-25 20:43:05,803 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:06,039 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 20:43:08,826 : [INFO]  ------------------------- Batch round 1, loss: 0.5554 -------------------------
2023-03-25 20:43:08,826 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:08,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:08,881 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 20:43:09,933 : [INFO]  ------------------------- Batch round 2, loss: 0.5512 -------------------------
2023-03-25 20:43:09,933 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:09,972 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:09,974 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 20:43:11,062 : [INFO]  ------------------------- Batch round 3, loss: 0.5449 -------------------------
2023-03-25 20:43:11,062 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:11,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:11,082 : [INFO]  ------------------------- Batch 10 training: round 4 -------------------------
2023-03-25 20:43:12,152 : [INFO]  ------------------------- Batch round 4, loss: 0.5371 -------------------------
2023-03-25 20:43:12,152 : [INFO]  ------------------------- Batch 10, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:12,182 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:12,184 : [INFO]  ------------------------- Batch 10 training: round 5 -------------------------
2023-03-25 20:43:13,313 : [INFO]  ------------------------- Batch round 5, loss: 0.5335 -------------------------
2023-03-25 20:43:13,313 : [INFO]  ------------------------- Batch 10, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:13,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:13,318 : [INFO]  ------------------------- Batch 10 training: round 6 -------------------------
2023-03-25 20:43:14,426 : [INFO]  ------------------------- Batch round 6, loss: 0.5312 -------------------------
2023-03-25 20:43:14,426 : [INFO]  ------------------------- Batch 10, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:14,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:14,466 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 20:43:14,466 : [INFO]  ################ Batch 10: final global model evalution after 6 rounds ################
2023-03-25 20:43:15,753 : [INFO]  Batch 10: Training set : loss - 0.5264, accuracy - 0.8043, recall - 0.9674, AUC - 0.9224, F1 - 0.8318, precision - 0.7295, training time - -8.0 seconds
2023-03-25 20:43:15,753 : [INFO]  Batch 10: Testing set : loss - 0.5441, accuracy - 0.7549, recall - 0.9118, AUC - 0.8935, F1 - 0.7881, precision - 0.694
2023-03-25 20:43:15,765 : [INFO]  Batch 11 initialized 
2023-03-25 20:43:16,195 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:16,442 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 20:43:19,279 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 20:43:19,280 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:19,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:19,312 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 20:43:20,385 : [INFO]  ------------------------- Batch round 2, loss: 0.5658 -------------------------
2023-03-25 20:43:20,386 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:20,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:20,391 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 20:43:21,501 : [INFO]  ------------------------- Batch round 3, loss: 0.5749 -------------------------
2023-03-25 20:43:21,501 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:21,505 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:21,506 : [INFO]  ------------------------- Batch 11 training: round 4 -------------------------
2023-03-25 20:43:22,621 : [INFO]  ------------------------- Batch round 4, loss: 0.5673 -------------------------
2023-03-25 20:43:22,622 : [INFO]  ------------------------- Batch 11, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:22,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:22,631 : [INFO]  ------------------------- Batch 11 training: round 5 -------------------------
2023-03-25 20:43:23,784 : [INFO]  ------------------------- Batch round 5, loss: 0.5684 -------------------------
2023-03-25 20:43:23,784 : [INFO]  ------------------------- Batch 11, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:23,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:23,789 : [INFO]  ------------------------- Batch 11 training: round 6 -------------------------
2023-03-25 20:43:24,885 : [INFO]  ------------------------- Batch round 6, loss: 0.554 -------------------------
2023-03-25 20:43:24,885 : [INFO]  ------------------------- Batch 11, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:24,888 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:24,890 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 20:43:24,890 : [INFO]  ################ Batch 11: final global model evalution after 6 rounds ################
2023-03-25 20:43:26,182 : [INFO]  Batch 11: Training set : loss - 0.5622, accuracy - 0.7554, recall - 0.9348, AUC - 0.8769, F1 - 0.7926, precision - 0.688, training time - -8.0 seconds
2023-03-25 20:43:26,182 : [INFO]  Batch 11: Testing set : loss - 0.5576, accuracy - 0.7304, recall - 0.8824, AUC - 0.8856, F1 - 0.766, precision - 0.6767
2023-03-25 20:43:26,205 : [INFO]  Batch 12 initialized 
2023-03-25 20:43:26,634 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:26,890 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 20:43:29,713 : [INFO]  ------------------------- Batch round 1, loss: 0.5659 -------------------------
2023-03-25 20:43:29,714 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:29,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:29,718 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 20:43:30,840 : [INFO]  ------------------------- Batch round 2, loss: 0.5645 -------------------------
2023-03-25 20:43:30,840 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:30,844 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:30,846 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 20:43:31,996 : [INFO]  ------------------------- Batch round 3, loss: 0.5477 -------------------------
2023-03-25 20:43:31,996 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:32,000 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:32,003 : [INFO]  ------------------------- Batch 12 training: round 4 -------------------------
2023-03-25 20:43:33,154 : [INFO]  ------------------------- Batch round 4, loss: 0.5647 -------------------------
2023-03-25 20:43:33,154 : [INFO]  ------------------------- Batch 12, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:33,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:33,159 : [INFO]  ------------------------- Batch 12 training: round 5 -------------------------
2023-03-25 20:43:34,308 : [INFO]  ------------------------- Batch round 5, loss: 0.5513 -------------------------
2023-03-25 20:43:34,308 : [INFO]  ------------------------- Batch 12, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:34,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:34,313 : [INFO]  ------------------------- Batch 12 training: round 6 -------------------------
2023-03-25 20:43:35,445 : [INFO]  ------------------------- Batch round 6, loss: 0.5593 -------------------------
2023-03-25 20:43:35,445 : [INFO]  ------------------------- Batch 12, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:35,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:35,450 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 20:43:35,450 : [INFO]  ################ Batch 12: final global model evalution after 6 rounds ################
2023-03-25 20:43:36,793 : [INFO]  Batch 12: Training set : loss - 0.5442, accuracy - 0.7826, recall - 0.8478, AUC - 0.8535, F1 - 0.7959, precision - 0.75, training time - -9.0 seconds
2023-03-25 20:43:36,793 : [INFO]  Batch 12: Testing set : loss - 0.5933, accuracy - 0.6863, recall - 0.8137, AUC - 0.8078, F1 - 0.7217, precision - 0.6484
2023-03-25 20:43:36,800 : [INFO]  Batch 13 initialized 
2023-03-25 20:43:37,222 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:37,473 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 20:43:40,280 : [INFO]  ------------------------- Batch round 1, loss: 0.6048 -------------------------
2023-03-25 20:43:40,280 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:40,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:40,285 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 20:43:41,379 : [INFO]  ------------------------- Batch round 2, loss: 0.6054 -------------------------
2023-03-25 20:43:41,379 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:41,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:41,384 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 20:43:42,469 : [INFO]  ------------------------- Batch round 3, loss: 0.6017 -------------------------
2023-03-25 20:43:42,469 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:42,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:42,487 : [INFO]  ------------------------- Batch 13 training: round 4 -------------------------
2023-03-25 20:43:43,563 : [INFO]  ------------------------- Batch round 4, loss: 0.5846 -------------------------
2023-03-25 20:43:43,563 : [INFO]  ------------------------- Batch 13, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:43,566 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:43,568 : [INFO]  ------------------------- Batch 13 training: round 5 -------------------------
2023-03-25 20:43:44,660 : [INFO]  ------------------------- Batch round 5, loss: 0.5882 -------------------------
2023-03-25 20:43:44,660 : [INFO]  ------------------------- Batch 13, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:44,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:44,665 : [INFO]  ------------------------- Batch 13 training: round 6 -------------------------
2023-03-25 20:43:45,784 : [INFO]  ------------------------- Batch round 6, loss: 0.5851 -------------------------
2023-03-25 20:43:45,784 : [INFO]  ------------------------- Batch 13, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:45,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:45,789 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 20:43:45,789 : [INFO]  ################ Batch 13: final global model evalution after 6 rounds ################
2023-03-25 20:43:47,138 : [INFO]  Batch 13: Training set : loss - 0.5829, accuracy - 0.712, recall - 0.9022, AUC - 0.8331, F1 - 0.758, precision - 0.6535, training time - -8.0 seconds
2023-03-25 20:43:47,138 : [INFO]  Batch 13: Testing set : loss - 0.58, accuracy - 0.7157, recall - 0.8039, AUC - 0.8212, F1 - 0.7387, precision - 0.6833
2023-03-25 20:43:47,147 : [INFO]  Batch 14 initialized 
2023-03-25 20:43:47,568 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:47,833 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 20:43:50,607 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 20:43:50,607 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:50,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:50,612 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 20:43:51,698 : [INFO]  ------------------------- Batch round 2, loss: 0.555 -------------------------
2023-03-25 20:43:51,698 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:51,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:51,703 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 20:43:52,823 : [INFO]  ------------------------- Batch round 3, loss: 0.5465 -------------------------
2023-03-25 20:43:52,823 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:52,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:52,828 : [INFO]  ------------------------- Batch 14 training: round 4 -------------------------
2023-03-25 20:43:53,951 : [INFO]  ------------------------- Batch round 4, loss: 0.5503 -------------------------
2023-03-25 20:43:53,951 : [INFO]  ------------------------- Batch 14, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:53,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:53,957 : [INFO]  ------------------------- Batch 14 training: round 5 -------------------------
2023-03-25 20:43:55,033 : [INFO]  ------------------------- Batch round 5, loss: 0.5431 -------------------------
2023-03-25 20:43:55,033 : [INFO]  ------------------------- Batch 14, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:55,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:55,038 : [INFO]  ------------------------- Batch 14 training: round 6 -------------------------
2023-03-25 20:43:56,139 : [INFO]  ------------------------- Batch round 6, loss: 0.5335 -------------------------
2023-03-25 20:43:56,139 : [INFO]  ------------------------- Batch 14, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:56,142 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:56,144 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 20:43:56,144 : [INFO]  ################ Batch 14: final global model evalution after 6 rounds ################
2023-03-25 20:43:57,433 : [INFO]  Batch 14: Training set : loss - 0.5357, accuracy - 0.8043, recall - 0.9239, AUC - 0.8917, F1 - 0.8252, precision - 0.7456, training time - -8.0 seconds
2023-03-25 20:43:57,433 : [INFO]  Batch 14: Testing set : loss - 0.5684, accuracy - 0.7108, recall - 0.8824, AUC - 0.8707, F1 - 0.7531, precision - 0.6569
2023-03-25 20:43:57,439 : [INFO]  Batch 15 initialized 
2023-03-25 20:43:57,863 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:58,128 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 20:44:00,984 : [INFO]  ------------------------- Batch round 1, loss: 0.5729 -------------------------
2023-03-25 20:44:00,984 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:00,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:00,989 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 20:44:02,113 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 20:44:02,113 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:02,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:02,118 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 20:44:03,230 : [INFO]  ------------------------- Batch round 3, loss: 0.5637 -------------------------
2023-03-25 20:44:03,230 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:03,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:03,235 : [INFO]  ------------------------- Batch 15 training: round 4 -------------------------
2023-03-25 20:44:04,351 : [INFO]  ------------------------- Batch round 4, loss: 0.5603 -------------------------
2023-03-25 20:44:04,351 : [INFO]  ------------------------- Batch 15, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:04,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:04,356 : [INFO]  ------------------------- Batch 15 training: round 5 -------------------------
2023-03-25 20:44:05,476 : [INFO]  ------------------------- Batch round 5, loss: 0.5608 -------------------------
2023-03-25 20:44:05,476 : [INFO]  ------------------------- Batch 15, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:05,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:05,481 : [INFO]  ------------------------- Batch 15 training: round 6 -------------------------
2023-03-25 20:44:06,599 : [INFO]  ------------------------- Batch round 6, loss: 0.5524 -------------------------
2023-03-25 20:44:06,599 : [INFO]  ------------------------- Batch 15, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:06,602 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:06,604 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 20:44:06,604 : [INFO]  ################ Batch 15: final global model evalution after 6 rounds ################
2023-03-25 20:44:07,944 : [INFO]  Batch 15: Training set : loss - 0.5543, accuracy - 0.7663, recall - 0.9457, AUC - 0.8663, F1 - 0.8018, precision - 0.696, training time - -8.0 seconds
2023-03-25 20:44:07,944 : [INFO]  Batch 15: Testing set : loss - 0.5804, accuracy - 0.6961, recall - 0.8137, AUC - 0.8402, F1 - 0.7281, precision - 0.6587
2023-03-25 20:44:07,953 : [INFO]  Batch 16 initialized 
2023-03-25 20:44:08,372 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:08,634 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 20:44:11,375 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-25 20:44:11,375 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:11,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:11,400 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 20:44:12,466 : [INFO]  ------------------------- Batch round 2, loss: 0.5534 -------------------------
2023-03-25 20:44:12,466 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:12,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:12,519 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 20:44:13,556 : [INFO]  ------------------------- Batch round 3, loss: 0.5462 -------------------------
2023-03-25 20:44:13,556 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:13,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:13,612 : [INFO]  ------------------------- Batch 16 training: round 4 -------------------------
2023-03-25 20:44:14,662 : [INFO]  ------------------------- Batch round 4, loss: 0.5455 -------------------------
2023-03-25 20:44:14,662 : [INFO]  ------------------------- Batch 16, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:14,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:14,723 : [INFO]  ------------------------- Batch 16 training: round 5 -------------------------
2023-03-25 20:44:15,764 : [INFO]  ------------------------- Batch round 5, loss: 0.5378 -------------------------
2023-03-25 20:44:15,764 : [INFO]  ------------------------- Batch 16, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:15,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:15,797 : [INFO]  ------------------------- Batch 16 training: round 6 -------------------------
2023-03-25 20:44:16,893 : [INFO]  ------------------------- Batch round 6, loss: 0.5377 -------------------------
2023-03-25 20:44:16,894 : [INFO]  ------------------------- Batch 16, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:16,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:16,913 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 20:44:16,913 : [INFO]  ################ Batch 16: final global model evalution after 6 rounds ################
2023-03-25 20:44:18,202 : [INFO]  Batch 16: Training set : loss - 0.5347, accuracy - 0.7717, recall - 0.9348, AUC - 0.9042, F1 - 0.8037, precision - 0.7049, training time - -8.0 seconds
2023-03-25 20:44:18,202 : [INFO]  Batch 16: Testing set : loss - 0.5414, accuracy - 0.7402, recall - 0.9216, AUC - 0.927, F1 - 0.7801, precision - 0.6763
2023-03-25 20:44:18,209 : [INFO]  Batch 17 initialized 
2023-03-25 20:44:18,635 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:18,910 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 20:44:21,683 : [INFO]  ------------------------- Batch round 1, loss: 0.5582 -------------------------
2023-03-25 20:44:21,683 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:21,698 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:21,700 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 20:44:22,992 : [INFO]  ------------------------- Batch round 2, loss: 0.5453 -------------------------
2023-03-25 20:44:22,992 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:22,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:22,997 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 20:44:24,020 : [INFO]  ------------------------- Batch round 3, loss: 0.5415 -------------------------
2023-03-25 20:44:24,020 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:24,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:24,070 : [INFO]  ------------------------- Batch 17 training: round 4 -------------------------
2023-03-25 20:44:25,134 : [INFO]  ------------------------- Batch round 4, loss: 0.5341 -------------------------
2023-03-25 20:44:25,134 : [INFO]  ------------------------- Batch 17, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:25,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:25,171 : [INFO]  ------------------------- Batch 17 training: round 5 -------------------------
2023-03-25 20:44:26,219 : [INFO]  ------------------------- Batch round 5, loss: 0.5379 -------------------------
2023-03-25 20:44:26,219 : [INFO]  ------------------------- Batch 17, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:26,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:26,250 : [INFO]  ------------------------- Batch 17 training: round 6 -------------------------
2023-03-25 20:44:27,281 : [INFO]  ------------------------- Batch round 6, loss: 0.5288 -------------------------
2023-03-25 20:44:27,281 : [INFO]  ------------------------- Batch 17, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:27,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:27,299 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 20:44:27,300 : [INFO]  ################ Batch 17: final global model evalution after 6 rounds ################
2023-03-25 20:44:28,583 : [INFO]  Batch 17: Training set : loss - 0.5208, accuracy - 0.8152, recall - 0.9348, AUC - 0.8784, F1 - 0.835, precision - 0.7544, training time - -8.0 seconds
2023-03-25 20:44:28,583 : [INFO]  Batch 17: Testing set : loss - 0.5779, accuracy - 0.7059, recall - 0.8824, AUC - 0.8559, F1 - 0.75, precision - 0.6522
2023-03-25 20:44:28,589 : [INFO]  Batch 18 initialized 
2023-03-25 20:44:29,011 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:29,284 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 20:44:31,991 : [INFO]  ------------------------- Batch round 1, loss: 0.5814 -------------------------
2023-03-25 20:44:31,991 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:32,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:32,345 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 20:44:33,403 : [INFO]  ------------------------- Batch round 2, loss: 0.5807 -------------------------
2023-03-25 20:44:33,403 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:33,468 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:33,470 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 20:44:34,549 : [INFO]  ------------------------- Batch round 3, loss: 0.5832 -------------------------
2023-03-25 20:44:34,549 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:34,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:34,632 : [INFO]  ------------------------- Batch 18 training: round 4 -------------------------
2023-03-25 20:44:35,665 : [INFO]  ------------------------- Batch round 4, loss: 0.5764 -------------------------
2023-03-25 20:44:35,665 : [INFO]  ------------------------- Batch 18, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:35,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:35,765 : [INFO]  ------------------------- Batch 18 training: round 5 -------------------------
2023-03-25 20:44:36,829 : [INFO]  ------------------------- Batch round 5, loss: 0.5653 -------------------------
2023-03-25 20:44:36,829 : [INFO]  ------------------------- Batch 18, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:36,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:36,899 : [INFO]  ------------------------- Batch 18 training: round 6 -------------------------
2023-03-25 20:44:37,968 : [INFO]  ------------------------- Batch round 6, loss: 0.5671 -------------------------
2023-03-25 20:44:37,968 : [INFO]  ------------------------- Batch 18, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:38,035 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:38,037 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 20:44:38,037 : [INFO]  ################ Batch 18: final global model evalution after 6 rounds ################
2023-03-25 20:44:39,288 : [INFO]  Batch 18: Training set : loss - 0.5695, accuracy - 0.7391, recall - 0.9348, AUC - 0.8462, F1 - 0.7818, precision - 0.6719, training time - -9.0 seconds
2023-03-25 20:44:39,288 : [INFO]  Batch 18: Testing set : loss - 0.5895, accuracy - 0.6814, recall - 0.8725, AUC - 0.85, F1 - 0.7325, precision - 0.6312
2023-03-25 20:44:39,301 : [INFO]  Batch 19 initialized 
2023-03-25 20:44:39,734 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:39,995 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 20:44:42,825 : [INFO]  ------------------------- Batch round 1, loss: 0.5846 -------------------------
2023-03-25 20:44:42,825 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:42,903 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:42,904 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 20:44:43,979 : [INFO]  ------------------------- Batch round 2, loss: 0.5919 -------------------------
2023-03-25 20:44:43,979 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:44,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:44,026 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 20:44:45,096 : [INFO]  ------------------------- Batch round 3, loss: 0.5697 -------------------------
2023-03-25 20:44:45,097 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:45,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:45,111 : [INFO]  ------------------------- Batch 19 training: round 4 -------------------------
2023-03-25 20:44:46,215 : [INFO]  ------------------------- Batch round 4, loss: 0.5663 -------------------------
2023-03-25 20:44:46,215 : [INFO]  ------------------------- Batch 19, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:46,243 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:46,245 : [INFO]  ------------------------- Batch 19 training: round 5 -------------------------
2023-03-25 20:44:47,358 : [INFO]  ------------------------- Batch round 5, loss: 0.5663 -------------------------
2023-03-25 20:44:47,358 : [INFO]  ------------------------- Batch 19, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:47,384 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:47,386 : [INFO]  ------------------------- Batch 19 training: round 6 -------------------------
2023-03-25 20:44:48,467 : [INFO]  ------------------------- Batch round 6, loss: 0.5584 -------------------------
2023-03-25 20:44:48,467 : [INFO]  ------------------------- Batch 19, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:48,475 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:48,477 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 20:44:48,478 : [INFO]  ################ Batch 19: final global model evalution after 6 rounds ################
2023-03-25 20:44:49,799 : [INFO]  Batch 19: Training set : loss - 0.561, accuracy - 0.7554, recall - 0.8804, AUC - 0.829, F1 - 0.7826, precision - 0.7043, training time - -8.0 seconds
2023-03-25 20:44:49,799 : [INFO]  Batch 19: Testing set : loss - 0.586, accuracy - 0.6912, recall - 0.8627, AUC - 0.8298, F1 - 0.7364, precision - 0.6423
2023-03-25 20:44:49,809 : [INFO]  Batch 20 initialized 
2023-03-25 20:44:50,227 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:50,507 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 20:44:53,331 : [INFO]  ------------------------- Batch round 1, loss: 0.5539 -------------------------
2023-03-25 20:44:53,331 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:53,362 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:53,364 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 20:44:54,454 : [INFO]  ------------------------- Batch round 2, loss: 0.5399 -------------------------
2023-03-25 20:44:54,454 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:54,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:54,495 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 20:44:55,626 : [INFO]  ------------------------- Batch round 3, loss: 0.5439 -------------------------
2023-03-25 20:44:55,626 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:55,639 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:55,641 : [INFO]  ------------------------- Batch 20 training: round 4 -------------------------
2023-03-25 20:44:56,733 : [INFO]  ------------------------- Batch round 4, loss: 0.5308 -------------------------
2023-03-25 20:44:56,733 : [INFO]  ------------------------- Batch 20, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:56,791 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:56,793 : [INFO]  ------------------------- Batch 20 training: round 5 -------------------------
2023-03-25 20:44:57,895 : [INFO]  ------------------------- Batch round 5, loss: 0.535 -------------------------
2023-03-25 20:44:57,895 : [INFO]  ------------------------- Batch 20, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:57,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:57,911 : [INFO]  ------------------------- Batch 20 training: round 6 -------------------------
2023-03-25 20:44:59,014 : [INFO]  ------------------------- Batch round 6, loss: 0.5304 -------------------------
2023-03-25 20:44:59,014 : [INFO]  ------------------------- Batch 20, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:59,035 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:59,038 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 20:44:59,038 : [INFO]  ################ Batch 20: final global model evalution after 6 rounds ################
2023-03-25 20:45:00,356 : [INFO]  Batch 20: Training set : loss - 0.5338, accuracy - 0.7554, recall - 0.9783, AUC - 0.9295, F1 - 0.8, precision - 0.6767, training time - -9.0 seconds
2023-03-25 20:45:00,356 : [INFO]  Batch 20: Testing set : loss - 0.5641, accuracy - 0.7157, recall - 0.9216, AUC - 0.8943, F1 - 0.7642, precision - 0.6528
2023-03-25 20:45:00,362 : [INFO]  Batch 21 initialized 
2023-03-25 20:45:00,783 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:01,060 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 20:45:03,862 : [INFO]  ------------------------- Batch round 1, loss: 0.6286 -------------------------
2023-03-25 20:45:03,863 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:03,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:03,902 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 20:45:04,976 : [INFO]  ------------------------- Batch round 2, loss: 0.6119 -------------------------
2023-03-25 20:45:04,977 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:04,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:04,987 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 20:45:06,095 : [INFO]  ------------------------- Batch round 3, loss: 0.6035 -------------------------
2023-03-25 20:45:06,095 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:06,104 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:06,106 : [INFO]  ------------------------- Batch 21 training: round 4 -------------------------
2023-03-25 20:45:07,245 : [INFO]  ------------------------- Batch round 4, loss: 0.5866 -------------------------
2023-03-25 20:45:07,245 : [INFO]  ------------------------- Batch 21, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:07,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:07,256 : [INFO]  ------------------------- Batch 21 training: round 5 -------------------------
2023-03-25 20:45:08,346 : [INFO]  ------------------------- Batch round 5, loss: 0.5887 -------------------------
2023-03-25 20:45:08,346 : [INFO]  ------------------------- Batch 21, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:08,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:08,362 : [INFO]  ------------------------- Batch 21 training: round 6 -------------------------
2023-03-25 20:45:09,439 : [INFO]  ------------------------- Batch round 6, loss: 0.5744 -------------------------
2023-03-25 20:45:09,439 : [INFO]  ------------------------- Batch 21, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:09,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:09,473 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 20:45:09,473 : [INFO]  ################ Batch 21: final global model evalution after 6 rounds ################
2023-03-25 20:45:10,787 : [INFO]  Batch 21: Training set : loss - 0.5866, accuracy - 0.6848, recall - 0.8043, AUC - 0.797, F1 - 0.7184, precision - 0.6491, training time - -8.0 seconds
2023-03-25 20:45:10,788 : [INFO]  Batch 21: Testing set : loss - 0.5595, accuracy - 0.7353, recall - 0.8922, AUC - 0.8534, F1 - 0.7712, precision - 0.6791
2023-03-25 20:45:10,800 : [INFO]  Batch 22 initialized 
2023-03-25 20:45:11,209 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:11,490 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 20:45:14,362 : [INFO]  ------------------------- Batch round 1, loss: 0.6122 -------------------------
2023-03-25 20:45:14,362 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:14,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:14,384 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 20:45:15,531 : [INFO]  ------------------------- Batch round 2, loss: 0.6008 -------------------------
2023-03-25 20:45:15,532 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:15,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:15,536 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 20:45:16,698 : [INFO]  ------------------------- Batch round 3, loss: 0.5851 -------------------------
2023-03-25 20:45:16,698 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:16,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:16,703 : [INFO]  ------------------------- Batch 22 training: round 4 -------------------------
2023-03-25 20:45:17,865 : [INFO]  ------------------------- Batch round 4, loss: 0.5882 -------------------------
2023-03-25 20:45:17,866 : [INFO]  ------------------------- Batch 22, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:18,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:18,095 : [INFO]  ------------------------- Batch 22 training: round 5 -------------------------
2023-03-25 20:45:19,219 : [INFO]  ------------------------- Batch round 5, loss: 0.5788 -------------------------
2023-03-25 20:45:19,219 : [INFO]  ------------------------- Batch 22, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:19,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:19,224 : [INFO]  ------------------------- Batch 22 training: round 6 -------------------------
2023-03-25 20:45:20,407 : [INFO]  ------------------------- Batch round 6, loss: 0.5702 -------------------------
2023-03-25 20:45:20,407 : [INFO]  ------------------------- Batch 22, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:20,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:20,412 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 20:45:20,412 : [INFO]  ################ Batch 22: final global model evalution after 6 rounds ################
2023-03-25 20:45:21,751 : [INFO]  Batch 22: Training set : loss - 0.5636, accuracy - 0.7337, recall - 0.8804, AUC - 0.8257, F1 - 0.7678, precision - 0.6807, training time - -9.0 seconds
2023-03-25 20:45:21,752 : [INFO]  Batch 22: Testing set : loss - 0.6343, accuracy - 0.6275, recall - 0.8529, AUC - 0.7713, F1 - 0.696, precision - 0.5878
2023-03-25 20:45:21,757 : [INFO]  Batch 23 initialized 
2023-03-25 20:45:22,171 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:22,459 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 20:45:25,351 : [INFO]  ------------------------- Batch round 1, loss: 0.5832 -------------------------
2023-03-25 20:45:25,351 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:25,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:25,356 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 20:45:26,503 : [INFO]  ------------------------- Batch round 2, loss: 0.5748 -------------------------
2023-03-25 20:45:26,503 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:26,506 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:26,509 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 20:45:27,704 : [INFO]  ------------------------- Batch round 3, loss: 0.5526 -------------------------
2023-03-25 20:45:27,704 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:27,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:27,709 : [INFO]  ------------------------- Batch 23 training: round 4 -------------------------
2023-03-25 20:45:28,867 : [INFO]  ------------------------- Batch round 4, loss: 0.5586 -------------------------
2023-03-25 20:45:28,867 : [INFO]  ------------------------- Batch 23, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:28,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:28,872 : [INFO]  ------------------------- Batch 23 training: round 5 -------------------------
2023-03-25 20:45:30,063 : [INFO]  ------------------------- Batch round 5, loss: 0.5517 -------------------------
2023-03-25 20:45:30,063 : [INFO]  ------------------------- Batch 23, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:30,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:30,068 : [INFO]  ------------------------- Batch 23 training: round 6 -------------------------
2023-03-25 20:45:31,198 : [INFO]  ------------------------- Batch round 6, loss: 0.5532 -------------------------
2023-03-25 20:45:31,198 : [INFO]  ------------------------- Batch 23, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:31,201 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:31,203 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 20:45:31,203 : [INFO]  ################ Batch 23: final global model evalution after 6 rounds ################
2023-03-25 20:45:32,558 : [INFO]  Batch 23: Training set : loss - 0.5433, accuracy - 0.7663, recall - 0.9348, AUC - 0.8987, F1 - 0.8, precision - 0.6992, training time - -9.0 seconds
2023-03-25 20:45:32,559 : [INFO]  Batch 23: Testing set : loss - 0.5677, accuracy - 0.7353, recall - 0.9118, AUC - 0.8823, F1 - 0.775, precision - 0.6739
2023-03-25 20:45:32,565 : [INFO]  Batch 24 initialized 
2023-03-25 20:45:32,979 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:33,265 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 20:45:36,172 : [INFO]  ------------------------- Batch round 1, loss: 0.5974 -------------------------
2023-03-25 20:45:36,172 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:36,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:36,177 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 20:45:37,280 : [INFO]  ------------------------- Batch round 2, loss: 0.5899 -------------------------
2023-03-25 20:45:37,281 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:37,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:37,285 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 20:45:38,431 : [INFO]  ------------------------- Batch round 3, loss: 0.593 -------------------------
2023-03-25 20:45:38,431 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:38,435 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:38,436 : [INFO]  ------------------------- Batch 24 training: round 4 -------------------------
2023-03-25 20:45:39,564 : [INFO]  ------------------------- Batch round 4, loss: 0.5814 -------------------------
2023-03-25 20:45:39,564 : [INFO]  ------------------------- Batch 24, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:39,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:39,569 : [INFO]  ------------------------- Batch 24 training: round 5 -------------------------
2023-03-25 20:45:40,714 : [INFO]  ------------------------- Batch round 5, loss: 0.5725 -------------------------
2023-03-25 20:45:40,714 : [INFO]  ------------------------- Batch 24, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:40,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:40,719 : [INFO]  ------------------------- Batch 24 training: round 6 -------------------------
2023-03-25 20:45:41,864 : [INFO]  ------------------------- Batch round 6, loss: 0.5785 -------------------------
2023-03-25 20:45:41,864 : [INFO]  ------------------------- Batch 24, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:41,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:41,869 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 20:45:41,869 : [INFO]  ################ Batch 24: final global model evalution after 6 rounds ################
2023-03-25 20:45:43,207 : [INFO]  Batch 24: Training set : loss - 0.5738, accuracy - 0.712, recall - 0.9022, AUC - 0.8299, F1 - 0.758, precision - 0.6535, training time - -9.0 seconds
2023-03-25 20:45:43,207 : [INFO]  Batch 24: Testing set : loss - 0.5903, accuracy - 0.6814, recall - 0.8824, AUC - 0.8249, F1 - 0.7347, precision - 0.6294
2023-03-25 20:45:43,216 : [INFO]  Batch 25 initialized 
2023-03-25 20:45:43,629 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:43,921 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 20:45:46,766 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-25 20:45:46,766 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:46,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:46,771 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 20:45:48,165 : [INFO]  ------------------------- Batch round 2, loss: 0.5578 -------------------------
2023-03-25 20:45:48,165 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:48,168 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:48,169 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 20:45:49,316 : [INFO]  ------------------------- Batch round 3, loss: 0.5568 -------------------------
2023-03-25 20:45:49,316 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:49,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:49,321 : [INFO]  ------------------------- Batch 25 training: round 4 -------------------------
2023-03-25 20:45:50,521 : [INFO]  ------------------------- Batch round 4, loss: 0.5616 -------------------------
2023-03-25 20:45:50,521 : [INFO]  ------------------------- Batch 25, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:50,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:50,526 : [INFO]  ------------------------- Batch 25 training: round 5 -------------------------
2023-03-25 20:45:51,672 : [INFO]  ------------------------- Batch round 5, loss: 0.5564 -------------------------
2023-03-25 20:45:51,673 : [INFO]  ------------------------- Batch 25, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:51,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:51,677 : [INFO]  ------------------------- Batch 25 training: round 6 -------------------------
2023-03-25 20:45:52,844 : [INFO]  ------------------------- Batch round 6, loss: 0.5539 -------------------------
2023-03-25 20:45:52,844 : [INFO]  ------------------------- Batch 25, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:52,847 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:52,849 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 20:45:52,849 : [INFO]  ################ Batch 25: final global model evalution after 6 rounds ################
2023-03-25 20:45:54,203 : [INFO]  Batch 25: Training set : loss - 0.5405, accuracy - 0.7717, recall - 0.913, AUC - 0.8892, F1 - 0.8, precision - 0.7119, training time - -9.0 seconds
2023-03-25 20:45:54,203 : [INFO]  Batch 25: Testing set : loss - 0.5705, accuracy - 0.7402, recall - 0.9314, AUC - 0.8744, F1 - 0.7819, precision - 0.6738
2023-03-25 20:45:54,220 : [INFO]  Batch 26 initialized 
2023-03-25 20:45:54,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:54,931 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 20:45:57,749 : [INFO]  ------------------------- Batch round 1, loss: 0.5972 -------------------------
2023-03-25 20:45:57,749 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:57,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:57,754 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 20:45:58,906 : [INFO]  ------------------------- Batch round 2, loss: 0.5814 -------------------------
2023-03-25 20:45:58,906 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:58,910 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:58,912 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 20:46:00,045 : [INFO]  ------------------------- Batch round 3, loss: 0.5845 -------------------------
2023-03-25 20:46:00,045 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:00,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:00,050 : [INFO]  ------------------------- Batch 26 training: round 4 -------------------------
2023-03-25 20:46:01,173 : [INFO]  ------------------------- Batch round 4, loss: 0.5821 -------------------------
2023-03-25 20:46:01,173 : [INFO]  ------------------------- Batch 26, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:01,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:01,180 : [INFO]  ------------------------- Batch 26 training: round 5 -------------------------
2023-03-25 20:46:02,313 : [INFO]  ------------------------- Batch round 5, loss: 0.5746 -------------------------
2023-03-25 20:46:02,313 : [INFO]  ------------------------- Batch 26, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:02,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:02,318 : [INFO]  ------------------------- Batch 26 training: round 6 -------------------------
2023-03-25 20:46:03,437 : [INFO]  ------------------------- Batch round 6, loss: 0.5691 -------------------------
2023-03-25 20:46:03,437 : [INFO]  ------------------------- Batch 26, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:03,440 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:03,442 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 20:46:03,442 : [INFO]  ################ Batch 26: final global model evalution after 6 rounds ################
2023-03-25 20:46:04,759 : [INFO]  Batch 26: Training set : loss - 0.5602, accuracy - 0.7391, recall - 0.8804, AUC - 0.8504, F1 - 0.7714, precision - 0.6864, training time - -9.0 seconds
2023-03-25 20:46:04,759 : [INFO]  Batch 26: Testing set : loss - 0.5911, accuracy - 0.6667, recall - 0.8922, AUC - 0.8289, F1 - 0.728, precision - 0.6149
2023-03-25 20:46:04,768 : [INFO]  Batch 27 initialized 
2023-03-25 20:46:05,184 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:05,484 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 20:46:08,288 : [INFO]  ------------------------- Batch round 1, loss: 0.6246 -------------------------
2023-03-25 20:46:08,288 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:08,292 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:08,294 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 20:46:09,407 : [INFO]  ------------------------- Batch round 2, loss: 0.6132 -------------------------
2023-03-25 20:46:09,407 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:09,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:09,412 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 20:46:10,507 : [INFO]  ------------------------- Batch round 3, loss: 0.6159 -------------------------
2023-03-25 20:46:10,507 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:10,510 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:10,512 : [INFO]  ------------------------- Batch 27 training: round 4 -------------------------
2023-03-25 20:46:11,604 : [INFO]  ------------------------- Batch round 4, loss: 0.606 -------------------------
2023-03-25 20:46:11,604 : [INFO]  ------------------------- Batch 27, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:11,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:11,609 : [INFO]  ------------------------- Batch 27 training: round 5 -------------------------
2023-03-25 20:46:12,691 : [INFO]  ------------------------- Batch round 5, loss: 0.6011 -------------------------
2023-03-25 20:46:12,691 : [INFO]  ------------------------- Batch 27, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:12,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:12,712 : [INFO]  ------------------------- Batch 27 training: round 6 -------------------------
2023-03-25 20:46:13,816 : [INFO]  ------------------------- Batch round 6, loss: 0.597 -------------------------
2023-03-25 20:46:13,817 : [INFO]  ------------------------- Batch 27, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:13,820 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:13,821 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 20:46:13,821 : [INFO]  ################ Batch 27: final global model evalution after 6 rounds ################
2023-03-25 20:46:15,156 : [INFO]  Batch 27: Training set : loss - 0.6041, accuracy - 0.6739, recall - 0.9022, AUC - 0.7912, F1 - 0.7345, precision - 0.6194, training time - -8.0 seconds
2023-03-25 20:46:15,156 : [INFO]  Batch 27: Testing set : loss - 0.6053, accuracy - 0.6422, recall - 0.8824, AUC - 0.8127, F1 - 0.7115, precision - 0.596
2023-03-25 20:46:15,162 : [INFO]  Batch 28 initialized 
2023-03-25 20:46:15,581 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:15,887 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 20:46:18,716 : [INFO]  ------------------------- Batch round 1, loss: 0.5844 -------------------------
2023-03-25 20:46:18,716 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:18,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:18,759 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 20:46:19,888 : [INFO]  ------------------------- Batch round 2, loss: 0.5839 -------------------------
2023-03-25 20:46:19,888 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:19,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:19,893 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 20:46:21,008 : [INFO]  ------------------------- Batch round 3, loss: 0.5637 -------------------------
2023-03-25 20:46:21,008 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:21,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:21,018 : [INFO]  ------------------------- Batch 28 training: round 4 -------------------------
2023-03-25 20:46:22,142 : [INFO]  ------------------------- Batch round 4, loss: 0.5566 -------------------------
2023-03-25 20:46:22,142 : [INFO]  ------------------------- Batch 28, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:22,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:22,146 : [INFO]  ------------------------- Batch 28 training: round 5 -------------------------
2023-03-25 20:46:23,276 : [INFO]  ------------------------- Batch round 5, loss: 0.5514 -------------------------
2023-03-25 20:46:23,276 : [INFO]  ------------------------- Batch 28, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:23,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:23,285 : [INFO]  ------------------------- Batch 28 training: round 6 -------------------------
2023-03-25 20:46:24,403 : [INFO]  ------------------------- Batch round 6, loss: 0.5622 -------------------------
2023-03-25 20:46:24,403 : [INFO]  ------------------------- Batch 28, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:24,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:24,424 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 20:46:24,424 : [INFO]  ################ Batch 28: final global model evalution after 6 rounds ################
2023-03-25 20:46:25,754 : [INFO]  Batch 28: Training set : loss - 0.5428, accuracy - 0.7935, recall - 0.837, AUC - 0.864, F1 - 0.8021, precision - 0.77, training time - -9.0 seconds
2023-03-25 20:46:25,754 : [INFO]  Batch 28: Testing set : loss - 0.5787, accuracy - 0.6912, recall - 0.8039, AUC - 0.828, F1 - 0.7225, precision - 0.656
2023-03-25 20:46:25,760 : [INFO]  Batch 29 initialized 
2023-03-25 20:46:26,184 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:26,502 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 20:46:29,279 : [INFO]  ------------------------- Batch round 1, loss: 0.5631 -------------------------
2023-03-25 20:46:29,279 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:29,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:29,376 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 20:46:30,411 : [INFO]  ------------------------- Batch round 2, loss: 0.5472 -------------------------
2023-03-25 20:46:30,411 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:30,531 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:30,534 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 20:46:31,590 : [INFO]  ------------------------- Batch round 3, loss: 0.537 -------------------------
2023-03-25 20:46:31,590 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:31,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:31,688 : [INFO]  ------------------------- Batch 29 training: round 4 -------------------------
2023-03-25 20:46:32,739 : [INFO]  ------------------------- Batch round 4, loss: 0.5403 -------------------------
2023-03-25 20:46:32,739 : [INFO]  ------------------------- Batch 29, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:32,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:32,806 : [INFO]  ------------------------- Batch 29 training: round 5 -------------------------
2023-03-25 20:46:33,858 : [INFO]  ------------------------- Batch round 5, loss: 0.5293 -------------------------
2023-03-25 20:46:33,858 : [INFO]  ------------------------- Batch 29, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:33,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:33,966 : [INFO]  ------------------------- Batch 29 training: round 6 -------------------------
2023-03-25 20:46:35,006 : [INFO]  ------------------------- Batch round 6, loss: 0.5215 -------------------------
2023-03-25 20:46:35,006 : [INFO]  ------------------------- Batch 29, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:35,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:35,110 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 20:46:35,110 : [INFO]  ################ Batch 29: final global model evalution after 6 rounds ################
2023-03-25 20:46:36,352 : [INFO]  Batch 29: Training set : loss - 0.5241, accuracy - 0.8098, recall - 0.9674, AUC - 0.9139, F1 - 0.8357, precision - 0.7355, training time - -9.0 seconds
2023-03-25 20:46:36,352 : [INFO]  Batch 29: Testing set : loss - 0.5703, accuracy - 0.7353, recall - 0.8725, AUC - 0.8582, F1 - 0.7672, precision - 0.6846
2023-03-25 20:46:36,363 : [INFO]  Batch 30 initialized 
2023-03-25 20:46:36,784 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:37,074 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 20:46:39,925 : [INFO]  ------------------------- Batch round 1, loss: 0.5871 -------------------------
2023-03-25 20:46:39,925 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:39,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:39,942 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 20:46:41,023 : [INFO]  ------------------------- Batch round 2, loss: 0.5712 -------------------------
2023-03-25 20:46:41,023 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:41,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:41,040 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 20:46:42,141 : [INFO]  ------------------------- Batch round 3, loss: 0.5674 -------------------------
2023-03-25 20:46:42,141 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:42,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:42,146 : [INFO]  ------------------------- Batch 30 training: round 4 -------------------------
2023-03-25 20:46:43,260 : [INFO]  ------------------------- Batch round 4, loss: 0.5708 -------------------------
2023-03-25 20:46:43,261 : [INFO]  ------------------------- Batch 30, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:43,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:43,268 : [INFO]  ------------------------- Batch 30 training: round 5 -------------------------
2023-03-25 20:46:44,352 : [INFO]  ------------------------- Batch round 5, loss: 0.5608 -------------------------
2023-03-25 20:46:44,352 : [INFO]  ------------------------- Batch 30, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:44,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:44,368 : [INFO]  ------------------------- Batch 30 training: round 6 -------------------------
2023-03-25 20:46:45,480 : [INFO]  ------------------------- Batch round 6, loss: 0.5641 -------------------------
2023-03-25 20:46:45,480 : [INFO]  ------------------------- Batch 30, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:45,483 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:45,485 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 20:46:45,485 : [INFO]  ################ Batch 30: final global model evalution after 6 rounds ################
2023-03-25 20:46:46,772 : [INFO]  Batch 30: Training set : loss - 0.5588, accuracy - 0.7772, recall - 0.8913, AUC - 0.8963, F1 - 0.8, precision - 0.7257, training time - -8.0 seconds
2023-03-25 20:46:46,772 : [INFO]  Batch 30: Testing set : loss - 0.5409, accuracy - 0.7598, recall - 0.9314, AUC - 0.9223, F1 - 0.795, precision - 0.6934
2023-03-25 20:46:46,784 : [INFO]  Batch 31 initialized 
2023-03-25 20:46:47,194 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:47,503 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 20:46:50,338 : [INFO]  ------------------------- Batch round 1, loss: 0.6122 -------------------------
2023-03-25 20:46:50,338 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:50,341 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:50,343 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 20:46:51,476 : [INFO]  ------------------------- Batch round 2, loss: 0.6086 -------------------------
2023-03-25 20:46:51,476 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:51,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:51,481 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 20:46:52,621 : [INFO]  ------------------------- Batch round 3, loss: 0.582 -------------------------
2023-03-25 20:46:52,621 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:52,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:52,626 : [INFO]  ------------------------- Batch 31 training: round 4 -------------------------
2023-03-25 20:46:53,768 : [INFO]  ------------------------- Batch round 4, loss: 0.5809 -------------------------
2023-03-25 20:46:53,768 : [INFO]  ------------------------- Batch 31, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:53,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:53,774 : [INFO]  ------------------------- Batch 31 training: round 5 -------------------------
2023-03-25 20:46:54,918 : [INFO]  ------------------------- Batch round 5, loss: 0.5855 -------------------------
2023-03-25 20:46:54,918 : [INFO]  ------------------------- Batch 31, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:54,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:54,923 : [INFO]  ------------------------- Batch 31 training: round 6 -------------------------
2023-03-25 20:46:56,059 : [INFO]  ------------------------- Batch round 6, loss: 0.5773 -------------------------
2023-03-25 20:46:56,059 : [INFO]  ------------------------- Batch 31, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:56,062 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:56,064 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 20:46:56,064 : [INFO]  ################ Batch 31: final global model evalution after 6 rounds ################
2023-03-25 20:46:57,392 : [INFO]  Batch 31: Training set : loss - 0.5717, accuracy - 0.7391, recall - 0.8478, AUC - 0.8281, F1 - 0.7647, precision - 0.6964, training time - -9.0 seconds
2023-03-25 20:46:57,393 : [INFO]  Batch 31: Testing set : loss - 0.5813, accuracy - 0.7206, recall - 0.8529, AUC - 0.8556, F1 - 0.7532, precision - 0.6744
2023-03-25 20:46:57,399 : [INFO]  Batch 32 initialized 
2023-03-25 20:46:57,811 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:58,138 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 20:47:01,005 : [INFO]  ------------------------- Batch round 1, loss: 0.6066 -------------------------
2023-03-25 20:47:01,005 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:01,008 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:01,010 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 20:47:02,133 : [INFO]  ------------------------- Batch round 2, loss: 0.5905 -------------------------
2023-03-25 20:47:02,133 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:02,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:02,138 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 20:47:03,285 : [INFO]  ------------------------- Batch round 3, loss: 0.5811 -------------------------
2023-03-25 20:47:03,285 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:03,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:03,290 : [INFO]  ------------------------- Batch 32 training: round 4 -------------------------
2023-03-25 20:47:04,435 : [INFO]  ------------------------- Batch round 4, loss: 0.584 -------------------------
2023-03-25 20:47:04,435 : [INFO]  ------------------------- Batch 32, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:04,438 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:04,439 : [INFO]  ------------------------- Batch 32 training: round 5 -------------------------
2023-03-25 20:47:05,549 : [INFO]  ------------------------- Batch round 5, loss: 0.5735 -------------------------
2023-03-25 20:47:05,549 : [INFO]  ------------------------- Batch 32, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:05,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:05,555 : [INFO]  ------------------------- Batch 32 training: round 6 -------------------------
2023-03-25 20:47:06,699 : [INFO]  ------------------------- Batch round 6, loss: 0.57 -------------------------
2023-03-25 20:47:06,699 : [INFO]  ------------------------- Batch 32, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:06,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:06,704 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 20:47:06,704 : [INFO]  ################ Batch 32: final global model evalution after 6 rounds ################
2023-03-25 20:47:08,031 : [INFO]  Batch 32: Training set : loss - 0.5704, accuracy - 0.7228, recall - 0.8804, AUC - 0.8376, F1 - 0.7606, precision - 0.6694, training time - -9.0 seconds
2023-03-25 20:47:08,031 : [INFO]  Batch 32: Testing set : loss - 0.5618, accuracy - 0.7206, recall - 0.8529, AUC - 0.8502, F1 - 0.7532, precision - 0.6744
2023-03-25 20:47:08,039 : [INFO]  Batch 33 initialized 
2023-03-25 20:47:08,468 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:08,771 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 20:47:11,671 : [INFO]  ------------------------- Batch round 1, loss: 0.595 -------------------------
2023-03-25 20:47:11,671 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:11,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:11,676 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 20:47:12,749 : [INFO]  ------------------------- Batch round 2, loss: 0.5923 -------------------------
2023-03-25 20:47:12,749 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:12,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:12,754 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 20:47:13,873 : [INFO]  ------------------------- Batch round 3, loss: 0.6012 -------------------------
2023-03-25 20:47:13,873 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:13,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:13,878 : [INFO]  ------------------------- Batch 33 training: round 4 -------------------------
2023-03-25 20:47:14,965 : [INFO]  ------------------------- Batch round 4, loss: 0.593 -------------------------
2023-03-25 20:47:14,965 : [INFO]  ------------------------- Batch 33, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:14,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:14,971 : [INFO]  ------------------------- Batch 33 training: round 5 -------------------------
2023-03-25 20:47:16,076 : [INFO]  ------------------------- Batch round 5, loss: 0.5909 -------------------------
2023-03-25 20:47:16,076 : [INFO]  ------------------------- Batch 33, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:16,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:16,081 : [INFO]  ------------------------- Batch 33 training: round 6 -------------------------
2023-03-25 20:47:17,159 : [INFO]  ------------------------- Batch round 6, loss: 0.5835 -------------------------
2023-03-25 20:47:17,159 : [INFO]  ------------------------- Batch 33, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:17,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:17,164 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 20:47:17,164 : [INFO]  ################ Batch 33: final global model evalution after 6 rounds ################
2023-03-25 20:47:18,476 : [INFO]  Batch 33: Training set : loss - 0.5946, accuracy - 0.7011, recall - 0.8913, AUC - 0.7538, F1 - 0.7489, precision - 0.6457, training time - -8.0 seconds
2023-03-25 20:47:18,476 : [INFO]  Batch 33: Testing set : loss - 0.5974, accuracy - 0.6618, recall - 0.8627, AUC - 0.7852, F1 - 0.7184, precision - 0.6154
2023-03-25 20:47:18,485 : [INFO]  Batch 34 initialized 
2023-03-25 20:47:18,904 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:19,227 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 20:47:22,071 : [INFO]  ------------------------- Batch round 1, loss: 0.5832 -------------------------
2023-03-25 20:47:22,071 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:22,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:22,076 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 20:47:23,129 : [INFO]  ------------------------- Batch round 2, loss: 0.5735 -------------------------
2023-03-25 20:47:23,130 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:23,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:23,169 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 20:47:24,259 : [INFO]  ------------------------- Batch round 3, loss: 0.5741 -------------------------
2023-03-25 20:47:24,260 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:24,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:24,288 : [INFO]  ------------------------- Batch 34 training: round 4 -------------------------
2023-03-25 20:47:25,364 : [INFO]  ------------------------- Batch round 4, loss: 0.5729 -------------------------
2023-03-25 20:47:25,364 : [INFO]  ------------------------- Batch 34, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:25,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:25,385 : [INFO]  ------------------------- Batch 34 training: round 5 -------------------------
2023-03-25 20:47:26,452 : [INFO]  ------------------------- Batch round 5, loss: 0.5597 -------------------------
2023-03-25 20:47:26,452 : [INFO]  ------------------------- Batch 34, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:26,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:26,493 : [INFO]  ------------------------- Batch 34 training: round 6 -------------------------
2023-03-25 20:47:27,580 : [INFO]  ------------------------- Batch round 6, loss: 0.5591 -------------------------
2023-03-25 20:47:27,581 : [INFO]  ------------------------- Batch 34, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:27,592 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:27,594 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 20:47:27,594 : [INFO]  ################ Batch 34: final global model evalution after 6 rounds ################
2023-03-25 20:47:28,855 : [INFO]  Batch 34: Training set : loss - 0.5645, accuracy - 0.7446, recall - 0.8913, AUC - 0.8762, F1 - 0.7773, precision - 0.6891, training time - -8.0 seconds
2023-03-25 20:47:28,855 : [INFO]  Batch 34: Testing set : loss - 0.5272, accuracy - 0.7843, recall - 0.9412, AUC - 0.9258, F1 - 0.8136, precision - 0.7164
2023-03-25 20:47:28,869 : [INFO]  Batch 35 initialized 
2023-03-25 20:47:29,287 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:29,607 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 20:47:32,455 : [INFO]  ------------------------- Batch round 1, loss: 0.5661 -------------------------
2023-03-25 20:47:32,456 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:32,775 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:32,781 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 20:47:33,844 : [INFO]  ------------------------- Batch round 2, loss: 0.5538 -------------------------
2023-03-25 20:47:33,844 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:33,847 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:33,850 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 20:47:34,960 : [INFO]  ------------------------- Batch round 3, loss: 0.5565 -------------------------
2023-03-25 20:47:34,960 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:34,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:34,965 : [INFO]  ------------------------- Batch 35 training: round 4 -------------------------
2023-03-25 20:47:36,065 : [INFO]  ------------------------- Batch round 4, loss: 0.5512 -------------------------
2023-03-25 20:47:36,066 : [INFO]  ------------------------- Batch 35, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:36,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:36,082 : [INFO]  ------------------------- Batch 35 training: round 5 -------------------------
2023-03-25 20:47:37,171 : [INFO]  ------------------------- Batch round 5, loss: 0.5416 -------------------------
2023-03-25 20:47:37,171 : [INFO]  ------------------------- Batch 35, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:37,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:37,177 : [INFO]  ------------------------- Batch 35 training: round 6 -------------------------
2023-03-25 20:47:38,277 : [INFO]  ------------------------- Batch round 6, loss: 0.5504 -------------------------
2023-03-25 20:47:38,277 : [INFO]  ------------------------- Batch 35, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:38,280 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:38,282 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 20:47:38,282 : [INFO]  ################ Batch 35: final global model evalution after 6 rounds ################
2023-03-25 20:47:39,732 : [INFO]  Batch 35: Training set : loss - 0.5385, accuracy - 0.7772, recall - 0.9022, AUC - 0.8884, F1 - 0.8019, precision - 0.7217, training time - -9.0 seconds
2023-03-25 20:47:39,732 : [INFO]  Batch 35: Testing set : loss - 0.5799, accuracy - 0.6765, recall - 0.8039, AUC - 0.8195, F1 - 0.713, precision - 0.6406
2023-03-25 20:47:39,739 : [INFO]  Batch 36 initialized 
2023-03-25 20:47:40,157 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:40,480 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 20:47:43,363 : [INFO]  ------------------------- Batch round 1, loss: 0.5631 -------------------------
2023-03-25 20:47:43,363 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:43,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:43,369 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 20:47:44,488 : [INFO]  ------------------------- Batch round 2, loss: 0.555 -------------------------
2023-03-25 20:47:44,488 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:44,494 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:44,496 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 20:47:45,597 : [INFO]  ------------------------- Batch round 3, loss: 0.5584 -------------------------
2023-03-25 20:47:45,597 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:45,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:45,602 : [INFO]  ------------------------- Batch 36 training: round 4 -------------------------
2023-03-25 20:47:46,711 : [INFO]  ------------------------- Batch round 4, loss: 0.5426 -------------------------
2023-03-25 20:47:46,711 : [INFO]  ------------------------- Batch 36, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:46,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:46,716 : [INFO]  ------------------------- Batch 36 training: round 5 -------------------------
2023-03-25 20:47:47,786 : [INFO]  ------------------------- Batch round 5, loss: 0.5368 -------------------------
2023-03-25 20:47:47,787 : [INFO]  ------------------------- Batch 36, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:47,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:47,792 : [INFO]  ------------------------- Batch 36 training: round 6 -------------------------
2023-03-25 20:47:48,899 : [INFO]  ------------------------- Batch round 6, loss: 0.5486 -------------------------
2023-03-25 20:47:48,899 : [INFO]  ------------------------- Batch 36, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:48,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:48,904 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 20:47:48,904 : [INFO]  ################ Batch 36: final global model evalution after 6 rounds ################
2023-03-25 20:47:50,216 : [INFO]  Batch 36: Training set : loss - 0.5408, accuracy - 0.7826, recall - 0.913, AUC - 0.8871, F1 - 0.8077, precision - 0.7241, training time - -8.0 seconds
2023-03-25 20:47:50,216 : [INFO]  Batch 36: Testing set : loss - 0.5603, accuracy - 0.7451, recall - 0.8824, AUC - 0.8627, F1 - 0.7759, precision - 0.6923
2023-03-25 20:47:50,225 : [INFO]  Batch 37 initialized 
2023-03-25 20:47:50,647 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:50,976 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 20:47:53,862 : [INFO]  ------------------------- Batch round 1, loss: 0.5837 -------------------------
2023-03-25 20:47:53,862 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:53,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:53,868 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 20:47:54,957 : [INFO]  ------------------------- Batch round 2, loss: 0.5705 -------------------------
2023-03-25 20:47:54,957 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:54,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:54,979 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 20:47:56,093 : [INFO]  ------------------------- Batch round 3, loss: 0.5602 -------------------------
2023-03-25 20:47:56,093 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:56,096 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:56,098 : [INFO]  ------------------------- Batch 37 training: round 4 -------------------------
2023-03-25 20:47:57,159 : [INFO]  ------------------------- Batch round 4, loss: 0.5601 -------------------------
2023-03-25 20:47:57,160 : [INFO]  ------------------------- Batch 37, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:57,172 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:57,173 : [INFO]  ------------------------- Batch 37 training: round 5 -------------------------
2023-03-25 20:47:58,268 : [INFO]  ------------------------- Batch round 5, loss: 0.5571 -------------------------
2023-03-25 20:47:58,268 : [INFO]  ------------------------- Batch 37, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:58,282 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:58,283 : [INFO]  ------------------------- Batch 37 training: round 6 -------------------------
2023-03-25 20:47:59,386 : [INFO]  ------------------------- Batch round 6, loss: 0.5495 -------------------------
2023-03-25 20:47:59,386 : [INFO]  ------------------------- Batch 37, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:59,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:59,396 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 20:47:59,396 : [INFO]  ################ Batch 37: final global model evalution after 6 rounds ################
2023-03-25 20:48:00,683 : [INFO]  Batch 37: Training set : loss - 0.548, accuracy - 0.7391, recall - 0.9022, AUC - 0.888, F1 - 0.7757, precision - 0.6803, training time - -8.0 seconds
2023-03-25 20:48:00,683 : [INFO]  Batch 37: Testing set : loss - 0.5827, accuracy - 0.6863, recall - 0.8725, AUC - 0.8547, F1 - 0.7355, precision - 0.6357
2023-03-25 20:48:00,697 : [INFO]  Batch 38 initialized 
2023-03-25 20:48:01,129 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:01,460 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 20:48:04,300 : [INFO]  ------------------------- Batch round 1, loss: 0.5971 -------------------------
2023-03-25 20:48:04,300 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:04,305 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:04,308 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 20:48:05,426 : [INFO]  ------------------------- Batch round 2, loss: 0.5993 -------------------------
2023-03-25 20:48:05,426 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:05,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:05,432 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 20:48:06,572 : [INFO]  ------------------------- Batch round 3, loss: 0.5886 -------------------------
2023-03-25 20:48:06,572 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:06,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:06,579 : [INFO]  ------------------------- Batch 38 training: round 4 -------------------------
2023-03-25 20:48:07,683 : [INFO]  ------------------------- Batch round 4, loss: 0.5873 -------------------------
2023-03-25 20:48:07,684 : [INFO]  ------------------------- Batch 38, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:07,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:07,689 : [INFO]  ------------------------- Batch 38 training: round 5 -------------------------
2023-03-25 20:48:08,857 : [INFO]  ------------------------- Batch round 5, loss: 0.5805 -------------------------
2023-03-25 20:48:08,857 : [INFO]  ------------------------- Batch 38, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:08,860 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:08,862 : [INFO]  ------------------------- Batch 38 training: round 6 -------------------------
2023-03-25 20:48:10,002 : [INFO]  ------------------------- Batch round 6, loss: 0.5771 -------------------------
2023-03-25 20:48:10,003 : [INFO]  ------------------------- Batch 38, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:10,006 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:10,008 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 20:48:10,008 : [INFO]  ################ Batch 38: final global model evalution after 6 rounds ################
2023-03-25 20:48:11,342 : [INFO]  Batch 38: Training set : loss - 0.5662, accuracy - 0.7772, recall - 0.9348, AUC - 0.854, F1 - 0.8075, precision - 0.7107, training time - -9.0 seconds
2023-03-25 20:48:11,342 : [INFO]  Batch 38: Testing set : loss - 0.5596, accuracy - 0.7304, recall - 0.8824, AUC - 0.8517, F1 - 0.766, precision - 0.6767
2023-03-25 20:48:11,348 : [INFO]  Batch 39 initialized 
2023-03-25 20:48:11,771 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:12,106 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 20:48:14,867 : [INFO]  ------------------------- Batch round 1, loss: 0.5468 -------------------------
2023-03-25 20:48:14,868 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:14,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:14,873 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 20:48:15,932 : [INFO]  ------------------------- Batch round 2, loss: 0.5442 -------------------------
2023-03-25 20:48:15,933 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:15,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:15,942 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 20:48:17,011 : [INFO]  ------------------------- Batch round 3, loss: 0.5392 -------------------------
2023-03-25 20:48:17,011 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:17,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:17,016 : [INFO]  ------------------------- Batch 39 training: round 4 -------------------------
2023-03-25 20:48:18,116 : [INFO]  ------------------------- Batch round 4, loss: 0.5315 -------------------------
2023-03-25 20:48:18,116 : [INFO]  ------------------------- Batch 39, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:18,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:18,121 : [INFO]  ------------------------- Batch 39 training: round 5 -------------------------
2023-03-25 20:48:19,211 : [INFO]  ------------------------- Batch round 5, loss: 0.5317 -------------------------
2023-03-25 20:48:19,211 : [INFO]  ------------------------- Batch 39, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:19,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:19,216 : [INFO]  ------------------------- Batch 39 training: round 6 -------------------------
2023-03-25 20:48:20,248 : [INFO]  ------------------------- Batch round 6, loss: 0.527 -------------------------
2023-03-25 20:48:20,248 : [INFO]  ------------------------- Batch 39, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:20,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:20,253 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 20:48:20,253 : [INFO]  ################ Batch 39: final global model evalution after 6 rounds ################
2023-03-25 20:48:21,548 : [INFO]  Batch 39: Training set : loss - 0.5231, accuracy - 0.8424, recall - 0.9674, AUC - 0.8856, F1 - 0.8599, precision - 0.7739, training time - -8.0 seconds
2023-03-25 20:48:21,548 : [INFO]  Batch 39: Testing set : loss - 0.5407, accuracy - 0.7696, recall - 0.951, AUC - 0.9105, F1 - 0.805, precision - 0.6978
2023-03-25 20:48:21,558 : [INFO]  Batch 40 initialized 
2023-03-25 20:48:21,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:22,320 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 20:48:25,316 : [INFO]  ------------------------- Batch round 1, loss: 0.5835 -------------------------
2023-03-25 20:48:25,316 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:25,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:25,321 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 20:48:26,492 : [INFO]  ------------------------- Batch round 2, loss: 0.5855 -------------------------
2023-03-25 20:48:26,492 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:26,495 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:26,498 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 20:48:27,646 : [INFO]  ------------------------- Batch round 3, loss: 0.5647 -------------------------
2023-03-25 20:48:27,646 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:27,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:27,651 : [INFO]  ------------------------- Batch 40 training: round 4 -------------------------
2023-03-25 20:48:28,791 : [INFO]  ------------------------- Batch round 4, loss: 0.563 -------------------------
2023-03-25 20:48:28,791 : [INFO]  ------------------------- Batch 40, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:28,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:28,796 : [INFO]  ------------------------- Batch 40 training: round 5 -------------------------
2023-03-25 20:48:29,981 : [INFO]  ------------------------- Batch round 5, loss: 0.5697 -------------------------
2023-03-25 20:48:29,981 : [INFO]  ------------------------- Batch 40, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:29,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:29,987 : [INFO]  ------------------------- Batch 40 training: round 6 -------------------------
2023-03-25 20:48:31,095 : [INFO]  ------------------------- Batch round 6, loss: 0.5681 -------------------------
2023-03-25 20:48:31,096 : [INFO]  ------------------------- Batch 40, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:31,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:31,100 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 20:48:31,101 : [INFO]  ################ Batch 40: final global model evalution after 6 rounds ################
2023-03-25 20:48:32,443 : [INFO]  Batch 40: Training set : loss - 0.5618, accuracy - 0.75, recall - 0.9457, AUC - 0.8774, F1 - 0.7909, precision - 0.6797, training time - -9.0 seconds
2023-03-25 20:48:32,444 : [INFO]  Batch 40: Testing set : loss - 0.5928, accuracy - 0.701, recall - 0.9216, AUC - 0.8507, F1 - 0.755, precision - 0.6395
2023-03-25 20:48:32,449 : [INFO]  Batch 41 initialized 
2023-03-25 20:48:32,875 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:33,220 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 20:48:36,020 : [INFO]  ------------------------- Batch round 1, loss: 0.5602 -------------------------
2023-03-25 20:48:36,020 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:36,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:36,025 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 20:48:37,114 : [INFO]  ------------------------- Batch round 2, loss: 0.5589 -------------------------
2023-03-25 20:48:37,114 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:37,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:37,119 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 20:48:38,209 : [INFO]  ------------------------- Batch round 3, loss: 0.5517 -------------------------
2023-03-25 20:48:38,209 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:38,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:38,247 : [INFO]  ------------------------- Batch 41 training: round 4 -------------------------
2023-03-25 20:48:39,686 : [INFO]  ------------------------- Batch round 4, loss: 0.5582 -------------------------
2023-03-25 20:48:39,687 : [INFO]  ------------------------- Batch 41, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:39,700 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:39,707 : [INFO]  ------------------------- Batch 41 training: round 5 -------------------------
2023-03-25 20:48:40,714 : [INFO]  ------------------------- Batch round 5, loss: 0.548 -------------------------
2023-03-25 20:48:40,714 : [INFO]  ------------------------- Batch 41, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:40,718 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:40,719 : [INFO]  ------------------------- Batch 41 training: round 6 -------------------------
2023-03-25 20:48:41,807 : [INFO]  ------------------------- Batch round 6, loss: 0.5477 -------------------------
2023-03-25 20:48:41,807 : [INFO]  ------------------------- Batch 41, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:41,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:41,842 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 20:48:41,842 : [INFO]  ################ Batch 41: final global model evalution after 6 rounds ################
2023-03-25 20:48:43,203 : [INFO]  Batch 41: Training set : loss - 0.5424, accuracy - 0.7446, recall - 0.9565, AUC - 0.906, F1 - 0.7892, precision - 0.6718, training time - -9.0 seconds
2023-03-25 20:48:43,203 : [INFO]  Batch 41: Testing set : loss - 0.5687, accuracy - 0.6863, recall - 0.951, AUC - 0.8926, F1 - 0.7519, precision - 0.6218
2023-03-25 20:48:43,209 : [INFO]  Batch 42 initialized 
2023-03-25 20:48:43,634 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:43,981 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 20:48:46,796 : [INFO]  ------------------------- Batch round 1, loss: 0.6053 -------------------------
2023-03-25 20:48:46,796 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:46,800 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:46,803 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 20:48:47,929 : [INFO]  ------------------------- Batch round 2, loss: 0.5939 -------------------------
2023-03-25 20:48:47,930 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:47,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:47,936 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 20:48:49,060 : [INFO]  ------------------------- Batch round 3, loss: 0.6002 -------------------------
2023-03-25 20:48:49,060 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:49,063 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:49,065 : [INFO]  ------------------------- Batch 42 training: round 4 -------------------------
2023-03-25 20:48:50,187 : [INFO]  ------------------------- Batch round 4, loss: 0.5993 -------------------------
2023-03-25 20:48:50,187 : [INFO]  ------------------------- Batch 42, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:50,190 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:50,192 : [INFO]  ------------------------- Batch 42 training: round 5 -------------------------
2023-03-25 20:48:51,255 : [INFO]  ------------------------- Batch round 5, loss: 0.5945 -------------------------
2023-03-25 20:48:51,256 : [INFO]  ------------------------- Batch 42, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:51,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:51,260 : [INFO]  ------------------------- Batch 42 training: round 6 -------------------------
2023-03-25 20:48:52,349 : [INFO]  ------------------------- Batch round 6, loss: 0.5917 -------------------------
2023-03-25 20:48:52,349 : [INFO]  ------------------------- Batch 42, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:52,352 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:52,354 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 20:48:52,354 : [INFO]  ################ Batch 42: final global model evalution after 6 rounds ################
2023-03-25 20:48:53,668 : [INFO]  Batch 42: Training set : loss - 0.5872, accuracy - 0.7174, recall - 0.9022, AUC - 0.8276, F1 - 0.7615, precision - 0.6587, training time - -8.0 seconds
2023-03-25 20:48:53,668 : [INFO]  Batch 42: Testing set : loss - 0.5859, accuracy - 0.652, recall - 0.8725, AUC - 0.8467, F1 - 0.7149, precision - 0.6054
2023-03-25 20:48:53,674 : [INFO]  Batch 43 initialized 
2023-03-25 20:48:54,105 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:54,445 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 20:48:57,259 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-25 20:48:57,259 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:57,262 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:57,264 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 20:48:58,374 : [INFO]  ------------------------- Batch round 2, loss: 0.5597 -------------------------
2023-03-25 20:48:58,374 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:58,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:58,380 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 20:48:59,496 : [INFO]  ------------------------- Batch round 3, loss: 0.5436 -------------------------
2023-03-25 20:48:59,496 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:59,500 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:59,503 : [INFO]  ------------------------- Batch 43 training: round 4 -------------------------
2023-03-25 20:49:00,621 : [INFO]  ------------------------- Batch round 4, loss: 0.5489 -------------------------
2023-03-25 20:49:00,621 : [INFO]  ------------------------- Batch 43, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:00,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:00,627 : [INFO]  ------------------------- Batch 43 training: round 5 -------------------------
2023-03-25 20:49:01,741 : [INFO]  ------------------------- Batch round 5, loss: 0.5418 -------------------------
2023-03-25 20:49:01,741 : [INFO]  ------------------------- Batch 43, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:01,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:01,746 : [INFO]  ------------------------- Batch 43 training: round 6 -------------------------
2023-03-25 20:49:02,814 : [INFO]  ------------------------- Batch round 6, loss: 0.5455 -------------------------
2023-03-25 20:49:02,814 : [INFO]  ------------------------- Batch 43, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:02,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:02,819 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 20:49:02,819 : [INFO]  ################ Batch 43: final global model evalution after 6 rounds ################
2023-03-25 20:49:04,118 : [INFO]  Batch 43: Training set : loss - 0.5367, accuracy - 0.7446, recall - 0.9239, AUC - 0.905, F1 - 0.7834, precision - 0.68, training time - -8.0 seconds
2023-03-25 20:49:04,118 : [INFO]  Batch 43: Testing set : loss - 0.5554, accuracy - 0.7549, recall - 0.9608, AUC - 0.8996, F1 - 0.7967, precision - 0.6806
2023-03-25 20:49:04,128 : [INFO]  Batch 44 initialized 
2023-03-25 20:49:04,553 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:04,906 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 20:49:07,720 : [INFO]  ------------------------- Batch round 1, loss: 0.5543 -------------------------
2023-03-25 20:49:07,720 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:07,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:07,726 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 20:49:08,833 : [INFO]  ------------------------- Batch round 2, loss: 0.5416 -------------------------
2023-03-25 20:49:08,833 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:08,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:08,838 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 20:49:09,972 : [INFO]  ------------------------- Batch round 3, loss: 0.5452 -------------------------
2023-03-25 20:49:09,972 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:09,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:09,976 : [INFO]  ------------------------- Batch 44 training: round 4 -------------------------
2023-03-25 20:49:11,078 : [INFO]  ------------------------- Batch round 4, loss: 0.534 -------------------------
2023-03-25 20:49:11,078 : [INFO]  ------------------------- Batch 44, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:11,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:11,083 : [INFO]  ------------------------- Batch 44 training: round 5 -------------------------
2023-03-25 20:49:12,175 : [INFO]  ------------------------- Batch round 5, loss: 0.5234 -------------------------
2023-03-25 20:49:12,176 : [INFO]  ------------------------- Batch 44, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:12,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:12,182 : [INFO]  ------------------------- Batch 44 training: round 6 -------------------------
2023-03-25 20:49:13,284 : [INFO]  ------------------------- Batch round 6, loss: 0.5352 -------------------------
2023-03-25 20:49:13,284 : [INFO]  ------------------------- Batch 44, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:13,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:13,290 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 20:49:13,290 : [INFO]  ################ Batch 44: final global model evalution after 6 rounds ################
2023-03-25 20:49:14,625 : [INFO]  Batch 44: Training set : loss - 0.5193, accuracy - 0.8315, recall - 0.9565, AUC - 0.9227, F1 - 0.8502, precision - 0.7652, training time - -8.0 seconds
2023-03-25 20:49:14,625 : [INFO]  Batch 44: Testing set : loss - 0.5404, accuracy - 0.7745, recall - 0.902, AUC - 0.8917, F1 - 0.8, precision - 0.7188
2023-03-25 20:49:14,632 : [INFO]  Batch 45 initialized 
2023-03-25 20:49:15,063 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:15,426 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 20:49:18,275 : [INFO]  ------------------------- Batch round 1, loss: 0.5683 -------------------------
2023-03-25 20:49:18,276 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:18,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:18,281 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 20:49:19,398 : [INFO]  ------------------------- Batch round 2, loss: 0.5687 -------------------------
2023-03-25 20:49:19,399 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:19,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:19,404 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 20:49:20,523 : [INFO]  ------------------------- Batch round 3, loss: 0.5662 -------------------------
2023-03-25 20:49:20,523 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:20,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:20,528 : [INFO]  ------------------------- Batch 45 training: round 4 -------------------------
2023-03-25 20:49:21,660 : [INFO]  ------------------------- Batch round 4, loss: 0.5629 -------------------------
2023-03-25 20:49:21,660 : [INFO]  ------------------------- Batch 45, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:21,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:21,666 : [INFO]  ------------------------- Batch 45 training: round 5 -------------------------
2023-03-25 20:49:22,799 : [INFO]  ------------------------- Batch round 5, loss: 0.5631 -------------------------
2023-03-25 20:49:22,799 : [INFO]  ------------------------- Batch 45, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:22,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:22,804 : [INFO]  ------------------------- Batch 45 training: round 6 -------------------------
2023-03-25 20:49:23,965 : [INFO]  ------------------------- Batch round 6, loss: 0.5508 -------------------------
2023-03-25 20:49:23,965 : [INFO]  ------------------------- Batch 45, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:23,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:23,970 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 20:49:23,970 : [INFO]  ################ Batch 45: final global model evalution after 6 rounds ################
2023-03-25 20:49:25,264 : [INFO]  Batch 45: Training set : loss - 0.5541, accuracy - 0.7717, recall - 0.9239, AUC - 0.8882, F1 - 0.8019, precision - 0.7083, training time - -9.0 seconds
2023-03-25 20:49:25,265 : [INFO]  Batch 45: Testing set : loss - 0.5488, accuracy - 0.7696, recall - 0.9216, AUC - 0.9033, F1 - 0.8, precision - 0.7068
2023-03-25 20:49:25,270 : [INFO]  Batch 46 initialized 
2023-03-25 20:49:25,686 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:26,044 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 20:49:28,849 : [INFO]  ------------------------- Batch round 1, loss: 0.5613 -------------------------
2023-03-25 20:49:28,849 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:28,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:28,858 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 20:49:29,947 : [INFO]  ------------------------- Batch round 2, loss: 0.5629 -------------------------
2023-03-25 20:49:29,947 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:29,951 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:29,952 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 20:49:31,019 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 20:49:31,019 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:31,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:31,287 : [INFO]  ------------------------- Batch 46 training: round 4 -------------------------
2023-03-25 20:49:32,325 : [INFO]  ------------------------- Batch round 4, loss: 0.5625 -------------------------
2023-03-25 20:49:32,325 : [INFO]  ------------------------- Batch 46, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:32,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:32,353 : [INFO]  ------------------------- Batch 46 training: round 5 -------------------------
2023-03-25 20:49:33,472 : [INFO]  ------------------------- Batch round 5, loss: 0.5549 -------------------------
2023-03-25 20:49:33,472 : [INFO]  ------------------------- Batch 46, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:33,475 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:33,477 : [INFO]  ------------------------- Batch 46 training: round 6 -------------------------
2023-03-25 20:49:34,558 : [INFO]  ------------------------- Batch round 6, loss: 0.5616 -------------------------
2023-03-25 20:49:34,558 : [INFO]  ------------------------- Batch 46, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:34,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:34,582 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 20:49:34,582 : [INFO]  ################ Batch 46: final global model evalution after 6 rounds ################
2023-03-25 20:49:35,918 : [INFO]  Batch 46: Training set : loss - 0.5545, accuracy - 0.7391, recall - 0.9022, AUC - 0.8871, F1 - 0.7757, precision - 0.6803, training time - -9.0 seconds
2023-03-25 20:49:35,919 : [INFO]  Batch 46: Testing set : loss - 0.5975, accuracy - 0.6667, recall - 0.8725, AUC - 0.8439, F1 - 0.7236, precision - 0.6181
2023-03-25 20:49:35,926 : [INFO]  Batch 47 initialized 
2023-03-25 20:49:36,356 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:36,720 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 20:49:39,501 : [INFO]  ------------------------- Batch round 1, loss: 0.5745 -------------------------
2023-03-25 20:49:39,501 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:39,505 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:39,507 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 20:49:40,602 : [INFO]  ------------------------- Batch round 2, loss: 0.5774 -------------------------
2023-03-25 20:49:40,602 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:40,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:40,625 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 20:49:41,688 : [INFO]  ------------------------- Batch round 3, loss: 0.5603 -------------------------
2023-03-25 20:49:41,688 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:41,718 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:41,720 : [INFO]  ------------------------- Batch 47 training: round 4 -------------------------
2023-03-25 20:49:42,782 : [INFO]  ------------------------- Batch round 4, loss: 0.5552 -------------------------
2023-03-25 20:49:42,782 : [INFO]  ------------------------- Batch 47, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:42,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:42,803 : [INFO]  ------------------------- Batch 47 training: round 5 -------------------------
2023-03-25 20:49:43,870 : [INFO]  ------------------------- Batch round 5, loss: 0.5588 -------------------------
2023-03-25 20:49:43,870 : [INFO]  ------------------------- Batch 47, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:43,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:43,894 : [INFO]  ------------------------- Batch 47 training: round 6 -------------------------
2023-03-25 20:49:44,966 : [INFO]  ------------------------- Batch round 6, loss: 0.5597 -------------------------
2023-03-25 20:49:44,966 : [INFO]  ------------------------- Batch 47, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:44,990 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:44,992 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 20:49:44,992 : [INFO]  ################ Batch 47: final global model evalution after 6 rounds ################
2023-03-25 20:49:46,312 : [INFO]  Batch 47: Training set : loss - 0.5513, accuracy - 0.7554, recall - 0.9565, AUC - 0.9162, F1 - 0.7964, precision - 0.6822, training time - -8.0 seconds
2023-03-25 20:49:46,312 : [INFO]  Batch 47: Testing set : loss - 0.5921, accuracy - 0.6863, recall - 0.8824, AUC - 0.8634, F1 - 0.7377, precision - 0.6338
2023-03-25 20:49:46,324 : [INFO]  Batch 48 initialized 
2023-03-25 20:49:46,756 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:47,115 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 20:49:49,887 : [INFO]  ------------------------- Batch round 1, loss: 0.5403 -------------------------
2023-03-25 20:49:49,888 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:49,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:49,907 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 20:49:50,977 : [INFO]  ------------------------- Batch round 2, loss: 0.5297 -------------------------
2023-03-25 20:49:50,977 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:51,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:51,026 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 20:49:52,121 : [INFO]  ------------------------- Batch round 3, loss: 0.5229 -------------------------
2023-03-25 20:49:52,121 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:52,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:52,150 : [INFO]  ------------------------- Batch 48 training: round 4 -------------------------
2023-03-25 20:49:53,211 : [INFO]  ------------------------- Batch round 4, loss: 0.5232 -------------------------
2023-03-25 20:49:53,211 : [INFO]  ------------------------- Batch 48, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:53,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:53,252 : [INFO]  ------------------------- Batch 48 training: round 5 -------------------------
2023-03-25 20:49:54,345 : [INFO]  ------------------------- Batch round 5, loss: 0.5208 -------------------------
2023-03-25 20:49:54,345 : [INFO]  ------------------------- Batch 48, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:54,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:54,368 : [INFO]  ------------------------- Batch 48 training: round 6 -------------------------
2023-03-25 20:49:55,437 : [INFO]  ------------------------- Batch round 6, loss: 0.5166 -------------------------
2023-03-25 20:49:55,437 : [INFO]  ------------------------- Batch 48, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:55,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:55,489 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 20:49:55,489 : [INFO]  ################ Batch 48: final global model evalution after 6 rounds ################
2023-03-25 20:49:56,761 : [INFO]  Batch 48: Training set : loss - 0.5117, accuracy - 0.8152, recall - 0.9891, AUC - 0.9379, F1 - 0.8426, precision - 0.7339, training time - -8.0 seconds
2023-03-25 20:49:56,761 : [INFO]  Batch 48: Testing set : loss - 0.572, accuracy - 0.6716, recall - 0.9412, AUC - 0.9103, F1 - 0.7413, precision - 0.6115
2023-03-25 20:49:56,772 : [INFO]  Batch 49 initialized 
2023-03-25 20:49:57,205 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:57,559 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 20:50:00,390 : [INFO]  ------------------------- Batch round 1, loss: 0.578 -------------------------
2023-03-25 20:50:00,390 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:00,449 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:00,451 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 20:50:01,524 : [INFO]  ------------------------- Batch round 2, loss: 0.5761 -------------------------
2023-03-25 20:50:01,524 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:01,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:01,578 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 20:50:02,660 : [INFO]  ------------------------- Batch round 3, loss: 0.5795 -------------------------
2023-03-25 20:50:02,661 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:02,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:02,718 : [INFO]  ------------------------- Batch 49 training: round 4 -------------------------
2023-03-25 20:50:03,771 : [INFO]  ------------------------- Batch round 4, loss: 0.5722 -------------------------
2023-03-25 20:50:03,772 : [INFO]  ------------------------- Batch 49, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:03,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:03,832 : [INFO]  ------------------------- Batch 49 training: round 5 -------------------------
2023-03-25 20:50:04,892 : [INFO]  ------------------------- Batch round 5, loss: 0.5538 -------------------------
2023-03-25 20:50:04,892 : [INFO]  ------------------------- Batch 49, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:04,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:04,973 : [INFO]  ------------------------- Batch 49 training: round 6 -------------------------
2023-03-25 20:50:06,043 : [INFO]  ------------------------- Batch round 6, loss: 0.5645 -------------------------
2023-03-25 20:50:06,043 : [INFO]  ------------------------- Batch 49, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:06,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:06,081 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 20:50:06,081 : [INFO]  ################ Batch 49: final global model evalution after 6 rounds ################
2023-03-25 20:50:07,366 : [INFO]  Batch 49: Training set : loss - 0.5545, accuracy - 0.7391, recall - 0.8804, AUC - 0.8973, F1 - 0.7714, precision - 0.6864, training time - -9.0 seconds
2023-03-25 20:50:07,367 : [INFO]  Batch 49: Testing set : loss - 0.5918, accuracy - 0.6961, recall - 0.8529, AUC - 0.8289, F1 - 0.7373, precision - 0.6493
2023-03-25 20:50:07,379 : [INFO]  Batch 50 initialized 
2023-03-25 20:50:07,798 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:08,147 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 20:50:10,958 : [INFO]  ------------------------- Batch round 1, loss: 0.5562 -------------------------
2023-03-25 20:50:10,958 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:10,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:10,988 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 20:50:12,083 : [INFO]  ------------------------- Batch round 2, loss: 0.5612 -------------------------
2023-03-25 20:50:12,083 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:12,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:12,111 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 20:50:13,161 : [INFO]  ------------------------- Batch round 3, loss: 0.5536 -------------------------
2023-03-25 20:50:13,161 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:13,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:13,217 : [INFO]  ------------------------- Batch 50 training: round 4 -------------------------
2023-03-25 20:50:14,309 : [INFO]  ------------------------- Batch round 4, loss: 0.5402 -------------------------
2023-03-25 20:50:14,309 : [INFO]  ------------------------- Batch 50, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:14,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:14,328 : [INFO]  ------------------------- Batch 50 training: round 5 -------------------------
2023-03-25 20:50:15,393 : [INFO]  ------------------------- Batch round 5, loss: 0.5377 -------------------------
2023-03-25 20:50:15,394 : [INFO]  ------------------------- Batch 50, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:15,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:15,406 : [INFO]  ------------------------- Batch 50 training: round 6 -------------------------
2023-03-25 20:50:16,499 : [INFO]  ------------------------- Batch round 6, loss: 0.5416 -------------------------
2023-03-25 20:50:16,499 : [INFO]  ------------------------- Batch 50, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:16,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:16,505 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 20:50:16,505 : [INFO]  ################ Batch 50: final global model evalution after 6 rounds ################
2023-03-25 20:50:17,759 : [INFO]  Batch 50: Training set : loss - 0.5375, accuracy - 0.7717, recall - 0.9239, AUC - 0.9017, F1 - 0.8019, precision - 0.7083, training time - -8.0 seconds
2023-03-25 20:50:17,760 : [INFO]  Batch 50: Testing set : loss - 0.5563, accuracy - 0.7255, recall - 0.9706, AUC - 0.9286, F1 - 0.7795, precision - 0.6513
2023-03-25 20:50:17,772 : [INFO]  Batch 51 initialized 
2023-03-25 20:50:18,195 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:18,566 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 20:50:21,342 : [INFO]  ------------------------- Batch round 1, loss: 0.5773 -------------------------
2023-03-25 20:50:21,342 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:21,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:21,369 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 20:50:22,435 : [INFO]  ------------------------- Batch round 2, loss: 0.5718 -------------------------
2023-03-25 20:50:22,435 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:22,440 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:22,442 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 20:50:23,522 : [INFO]  ------------------------- Batch round 3, loss: 0.5688 -------------------------
2023-03-25 20:50:23,522 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:23,525 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:23,528 : [INFO]  ------------------------- Batch 51 training: round 4 -------------------------
2023-03-25 20:50:24,665 : [INFO]  ------------------------- Batch round 4, loss: 0.579 -------------------------
2023-03-25 20:50:24,665 : [INFO]  ------------------------- Batch 51, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:24,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:24,670 : [INFO]  ------------------------- Batch 51 training: round 5 -------------------------
2023-03-25 20:50:25,754 : [INFO]  ------------------------- Batch round 5, loss: 0.5735 -------------------------
2023-03-25 20:50:25,754 : [INFO]  ------------------------- Batch 51, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:25,761 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:25,763 : [INFO]  ------------------------- Batch 51 training: round 6 -------------------------
2023-03-25 20:50:26,848 : [INFO]  ------------------------- Batch round 6, loss: 0.5673 -------------------------
2023-03-25 20:50:26,848 : [INFO]  ------------------------- Batch 51, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:26,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:26,854 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 20:50:26,854 : [INFO]  ################ Batch 51: final global model evalution after 6 rounds ################
2023-03-25 20:50:28,173 : [INFO]  Batch 51: Training set : loss - 0.5684, accuracy - 0.7228, recall - 0.8913, AUC - 0.8567, F1 - 0.7628, precision - 0.6667, training time - -8.0 seconds
2023-03-25 20:50:28,173 : [INFO]  Batch 51: Testing set : loss - 0.5974, accuracy - 0.6863, recall - 0.8824, AUC - 0.8081, F1 - 0.7377, precision - 0.6338
2023-03-25 20:50:28,181 : [INFO]  Batch 52 initialized 
2023-03-25 20:50:28,600 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:28,979 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 20:50:31,760 : [INFO]  ------------------------- Batch round 1, loss: 0.5596 -------------------------
2023-03-25 20:50:31,760 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:31,786 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:31,788 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 20:50:32,887 : [INFO]  ------------------------- Batch round 2, loss: 0.5473 -------------------------
2023-03-25 20:50:32,888 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:32,908 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:32,910 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 20:50:33,993 : [INFO]  ------------------------- Batch round 3, loss: 0.5466 -------------------------
2023-03-25 20:50:33,993 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:34,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:34,044 : [INFO]  ------------------------- Batch 52 training: round 4 -------------------------
2023-03-25 20:50:35,107 : [INFO]  ------------------------- Batch round 4, loss: 0.5411 -------------------------
2023-03-25 20:50:35,107 : [INFO]  ------------------------- Batch 52, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:35,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:35,147 : [INFO]  ------------------------- Batch 52 training: round 5 -------------------------
2023-03-25 20:50:36,228 : [INFO]  ------------------------- Batch round 5, loss: 0.5377 -------------------------
2023-03-25 20:50:36,228 : [INFO]  ------------------------- Batch 52, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:36,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:36,280 : [INFO]  ------------------------- Batch 52 training: round 6 -------------------------
2023-03-25 20:50:37,341 : [INFO]  ------------------------- Batch round 6, loss: 0.5335 -------------------------
2023-03-25 20:50:37,342 : [INFO]  ------------------------- Batch 52, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:37,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:37,379 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 20:50:37,379 : [INFO]  ################ Batch 52: final global model evalution after 6 rounds ################
2023-03-25 20:50:38,660 : [INFO]  Batch 52: Training set : loss - 0.5311, accuracy - 0.7772, recall - 0.9239, AUC - 0.92, F1 - 0.8057, precision - 0.7143, training time - -8.0 seconds
2023-03-25 20:50:38,661 : [INFO]  Batch 52: Testing set : loss - 0.5671, accuracy - 0.7304, recall - 0.8824, AUC - 0.8762, F1 - 0.766, precision - 0.6767
2023-03-25 20:50:38,675 : [INFO]  Batch 53 initialized 
2023-03-25 20:50:39,104 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:39,475 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 20:50:42,324 : [INFO]  ------------------------- Batch round 1, loss: 0.5825 -------------------------
2023-03-25 20:50:42,324 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:42,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:42,330 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 20:50:43,467 : [INFO]  ------------------------- Batch round 2, loss: 0.5748 -------------------------
2023-03-25 20:50:43,467 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:43,470 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:43,472 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 20:50:44,587 : [INFO]  ------------------------- Batch round 3, loss: 0.569 -------------------------
2023-03-25 20:50:44,587 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:44,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:44,592 : [INFO]  ------------------------- Batch 53 training: round 4 -------------------------
2023-03-25 20:50:45,655 : [INFO]  ------------------------- Batch round 4, loss: 0.5643 -------------------------
2023-03-25 20:50:45,655 : [INFO]  ------------------------- Batch 53, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:45,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:45,660 : [INFO]  ------------------------- Batch 53 training: round 5 -------------------------
2023-03-25 20:50:46,778 : [INFO]  ------------------------- Batch round 5, loss: 0.5676 -------------------------
2023-03-25 20:50:46,778 : [INFO]  ------------------------- Batch 53, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:46,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:46,783 : [INFO]  ------------------------- Batch 53 training: round 6 -------------------------
2023-03-25 20:50:47,887 : [INFO]  ------------------------- Batch round 6, loss: 0.5708 -------------------------
2023-03-25 20:50:47,888 : [INFO]  ------------------------- Batch 53, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:47,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:47,893 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 20:50:47,893 : [INFO]  ################ Batch 53: final global model evalution after 6 rounds ################
2023-03-25 20:50:49,234 : [INFO]  Batch 53: Training set : loss - 0.5582, accuracy - 0.7446, recall - 0.8913, AUC - 0.8681, F1 - 0.7773, precision - 0.6891, training time - -8.0 seconds
2023-03-25 20:50:49,234 : [INFO]  Batch 53: Testing set : loss - 0.5753, accuracy - 0.7304, recall - 0.8725, AUC - 0.8501, F1 - 0.7639, precision - 0.6794
2023-03-25 20:50:49,241 : [INFO]  Batch 54 initialized 
2023-03-25 20:50:49,668 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:50,034 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 20:50:52,874 : [INFO]  ------------------------- Batch round 1, loss: 0.5949 -------------------------
2023-03-25 20:50:52,874 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:52,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:52,878 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 20:50:53,971 : [INFO]  ------------------------- Batch round 2, loss: 0.5865 -------------------------
2023-03-25 20:50:53,972 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:53,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:53,976 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 20:50:55,063 : [INFO]  ------------------------- Batch round 3, loss: 0.5791 -------------------------
2023-03-25 20:50:55,063 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:55,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:55,068 : [INFO]  ------------------------- Batch 54 training: round 4 -------------------------
2023-03-25 20:50:56,175 : [INFO]  ------------------------- Batch round 4, loss: 0.584 -------------------------
2023-03-25 20:50:56,175 : [INFO]  ------------------------- Batch 54, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:56,178 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:56,180 : [INFO]  ------------------------- Batch 54 training: round 5 -------------------------
2023-03-25 20:50:57,312 : [INFO]  ------------------------- Batch round 5, loss: 0.585 -------------------------
2023-03-25 20:50:57,313 : [INFO]  ------------------------- Batch 54, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:57,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:57,318 : [INFO]  ------------------------- Batch 54 training: round 6 -------------------------
2023-03-25 20:50:58,401 : [INFO]  ------------------------- Batch round 6, loss: 0.5865 -------------------------
2023-03-25 20:50:58,401 : [INFO]  ------------------------- Batch 54, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:58,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:58,406 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 20:50:58,406 : [INFO]  ################ Batch 54: final global model evalution after 6 rounds ################
2023-03-25 20:50:59,711 : [INFO]  Batch 54: Training set : loss - 0.5793, accuracy - 0.7174, recall - 0.8804, AUC - 0.8218, F1 - 0.757, precision - 0.6639, training time - -8.0 seconds
2023-03-25 20:50:59,711 : [INFO]  Batch 54: Testing set : loss - 0.5866, accuracy - 0.7157, recall - 0.8529, AUC - 0.8423, F1 - 0.75, precision - 0.6692
2023-03-25 20:50:59,717 : [INFO]  Batch 55 initialized 
2023-03-25 20:51:00,143 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:00,522 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 20:51:03,445 : [INFO]  ------------------------- Batch round 1, loss: 0.5436 -------------------------
2023-03-25 20:51:03,445 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:03,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:03,450 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 20:51:04,552 : [INFO]  ------------------------- Batch round 2, loss: 0.5273 -------------------------
2023-03-25 20:51:04,552 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:04,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:04,557 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 20:51:05,647 : [INFO]  ------------------------- Batch round 3, loss: 0.5254 -------------------------
2023-03-25 20:51:05,647 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:05,650 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:05,652 : [INFO]  ------------------------- Batch 55 training: round 4 -------------------------
2023-03-25 20:51:06,749 : [INFO]  ------------------------- Batch round 4, loss: 0.5416 -------------------------
2023-03-25 20:51:06,749 : [INFO]  ------------------------- Batch 55, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:06,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:06,754 : [INFO]  ------------------------- Batch 55 training: round 5 -------------------------
2023-03-25 20:51:07,851 : [INFO]  ------------------------- Batch round 5, loss: 0.5252 -------------------------
2023-03-25 20:51:07,851 : [INFO]  ------------------------- Batch 55, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:07,854 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:07,856 : [INFO]  ------------------------- Batch 55 training: round 6 -------------------------
2023-03-25 20:51:08,971 : [INFO]  ------------------------- Batch round 6, loss: 0.5167 -------------------------
2023-03-25 20:51:08,971 : [INFO]  ------------------------- Batch 55, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:08,974 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:08,976 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 20:51:08,976 : [INFO]  ################ Batch 55: final global model evalution after 6 rounds ################
2023-03-25 20:51:10,305 : [INFO]  Batch 55: Training set : loss - 0.5213, accuracy - 0.788, recall - 0.9348, AUC - 0.9242, F1 - 0.8152, precision - 0.7227, training time - -8.0 seconds
2023-03-25 20:51:10,306 : [INFO]  Batch 55: Testing set : loss - 0.5863, accuracy - 0.6618, recall - 0.8627, AUC - 0.8519, F1 - 0.7184, precision - 0.6154
2023-03-25 20:51:10,317 : [INFO]  Batch 56 initialized 
2023-03-25 20:51:10,739 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:11,134 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 20:51:13,874 : [INFO]  ------------------------- Batch round 1, loss: 0.5864 -------------------------
2023-03-25 20:51:13,874 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:13,932 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:13,934 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 20:51:14,982 : [INFO]  ------------------------- Batch round 2, loss: 0.5745 -------------------------
2023-03-25 20:51:14,982 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:15,013 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:15,015 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 20:51:16,095 : [INFO]  ------------------------- Batch round 3, loss: 0.5719 -------------------------
2023-03-25 20:51:16,096 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:16,142 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:16,144 : [INFO]  ------------------------- Batch 56 training: round 4 -------------------------
2023-03-25 20:51:17,188 : [INFO]  ------------------------- Batch round 4, loss: 0.5674 -------------------------
2023-03-25 20:51:17,189 : [INFO]  ------------------------- Batch 56, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:17,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:17,211 : [INFO]  ------------------------- Batch 56 training: round 5 -------------------------
2023-03-25 20:51:18,238 : [INFO]  ------------------------- Batch round 5, loss: 0.569 -------------------------
2023-03-25 20:51:18,238 : [INFO]  ------------------------- Batch 56, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:18,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:18,286 : [INFO]  ------------------------- Batch 56 training: round 6 -------------------------
2023-03-25 20:51:19,338 : [INFO]  ------------------------- Batch round 6, loss: 0.5528 -------------------------
2023-03-25 20:51:19,338 : [INFO]  ------------------------- Batch 56, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:19,379 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:19,381 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 20:51:19,381 : [INFO]  ################ Batch 56: final global model evalution after 6 rounds ################
2023-03-25 20:51:20,651 : [INFO]  Batch 56: Training set : loss - 0.5545, accuracy - 0.788, recall - 0.9457, AUC - 0.8806, F1 - 0.8169, precision - 0.719, training time - -8.0 seconds
2023-03-25 20:51:20,651 : [INFO]  Batch 56: Testing set : loss - 0.5435, accuracy - 0.7549, recall - 0.8529, AUC - 0.8843, F1 - 0.7768, precision - 0.7131
2023-03-25 20:51:20,662 : [INFO]  Batch 57 initialized 
2023-03-25 20:51:21,086 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:21,467 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 20:51:24,231 : [INFO]  ------------------------- Batch round 1, loss: 0.5464 -------------------------
2023-03-25 20:51:24,231 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:24,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:24,352 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 20:51:25,454 : [INFO]  ------------------------- Batch round 2, loss: 0.5339 -------------------------
2023-03-25 20:51:25,454 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:25,499 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:25,501 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 20:51:26,523 : [INFO]  ------------------------- Batch round 3, loss: 0.5388 -------------------------
2023-03-25 20:51:26,523 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:26,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:26,618 : [INFO]  ------------------------- Batch 57 training: round 4 -------------------------
2023-03-25 20:51:27,683 : [INFO]  ------------------------- Batch round 4, loss: 0.5242 -------------------------
2023-03-25 20:51:27,683 : [INFO]  ------------------------- Batch 57, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:27,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:27,747 : [INFO]  ------------------------- Batch 57 training: round 5 -------------------------
2023-03-25 20:51:28,792 : [INFO]  ------------------------- Batch round 5, loss: 0.5376 -------------------------
2023-03-25 20:51:28,792 : [INFO]  ------------------------- Batch 57, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:28,863 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:28,866 : [INFO]  ------------------------- Batch 57 training: round 6 -------------------------
2023-03-25 20:51:29,957 : [INFO]  ------------------------- Batch round 6, loss: 0.527 -------------------------
2023-03-25 20:51:29,957 : [INFO]  ------------------------- Batch 57, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:30,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:30,047 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 20:51:30,047 : [INFO]  ################ Batch 57: final global model evalution after 6 rounds ################
2023-03-25 20:51:31,349 : [INFO]  Batch 57: Training set : loss - 0.5227, accuracy - 0.7826, recall - 0.9348, AUC - 0.9212, F1 - 0.8113, precision - 0.7167, training time - -9.0 seconds
2023-03-25 20:51:31,349 : [INFO]  Batch 57: Testing set : loss - 0.589, accuracy - 0.6912, recall - 0.8824, AUC - 0.8592, F1 - 0.7407, precision - 0.6383
2023-03-25 20:51:31,358 : [INFO]  Batch 58 initialized 
2023-03-25 20:51:31,780 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:32,154 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 20:51:34,984 : [INFO]  ------------------------- Batch round 1, loss: 0.5501 -------------------------
2023-03-25 20:51:34,984 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:35,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:35,092 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 20:51:36,139 : [INFO]  ------------------------- Batch round 2, loss: 0.5498 -------------------------
2023-03-25 20:51:36,139 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:36,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:36,180 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 20:51:37,225 : [INFO]  ------------------------- Batch round 3, loss: 0.5454 -------------------------
2023-03-25 20:51:37,225 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:37,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:37,290 : [INFO]  ------------------------- Batch 58 training: round 4 -------------------------
2023-03-25 20:51:38,326 : [INFO]  ------------------------- Batch round 4, loss: 0.5416 -------------------------
2023-03-25 20:51:38,326 : [INFO]  ------------------------- Batch 58, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:38,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:38,382 : [INFO]  ------------------------- Batch 58 training: round 5 -------------------------
2023-03-25 20:51:39,398 : [INFO]  ------------------------- Batch round 5, loss: 0.5319 -------------------------
2023-03-25 20:51:39,398 : [INFO]  ------------------------- Batch 58, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:39,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:39,473 : [INFO]  ------------------------- Batch 58 training: round 6 -------------------------
2023-03-25 20:51:40,821 : [INFO]  ------------------------- Batch round 6, loss: 0.5346 -------------------------
2023-03-25 20:51:40,821 : [INFO]  ------------------------- Batch 58, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:40,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:40,839 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 20:51:40,839 : [INFO]  ################ Batch 58: final global model evalution after 6 rounds ################
2023-03-25 20:51:42,021 : [INFO]  Batch 58: Training set : loss - 0.5329, accuracy - 0.7717, recall - 0.9565, AUC - 0.9103, F1 - 0.8073, precision - 0.6984, training time - -9.0 seconds
2023-03-25 20:51:42,021 : [INFO]  Batch 58: Testing set : loss - 0.5737, accuracy - 0.7059, recall - 0.9216, AUC - 0.8746, F1 - 0.7581, precision - 0.6438
2023-03-25 20:51:42,033 : [INFO]  Batch 59 initialized 
2023-03-25 20:51:42,455 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:42,844 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 20:51:45,619 : [INFO]  ------------------------- Batch round 1, loss: 0.5717 -------------------------
2023-03-25 20:51:45,619 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:45,651 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:45,653 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 20:51:46,767 : [INFO]  ------------------------- Batch round 2, loss: 0.5642 -------------------------
2023-03-25 20:51:46,767 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:46,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:46,772 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 20:51:47,826 : [INFO]  ------------------------- Batch round 3, loss: 0.5555 -------------------------
2023-03-25 20:51:47,826 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:47,829 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:47,831 : [INFO]  ------------------------- Batch 59 training: round 4 -------------------------
2023-03-25 20:51:48,910 : [INFO]  ------------------------- Batch round 4, loss: 0.5526 -------------------------
2023-03-25 20:51:48,910 : [INFO]  ------------------------- Batch 59, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:48,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:48,915 : [INFO]  ------------------------- Batch 59 training: round 5 -------------------------
2023-03-25 20:51:49,982 : [INFO]  ------------------------- Batch round 5, loss: 0.5582 -------------------------
2023-03-25 20:51:49,982 : [INFO]  ------------------------- Batch 59, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:49,989 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:49,991 : [INFO]  ------------------------- Batch 59 training: round 6 -------------------------
2023-03-25 20:51:51,039 : [INFO]  ------------------------- Batch round 6, loss: 0.5511 -------------------------
2023-03-25 20:51:51,039 : [INFO]  ------------------------- Batch 59, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:51,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:51,058 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 20:51:51,058 : [INFO]  ################ Batch 59: final global model evalution after 6 rounds ################
2023-03-25 20:51:52,346 : [INFO]  Batch 59: Training set : loss - 0.5517, accuracy - 0.7717, recall - 0.9348, AUC - 0.8972, F1 - 0.8037, precision - 0.7049, training time - -8.0 seconds
2023-03-25 20:51:52,346 : [INFO]  Batch 59: Testing set : loss - 0.5573, accuracy - 0.7206, recall - 0.9314, AUC - 0.8999, F1 - 0.7692, precision - 0.6552
2023-03-25 20:51:52,357 : [INFO]  Batch 60 initialized 
2023-03-25 20:51:52,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:53,174 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 20:51:55,937 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 20:51:55,937 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:55,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:55,996 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 20:51:57,052 : [INFO]  ------------------------- Batch round 2, loss: 0.549 -------------------------
2023-03-25 20:51:57,052 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:57,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:57,099 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 20:51:58,171 : [INFO]  ------------------------- Batch round 3, loss: 0.5389 -------------------------
2023-03-25 20:51:58,171 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:58,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:58,175 : [INFO]  ------------------------- Batch 60 training: round 4 -------------------------
2023-03-25 20:51:59,298 : [INFO]  ------------------------- Batch round 4, loss: 0.5459 -------------------------
2023-03-25 20:51:59,298 : [INFO]  ------------------------- Batch 60, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:59,307 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:59,309 : [INFO]  ------------------------- Batch 60 training: round 5 -------------------------
2023-03-25 20:52:00,391 : [INFO]  ------------------------- Batch round 5, loss: 0.5336 -------------------------
2023-03-25 20:52:00,391 : [INFO]  ------------------------- Batch 60, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:00,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:00,396 : [INFO]  ------------------------- Batch 60 training: round 6 -------------------------
2023-03-25 20:52:01,477 : [INFO]  ------------------------- Batch round 6, loss: 0.5309 -------------------------
2023-03-25 20:52:01,477 : [INFO]  ------------------------- Batch 60, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:01,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:01,483 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 20:52:01,483 : [INFO]  ################ Batch 60: final global model evalution after 6 rounds ################
2023-03-25 20:52:02,829 : [INFO]  Batch 60: Training set : loss - 0.5248, accuracy - 0.7989, recall - 0.913, AUC - 0.8882, F1 - 0.8195, precision - 0.7434, training time - -8.0 seconds
2023-03-25 20:52:02,829 : [INFO]  Batch 60: Testing set : loss - 0.5757, accuracy - 0.6961, recall - 0.8529, AUC - 0.8532, F1 - 0.7373, precision - 0.6493
2023-03-25 20:52:02,836 : [INFO]  Batch 61 initialized 
2023-03-25 20:52:03,257 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:03,658 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 20:52:06,455 : [INFO]  ------------------------- Batch round 1, loss: 0.628 -------------------------
2023-03-25 20:52:06,455 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:06,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:06,460 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 20:52:07,586 : [INFO]  ------------------------- Batch round 2, loss: 0.6222 -------------------------
2023-03-25 20:52:07,586 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:07,589 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:07,591 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 20:52:08,715 : [INFO]  ------------------------- Batch round 3, loss: 0.6014 -------------------------
2023-03-25 20:52:08,716 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:08,719 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:08,720 : [INFO]  ------------------------- Batch 61 training: round 4 -------------------------
2023-03-25 20:52:09,836 : [INFO]  ------------------------- Batch round 4, loss: 0.597 -------------------------
2023-03-25 20:52:09,836 : [INFO]  ------------------------- Batch 61, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:09,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:09,841 : [INFO]  ------------------------- Batch 61 training: round 5 -------------------------
2023-03-25 20:52:10,965 : [INFO]  ------------------------- Batch round 5, loss: 0.605 -------------------------
2023-03-25 20:52:10,965 : [INFO]  ------------------------- Batch 61, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:10,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:10,970 : [INFO]  ------------------------- Batch 61 training: round 6 -------------------------
2023-03-25 20:52:12,061 : [INFO]  ------------------------- Batch round 6, loss: 0.5894 -------------------------
2023-03-25 20:52:12,061 : [INFO]  ------------------------- Batch 61, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:12,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:12,067 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 20:52:12,067 : [INFO]  ################ Batch 61: final global model evalution after 6 rounds ################
2023-03-25 20:52:13,428 : [INFO]  Batch 61: Training set : loss - 0.6006, accuracy - 0.7174, recall - 0.8696, AUC - 0.7993, F1 - 0.7547, precision - 0.6667, training time - -8.0 seconds
2023-03-25 20:52:13,428 : [INFO]  Batch 61: Testing set : loss - 0.5756, accuracy - 0.7255, recall - 0.8725, AUC - 0.844, F1 - 0.7607, precision - 0.6742
2023-03-25 20:52:13,434 : [INFO]  Batch 62 initialized 
2023-03-25 20:52:13,856 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:14,253 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 20:52:17,098 : [INFO]  ------------------------- Batch round 1, loss: 0.5875 -------------------------
2023-03-25 20:52:17,098 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:17,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:17,103 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 20:52:18,203 : [INFO]  ------------------------- Batch round 2, loss: 0.5742 -------------------------
2023-03-25 20:52:18,203 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:18,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:18,210 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 20:52:19,334 : [INFO]  ------------------------- Batch round 3, loss: 0.5705 -------------------------
2023-03-25 20:52:19,334 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:19,338 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:19,339 : [INFO]  ------------------------- Batch 62 training: round 4 -------------------------
2023-03-25 20:52:20,402 : [INFO]  ------------------------- Batch round 4, loss: 0.5614 -------------------------
2023-03-25 20:52:20,402 : [INFO]  ------------------------- Batch 62, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:20,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:20,664 : [INFO]  ------------------------- Batch 62 training: round 5 -------------------------
2023-03-25 20:52:21,782 : [INFO]  ------------------------- Batch round 5, loss: 0.5458 -------------------------
2023-03-25 20:52:21,782 : [INFO]  ------------------------- Batch 62, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:21,785 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:21,787 : [INFO]  ------------------------- Batch 62 training: round 6 -------------------------
2023-03-25 20:52:22,904 : [INFO]  ------------------------- Batch round 6, loss: 0.5527 -------------------------
2023-03-25 20:52:22,904 : [INFO]  ------------------------- Batch 62, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:22,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:22,912 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 20:52:22,912 : [INFO]  ################ Batch 62: final global model evalution after 6 rounds ################
2023-03-25 20:52:24,378 : [INFO]  Batch 62: Training set : loss - 0.5383, accuracy - 0.7717, recall - 0.9022, AUC - 0.8807, F1 - 0.7981, precision - 0.7155, training time - -9.0 seconds
2023-03-25 20:52:24,378 : [INFO]  Batch 62: Testing set : loss - 0.5983, accuracy - 0.6961, recall - 0.8333, AUC - 0.7866, F1 - 0.7328, precision - 0.6538
2023-03-25 20:52:24,384 : [INFO]  Batch 63 initialized 
2023-03-25 20:52:24,823 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:25,204 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 20:52:28,065 : [INFO]  ------------------------- Batch round 1, loss: 0.5779 -------------------------
2023-03-25 20:52:28,065 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:28,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:28,070 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 20:52:29,144 : [INFO]  ------------------------- Batch round 2, loss: 0.5676 -------------------------
2023-03-25 20:52:29,144 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:29,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:29,165 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 20:52:30,252 : [INFO]  ------------------------- Batch round 3, loss: 0.5668 -------------------------
2023-03-25 20:52:30,253 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:30,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:30,258 : [INFO]  ------------------------- Batch 63 training: round 4 -------------------------
2023-03-25 20:52:31,378 : [INFO]  ------------------------- Batch round 4, loss: 0.5535 -------------------------
2023-03-25 20:52:31,378 : [INFO]  ------------------------- Batch 63, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:31,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:31,383 : [INFO]  ------------------------- Batch 63 training: round 5 -------------------------
2023-03-25 20:52:32,483 : [INFO]  ------------------------- Batch round 5, loss: 0.5566 -------------------------
2023-03-25 20:52:32,483 : [INFO]  ------------------------- Batch 63, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:32,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:32,489 : [INFO]  ------------------------- Batch 63 training: round 6 -------------------------
2023-03-25 20:52:33,552 : [INFO]  ------------------------- Batch round 6, loss: 0.5541 -------------------------
2023-03-25 20:52:33,552 : [INFO]  ------------------------- Batch 63, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:33,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:33,557 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 20:52:33,557 : [INFO]  ################ Batch 63: final global model evalution after 6 rounds ################
2023-03-25 20:52:34,865 : [INFO]  Batch 63: Training set : loss - 0.551, accuracy - 0.7554, recall - 0.9239, AUC - 0.8744, F1 - 0.7907, precision - 0.6911, training time - -8.0 seconds
2023-03-25 20:52:34,865 : [INFO]  Batch 63: Testing set : loss - 0.6076, accuracy - 0.6569, recall - 0.8431, AUC - 0.7822, F1 - 0.7107, precision - 0.6143
2023-03-25 20:52:34,876 : [INFO]  Batch 64 initialized 
2023-03-25 20:52:35,295 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:35,705 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 20:52:38,470 : [INFO]  ------------------------- Batch round 1, loss: 0.5509 -------------------------
2023-03-25 20:52:38,471 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:38,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:38,521 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 20:52:39,606 : [INFO]  ------------------------- Batch round 2, loss: 0.553 -------------------------
2023-03-25 20:52:39,606 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:39,613 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:39,615 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 20:52:40,714 : [INFO]  ------------------------- Batch round 3, loss: 0.5515 -------------------------
2023-03-25 20:52:40,714 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:40,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:40,719 : [INFO]  ------------------------- Batch 64 training: round 4 -------------------------
2023-03-25 20:52:41,839 : [INFO]  ------------------------- Batch round 4, loss: 0.5498 -------------------------
2023-03-25 20:52:41,839 : [INFO]  ------------------------- Batch 64, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:41,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:41,870 : [INFO]  ------------------------- Batch 64 training: round 5 -------------------------
2023-03-25 20:52:42,919 : [INFO]  ------------------------- Batch round 5, loss: 0.5436 -------------------------
2023-03-25 20:52:42,919 : [INFO]  ------------------------- Batch 64, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:42,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:42,957 : [INFO]  ------------------------- Batch 64 training: round 6 -------------------------
2023-03-25 20:52:44,253 : [INFO]  ------------------------- Batch round 6, loss: 0.5416 -------------------------
2023-03-25 20:52:44,253 : [INFO]  ------------------------- Batch 64, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:44,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:44,257 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 20:52:44,257 : [INFO]  ################ Batch 64: final global model evalution after 6 rounds ################
2023-03-25 20:52:45,509 : [INFO]  Batch 64: Training set : loss - 0.5318, accuracy - 0.7717, recall - 0.913, AUC - 0.8964, F1 - 0.8, precision - 0.7119, training time - -9.0 seconds
2023-03-25 20:52:45,510 : [INFO]  Batch 64: Testing set : loss - 0.5679, accuracy - 0.7206, recall - 0.8922, AUC - 0.8623, F1 - 0.7615, precision - 0.6642
2023-03-25 20:52:45,523 : [INFO]  Batch 65 initialized 
2023-03-25 20:52:45,961 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:46,367 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 20:52:49,139 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 20:52:49,140 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:49,143 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:49,146 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 20:52:50,291 : [INFO]  ------------------------- Batch round 2, loss: 0.5729 -------------------------
2023-03-25 20:52:50,291 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:50,294 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:50,296 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 20:52:51,369 : [INFO]  ------------------------- Batch round 3, loss: 0.5636 -------------------------
2023-03-25 20:52:51,369 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:51,373 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:51,375 : [INFO]  ------------------------- Batch 65 training: round 4 -------------------------
2023-03-25 20:52:52,453 : [INFO]  ------------------------- Batch round 4, loss: 0.558 -------------------------
2023-03-25 20:52:52,453 : [INFO]  ------------------------- Batch 65, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:52,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:52,458 : [INFO]  ------------------------- Batch 65 training: round 5 -------------------------
2023-03-25 20:52:53,524 : [INFO]  ------------------------- Batch round 5, loss: 0.5565 -------------------------
2023-03-25 20:52:53,524 : [INFO]  ------------------------- Batch 65, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:53,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:53,771 : [INFO]  ------------------------- Batch 65 training: round 6 -------------------------
2023-03-25 20:52:54,823 : [INFO]  ------------------------- Batch round 6, loss: 0.555 -------------------------
2023-03-25 20:52:54,823 : [INFO]  ------------------------- Batch 65, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:54,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:54,828 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 20:52:54,829 : [INFO]  ################ Batch 65: final global model evalution after 6 rounds ################
2023-03-25 20:52:56,202 : [INFO]  Batch 65: Training set : loss - 0.5399, accuracy - 0.7717, recall - 0.913, AUC - 0.8754, F1 - 0.8, precision - 0.7119, training time - -8.0 seconds
2023-03-25 20:52:56,202 : [INFO]  Batch 65: Testing set : loss - 0.542, accuracy - 0.7843, recall - 0.9412, AUC - 0.9233, F1 - 0.8136, precision - 0.7164
2023-03-25 20:52:56,213 : [INFO]  Batch 66 initialized 
2023-03-25 20:52:56,640 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:57,057 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 20:52:59,860 : [INFO]  ------------------------- Batch round 1, loss: 0.5533 -------------------------
2023-03-25 20:52:59,860 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:59,865 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:59,866 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 20:53:01,007 : [INFO]  ------------------------- Batch round 2, loss: 0.5446 -------------------------
2023-03-25 20:53:01,007 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 20:53:01,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:01,071 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 20:53:02,543 : [INFO]  ------------------------- Batch round 3, loss: 0.5512 -------------------------
2023-03-25 20:53:02,543 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 20:53:02,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:02,640 : [INFO]  ------------------------- Batch 66 training: round 4 -------------------------
2023-03-25 20:53:04,069 : [INFO]  ------------------------- Batch round 4, loss: 0.5376 -------------------------
2023-03-25 20:53:04,069 : [INFO]  ------------------------- Batch 66, round 4: Sent local model to the server -------------------------
2023-03-25 20:53:04,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:04,165 : [INFO]  ------------------------- Batch 66 training: round 5 -------------------------
2023-03-25 20:53:05,824 : [INFO]  ------------------------- Batch round 5, loss: 0.5438 -------------------------
2023-03-25 20:53:05,824 : [INFO]  ------------------------- Batch 66, round 5: Sent local model to the server -------------------------
2023-03-25 20:53:05,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:05,834 : [INFO]  ------------------------- Batch 66 training: round 6 -------------------------
2023-03-25 20:53:08,260 : [INFO]  ------------------------- Batch round 6, loss: 0.5344 -------------------------
2023-03-25 20:53:08,260 : [INFO]  ------------------------- Batch 66, round 6: Sent local model to the server -------------------------
2023-03-25 20:53:08,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:08,490 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 20:53:08,490 : [INFO]  ################ Batch 66: final global model evalution after 6 rounds ################
2023-03-25 20:53:09,949 : [INFO]  Batch 66: Training set : loss - 0.5303, accuracy - 0.788, recall - 0.9783, AUC - 0.8996, F1 - 0.8219, precision - 0.7087, training time - -11.0 seconds
2023-03-25 20:53:09,949 : [INFO]  Batch 66: Testing set : loss - 0.5566, accuracy - 0.7647, recall - 0.9216, AUC - 0.882, F1 - 0.7966, precision - 0.7015
2023-03-25 20:53:09,968 : [INFO]  Batch 67 initialized 
2023-03-25 20:53:10,400 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:53:10,834 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 20:53:13,747 : [INFO]  ------------------------- Batch round 1, loss: 0.5731 -------------------------
2023-03-25 20:53:13,747 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 20:53:13,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:13,909 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 20:53:14,994 : [INFO]  ------------------------- Batch round 2, loss: 0.5594 -------------------------
2023-03-25 20:53:14,994 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 20:53:15,113 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:15,115 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 20:53:16,238 : [INFO]  ------------------------- Batch round 3, loss: 0.5547 -------------------------
2023-03-25 20:53:16,238 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 20:53:16,543 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:16,545 : [INFO]  ------------------------- Batch 67 training: round 4 -------------------------
2023-03-25 20:53:17,799 : [INFO]  ------------------------- Batch round 4, loss: 0.559 -------------------------
2023-03-25 20:53:17,800 : [INFO]  ------------------------- Batch 67, round 4: Sent local model to the server -------------------------
2023-03-25 20:53:17,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
