2023-03-25 17:20:02,014 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 17:20:02,014 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 6, epochs 6
2023-03-25 17:20:05,231 : [INFO]  Model initialized for training
2023-03-25 17:20:20,371 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:20:20,506 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 17:20:20,507 : [INFO]  Connected to the server
2023-03-25 17:20:20,590 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 17:20:20,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:20:20,598 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 17:20:20,598 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 17:23:30,923 : [INFO]  ------------------------- Training round 1, loss: 0.6208 -------------------------
2023-03-25 17:23:30,923 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 17:23:30,927 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:23:30,929 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 17:26:30,876 : [INFO]  ------------------------- Training round 2, loss: 0.5945 -------------------------
2023-03-25 17:26:30,876 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 17:26:30,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:26:30,882 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 17:29:26,721 : [INFO]  ------------------------- Training round 3, loss: 0.5927 -------------------------
2023-03-25 17:29:26,722 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 17:29:26,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:29:26,729 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 17:32:31,068 : [INFO]  ------------------------- Training round 4, loss: 0.5912 -------------------------
2023-03-25 17:32:31,068 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 17:32:31,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:32:31,074 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 17:35:26,800 : [INFO]  ------------------------- Training round 5, loss: 0.5916 -------------------------
2023-03-25 17:35:26,800 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 17:35:26,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:35:26,807 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 17:36:26,627 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.7, recall - 0.88, AUC - 0.83, F1 - 0.75, precision - 0.65, training time - -906.0 seconds
2023-03-25 17:36:26,627 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.65
2023-03-25 17:36:26,637 : [INFO]  Batch 1 initialized 
2023-03-25 17:36:27,211 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:36:27,328 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 17:36:27,328 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 17:36:32,375 : [INFO]  ------------------------- Batch round 1, loss: 0.5848 -------------------------
2023-03-25 17:36:32,375 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 17:36:32,379 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:32,381 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 17:36:35,264 : [INFO]  ------------------------- Batch round 2, loss: 0.5807 -------------------------
2023-03-25 17:36:35,264 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 17:36:35,407 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:35,410 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 17:36:38,174 : [INFO]  ------------------------- Batch round 3, loss: 0.5856 -------------------------
2023-03-25 17:36:38,174 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 17:36:38,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:38,307 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 17:36:38,307 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 17:36:40,045 : [INFO]  Batch 1: Training set : loss - 0.5988, accuracy - 0.6685, recall - 0.8804, AUC - 0.7912, F1 - 0.7265, precision - 0.6183, training time - -11.0 seconds
2023-03-25 17:36:40,045 : [INFO]  Batch 1: Testing set : loss - 0.5743, accuracy - 0.6814, recall - 0.8922, AUC - 0.8576, F1 - 0.7368, precision - 0.6276
2023-03-25 17:36:40,065 : [INFO]  Batch 2 initialized 
2023-03-25 17:36:40,625 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:36:40,778 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 17:36:45,902 : [INFO]  ------------------------- Batch round 1, loss: 0.5599 -------------------------
2023-03-25 17:36:45,902 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 17:36:45,906 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:45,910 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 17:36:48,579 : [INFO]  ------------------------- Batch round 2, loss: 0.5586 -------------------------
2023-03-25 17:36:48,579 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 17:36:48,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:48,586 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 17:36:51,294 : [INFO]  ------------------------- Batch round 3, loss: 0.5562 -------------------------
2023-03-25 17:36:51,294 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 17:36:51,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:51,311 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 17:36:51,311 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 17:36:53,074 : [INFO]  Batch 2: Training set : loss - 0.5774, accuracy - 0.7337, recall - 0.9348, AUC - 0.8285, F1 - 0.7783, precision - 0.6667, training time - -11.0 seconds
2023-03-25 17:36:53,075 : [INFO]  Batch 2: Testing set : loss - 0.5688, accuracy - 0.6912, recall - 0.9118, AUC - 0.8728, F1 - 0.747, precision - 0.6327
2023-03-25 17:36:53,081 : [INFO]  Batch 3 initialized 
2023-03-25 17:36:53,627 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:36:53,851 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 17:36:59,000 : [INFO]  ------------------------- Batch round 1, loss: 0.5451 -------------------------
2023-03-25 17:36:59,000 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 17:36:59,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:59,006 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 17:37:01,871 : [INFO]  ------------------------- Batch round 2, loss: 0.5517 -------------------------
2023-03-25 17:37:01,871 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:01,875 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:01,877 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 17:37:04,677 : [INFO]  ------------------------- Batch round 3, loss: 0.549 -------------------------
2023-03-25 17:37:04,678 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:04,681 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:04,684 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 17:37:04,684 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 17:37:06,452 : [INFO]  Batch 3: Training set : loss - 0.5654, accuracy - 0.7174, recall - 0.837, AUC - 0.853, F1 - 0.7476, precision - 0.6754, training time - -11.0 seconds
2023-03-25 17:37:06,453 : [INFO]  Batch 3: Testing set : loss - 0.5796, accuracy - 0.701, recall - 0.8627, AUC - 0.8508, F1 - 0.7426, precision - 0.6519
2023-03-25 17:37:06,462 : [INFO]  Batch 4 initialized 
2023-03-25 17:37:07,055 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:07,270 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 17:37:12,446 : [INFO]  ------------------------- Batch round 1, loss: 0.5559 -------------------------
2023-03-25 17:37:12,446 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:12,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:12,453 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 17:37:15,227 : [INFO]  ------------------------- Batch round 2, loss: 0.5468 -------------------------
2023-03-25 17:37:15,227 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:15,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:15,256 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 17:37:17,902 : [INFO]  ------------------------- Batch round 3, loss: 0.5514 -------------------------
2023-03-25 17:37:17,902 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:17,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:17,948 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 17:37:17,948 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 17:37:19,656 : [INFO]  Batch 4: Training set : loss - 0.5659, accuracy - 0.7011, recall - 0.9239, AUC - 0.8589, F1 - 0.7556, precision - 0.6391, training time - -11.0 seconds
2023-03-25 17:37:19,656 : [INFO]  Batch 4: Testing set : loss - 0.564, accuracy - 0.7059, recall - 0.9412, AUC - 0.899, F1 - 0.7619, precision - 0.64
2023-03-25 17:37:19,666 : [INFO]  Batch 5 initialized 
2023-03-25 17:37:20,232 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:20,466 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 17:37:25,664 : [INFO]  ------------------------- Batch round 1, loss: 0.5372 -------------------------
2023-03-25 17:37:25,664 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:25,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:25,670 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 17:37:28,514 : [INFO]  ------------------------- Batch round 2, loss: 0.539 -------------------------
2023-03-25 17:37:28,514 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:28,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:28,522 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 17:37:31,343 : [INFO]  ------------------------- Batch round 3, loss: 0.5411 -------------------------
2023-03-25 17:37:31,343 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:31,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:31,360 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 17:37:31,360 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 17:37:33,068 : [INFO]  Batch 5: Training set : loss - 0.5429, accuracy - 0.7609, recall - 0.913, AUC - 0.8765, F1 - 0.7925, precision - 0.7, training time - -11.0 seconds
2023-03-25 17:37:33,069 : [INFO]  Batch 5: Testing set : loss - 0.5516, accuracy - 0.7108, recall - 0.8922, AUC - 0.8808, F1 - 0.7552, precision - 0.6547
2023-03-25 17:37:33,076 : [INFO]  Batch 6 initialized 
2023-03-25 17:37:33,625 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:33,854 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 17:37:39,013 : [INFO]  ------------------------- Batch round 1, loss: 0.5403 -------------------------
2023-03-25 17:37:39,013 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:39,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:39,019 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 17:37:41,733 : [INFO]  ------------------------- Batch round 2, loss: 0.5423 -------------------------
2023-03-25 17:37:41,734 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:41,738 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:41,740 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 17:37:44,484 : [INFO]  ------------------------- Batch round 3, loss: 0.5367 -------------------------
2023-03-25 17:37:44,484 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:44,488 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:44,491 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 17:37:44,491 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 17:37:46,195 : [INFO]  Batch 6: Training set : loss - 0.5498, accuracy - 0.7554, recall - 0.9239, AUC - 0.8756, F1 - 0.7907, precision - 0.6911, training time - -11.0 seconds
2023-03-25 17:37:46,195 : [INFO]  Batch 6: Testing set : loss - 0.5808, accuracy - 0.6716, recall - 0.9314, AUC - 0.853, F1 - 0.7393, precision - 0.6129
2023-03-25 17:37:46,202 : [INFO]  Batch 7 initialized 
2023-03-25 17:37:46,761 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:46,998 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 17:37:52,240 : [INFO]  ------------------------- Batch round 1, loss: 0.5473 -------------------------
2023-03-25 17:37:52,240 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:52,243 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:52,247 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 17:37:55,089 : [INFO]  ------------------------- Batch round 2, loss: 0.5504 -------------------------
2023-03-25 17:37:55,089 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:55,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:55,120 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 17:37:57,963 : [INFO]  ------------------------- Batch round 3, loss: 0.5462 -------------------------
2023-03-25 17:37:57,963 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:57,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:57,970 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 17:37:57,970 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 17:37:59,718 : [INFO]  Batch 7: Training set : loss - 0.5668, accuracy - 0.6957, recall - 0.9022, AUC - 0.8557, F1 - 0.7477, precision - 0.6385, training time - -11.0 seconds
2023-03-25 17:37:59,718 : [INFO]  Batch 7: Testing set : loss - 0.5941, accuracy - 0.6373, recall - 0.8725, AUC - 0.8372, F1 - 0.7063, precision - 0.5933
2023-03-25 17:37:59,725 : [INFO]  Batch 8 initialized 
2023-03-25 17:38:00,295 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:00,523 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 17:38:05,773 : [INFO]  ------------------------- Batch round 1, loss: 0.5623 -------------------------
2023-03-25 17:38:05,773 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:05,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:05,781 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 17:38:08,626 : [INFO]  ------------------------- Batch round 2, loss: 0.5677 -------------------------
2023-03-25 17:38:08,626 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:08,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:08,632 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 17:38:11,600 : [INFO]  ------------------------- Batch round 3, loss: 0.5718 -------------------------
2023-03-25 17:38:11,601 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:11,605 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:11,607 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 17:38:11,608 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 17:38:13,401 : [INFO]  Batch 8: Training set : loss - 0.5747, accuracy - 0.7283, recall - 0.8913, AUC - 0.8504, F1 - 0.7664, precision - 0.6721, training time - -11.0 seconds
2023-03-25 17:38:13,402 : [INFO]  Batch 8: Testing set : loss - 0.5993, accuracy - 0.6618, recall - 0.8725, AUC - 0.8136, F1 - 0.7206, precision - 0.6138
2023-03-25 17:38:13,408 : [INFO]  Batch 9 initialized 
2023-03-25 17:38:13,968 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:14,223 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 17:38:19,696 : [INFO]  ------------------------- Batch round 1, loss: 0.5779 -------------------------
2023-03-25 17:38:19,696 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:19,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:19,703 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 17:38:22,741 : [INFO]  ------------------------- Batch round 2, loss: 0.5879 -------------------------
2023-03-25 17:38:22,741 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:22,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:22,747 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 17:38:25,770 : [INFO]  ------------------------- Batch round 3, loss: 0.5883 -------------------------
2023-03-25 17:38:25,770 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:25,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:25,776 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 17:38:25,776 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 17:38:27,640 : [INFO]  Batch 9: Training set : loss - 0.6108, accuracy - 0.6576, recall - 0.8152, AUC - 0.7545, F1 - 0.7042, precision - 0.6198, training time - -12.0 seconds
2023-03-25 17:38:27,640 : [INFO]  Batch 9: Testing set : loss - 0.6336, accuracy - 0.5931, recall - 0.7745, AUC - 0.7338, F1 - 0.6556, precision - 0.5683
2023-03-25 17:38:27,648 : [INFO]  Batch 10 initialized 
2023-03-25 17:38:28,224 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:28,455 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 17:38:33,895 : [INFO]  ------------------------- Batch round 1, loss: 0.5706 -------------------------
2023-03-25 17:38:33,895 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:33,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:33,902 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 17:38:36,845 : [INFO]  ------------------------- Batch round 2, loss: 0.5677 -------------------------
2023-03-25 17:38:36,845 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:36,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:36,852 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 17:38:39,792 : [INFO]  ------------------------- Batch round 3, loss: 0.5629 -------------------------
2023-03-25 17:38:39,792 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:39,888 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:39,890 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 17:38:39,890 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 17:38:41,762 : [INFO]  Batch 10: Training set : loss - 0.5873, accuracy - 0.6957, recall - 0.8913, AUC - 0.8168, F1 - 0.7455, precision - 0.6406, training time - -11.0 seconds
2023-03-25 17:38:41,762 : [INFO]  Batch 10: Testing set : loss - 0.5766, accuracy - 0.6961, recall - 0.8725, AUC - 0.8407, F1 - 0.7417, precision - 0.6449
2023-03-25 17:38:41,770 : [INFO]  Batch 11 initialized 
2023-03-25 17:38:42,340 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:42,569 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 17:38:47,778 : [INFO]  ------------------------- Batch round 1, loss: 0.575 -------------------------
2023-03-25 17:38:47,778 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:47,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:47,785 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 17:38:50,704 : [INFO]  ------------------------- Batch round 2, loss: 0.5856 -------------------------
2023-03-25 17:38:50,704 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:50,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:50,712 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 17:38:53,539 : [INFO]  ------------------------- Batch round 3, loss: 0.5784 -------------------------
2023-03-25 17:38:53,539 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:53,543 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:53,545 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 17:38:53,545 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 17:38:55,290 : [INFO]  Batch 11: Training set : loss - 0.6051, accuracy - 0.6739, recall - 0.8478, AUC - 0.775, F1 - 0.7222, precision - 0.629, training time - -11.0 seconds
2023-03-25 17:38:55,290 : [INFO]  Batch 11: Testing set : loss - 0.6051, accuracy - 0.6569, recall - 0.8627, AUC - 0.8201, F1 - 0.7154, precision - 0.6111
2023-03-25 17:38:55,298 : [INFO]  Batch 12 initialized 
2023-03-25 17:38:55,862 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:56,115 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 17:39:01,407 : [INFO]  ------------------------- Batch round 1, loss: 0.5782 -------------------------
2023-03-25 17:39:01,408 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:01,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:01,539 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 17:39:04,348 : [INFO]  ------------------------- Batch round 2, loss: 0.5766 -------------------------
2023-03-25 17:39:04,348 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:04,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:04,500 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 17:39:07,670 : [INFO]  ------------------------- Batch round 3, loss: 0.5805 -------------------------
2023-03-25 17:39:07,670 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:07,675 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:07,677 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 17:39:07,677 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 17:39:09,449 : [INFO]  Batch 12: Training set : loss - 0.5952, accuracy - 0.7011, recall - 0.8804, AUC - 0.8027, F1 - 0.7465, precision - 0.648, training time - -12.0 seconds
2023-03-25 17:39:09,449 : [INFO]  Batch 12: Testing set : loss - 0.6008, accuracy - 0.6716, recall - 0.8431, AUC - 0.8014, F1 - 0.7197, precision - 0.6277
2023-03-25 17:39:09,459 : [INFO]  Batch 13 initialized 
2023-03-25 17:39:10,044 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:10,300 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 17:39:15,627 : [INFO]  ------------------------- Batch round 1, loss: 0.5457 -------------------------
2023-03-25 17:39:15,628 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:15,633 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:15,635 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 17:39:18,516 : [INFO]  ------------------------- Batch round 2, loss: 0.5513 -------------------------
2023-03-25 17:39:18,516 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:18,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:18,523 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 17:39:21,336 : [INFO]  ------------------------- Batch round 3, loss: 0.5421 -------------------------
2023-03-25 17:39:21,336 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:21,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:21,392 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 17:39:21,392 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 17:39:23,141 : [INFO]  Batch 13: Training set : loss - 0.562, accuracy - 0.7174, recall - 0.8913, AUC - 0.8478, F1 - 0.7593, precision - 0.6613, training time - -11.0 seconds
2023-03-25 17:39:23,141 : [INFO]  Batch 13: Testing set : loss - 0.5862, accuracy - 0.6422, recall - 0.8431, AUC - 0.8406, F1 - 0.702, precision - 0.6014
2023-03-25 17:39:23,150 : [INFO]  Batch 14 initialized 
2023-03-25 17:39:23,792 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:24,053 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 17:39:29,244 : [INFO]  ------------------------- Batch round 1, loss: 0.5638 -------------------------
2023-03-25 17:39:29,244 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:29,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:29,251 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 17:39:31,989 : [INFO]  ------------------------- Batch round 2, loss: 0.5633 -------------------------
2023-03-25 17:39:31,989 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:32,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:32,029 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 17:39:34,782 : [INFO]  ------------------------- Batch round 3, loss: 0.5667 -------------------------
2023-03-25 17:39:34,783 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:34,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:34,833 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 17:39:34,834 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 17:39:36,533 : [INFO]  Batch 14: Training set : loss - 0.5877, accuracy - 0.6739, recall - 0.9239, AUC - 0.8339, F1 - 0.7391, precision - 0.6159, training time - -11.0 seconds
2023-03-25 17:39:36,534 : [INFO]  Batch 14: Testing set : loss - 0.5728, accuracy - 0.7206, recall - 0.9314, AUC - 0.8692, F1 - 0.7692, precision - 0.6552
2023-03-25 17:39:36,542 : [INFO]  Batch 15 initialized 
2023-03-25 17:39:37,109 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:37,369 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 17:39:42,565 : [INFO]  ------------------------- Batch round 1, loss: 0.5896 -------------------------
2023-03-25 17:39:42,565 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:42,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:42,671 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 17:39:45,529 : [INFO]  ------------------------- Batch round 2, loss: 0.5955 -------------------------
2023-03-25 17:39:45,529 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:45,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:45,581 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 17:39:48,562 : [INFO]  ------------------------- Batch round 3, loss: 0.5936 -------------------------
2023-03-25 17:39:48,563 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:48,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:48,569 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 17:39:48,569 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 17:39:50,322 : [INFO]  Batch 15: Training set : loss - 0.6016, accuracy - 0.6902, recall - 0.837, AUC - 0.7718, F1 - 0.7299, precision - 0.6471, training time - -11.0 seconds
2023-03-25 17:39:50,322 : [INFO]  Batch 15: Testing set : loss - 0.5695, accuracy - 0.701, recall - 0.9118, AUC - 0.871, F1 - 0.753, precision - 0.6414
2023-03-25 17:39:50,331 : [INFO]  Batch 16 initialized 
2023-03-25 17:39:50,886 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:51,142 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 17:39:56,338 : [INFO]  ------------------------- Batch round 1, loss: 0.5773 -------------------------
2023-03-25 17:39:56,339 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:56,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:56,345 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 17:39:59,211 : [INFO]  ------------------------- Batch round 2, loss: 0.5834 -------------------------
2023-03-25 17:39:59,212 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:59,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:59,220 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 17:40:02,135 : [INFO]  ------------------------- Batch round 3, loss: 0.5843 -------------------------
2023-03-25 17:40:02,135 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:02,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:02,143 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 17:40:02,143 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 17:40:03,907 : [INFO]  Batch 16: Training set : loss - 0.5921, accuracy - 0.712, recall - 0.8804, AUC - 0.806, F1 - 0.7535, precision - 0.6585, training time - -11.0 seconds
2023-03-25 17:40:03,907 : [INFO]  Batch 16: Testing set : loss - 0.5805, accuracy - 0.6912, recall - 0.8431, AUC - 0.853, F1 - 0.7319, precision - 0.6466
2023-03-25 17:40:03,914 : [INFO]  Batch 17 initialized 
2023-03-25 17:40:04,491 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:04,744 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 17:40:09,910 : [INFO]  ------------------------- Batch round 1, loss: 0.557 -------------------------
2023-03-25 17:40:09,910 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:09,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:09,917 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 17:40:12,711 : [INFO]  ------------------------- Batch round 2, loss: 0.5639 -------------------------
2023-03-25 17:40:12,711 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:12,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:12,718 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 17:40:15,450 : [INFO]  ------------------------- Batch round 3, loss: 0.5597 -------------------------
2023-03-25 17:40:15,450 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:15,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:15,460 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 17:40:15,460 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 17:40:17,190 : [INFO]  Batch 17: Training set : loss - 0.5898, accuracy - 0.7391, recall - 0.9239, AUC - 0.8063, F1 - 0.7798, precision - 0.6746, training time - -11.0 seconds
2023-03-25 17:40:17,190 : [INFO]  Batch 17: Testing set : loss - 0.5771, accuracy - 0.75, recall - 0.9804, AUC - 0.8477, F1 - 0.7968, precision - 0.6711
2023-03-25 17:40:17,196 : [INFO]  Batch 18 initialized 
2023-03-25 17:40:17,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:18,001 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 17:40:23,346 : [INFO]  ------------------------- Batch round 1, loss: 0.6044 -------------------------
2023-03-25 17:40:23,346 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:23,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:23,353 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 17:40:26,297 : [INFO]  ------------------------- Batch round 2, loss: 0.5958 -------------------------
2023-03-25 17:40:26,297 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:26,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:26,304 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 17:40:29,188 : [INFO]  ------------------------- Batch round 3, loss: 0.5952 -------------------------
2023-03-25 17:40:29,189 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:29,193 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:29,196 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 17:40:29,196 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 17:40:31,014 : [INFO]  Batch 18: Training set : loss - 0.6297, accuracy - 0.6413, recall - 0.9239, AUC - 0.7927, F1 - 0.7203, precision - 0.5903, training time - -11.0 seconds
2023-03-25 17:40:31,014 : [INFO]  Batch 18: Testing set : loss - 0.6513, accuracy - 0.6029, recall - 0.8235, AUC - 0.7247, F1 - 0.6747, precision - 0.5714
2023-03-25 17:40:31,020 : [INFO]  Batch 19 initialized 
2023-03-25 17:40:31,582 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:31,846 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 17:40:37,146 : [INFO]  ------------------------- Batch round 1, loss: 0.5805 -------------------------
2023-03-25 17:40:37,146 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:37,151 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:37,153 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 17:40:40,011 : [INFO]  ------------------------- Batch round 2, loss: 0.579 -------------------------
2023-03-25 17:40:40,012 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:40,016 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:40,021 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 17:40:42,914 : [INFO]  ------------------------- Batch round 3, loss: 0.5866 -------------------------
2023-03-25 17:40:42,914 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:42,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:42,922 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 17:40:42,922 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 17:40:44,712 : [INFO]  Batch 19: Training set : loss - 0.6121, accuracy - 0.6304, recall - 0.9565, AUC - 0.8174, F1 - 0.7213, precision - 0.5789, training time - -11.0 seconds
2023-03-25 17:40:44,713 : [INFO]  Batch 19: Testing set : loss - 0.6159, accuracy - 0.6667, recall - 0.9608, AUC - 0.8218, F1 - 0.7424, precision - 0.6049
2023-03-25 17:40:44,722 : [INFO]  Batch 20 initialized 
2023-03-25 17:40:45,275 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:45,542 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 17:40:50,995 : [INFO]  ------------------------- Batch round 1, loss: 0.5894 -------------------------
2023-03-25 17:40:50,996 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:51,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:51,004 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 17:40:53,929 : [INFO]  ------------------------- Batch round 2, loss: 0.5864 -------------------------
2023-03-25 17:40:53,930 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:54,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:54,052 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 17:40:57,038 : [INFO]  ------------------------- Batch round 3, loss: 0.595 -------------------------
2023-03-25 17:40:57,038 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:57,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:57,046 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 17:40:57,046 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 17:40:58,886 : [INFO]  Batch 20: Training set : loss - 0.6109, accuracy - 0.6685, recall - 0.9239, AUC - 0.819, F1 - 0.7359, precision - 0.6115, training time - -12.0 seconds
2023-03-25 17:40:58,886 : [INFO]  Batch 20: Testing set : loss - 0.6026, accuracy - 0.6863, recall - 0.9608, AUC - 0.8445, F1 - 0.7538, precision - 0.6203
2023-03-25 17:40:58,896 : [INFO]  Batch 21 initialized 
2023-03-25 17:40:59,450 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:59,724 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 17:41:05,014 : [INFO]  ------------------------- Batch round 1, loss: 0.6002 -------------------------
2023-03-25 17:41:05,014 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:05,018 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:05,021 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 17:41:07,928 : [INFO]  ------------------------- Batch round 2, loss: 0.6017 -------------------------
2023-03-25 17:41:07,928 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:07,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:07,935 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 17:41:10,771 : [INFO]  ------------------------- Batch round 3, loss: 0.6059 -------------------------
2023-03-25 17:41:10,772 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:10,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:10,780 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 17:41:10,780 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 17:41:12,620 : [INFO]  Batch 21: Training set : loss - 0.6189, accuracy - 0.6793, recall - 0.9348, AUC - 0.7929, F1 - 0.7446, precision - 0.6187, training time - -11.0 seconds
2023-03-25 17:41:12,620 : [INFO]  Batch 21: Testing set : loss - 0.5888, accuracy - 0.701, recall - 0.9804, AUC - 0.8671, F1 - 0.7663, precision - 0.6289
2023-03-25 17:41:12,627 : [INFO]  Batch 22 initialized 
2023-03-25 17:41:13,211 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:13,479 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 17:41:18,912 : [INFO]  ------------------------- Batch round 1, loss: 0.6089 -------------------------
2023-03-25 17:41:18,912 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:18,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:18,957 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 17:41:21,869 : [INFO]  ------------------------- Batch round 2, loss: 0.6143 -------------------------
2023-03-25 17:41:21,870 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:21,944 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:21,946 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 17:41:24,824 : [INFO]  ------------------------- Batch round 3, loss: 0.6074 -------------------------
2023-03-25 17:41:24,824 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:24,931 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:24,934 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 17:41:24,934 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 17:41:26,711 : [INFO]  Batch 22: Training set : loss - 0.6388, accuracy - 0.6304, recall - 0.8804, AUC - 0.758, F1 - 0.7043, precision - 0.587, training time - -11.0 seconds
2023-03-25 17:41:26,711 : [INFO]  Batch 22: Testing set : loss - 0.6247, accuracy - 0.6127, recall - 0.951, AUC - 0.8477, F1 - 0.7106, precision - 0.5673
2023-03-25 17:41:26,725 : [INFO]  Batch 23 initialized 
2023-03-25 17:41:27,278 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:27,557 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 17:41:33,093 : [INFO]  ------------------------- Batch round 1, loss: 0.591 -------------------------
2023-03-25 17:41:33,093 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:33,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:33,155 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 17:41:36,074 : [INFO]  ------------------------- Batch round 2, loss: 0.5892 -------------------------
2023-03-25 17:41:36,075 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:36,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:36,164 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 17:41:39,061 : [INFO]  ------------------------- Batch round 3, loss: 0.5926 -------------------------
2023-03-25 17:41:39,061 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:39,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:39,096 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 17:41:39,096 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 17:41:40,932 : [INFO]  Batch 23: Training set : loss - 0.6101, accuracy - 0.625, recall - 0.8804, AUC - 0.8111, F1 - 0.7013, precision - 0.5827, training time - -12.0 seconds
2023-03-25 17:41:40,932 : [INFO]  Batch 23: Testing set : loss - 0.6237, accuracy - 0.6324, recall - 0.8725, AUC - 0.7867, F1 - 0.7036, precision - 0.5894
2023-03-25 17:41:40,940 : [INFO]  Batch 24 initialized 
2023-03-25 17:41:41,520 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:41,799 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 17:41:47,305 : [INFO]  ------------------------- Batch round 1, loss: 0.5878 -------------------------
2023-03-25 17:41:47,305 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:47,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:47,357 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 17:41:50,244 : [INFO]  ------------------------- Batch round 2, loss: 0.5843 -------------------------
2023-03-25 17:41:50,244 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:50,274 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:50,277 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 17:41:53,276 : [INFO]  ------------------------- Batch round 3, loss: 0.5916 -------------------------
2023-03-25 17:41:53,277 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:53,290 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:53,293 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 17:41:53,293 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 17:41:55,075 : [INFO]  Batch 24: Training set : loss - 0.6105, accuracy - 0.663, recall - 0.9022, AUC - 0.7965, F1 - 0.7281, precision - 0.6103, training time - -11.0 seconds
2023-03-25 17:41:55,076 : [INFO]  Batch 24: Testing set : loss - 0.5984, accuracy - 0.6863, recall - 0.9314, AUC - 0.8331, F1 - 0.748, precision - 0.625
2023-03-25 17:41:55,083 : [INFO]  Batch 25 initialized 
2023-03-25 17:41:55,641 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:55,923 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 17:42:01,280 : [INFO]  ------------------------- Batch round 1, loss: 0.5846 -------------------------
2023-03-25 17:42:01,280 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:01,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:01,425 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 17:42:04,368 : [INFO]  ------------------------- Batch round 2, loss: 0.5841 -------------------------
2023-03-25 17:42:04,368 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:04,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:04,490 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 17:42:07,349 : [INFO]  ------------------------- Batch round 3, loss: 0.5856 -------------------------
2023-03-25 17:42:07,350 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:07,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:07,506 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 17:42:07,506 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 17:42:09,285 : [INFO]  Batch 25: Training set : loss - 0.5998, accuracy - 0.7065, recall - 0.913, AUC - 0.7974, F1 - 0.7568, precision - 0.6462, training time - -12.0 seconds
2023-03-25 17:42:09,285 : [INFO]  Batch 25: Testing set : loss - 0.6097, accuracy - 0.6716, recall - 0.8431, AUC - 0.7799, F1 - 0.7197, precision - 0.6277
2023-03-25 17:42:09,303 : [INFO]  Batch 26 initialized 
2023-03-25 17:42:09,875 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:10,159 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 17:42:15,477 : [INFO]  ------------------------- Batch round 1, loss: 0.5694 -------------------------
2023-03-25 17:42:15,477 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:15,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:15,568 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 17:42:18,359 : [INFO]  ------------------------- Batch round 2, loss: 0.5719 -------------------------
2023-03-25 17:42:18,359 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:18,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:18,454 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 17:42:21,209 : [INFO]  ------------------------- Batch round 3, loss: 0.5661 -------------------------
2023-03-25 17:42:21,209 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:21,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:21,338 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 17:42:21,338 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 17:42:23,071 : [INFO]  Batch 26: Training set : loss - 0.5945, accuracy - 0.663, recall - 0.8587, AUC - 0.8157, F1 - 0.7182, precision - 0.6172, training time - -11.0 seconds
2023-03-25 17:42:23,072 : [INFO]  Batch 26: Testing set : loss - 0.5779, accuracy - 0.6912, recall - 0.9118, AUC - 0.8656, F1 - 0.747, precision - 0.6327
2023-03-25 17:42:23,085 : [INFO]  Batch 27 initialized 
2023-03-25 17:42:23,653 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:23,934 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 17:42:29,186 : [INFO]  ------------------------- Batch round 1, loss: 0.5692 -------------------------
2023-03-25 17:42:29,186 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:29,232 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:29,235 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 17:42:32,013 : [INFO]  ------------------------- Batch round 2, loss: 0.573 -------------------------
2023-03-25 17:42:32,014 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:32,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:32,021 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 17:42:34,914 : [INFO]  ------------------------- Batch round 3, loss: 0.5733 -------------------------
2023-03-25 17:42:34,914 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:34,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:34,983 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 17:42:34,983 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 17:42:36,798 : [INFO]  Batch 27: Training set : loss - 0.5841, accuracy - 0.6957, recall - 0.8913, AUC - 0.8222, F1 - 0.7455, precision - 0.6406, training time - -11.0 seconds
2023-03-25 17:42:36,798 : [INFO]  Batch 27: Testing set : loss - 0.5947, accuracy - 0.6912, recall - 0.8235, AUC - 0.8128, F1 - 0.7273, precision - 0.6512
2023-03-25 17:42:36,805 : [INFO]  Batch 28 initialized 
2023-03-25 17:42:37,360 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:37,649 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 17:42:43,403 : [INFO]  ------------------------- Batch round 1, loss: 0.5647 -------------------------
2023-03-25 17:42:43,403 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:43,409 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:43,412 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 17:42:46,392 : [INFO]  ------------------------- Batch round 2, loss: 0.5687 -------------------------
2023-03-25 17:42:46,392 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:46,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:46,400 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 17:42:49,253 : [INFO]  ------------------------- Batch round 3, loss: 0.5636 -------------------------
2023-03-25 17:42:49,253 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:49,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:49,262 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 17:42:49,262 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 17:42:51,032 : [INFO]  Batch 28: Training set : loss - 0.5769, accuracy - 0.7065, recall - 0.8696, AUC - 0.8443, F1 - 0.7477, precision - 0.6557, training time - -12.0 seconds
2023-03-25 17:42:51,032 : [INFO]  Batch 28: Testing set : loss - 0.6104, accuracy - 0.6324, recall - 0.8627, AUC - 0.8204, F1 - 0.7012, precision - 0.5906
2023-03-25 17:42:51,038 : [INFO]  Batch 29 initialized 
2023-03-25 17:42:51,575 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:51,868 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 17:42:57,474 : [INFO]  ------------------------- Batch round 1, loss: 0.5606 -------------------------
2023-03-25 17:42:57,474 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:57,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:57,482 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 17:43:00,433 : [INFO]  ------------------------- Batch round 2, loss: 0.56 -------------------------
2023-03-25 17:43:00,433 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:00,438 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:00,442 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 17:43:03,419 : [INFO]  ------------------------- Batch round 3, loss: 0.5672 -------------------------
2023-03-25 17:43:03,420 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:03,425 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:03,428 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 17:43:03,428 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 17:43:05,253 : [INFO]  Batch 29: Training set : loss - 0.5664, accuracy - 0.7283, recall - 0.9022, AUC - 0.8692, F1 - 0.7685, precision - 0.6694, training time - -12.0 seconds
2023-03-25 17:43:05,254 : [INFO]  Batch 29: Testing set : loss - 0.5688, accuracy - 0.7353, recall - 0.902, AUC - 0.8582, F1 - 0.7731, precision - 0.6765
2023-03-25 17:43:05,265 : [INFO]  Batch 30 initialized 
2023-03-25 17:43:05,827 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:06,108 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 17:43:11,451 : [INFO]  ------------------------- Batch round 1, loss: 0.5918 -------------------------
2023-03-25 17:43:11,452 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:11,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:11,459 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 17:43:14,279 : [INFO]  ------------------------- Batch round 2, loss: 0.5853 -------------------------
2023-03-25 17:43:14,279 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:14,441 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:14,449 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 17:43:17,422 : [INFO]  ------------------------- Batch round 3, loss: 0.5917 -------------------------
2023-03-25 17:43:17,422 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:17,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:17,429 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 17:43:17,430 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 17:43:19,280 : [INFO]  Batch 30: Training set : loss - 0.6073, accuracy - 0.6793, recall - 0.8261, AUC - 0.7587, F1 - 0.7204, precision - 0.6387, training time - -11.0 seconds
2023-03-25 17:43:19,280 : [INFO]  Batch 30: Testing set : loss - 0.586, accuracy - 0.6814, recall - 0.8137, AUC - 0.8142, F1 - 0.7186, precision - 0.6434
2023-03-25 17:43:19,288 : [INFO]  Batch 31 initialized 
2023-03-25 17:43:19,857 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:20,155 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 17:43:25,595 : [INFO]  ------------------------- Batch round 1, loss: 0.559 -------------------------
2023-03-25 17:43:25,595 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:25,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:25,786 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 17:43:28,721 : [INFO]  ------------------------- Batch round 2, loss: 0.562 -------------------------
2023-03-25 17:43:28,721 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:28,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:28,835 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 17:43:31,744 : [INFO]  ------------------------- Batch round 3, loss: 0.5555 -------------------------
2023-03-25 17:43:31,744 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:31,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:31,818 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 17:43:31,818 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 17:43:33,624 : [INFO]  Batch 31: Training set : loss - 0.5768, accuracy - 0.7228, recall - 0.8587, AUC - 0.8425, F1 - 0.756, precision - 0.6752, training time - -12.0 seconds
2023-03-25 17:43:33,624 : [INFO]  Batch 31: Testing set : loss - 0.5829, accuracy - 0.7108, recall - 0.8627, AUC - 0.8204, F1 - 0.7489, precision - 0.6617
2023-03-25 17:43:33,638 : [INFO]  Batch 32 initialized 
2023-03-25 17:43:34,254 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:34,596 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 17:43:39,927 : [INFO]  ------------------------- Batch round 1, loss: 0.5832 -------------------------
2023-03-25 17:43:39,927 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:40,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:40,135 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 17:43:43,010 : [INFO]  ------------------------- Batch round 2, loss: 0.5813 -------------------------
2023-03-25 17:43:43,011 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:43,227 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:43,230 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 17:43:46,022 : [INFO]  ------------------------- Batch round 3, loss: 0.5871 -------------------------
2023-03-25 17:43:46,022 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:46,196 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:46,199 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 17:43:46,200 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 17:43:47,987 : [INFO]  Batch 32: Training set : loss - 0.6061, accuracy - 0.6522, recall - 0.8478, AUC - 0.788, F1 - 0.7091, precision - 0.6094, training time - -12.0 seconds
2023-03-25 17:43:47,987 : [INFO]  Batch 32: Testing set : loss - 0.5862, accuracy - 0.701, recall - 0.9118, AUC - 0.8555, F1 - 0.753, precision - 0.6414
2023-03-25 17:43:47,994 : [INFO]  Batch 33 initialized 
2023-03-25 17:43:48,559 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:48,850 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 17:43:54,005 : [INFO]  ------------------------- Batch round 1, loss: 0.5744 -------------------------
2023-03-25 17:43:54,005 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:54,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:54,220 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 17:43:56,922 : [INFO]  ------------------------- Batch round 2, loss: 0.5752 -------------------------
2023-03-25 17:43:56,922 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:57,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:57,039 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 17:43:59,685 : [INFO]  ------------------------- Batch round 3, loss: 0.5696 -------------------------
2023-03-25 17:43:59,685 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:59,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:59,835 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 17:43:59,835 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 17:44:01,550 : [INFO]  Batch 33: Training set : loss - 0.5822, accuracy - 0.7283, recall - 0.9565, AUC - 0.8541, F1 - 0.7788, precision - 0.6567, training time - -11.0 seconds
2023-03-25 17:44:01,550 : [INFO]  Batch 33: Testing set : loss - 0.5802, accuracy - 0.7402, recall - 0.9314, AUC - 0.8505, F1 - 0.7819, precision - 0.6738
2023-03-25 17:44:01,563 : [INFO]  Batch 34 initialized 
2023-03-25 17:44:02,122 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:02,415 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 17:44:07,757 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 17:44:07,757 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:07,762 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:07,764 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 17:44:10,546 : [INFO]  ------------------------- Batch round 2, loss: 0.5735 -------------------------
2023-03-25 17:44:10,546 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:10,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:10,553 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 17:44:13,544 : [INFO]  ------------------------- Batch round 3, loss: 0.5678 -------------------------
2023-03-25 17:44:13,544 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:13,549 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:13,552 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 17:44:13,552 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 17:44:15,407 : [INFO]  Batch 34: Training set : loss - 0.5928, accuracy - 0.7228, recall - 0.8804, AUC - 0.803, F1 - 0.7606, precision - 0.6694, training time - -11.0 seconds
2023-03-25 17:44:15,407 : [INFO]  Batch 34: Testing set : loss - 0.5633, accuracy - 0.75, recall - 0.8922, AUC - 0.8579, F1 - 0.7811, precision - 0.6947
2023-03-25 17:44:15,415 : [INFO]  Batch 35 initialized 
2023-03-25 17:44:15,987 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:16,294 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 17:44:21,727 : [INFO]  ------------------------- Batch round 1, loss: 0.5763 -------------------------
2023-03-25 17:44:21,727 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:21,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:21,735 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 17:44:24,610 : [INFO]  ------------------------- Batch round 2, loss: 0.5777 -------------------------
2023-03-25 17:44:24,610 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:24,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:24,621 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 17:44:27,474 : [INFO]  ------------------------- Batch round 3, loss: 0.5695 -------------------------
2023-03-25 17:44:27,474 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:27,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:27,487 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 17:44:27,487 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 17:44:29,293 : [INFO]  Batch 35: Training set : loss - 0.5848, accuracy - 0.7174, recall - 0.8804, AUC - 0.8237, F1 - 0.757, precision - 0.6639, training time - -11.0 seconds
2023-03-25 17:44:29,294 : [INFO]  Batch 35: Testing set : loss - 0.5842, accuracy - 0.6716, recall - 0.9118, AUC - 0.8667, F1 - 0.7352, precision - 0.6159
2023-03-25 17:44:29,305 : [INFO]  Batch 36 initialized 
2023-03-25 17:44:29,916 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:30,232 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 17:44:35,606 : [INFO]  ------------------------- Batch round 1, loss: 0.567 -------------------------
2023-03-25 17:44:35,606 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:35,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:35,653 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 17:44:38,635 : [INFO]  ------------------------- Batch round 2, loss: 0.5631 -------------------------
2023-03-25 17:44:38,636 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:38,641 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:38,643 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 17:44:41,635 : [INFO]  ------------------------- Batch round 3, loss: 0.5673 -------------------------
2023-03-25 17:44:41,635 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:41,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:41,643 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 17:44:41,643 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-25 17:44:43,555 : [INFO]  Batch 36: Training set : loss - 0.5818, accuracy - 0.7283, recall - 0.8804, AUC - 0.8403, F1 - 0.7642, precision - 0.675, training time - -11.0 seconds
2023-03-25 17:44:43,556 : [INFO]  Batch 36: Testing set : loss - 0.5556, accuracy - 0.7255, recall - 0.9706, AUC - 0.9383, F1 - 0.7795, precision - 0.6513
2023-03-25 17:44:43,564 : [INFO]  Batch 37 initialized 
2023-03-25 17:44:44,143 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:44,452 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 17:44:49,850 : [INFO]  ------------------------- Batch round 1, loss: 0.6018 -------------------------
2023-03-25 17:44:49,850 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:49,855 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:49,858 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 17:44:52,727 : [INFO]  ------------------------- Batch round 2, loss: 0.6027 -------------------------
2023-03-25 17:44:52,727 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:52,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:52,735 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 17:44:55,619 : [INFO]  ------------------------- Batch round 3, loss: 0.5986 -------------------------
2023-03-25 17:44:55,619 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:55,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:55,629 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 17:44:55,629 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-25 17:44:57,393 : [INFO]  Batch 37: Training set : loss - 0.6163, accuracy - 0.6467, recall - 0.9022, AUC - 0.8039, F1 - 0.7186, precision - 0.5971, training time - -11.0 seconds
2023-03-25 17:44:57,393 : [INFO]  Batch 37: Testing set : loss - 0.5814, accuracy - 0.7108, recall - 0.8922, AUC - 0.8518, F1 - 0.7552, precision - 0.6547
2023-03-25 17:44:57,409 : [INFO]  Batch 38 initialized 
2023-03-25 17:44:57,988 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:58,296 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 17:45:03,687 : [INFO]  ------------------------- Batch round 1, loss: 0.5766 -------------------------
2023-03-25 17:45:03,687 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:03,729 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:03,732 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 17:45:06,808 : [INFO]  ------------------------- Batch round 2, loss: 0.5855 -------------------------
2023-03-25 17:45:06,808 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:06,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:06,816 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 17:45:09,755 : [INFO]  ------------------------- Batch round 3, loss: 0.5771 -------------------------
2023-03-25 17:45:09,755 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:09,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:09,791 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 17:45:09,791 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-25 17:45:11,553 : [INFO]  Batch 38: Training set : loss - 0.5987, accuracy - 0.663, recall - 0.8587, AUC - 0.8096, F1 - 0.7182, precision - 0.6172, training time - -11.0 seconds
2023-03-25 17:45:11,554 : [INFO]  Batch 38: Testing set : loss - 0.5781, accuracy - 0.7059, recall - 0.9314, AUC - 0.8643, F1 - 0.76, precision - 0.6419
2023-03-25 17:45:11,569 : [INFO]  Batch 39 initialized 
2023-03-25 17:45:12,144 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:12,441 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 17:45:17,617 : [INFO]  ------------------------- Batch round 1, loss: 0.5614 -------------------------
2023-03-25 17:45:17,617 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:17,722 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:17,724 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 17:45:20,435 : [INFO]  ------------------------- Batch round 2, loss: 0.5636 -------------------------
2023-03-25 17:45:20,435 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:20,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:20,613 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 17:45:23,351 : [INFO]  ------------------------- Batch round 3, loss: 0.5641 -------------------------
2023-03-25 17:45:23,351 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:23,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:23,368 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 17:45:23,368 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-25 17:45:25,136 : [INFO]  Batch 39: Training set : loss - 0.5761, accuracy - 0.7065, recall - 0.9565, AUC - 0.8583, F1 - 0.7652, precision - 0.6377, training time - -11.0 seconds
2023-03-25 17:45:25,136 : [INFO]  Batch 39: Testing set : loss - 0.5578, accuracy - 0.701, recall - 0.9412, AUC - 0.8958, F1 - 0.7589, precision - 0.6358
2023-03-25 17:45:25,159 : [INFO]  Batch 40 initialized 
2023-03-25 17:45:25,735 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:26,055 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 17:45:31,415 : [INFO]  ------------------------- Batch round 1, loss: 0.5548 -------------------------
2023-03-25 17:45:31,415 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:31,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:31,520 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 17:45:34,432 : [INFO]  ------------------------- Batch round 2, loss: 0.5621 -------------------------
2023-03-25 17:45:34,432 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:34,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:34,489 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 17:45:37,315 : [INFO]  ------------------------- Batch round 3, loss: 0.5659 -------------------------
2023-03-25 17:45:37,316 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:37,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:37,454 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 17:45:37,454 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-25 17:45:39,186 : [INFO]  Batch 40: Training set : loss - 0.5731, accuracy - 0.6902, recall - 0.8696, AUC - 0.85, F1 - 0.7373, precision - 0.64, training time - -11.0 seconds
2023-03-25 17:45:39,186 : [INFO]  Batch 40: Testing set : loss - 0.5929, accuracy - 0.6618, recall - 0.8529, AUC - 0.8202, F1 - 0.716, precision - 0.617
2023-03-25 17:45:39,197 : [INFO]  Batch 41 initialized 
2023-03-25 17:45:39,776 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:40,102 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 17:45:45,534 : [INFO]  ------------------------- Batch round 1, loss: 0.5432 -------------------------
2023-03-25 17:45:45,534 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:45,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:45,543 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 17:45:48,450 : [INFO]  ------------------------- Batch round 2, loss: 0.5546 -------------------------
2023-03-25 17:45:48,450 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:48,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:48,522 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 17:45:51,344 : [INFO]  ------------------------- Batch round 3, loss: 0.5477 -------------------------
2023-03-25 17:45:51,344 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:51,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:51,496 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 17:45:51,496 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-25 17:45:53,326 : [INFO]  Batch 41: Training set : loss - 0.5735, accuracy - 0.712, recall - 0.9022, AUC - 0.8427, F1 - 0.758, precision - 0.6535, training time - -11.0 seconds
2023-03-25 17:45:53,326 : [INFO]  Batch 41: Testing set : loss - 0.6111, accuracy - 0.6422, recall - 0.8529, AUC - 0.7999, F1 - 0.7045, precision - 0.6
2023-03-25 17:45:53,334 : [INFO]  Batch 42 initialized 
2023-03-25 17:45:53,908 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:54,228 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 17:45:59,782 : [INFO]  ------------------------- Batch round 1, loss: 0.5553 -------------------------
2023-03-25 17:45:59,782 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:59,800 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:59,808 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 17:46:02,580 : [INFO]  ------------------------- Batch round 2, loss: 0.5574 -------------------------
2023-03-25 17:46:02,580 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:02,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:02,651 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 17:46:05,524 : [INFO]  ------------------------- Batch round 3, loss: 0.5637 -------------------------
2023-03-25 17:46:05,525 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:05,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:05,561 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 17:46:05,562 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-25 17:46:07,366 : [INFO]  Batch 42: Training set : loss - 0.5726, accuracy - 0.6902, recall - 0.9022, AUC - 0.8692, F1 - 0.7444, precision - 0.6336, training time - -11.0 seconds
2023-03-25 17:46:07,367 : [INFO]  Batch 42: Testing set : loss - 0.5804, accuracy - 0.6961, recall - 0.9216, AUC - 0.8628, F1 - 0.752, precision - 0.6351
2023-03-25 17:46:07,377 : [INFO]  Batch 43 initialized 
2023-03-25 17:46:07,964 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:08,294 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 17:46:13,675 : [INFO]  ------------------------- Batch round 1, loss: 0.594 -------------------------
2023-03-25 17:46:13,675 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:13,680 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:13,683 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 17:46:16,414 : [INFO]  ------------------------- Batch round 2, loss: 0.5913 -------------------------
2023-03-25 17:46:16,414 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:16,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:16,510 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 17:46:19,206 : [INFO]  ------------------------- Batch round 3, loss: 0.5914 -------------------------
2023-03-25 17:46:19,206 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:19,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:19,313 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 17:46:19,313 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-25 17:46:21,024 : [INFO]  Batch 43: Training set : loss - 0.5951, accuracy - 0.6957, recall - 0.8804, AUC - 0.7706, F1 - 0.7431, precision - 0.6429, training time - -11.0 seconds
2023-03-25 17:46:21,024 : [INFO]  Batch 43: Testing set : loss - 0.5476, accuracy - 0.7598, recall - 0.9216, AUC - 0.8813, F1 - 0.7932, precision - 0.6963
2023-03-25 17:46:21,045 : [INFO]  Batch 44 initialized 
2023-03-25 17:46:21,605 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:21,927 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 17:46:27,242 : [INFO]  ------------------------- Batch round 1, loss: 0.5553 -------------------------
2023-03-25 17:46:27,242 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:27,315 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:27,318 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 17:46:30,117 : [INFO]  ------------------------- Batch round 2, loss: 0.5479 -------------------------
2023-03-25 17:46:30,117 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:30,183 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:30,186 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 17:46:32,993 : [INFO]  ------------------------- Batch round 3, loss: 0.5505 -------------------------
2023-03-25 17:46:32,993 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:33,040 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:33,045 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 17:46:33,045 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-25 17:46:34,747 : [INFO]  Batch 44: Training set : loss - 0.5643, accuracy - 0.7337, recall - 0.9457, AUC - 0.8846, F1 - 0.7803, precision - 0.6641, training time - -11.0 seconds
2023-03-25 17:46:34,747 : [INFO]  Batch 44: Testing set : loss - 0.5818, accuracy - 0.6863, recall - 0.9118, AUC - 0.8543, F1 - 0.744, precision - 0.6284
2023-03-25 17:46:34,760 : [INFO]  Batch 45 initialized 
2023-03-25 17:46:35,317 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:35,679 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 17:46:41,054 : [INFO]  ------------------------- Batch round 1, loss: 0.5511 -------------------------
2023-03-25 17:46:41,055 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:41,202 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:41,205 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 17:46:44,038 : [INFO]  ------------------------- Batch round 2, loss: 0.5559 -------------------------
2023-03-25 17:46:44,038 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:44,123 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:44,126 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 17:46:46,969 : [INFO]  ------------------------- Batch round 3, loss: 0.5539 -------------------------
2023-03-25 17:46:46,969 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:47,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:47,078 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 17:46:47,079 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-25 17:46:48,822 : [INFO]  Batch 45: Training set : loss - 0.5628, accuracy - 0.7663, recall - 0.9783, AUC - 0.8682, F1 - 0.8072, precision - 0.687, training time - -11.0 seconds
2023-03-25 17:46:48,822 : [INFO]  Batch 45: Testing set : loss - 0.5709, accuracy - 0.7206, recall - 0.9608, AUC - 0.8645, F1 - 0.7747, precision - 0.649
2023-03-25 17:46:48,834 : [INFO]  Batch 46 initialized 
2023-03-25 17:46:49,403 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:49,730 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 17:46:55,218 : [INFO]  ------------------------- Batch round 1, loss: 0.5679 -------------------------
2023-03-25 17:46:55,218 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:55,225 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:55,228 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 17:46:58,112 : [INFO]  ------------------------- Batch round 2, loss: 0.57 -------------------------
2023-03-25 17:46:58,112 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:58,119 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:58,122 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 17:47:01,013 : [INFO]  ------------------------- Batch round 3, loss: 0.5764 -------------------------
2023-03-25 17:47:01,014 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:01,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:01,022 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 17:47:01,023 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-25 17:47:02,874 : [INFO]  Batch 46: Training set : loss - 0.5971, accuracy - 0.6522, recall - 0.8913, AUC - 0.8434, F1 - 0.7193, precision - 0.6029, training time - -11.0 seconds
2023-03-25 17:47:02,874 : [INFO]  Batch 46: Testing set : loss - 0.5795, accuracy - 0.6716, recall - 0.902, AUC - 0.8768, F1 - 0.7331, precision - 0.6174
2023-03-25 17:47:02,889 : [INFO]  Batch 47 initialized 
2023-03-25 17:47:03,478 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:03,820 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 17:47:09,184 : [INFO]  ------------------------- Batch round 1, loss: 0.5862 -------------------------
2023-03-25 17:47:09,185 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:09,190 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:09,194 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 17:47:12,068 : [INFO]  ------------------------- Batch round 2, loss: 0.5939 -------------------------
2023-03-25 17:47:12,068 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:12,073 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:12,076 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 17:47:14,910 : [INFO]  ------------------------- Batch round 3, loss: 0.5848 -------------------------
2023-03-25 17:47:14,911 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:14,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:14,919 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 17:47:14,919 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-25 17:47:16,667 : [INFO]  Batch 47: Training set : loss - 0.6183, accuracy - 0.7065, recall - 0.9457, AUC - 0.7647, F1 - 0.7632, precision - 0.6397, training time - -11.0 seconds
2023-03-25 17:47:16,667 : [INFO]  Batch 47: Testing set : loss - 0.6195, accuracy - 0.6422, recall - 0.8922, AUC - 0.7897, F1 - 0.7137, precision - 0.5948
2023-03-25 17:47:16,678 : [INFO]  Batch 48 initialized 
2023-03-25 17:47:17,249 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:17,588 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 17:47:22,973 : [INFO]  ------------------------- Batch round 1, loss: 0.5964 -------------------------
2023-03-25 17:47:22,973 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:22,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:22,984 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 17:47:25,871 : [INFO]  ------------------------- Batch round 2, loss: 0.6007 -------------------------
2023-03-25 17:47:25,871 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:25,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:25,879 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 17:47:28,804 : [INFO]  ------------------------- Batch round 3, loss: 0.5975 -------------------------
2023-03-25 17:47:28,804 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:28,810 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:28,812 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 17:47:28,812 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-25 17:47:30,609 : [INFO]  Batch 48: Training set : loss - 0.6218, accuracy - 0.6522, recall - 0.8478, AUC - 0.7648, F1 - 0.7091, precision - 0.6094, training time - -11.0 seconds
2023-03-25 17:47:30,609 : [INFO]  Batch 48: Testing set : loss - 0.5829, accuracy - 0.7059, recall - 0.8824, AUC - 0.8425, F1 - 0.75, precision - 0.6522
2023-03-25 17:47:30,622 : [INFO]  Batch 49 initialized 
2023-03-25 17:47:31,238 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:31,580 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 17:47:37,027 : [INFO]  ------------------------- Batch round 1, loss: 0.6129 -------------------------
2023-03-25 17:47:37,027 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:37,033 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:37,035 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 17:47:39,988 : [INFO]  ------------------------- Batch round 2, loss: 0.6199 -------------------------
2023-03-25 17:47:39,988 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:39,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:39,996 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 17:47:42,986 : [INFO]  ------------------------- Batch round 3, loss: 0.613 -------------------------
2023-03-25 17:47:42,986 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:42,992 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:42,994 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 17:47:42,995 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-25 17:47:44,828 : [INFO]  Batch 49: Training set : loss - 0.6441, accuracy - 0.5978, recall - 0.8587, AUC - 0.7499, F1 - 0.681, precision - 0.5643, training time - -11.0 seconds
2023-03-25 17:47:44,828 : [INFO]  Batch 49: Testing set : loss - 0.624, accuracy - 0.6422, recall - 0.8529, AUC - 0.7502, F1 - 0.7045, precision - 0.6
2023-03-25 17:47:44,841 : [INFO]  Batch 50 initialized 
2023-03-25 17:47:45,416 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:45,761 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 17:47:51,255 : [INFO]  ------------------------- Batch round 1, loss: 0.5763 -------------------------
2023-03-25 17:47:51,256 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:51,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:51,264 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 17:47:54,260 : [INFO]  ------------------------- Batch round 2, loss: 0.5791 -------------------------
2023-03-25 17:47:54,260 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:54,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:54,270 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 17:47:57,086 : [INFO]  ------------------------- Batch round 3, loss: 0.5758 -------------------------
2023-03-25 17:47:57,087 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:57,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:57,095 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 17:47:57,095 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-25 17:47:58,921 : [INFO]  Batch 50: Training set : loss - 0.5975, accuracy - 0.7011, recall - 0.9239, AUC - 0.8156, F1 - 0.7556, precision - 0.6391, training time - -11.0 seconds
2023-03-25 17:47:58,921 : [INFO]  Batch 50: Testing set : loss - 0.6007, accuracy - 0.652, recall - 0.8922, AUC - 0.8292, F1 - 0.7194, precision - 0.6026
2023-03-25 17:47:58,928 : [INFO]  Batch 51 initialized 
2023-03-25 17:47:59,506 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:59,852 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 17:48:05,186 : [INFO]  ------------------------- Batch round 1, loss: 0.5706 -------------------------
2023-03-25 17:48:05,187 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:05,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:05,263 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 17:48:08,004 : [INFO]  ------------------------- Batch round 2, loss: 0.5647 -------------------------
2023-03-25 17:48:08,005 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:08,032 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:08,034 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 17:48:10,810 : [INFO]  ------------------------- Batch round 3, loss: 0.559 -------------------------
2023-03-25 17:48:10,810 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:10,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:10,819 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 17:48:10,819 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-25 17:48:12,549 : [INFO]  Batch 51: Training set : loss - 0.5778, accuracy - 0.7228, recall - 0.913, AUC - 0.8307, F1 - 0.7671, precision - 0.6614, training time - -11.0 seconds
2023-03-25 17:48:12,549 : [INFO]  Batch 51: Testing set : loss - 0.5591, accuracy - 0.7451, recall - 0.9216, AUC - 0.8738, F1 - 0.7833, precision - 0.6812
2023-03-25 17:48:12,564 : [INFO]  Batch 52 initialized 
2023-03-25 17:48:13,134 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:13,467 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 17:48:18,821 : [INFO]  ------------------------- Batch round 1, loss: 0.574 -------------------------
2023-03-25 17:48:18,822 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:18,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:18,830 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 17:48:21,688 : [INFO]  ------------------------- Batch round 2, loss: 0.5764 -------------------------
2023-03-25 17:48:21,688 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:21,694 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:21,696 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 17:48:24,600 : [INFO]  ------------------------- Batch round 3, loss: 0.582 -------------------------
2023-03-25 17:48:24,600 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:24,605 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:24,609 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 17:48:24,609 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-25 17:48:26,443 : [INFO]  Batch 52: Training set : loss - 0.5991, accuracy - 0.6522, recall - 0.8478, AUC - 0.8159, F1 - 0.7091, precision - 0.6094, training time - -11.0 seconds
2023-03-25 17:48:26,444 : [INFO]  Batch 52: Testing set : loss - 0.5959, accuracy - 0.6618, recall - 0.8529, AUC - 0.8129, F1 - 0.716, precision - 0.617
2023-03-25 17:48:26,452 : [INFO]  Batch 53 initialized 
2023-03-25 17:48:27,028 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:27,367 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 17:48:32,689 : [INFO]  ------------------------- Batch round 1, loss: 0.5662 -------------------------
2023-03-25 17:48:32,689 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:32,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:32,895 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 17:48:35,824 : [INFO]  ------------------------- Batch round 2, loss: 0.5649 -------------------------
2023-03-25 17:48:35,824 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:35,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:35,853 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 17:48:38,639 : [INFO]  ------------------------- Batch round 3, loss: 0.5644 -------------------------
2023-03-25 17:48:38,640 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:38,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:38,650 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 17:48:38,651 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-25 17:48:40,439 : [INFO]  Batch 53: Training set : loss - 0.5684, accuracy - 0.7174, recall - 0.8804, AUC - 0.8391, F1 - 0.757, precision - 0.6639, training time - -11.0 seconds
2023-03-25 17:48:40,440 : [INFO]  Batch 53: Testing set : loss - 0.5524, accuracy - 0.7353, recall - 0.8922, AUC - 0.8783, F1 - 0.7712, precision - 0.6791
2023-03-25 17:48:40,454 : [INFO]  Batch 54 initialized 
2023-03-25 17:48:41,040 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:41,394 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 17:48:46,629 : [INFO]  ------------------------- Batch round 1, loss: 0.544 -------------------------
2023-03-25 17:48:46,629 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:46,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:46,718 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 17:48:49,528 : [INFO]  ------------------------- Batch round 2, loss: 0.5489 -------------------------
2023-03-25 17:48:49,528 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:49,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:49,586 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 17:48:52,355 : [INFO]  ------------------------- Batch round 3, loss: 0.5411 -------------------------
2023-03-25 17:48:52,356 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:52,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:52,454 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 17:48:52,454 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-25 17:48:54,177 : [INFO]  Batch 54: Training set : loss - 0.56, accuracy - 0.7174, recall - 0.9565, AUC - 0.9104, F1 - 0.7719, precision - 0.6471, training time - -11.0 seconds
2023-03-25 17:48:54,177 : [INFO]  Batch 54: Testing set : loss - 0.5563, accuracy - 0.7451, recall - 0.9216, AUC - 0.88, F1 - 0.7833, precision - 0.6812
2023-03-25 17:48:54,184 : [INFO]  Batch 55 initialized 
2023-03-25 17:48:54,742 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:55,076 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 17:49:00,534 : [INFO]  ------------------------- Batch round 1, loss: 0.5764 -------------------------
2023-03-25 17:49:00,534 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:00,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:00,594 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 17:49:03,490 : [INFO]  ------------------------- Batch round 2, loss: 0.5793 -------------------------
2023-03-25 17:49:03,490 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:03,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:03,540 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 17:49:06,513 : [INFO]  ------------------------- Batch round 3, loss: 0.5759 -------------------------
2023-03-25 17:49:06,514 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:06,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:06,524 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 17:49:06,524 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-25 17:49:08,316 : [INFO]  Batch 55: Training set : loss - 0.583, accuracy - 0.7228, recall - 0.8261, AUC - 0.8085, F1 - 0.7488, precision - 0.6847, training time - -11.0 seconds
2023-03-25 17:49:08,317 : [INFO]  Batch 55: Testing set : loss - 0.5848, accuracy - 0.6912, recall - 0.8824, AUC - 0.8466, F1 - 0.7407, precision - 0.6383
2023-03-25 17:49:08,324 : [INFO]  Batch 56 initialized 
2023-03-25 17:49:08,885 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:09,247 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 17:49:14,678 : [INFO]  ------------------------- Batch round 1, loss: 0.5754 -------------------------
2023-03-25 17:49:14,678 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:14,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:14,687 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 17:49:17,700 : [INFO]  ------------------------- Batch round 2, loss: 0.5757 -------------------------
2023-03-25 17:49:17,700 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:17,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:17,709 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 17:49:20,561 : [INFO]  ------------------------- Batch round 3, loss: 0.5796 -------------------------
2023-03-25 17:49:20,561 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:20,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:20,569 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 17:49:20,569 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-25 17:49:22,418 : [INFO]  Batch 56: Training set : loss - 0.5826, accuracy - 0.7065, recall - 0.8696, AUC - 0.8285, F1 - 0.7477, precision - 0.6557, training time - -11.0 seconds
2023-03-25 17:49:22,418 : [INFO]  Batch 56: Testing set : loss - 0.6005, accuracy - 0.6814, recall - 0.902, AUC - 0.8296, F1 - 0.739, precision - 0.6259
2023-03-25 17:49:22,428 : [INFO]  Batch 57 initialized 
2023-03-25 17:49:22,990 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:23,341 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 17:49:28,723 : [INFO]  ------------------------- Batch round 1, loss: 0.5784 -------------------------
2023-03-25 17:49:28,723 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:28,729 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:28,732 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 17:49:31,773 : [INFO]  ------------------------- Batch round 2, loss: 0.5761 -------------------------
2023-03-25 17:49:31,773 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:31,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:31,781 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 17:49:34,631 : [INFO]  ------------------------- Batch round 3, loss: 0.569 -------------------------
2023-03-25 17:49:34,631 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:34,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:34,639 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 17:49:34,639 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-25 17:49:36,425 : [INFO]  Batch 57: Training set : loss - 0.5924, accuracy - 0.6848, recall - 0.8913, AUC - 0.8133, F1 - 0.7387, precision - 0.6308, training time - -11.0 seconds
2023-03-25 17:49:36,426 : [INFO]  Batch 57: Testing set : loss - 0.5815, accuracy - 0.6912, recall - 0.8431, AUC - 0.8317, F1 - 0.7319, precision - 0.6466
2023-03-25 17:49:36,433 : [INFO]  Batch 58 initialized 
2023-03-25 17:49:36,990 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:37,340 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 17:49:42,667 : [INFO]  ------------------------- Batch round 1, loss: 0.5706 -------------------------
2023-03-25 17:49:42,667 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:42,673 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:42,675 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 17:49:45,538 : [INFO]  ------------------------- Batch round 2, loss: 0.5748 -------------------------
2023-03-25 17:49:45,538 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:45,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:45,548 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 17:49:48,382 : [INFO]  ------------------------- Batch round 3, loss: 0.5701 -------------------------
2023-03-25 17:49:48,383 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:48,390 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:48,393 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 17:49:48,393 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-25 17:49:50,236 : [INFO]  Batch 58: Training set : loss - 0.5828, accuracy - 0.7174, recall - 0.913, AUC - 0.8412, F1 - 0.7636, precision - 0.6562, training time - -11.0 seconds
2023-03-25 17:49:50,236 : [INFO]  Batch 58: Testing set : loss - 0.5948, accuracy - 0.6765, recall - 0.8529, AUC - 0.8086, F1 - 0.725, precision - 0.6304
2023-03-25 17:49:50,245 : [INFO]  Batch 59 initialized 
2023-03-25 17:49:50,816 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:51,174 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 17:49:56,411 : [INFO]  ------------------------- Batch round 1, loss: 0.5524 -------------------------
2023-03-25 17:49:56,411 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:56,574 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:56,576 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 17:49:59,338 : [INFO]  ------------------------- Batch round 2, loss: 0.5549 -------------------------
2023-03-25 17:49:59,338 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:59,344 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:59,347 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 17:50:02,116 : [INFO]  ------------------------- Batch round 3, loss: 0.5539 -------------------------
2023-03-25 17:50:02,116 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:02,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:02,124 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 17:50:02,125 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-25 17:50:03,852 : [INFO]  Batch 59: Training set : loss - 0.5628, accuracy - 0.6957, recall - 0.9457, AUC - 0.8967, F1 - 0.7565, precision - 0.6304, training time - -11.0 seconds
2023-03-25 17:50:03,852 : [INFO]  Batch 59: Testing set : loss - 0.5619, accuracy - 0.7157, recall - 0.9314, AUC - 0.8816, F1 - 0.7661, precision - 0.6507
2023-03-25 17:50:03,861 : [INFO]  Batch 60 initialized 
2023-03-25 17:50:04,427 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:04,783 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 17:50:10,161 : [INFO]  ------------------------- Batch round 1, loss: 0.5399 -------------------------
2023-03-25 17:50:10,161 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:10,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:10,170 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 17:50:12,984 : [INFO]  ------------------------- Batch round 2, loss: 0.547 -------------------------
2023-03-25 17:50:12,984 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:13,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:13,041 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 17:50:15,919 : [INFO]  ------------------------- Batch round 3, loss: 0.5423 -------------------------
2023-03-25 17:50:15,919 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:15,925 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:15,928 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 17:50:15,928 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-25 17:50:17,695 : [INFO]  Batch 60: Training set : loss - 0.5527, accuracy - 0.7609, recall - 0.9674, AUC - 0.8707, F1 - 0.8018, precision - 0.6846, training time - -11.0 seconds
2023-03-25 17:50:17,696 : [INFO]  Batch 60: Testing set : loss - 0.5778, accuracy - 0.7157, recall - 0.9608, AUC - 0.8601, F1 - 0.7717, precision - 0.6447
2023-03-25 17:50:17,705 : [INFO]  Batch 61 initialized 
2023-03-25 17:50:18,258 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:18,608 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 17:50:24,001 : [INFO]  ------------------------- Batch round 1, loss: 0.5302 -------------------------
2023-03-25 17:50:24,001 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:24,007 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:24,010 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 17:50:26,872 : [INFO]  ------------------------- Batch round 2, loss: 0.5285 -------------------------
2023-03-25 17:50:26,872 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:26,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:26,961 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 17:50:29,764 : [INFO]  ------------------------- Batch round 3, loss: 0.5243 -------------------------
2023-03-25 17:50:29,764 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:29,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:29,821 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 17:50:29,821 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-25 17:50:31,655 : [INFO]  Batch 61: Training set : loss - 0.5416, accuracy - 0.788, recall - 0.9783, AUC - 0.9086, F1 - 0.8219, precision - 0.7087, training time - -11.0 seconds
2023-03-25 17:50:31,655 : [INFO]  Batch 61: Testing set : loss - 0.599, accuracy - 0.6618, recall - 0.9118, AUC - 0.8423, F1 - 0.7294, precision - 0.6078
2023-03-25 17:50:31,665 : [INFO]  Batch 62 initialized 
2023-03-25 17:50:32,251 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:32,601 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 17:50:37,981 : [INFO]  ------------------------- Batch round 1, loss: 0.586 -------------------------
2023-03-25 17:50:37,981 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:37,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:37,989 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 17:50:40,874 : [INFO]  ------------------------- Batch round 2, loss: 0.5907 -------------------------
2023-03-25 17:50:40,874 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:40,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:40,953 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 17:50:43,957 : [INFO]  ------------------------- Batch round 3, loss: 0.5881 -------------------------
2023-03-25 17:50:43,957 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:43,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:43,965 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 17:50:43,965 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-25 17:50:45,800 : [INFO]  Batch 62: Training set : loss - 0.5979, accuracy - 0.6685, recall - 0.8913, AUC - 0.7949, F1 - 0.7289, precision - 0.6165, training time - -11.0 seconds
2023-03-25 17:50:45,800 : [INFO]  Batch 62: Testing set : loss - 0.5682, accuracy - 0.6618, recall - 0.8627, AUC - 0.8559, F1 - 0.7184, precision - 0.6154
2023-03-25 17:50:45,810 : [INFO]  Batch 63 initialized 
2023-03-25 17:50:46,387 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:46,749 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 17:50:51,972 : [INFO]  ------------------------- Batch round 1, loss: 0.5437 -------------------------
2023-03-25 17:50:51,972 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:51,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:51,990 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 17:50:54,894 : [INFO]  ------------------------- Batch round 2, loss: 0.5403 -------------------------
2023-03-25 17:50:54,894 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:54,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:54,939 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 17:50:57,689 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 17:50:57,689 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:57,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:57,932 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 17:50:57,932 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-25 17:50:59,626 : [INFO]  Batch 63: Training set : loss - 0.5564, accuracy - 0.7337, recall - 0.8804, AUC - 0.8598, F1 - 0.7678, precision - 0.6807, training time - -11.0 seconds
2023-03-25 17:50:59,626 : [INFO]  Batch 63: Testing set : loss - 0.5444, accuracy - 0.7549, recall - 0.9118, AUC - 0.9058, F1 - 0.7881, precision - 0.694
2023-03-25 17:50:59,641 : [INFO]  Batch 64 initialized 
2023-03-25 17:51:00,215 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:00,580 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 17:51:05,841 : [INFO]  ------------------------- Batch round 1, loss: 0.5646 -------------------------
2023-03-25 17:51:05,841 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:05,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:05,853 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 17:51:08,800 : [INFO]  ------------------------- Batch round 2, loss: 0.572 -------------------------
2023-03-25 17:51:08,800 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:08,807 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:08,810 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 17:51:11,757 : [INFO]  ------------------------- Batch round 3, loss: 0.5727 -------------------------
2023-03-25 17:51:11,757 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:11,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:11,767 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 17:51:11,767 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-25 17:51:13,632 : [INFO]  Batch 64: Training set : loss - 0.5995, accuracy - 0.6304, recall - 0.8696, AUC - 0.8361, F1 - 0.7018, precision - 0.5882, training time - -11.0 seconds
2023-03-25 17:51:13,632 : [INFO]  Batch 64: Testing set : loss - 0.5907, accuracy - 0.6422, recall - 0.9412, AUC - 0.8802, F1 - 0.7245, precision - 0.589
2023-03-25 17:51:13,642 : [INFO]  Batch 65 initialized 
2023-03-25 17:51:14,212 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:14,576 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 17:51:19,911 : [INFO]  ------------------------- Batch round 1, loss: 0.5705 -------------------------
2023-03-25 17:51:19,911 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:19,961 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:19,965 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 17:51:22,876 : [INFO]  ------------------------- Batch round 2, loss: 0.5787 -------------------------
2023-03-25 17:51:22,877 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:23,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:23,103 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 17:51:26,063 : [INFO]  ------------------------- Batch round 3, loss: 0.574 -------------------------
2023-03-25 17:51:26,063 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:26,123 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:26,126 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 17:51:26,126 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-25 17:51:27,905 : [INFO]  Batch 65: Training set : loss - 0.5892, accuracy - 0.6902, recall - 0.913, AUC - 0.8426, F1 - 0.7467, precision - 0.6316, training time - -12.0 seconds
2023-03-25 17:51:27,905 : [INFO]  Batch 65: Testing set : loss - 0.606, accuracy - 0.6814, recall - 0.8627, AUC - 0.7735, F1 - 0.7303, precision - 0.6331
2023-03-25 17:51:27,913 : [INFO]  Batch 66 initialized 
2023-03-25 17:51:28,468 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:28,842 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 17:51:34,234 : [INFO]  ------------------------- Batch round 1, loss: 0.5655 -------------------------
2023-03-25 17:51:34,234 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:34,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:34,242 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 17:51:37,118 : [INFO]  ------------------------- Batch round 2, loss: 0.5665 -------------------------
2023-03-25 17:51:37,118 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:37,125 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:37,128 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 17:51:39,950 : [INFO]  ------------------------- Batch round 3, loss: 0.5649 -------------------------
2023-03-25 17:51:39,951 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:39,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:39,960 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 17:51:39,960 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-25 17:51:41,694 : [INFO]  Batch 66: Training set : loss - 0.5795, accuracy - 0.6902, recall - 0.837, AUC - 0.8105, F1 - 0.7299, precision - 0.6471, training time - -11.0 seconds
2023-03-25 17:51:41,695 : [INFO]  Batch 66: Testing set : loss - 0.5953, accuracy - 0.7108, recall - 0.8725, AUC - 0.7689, F1 - 0.7511, precision - 0.6593
2023-03-25 17:51:41,704 : [INFO]  Batch 67 initialized 
2023-03-25 17:51:42,251 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:42,628 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 17:51:48,227 : [INFO]  ------------------------- Batch round 1, loss: 0.5368 -------------------------
2023-03-25 17:51:48,228 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:48,234 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:48,237 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 17:51:51,407 : [INFO]  ------------------------- Batch round 2, loss: 0.538 -------------------------
2023-03-25 17:51:51,407 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:51,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:51,416 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 17:51:54,490 : [INFO]  ------------------------- Batch round 3, loss: 0.5464 -------------------------
2023-03-25 17:51:54,490 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:54,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:54,499 : [INFO]  Batch number 67 model fetched from the server
2023-03-25 17:51:54,499 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-25 17:51:56,471 : [INFO]  Batch 67: Training set : loss - 0.5479, accuracy - 0.7717, recall - 0.9565, AUC - 0.9051, F1 - 0.8073, precision - 0.6984, training time - -12.0 seconds
2023-03-25 17:51:56,472 : [INFO]  Batch 67: Testing set : loss - 0.5815, accuracy - 0.7108, recall - 0.8922, AUC - 0.8506, F1 - 0.7552, precision - 0.6547
2023-03-25 17:51:56,483 : [INFO]  Batch 68 initialized 
2023-03-25 17:51:57,077 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:57,440 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-25 17:52:02,795 : [INFO]  ------------------------- Batch round 1, loss: 0.548 -------------------------
2023-03-25 17:52:02,795 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:02,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:02,805 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-25 17:52:05,593 : [INFO]  ------------------------- Batch round 2, loss: 0.5547 -------------------------
2023-03-25 17:52:05,593 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:05,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:05,602 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-25 17:52:08,397 : [INFO]  ------------------------- Batch round 3, loss: 0.5465 -------------------------
2023-03-25 17:52:08,397 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:08,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:08,422 : [INFO]  Batch number 68 model fetched from the server
2023-03-25 17:52:08,423 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-25 17:52:10,166 : [INFO]  Batch 68: Training set : loss - 0.5584, accuracy - 0.7609, recall - 0.9239, AUC - 0.8871, F1 - 0.7944, precision - 0.6967, training time - -11.0 seconds
2023-03-25 17:52:10,167 : [INFO]  Batch 68: Testing set : loss - 0.5693, accuracy - 0.7353, recall - 0.9412, AUC - 0.855, F1 - 0.7805, precision - 0.6667
2023-03-25 17:52:10,182 : [INFO]  Batch 69 initialized 
2023-03-25 17:52:10,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:11,132 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-25 17:52:16,568 : [INFO]  ------------------------- Batch round 1, loss: 0.5738 -------------------------
2023-03-25 17:52:16,568 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:16,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:16,577 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-25 17:52:19,404 : [INFO]  ------------------------- Batch round 2, loss: 0.5748 -------------------------
2023-03-25 17:52:19,404 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:19,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:19,413 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-25 17:52:22,304 : [INFO]  ------------------------- Batch round 3, loss: 0.5793 -------------------------
2023-03-25 17:52:22,304 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:22,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:22,312 : [INFO]  Batch number 69 model fetched from the server
2023-03-25 17:52:22,312 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-25 17:52:24,133 : [INFO]  Batch 69: Training set : loss - 0.5882, accuracy - 0.6848, recall - 0.8804, AUC - 0.8319, F1 - 0.7364, precision - 0.6328, training time - -11.0 seconds
2023-03-25 17:52:24,134 : [INFO]  Batch 69: Testing set : loss - 0.5633, accuracy - 0.7157, recall - 0.9118, AUC - 0.8833, F1 - 0.7623, precision - 0.6549
2023-03-25 17:52:24,141 : [INFO]  Batch 70 initialized 
2023-03-25 17:52:24,724 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:25,100 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-25 17:52:30,517 : [INFO]  ------------------------- Batch round 1, loss: 0.5568 -------------------------
2023-03-25 17:52:30,517 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:30,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:30,527 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-25 17:52:33,455 : [INFO]  ------------------------- Batch round 2, loss: 0.5644 -------------------------
2023-03-25 17:52:33,455 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:33,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:33,463 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-25 17:52:36,344 : [INFO]  ------------------------- Batch round 3, loss: 0.5603 -------------------------
2023-03-25 17:52:36,344 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:36,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:36,357 : [INFO]  Batch number 70 model fetched from the server
2023-03-25 17:52:36,357 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-25 17:52:38,209 : [INFO]  Batch 70: Training set : loss - 0.573, accuracy - 0.7337, recall - 0.913, AUC - 0.8438, F1 - 0.7742, precision - 0.672, training time - -11.0 seconds
2023-03-25 17:52:38,209 : [INFO]  Batch 70: Testing set : loss - 0.564, accuracy - 0.7549, recall - 0.8824, AUC - 0.8484, F1 - 0.7826, precision - 0.7031
2023-03-25 17:52:38,221 : [INFO]  Batch 71 initialized 
2023-03-25 17:52:38,807 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:39,179 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-25 17:52:44,549 : [INFO]  ------------------------- Batch round 1, loss: 0.5564 -------------------------
2023-03-25 17:52:44,549 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:44,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:44,558 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-25 17:52:47,435 : [INFO]  ------------------------- Batch round 2, loss: 0.5597 -------------------------
2023-03-25 17:52:47,435 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:47,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:47,451 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-25 17:52:50,223 : [INFO]  ------------------------- Batch round 3, loss: 0.5628 -------------------------
2023-03-25 17:52:50,223 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:50,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:50,256 : [INFO]  Batch number 71 model fetched from the server
2023-03-25 17:52:50,256 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-25 17:52:51,985 : [INFO]  Batch 71: Training set : loss - 0.5834, accuracy - 0.6576, recall - 0.8696, AUC - 0.8218, F1 - 0.7175, precision - 0.6107, training time - -11.0 seconds
2023-03-25 17:52:51,986 : [INFO]  Batch 71: Testing set : loss - 0.6025, accuracy - 0.6373, recall - 0.8235, AUC - 0.802, F1 - 0.6942, precision - 0.6
2023-03-25 17:52:51,999 : [INFO]  Batch 72 initialized 
2023-03-25 17:52:52,566 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:52,951 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-25 17:52:58,155 : [INFO]  ------------------------- Batch round 1, loss: 0.5705 -------------------------
2023-03-25 17:52:58,156 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:58,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:58,258 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-25 17:53:00,992 : [INFO]  ------------------------- Batch round 2, loss: 0.5692 -------------------------
2023-03-25 17:53:00,992 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:01,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:01,119 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-25 17:53:03,859 : [INFO]  ------------------------- Batch round 3, loss: 0.5758 -------------------------
2023-03-25 17:53:03,859 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:04,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:04,024 : [INFO]  Batch number 72 model fetched from the server
2023-03-25 17:53:04,024 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-25 17:53:05,757 : [INFO]  Batch 72: Training set : loss - 0.5959, accuracy - 0.6848, recall - 0.8804, AUC - 0.8084, F1 - 0.7364, precision - 0.6328, training time - -11.0 seconds
2023-03-25 17:53:05,757 : [INFO]  Batch 72: Testing set : loss - 0.5872, accuracy - 0.6961, recall - 0.902, AUC - 0.8245, F1 - 0.748, precision - 0.6389
2023-03-25 17:53:05,772 : [INFO]  Batch 73 initialized 
2023-03-25 17:53:06,349 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:06,730 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-25 17:53:12,304 : [INFO]  ------------------------- Batch round 1, loss: 0.5604 -------------------------
2023-03-25 17:53:12,304 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:12,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:12,332 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-25 17:53:15,288 : [INFO]  ------------------------- Batch round 2, loss: 0.5609 -------------------------
2023-03-25 17:53:15,288 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:15,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:15,297 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-25 17:53:18,180 : [INFO]  ------------------------- Batch round 3, loss: 0.5638 -------------------------
2023-03-25 17:53:18,180 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:18,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:18,192 : [INFO]  Batch number 73 model fetched from the server
2023-03-25 17:53:18,192 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-25 17:53:19,992 : [INFO]  Batch 73: Training set : loss - 0.5779, accuracy - 0.712, recall - 0.8804, AUC - 0.851, F1 - 0.7535, precision - 0.6585, training time - -11.0 seconds
2023-03-25 17:53:19,992 : [INFO]  Batch 73: Testing set : loss - 0.5898, accuracy - 0.6912, recall - 0.8235, AUC - 0.7987, F1 - 0.7273, precision - 0.6512
2023-03-25 17:53:20,013 : [INFO]  Batch 74 initialized 
2023-03-25 17:53:20,597 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:20,981 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-25 17:53:26,484 : [INFO]  ------------------------- Batch round 1, loss: 0.5335 -------------------------
2023-03-25 17:53:26,484 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:26,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:26,496 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-25 17:53:29,252 : [INFO]  ------------------------- Batch round 2, loss: 0.538 -------------------------
2023-03-25 17:53:29,252 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:29,260 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:29,263 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-25 17:53:32,109 : [INFO]  ------------------------- Batch round 3, loss: 0.5374 -------------------------
2023-03-25 17:53:32,109 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:32,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:32,118 : [INFO]  Batch number 74 model fetched from the server
2023-03-25 17:53:32,118 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-25 17:53:33,877 : [INFO]  Batch 74: Training set : loss - 0.5468, accuracy - 0.7554, recall - 0.9239, AUC - 0.8891, F1 - 0.7907, precision - 0.6911, training time - -11.0 seconds
2023-03-25 17:53:33,877 : [INFO]  Batch 74: Testing set : loss - 0.5572, accuracy - 0.7745, recall - 0.9118, AUC - 0.8729, F1 - 0.8017, precision - 0.7154
2023-03-25 17:53:33,892 : [INFO]  Batch 75 initialized 
2023-03-25 17:53:34,466 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:34,852 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-25 17:53:40,358 : [INFO]  ------------------------- Batch round 1, loss: 0.5675 -------------------------
2023-03-25 17:53:40,358 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:40,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:40,367 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-25 17:53:43,297 : [INFO]  ------------------------- Batch round 2, loss: 0.5694 -------------------------
2023-03-25 17:53:43,297 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:43,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:43,306 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-25 17:53:46,222 : [INFO]  ------------------------- Batch round 3, loss: 0.5661 -------------------------
2023-03-25 17:53:46,222 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:46,232 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:46,235 : [INFO]  Batch number 75 model fetched from the server
2023-03-25 17:53:46,235 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-25 17:53:48,083 : [INFO]  Batch 75: Training set : loss - 0.5905, accuracy - 0.6739, recall - 0.8043, AUC - 0.8025, F1 - 0.7115, precision - 0.6379, training time - -11.0 seconds
2023-03-25 17:53:48,083 : [INFO]  Batch 75: Testing set : loss - 0.603, accuracy - 0.6618, recall - 0.8235, AUC - 0.784, F1 - 0.7089, precision - 0.6222
2023-03-25 17:53:48,098 : [INFO]  Batch 76 initialized 
2023-03-25 17:53:48,647 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:49,033 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-25 17:53:54,451 : [INFO]  ------------------------- Batch round 1, loss: 0.5851 -------------------------
2023-03-25 17:53:54,451 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:54,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:54,460 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-25 17:53:57,391 : [INFO]  ------------------------- Batch round 2, loss: 0.5824 -------------------------
2023-03-25 17:53:57,391 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:57,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:57,401 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-25 17:54:00,464 : [INFO]  ------------------------- Batch round 3, loss: 0.5797 -------------------------
2023-03-25 17:54:00,464 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:00,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:00,474 : [INFO]  Batch number 76 model fetched from the server
2023-03-25 17:54:00,474 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-25 17:54:02,245 : [INFO]  Batch 76: Training set : loss - 0.5933, accuracy - 0.6793, recall - 0.8261, AUC - 0.8069, F1 - 0.7204, precision - 0.6387, training time - -11.0 seconds
2023-03-25 17:54:02,245 : [INFO]  Batch 76: Testing set : loss - 0.5787, accuracy - 0.6961, recall - 0.9118, AUC - 0.8696, F1 - 0.75, precision - 0.637
2023-03-25 17:54:02,253 : [INFO]  Batch 77 initialized 
2023-03-25 17:54:02,814 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:03,207 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-25 17:54:08,486 : [INFO]  ------------------------- Batch round 1, loss: 0.5803 -------------------------
2023-03-25 17:54:08,486 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:08,494 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:08,496 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-25 17:54:11,327 : [INFO]  ------------------------- Batch round 2, loss: 0.5874 -------------------------
2023-03-25 17:54:11,328 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:11,423 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:11,426 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-25 17:54:14,295 : [INFO]  ------------------------- Batch round 3, loss: 0.5772 -------------------------
2023-03-25 17:54:14,295 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:14,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:14,305 : [INFO]  Batch number 77 model fetched from the server
2023-03-25 17:54:14,306 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-25 17:54:16,104 : [INFO]  Batch 77: Training set : loss - 0.5994, accuracy - 0.6739, recall - 0.8804, AUC - 0.8162, F1 - 0.7297, precision - 0.6231, training time - -11.0 seconds
2023-03-25 17:54:16,104 : [INFO]  Batch 77: Testing set : loss - 0.5761, accuracy - 0.7402, recall - 0.8431, AUC - 0.8319, F1 - 0.7644, precision - 0.6992
2023-03-25 17:54:16,112 : [INFO]  Batch 78 initialized 
2023-03-25 17:54:16,685 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:17,079 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-25 17:54:22,336 : [INFO]  ------------------------- Batch round 1, loss: 0.5409 -------------------------
2023-03-25 17:54:22,336 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:22,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:22,345 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-25 17:54:25,128 : [INFO]  ------------------------- Batch round 2, loss: 0.5443 -------------------------
2023-03-25 17:54:25,128 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:25,187 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:25,190 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-25 17:54:27,953 : [INFO]  ------------------------- Batch round 3, loss: 0.5334 -------------------------
2023-03-25 17:54:27,954 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:28,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:28,045 : [INFO]  Batch number 78 model fetched from the server
2023-03-25 17:54:28,045 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-25 17:54:29,807 : [INFO]  Batch 78: Training set : loss - 0.5517, accuracy - 0.7391, recall - 0.9239, AUC - 0.8722, F1 - 0.7798, precision - 0.6746, training time - -11.0 seconds
2023-03-25 17:54:29,808 : [INFO]  Batch 78: Testing set : loss - 0.5947, accuracy - 0.6814, recall - 0.9216, AUC - 0.8541, F1 - 0.7431, precision - 0.6225
2023-03-25 17:54:29,820 : [INFO]  Batch 79 initialized 
2023-03-25 17:54:30,394 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:30,788 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-25 17:54:36,200 : [INFO]  ------------------------- Batch round 1, loss: 0.5894 -------------------------
2023-03-25 17:54:36,200 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:36,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:36,209 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-25 17:54:39,197 : [INFO]  ------------------------- Batch round 2, loss: 0.587 -------------------------
2023-03-25 17:54:39,197 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:39,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:39,207 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-25 17:54:42,211 : [INFO]  ------------------------- Batch round 3, loss: 0.5909 -------------------------
2023-03-25 17:54:42,212 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:42,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:42,221 : [INFO]  Batch number 79 model fetched from the server
2023-03-25 17:54:42,221 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-25 17:54:44,108 : [INFO]  Batch 79: Training set : loss - 0.6008, accuracy - 0.663, recall - 0.8261, AUC - 0.7864, F1 - 0.7103, precision - 0.623, training time - -11.0 seconds
2023-03-25 17:54:44,108 : [INFO]  Batch 79: Testing set : loss - 0.6115, accuracy - 0.6471, recall - 0.7843, AUC - 0.7672, F1 - 0.6897, precision - 0.6154
2023-03-25 17:54:44,115 : [INFO]  Batch 80 initialized 
2023-03-25 17:54:44,681 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:45,066 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-25 17:54:50,540 : [INFO]  ------------------------- Batch round 1, loss: 0.5886 -------------------------
2023-03-25 17:54:50,540 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:50,547 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:50,550 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-25 17:54:53,448 : [INFO]  ------------------------- Batch round 2, loss: 0.5924 -------------------------
2023-03-25 17:54:53,448 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:53,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:53,519 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-25 17:54:56,469 : [INFO]  ------------------------- Batch round 3, loss: 0.5873 -------------------------
2023-03-25 17:54:56,469 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:56,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:56,523 : [INFO]  Batch number 80 model fetched from the server
2023-03-25 17:54:56,523 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-25 17:54:58,301 : [INFO]  Batch 80: Training set : loss - 0.5921, accuracy - 0.6902, recall - 0.8478, AUC - 0.7797, F1 - 0.7324, precision - 0.6446, training time - -11.0 seconds
2023-03-25 17:54:58,302 : [INFO]  Batch 80: Testing set : loss - 0.5766, accuracy - 0.6961, recall - 0.8333, AUC - 0.8358, F1 - 0.7328, precision - 0.6538
2023-03-25 17:54:58,309 : [INFO]  Batch 81 initialized 
2023-03-25 17:54:58,893 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:59,271 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-25 17:55:04,660 : [INFO]  ------------------------- Batch round 1, loss: 0.578 -------------------------
2023-03-25 17:55:04,660 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:04,742 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:04,744 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-25 17:55:07,601 : [INFO]  ------------------------- Batch round 2, loss: 0.578 -------------------------
2023-03-25 17:55:07,601 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:07,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:07,613 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-25 17:55:10,498 : [INFO]  ------------------------- Batch round 3, loss: 0.5787 -------------------------
2023-03-25 17:55:10,498 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:10,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:10,545 : [INFO]  Batch number 81 model fetched from the server
2023-03-25 17:55:10,545 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-25 17:55:12,343 : [INFO]  Batch 81: Training set : loss - 0.5913, accuracy - 0.7228, recall - 0.8913, AUC - 0.7856, F1 - 0.7628, precision - 0.6667, training time - -11.0 seconds
2023-03-25 17:55:12,344 : [INFO]  Batch 81: Testing set : loss - 0.5944, accuracy - 0.6765, recall - 0.8725, AUC - 0.8246, F1 - 0.7295, precision - 0.6268
2023-03-25 17:55:12,351 : [INFO]  Batch 82 initialized 
2023-03-25 17:55:13,021 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:13,420 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-25 17:55:18,960 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-25 17:55:18,960 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:18,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:18,970 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-25 17:55:21,792 : [INFO]  ------------------------- Batch round 2, loss: 0.5636 -------------------------
2023-03-25 17:55:21,792 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:21,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:21,821 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-25 17:55:24,675 : [INFO]  ------------------------- Batch round 3, loss: 0.5649 -------------------------
2023-03-25 17:55:24,675 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:24,694 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:24,699 : [INFO]  Batch number 82 model fetched from the server
2023-03-25 17:55:24,699 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-25 17:55:26,480 : [INFO]  Batch 82: Training set : loss - 0.5715, accuracy - 0.7391, recall - 0.8804, AUC - 0.8319, F1 - 0.7714, precision - 0.6864, training time - -11.0 seconds
2023-03-25 17:55:26,480 : [INFO]  Batch 82: Testing set : loss - 0.588, accuracy - 0.7059, recall - 0.8725, AUC - 0.8176, F1 - 0.7479, precision - 0.6544
2023-03-25 17:55:26,491 : [INFO]  Batch 83 initialized 
2023-03-25 17:55:27,073 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:27,476 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-25 17:55:32,879 : [INFO]  ------------------------- Batch round 1, loss: 0.5468 -------------------------
2023-03-25 17:55:32,879 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:32,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:32,888 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-25 17:55:35,681 : [INFO]  ------------------------- Batch round 2, loss: 0.5535 -------------------------
2023-03-25 17:55:35,681 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:35,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:35,728 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-25 17:55:38,546 : [INFO]  ------------------------- Batch round 3, loss: 0.5571 -------------------------
2023-03-25 17:55:38,546 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:38,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:38,555 : [INFO]  Batch number 83 model fetched from the server
2023-03-25 17:55:38,555 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-25 17:55:40,476 : [INFO]  Batch 83: Training set : loss - 0.5659, accuracy - 0.7174, recall - 0.9565, AUC - 0.8935, F1 - 0.7719, precision - 0.6471, training time - -11.0 seconds
2023-03-25 17:55:40,477 : [INFO]  Batch 83: Testing set : loss - 0.5855, accuracy - 0.6716, recall - 0.8824, AUC - 0.8138, F1 - 0.7287, precision - 0.6207
2023-03-25 17:55:40,485 : [INFO]  Batch 84 initialized 
2023-03-25 17:55:41,076 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:41,477 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-25 17:55:46,796 : [INFO]  ------------------------- Batch round 1, loss: 0.5336 -------------------------
2023-03-25 17:55:46,796 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:46,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:46,875 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-25 17:55:49,642 : [INFO]  ------------------------- Batch round 2, loss: 0.5347 -------------------------
2023-03-25 17:55:49,643 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:49,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:49,768 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-25 17:55:52,583 : [INFO]  ------------------------- Batch round 3, loss: 0.5366 -------------------------
2023-03-25 17:55:52,583 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:52,704 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:52,707 : [INFO]  Batch number 84 model fetched from the server
2023-03-25 17:55:52,707 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-25 17:55:54,480 : [INFO]  Batch 84: Training set : loss - 0.5471, accuracy - 0.7337, recall - 0.9457, AUC - 0.9008, F1 - 0.7803, precision - 0.6641, training time - -11.0 seconds
2023-03-25 17:55:54,481 : [INFO]  Batch 84: Testing set : loss - 0.5744, accuracy - 0.6814, recall - 0.8824, AUC - 0.8313, F1 - 0.7347, precision - 0.6294
2023-03-25 17:55:54,495 : [INFO]  Batch 85 initialized 
2023-03-25 17:55:55,080 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:55,491 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-25 17:56:00,876 : [INFO]  ------------------------- Batch round 1, loss: 0.579 -------------------------
2023-03-25 17:56:00,876 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:00,883 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:00,885 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-25 17:56:03,691 : [INFO]  ------------------------- Batch round 2, loss: 0.5923 -------------------------
2023-03-25 17:56:03,691 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:03,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:03,704 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-25 17:56:06,478 : [INFO]  ------------------------- Batch round 3, loss: 0.5903 -------------------------
2023-03-25 17:56:06,478 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:06,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:06,488 : [INFO]  Batch number 85 model fetched from the server
2023-03-25 17:56:06,488 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-25 17:56:08,224 : [INFO]  Batch 85: Training set : loss - 0.6032, accuracy - 0.6576, recall - 0.8587, AUC - 0.7739, F1 - 0.7149, precision - 0.6124, training time - -11.0 seconds
2023-03-25 17:56:08,224 : [INFO]  Batch 85: Testing set : loss - 0.582, accuracy - 0.6912, recall - 0.8431, AUC - 0.835, F1 - 0.7319, precision - 0.6466
2023-03-25 17:56:08,236 : [INFO]  Batch 86 initialized 
2023-03-25 17:56:08,791 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:09,196 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-25 17:56:14,714 : [INFO]  ------------------------- Batch round 1, loss: 0.5962 -------------------------
2023-03-25 17:56:14,714 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:14,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:14,724 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-25 17:56:17,611 : [INFO]  ------------------------- Batch round 2, loss: 0.6011 -------------------------
2023-03-25 17:56:17,611 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:17,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:17,620 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-25 17:56:20,546 : [INFO]  ------------------------- Batch round 3, loss: 0.5938 -------------------------
2023-03-25 17:56:20,546 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:20,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:20,555 : [INFO]  Batch number 86 model fetched from the server
2023-03-25 17:56:20,555 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-25 17:56:22,448 : [INFO]  Batch 86: Training set : loss - 0.6201, accuracy - 0.663, recall - 0.8913, AUC - 0.7588, F1 - 0.7257, precision - 0.6119, training time - -11.0 seconds
2023-03-25 17:56:22,448 : [INFO]  Batch 86: Testing set : loss - 0.6089, accuracy - 0.701, recall - 0.8824, AUC - 0.7591, F1 - 0.7469, precision - 0.6475
2023-03-25 17:56:22,456 : [INFO]  Batch 87 initialized 
2023-03-25 17:56:23,042 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:23,450 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-25 17:56:28,790 : [INFO]  ------------------------- Batch round 1, loss: 0.545 -------------------------
2023-03-25 17:56:28,790 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:28,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:28,800 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-25 17:56:31,662 : [INFO]  ------------------------- Batch round 2, loss: 0.5456 -------------------------
2023-03-25 17:56:31,662 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:31,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:31,673 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-25 17:56:34,399 : [INFO]  ------------------------- Batch round 3, loss: 0.5495 -------------------------
2023-03-25 17:56:34,399 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:34,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:34,583 : [INFO]  Batch number 87 model fetched from the server
2023-03-25 17:56:34,583 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-25 17:56:36,382 : [INFO]  Batch 87: Training set : loss - 0.5553, accuracy - 0.7391, recall - 0.9239, AUC - 0.879, F1 - 0.7798, precision - 0.6746, training time - -11.0 seconds
2023-03-25 17:56:36,382 : [INFO]  Batch 87: Testing set : loss - 0.5604, accuracy - 0.7402, recall - 0.9216, AUC - 0.8909, F1 - 0.7801, precision - 0.6763
2023-03-25 17:56:36,390 : [INFO]  Batch 88 initialized 
2023-03-25 17:56:36,962 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:37,373 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-25 17:56:42,705 : [INFO]  ------------------------- Batch round 1, loss: 0.5537 -------------------------
2023-03-25 17:56:42,706 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:42,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:42,750 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-25 17:56:45,656 : [INFO]  ------------------------- Batch round 2, loss: 0.5585 -------------------------
2023-03-25 17:56:45,657 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:45,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:45,666 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-25 17:56:48,393 : [INFO]  ------------------------- Batch round 3, loss: 0.5594 -------------------------
2023-03-25 17:56:48,393 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:48,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:48,508 : [INFO]  Batch number 88 model fetched from the server
2023-03-25 17:56:48,508 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-25 17:56:50,255 : [INFO]  Batch 88: Training set : loss - 0.5852, accuracy - 0.6467, recall - 0.9239, AUC - 0.8899, F1 - 0.7234, precision - 0.5944, training time - -11.0 seconds
2023-03-25 17:56:50,255 : [INFO]  Batch 88: Testing set : loss - 0.5917, accuracy - 0.6569, recall - 0.9412, AUC - 0.8831, F1 - 0.7328, precision - 0.6
2023-03-25 17:56:50,270 : [INFO]  Batch 89 initialized 
2023-03-25 17:56:50,832 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:51,255 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-25 17:56:56,511 : [INFO]  ------------------------- Batch round 1, loss: 0.5494 -------------------------
2023-03-25 17:56:56,512 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:56,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:56,632 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-25 17:56:59,365 : [INFO]  ------------------------- Batch round 2, loss: 0.5561 -------------------------
2023-03-25 17:56:59,365 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:59,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:59,374 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-25 17:57:02,343 : [INFO]  ------------------------- Batch round 3, loss: 0.5578 -------------------------
2023-03-25 17:57:02,344 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:02,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:02,356 : [INFO]  Batch number 89 model fetched from the server
2023-03-25 17:57:02,356 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-25 17:57:04,179 : [INFO]  Batch 89: Training set : loss - 0.5703, accuracy - 0.7174, recall - 0.913, AUC - 0.8725, F1 - 0.7636, precision - 0.6562, training time - -11.0 seconds
2023-03-25 17:57:04,180 : [INFO]  Batch 89: Testing set : loss - 0.5796, accuracy - 0.6863, recall - 0.8627, AUC - 0.8537, F1 - 0.7333, precision - 0.6377
2023-03-25 17:57:04,189 : [INFO]  Batch 90 initialized 
2023-03-25 17:57:04,756 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:05,173 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-25 17:57:10,615 : [INFO]  ------------------------- Batch round 1, loss: 0.5597 -------------------------
2023-03-25 17:57:10,615 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:10,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:10,626 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-25 17:57:13,482 : [INFO]  ------------------------- Batch round 2, loss: 0.5585 -------------------------
2023-03-25 17:57:13,483 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:13,490 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:13,493 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-25 17:57:16,411 : [INFO]  ------------------------- Batch round 3, loss: 0.5606 -------------------------
2023-03-25 17:57:16,411 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:16,420 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:16,423 : [INFO]  Batch number 90 model fetched from the server
2023-03-25 17:57:16,423 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-25 17:57:18,156 : [INFO]  Batch 90: Training set : loss - 0.5807, accuracy - 0.6902, recall - 0.8804, AUC - 0.8514, F1 - 0.7397, precision - 0.6378, training time - -11.0 seconds
2023-03-25 17:57:18,156 : [INFO]  Batch 90: Testing set : loss - 0.5987, accuracy - 0.652, recall - 0.8922, AUC - 0.8265, F1 - 0.7194, precision - 0.6026
2023-03-25 17:57:18,170 : [INFO]  Batch 91 initialized 
2023-03-25 17:57:18,739 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:19,154 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-25 17:57:24,549 : [INFO]  ------------------------- Batch round 1, loss: 0.5403 -------------------------
2023-03-25 17:57:24,549 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:24,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:24,630 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-25 17:57:27,464 : [INFO]  ------------------------- Batch round 2, loss: 0.5404 -------------------------
2023-03-25 17:57:27,464 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:27,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:27,527 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-25 17:57:30,328 : [INFO]  ------------------------- Batch round 3, loss: 0.5444 -------------------------
2023-03-25 17:57:30,329 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:30,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:30,406 : [INFO]  Batch number 91 model fetched from the server
2023-03-25 17:57:30,406 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-25 17:57:32,189 : [INFO]  Batch 91: Training set : loss - 0.5456, accuracy - 0.8043, recall - 0.8587, AUC - 0.8331, F1 - 0.8144, precision - 0.7745, training time - -11.0 seconds
2023-03-25 17:57:32,189 : [INFO]  Batch 91: Testing set : loss - 0.5965, accuracy - 0.7304, recall - 0.8627, AUC - 0.7689, F1 - 0.7619, precision - 0.6822
2023-03-25 17:57:32,200 : [INFO]  Batch 92 initialized 
2023-03-25 17:57:32,778 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:33,195 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-25 17:57:38,708 : [INFO]  ------------------------- Batch round 1, loss: 0.5487 -------------------------
2023-03-25 17:57:38,708 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:38,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:38,719 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-25 17:57:41,827 : [INFO]  ------------------------- Batch round 2, loss: 0.5511 -------------------------
2023-03-25 17:57:41,827 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:41,835 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:41,837 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-25 17:57:44,869 : [INFO]  ------------------------- Batch round 3, loss: 0.5479 -------------------------
2023-03-25 17:57:44,869 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:44,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:44,879 : [INFO]  Batch number 92 model fetched from the server
2023-03-25 17:57:44,879 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-25 17:57:46,746 : [INFO]  Batch 92: Training set : loss - 0.5638, accuracy - 0.7446, recall - 0.913, AUC - 0.8842, F1 - 0.7814, precision - 0.6829, training time - -12.0 seconds
2023-03-25 17:57:46,747 : [INFO]  Batch 92: Testing set : loss - 0.5843, accuracy - 0.6912, recall - 0.9118, AUC - 0.8659, F1 - 0.747, precision - 0.6327
2023-03-25 17:57:46,778 : [INFO]  Batch 93 initialized 
2023-03-25 17:57:47,448 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:47,849 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-25 17:57:53,205 : [INFO]  ------------------------- Batch round 1, loss: 0.5752 -------------------------
2023-03-25 17:57:53,205 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:53,211 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:53,215 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-25 17:57:56,088 : [INFO]  ------------------------- Batch round 2, loss: 0.5747 -------------------------
2023-03-25 17:57:56,088 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:56,096 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:56,101 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-25 17:57:58,979 : [INFO]  ------------------------- Batch round 3, loss: 0.5777 -------------------------
2023-03-25 17:57:58,979 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:58,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:58,989 : [INFO]  Batch number 93 model fetched from the server
2023-03-25 17:57:58,989 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-25 17:58:00,761 : [INFO]  Batch 93: Training set : loss - 0.5944, accuracy - 0.6957, recall - 0.9348, AUC - 0.8374, F1 - 0.7544, precision - 0.6324, training time - -11.0 seconds
2023-03-25 17:58:00,761 : [INFO]  Batch 93: Testing set : loss - 0.6086, accuracy - 0.6569, recall - 0.8529, AUC - 0.8082, F1 - 0.7131, precision - 0.6127
2023-03-25 17:58:00,770 : [INFO]  Batch 94 initialized 
2023-03-25 17:58:01,347 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:01,778 : [INFO]  ------------------------- Batch 94 training: round 1 -------------------------
2023-03-25 17:58:07,281 : [INFO]  ------------------------- Batch round 1, loss: 0.5949 -------------------------
2023-03-25 17:58:07,281 : [INFO]  ------------------------- Batch 94, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:07,289 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:07,292 : [INFO]  ------------------------- Batch 94 training: round 2 -------------------------
2023-03-25 17:58:10,193 : [INFO]  ------------------------- Batch round 2, loss: 0.6009 -------------------------
2023-03-25 17:58:10,193 : [INFO]  ------------------------- Batch 94, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:10,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:10,203 : [INFO]  ------------------------- Batch 94 training: round 3 -------------------------
2023-03-25 17:58:13,121 : [INFO]  ------------------------- Batch round 3, loss: 0.6038 -------------------------
2023-03-25 17:58:13,121 : [INFO]  ------------------------- Batch 94, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:13,130 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:13,133 : [INFO]  Batch number 94 model fetched from the server
2023-03-25 17:58:13,133 : [INFO]  ################ Batch 94: final global model evalution after 3 rounds ################
2023-03-25 17:58:14,891 : [INFO]  Batch 94: Training set : loss - 0.6239, accuracy - 0.587, recall - 0.837, AUC - 0.7725, F1 - 0.6696, precision - 0.558, training time - -11.0 seconds
2023-03-25 17:58:14,892 : [INFO]  Batch 94: Testing set : loss - 0.5679, accuracy - 0.701, recall - 0.9608, AUC - 0.8915, F1 - 0.7626, precision - 0.6323
2023-03-25 17:58:14,906 : [INFO]  Batch 95 initialized 
2023-03-25 17:58:15,470 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:15,891 : [INFO]  ------------------------- Batch 95 training: round 1 -------------------------
2023-03-25 17:58:21,174 : [INFO]  ------------------------- Batch round 1, loss: 0.5273 -------------------------
2023-03-25 17:58:21,175 : [INFO]  ------------------------- Batch 95, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:21,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:21,305 : [INFO]  ------------------------- Batch 95 training: round 2 -------------------------
2023-03-25 17:58:24,026 : [INFO]  ------------------------- Batch round 2, loss: 0.5273 -------------------------
2023-03-25 17:58:24,026 : [INFO]  ------------------------- Batch 95, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:24,308 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:24,310 : [INFO]  ------------------------- Batch 95 training: round 3 -------------------------
2023-03-25 17:58:26,989 : [INFO]  ------------------------- Batch round 3, loss: 0.5246 -------------------------
2023-03-25 17:58:26,989 : [INFO]  ------------------------- Batch 95, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:27,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:27,184 : [INFO]  Batch number 95 model fetched from the server
2023-03-25 17:58:27,184 : [INFO]  ################ Batch 95: final global model evalution after 3 rounds ################
2023-03-25 17:58:28,873 : [INFO]  Batch 95: Training set : loss - 0.5359, accuracy - 0.7989, recall - 0.9565, AUC - 0.9306, F1 - 0.8263, precision - 0.7273, training time - -11.0 seconds
2023-03-25 17:58:28,874 : [INFO]  Batch 95: Testing set : loss - 0.5395, accuracy - 0.7843, recall - 0.9412, AUC - 0.9068, F1 - 0.8136, precision - 0.7164
2023-03-25 17:58:28,890 : [INFO]  Batch 96 initialized 
2023-03-25 17:58:29,470 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:29,884 : [INFO]  ------------------------- Batch 96 training: round 1 -------------------------
2023-03-25 17:58:35,467 : [INFO]  ------------------------- Batch round 1, loss: 0.5782 -------------------------
2023-03-25 17:58:35,467 : [INFO]  ------------------------- Batch 96, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:35,498 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:35,502 : [INFO]  ------------------------- Batch 96 training: round 2 -------------------------
2023-03-25 17:58:38,589 : [INFO]  ------------------------- Batch round 2, loss: 0.5779 -------------------------
2023-03-25 17:58:38,589 : [INFO]  ------------------------- Batch 96, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:38,597 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:38,600 : [INFO]  ------------------------- Batch 96 training: round 3 -------------------------
2023-03-25 17:58:41,571 : [INFO]  ------------------------- Batch round 3, loss: 0.5759 -------------------------
2023-03-25 17:58:41,571 : [INFO]  ------------------------- Batch 96, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:41,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:41,628 : [INFO]  Batch number 96 model fetched from the server
2023-03-25 17:58:41,628 : [INFO]  ################ Batch 96: final global model evalution after 3 rounds ################
2023-03-25 17:58:43,469 : [INFO]  Batch 96: Training set : loss - 0.5889, accuracy - 0.7174, recall - 0.9457, AUC - 0.8232, F1 - 0.7699, precision - 0.6493, training time - -12.0 seconds
2023-03-25 17:58:43,469 : [INFO]  Batch 96: Testing set : loss - 0.5731, accuracy - 0.7157, recall - 0.8725, AUC - 0.8366, F1 - 0.7542, precision - 0.6642
2023-03-25 17:58:43,484 : [INFO]  Batch 97 initialized 
2023-03-25 17:58:44,060 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:44,478 : [INFO]  ------------------------- Batch 97 training: round 1 -------------------------
2023-03-25 17:58:49,867 : [INFO]  ------------------------- Batch round 1, loss: 0.5606 -------------------------
2023-03-25 17:58:49,867 : [INFO]  ------------------------- Batch 97, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:49,875 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:49,878 : [INFO]  ------------------------- Batch 97 training: round 2 -------------------------
2023-03-25 17:58:52,932 : [INFO]  ------------------------- Batch round 2, loss: 0.5604 -------------------------
2023-03-25 17:58:52,932 : [INFO]  ------------------------- Batch 97, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:52,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:52,942 : [INFO]  ------------------------- Batch 97 training: round 3 -------------------------
2023-03-25 17:58:55,864 : [INFO]  ------------------------- Batch round 3, loss: 0.5596 -------------------------
2023-03-25 17:58:55,864 : [INFO]  ------------------------- Batch 97, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:55,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:55,874 : [INFO]  Batch number 97 model fetched from the server
2023-03-25 17:58:55,874 : [INFO]  ################ Batch 97: final global model evalution after 3 rounds ################
2023-03-25 17:58:57,722 : [INFO]  Batch 97: Training set : loss - 0.5841, accuracy - 0.7174, recall - 0.9239, AUC - 0.8416, F1 - 0.7658, precision - 0.6538, training time - -11.0 seconds
2023-03-25 17:58:57,722 : [INFO]  Batch 97: Testing set : loss - 0.5809, accuracy - 0.7157, recall - 0.8824, AUC - 0.8145, F1 - 0.7563, precision - 0.6618
2023-03-25 17:58:57,730 : [INFO]  Batch 98 initialized 
2023-03-25 17:58:58,322 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:58,740 : [INFO]  ------------------------- Batch 98 training: round 1 -------------------------
2023-03-25 17:59:04,319 : [INFO]  ------------------------- Batch round 1, loss: 0.5601 -------------------------
2023-03-25 17:59:04,319 : [INFO]  ------------------------- Batch 98, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:04,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:04,329 : [INFO]  ------------------------- Batch 98 training: round 2 -------------------------
2023-03-25 17:59:07,263 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 17:59:07,263 : [INFO]  ------------------------- Batch 98, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:07,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:07,345 : [INFO]  ------------------------- Batch 98 training: round 3 -------------------------
2023-03-25 17:59:10,268 : [INFO]  ------------------------- Batch round 3, loss: 0.5589 -------------------------
2023-03-25 17:59:10,268 : [INFO]  ------------------------- Batch 98, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:10,276 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:10,279 : [INFO]  Batch number 98 model fetched from the server
2023-03-25 17:59:10,279 : [INFO]  ################ Batch 98: final global model evalution after 3 rounds ################
2023-03-25 17:59:12,057 : [INFO]  Batch 98: Training set : loss - 0.5777, accuracy - 0.7011, recall - 0.8913, AUC - 0.8326, F1 - 0.7489, precision - 0.6457, training time - -12.0 seconds
2023-03-25 17:59:12,057 : [INFO]  Batch 98: Testing set : loss - 0.5766, accuracy - 0.7157, recall - 0.8725, AUC - 0.8438, F1 - 0.7542, precision - 0.6642
2023-03-25 17:59:12,067 : [INFO]  Batch 99 initialized 
2023-03-25 17:59:12,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:13,061 : [INFO]  ------------------------- Batch 99 training: round 1 -------------------------
2023-03-25 17:59:18,647 : [INFO]  ------------------------- Batch round 1, loss: 0.5835 -------------------------
2023-03-25 17:59:18,648 : [INFO]  ------------------------- Batch 99, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:18,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:18,657 : [INFO]  ------------------------- Batch 99 training: round 2 -------------------------
2023-03-25 17:59:21,560 : [INFO]  ------------------------- Batch round 2, loss: 0.5825 -------------------------
2023-03-25 17:59:21,560 : [INFO]  ------------------------- Batch 99, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:21,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:21,570 : [INFO]  ------------------------- Batch 99 training: round 3 -------------------------
2023-03-25 17:59:24,478 : [INFO]  ------------------------- Batch round 3, loss: 0.581 -------------------------
2023-03-25 17:59:24,478 : [INFO]  ------------------------- Batch 99, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:24,486 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:24,488 : [INFO]  Batch number 99 model fetched from the server
2023-03-25 17:59:24,488 : [INFO]  ################ Batch 99: final global model evalution after 3 rounds ################
2023-03-25 17:59:26,227 : [INFO]  Batch 99: Training set : loss - 0.5951, accuracy - 0.6848, recall - 0.8587, AUC - 0.7719, F1 - 0.7315, precision - 0.6371, training time - -11.0 seconds
2023-03-25 17:59:26,227 : [INFO]  Batch 99: Testing set : loss - 0.5738, accuracy - 0.6912, recall - 0.9314, AUC - 0.8598, F1 - 0.751, precision - 0.6291
2023-03-25 17:59:26,241 : [INFO]  Batch 100 initialized 
2023-03-25 17:59:26,799 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:27,224 : [INFO]  ------------------------- Batch 100 training: round 1 -------------------------
2023-03-25 17:59:32,478 : [INFO]  ------------------------- Batch round 1, loss: 0.5767 -------------------------
2023-03-25 17:59:32,478 : [INFO]  ------------------------- Batch 100, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:32,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:32,515 : [INFO]  ------------------------- Batch 100 training: round 2 -------------------------
2023-03-25 17:59:35,248 : [INFO]  ------------------------- Batch round 2, loss: 0.5804 -------------------------
2023-03-25 17:59:35,248 : [INFO]  ------------------------- Batch 100, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:35,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:35,313 : [INFO]  ------------------------- Batch 100 training: round 3 -------------------------
2023-03-25 17:59:38,228 : [INFO]  ------------------------- Batch round 3, loss: 0.5834 -------------------------
2023-03-25 17:59:38,228 : [INFO]  ------------------------- Batch 100, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:38,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:38,292 : [INFO]  Batch number 100 model fetched from the server
2023-03-25 17:59:38,292 : [INFO]  ################ Batch 100: final global model evalution after 3 rounds ################
2023-03-25 17:59:40,040 : [INFO]  Batch 100: Training set : loss - 0.5947, accuracy - 0.6793, recall - 0.9239, AUC - 0.8095, F1 - 0.7424, precision - 0.6204, training time - -11.0 seconds
2023-03-25 17:59:40,041 : [INFO]  Batch 100: Testing set : loss - 0.6023, accuracy - 0.6324, recall - 0.902, AUC - 0.8446, F1 - 0.7104, precision - 0.586
2023-03-25 17:59:40,054 : [INFO]  Batch 101 initialized 
2023-03-25 17:59:40,644 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:41,083 : [INFO]  ------------------------- Batch 101 training: round 1 -------------------------
2023-03-25 17:59:46,425 : [INFO]  ------------------------- Batch round 1, loss: 0.5555 -------------------------
2023-03-25 17:59:46,425 : [INFO]  ------------------------- Batch 101, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:46,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:46,435 : [INFO]  ------------------------- Batch 101 training: round 2 -------------------------
2023-03-25 17:59:49,290 : [INFO]  ------------------------- Batch round 2, loss: 0.5557 -------------------------
2023-03-25 17:59:49,290 : [INFO]  ------------------------- Batch 101, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:49,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:49,300 : [INFO]  ------------------------- Batch 101 training: round 3 -------------------------
2023-03-25 17:59:52,077 : [INFO]  ------------------------- Batch round 3, loss: 0.552 -------------------------
2023-03-25 17:59:52,077 : [INFO]  ------------------------- Batch 101, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:52,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:52,087 : [INFO]  Batch number 101 model fetched from the server
2023-03-25 17:59:52,087 : [INFO]  ################ Batch 101: final global model evalution after 3 rounds ################
2023-03-25 17:59:53,808 : [INFO]  Batch 101: Training set : loss - 0.5611, accuracy - 0.7446, recall - 0.9457, AUC - 0.8989, F1 - 0.7873, precision - 0.6744, training time - -11.0 seconds
2023-03-25 17:59:53,808 : [INFO]  Batch 101: Testing set : loss - 0.5612, accuracy - 0.75, recall - 0.8824, AUC - 0.8564, F1 - 0.7792, precision - 0.6977
2023-03-25 17:59:53,819 : [INFO]  Batch 102 initialized 
2023-03-25 17:59:54,416 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:54,855 : [INFO]  ------------------------- Batch 102 training: round 1 -------------------------
2023-03-25 18:00:00,368 : [INFO]  ------------------------- Batch round 1, loss: 0.5787 -------------------------
2023-03-25 18:00:00,368 : [INFO]  ------------------------- Batch 102, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:00,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:00,378 : [INFO]  ------------------------- Batch 102 training: round 2 -------------------------
2023-03-25 18:00:03,306 : [INFO]  ------------------------- Batch round 2, loss: 0.5797 -------------------------
2023-03-25 18:00:03,306 : [INFO]  ------------------------- Batch 102, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:03,313 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:03,316 : [INFO]  ------------------------- Batch 102 training: round 3 -------------------------
2023-03-25 18:00:06,242 : [INFO]  ------------------------- Batch round 3, loss: 0.5731 -------------------------
2023-03-25 18:00:06,242 : [INFO]  ------------------------- Batch 102, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:06,249 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:06,252 : [INFO]  Batch number 102 model fetched from the server
2023-03-25 18:00:06,252 : [INFO]  ################ Batch 102: final global model evalution after 3 rounds ################
2023-03-25 18:00:08,101 : [INFO]  Batch 102: Training set : loss - 0.5852, accuracy - 0.7065, recall - 0.9348, AUC - 0.838, F1 - 0.7611, precision - 0.6418, training time - -11.0 seconds
2023-03-25 18:00:08,102 : [INFO]  Batch 102: Testing set : loss - 0.5968, accuracy - 0.6716, recall - 0.8725, AUC - 0.8104, F1 - 0.7265, precision - 0.6224
2023-03-25 18:00:08,109 : [INFO]  Batch 103 initialized 
2023-03-25 18:00:08,685 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:09,107 : [INFO]  ------------------------- Batch 103 training: round 1 -------------------------
2023-03-25 18:00:14,616 : [INFO]  ------------------------- Batch round 1, loss: 0.5539 -------------------------
2023-03-25 18:00:14,616 : [INFO]  ------------------------- Batch 103, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:14,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:14,626 : [INFO]  ------------------------- Batch 103 training: round 2 -------------------------
2023-03-25 18:00:17,474 : [INFO]  ------------------------- Batch round 2, loss: 0.5488 -------------------------
2023-03-25 18:00:17,474 : [INFO]  ------------------------- Batch 103, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:17,534 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:17,537 : [INFO]  ------------------------- Batch 103 training: round 3 -------------------------
2023-03-25 18:00:20,431 : [INFO]  ------------------------- Batch round 3, loss: 0.5507 -------------------------
2023-03-25 18:00:20,431 : [INFO]  ------------------------- Batch 103, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:20,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:20,441 : [INFO]  Batch number 103 model fetched from the server
2023-03-25 18:00:20,442 : [INFO]  ################ Batch 103: final global model evalution after 3 rounds ################
2023-03-25 18:00:22,253 : [INFO]  Batch 103: Training set : loss - 0.5595, accuracy - 0.7174, recall - 0.8913, AUC - 0.8507, F1 - 0.7593, precision - 0.6613, training time - -11.0 seconds
2023-03-25 18:00:22,253 : [INFO]  Batch 103: Testing set : loss - 0.5671, accuracy - 0.701, recall - 0.8824, AUC - 0.8651, F1 - 0.7469, precision - 0.6475
2023-03-25 18:00:22,269 : [INFO]  Batch 104 initialized 
2023-03-25 18:00:22,841 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:23,293 : [INFO]  ------------------------- Batch 104 training: round 1 -------------------------
2023-03-25 18:00:28,727 : [INFO]  ------------------------- Batch round 1, loss: 0.6062 -------------------------
2023-03-25 18:00:28,728 : [INFO]  ------------------------- Batch 104, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:28,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:28,737 : [INFO]  ------------------------- Batch 104 training: round 2 -------------------------
2023-03-25 18:00:31,676 : [INFO]  ------------------------- Batch round 2, loss: 0.6128 -------------------------
2023-03-25 18:00:31,676 : [INFO]  ------------------------- Batch 104, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:31,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:31,687 : [INFO]  ------------------------- Batch 104 training: round 3 -------------------------
2023-03-25 18:00:34,641 : [INFO]  ------------------------- Batch round 3, loss: 0.6089 -------------------------
2023-03-25 18:00:34,642 : [INFO]  ------------------------- Batch 104, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:34,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:34,652 : [INFO]  Batch number 104 model fetched from the server
2023-03-25 18:00:34,652 : [INFO]  ################ Batch 104: final global model evalution after 3 rounds ################
2023-03-25 18:00:36,441 : [INFO]  Batch 104: Training set : loss - 0.6372, accuracy - 0.5924, recall - 0.8043, AUC - 0.7341, F1 - 0.6637, precision - 0.5649, training time - -11.0 seconds
2023-03-25 18:00:36,441 : [INFO]  Batch 104: Testing set : loss - 0.6066, accuracy - 0.6961, recall - 0.8627, AUC - 0.7931, F1 - 0.7395, precision - 0.6471
2023-03-25 18:00:36,452 : [INFO]  Batch 105 initialized 
2023-03-25 18:00:37,019 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:37,462 : [INFO]  ------------------------- Batch 105 training: round 1 -------------------------
2023-03-25 18:00:43,051 : [INFO]  ------------------------- Batch round 1, loss: 0.6041 -------------------------
2023-03-25 18:00:43,051 : [INFO]  ------------------------- Batch 105, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:43,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:43,061 : [INFO]  ------------------------- Batch 105 training: round 2 -------------------------
2023-03-25 18:00:46,000 : [INFO]  ------------------------- Batch round 2, loss: 0.6063 -------------------------
2023-03-25 18:00:46,001 : [INFO]  ------------------------- Batch 105, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:46,011 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:46,015 : [INFO]  ------------------------- Batch 105 training: round 3 -------------------------
2023-03-25 18:00:49,050 : [INFO]  ------------------------- Batch round 3, loss: 0.602 -------------------------
2023-03-25 18:00:49,050 : [INFO]  ------------------------- Batch 105, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:49,058 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:49,060 : [INFO]  Batch number 105 model fetched from the server
2023-03-25 18:00:49,060 : [INFO]  ################ Batch 105: final global model evalution after 3 rounds ################
2023-03-25 18:00:50,857 : [INFO]  Batch 105: Training set : loss - 0.6096, accuracy - 0.6902, recall - 0.8478, AUC - 0.7903, F1 - 0.7324, precision - 0.6446, training time - -12.0 seconds
2023-03-25 18:00:50,857 : [INFO]  Batch 105: Testing set : loss - 0.6155, accuracy - 0.6863, recall - 0.9118, AUC - 0.7837, F1 - 0.744, precision - 0.6284
2023-03-25 18:00:50,864 : [INFO]  Batch 106 initialized 
2023-03-25 18:00:51,433 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:51,876 : [INFO]  ------------------------- Batch 106 training: round 1 -------------------------
2023-03-25 18:00:57,559 : [INFO]  ------------------------- Batch round 1, loss: 0.5726 -------------------------
2023-03-25 18:00:57,560 : [INFO]  ------------------------- Batch 106, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:57,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:57,569 : [INFO]  ------------------------- Batch 106 training: round 2 -------------------------
2023-03-25 18:01:00,476 : [INFO]  ------------------------- Batch round 2, loss: 0.5773 -------------------------
2023-03-25 18:01:00,476 : [INFO]  ------------------------- Batch 106, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:00,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:00,601 : [INFO]  ------------------------- Batch 106 training: round 3 -------------------------
2023-03-25 18:01:03,521 : [INFO]  ------------------------- Batch round 3, loss: 0.5747 -------------------------
2023-03-25 18:01:03,521 : [INFO]  ------------------------- Batch 106, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:03,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:03,553 : [INFO]  Batch number 106 model fetched from the server
2023-03-25 18:01:03,553 : [INFO]  ################ Batch 106: final global model evalution after 3 rounds ################
2023-03-25 18:01:05,310 : [INFO]  Batch 106: Training set : loss - 0.5895, accuracy - 0.7283, recall - 0.8587, AUC - 0.7946, F1 - 0.7596, precision - 0.681, training time - -12.0 seconds
2023-03-25 18:01:05,310 : [INFO]  Batch 106: Testing set : loss - 0.5865, accuracy - 0.6912, recall - 0.8824, AUC - 0.843, F1 - 0.7407, precision - 0.6383
2023-03-25 18:01:05,324 : [INFO]  Batch 107 initialized 
2023-03-25 18:01:05,894 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:06,341 : [INFO]  ------------------------- Batch 107 training: round 1 -------------------------
2023-03-25 18:01:11,791 : [INFO]  ------------------------- Batch round 1, loss: 0.5628 -------------------------
2023-03-25 18:01:11,791 : [INFO]  ------------------------- Batch 107, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:11,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:11,892 : [INFO]  ------------------------- Batch 107 training: round 2 -------------------------
2023-03-25 18:01:14,688 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 18:01:14,688 : [INFO]  ------------------------- Batch 107, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:14,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:14,774 : [INFO]  ------------------------- Batch 107 training: round 3 -------------------------
2023-03-25 18:01:17,635 : [INFO]  ------------------------- Batch round 3, loss: 0.5728 -------------------------
2023-03-25 18:01:17,635 : [INFO]  ------------------------- Batch 107, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:17,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:17,713 : [INFO]  Batch number 107 model fetched from the server
2023-03-25 18:01:17,713 : [INFO]  ################ Batch 107: final global model evalution after 3 rounds ################
2023-03-25 18:01:19,449 : [INFO]  Batch 107: Training set : loss - 0.5709, accuracy - 0.7554, recall - 0.913, AUC - 0.85, F1 - 0.7887, precision - 0.6942, training time - -11.0 seconds
2023-03-25 18:01:19,449 : [INFO]  Batch 107: Testing set : loss - 0.6195, accuracy - 0.652, recall - 0.8431, AUC - 0.7696, F1 - 0.7078, precision - 0.6099
2023-03-25 18:01:19,465 : [INFO]  Batch 108 initialized 
2023-03-25 18:01:20,105 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:20,554 : [INFO]  ------------------------- Batch 108 training: round 1 -------------------------
2023-03-25 18:01:25,966 : [INFO]  ------------------------- Batch round 1, loss: 0.5541 -------------------------
2023-03-25 18:01:25,966 : [INFO]  ------------------------- Batch 108, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:26,037 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:26,040 : [INFO]  ------------------------- Batch 108 training: round 2 -------------------------
2023-03-25 18:01:28,796 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 18:01:28,796 : [INFO]  ------------------------- Batch 108, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:28,881 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:28,884 : [INFO]  ------------------------- Batch 108 training: round 3 -------------------------
2023-03-25 18:01:31,807 : [INFO]  ------------------------- Batch round 3, loss: 0.5629 -------------------------
2023-03-25 18:01:31,807 : [INFO]  ------------------------- Batch 108, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:31,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:31,945 : [INFO]  Batch number 108 model fetched from the server
2023-03-25 18:01:31,946 : [INFO]  ################ Batch 108: final global model evalution after 3 rounds ################
2023-03-25 18:01:33,745 : [INFO]  Batch 108: Training set : loss - 0.5759, accuracy - 0.6902, recall - 0.9022, AUC - 0.8446, F1 - 0.7444, precision - 0.6336, training time - -11.0 seconds
2023-03-25 18:01:33,746 : [INFO]  Batch 108: Testing set : loss - 0.5713, accuracy - 0.7108, recall - 0.9412, AUC - 0.875, F1 - 0.7649, precision - 0.6443
2023-03-25 18:01:33,760 : [INFO]  Batch 109 initialized 
2023-03-25 18:01:34,332 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:34,774 : [INFO]  ------------------------- Batch 109 training: round 1 -------------------------
2023-03-25 18:01:40,187 : [INFO]  ------------------------- Batch round 1, loss: 0.5772 -------------------------
2023-03-25 18:01:40,187 : [INFO]  ------------------------- Batch 109, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:40,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:40,198 : [INFO]  ------------------------- Batch 109 training: round 2 -------------------------
2023-03-25 18:01:43,084 : [INFO]  ------------------------- Batch round 2, loss: 0.5808 -------------------------
2023-03-25 18:01:43,084 : [INFO]  ------------------------- Batch 109, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:43,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:43,094 : [INFO]  ------------------------- Batch 109 training: round 3 -------------------------
2023-03-25 18:01:46,006 : [INFO]  ------------------------- Batch round 3, loss: 0.5788 -------------------------
2023-03-25 18:01:46,006 : [INFO]  ------------------------- Batch 109, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:46,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:46,016 : [INFO]  Batch number 109 model fetched from the server
2023-03-25 18:01:46,016 : [INFO]  ################ Batch 109: final global model evalution after 3 rounds ################
2023-03-25 18:01:47,834 : [INFO]  Batch 109: Training set : loss - 0.6014, accuracy - 0.6793, recall - 0.913, AUC - 0.8303, F1 - 0.7401, precision - 0.6222, training time - -11.0 seconds
2023-03-25 18:01:47,834 : [INFO]  Batch 109: Testing set : loss - 0.5965, accuracy - 0.6961, recall - 0.9314, AUC - 0.8434, F1 - 0.754, precision - 0.6333
2023-03-25 18:01:47,842 : [INFO]  Batch 110 initialized 
2023-03-25 18:01:48,419 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:48,878 : [INFO]  ------------------------- Batch 110 training: round 1 -------------------------
2023-03-25 18:01:54,254 : [INFO]  ------------------------- Batch round 1, loss: 0.563 -------------------------
2023-03-25 18:01:54,254 : [INFO]  ------------------------- Batch 110, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:54,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:54,266 : [INFO]  ------------------------- Batch 110 training: round 2 -------------------------
2023-03-25 18:01:57,226 : [INFO]  ------------------------- Batch round 2, loss: 0.57 -------------------------
2023-03-25 18:01:57,226 : [INFO]  ------------------------- Batch 110, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:57,235 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:57,238 : [INFO]  ------------------------- Batch 110 training: round 3 -------------------------
2023-03-25 18:02:00,006 : [INFO]  ------------------------- Batch round 3, loss: 0.5742 -------------------------
2023-03-25 18:02:00,006 : [INFO]  ------------------------- Batch 110, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:00,084 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:00,088 : [INFO]  Batch number 110 model fetched from the server
2023-03-25 18:02:00,088 : [INFO]  ################ Batch 110: final global model evalution after 3 rounds ################
2023-03-25 18:02:01,835 : [INFO]  Batch 110: Training set : loss - 0.5872, accuracy - 0.7011, recall - 0.913, AUC - 0.8001, F1 - 0.7534, precision - 0.6412, training time - -11.0 seconds
2023-03-25 18:02:01,835 : [INFO]  Batch 110: Testing set : loss - 0.6073, accuracy - 0.6324, recall - 0.9216, AUC - 0.8144, F1 - 0.7148, precision - 0.5839
2023-03-25 18:02:01,850 : [INFO]  Batch 111 initialized 
2023-03-25 18:02:02,409 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:02,857 : [INFO]  ------------------------- Batch 111 training: round 1 -------------------------
2023-03-25 18:02:08,206 : [INFO]  ------------------------- Batch round 1, loss: 0.5934 -------------------------
2023-03-25 18:02:08,206 : [INFO]  ------------------------- Batch 111, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:08,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:08,220 : [INFO]  ------------------------- Batch 111 training: round 2 -------------------------
2023-03-25 18:02:11,032 : [INFO]  ------------------------- Batch round 2, loss: 0.5883 -------------------------
2023-03-25 18:02:11,032 : [INFO]  ------------------------- Batch 111, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:11,040 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:11,043 : [INFO]  ------------------------- Batch 111 training: round 3 -------------------------
2023-03-25 18:02:13,808 : [INFO]  ------------------------- Batch round 3, loss: 0.5864 -------------------------
2023-03-25 18:02:13,808 : [INFO]  ------------------------- Batch 111, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:13,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:13,818 : [INFO]  Batch number 111 model fetched from the server
2023-03-25 18:02:13,818 : [INFO]  ################ Batch 111: final global model evalution after 3 rounds ################
2023-03-25 18:02:15,596 : [INFO]  Batch 111: Training set : loss - 0.5957, accuracy - 0.6848, recall - 0.837, AUC - 0.7955, F1 - 0.7264, precision - 0.6417, training time - -11.0 seconds
2023-03-25 18:02:15,597 : [INFO]  Batch 111: Testing set : loss - 0.5927, accuracy - 0.6961, recall - 0.8529, AUC - 0.8038, F1 - 0.7373, precision - 0.6493
2023-03-25 18:02:15,605 : [INFO]  Batch 112 initialized 
2023-03-25 18:02:16,163 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:16,605 : [INFO]  ------------------------- Batch 112 training: round 1 -------------------------
2023-03-25 18:02:21,872 : [INFO]  ------------------------- Batch round 1, loss: 0.5688 -------------------------
2023-03-25 18:02:21,873 : [INFO]  ------------------------- Batch 112, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:21,881 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:21,883 : [INFO]  ------------------------- Batch 112 training: round 2 -------------------------
2023-03-25 18:02:24,699 : [INFO]  ------------------------- Batch round 2, loss: 0.5728 -------------------------
2023-03-25 18:02:24,699 : [INFO]  ------------------------- Batch 112, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:24,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:24,710 : [INFO]  ------------------------- Batch 112 training: round 3 -------------------------
2023-03-25 18:02:27,565 : [INFO]  ------------------------- Batch round 3, loss: 0.5626 -------------------------
2023-03-25 18:02:27,565 : [INFO]  ------------------------- Batch 112, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:27,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:27,576 : [INFO]  Batch number 112 model fetched from the server
2023-03-25 18:02:27,576 : [INFO]  ################ Batch 112: final global model evalution after 3 rounds ################
2023-03-25 18:02:29,341 : [INFO]  Batch 112: Training set : loss - 0.5763, accuracy - 0.7065, recall - 0.8696, AUC - 0.8226, F1 - 0.7477, precision - 0.6557, training time - -11.0 seconds
2023-03-25 18:02:29,341 : [INFO]  Batch 112: Testing set : loss - 0.5956, accuracy - 0.6667, recall - 0.8725, AUC - 0.8298, F1 - 0.7236, precision - 0.6181
2023-03-25 18:02:29,351 : [INFO]  Batch 113 initialized 
2023-03-25 18:02:29,923 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:30,381 : [INFO]  ------------------------- Batch 113 training: round 1 -------------------------
2023-03-25 18:02:35,644 : [INFO]  ------------------------- Batch round 1, loss: 0.5574 -------------------------
2023-03-25 18:02:35,644 : [INFO]  ------------------------- Batch 113, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:35,679 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:35,681 : [INFO]  ------------------------- Batch 113 training: round 2 -------------------------
2023-03-25 18:02:38,569 : [INFO]  ------------------------- Batch round 2, loss: 0.5637 -------------------------
2023-03-25 18:02:38,569 : [INFO]  ------------------------- Batch 113, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:38,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:38,582 : [INFO]  ------------------------- Batch 113 training: round 3 -------------------------
2023-03-25 18:02:41,358 : [INFO]  ------------------------- Batch round 3, loss: 0.5566 -------------------------
2023-03-25 18:02:41,358 : [INFO]  ------------------------- Batch 113, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:41,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:41,416 : [INFO]  Batch number 113 model fetched from the server
2023-03-25 18:02:41,416 : [INFO]  ################ Batch 113: final global model evalution after 3 rounds ################
2023-03-25 18:02:43,473 : [INFO]  Batch 113: Training set : loss - 0.5779, accuracy - 0.7011, recall - 0.8587, AUC - 0.8403, F1 - 0.7418, precision - 0.6529, training time - -11.0 seconds
2023-03-25 18:02:43,474 : [INFO]  Batch 113: Testing set : loss - 0.5747, accuracy - 0.6961, recall - 0.8922, AUC - 0.8542, F1 - 0.7459, precision - 0.6408
2023-03-25 18:02:43,489 : [INFO]  Batch 114 initialized 
2023-03-25 18:02:44,068 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:44,528 : [INFO]  ------------------------- Batch 114 training: round 1 -------------------------
2023-03-25 18:02:49,919 : [INFO]  ------------------------- Batch round 1, loss: 0.572 -------------------------
2023-03-25 18:02:49,919 : [INFO]  ------------------------- Batch 114, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:49,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:49,929 : [INFO]  ------------------------- Batch 114 training: round 2 -------------------------
2023-03-25 18:02:52,848 : [INFO]  ------------------------- Batch round 2, loss: 0.5683 -------------------------
2023-03-25 18:02:52,849 : [INFO]  ------------------------- Batch 114, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:52,857 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:52,860 : [INFO]  ------------------------- Batch 114 training: round 3 -------------------------
2023-03-25 18:02:55,660 : [INFO]  ------------------------- Batch round 3, loss: 0.5757 -------------------------
2023-03-25 18:02:55,661 : [INFO]  ------------------------- Batch 114, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:55,685 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:55,688 : [INFO]  Batch number 114 model fetched from the server
2023-03-25 18:02:55,689 : [INFO]  ################ Batch 114: final global model evalution after 3 rounds ################
2023-03-25 18:02:57,465 : [INFO]  Batch 114: Training set : loss - 0.5852, accuracy - 0.7174, recall - 0.8696, AUC - 0.7966, F1 - 0.7547, precision - 0.6667, training time - -11.0 seconds
2023-03-25 18:02:57,465 : [INFO]  Batch 114: Testing set : loss - 0.5866, accuracy - 0.6569, recall - 0.8922, AUC - 0.8663, F1 - 0.7222, precision - 0.6067
2023-03-25 18:02:57,473 : [INFO]  Batch 115 initialized 
2023-03-25 18:02:58,050 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:58,512 : [INFO]  ------------------------- Batch 115 training: round 1 -------------------------
2023-03-25 18:03:03,867 : [INFO]  ------------------------- Batch round 1, loss: 0.5734 -------------------------
2023-03-25 18:03:03,867 : [INFO]  ------------------------- Batch 115, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:03,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:03,999 : [INFO]  ------------------------- Batch 115 training: round 2 -------------------------
2023-03-25 18:03:06,826 : [INFO]  ------------------------- Batch round 2, loss: 0.5734 -------------------------
2023-03-25 18:03:06,826 : [INFO]  ------------------------- Batch 115, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:06,906 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:06,909 : [INFO]  ------------------------- Batch 115 training: round 3 -------------------------
2023-03-25 18:03:09,724 : [INFO]  ------------------------- Batch round 3, loss: 0.5696 -------------------------
2023-03-25 18:03:09,724 : [INFO]  ------------------------- Batch 115, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:09,845 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:09,848 : [INFO]  Batch number 115 model fetched from the server
2023-03-25 18:03:09,848 : [INFO]  ################ Batch 115: final global model evalution after 3 rounds ################
2023-03-25 18:03:11,569 : [INFO]  Batch 115: Training set : loss - 0.581, accuracy - 0.7011, recall - 0.8913, AUC - 0.8465, F1 - 0.7489, precision - 0.6457, training time - -11.0 seconds
2023-03-25 18:03:11,569 : [INFO]  Batch 115: Testing set : loss - 0.5754, accuracy - 0.7059, recall - 0.9216, AUC - 0.862, F1 - 0.7581, precision - 0.6438
2023-03-25 18:03:11,584 : [INFO]  Batch 116 initialized 
2023-03-25 18:03:12,155 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:12,606 : [INFO]  ------------------------- Batch 116 training: round 1 -------------------------
2023-03-25 18:03:17,972 : [INFO]  ------------------------- Batch round 1, loss: 0.5239 -------------------------
2023-03-25 18:03:17,973 : [INFO]  ------------------------- Batch 116, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:18,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:18,031 : [INFO]  ------------------------- Batch 116 training: round 2 -------------------------
2023-03-25 18:03:20,846 : [INFO]  ------------------------- Batch round 2, loss: 0.5283 -------------------------
2023-03-25 18:03:20,847 : [INFO]  ------------------------- Batch 116, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:20,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:20,893 : [INFO]  ------------------------- Batch 116 training: round 3 -------------------------
2023-03-25 18:03:23,730 : [INFO]  ------------------------- Batch round 3, loss: 0.5275 -------------------------
2023-03-25 18:03:23,731 : [INFO]  ------------------------- Batch 116, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:23,739 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:23,742 : [INFO]  Batch number 116 model fetched from the server
2023-03-25 18:03:23,742 : [INFO]  ################ Batch 116: final global model evalution after 3 rounds ################
2023-03-25 18:03:25,463 : [INFO]  Batch 116: Training set : loss - 0.5373, accuracy - 0.7772, recall - 0.9783, AUC - 0.943, F1 - 0.8145, precision - 0.6977, training time - -11.0 seconds
2023-03-25 18:03:25,463 : [INFO]  Batch 116: Testing set : loss - 0.5879, accuracy - 0.6961, recall - 0.9118, AUC - 0.8521, F1 - 0.75, precision - 0.637
2023-03-25 18:03:25,477 : [INFO]  Batch 117 initialized 
2023-03-25 18:03:26,061 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:26,538 : [INFO]  ------------------------- Batch 117 training: round 1 -------------------------
2023-03-25 18:03:31,973 : [INFO]  ------------------------- Batch round 1, loss: 0.5695 -------------------------
2023-03-25 18:03:31,973 : [INFO]  ------------------------- Batch 117, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:31,981 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:31,984 : [INFO]  ------------------------- Batch 117 training: round 2 -------------------------
2023-03-25 18:03:34,896 : [INFO]  ------------------------- Batch round 2, loss: 0.5757 -------------------------
2023-03-25 18:03:34,897 : [INFO]  ------------------------- Batch 117, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:35,049 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:35,053 : [INFO]  ------------------------- Batch 117 training: round 3 -------------------------
2023-03-25 18:03:37,919 : [INFO]  ------------------------- Batch round 3, loss: 0.5702 -------------------------
2023-03-25 18:03:37,920 : [INFO]  ------------------------- Batch 117, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:37,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:37,939 : [INFO]  Batch number 117 model fetched from the server
2023-03-25 18:03:37,939 : [INFO]  ################ Batch 117: final global model evalution after 3 rounds ################
2023-03-25 18:03:39,738 : [INFO]  Batch 117: Training set : loss - 0.5822, accuracy - 0.6957, recall - 0.8261, AUC - 0.7934, F1 - 0.7308, precision - 0.6552, training time - -11.0 seconds
2023-03-25 18:03:39,738 : [INFO]  Batch 117: Testing set : loss - 0.5884, accuracy - 0.6863, recall - 0.8922, AUC - 0.8301, F1 - 0.7398, precision - 0.6319
2023-03-25 18:03:39,747 : [INFO]  Batch 118 initialized 
2023-03-25 18:03:40,320 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:40,779 : [INFO]  ------------------------- Batch 118 training: round 1 -------------------------
2023-03-25 18:03:46,223 : [INFO]  ------------------------- Batch round 1, loss: 0.5732 -------------------------
2023-03-25 18:03:46,223 : [INFO]  ------------------------- Batch 118, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:46,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:46,234 : [INFO]  ------------------------- Batch 118 training: round 2 -------------------------
2023-03-25 18:03:49,100 : [INFO]  ------------------------- Batch round 2, loss: 0.5744 -------------------------
2023-03-25 18:03:49,100 : [INFO]  ------------------------- Batch 118, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:49,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:49,111 : [INFO]  ------------------------- Batch 118 training: round 3 -------------------------
2023-03-25 18:03:52,010 : [INFO]  ------------------------- Batch round 3, loss: 0.5752 -------------------------
2023-03-25 18:03:52,011 : [INFO]  ------------------------- Batch 118, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:52,018 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:52,021 : [INFO]  Batch number 118 model fetched from the server
2023-03-25 18:03:52,021 : [INFO]  ################ Batch 118: final global model evalution after 3 rounds ################
2023-03-25 18:03:53,828 : [INFO]  Batch 118: Training set : loss - 0.5888, accuracy - 0.6739, recall - 0.9022, AUC - 0.8488, F1 - 0.7345, precision - 0.6194, training time - -11.0 seconds
2023-03-25 18:03:53,828 : [INFO]  Batch 118: Testing set : loss - 0.5976, accuracy - 0.6765, recall - 0.8039, AUC - 0.7892, F1 - 0.713, precision - 0.6406
2023-03-25 18:03:53,839 : [INFO]  Batch 119 initialized 
2023-03-25 18:03:54,390 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:54,854 : [INFO]  ------------------------- Batch 119 training: round 1 -------------------------
2023-03-25 18:04:00,277 : [INFO]  ------------------------- Batch round 1, loss: 0.5984 -------------------------
2023-03-25 18:04:00,277 : [INFO]  ------------------------- Batch 119, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:00,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:00,287 : [INFO]  ------------------------- Batch 119 training: round 2 -------------------------
2023-03-25 18:04:03,219 : [INFO]  ------------------------- Batch round 2, loss: 0.6005 -------------------------
2023-03-25 18:04:03,219 : [INFO]  ------------------------- Batch 119, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:03,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:03,229 : [INFO]  ------------------------- Batch 119 training: round 3 -------------------------
2023-03-25 18:04:06,071 : [INFO]  ------------------------- Batch round 3, loss: 0.5968 -------------------------
2023-03-25 18:04:06,071 : [INFO]  ------------------------- Batch 119, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:06,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:06,081 : [INFO]  Batch number 119 model fetched from the server
2023-03-25 18:04:06,081 : [INFO]  ################ Batch 119: final global model evalution after 3 rounds ################
2023-03-25 18:04:07,871 : [INFO]  Batch 119: Training set : loss - 0.6133, accuracy - 0.6522, recall - 0.8261, AUC - 0.7886, F1 - 0.7037, precision - 0.6129, training time - -11.0 seconds
2023-03-25 18:04:07,871 : [INFO]  Batch 119: Testing set : loss - 0.5646, accuracy - 0.7451, recall - 0.9118, AUC - 0.8675, F1 - 0.7815, precision - 0.6838
2023-03-25 18:04:07,882 : [INFO]  Batch 120 initialized 
2023-03-25 18:04:08,436 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:08,901 : [INFO]  ------------------------- Batch 120 training: round 1 -------------------------
2023-03-25 18:04:14,394 : [INFO]  ------------------------- Batch round 1, loss: 0.5651 -------------------------
2023-03-25 18:04:14,394 : [INFO]  ------------------------- Batch 120, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:14,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:14,405 : [INFO]  ------------------------- Batch 120 training: round 2 -------------------------
2023-03-25 18:04:17,260 : [INFO]  ------------------------- Batch round 2, loss: 0.5712 -------------------------
2023-03-25 18:04:17,260 : [INFO]  ------------------------- Batch 120, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:17,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:17,299 : [INFO]  ------------------------- Batch 120 training: round 3 -------------------------
2023-03-25 18:04:20,278 : [INFO]  ------------------------- Batch round 3, loss: 0.5728 -------------------------
2023-03-25 18:04:20,278 : [INFO]  ------------------------- Batch 120, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:20,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:20,289 : [INFO]  Batch number 120 model fetched from the server
2023-03-25 18:04:20,289 : [INFO]  ################ Batch 120: final global model evalution after 3 rounds ################
2023-03-25 18:04:22,105 : [INFO]  Batch 120: Training set : loss - 0.5746, accuracy - 0.7391, recall - 0.913, AUC - 0.8396, F1 - 0.7778, precision - 0.6774, training time - -11.0 seconds
2023-03-25 18:04:22,105 : [INFO]  Batch 120: Testing set : loss - 0.5916, accuracy - 0.7059, recall - 0.8431, AUC - 0.8074, F1 - 0.7414, precision - 0.6615
2023-03-25 18:04:22,112 : [INFO]  Batch 121 initialized 
2023-03-25 18:04:22,729 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:23,203 : [INFO]  ------------------------- Batch 121 training: round 1 -------------------------
2023-03-25 18:04:28,732 : [INFO]  ------------------------- Batch round 1, loss: 0.61 -------------------------
2023-03-25 18:04:28,732 : [INFO]  ------------------------- Batch 121, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:28,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:28,744 : [INFO]  ------------------------- Batch 121 training: round 2 -------------------------
2023-03-25 18:04:31,799 : [INFO]  ------------------------- Batch round 2, loss: 0.6132 -------------------------
2023-03-25 18:04:31,800 : [INFO]  ------------------------- Batch 121, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:31,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:31,811 : [INFO]  ------------------------- Batch 121 training: round 3 -------------------------
2023-03-25 18:04:34,744 : [INFO]  ------------------------- Batch round 3, loss: 0.6095 -------------------------
2023-03-25 18:04:34,744 : [INFO]  ------------------------- Batch 121, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:34,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:34,755 : [INFO]  Batch number 121 model fetched from the server
2023-03-25 18:04:34,755 : [INFO]  ################ Batch 121: final global model evalution after 3 rounds ################
2023-03-25 18:04:36,586 : [INFO]  Batch 121: Training set : loss - 0.6274, accuracy - 0.6359, recall - 0.7826, AUC - 0.7358, F1 - 0.6825, precision - 0.605, training time - -12.0 seconds
2023-03-25 18:04:36,586 : [INFO]  Batch 121: Testing set : loss - 0.5981, accuracy - 0.652, recall - 0.8235, AUC - 0.8076, F1 - 0.7029, precision - 0.6131
2023-03-25 18:04:36,617 : [INFO]  Batch 122 initialized 
2023-03-25 18:04:37,192 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:37,639 : [INFO]  ------------------------- Batch 122 training: round 1 -------------------------
2023-03-25 18:04:43,402 : [INFO]  ------------------------- Batch round 1, loss: 0.5901 -------------------------
2023-03-25 18:04:43,402 : [INFO]  ------------------------- Batch 122, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:43,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:43,416 : [INFO]  ------------------------- Batch 122 training: round 2 -------------------------
2023-03-25 18:04:46,328 : [INFO]  ------------------------- Batch round 2, loss: 0.5855 -------------------------
2023-03-25 18:04:46,328 : [INFO]  ------------------------- Batch 122, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:46,337 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:46,340 : [INFO]  ------------------------- Batch 122 training: round 3 -------------------------
2023-03-25 18:04:49,289 : [INFO]  ------------------------- Batch round 3, loss: 0.5838 -------------------------
2023-03-25 18:04:49,290 : [INFO]  ------------------------- Batch 122, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:49,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:49,301 : [INFO]  Batch number 122 model fetched from the server
2023-03-25 18:04:49,301 : [INFO]  ################ Batch 122: final global model evalution after 3 rounds ################
2023-03-25 18:04:51,266 : [INFO]  Batch 122: Training set : loss - 0.6008, accuracy - 0.6902, recall - 0.9457, AUC - 0.847, F1 - 0.7532, precision - 0.6259, training time - -12.0 seconds
2023-03-25 18:04:51,267 : [INFO]  Batch 122: Testing set : loss - 0.645, accuracy - 0.6324, recall - 0.9216, AUC - 0.724, F1 - 0.7148, precision - 0.5839
2023-03-25 18:04:51,274 : [INFO]  Batch 123 initialized 
2023-03-25 18:04:51,846 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:52,323 : [INFO]  ------------------------- Batch 123 training: round 1 -------------------------
2023-03-25 18:04:57,826 : [INFO]  ------------------------- Batch round 1, loss: 0.5474 -------------------------
2023-03-25 18:04:57,826 : [INFO]  ------------------------- Batch 123, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:57,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:57,836 : [INFO]  ------------------------- Batch 123 training: round 2 -------------------------
2023-03-25 18:05:00,826 : [INFO]  ------------------------- Batch round 2, loss: 0.5463 -------------------------
2023-03-25 18:05:00,826 : [INFO]  ------------------------- Batch 123, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:00,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:00,837 : [INFO]  ------------------------- Batch 123 training: round 3 -------------------------
2023-03-25 18:05:03,660 : [INFO]  ------------------------- Batch round 3, loss: 0.5432 -------------------------
2023-03-25 18:05:03,660 : [INFO]  ------------------------- Batch 123, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:03,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:03,673 : [INFO]  Batch number 123 model fetched from the server
2023-03-25 18:05:03,673 : [INFO]  ################ Batch 123: final global model evalution after 3 rounds ################
2023-03-25 18:05:05,503 : [INFO]  Batch 123: Training set : loss - 0.5596, accuracy - 0.7174, recall - 0.8913, AUC - 0.871, F1 - 0.7593, precision - 0.6613, training time - -11.0 seconds
2023-03-25 18:05:05,503 : [INFO]  Batch 123: Testing set : loss - 0.5537, accuracy - 0.7402, recall - 0.9118, AUC - 0.8523, F1 - 0.7782, precision - 0.6788
2023-03-25 18:05:05,521 : [INFO]  Batch 124 initialized 
2023-03-25 18:05:06,134 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:06,608 : [INFO]  ------------------------- Batch 124 training: round 1 -------------------------
2023-03-25 18:05:12,266 : [INFO]  ------------------------- Batch round 1, loss: 0.591 -------------------------
2023-03-25 18:05:12,266 : [INFO]  ------------------------- Batch 124, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:12,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:12,331 : [INFO]  ------------------------- Batch 124 training: round 2 -------------------------
2023-03-25 18:05:15,345 : [INFO]  ------------------------- Batch round 2, loss: 0.5903 -------------------------
2023-03-25 18:05:15,345 : [INFO]  ------------------------- Batch 124, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:15,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:15,415 : [INFO]  ------------------------- Batch 124 training: round 3 -------------------------
2023-03-25 18:05:18,521 : [INFO]  ------------------------- Batch round 3, loss: 0.5936 -------------------------
2023-03-25 18:05:18,521 : [INFO]  ------------------------- Batch 124, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:18,531 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:18,533 : [INFO]  Batch number 124 model fetched from the server
2023-03-25 18:05:18,533 : [INFO]  ################ Batch 124: final global model evalution after 3 rounds ################
2023-03-25 18:05:20,357 : [INFO]  Batch 124: Training set : loss - 0.6006, accuracy - 0.6848, recall - 0.7935, AUC - 0.7886, F1 - 0.7157, precision - 0.6518, training time - -12.0 seconds
2023-03-25 18:05:20,357 : [INFO]  Batch 124: Testing set : loss - 0.5771, accuracy - 0.6961, recall - 0.8431, AUC - 0.8411, F1 - 0.735, precision - 0.6515
2023-03-25 18:05:20,372 : [INFO]  Batch 125 initialized 
2023-03-25 18:05:20,927 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:21,412 : [INFO]  ------------------------- Batch 125 training: round 1 -------------------------
2023-03-25 18:05:26,935 : [INFO]  ------------------------- Batch round 1, loss: 0.5651 -------------------------
2023-03-25 18:05:26,935 : [INFO]  ------------------------- Batch 125, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:26,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:26,985 : [INFO]  ------------------------- Batch 125 training: round 2 -------------------------
2023-03-25 18:05:29,876 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-25 18:05:29,877 : [INFO]  ------------------------- Batch 125, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:30,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:30,081 : [INFO]  ------------------------- Batch 125 training: round 3 -------------------------
2023-03-25 18:05:32,997 : [INFO]  ------------------------- Batch round 3, loss: 0.567 -------------------------
2023-03-25 18:05:32,998 : [INFO]  ------------------------- Batch 125, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:33,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:33,192 : [INFO]  Batch number 125 model fetched from the server
2023-03-25 18:05:33,192 : [INFO]  ################ Batch 125: final global model evalution after 3 rounds ################
2023-03-25 18:05:34,998 : [INFO]  Batch 125: Training set : loss - 0.5789, accuracy - 0.7065, recall - 0.9457, AUC - 0.8448, F1 - 0.7632, precision - 0.6397, training time - -12.0 seconds
2023-03-25 18:05:34,999 : [INFO]  Batch 125: Testing set : loss - 0.5759, accuracy - 0.701, recall - 0.8627, AUC - 0.8451, F1 - 0.7426, precision - 0.6519
2023-03-25 18:05:35,026 : [INFO]  Batch 126 initialized 
2023-03-25 18:05:35,601 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:36,083 : [INFO]  ------------------------- Batch 126 training: round 1 -------------------------
2023-03-25 18:05:41,499 : [INFO]  ------------------------- Batch round 1, loss: 0.5693 -------------------------
2023-03-25 18:05:41,500 : [INFO]  ------------------------- Batch 126, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:41,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:41,670 : [INFO]  ------------------------- Batch 126 training: round 2 -------------------------
2023-03-25 18:05:44,462 : [INFO]  ------------------------- Batch round 2, loss: 0.5645 -------------------------
2023-03-25 18:05:44,462 : [INFO]  ------------------------- Batch 126, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:44,639 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:44,642 : [INFO]  ------------------------- Batch 126 training: round 3 -------------------------
2023-03-25 18:05:47,447 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-25 18:05:47,447 : [INFO]  ------------------------- Batch 126, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:47,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:47,666 : [INFO]  Batch number 126 model fetched from the server
2023-03-25 18:05:47,667 : [INFO]  ################ Batch 126: final global model evalution after 3 rounds ################
2023-03-25 18:05:49,399 : [INFO]  Batch 126: Training set : loss - 0.5702, accuracy - 0.7228, recall - 0.913, AUC - 0.8443, F1 - 0.7671, precision - 0.6614, training time - -12.0 seconds
2023-03-25 18:05:49,399 : [INFO]  Batch 126: Testing set : loss - 0.5618, accuracy - 0.7402, recall - 0.9314, AUC - 0.8621, F1 - 0.7819, precision - 0.6738
2023-03-25 18:05:49,413 : [INFO]  Batch 127 initialized 
2023-03-25 18:05:50,010 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:50,461 : [INFO]  ------------------------- Batch 127 training: round 1 -------------------------
2023-03-25 18:05:55,710 : [INFO]  ------------------------- Batch round 1, loss: 0.5589 -------------------------
2023-03-25 18:05:55,710 : [INFO]  ------------------------- Batch 127, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:55,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:55,880 : [INFO]  ------------------------- Batch 127 training: round 2 -------------------------
2023-03-25 18:05:58,804 : [INFO]  ------------------------- Batch round 2, loss: 0.5626 -------------------------
2023-03-25 18:05:58,804 : [INFO]  ------------------------- Batch 127, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:58,813 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:58,817 : [INFO]  ------------------------- Batch 127 training: round 3 -------------------------
2023-03-25 18:06:01,542 : [INFO]  ------------------------- Batch round 3, loss: 0.5609 -------------------------
2023-03-25 18:06:01,542 : [INFO]  ------------------------- Batch 127, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:01,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:01,604 : [INFO]  Batch number 127 model fetched from the server
2023-03-25 18:06:01,604 : [INFO]  ################ Batch 127: final global model evalution after 3 rounds ################
2023-03-25 18:06:03,386 : [INFO]  Batch 127: Training set : loss - 0.5726, accuracy - 0.7228, recall - 0.8913, AUC - 0.8539, F1 - 0.7628, precision - 0.6667, training time - -11.0 seconds
2023-03-25 18:06:03,387 : [INFO]  Batch 127: Testing set : loss - 0.6023, accuracy - 0.6667, recall - 0.8529, AUC - 0.7933, F1 - 0.719, precision - 0.6214
2023-03-25 18:06:03,399 : [INFO]  Batch 128 initialized 
2023-03-25 18:06:03,965 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:04,452 : [INFO]  ------------------------- Batch 128 training: round 1 -------------------------
2023-03-25 18:06:09,704 : [INFO]  ------------------------- Batch round 1, loss: 0.5391 -------------------------
2023-03-25 18:06:09,704 : [INFO]  ------------------------- Batch 128, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:09,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:09,947 : [INFO]  ------------------------- Batch 128 training: round 2 -------------------------
2023-03-25 18:06:12,723 : [INFO]  ------------------------- Batch round 2, loss: 0.5478 -------------------------
2023-03-25 18:06:12,724 : [INFO]  ------------------------- Batch 128, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:12,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:12,812 : [INFO]  ------------------------- Batch 128 training: round 3 -------------------------
2023-03-25 18:06:15,549 : [INFO]  ------------------------- Batch round 3, loss: 0.5412 -------------------------
2023-03-25 18:06:15,549 : [INFO]  ------------------------- Batch 128, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:15,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:15,567 : [INFO]  Batch number 128 model fetched from the server
2023-03-25 18:06:15,567 : [INFO]  ################ Batch 128: final global model evalution after 3 rounds ################
2023-03-25 18:06:17,334 : [INFO]  Batch 128: Training set : loss - 0.5494, accuracy - 0.75, recall - 0.9457, AUC - 0.8996, F1 - 0.7909, precision - 0.6797, training time - -11.0 seconds
2023-03-25 18:06:17,334 : [INFO]  Batch 128: Testing set : loss - 0.5539, accuracy - 0.7353, recall - 0.902, AUC - 0.8764, F1 - 0.7731, precision - 0.6765
2023-03-25 18:06:17,341 : [INFO]  Batch 129 initialized 
2023-03-25 18:06:17,933 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:18,407 : [INFO]  ------------------------- Batch 129 training: round 1 -------------------------
2023-03-25 18:06:23,750 : [INFO]  ------------------------- Batch round 1, loss: 0.6114 -------------------------
2023-03-25 18:06:23,750 : [INFO]  ------------------------- Batch 129, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:23,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:23,820 : [INFO]  ------------------------- Batch 129 training: round 2 -------------------------
2023-03-25 18:06:26,768 : [INFO]  ------------------------- Batch round 2, loss: 0.6135 -------------------------
2023-03-25 18:06:26,769 : [INFO]  ------------------------- Batch 129, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:26,811 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:26,814 : [INFO]  ------------------------- Batch 129 training: round 3 -------------------------
2023-03-25 18:06:29,633 : [INFO]  ------------------------- Batch round 3, loss: 0.6143 -------------------------
2023-03-25 18:06:29,634 : [INFO]  ------------------------- Batch 129, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:29,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:29,647 : [INFO]  Batch number 129 model fetched from the server
2023-03-25 18:06:29,647 : [INFO]  ################ Batch 129: final global model evalution after 3 rounds ################
2023-03-25 18:06:31,435 : [INFO]  Batch 129: Training set : loss - 0.6205, accuracy - 0.6413, recall - 0.7826, AUC - 0.7504, F1 - 0.6857, precision - 0.6102, training time - -11.0 seconds
2023-03-25 18:06:31,436 : [INFO]  Batch 129: Testing set : loss - 0.5952, accuracy - 0.7059, recall - 0.9118, AUC - 0.829, F1 - 0.7561, precision - 0.6458
2023-03-25 18:06:31,452 : [INFO]  Batch 130 initialized 
2023-03-25 18:06:32,054 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:32,557 : [INFO]  ------------------------- Batch 130 training: round 1 -------------------------
2023-03-25 18:06:37,968 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-25 18:06:37,969 : [INFO]  ------------------------- Batch 130, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:38,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:38,023 : [INFO]  ------------------------- Batch 130 training: round 2 -------------------------
2023-03-25 18:06:40,851 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-25 18:06:40,852 : [INFO]  ------------------------- Batch 130, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:40,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:40,919 : [INFO]  ------------------------- Batch 130 training: round 3 -------------------------
2023-03-25 18:06:43,724 : [INFO]  ------------------------- Batch round 3, loss: 0.5807 -------------------------
2023-03-25 18:06:43,724 : [INFO]  ------------------------- Batch 130, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:43,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:43,786 : [INFO]  Batch number 130 model fetched from the server
2023-03-25 18:06:43,786 : [INFO]  ################ Batch 130: final global model evalution after 3 rounds ################
2023-03-25 18:06:45,538 : [INFO]  Batch 130: Training set : loss - 0.5842, accuracy - 0.7011, recall - 0.8913, AUC - 0.8221, F1 - 0.7489, precision - 0.6457, training time - -11.0 seconds
2023-03-25 18:06:45,539 : [INFO]  Batch 130: Testing set : loss - 0.5514, accuracy - 0.7206, recall - 0.9412, AUC - 0.9015, F1 - 0.7711, precision - 0.6531
2023-03-25 18:06:45,550 : [INFO]  Batch 131 initialized 
2023-03-25 18:06:46,111 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:46,597 : [INFO]  ------------------------- Batch 131 training: round 1 -------------------------
2023-03-25 18:06:51,917 : [INFO]  ------------------------- Batch round 1, loss: 0.5447 -------------------------
2023-03-25 18:06:51,917 : [INFO]  ------------------------- Batch 131, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:51,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:51,957 : [INFO]  ------------------------- Batch 131 training: round 2 -------------------------
2023-03-25 18:06:54,737 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-25 18:06:54,737 : [INFO]  ------------------------- Batch 131, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:54,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:54,802 : [INFO]  ------------------------- Batch 131 training: round 3 -------------------------
2023-03-25 18:06:57,676 : [INFO]  ------------------------- Batch round 3, loss: 0.551 -------------------------
2023-03-25 18:06:57,676 : [INFO]  ------------------------- Batch 131, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:57,685 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:57,687 : [INFO]  Batch number 131 model fetched from the server
2023-03-25 18:06:57,688 : [INFO]  ################ Batch 131: final global model evalution after 3 rounds ################
2023-03-25 18:06:59,463 : [INFO]  Batch 131: Training set : loss - 0.5647, accuracy - 0.6957, recall - 0.9239, AUC - 0.8998, F1 - 0.7522, precision - 0.6343, training time - -11.0 seconds
2023-03-25 18:06:59,464 : [INFO]  Batch 131: Testing set : loss - 0.5465, accuracy - 0.7206, recall - 0.9216, AUC - 0.9173, F1 - 0.7673, precision - 0.6573
2023-03-25 18:06:59,506 : [INFO]  Batch 132 initialized 
2023-03-25 18:07:00,084 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:00,573 : [INFO]  ------------------------- Batch 132 training: round 1 -------------------------
2023-03-25 18:07:06,073 : [INFO]  ------------------------- Batch round 1, loss: 0.5835 -------------------------
2023-03-25 18:07:06,073 : [INFO]  ------------------------- Batch 132, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:06,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:06,084 : [INFO]  ------------------------- Batch 132 training: round 2 -------------------------
2023-03-25 18:07:08,937 : [INFO]  ------------------------- Batch round 2, loss: 0.586 -------------------------
2023-03-25 18:07:08,937 : [INFO]  ------------------------- Batch 132, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:08,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:08,949 : [INFO]  ------------------------- Batch 132 training: round 3 -------------------------
2023-03-25 18:07:11,832 : [INFO]  ------------------------- Batch round 3, loss: 0.5829 -------------------------
2023-03-25 18:07:11,832 : [INFO]  ------------------------- Batch 132, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:11,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:11,955 : [INFO]  Batch number 132 model fetched from the server
2023-03-25 18:07:11,955 : [INFO]  ################ Batch 132: final global model evalution after 3 rounds ################
2023-03-25 18:07:13,698 : [INFO]  Batch 132: Training set : loss - 0.5957, accuracy - 0.7174, recall - 0.913, AUC - 0.8309, F1 - 0.7636, precision - 0.6562, training time - -11.0 seconds
2023-03-25 18:07:13,699 : [INFO]  Batch 132: Testing set : loss - 0.5849, accuracy - 0.6765, recall - 0.8529, AUC - 0.8187, F1 - 0.725, precision - 0.6304
2023-03-25 18:07:13,709 : [INFO]  Batch 133 initialized 
2023-03-25 18:07:14,269 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:14,759 : [INFO]  ------------------------- Batch 133 training: round 1 -------------------------
2023-03-25 18:07:20,124 : [INFO]  ------------------------- Batch round 1, loss: 0.5725 -------------------------
2023-03-25 18:07:20,124 : [INFO]  ------------------------- Batch 133, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:20,132 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:20,134 : [INFO]  ------------------------- Batch 133 training: round 2 -------------------------
2023-03-25 18:07:22,976 : [INFO]  ------------------------- Batch round 2, loss: 0.5751 -------------------------
2023-03-25 18:07:22,977 : [INFO]  ------------------------- Batch 133, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:22,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:22,987 : [INFO]  ------------------------- Batch 133 training: round 3 -------------------------
2023-03-25 18:07:25,963 : [INFO]  ------------------------- Batch round 3, loss: 0.5768 -------------------------
2023-03-25 18:07:25,963 : [INFO]  ------------------------- Batch 133, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:25,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:25,973 : [INFO]  Batch number 133 model fetched from the server
2023-03-25 18:07:25,973 : [INFO]  ################ Batch 133: final global model evalution after 3 rounds ################
2023-03-25 18:07:27,791 : [INFO]  Batch 133: Training set : loss - 0.5948, accuracy - 0.6522, recall - 0.9348, AUC - 0.8524, F1 - 0.7288, precision - 0.5972, training time - -11.0 seconds
2023-03-25 18:07:27,791 : [INFO]  Batch 133: Testing set : loss - 0.5763, accuracy - 0.6765, recall - 0.9412, AUC - 0.8856, F1 - 0.7442, precision - 0.6154
2023-03-25 18:07:27,798 : [INFO]  Batch 134 initialized 
2023-03-25 18:07:28,372 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:28,868 : [INFO]  ------------------------- Batch 134 training: round 1 -------------------------
2023-03-25 18:07:34,422 : [INFO]  ------------------------- Batch round 1, loss: 0.5616 -------------------------
2023-03-25 18:07:34,422 : [INFO]  ------------------------- Batch 134, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:34,430 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:34,433 : [INFO]  ------------------------- Batch 134 training: round 2 -------------------------
2023-03-25 18:07:37,388 : [INFO]  ------------------------- Batch round 2, loss: 0.5556 -------------------------
2023-03-25 18:07:37,388 : [INFO]  ------------------------- Batch 134, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:37,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:37,399 : [INFO]  ------------------------- Batch 134 training: round 3 -------------------------
2023-03-25 18:07:40,287 : [INFO]  ------------------------- Batch round 3, loss: 0.5646 -------------------------
2023-03-25 18:07:40,287 : [INFO]  ------------------------- Batch 134, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:40,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:40,299 : [INFO]  Batch number 134 model fetched from the server
2023-03-25 18:07:40,299 : [INFO]  ################ Batch 134: final global model evalution after 3 rounds ################
2023-03-25 18:07:42,166 : [INFO]  Batch 134: Training set : loss - 0.5787, accuracy - 0.75, recall - 0.9239, AUC - 0.844, F1 - 0.787, precision - 0.6855, training time - -11.0 seconds
2023-03-25 18:07:42,166 : [INFO]  Batch 134: Testing set : loss - 0.5977, accuracy - 0.6912, recall - 0.902, AUC - 0.8379, F1 - 0.7449, precision - 0.6345
2023-03-25 18:07:42,174 : [INFO]  Batch 135 initialized 
2023-03-25 18:07:42,759 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:43,242 : [INFO]  ------------------------- Batch 135 training: round 1 -------------------------
2023-03-25 18:07:48,853 : [INFO]  ------------------------- Batch round 1, loss: 0.6132 -------------------------
2023-03-25 18:07:48,853 : [INFO]  ------------------------- Batch 135, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:48,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:48,864 : [INFO]  ------------------------- Batch 135 training: round 2 -------------------------
2023-03-25 18:07:51,820 : [INFO]  ------------------------- Batch round 2, loss: 0.6111 -------------------------
2023-03-25 18:07:51,820 : [INFO]  ------------------------- Batch 135, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:51,829 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:51,831 : [INFO]  ------------------------- Batch 135 training: round 3 -------------------------
2023-03-25 18:07:54,717 : [INFO]  ------------------------- Batch round 3, loss: 0.6129 -------------------------
2023-03-25 18:07:54,718 : [INFO]  ------------------------- Batch 135, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:54,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:54,728 : [INFO]  Batch number 135 model fetched from the server
2023-03-25 18:07:54,728 : [INFO]  ################ Batch 135: final global model evalution after 3 rounds ################
2023-03-25 18:07:56,530 : [INFO]  Batch 135: Training set : loss - 0.6273, accuracy - 0.6087, recall - 0.7283, AUC - 0.7126, F1 - 0.6505, precision - 0.5877, training time - -11.0 seconds
2023-03-25 18:07:56,531 : [INFO]  Batch 135: Testing set : loss - 0.6428, accuracy - 0.6078, recall - 0.7647, AUC - 0.7031, F1 - 0.661, precision - 0.5821
2023-03-25 18:07:56,543 : [INFO]  Batch 136 initialized 
2023-03-25 18:07:57,114 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:57,629 : [INFO]  ------------------------- Batch 136 training: round 1 -------------------------
2023-03-25 18:08:03,181 : [INFO]  ------------------------- Batch round 1, loss: 0.5624 -------------------------
2023-03-25 18:08:03,181 : [INFO]  ------------------------- Batch 136, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:03,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:03,194 : [INFO]  ------------------------- Batch 136 training: round 2 -------------------------
2023-03-25 18:08:06,035 : [INFO]  ------------------------- Batch round 2, loss: 0.5607 -------------------------
2023-03-25 18:08:06,035 : [INFO]  ------------------------- Batch 136, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:06,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:06,046 : [INFO]  ------------------------- Batch 136 training: round 3 -------------------------
2023-03-25 18:08:08,960 : [INFO]  ------------------------- Batch round 3, loss: 0.5659 -------------------------
2023-03-25 18:08:08,961 : [INFO]  ------------------------- Batch 136, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:08,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:08,972 : [INFO]  Batch number 136 model fetched from the server
2023-03-25 18:08:08,973 : [INFO]  ################ Batch 136: final global model evalution after 3 rounds ################
2023-03-25 18:08:10,788 : [INFO]  Batch 136: Training set : loss - 0.5714, accuracy - 0.7283, recall - 0.8804, AUC - 0.8218, F1 - 0.7642, precision - 0.675, training time - -11.0 seconds
2023-03-25 18:08:10,788 : [INFO]  Batch 136: Testing set : loss - 0.5935, accuracy - 0.7157, recall - 0.9118, AUC - 0.8104, F1 - 0.7623, precision - 0.6549
2023-03-25 18:08:10,802 : [INFO]  Batch 137 initialized 
2023-03-25 18:08:11,363 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:11,866 : [INFO]  ------------------------- Batch 137 training: round 1 -------------------------
2023-03-25 18:08:17,323 : [INFO]  ------------------------- Batch round 1, loss: 0.5934 -------------------------
2023-03-25 18:08:17,323 : [INFO]  ------------------------- Batch 137, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:17,331 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:17,334 : [INFO]  ------------------------- Batch 137 training: round 2 -------------------------
2023-03-25 18:08:20,339 : [INFO]  ------------------------- Batch round 2, loss: 0.5866 -------------------------
2023-03-25 18:08:20,340 : [INFO]  ------------------------- Batch 137, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:20,355 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:20,359 : [INFO]  ------------------------- Batch 137 training: round 3 -------------------------
2023-03-25 18:08:23,408 : [INFO]  ------------------------- Batch round 3, loss: 0.5931 -------------------------
2023-03-25 18:08:23,408 : [INFO]  ------------------------- Batch 137, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:23,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:23,421 : [INFO]  Batch number 137 model fetched from the server
2023-03-25 18:08:23,421 : [INFO]  ################ Batch 137: final global model evalution after 3 rounds ################
2023-03-25 18:08:25,241 : [INFO]  Batch 137: Training set : loss - 0.5937, accuracy - 0.6902, recall - 0.8913, AUC - 0.8156, F1 - 0.7421, precision - 0.6357, training time - -12.0 seconds
2023-03-25 18:08:25,241 : [INFO]  Batch 137: Testing set : loss - 0.58, accuracy - 0.701, recall - 0.8922, AUC - 0.857, F1 - 0.749, precision - 0.6454
2023-03-25 18:08:25,251 : [INFO]  Batch 138 initialized 
2023-03-25 18:08:25,819 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:26,319 : [INFO]  ------------------------- Batch 138 training: round 1 -------------------------
2023-03-25 18:08:31,883 : [INFO]  ------------------------- Batch round 1, loss: 0.5972 -------------------------
2023-03-25 18:08:31,883 : [INFO]  ------------------------- Batch 138, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:31,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:31,894 : [INFO]  ------------------------- Batch 138 training: round 2 -------------------------
2023-03-25 18:08:34,845 : [INFO]  ------------------------- Batch round 2, loss: 0.5981 -------------------------
2023-03-25 18:08:34,846 : [INFO]  ------------------------- Batch 138, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:35,061 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:35,069 : [INFO]  ------------------------- Batch 138 training: round 3 -------------------------
2023-03-25 18:08:38,047 : [INFO]  ------------------------- Batch round 3, loss: 0.5959 -------------------------
2023-03-25 18:08:38,048 : [INFO]  ------------------------- Batch 138, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:38,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:38,077 : [INFO]  Batch number 138 model fetched from the server
2023-03-25 18:08:38,077 : [INFO]  ################ Batch 138: final global model evalution after 3 rounds ################
2023-03-25 18:08:39,885 : [INFO]  Batch 138: Training set : loss - 0.6015, accuracy - 0.6848, recall - 0.9022, AUC - 0.7942, F1 - 0.7411, precision - 0.6288, training time - -12.0 seconds
2023-03-25 18:08:39,885 : [INFO]  Batch 138: Testing set : loss - 0.6067, accuracy - 0.6716, recall - 0.8137, AUC - 0.7871, F1 - 0.7124, precision - 0.6336
2023-03-25 18:08:39,893 : [INFO]  Batch 139 initialized 
2023-03-25 18:08:40,459 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:40,958 : [INFO]  ------------------------- Batch 139 training: round 1 -------------------------
2023-03-25 18:08:46,392 : [INFO]  ------------------------- Batch round 1, loss: 0.584 -------------------------
2023-03-25 18:08:46,392 : [INFO]  ------------------------- Batch 139, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:46,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:46,403 : [INFO]  ------------------------- Batch 139 training: round 2 -------------------------
2023-03-25 18:08:49,364 : [INFO]  ------------------------- Batch round 2, loss: 0.5793 -------------------------
2023-03-25 18:08:49,364 : [INFO]  ------------------------- Batch 139, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:49,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:49,379 : [INFO]  ------------------------- Batch 139 training: round 3 -------------------------
2023-03-25 18:08:52,280 : [INFO]  ------------------------- Batch round 3, loss: 0.5878 -------------------------
2023-03-25 18:08:52,281 : [INFO]  ------------------------- Batch 139, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:52,290 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:52,292 : [INFO]  Batch number 139 model fetched from the server
2023-03-25 18:08:52,293 : [INFO]  ################ Batch 139: final global model evalution after 3 rounds ################
2023-03-25 18:08:54,099 : [INFO]  Batch 139: Training set : loss - 0.594, accuracy - 0.6957, recall - 0.9239, AUC - 0.8233, F1 - 0.7522, precision - 0.6343, training time - -11.0 seconds
2023-03-25 18:08:54,100 : [INFO]  Batch 139: Testing set : loss - 0.6046, accuracy - 0.6716, recall - 0.8529, AUC - 0.8031, F1 - 0.722, precision - 0.6259
2023-03-25 18:08:54,108 : [INFO]  Batch 140 initialized 
2023-03-25 18:08:54,671 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:55,190 : [INFO]  ------------------------- Batch 140 training: round 1 -------------------------
2023-03-25 18:09:00,648 : [INFO]  ------------------------- Batch round 1, loss: 0.5654 -------------------------
2023-03-25 18:09:00,648 : [INFO]  ------------------------- Batch 140, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:00,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:00,664 : [INFO]  ------------------------- Batch 140 training: round 2 -------------------------
2023-03-25 18:09:03,685 : [INFO]  ------------------------- Batch round 2, loss: 0.5667 -------------------------
2023-03-25 18:09:03,685 : [INFO]  ------------------------- Batch 140, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:03,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:03,699 : [INFO]  ------------------------- Batch 140 training: round 3 -------------------------
2023-03-25 18:09:06,715 : [INFO]  ------------------------- Batch round 3, loss: 0.5645 -------------------------
2023-03-25 18:09:06,715 : [INFO]  ------------------------- Batch 140, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:06,727 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:06,731 : [INFO]  Batch number 140 model fetched from the server
2023-03-25 18:09:06,731 : [INFO]  ################ Batch 140: final global model evalution after 3 rounds ################
2023-03-25 18:09:08,520 : [INFO]  Batch 140: Training set : loss - 0.5727, accuracy - 0.6848, recall - 0.8587, AUC - 0.8373, F1 - 0.7315, precision - 0.6371, training time - -12.0 seconds
2023-03-25 18:09:08,520 : [INFO]  Batch 140: Testing set : loss - 0.5784, accuracy - 0.6667, recall - 0.8627, AUC - 0.8515, F1 - 0.7213, precision - 0.6197
2023-03-25 18:09:08,528 : [INFO]  Batch 141 initialized 
2023-03-25 18:09:09,102 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:09,608 : [INFO]  ------------------------- Batch 141 training: round 1 -------------------------
2023-03-25 18:09:14,978 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-25 18:09:14,978 : [INFO]  ------------------------- Batch 141, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:15,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:15,067 : [INFO]  ------------------------- Batch 141 training: round 2 -------------------------
2023-03-25 18:09:17,981 : [INFO]  ------------------------- Batch round 2, loss: 0.5705 -------------------------
2023-03-25 18:09:17,982 : [INFO]  ------------------------- Batch 141, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:18,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:18,030 : [INFO]  ------------------------- Batch 141 training: round 3 -------------------------
2023-03-25 18:09:20,806 : [INFO]  ------------------------- Batch round 3, loss: 0.5736 -------------------------
2023-03-25 18:09:20,806 : [INFO]  ------------------------- Batch 141, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:20,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:20,883 : [INFO]  Batch number 141 model fetched from the server
2023-03-25 18:09:20,883 : [INFO]  ################ Batch 141: final global model evalution after 3 rounds ################
2023-03-25 18:09:22,632 : [INFO]  Batch 141: Training set : loss - 0.5802, accuracy - 0.7174, recall - 0.8587, AUC - 0.8207, F1 - 0.7524, precision - 0.6695, training time - -11.0 seconds
2023-03-25 18:09:22,632 : [INFO]  Batch 141: Testing set : loss - 0.5917, accuracy - 0.6863, recall - 0.8137, AUC - 0.7997, F1 - 0.7217, precision - 0.6484
2023-03-25 18:09:22,647 : [INFO]  Batch 142 initialized 
2023-03-25 18:09:23,244 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:23,772 : [INFO]  ------------------------- Batch 142 training: round 1 -------------------------
2023-03-25 18:09:29,181 : [INFO]  ------------------------- Batch round 1, loss: 0.5537 -------------------------
2023-03-25 18:09:29,181 : [INFO]  ------------------------- Batch 142, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:29,308 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:29,311 : [INFO]  ------------------------- Batch 142 training: round 2 -------------------------
2023-03-25 18:09:32,121 : [INFO]  ------------------------- Batch round 2, loss: 0.5613 -------------------------
2023-03-25 18:09:32,121 : [INFO]  ------------------------- Batch 142, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:32,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:32,217 : [INFO]  ------------------------- Batch 142 training: round 3 -------------------------
2023-03-25 18:09:35,106 : [INFO]  ------------------------- Batch round 3, loss: 0.5635 -------------------------
2023-03-25 18:09:35,106 : [INFO]  ------------------------- Batch 142, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:35,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:35,210 : [INFO]  Batch number 142 model fetched from the server
2023-03-25 18:09:35,210 : [INFO]  ################ Batch 142: final global model evalution after 3 rounds ################
2023-03-25 18:09:36,993 : [INFO]  Batch 142: Training set : loss - 0.5724, accuracy - 0.7174, recall - 0.9783, AUC - 0.8806, F1 - 0.7759, precision - 0.6429, training time - -11.0 seconds
2023-03-25 18:09:36,993 : [INFO]  Batch 142: Testing set : loss - 0.5667, accuracy - 0.7402, recall - 0.9314, AUC - 0.877, F1 - 0.7819, precision - 0.6738
2023-03-25 18:09:37,007 : [INFO]  Batch 143 initialized 
2023-03-25 18:09:37,584 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:38,083 : [INFO]  ------------------------- Batch 143 training: round 1 -------------------------
2023-03-25 18:09:43,404 : [INFO]  ------------------------- Batch round 1, loss: 0.5716 -------------------------
2023-03-25 18:09:43,404 : [INFO]  ------------------------- Batch 143, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:43,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:43,418 : [INFO]  ------------------------- Batch 143 training: round 2 -------------------------
2023-03-25 18:09:46,165 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 18:09:46,165 : [INFO]  ------------------------- Batch 143, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:46,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:46,380 : [INFO]  ------------------------- Batch 143 training: round 3 -------------------------
2023-03-25 18:09:49,182 : [INFO]  ------------------------- Batch round 3, loss: 0.566 -------------------------
2023-03-25 18:09:49,182 : [INFO]  ------------------------- Batch 143, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:49,408 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:49,417 : [INFO]  Batch number 143 model fetched from the server
2023-03-25 18:09:49,418 : [INFO]  ################ Batch 143: final global model evalution after 3 rounds ################
2023-03-25 18:09:51,302 : [INFO]  Batch 143: Training set : loss - 0.5797, accuracy - 0.6793, recall - 0.8587, AUC - 0.8344, F1 - 0.7281, precision - 0.632, training time - -11.0 seconds
2023-03-25 18:09:51,303 : [INFO]  Batch 143: Testing set : loss - 0.547, accuracy - 0.7549, recall - 0.8922, AUC - 0.8856, F1 - 0.7845, precision - 0.7
2023-03-25 18:09:51,317 : [INFO]  Batch 144 initialized 
2023-03-25 18:09:51,890 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:52,416 : [INFO]  ------------------------- Batch 144 training: round 1 -------------------------
2023-03-25 18:09:57,926 : [INFO]  ------------------------- Batch round 1, loss: 0.578 -------------------------
2023-03-25 18:09:57,926 : [INFO]  ------------------------- Batch 144, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:57,935 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:57,938 : [INFO]  ------------------------- Batch 144 training: round 2 -------------------------
2023-03-25 18:10:00,915 : [INFO]  ------------------------- Batch round 2, loss: 0.5745 -------------------------
2023-03-25 18:10:00,915 : [INFO]  ------------------------- Batch 144, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:00,925 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:00,929 : [INFO]  ------------------------- Batch 144 training: round 3 -------------------------
2023-03-25 18:10:03,909 : [INFO]  ------------------------- Batch round 3, loss: 0.5798 -------------------------
2023-03-25 18:10:03,909 : [INFO]  ------------------------- Batch 144, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:03,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:03,921 : [INFO]  Batch number 144 model fetched from the server
2023-03-25 18:10:03,922 : [INFO]  ################ Batch 144: final global model evalution after 3 rounds ################
2023-03-25 18:10:05,732 : [INFO]  Batch 144: Training set : loss - 0.5881, accuracy - 0.712, recall - 0.8804, AUC - 0.7999, F1 - 0.7535, precision - 0.6585, training time - -12.0 seconds
2023-03-25 18:10:05,732 : [INFO]  Batch 144: Testing set : loss - 0.5845, accuracy - 0.7059, recall - 0.9216, AUC - 0.8541, F1 - 0.7581, precision - 0.6438
2023-03-25 18:10:05,740 : [INFO]  Batch 145 initialized 
2023-03-25 18:10:06,311 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:06,822 : [INFO]  ------------------------- Batch 145 training: round 1 -------------------------
2023-03-25 18:10:12,323 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 18:10:12,323 : [INFO]  ------------------------- Batch 145, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:12,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:12,334 : [INFO]  ------------------------- Batch 145 training: round 2 -------------------------
2023-03-25 18:10:15,233 : [INFO]  ------------------------- Batch round 2, loss: 0.5681 -------------------------
2023-03-25 18:10:15,233 : [INFO]  ------------------------- Batch 145, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:15,241 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:15,244 : [INFO]  ------------------------- Batch 145 training: round 3 -------------------------
2023-03-25 18:10:18,122 : [INFO]  ------------------------- Batch round 3, loss: 0.5684 -------------------------
2023-03-25 18:10:18,123 : [INFO]  ------------------------- Batch 145, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:18,133 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:18,137 : [INFO]  Batch number 145 model fetched from the server
2023-03-25 18:10:18,137 : [INFO]  ################ Batch 145: final global model evalution after 3 rounds ################
2023-03-25 18:10:19,913 : [INFO]  Batch 145: Training set : loss - 0.578, accuracy - 0.6957, recall - 0.9239, AUC - 0.8724, F1 - 0.7522, precision - 0.6343, training time - -11.0 seconds
2023-03-25 18:10:19,914 : [INFO]  Batch 145: Testing set : loss - 0.5808, accuracy - 0.6912, recall - 0.902, AUC - 0.8458, F1 - 0.7449, precision - 0.6345
2023-03-25 18:10:19,954 : [INFO]  Batch 146 initialized 
2023-03-25 18:10:20,519 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:21,031 : [INFO]  ------------------------- Batch 146 training: round 1 -------------------------
2023-03-25 18:10:26,581 : [INFO]  ------------------------- Batch round 1, loss: 0.5742 -------------------------
2023-03-25 18:10:26,581 : [INFO]  ------------------------- Batch 146, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:26,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:26,672 : [INFO]  ------------------------- Batch 146 training: round 2 -------------------------
2023-03-25 18:10:29,613 : [INFO]  ------------------------- Batch round 2, loss: 0.5798 -------------------------
2023-03-25 18:10:29,613 : [INFO]  ------------------------- Batch 146, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:29,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:29,661 : [INFO]  ------------------------- Batch 146 training: round 3 -------------------------
2023-03-25 18:10:32,618 : [INFO]  ------------------------- Batch round 3, loss: 0.573 -------------------------
2023-03-25 18:10:32,618 : [INFO]  ------------------------- Batch 146, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:32,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:32,711 : [INFO]  Batch number 146 model fetched from the server
2023-03-25 18:10:32,712 : [INFO]  ################ Batch 146: final global model evalution after 3 rounds ################
2023-03-25 18:10:34,547 : [INFO]  Batch 146: Training set : loss - 0.5876, accuracy - 0.6902, recall - 0.8913, AUC - 0.823, F1 - 0.7421, precision - 0.6357, training time - -12.0 seconds
2023-03-25 18:10:34,547 : [INFO]  Batch 146: Testing set : loss - 0.5668, accuracy - 0.7255, recall - 0.9412, AUC - 0.893, F1 - 0.7742, precision - 0.6575
2023-03-25 18:10:34,560 : [INFO]  Batch 147 initialized 
2023-03-25 18:10:35,138 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:35,667 : [INFO]  ------------------------- Batch 147 training: round 1 -------------------------
2023-03-25 18:10:41,154 : [INFO]  ------------------------- Batch round 1, loss: 0.5763 -------------------------
2023-03-25 18:10:41,155 : [INFO]  ------------------------- Batch 147, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:41,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:41,165 : [INFO]  ------------------------- Batch 147 training: round 2 -------------------------
2023-03-25 18:10:44,004 : [INFO]  ------------------------- Batch round 2, loss: 0.5753 -------------------------
2023-03-25 18:10:44,004 : [INFO]  ------------------------- Batch 147, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:44,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:44,018 : [INFO]  ------------------------- Batch 147 training: round 3 -------------------------
2023-03-25 18:10:46,878 : [INFO]  ------------------------- Batch round 3, loss: 0.5687 -------------------------
2023-03-25 18:10:46,878 : [INFO]  ------------------------- Batch 147, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:46,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:46,892 : [INFO]  Batch number 147 model fetched from the server
2023-03-25 18:10:46,892 : [INFO]  ################ Batch 147: final global model evalution after 3 rounds ################
2023-03-25 18:10:48,780 : [INFO]  Batch 147: Training set : loss - 0.5867, accuracy - 0.7011, recall - 0.8804, AUC - 0.83, F1 - 0.7465, precision - 0.648, training time - -11.0 seconds
2023-03-25 18:10:48,781 : [INFO]  Batch 147: Testing set : loss - 0.6041, accuracy - 0.6618, recall - 0.902, AUC - 0.8283, F1 - 0.7273, precision - 0.6093
2023-03-25 18:10:48,793 : [INFO]  Batch 148 initialized 
2023-03-25 18:10:49,349 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:49,879 : [INFO]  ------------------------- Batch 148 training: round 1 -------------------------
2023-03-25 18:10:55,622 : [INFO]  ------------------------- Batch round 1, loss: 0.5929 -------------------------
2023-03-25 18:10:55,622 : [INFO]  ------------------------- Batch 148, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:55,631 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:55,633 : [INFO]  ------------------------- Batch 148 training: round 2 -------------------------
2023-03-25 18:10:58,696 : [INFO]  ------------------------- Batch round 2, loss: 0.5883 -------------------------
2023-03-25 18:10:58,696 : [INFO]  ------------------------- Batch 148, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:58,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:58,708 : [INFO]  ------------------------- Batch 148 training: round 3 -------------------------
2023-03-25 18:11:01,654 : [INFO]  ------------------------- Batch round 3, loss: 0.596 -------------------------
2023-03-25 18:11:01,654 : [INFO]  ------------------------- Batch 148, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:01,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:01,667 : [INFO]  Batch number 148 model fetched from the server
2023-03-25 18:11:01,667 : [INFO]  ################ Batch 148: final global model evalution after 3 rounds ################
2023-03-25 18:11:03,469 : [INFO]  Batch 148: Training set : loss - 0.6026, accuracy - 0.6685, recall - 0.9022, AUC - 0.8144, F1 - 0.7313, precision - 0.6148, training time - -12.0 seconds
2023-03-25 18:11:03,469 : [INFO]  Batch 148: Testing set : loss - 0.6072, accuracy - 0.652, recall - 0.8922, AUC - 0.831, F1 - 0.7194, precision - 0.6026
2023-03-25 18:11:03,478 : [INFO]  Batch 149 initialized 
2023-03-25 18:11:04,041 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:04,572 : [INFO]  ------------------------- Batch 149 training: round 1 -------------------------
2023-03-25 18:11:09,970 : [INFO]  ------------------------- Batch round 1, loss: 0.5833 -------------------------
2023-03-25 18:11:09,970 : [INFO]  ------------------------- Batch 149, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:09,979 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:09,981 : [INFO]  ------------------------- Batch 149 training: round 2 -------------------------
2023-03-25 18:11:12,924 : [INFO]  ------------------------- Batch round 2, loss: 0.5893 -------------------------
2023-03-25 18:11:12,924 : [INFO]  ------------------------- Batch 149, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:12,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:12,936 : [INFO]  ------------------------- Batch 149 training: round 3 -------------------------
2023-03-25 18:11:15,988 : [INFO]  ------------------------- Batch round 3, loss: 0.5838 -------------------------
2023-03-25 18:11:15,988 : [INFO]  ------------------------- Batch 149, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:15,998 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:16,000 : [INFO]  Batch number 149 model fetched from the server
2023-03-25 18:11:16,000 : [INFO]  ################ Batch 149: final global model evalution after 3 rounds ################
2023-03-25 18:11:17,776 : [INFO]  Batch 149: Training set : loss - 0.594, accuracy - 0.7065, recall - 0.8261, AUC - 0.796, F1 - 0.7379, precision - 0.6667, training time - -11.0 seconds
2023-03-25 18:11:17,776 : [INFO]  Batch 149: Testing set : loss - 0.6204, accuracy - 0.6471, recall - 0.7647, AUC - 0.746, F1 - 0.6842, precision - 0.619
2023-03-25 18:11:17,809 : [INFO]  Batch 150 initialized 
2023-03-25 18:11:18,374 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:18,905 : [INFO]  ------------------------- Batch 150 training: round 1 -------------------------
2023-03-25 18:11:24,530 : [INFO]  ------------------------- Batch round 1, loss: 0.5615 -------------------------
2023-03-25 18:11:24,530 : [INFO]  ------------------------- Batch 150, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:24,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:24,541 : [INFO]  ------------------------- Batch 150 training: round 2 -------------------------
2023-03-25 18:11:27,497 : [INFO]  ------------------------- Batch round 2, loss: 0.5685 -------------------------
2023-03-25 18:11:27,497 : [INFO]  ------------------------- Batch 150, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:27,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:27,510 : [INFO]  ------------------------- Batch 150 training: round 3 -------------------------
2023-03-25 18:11:30,510 : [INFO]  ------------------------- Batch round 3, loss: 0.5681 -------------------------
2023-03-25 18:11:30,510 : [INFO]  ------------------------- Batch 150, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:30,518 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:30,521 : [INFO]  Batch number 150 model fetched from the server
2023-03-25 18:11:30,521 : [INFO]  ################ Batch 150: final global model evalution after 3 rounds ################
2023-03-25 18:11:32,374 : [INFO]  Batch 150: Training set : loss - 0.5704, accuracy - 0.7228, recall - 0.8913, AUC - 0.8433, F1 - 0.7628, precision - 0.6667, training time - -12.0 seconds
2023-03-25 18:11:32,375 : [INFO]  Batch 150: Testing set : loss - 0.6076, accuracy - 0.6618, recall - 0.8725, AUC - 0.8138, F1 - 0.7206, precision - 0.6138
2023-03-25 18:11:32,387 : [INFO]  Batch 151 initialized 
2023-03-25 18:11:32,935 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:33,460 : [INFO]  ------------------------- Batch 151 training: round 1 -------------------------
2023-03-25 18:11:38,904 : [INFO]  ------------------------- Batch round 1, loss: 0.5634 -------------------------
2023-03-25 18:11:38,904 : [INFO]  ------------------------- Batch 151, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:38,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:38,917 : [INFO]  ------------------------- Batch 151 training: round 2 -------------------------
2023-03-25 18:11:41,680 : [INFO]  ------------------------- Batch round 2, loss: 0.5629 -------------------------
2023-03-25 18:11:41,680 : [INFO]  ------------------------- Batch 151, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:41,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:41,712 : [INFO]  ------------------------- Batch 151 training: round 3 -------------------------
2023-03-25 18:11:44,516 : [INFO]  ------------------------- Batch round 3, loss: 0.5658 -------------------------
2023-03-25 18:11:44,516 : [INFO]  ------------------------- Batch 151, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:44,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:44,529 : [INFO]  Batch number 151 model fetched from the server
2023-03-25 18:11:44,529 : [INFO]  ################ Batch 151: final global model evalution after 3 rounds ################
2023-03-25 18:11:46,269 : [INFO]  Batch 151: Training set : loss - 0.5669, accuracy - 0.7337, recall - 0.8913, AUC - 0.8677, F1 - 0.77, precision - 0.6777, training time - -11.0 seconds
2023-03-25 18:11:46,269 : [INFO]  Batch 151: Testing set : loss - 0.6073, accuracy - 0.6569, recall - 0.7941, AUC - 0.7814, F1 - 0.6983, precision - 0.6231
2023-03-25 18:11:46,283 : [INFO]  Batch 152 initialized 
2023-03-25 18:11:46,855 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:47,382 : [INFO]  ------------------------- Batch 152 training: round 1 -------------------------
2023-03-25 18:11:52,960 : [INFO]  ------------------------- Batch round 1, loss: 0.5683 -------------------------
2023-03-25 18:11:52,960 : [INFO]  ------------------------- Batch 152, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:52,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:52,972 : [INFO]  ------------------------- Batch 152 training: round 2 -------------------------
2023-03-25 18:11:55,910 : [INFO]  ------------------------- Batch round 2, loss: 0.5688 -------------------------
2023-03-25 18:11:55,910 : [INFO]  ------------------------- Batch 152, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:55,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:55,923 : [INFO]  ------------------------- Batch 152 training: round 3 -------------------------
2023-03-25 18:11:58,836 : [INFO]  ------------------------- Batch round 3, loss: 0.5678 -------------------------
2023-03-25 18:11:58,836 : [INFO]  ------------------------- Batch 152, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:58,847 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:58,850 : [INFO]  Batch number 152 model fetched from the server
2023-03-25 18:11:58,850 : [INFO]  ################ Batch 152: final global model evalution after 3 rounds ################
2023-03-25 18:12:00,650 : [INFO]  Batch 152: Training set : loss - 0.5843, accuracy - 0.6848, recall - 0.8152, AUC - 0.8056, F1 - 0.7212, precision - 0.6466, training time - -11.0 seconds
2023-03-25 18:12:00,650 : [INFO]  Batch 152: Testing set : loss - 0.5622, accuracy - 0.7549, recall - 0.9118, AUC - 0.8815, F1 - 0.7881, precision - 0.694
2023-03-25 18:12:00,665 : [INFO]  Batch 153 initialized 
2023-03-25 18:12:01,236 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:01,772 : [INFO]  ------------------------- Batch 153 training: round 1 -------------------------
2023-03-25 18:12:07,183 : [INFO]  ------------------------- Batch round 1, loss: 0.584 -------------------------
2023-03-25 18:12:07,184 : [INFO]  ------------------------- Batch 153, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:07,283 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:07,286 : [INFO]  ------------------------- Batch 153 training: round 2 -------------------------
2023-03-25 18:12:10,137 : [INFO]  ------------------------- Batch round 2, loss: 0.5868 -------------------------
2023-03-25 18:12:10,137 : [INFO]  ------------------------- Batch 153, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:10,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:10,288 : [INFO]  ------------------------- Batch 153 training: round 3 -------------------------
2023-03-25 18:12:13,068 : [INFO]  ------------------------- Batch round 3, loss: 0.5887 -------------------------
2023-03-25 18:12:13,068 : [INFO]  ------------------------- Batch 153, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:13,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:13,255 : [INFO]  Batch number 153 model fetched from the server
2023-03-25 18:12:13,255 : [INFO]  ################ Batch 153: final global model evalution after 3 rounds ################
2023-03-25 18:12:14,976 : [INFO]  Batch 153: Training set : loss - 0.5942, accuracy - 0.6848, recall - 0.8587, AUC - 0.8042, F1 - 0.7315, precision - 0.6371, training time - -11.0 seconds
2023-03-25 18:12:14,976 : [INFO]  Batch 153: Testing set : loss - 0.5941, accuracy - 0.6863, recall - 0.9216, AUC - 0.8471, F1 - 0.746, precision - 0.6267
2023-03-25 18:12:14,984 : [INFO]  Batch 154 initialized 
2023-03-25 18:12:15,545 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:16,049 : [INFO]  ------------------------- Batch 154 training: round 1 -------------------------
2023-03-25 18:12:21,364 : [INFO]  ------------------------- Batch round 1, loss: 0.5413 -------------------------
2023-03-25 18:12:21,365 : [INFO]  ------------------------- Batch 154, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:21,547 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:21,550 : [INFO]  ------------------------- Batch 154 training: round 2 -------------------------
2023-03-25 18:12:24,495 : [INFO]  ------------------------- Batch round 2, loss: 0.5485 -------------------------
2023-03-25 18:12:24,495 : [INFO]  ------------------------- Batch 154, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:24,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:24,576 : [INFO]  ------------------------- Batch 154 training: round 3 -------------------------
2023-03-25 18:12:27,530 : [INFO]  ------------------------- Batch round 3, loss: 0.5428 -------------------------
2023-03-25 18:12:27,531 : [INFO]  ------------------------- Batch 154, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:27,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:27,643 : [INFO]  Batch number 154 model fetched from the server
2023-03-25 18:12:27,643 : [INFO]  ################ Batch 154: final global model evalution after 3 rounds ################
2023-03-25 18:12:29,367 : [INFO]  Batch 154: Training set : loss - 0.5549, accuracy - 0.7228, recall - 0.8913, AUC - 0.8869, F1 - 0.7628, precision - 0.6667, training time - -12.0 seconds
2023-03-25 18:12:29,368 : [INFO]  Batch 154: Testing set : loss - 0.5717, accuracy - 0.7059, recall - 0.8725, AUC - 0.868, F1 - 0.7479, precision - 0.6544
2023-03-25 18:12:29,383 : [INFO]  Batch 155 initialized 
2023-03-25 18:12:29,951 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:30,475 : [INFO]  ------------------------- Batch 155 training: round 1 -------------------------
2023-03-25 18:12:35,952 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-25 18:12:35,952 : [INFO]  ------------------------- Batch 155, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:36,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:36,222 : [INFO]  ------------------------- Batch 155 training: round 2 -------------------------
2023-03-25 18:12:39,119 : [INFO]  ------------------------- Batch round 2, loss: 0.5597 -------------------------
2023-03-25 18:12:39,120 : [INFO]  ------------------------- Batch 155, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:39,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:39,307 : [INFO]  ------------------------- Batch 155 training: round 3 -------------------------
2023-03-25 18:12:42,070 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 18:12:42,071 : [INFO]  ------------------------- Batch 155, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:42,500 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:42,503 : [INFO]  Batch number 155 model fetched from the server
2023-03-25 18:12:42,503 : [INFO]  ################ Batch 155: final global model evalution after 3 rounds ################
2023-03-25 18:12:44,312 : [INFO]  Batch 155: Training set : loss - 0.5602, accuracy - 0.7663, recall - 0.913, AUC - 0.8514, F1 - 0.7962, precision - 0.7059, training time - -12.0 seconds
2023-03-25 18:12:44,312 : [INFO]  Batch 155: Testing set : loss - 0.5744, accuracy - 0.7157, recall - 0.8529, AUC - 0.8312, F1 - 0.75, precision - 0.6692
2023-03-25 18:12:44,325 : [INFO]  Batch 156 initialized 
2023-03-25 18:12:44,898 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:45,419 : [INFO]  ------------------------- Batch 156 training: round 1 -------------------------
2023-03-25 18:12:50,951 : [INFO]  ------------------------- Batch round 1, loss: 0.5746 -------------------------
2023-03-25 18:12:50,951 : [INFO]  ------------------------- Batch 156, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:51,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:51,006 : [INFO]  ------------------------- Batch 156 training: round 2 -------------------------
2023-03-25 18:12:53,861 : [INFO]  ------------------------- Batch round 2, loss: 0.5728 -------------------------
2023-03-25 18:12:53,861 : [INFO]  ------------------------- Batch 156, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:53,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:53,930 : [INFO]  ------------------------- Batch 156 training: round 3 -------------------------
2023-03-25 18:12:56,983 : [INFO]  ------------------------- Batch round 3, loss: 0.5695 -------------------------
2023-03-25 18:12:56,983 : [INFO]  ------------------------- Batch 156, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:57,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:57,194 : [INFO]  Batch number 156 model fetched from the server
2023-03-25 18:12:57,194 : [INFO]  ################ Batch 156: final global model evalution after 3 rounds ################
2023-03-25 18:12:59,018 : [INFO]  Batch 156: Training set : loss - 0.578, accuracy - 0.6902, recall - 0.9022, AUC - 0.8613, F1 - 0.7444, precision - 0.6336, training time - -12.0 seconds
2023-03-25 18:12:59,018 : [INFO]  Batch 156: Testing set : loss - 0.5584, accuracy - 0.7402, recall - 0.8725, AUC - 0.8681, F1 - 0.7706, precision - 0.6899
2023-03-25 18:12:59,035 : [INFO]  Batch 157 initialized 
2023-03-25 18:12:59,630 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:00,159 : [INFO]  ------------------------- Batch 157 training: round 1 -------------------------
2023-03-25 18:13:05,682 : [INFO]  ------------------------- Batch round 1, loss: 0.574 -------------------------
2023-03-25 18:13:05,682 : [INFO]  ------------------------- Batch 157, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:05,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:05,693 : [INFO]  ------------------------- Batch 157 training: round 2 -------------------------
2023-03-25 18:13:08,575 : [INFO]  ------------------------- Batch round 2, loss: 0.5804 -------------------------
2023-03-25 18:13:08,575 : [INFO]  ------------------------- Batch 157, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:08,585 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:08,587 : [INFO]  ------------------------- Batch 157 training: round 3 -------------------------
2023-03-25 18:13:11,459 : [INFO]  ------------------------- Batch round 3, loss: 0.5774 -------------------------
2023-03-25 18:13:11,459 : [INFO]  ------------------------- Batch 157, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:11,469 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:11,473 : [INFO]  Batch number 157 model fetched from the server
2023-03-25 18:13:11,473 : [INFO]  ################ Batch 157: final global model evalution after 3 rounds ################
2023-03-25 18:13:13,228 : [INFO]  Batch 157: Training set : loss - 0.5875, accuracy - 0.6902, recall - 0.8804, AUC - 0.8025, F1 - 0.7397, precision - 0.6378, training time - -11.0 seconds
2023-03-25 18:13:13,228 : [INFO]  Batch 157: Testing set : loss - 0.5636, accuracy - 0.7451, recall - 0.9118, AUC - 0.8674, F1 - 0.7815, precision - 0.6838
2023-03-25 18:13:13,239 : [INFO]  Batch 158 initialized 
2023-03-25 18:13:13,802 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:14,327 : [INFO]  ------------------------- Batch 158 training: round 1 -------------------------
2023-03-25 18:13:19,740 : [INFO]  ------------------------- Batch round 1, loss: 0.5881 -------------------------
2023-03-25 18:13:19,740 : [INFO]  ------------------------- Batch 158, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:19,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:19,752 : [INFO]  ------------------------- Batch 158 training: round 2 -------------------------
2023-03-25 18:13:22,787 : [INFO]  ------------------------- Batch round 2, loss: 0.589 -------------------------
2023-03-25 18:13:22,787 : [INFO]  ------------------------- Batch 158, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:22,797 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:22,800 : [INFO]  ------------------------- Batch 158 training: round 3 -------------------------
2023-03-25 18:13:25,785 : [INFO]  ------------------------- Batch round 3, loss: 0.5925 -------------------------
2023-03-25 18:13:25,785 : [INFO]  ------------------------- Batch 158, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:25,924 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:25,932 : [INFO]  Batch number 158 model fetched from the server
2023-03-25 18:13:25,932 : [INFO]  ################ Batch 158: final global model evalution after 3 rounds ################
2023-03-25 18:13:27,716 : [INFO]  Batch 158: Training set : loss - 0.6177, accuracy - 0.6576, recall - 0.8261, AUC - 0.7677, F1 - 0.707, precision - 0.6179, training time - -12.0 seconds
2023-03-25 18:13:27,716 : [INFO]  Batch 158: Testing set : loss - 0.5718, accuracy - 0.7157, recall - 0.8627, AUC - 0.8502, F1 - 0.7521, precision - 0.6667
2023-03-25 18:13:27,731 : [INFO]  Batch 159 initialized 
2023-03-25 18:13:28,307 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:28,850 : [INFO]  ------------------------- Batch 159 training: round 1 -------------------------
2023-03-25 18:13:34,424 : [INFO]  ------------------------- Batch round 1, loss: 0.5609 -------------------------
2023-03-25 18:13:34,424 : [INFO]  ------------------------- Batch 159, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:34,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:34,436 : [INFO]  ------------------------- Batch 159 training: round 2 -------------------------
2023-03-25 18:13:37,356 : [INFO]  ------------------------- Batch round 2, loss: 0.5667 -------------------------
2023-03-25 18:13:37,356 : [INFO]  ------------------------- Batch 159, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:37,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:37,368 : [INFO]  ------------------------- Batch 159 training: round 3 -------------------------
2023-03-25 18:13:40,236 : [INFO]  ------------------------- Batch round 3, loss: 0.557 -------------------------
2023-03-25 18:13:40,236 : [INFO]  ------------------------- Batch 159, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:40,249 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:40,254 : [INFO]  Batch number 159 model fetched from the server
2023-03-25 18:13:40,254 : [INFO]  ################ Batch 159: final global model evalution after 3 rounds ################
2023-03-25 18:13:42,126 : [INFO]  Batch 159: Training set : loss - 0.5622, accuracy - 0.7283, recall - 0.8587, AUC - 0.8549, F1 - 0.7596, precision - 0.681, training time - -11.0 seconds
2023-03-25 18:13:42,127 : [INFO]  Batch 159: Testing set : loss - 0.5754, accuracy - 0.6961, recall - 0.9118, AUC - 0.8507, F1 - 0.75, precision - 0.637
2023-03-25 18:13:42,137 : [INFO]  Batch 160 initialized 
2023-03-25 18:13:42,686 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:43,231 : [INFO]  ------------------------- Batch 160 training: round 1 -------------------------
2023-03-25 18:13:48,689 : [INFO]  ------------------------- Batch round 1, loss: 0.5593 -------------------------
2023-03-25 18:13:48,689 : [INFO]  ------------------------- Batch 160, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:48,700 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:48,703 : [INFO]  ------------------------- Batch 160 training: round 2 -------------------------
2023-03-25 18:13:51,654 : [INFO]  ------------------------- Batch round 2, loss: 0.5556 -------------------------
2023-03-25 18:13:51,654 : [INFO]  ------------------------- Batch 160, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:51,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:51,666 : [INFO]  ------------------------- Batch 160 training: round 3 -------------------------
2023-03-25 18:13:54,684 : [INFO]  ------------------------- Batch round 3, loss: 0.5597 -------------------------
2023-03-25 18:13:54,684 : [INFO]  ------------------------- Batch 160, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:54,694 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:54,697 : [INFO]  Batch number 160 model fetched from the server
2023-03-25 18:13:54,697 : [INFO]  ################ Batch 160: final global model evalution after 3 rounds ################
2023-03-25 18:13:56,505 : [INFO]  Batch 160: Training set : loss - 0.5668, accuracy - 0.7228, recall - 0.9457, AUC - 0.8804, F1 - 0.7733, precision - 0.6541, training time - -11.0 seconds
2023-03-25 18:13:56,505 : [INFO]  Batch 160: Testing set : loss - 0.5843, accuracy - 0.6569, recall - 0.8922, AUC - 0.8604, F1 - 0.7222, precision - 0.6067
2023-03-25 18:13:56,514 : [INFO]  Batch 161 initialized 
2023-03-25 18:13:57,078 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:57,596 : [INFO]  ------------------------- Batch 161 training: round 1 -------------------------
2023-03-25 18:14:03,067 : [INFO]  ------------------------- Batch round 1, loss: 0.5978 -------------------------
2023-03-25 18:14:03,067 : [INFO]  ------------------------- Batch 161, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:03,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:03,078 : [INFO]  ------------------------- Batch 161 training: round 2 -------------------------
2023-03-25 18:14:06,131 : [INFO]  ------------------------- Batch round 2, loss: 0.5964 -------------------------
2023-03-25 18:14:06,131 : [INFO]  ------------------------- Batch 161, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:06,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:06,143 : [INFO]  ------------------------- Batch 161 training: round 3 -------------------------
2023-03-25 18:14:09,156 : [INFO]  ------------------------- Batch round 3, loss: 0.5992 -------------------------
2023-03-25 18:14:09,156 : [INFO]  ------------------------- Batch 161, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:09,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:09,168 : [INFO]  Batch number 161 model fetched from the server
2023-03-25 18:14:09,168 : [INFO]  ################ Batch 161: final global model evalution after 3 rounds ################
2023-03-25 18:14:11,028 : [INFO]  Batch 161: Training set : loss - 0.6096, accuracy - 0.6685, recall - 0.8696, AUC - 0.8082, F1 - 0.724, precision - 0.6202, training time - -12.0 seconds
2023-03-25 18:14:11,028 : [INFO]  Batch 161: Testing set : loss - 0.5967, accuracy - 0.6765, recall - 0.9314, AUC - 0.8386, F1 - 0.7422, precision - 0.6169
2023-03-25 18:14:11,038 : [INFO]  Batch 162 initialized 
2023-03-25 18:14:11,624 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:12,149 : [INFO]  ------------------------- Batch 162 training: round 1 -------------------------
2023-03-25 18:14:17,433 : [INFO]  ------------------------- Batch round 1, loss: 0.5716 -------------------------
2023-03-25 18:14:17,433 : [INFO]  ------------------------- Batch 162, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:17,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:17,450 : [INFO]  ------------------------- Batch 162 training: round 2 -------------------------
2023-03-25 18:14:20,183 : [INFO]  ------------------------- Batch round 2, loss: 0.5739 -------------------------
2023-03-25 18:14:20,183 : [INFO]  ------------------------- Batch 162, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:20,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:20,271 : [INFO]  ------------------------- Batch 162 training: round 3 -------------------------
2023-03-25 18:14:23,053 : [INFO]  ------------------------- Batch round 3, loss: 0.5715 -------------------------
2023-03-25 18:14:23,053 : [INFO]  ------------------------- Batch 162, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:23,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:23,160 : [INFO]  Batch number 162 model fetched from the server
2023-03-25 18:14:23,160 : [INFO]  ################ Batch 162: final global model evalution after 3 rounds ################
2023-03-25 18:14:24,919 : [INFO]  Batch 162: Training set : loss - 0.5801, accuracy - 0.7011, recall - 0.9348, AUC - 0.8728, F1 - 0.7577, precision - 0.637, training time - -11.0 seconds
2023-03-25 18:14:24,919 : [INFO]  Batch 162: Testing set : loss - 0.541, accuracy - 0.7549, recall - 0.9216, AUC - 0.8975, F1 - 0.7899, precision - 0.6912
2023-03-25 18:14:24,932 : [INFO]  Batch 163 initialized 
2023-03-25 18:14:25,499 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:26,059 : [INFO]  ------------------------- Batch 163 training: round 1 -------------------------
2023-03-25 18:14:31,677 : [INFO]  ------------------------- Batch round 1, loss: 0.562 -------------------------
2023-03-25 18:14:31,677 : [INFO]  ------------------------- Batch 163, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:31,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:31,690 : [INFO]  ------------------------- Batch 163 training: round 2 -------------------------
2023-03-25 18:14:34,685 : [INFO]  ------------------------- Batch round 2, loss: 0.5613 -------------------------
2023-03-25 18:14:34,685 : [INFO]  ------------------------- Batch 163, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:34,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:34,697 : [INFO]  ------------------------- Batch 163 training: round 3 -------------------------
2023-03-25 18:14:37,734 : [INFO]  ------------------------- Batch round 3, loss: 0.5662 -------------------------
2023-03-25 18:14:37,734 : [INFO]  ------------------------- Batch 163, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:37,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:37,752 : [INFO]  Batch number 163 model fetched from the server
2023-03-25 18:14:37,753 : [INFO]  ################ Batch 163: final global model evalution after 3 rounds ################
2023-03-25 18:14:39,605 : [INFO]  Batch 163: Training set : loss - 0.5737, accuracy - 0.6902, recall - 0.8913, AUC - 0.8654, F1 - 0.7421, precision - 0.6357, training time - -12.0 seconds
2023-03-25 18:14:39,605 : [INFO]  Batch 163: Testing set : loss - 0.5706, accuracy - 0.7157, recall - 0.8922, AUC - 0.8594, F1 - 0.7583, precision - 0.6594
2023-03-25 18:14:39,611 : [INFO]  Batch 164 initialized 
2023-03-25 18:14:40,171 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:40,724 : [INFO]  ------------------------- Batch 164 training: round 1 -------------------------
2023-03-25 18:14:46,211 : [INFO]  ------------------------- Batch round 1, loss: 0.5775 -------------------------
2023-03-25 18:14:46,211 : [INFO]  ------------------------- Batch 164, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:46,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:46,225 : [INFO]  ------------------------- Batch 164 training: round 2 -------------------------
2023-03-25 18:14:49,286 : [INFO]  ------------------------- Batch round 2, loss: 0.5925 -------------------------
2023-03-25 18:14:49,286 : [INFO]  ------------------------- Batch 164, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:49,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:49,298 : [INFO]  ------------------------- Batch 164 training: round 3 -------------------------
2023-03-25 18:14:52,341 : [INFO]  ------------------------- Batch round 3, loss: 0.5951 -------------------------
2023-03-25 18:14:52,342 : [INFO]  ------------------------- Batch 164, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:52,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:52,353 : [INFO]  Batch number 164 model fetched from the server
2023-03-25 18:14:52,353 : [INFO]  ################ Batch 164: final global model evalution after 3 rounds ################
2023-03-25 18:14:54,210 : [INFO]  Batch 164: Training set : loss - 0.6005, accuracy - 0.712, recall - 0.9239, AUC - 0.8185, F1 - 0.7623, precision - 0.6489, training time - -12.0 seconds
2023-03-25 18:14:54,210 : [INFO]  Batch 164: Testing set : loss - 0.5436, accuracy - 0.7647, recall - 0.9412, AUC - 0.9145, F1 - 0.8, precision - 0.6957
2023-03-25 18:14:54,218 : [INFO]  Batch 165 initialized 
2023-03-25 18:14:54,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:55,297 : [INFO]  ------------------------- Batch 165 training: round 1 -------------------------
2023-03-25 18:15:00,700 : [INFO]  ------------------------- Batch round 1, loss: 0.5816 -------------------------
2023-03-25 18:15:00,700 : [INFO]  ------------------------- Batch 165, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:00,742 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:00,746 : [INFO]  ------------------------- Batch 165 training: round 2 -------------------------
2023-03-25 18:15:03,682 : [INFO]  ------------------------- Batch round 2, loss: 0.5918 -------------------------
2023-03-25 18:15:03,683 : [INFO]  ------------------------- Batch 165, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:03,820 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:03,823 : [INFO]  ------------------------- Batch 165 training: round 3 -------------------------
2023-03-25 18:15:06,638 : [INFO]  ------------------------- Batch round 3, loss: 0.5888 -------------------------
2023-03-25 18:15:06,638 : [INFO]  ------------------------- Batch 165, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:06,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:06,830 : [INFO]  Batch number 165 model fetched from the server
2023-03-25 18:15:06,830 : [INFO]  ################ Batch 165: final global model evalution after 3 rounds ################
2023-03-25 18:15:08,624 : [INFO]  Batch 165: Training set : loss - 0.6004, accuracy - 0.6793, recall - 0.8478, AUC - 0.817, F1 - 0.7256, precision - 0.6341, training time - -12.0 seconds
2023-03-25 18:15:08,624 : [INFO]  Batch 165: Testing set : loss - 0.6014, accuracy - 0.6814, recall - 0.8725, AUC - 0.8107, F1 - 0.7325, precision - 0.6312
2023-03-25 18:15:08,640 : [INFO]  Batch 166 initialized 
2023-03-25 18:15:09,194 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:09,757 : [INFO]  ------------------------- Batch 166 training: round 1 -------------------------
2023-03-25 18:15:15,071 : [INFO]  ------------------------- Batch round 1, loss: 0.5643 -------------------------
2023-03-25 18:15:15,072 : [INFO]  ------------------------- Batch 166, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:15,243 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:15,245 : [INFO]  ------------------------- Batch 166 training: round 2 -------------------------
2023-03-25 18:15:17,959 : [INFO]  ------------------------- Batch round 2, loss: 0.5618 -------------------------
2023-03-25 18:15:17,959 : [INFO]  ------------------------- Batch 166, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:18,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:18,141 : [INFO]  ------------------------- Batch 166 training: round 3 -------------------------
2023-03-25 18:15:20,956 : [INFO]  ------------------------- Batch round 3, loss: 0.5683 -------------------------
2023-03-25 18:15:20,956 : [INFO]  ------------------------- Batch 166, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:21,136 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:21,138 : [INFO]  Batch number 166 model fetched from the server
2023-03-25 18:15:21,139 : [INFO]  ################ Batch 166: final global model evalution after 3 rounds ################
2023-03-25 18:15:22,919 : [INFO]  Batch 166: Training set : loss - 0.5782, accuracy - 0.7065, recall - 0.9783, AUC - 0.8655, F1 - 0.7692, precision - 0.6338, training time - -11.0 seconds
2023-03-25 18:15:22,919 : [INFO]  Batch 166: Testing set : loss - 0.5601, accuracy - 0.7206, recall - 0.8922, AUC - 0.8706, F1 - 0.7615, precision - 0.6642
2023-03-25 18:15:22,930 : [INFO]  Batch 167 initialized 
2023-03-25 18:15:23,532 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:24,087 : [INFO]  ------------------------- Batch 167 training: round 1 -------------------------
2023-03-25 18:15:29,443 : [INFO]  ------------------------- Batch round 1, loss: 0.5652 -------------------------
2023-03-25 18:15:29,443 : [INFO]  ------------------------- Batch 167, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:29,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:29,458 : [INFO]  ------------------------- Batch 167 training: round 2 -------------------------
2023-03-25 18:15:32,284 : [INFO]  ------------------------- Batch round 2, loss: 0.5677 -------------------------
2023-03-25 18:15:32,285 : [INFO]  ------------------------- Batch 167, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:32,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:32,298 : [INFO]  ------------------------- Batch 167 training: round 3 -------------------------
2023-03-25 18:15:35,142 : [INFO]  ------------------------- Batch round 3, loss: 0.5702 -------------------------
2023-03-25 18:15:35,142 : [INFO]  ------------------------- Batch 167, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:35,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:35,155 : [INFO]  Batch number 167 model fetched from the server
2023-03-25 18:15:35,155 : [INFO]  ################ Batch 167: final global model evalution after 3 rounds ################
2023-03-25 18:15:37,005 : [INFO]  Batch 167: Training set : loss - 0.5784, accuracy - 0.7228, recall - 0.8696, AUC - 0.8192, F1 - 0.7583, precision - 0.6723, training time - -11.0 seconds
2023-03-25 18:15:37,006 : [INFO]  Batch 167: Testing set : loss - 0.5735, accuracy - 0.7304, recall - 0.8824, AUC - 0.8711, F1 - 0.766, precision - 0.6767
2023-03-25 18:15:37,015 : [INFO]  Batch 168 initialized 
2023-03-25 18:15:37,574 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:38,123 : [INFO]  ------------------------- Batch 168 training: round 1 -------------------------
2023-03-25 18:15:43,533 : [INFO]  ------------------------- Batch round 1, loss: 0.5819 -------------------------
2023-03-25 18:15:43,534 : [INFO]  ------------------------- Batch 168, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:43,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:43,717 : [INFO]  ------------------------- Batch 168 training: round 2 -------------------------
2023-03-25 18:15:46,713 : [INFO]  ------------------------- Batch round 2, loss: 0.5824 -------------------------
2023-03-25 18:15:46,713 : [INFO]  ------------------------- Batch 168, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:46,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:46,785 : [INFO]  ------------------------- Batch 168 training: round 3 -------------------------
2023-03-25 18:15:49,538 : [INFO]  ------------------------- Batch round 3, loss: 0.5803 -------------------------
2023-03-25 18:15:49,538 : [INFO]  ------------------------- Batch 168, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:49,823 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:49,827 : [INFO]  Batch number 168 model fetched from the server
2023-03-25 18:15:49,827 : [INFO]  ################ Batch 168: final global model evalution after 3 rounds ################
2023-03-25 18:15:51,640 : [INFO]  Batch 168: Training set : loss - 0.5892, accuracy - 0.7011, recall - 0.9022, AUC - 0.8091, F1 - 0.7511, precision - 0.6434, training time - -12.0 seconds
2023-03-25 18:15:51,640 : [INFO]  Batch 168: Testing set : loss - 0.5765, accuracy - 0.7206, recall - 0.8922, AUC - 0.8591, F1 - 0.7615, precision - 0.6642
2023-03-25 18:15:51,655 : [INFO]  Batch 169 initialized 
2023-03-25 18:15:52,230 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:52,794 : [INFO]  ------------------------- Batch 169 training: round 1 -------------------------
2023-03-25 18:15:58,126 : [INFO]  ------------------------- Batch round 1, loss: 0.5588 -------------------------
2023-03-25 18:15:58,126 : [INFO]  ------------------------- Batch 169, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:58,306 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:58,309 : [INFO]  ------------------------- Batch 169 training: round 2 -------------------------
2023-03-25 18:16:01,131 : [INFO]  ------------------------- Batch round 2, loss: 0.5654 -------------------------
2023-03-25 18:16:01,131 : [INFO]  ------------------------- Batch 169, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:01,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:01,301 : [INFO]  ------------------------- Batch 169 training: round 3 -------------------------
2023-03-25 18:16:04,196 : [INFO]  ------------------------- Batch round 3, loss: 0.5606 -------------------------
2023-03-25 18:16:04,196 : [INFO]  ------------------------- Batch 169, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:04,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:04,443 : [INFO]  Batch number 169 model fetched from the server
2023-03-25 18:16:04,443 : [INFO]  ################ Batch 169: final global model evalution after 3 rounds ################
2023-03-25 18:16:06,241 : [INFO]  Batch 169: Training set : loss - 0.565, accuracy - 0.7446, recall - 0.9565, AUC - 0.8598, F1 - 0.7892, precision - 0.6718, training time - -12.0 seconds
2023-03-25 18:16:06,242 : [INFO]  Batch 169: Testing set : loss - 0.5533, accuracy - 0.7402, recall - 0.902, AUC - 0.896, F1 - 0.7764, precision - 0.6815
2023-03-25 18:16:06,257 : [INFO]  Batch 170 initialized 
2023-03-25 18:16:06,835 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:07,380 : [INFO]  ------------------------- Batch 170 training: round 1 -------------------------
2023-03-25 18:16:13,105 : [INFO]  ------------------------- Batch round 1, loss: 0.5695 -------------------------
2023-03-25 18:16:13,105 : [INFO]  ------------------------- Batch 170, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:13,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:13,121 : [INFO]  ------------------------- Batch 170 training: round 2 -------------------------
2023-03-25 18:16:15,983 : [INFO]  ------------------------- Batch round 2, loss: 0.5699 -------------------------
2023-03-25 18:16:15,983 : [INFO]  ------------------------- Batch 170, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:16,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:16,027 : [INFO]  ------------------------- Batch 170 training: round 3 -------------------------
2023-03-25 18:16:18,904 : [INFO]  ------------------------- Batch round 3, loss: 0.5692 -------------------------
2023-03-25 18:16:18,904 : [INFO]  ------------------------- Batch 170, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:19,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:19,028 : [INFO]  Batch number 170 model fetched from the server
2023-03-25 18:16:19,028 : [INFO]  ################ Batch 170: final global model evalution after 3 rounds ################
2023-03-25 18:16:20,824 : [INFO]  Batch 170: Training set : loss - 0.5793, accuracy - 0.7065, recall - 0.8587, AUC - 0.811, F1 - 0.7453, precision - 0.6583, training time - -12.0 seconds
2023-03-25 18:16:20,824 : [INFO]  Batch 170: Testing set : loss - 0.5819, accuracy - 0.6814, recall - 0.8333, AUC - 0.8184, F1 - 0.7234, precision - 0.6391
2023-03-25 18:16:20,834 : [INFO]  Batch 171 initialized 
2023-03-25 18:16:21,430 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:22,010 : [INFO]  ------------------------- Batch 171 training: round 1 -------------------------
2023-03-25 18:16:27,517 : [INFO]  ------------------------- Batch round 1, loss: 0.5524 -------------------------
2023-03-25 18:16:27,517 : [INFO]  ------------------------- Batch 171, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:27,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:27,529 : [INFO]  ------------------------- Batch 171 training: round 2 -------------------------
2023-03-25 18:16:30,458 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-25 18:16:30,459 : [INFO]  ------------------------- Batch 171, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:30,468 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:30,471 : [INFO]  ------------------------- Batch 171 training: round 3 -------------------------
2023-03-25 18:16:33,463 : [INFO]  ------------------------- Batch round 3, loss: 0.556 -------------------------
2023-03-25 18:16:33,464 : [INFO]  ------------------------- Batch 171, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:33,473 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:33,476 : [INFO]  Batch number 171 model fetched from the server
2023-03-25 18:16:33,476 : [INFO]  ################ Batch 171: final global model evalution after 3 rounds ################
2023-03-25 18:16:35,256 : [INFO]  Batch 171: Training set : loss - 0.5631, accuracy - 0.75, recall - 0.8804, AUC - 0.8595, F1 - 0.7788, precision - 0.6983, training time - -11.0 seconds
2023-03-25 18:16:35,257 : [INFO]  Batch 171: Testing set : loss - 0.5828, accuracy - 0.6765, recall - 0.8431, AUC - 0.8181, F1 - 0.7227, precision - 0.6324
2023-03-25 18:16:35,264 : [INFO]  Batch 172 initialized 
2023-03-25 18:16:35,831 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:36,384 : [INFO]  ------------------------- Batch 172 training: round 1 -------------------------
2023-03-25 18:16:41,782 : [INFO]  ------------------------- Batch round 1, loss: 0.5862 -------------------------
2023-03-25 18:16:41,782 : [INFO]  ------------------------- Batch 172, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:41,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:41,796 : [INFO]  ------------------------- Batch 172 training: round 2 -------------------------
2023-03-25 18:16:44,710 : [INFO]  ------------------------- Batch round 2, loss: 0.593 -------------------------
2023-03-25 18:16:44,710 : [INFO]  ------------------------- Batch 172, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:44,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:44,723 : [INFO]  ------------------------- Batch 172 training: round 3 -------------------------
2023-03-25 18:16:47,566 : [INFO]  ------------------------- Batch round 3, loss: 0.586 -------------------------
2023-03-25 18:16:47,566 : [INFO]  ------------------------- Batch 172, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:47,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:47,578 : [INFO]  Batch number 172 model fetched from the server
2023-03-25 18:16:47,578 : [INFO]  ################ Batch 172: final global model evalution after 3 rounds ################
2023-03-25 18:16:49,348 : [INFO]  Batch 172: Training set : loss - 0.5966, accuracy - 0.6467, recall - 0.837, AUC - 0.8112, F1 - 0.7032, precision - 0.6063, training time - -11.0 seconds
2023-03-25 18:16:49,348 : [INFO]  Batch 172: Testing set : loss - 0.5764, accuracy - 0.701, recall - 0.8529, AUC - 0.8344, F1 - 0.7404, precision - 0.6541
2023-03-25 18:16:49,356 : [INFO]  Batch 173 initialized 
2023-03-25 18:16:49,920 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:50,487 : [INFO]  ------------------------- Batch 173 training: round 1 -------------------------
2023-03-25 18:16:55,893 : [INFO]  ------------------------- Batch round 1, loss: 0.5726 -------------------------
2023-03-25 18:16:55,893 : [INFO]  ------------------------- Batch 173, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:55,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:55,911 : [INFO]  ------------------------- Batch 173 training: round 2 -------------------------
2023-03-25 18:16:58,809 : [INFO]  ------------------------- Batch round 2, loss: 0.5772 -------------------------
2023-03-25 18:16:58,809 : [INFO]  ------------------------- Batch 173, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:58,819 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:58,821 : [INFO]  ------------------------- Batch 173 training: round 3 -------------------------
2023-03-25 18:17:01,701 : [INFO]  ------------------------- Batch round 3, loss: 0.5743 -------------------------
2023-03-25 18:17:01,702 : [INFO]  ------------------------- Batch 173, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:01,711 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:01,713 : [INFO]  Batch number 173 model fetched from the server
2023-03-25 18:17:01,713 : [INFO]  ################ Batch 173: final global model evalution after 3 rounds ################
2023-03-25 18:17:03,550 : [INFO]  Batch 173: Training set : loss - 0.5821, accuracy - 0.7174, recall - 0.9022, AUC - 0.8338, F1 - 0.7615, precision - 0.6587, training time - -11.0 seconds
2023-03-25 18:17:03,550 : [INFO]  Batch 173: Testing set : loss - 0.5784, accuracy - 0.7059, recall - 0.9118, AUC - 0.8622, F1 - 0.7561, precision - 0.6458
2023-03-25 18:17:03,557 : [INFO]  Batch 174 initialized 
2023-03-25 18:17:04,103 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:04,654 : [INFO]  ------------------------- Batch 174 training: round 1 -------------------------
2023-03-25 18:17:10,054 : [INFO]  ------------------------- Batch round 1, loss: 0.564 -------------------------
2023-03-25 18:17:10,054 : [INFO]  ------------------------- Batch 174, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:10,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:10,067 : [INFO]  ------------------------- Batch 174 training: round 2 -------------------------
2023-03-25 18:17:13,026 : [INFO]  ------------------------- Batch round 2, loss: 0.564 -------------------------
2023-03-25 18:17:13,026 : [INFO]  ------------------------- Batch 174, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:13,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:13,039 : [INFO]  ------------------------- Batch 174 training: round 3 -------------------------
2023-03-25 18:17:16,120 : [INFO]  ------------------------- Batch round 3, loss: 0.5688 -------------------------
2023-03-25 18:17:16,120 : [INFO]  ------------------------- Batch 174, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:16,130 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:16,133 : [INFO]  Batch number 174 model fetched from the server
2023-03-25 18:17:16,133 : [INFO]  ################ Batch 174: final global model evalution after 3 rounds ################
2023-03-25 18:17:17,974 : [INFO]  Batch 174: Training set : loss - 0.5747, accuracy - 0.7391, recall - 0.913, AUC - 0.856, F1 - 0.7778, precision - 0.6774, training time - -11.0 seconds
2023-03-25 18:17:17,974 : [INFO]  Batch 174: Testing set : loss - 0.5964, accuracy - 0.7059, recall - 0.8725, AUC - 0.8291, F1 - 0.7479, precision - 0.6544
2023-03-25 18:17:17,985 : [INFO]  Batch 175 initialized 
2023-03-25 18:17:18,547 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:19,086 : [INFO]  ------------------------- Batch 175 training: round 1 -------------------------
2023-03-25 18:17:24,643 : [INFO]  ------------------------- Batch round 1, loss: 0.5929 -------------------------
2023-03-25 18:17:24,644 : [INFO]  ------------------------- Batch 175, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:24,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:24,655 : [INFO]  ------------------------- Batch 175 training: round 2 -------------------------
2023-03-25 18:17:27,696 : [INFO]  ------------------------- Batch round 2, loss: 0.5959 -------------------------
2023-03-25 18:17:27,696 : [INFO]  ------------------------- Batch 175, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:27,705 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:27,708 : [INFO]  ------------------------- Batch 175 training: round 3 -------------------------
2023-03-25 18:17:30,868 : [INFO]  ------------------------- Batch round 3, loss: 0.5945 -------------------------
2023-03-25 18:17:30,868 : [INFO]  ------------------------- Batch 175, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:30,878 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:30,881 : [INFO]  Batch number 175 model fetched from the server
2023-03-25 18:17:30,881 : [INFO]  ################ Batch 175: final global model evalution after 3 rounds ################
2023-03-25 18:17:32,782 : [INFO]  Batch 175: Training set : loss - 0.629, accuracy - 0.6467, recall - 0.8913, AUC - 0.7825, F1 - 0.7162, precision - 0.5985, training time - -12.0 seconds
2023-03-25 18:17:32,782 : [INFO]  Batch 175: Testing set : loss - 0.6041, accuracy - 0.6618, recall - 0.9118, AUC - 0.8372, F1 - 0.7294, precision - 0.6078
2023-03-25 18:17:32,791 : [INFO]  Batch 176 initialized 
2023-03-25 18:17:33,356 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:33,885 : [INFO]  ------------------------- Batch 176 training: round 1 -------------------------
2023-03-25 18:17:39,424 : [INFO]  ------------------------- Batch round 1, loss: 0.5657 -------------------------
2023-03-25 18:17:39,424 : [INFO]  ------------------------- Batch 176, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:39,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:39,436 : [INFO]  ------------------------- Batch 176 training: round 2 -------------------------
2023-03-25 18:17:42,270 : [INFO]  ------------------------- Batch round 2, loss: 0.5663 -------------------------
2023-03-25 18:17:42,270 : [INFO]  ------------------------- Batch 176, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:42,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:42,457 : [INFO]  ------------------------- Batch 176 training: round 3 -------------------------
2023-03-25 18:17:45,406 : [INFO]  ------------------------- Batch round 3, loss: 0.5646 -------------------------
2023-03-25 18:17:45,407 : [INFO]  ------------------------- Batch 176, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:45,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:45,430 : [INFO]  Batch number 176 model fetched from the server
2023-03-25 18:17:45,430 : [INFO]  ################ Batch 176: final global model evalution after 3 rounds ################
2023-03-25 18:17:47,217 : [INFO]  Batch 176: Training set : loss - 0.5721, accuracy - 0.7174, recall - 0.837, AUC - 0.8349, F1 - 0.7476, precision - 0.6754, training time - -12.0 seconds
2023-03-25 18:17:47,217 : [INFO]  Batch 176: Testing set : loss - 0.5652, accuracy - 0.7304, recall - 0.8725, AUC - 0.8637, F1 - 0.7639, precision - 0.6794
2023-03-25 18:17:47,228 : [INFO]  Batch 177 initialized 
2023-03-25 18:17:47,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:48,346 : [INFO]  ------------------------- Batch 177 training: round 1 -------------------------
2023-03-25 18:17:53,725 : [INFO]  ------------------------- Batch round 1, loss: 0.6017 -------------------------
2023-03-25 18:17:53,725 : [INFO]  ------------------------- Batch 177, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:53,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:53,736 : [INFO]  ------------------------- Batch 177 training: round 2 -------------------------
2023-03-25 18:17:56,549 : [INFO]  ------------------------- Batch round 2, loss: 0.5988 -------------------------
2023-03-25 18:17:56,549 : [INFO]  ------------------------- Batch 177, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:56,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:56,642 : [INFO]  ------------------------- Batch 177 training: round 3 -------------------------
2023-03-25 18:17:59,526 : [INFO]  ------------------------- Batch round 3, loss: 0.6041 -------------------------
2023-03-25 18:17:59,527 : [INFO]  ------------------------- Batch 177, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:59,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:59,592 : [INFO]  Batch number 177 model fetched from the server
2023-03-25 18:17:59,592 : [INFO]  ################ Batch 177: final global model evalution after 3 rounds ################
2023-03-25 18:18:01,369 : [INFO]  Batch 177: Training set : loss - 0.6169, accuracy - 0.6902, recall - 0.8696, AUC - 0.7678, F1 - 0.7373, precision - 0.64, training time - -11.0 seconds
2023-03-25 18:18:01,369 : [INFO]  Batch 177: Testing set : loss - 0.587, accuracy - 0.6863, recall - 0.8824, AUC - 0.8226, F1 - 0.7377, precision - 0.6338
2023-03-25 18:18:01,381 : [INFO]  Batch 178 initialized 
2023-03-25 18:18:01,951 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:02,508 : [INFO]  ------------------------- Batch 178 training: round 1 -------------------------
2023-03-25 18:18:07,814 : [INFO]  ------------------------- Batch round 1, loss: 0.5525 -------------------------
2023-03-25 18:18:07,814 : [INFO]  ------------------------- Batch 178, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:08,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:08,083 : [INFO]  ------------------------- Batch 178 training: round 2 -------------------------
2023-03-25 18:18:10,940 : [INFO]  ------------------------- Batch round 2, loss: 0.5539 -------------------------
2023-03-25 18:18:10,941 : [INFO]  ------------------------- Batch 178, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:11,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:11,163 : [INFO]  ------------------------- Batch 178 training: round 3 -------------------------
2023-03-25 18:18:13,916 : [INFO]  ------------------------- Batch round 3, loss: 0.5542 -------------------------
2023-03-25 18:18:13,916 : [INFO]  ------------------------- Batch 178, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:14,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:14,181 : [INFO]  Batch number 178 model fetched from the server
2023-03-25 18:18:14,181 : [INFO]  ################ Batch 178: final global model evalution after 3 rounds ################
2023-03-25 18:18:15,957 : [INFO]  Batch 178: Training set : loss - 0.5731, accuracy - 0.712, recall - 0.9457, AUC - 0.8488, F1 - 0.7665, precision - 0.6444, training time - -12.0 seconds
2023-03-25 18:18:15,958 : [INFO]  Batch 178: Testing set : loss - 0.5788, accuracy - 0.7108, recall - 0.8529, AUC - 0.828, F1 - 0.7468, precision - 0.6641
2023-03-25 18:18:15,972 : [INFO]  Batch 179 initialized 
2023-03-25 18:18:16,532 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:17,099 : [INFO]  ------------------------- Batch 179 training: round 1 -------------------------
2023-03-25 18:18:22,523 : [INFO]  ------------------------- Batch round 1, loss: 0.579 -------------------------
2023-03-25 18:18:22,523 : [INFO]  ------------------------- Batch 179, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:22,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:22,697 : [INFO]  ------------------------- Batch 179 training: round 2 -------------------------
2023-03-25 18:18:25,568 : [INFO]  ------------------------- Batch round 2, loss: 0.5824 -------------------------
2023-03-25 18:18:25,569 : [INFO]  ------------------------- Batch 179, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:25,759 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:25,761 : [INFO]  ------------------------- Batch 179 training: round 3 -------------------------
2023-03-25 18:18:28,548 : [INFO]  ------------------------- Batch round 3, loss: 0.5776 -------------------------
2023-03-25 18:18:28,548 : [INFO]  ------------------------- Batch 179, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:28,761 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:28,764 : [INFO]  Batch number 179 model fetched from the server
2023-03-25 18:18:28,764 : [INFO]  ################ Batch 179: final global model evalution after 3 rounds ################
2023-03-25 18:18:30,544 : [INFO]  Batch 179: Training set : loss - 0.5934, accuracy - 0.6957, recall - 0.8804, AUC - 0.8075, F1 - 0.7431, precision - 0.6429, training time - -12.0 seconds
2023-03-25 18:18:30,545 : [INFO]  Batch 179: Testing set : loss - 0.5928, accuracy - 0.6667, recall - 0.8824, AUC - 0.8205, F1 - 0.7258, precision - 0.6164
2023-03-25 18:18:30,561 : [INFO]  Batch 180 initialized 
2023-03-25 18:18:31,142 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:31,698 : [INFO]  ------------------------- Batch 180 training: round 1 -------------------------
2023-03-25 18:18:37,132 : [INFO]  ------------------------- Batch round 1, loss: 0.5476 -------------------------
2023-03-25 18:18:37,132 : [INFO]  ------------------------- Batch 180, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:37,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:37,177 : [INFO]  ------------------------- Batch 180 training: round 2 -------------------------
2023-03-25 18:18:40,043 : [INFO]  ------------------------- Batch round 2, loss: 0.5468 -------------------------
2023-03-25 18:18:40,044 : [INFO]  ------------------------- Batch 180, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:40,221 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:40,224 : [INFO]  ------------------------- Batch 180 training: round 3 -------------------------
2023-03-25 18:18:43,136 : [INFO]  ------------------------- Batch round 3, loss: 0.5503 -------------------------
2023-03-25 18:18:43,137 : [INFO]  ------------------------- Batch 180, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:43,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:43,212 : [INFO]  Batch number 180 model fetched from the server
2023-03-25 18:18:43,212 : [INFO]  ################ Batch 180: final global model evalution after 3 rounds ################
2023-03-25 18:18:45,021 : [INFO]  Batch 180: Training set : loss - 0.5486, accuracy - 0.7989, recall - 0.9348, AUC - 0.8881, F1 - 0.823, precision - 0.735, training time - -12.0 seconds
2023-03-25 18:18:45,021 : [INFO]  Batch 180: Testing set : loss - 0.5746, accuracy - 0.6961, recall - 0.9118, AUC - 0.8581, F1 - 0.75, precision - 0.637
2023-03-25 18:18:45,028 : [INFO]  Batch 181 initialized 
2023-03-25 18:18:45,590 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:46,174 : [INFO]  ------------------------- Batch 181 training: round 1 -------------------------
2023-03-25 18:18:51,533 : [INFO]  ------------------------- Batch round 1, loss: 0.5704 -------------------------
2023-03-25 18:18:51,533 : [INFO]  ------------------------- Batch 181, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:51,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:51,551 : [INFO]  ------------------------- Batch 181 training: round 2 -------------------------
2023-03-25 18:18:54,388 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-25 18:18:54,388 : [INFO]  ------------------------- Batch 181, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:54,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:54,424 : [INFO]  ------------------------- Batch 181 training: round 3 -------------------------
2023-03-25 18:18:57,279 : [INFO]  ------------------------- Batch round 3, loss: 0.5699 -------------------------
2023-03-25 18:18:57,279 : [INFO]  ------------------------- Batch 181, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:57,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:57,336 : [INFO]  Batch number 181 model fetched from the server
2023-03-25 18:18:57,336 : [INFO]  ################ Batch 181: final global model evalution after 3 rounds ################
2023-03-25 18:18:59,055 : [INFO]  Batch 181: Training set : loss - 0.5838, accuracy - 0.6848, recall - 0.8696, AUC - 0.8313, F1 - 0.7339, precision - 0.6349, training time - -11.0 seconds
2023-03-25 18:18:59,055 : [INFO]  Batch 181: Testing set : loss - 0.5682, accuracy - 0.7353, recall - 0.9412, AUC - 0.8592, F1 - 0.7805, precision - 0.6667
2023-03-25 18:18:59,063 : [INFO]  Batch 182 initialized 
2023-03-25 18:18:59,619 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:00,208 : [INFO]  ------------------------- Batch 182 training: round 1 -------------------------
2023-03-25 18:19:05,511 : [INFO]  ------------------------- Batch round 1, loss: 0.5543 -------------------------
2023-03-25 18:19:05,511 : [INFO]  ------------------------- Batch 182, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:05,597 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:05,600 : [INFO]  ------------------------- Batch 182 training: round 2 -------------------------
2023-03-25 18:19:08,420 : [INFO]  ------------------------- Batch round 2, loss: 0.5621 -------------------------
2023-03-25 18:19:08,420 : [INFO]  ------------------------- Batch 182, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:08,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:08,526 : [INFO]  ------------------------- Batch 182 training: round 3 -------------------------
2023-03-25 18:19:11,336 : [INFO]  ------------------------- Batch round 3, loss: 0.5623 -------------------------
2023-03-25 18:19:11,336 : [INFO]  ------------------------- Batch 182, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:11,441 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:11,444 : [INFO]  Batch number 182 model fetched from the server
2023-03-25 18:19:11,445 : [INFO]  ################ Batch 182: final global model evalution after 3 rounds ################
2023-03-25 18:19:13,197 : [INFO]  Batch 182: Training set : loss - 0.572, accuracy - 0.7228, recall - 0.8804, AUC - 0.8557, F1 - 0.7606, precision - 0.6694, training time - -11.0 seconds
2023-03-25 18:19:13,198 : [INFO]  Batch 182: Testing set : loss - 0.5839, accuracy - 0.7304, recall - 0.902, AUC - 0.8441, F1 - 0.7699, precision - 0.6715
2023-03-25 18:19:13,212 : [INFO]  Batch 183 initialized 
2023-03-25 18:19:13,776 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:14,354 : [INFO]  ------------------------- Batch 183 training: round 1 -------------------------
2023-03-25 18:19:19,740 : [INFO]  ------------------------- Batch round 1, loss: 0.5825 -------------------------
2023-03-25 18:19:19,740 : [INFO]  ------------------------- Batch 183, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:19,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:19,754 : [INFO]  ------------------------- Batch 183 training: round 2 -------------------------
2023-03-25 18:19:22,701 : [INFO]  ------------------------- Batch round 2, loss: 0.5828 -------------------------
2023-03-25 18:19:22,701 : [INFO]  ------------------------- Batch 183, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:22,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:22,830 : [INFO]  ------------------------- Batch 183 training: round 3 -------------------------
2023-03-25 18:19:25,729 : [INFO]  ------------------------- Batch round 3, loss: 0.5827 -------------------------
2023-03-25 18:19:25,729 : [INFO]  ------------------------- Batch 183, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:25,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:25,743 : [INFO]  Batch number 183 model fetched from the server
2023-03-25 18:19:25,743 : [INFO]  ################ Batch 183: final global model evalution after 3 rounds ################
2023-03-25 18:19:27,525 : [INFO]  Batch 183: Training set : loss - 0.592, accuracy - 0.6739, recall - 0.8261, AUC - 0.8221, F1 - 0.717, precision - 0.6333, training time - -11.0 seconds
2023-03-25 18:19:27,525 : [INFO]  Batch 183: Testing set : loss - 0.5909, accuracy - 0.6667, recall - 0.8235, AUC - 0.8247, F1 - 0.7119, precision - 0.6269
2023-03-25 18:19:27,539 : [INFO]  Batch 184 initialized 
2023-03-25 18:19:28,102 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:28,686 : [INFO]  ------------------------- Batch 184 training: round 1 -------------------------
2023-03-25 18:19:34,084 : [INFO]  ------------------------- Batch round 1, loss: 0.5255 -------------------------
2023-03-25 18:19:34,084 : [INFO]  ------------------------- Batch 184, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:34,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:34,097 : [INFO]  ------------------------- Batch 184 training: round 2 -------------------------
2023-03-25 18:19:36,946 : [INFO]  ------------------------- Batch round 2, loss: 0.5401 -------------------------
2023-03-25 18:19:36,946 : [INFO]  ------------------------- Batch 184, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:36,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:36,960 : [INFO]  ------------------------- Batch 184 training: round 3 -------------------------
2023-03-25 18:19:39,741 : [INFO]  ------------------------- Batch round 3, loss: 0.534 -------------------------
2023-03-25 18:19:39,741 : [INFO]  ------------------------- Batch 184, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:39,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:39,761 : [INFO]  Batch number 184 model fetched from the server
2023-03-25 18:19:39,761 : [INFO]  ################ Batch 184: final global model evalution after 3 rounds ################
2023-03-25 18:19:41,549 : [INFO]  Batch 184: Training set : loss - 0.5407, accuracy - 0.7826, recall - 0.913, AUC - 0.8959, F1 - 0.8077, precision - 0.7241, training time - -11.0 seconds
2023-03-25 18:19:41,549 : [INFO]  Batch 184: Testing set : loss - 0.5836, accuracy - 0.6863, recall - 0.8725, AUC - 0.8349, F1 - 0.7355, precision - 0.6357
2023-03-25 18:19:41,559 : [INFO]  Batch 185 initialized 
2023-03-25 18:19:42,120 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:42,707 : [INFO]  ------------------------- Batch 185 training: round 1 -------------------------
2023-03-25 18:19:47,982 : [INFO]  ------------------------- Batch round 1, loss: 0.5717 -------------------------
2023-03-25 18:19:47,983 : [INFO]  ------------------------- Batch 185, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:48,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:48,098 : [INFO]  ------------------------- Batch 185 training: round 2 -------------------------
2023-03-25 18:19:50,813 : [INFO]  ------------------------- Batch round 2, loss: 0.5726 -------------------------
2023-03-25 18:19:50,813 : [INFO]  ------------------------- Batch 185, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:50,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:50,832 : [INFO]  ------------------------- Batch 185 training: round 3 -------------------------
2023-03-25 18:19:53,581 : [INFO]  ------------------------- Batch round 3, loss: 0.5674 -------------------------
2023-03-25 18:19:53,581 : [INFO]  ------------------------- Batch 185, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:53,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:53,695 : [INFO]  Batch number 185 model fetched from the server
2023-03-25 18:19:53,695 : [INFO]  ################ Batch 185: final global model evalution after 3 rounds ################
2023-03-25 18:19:55,481 : [INFO]  Batch 185: Training set : loss - 0.5781, accuracy - 0.7337, recall - 0.9457, AUC - 0.8243, F1 - 0.7803, precision - 0.6641, training time - -11.0 seconds
2023-03-25 18:19:55,481 : [INFO]  Batch 185: Testing set : loss - 0.5785, accuracy - 0.7059, recall - 0.9412, AUC - 0.8599, F1 - 0.7619, precision - 0.64
2023-03-25 18:19:55,494 : [INFO]  Batch 186 initialized 
2023-03-25 18:19:56,050 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:56,631 : [INFO]  ------------------------- Batch 186 training: round 1 -------------------------
2023-03-25 18:20:02,193 : [INFO]  ------------------------- Batch round 1, loss: 0.5814 -------------------------
2023-03-25 18:20:02,194 : [INFO]  ------------------------- Batch 186, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:02,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:02,238 : [INFO]  ------------------------- Batch 186 training: round 2 -------------------------
2023-03-25 18:20:05,210 : [INFO]  ------------------------- Batch round 2, loss: 0.584 -------------------------
2023-03-25 18:20:05,210 : [INFO]  ------------------------- Batch 186, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:05,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:05,222 : [INFO]  ------------------------- Batch 186 training: round 3 -------------------------
2023-03-25 18:20:08,175 : [INFO]  ------------------------- Batch round 3, loss: 0.5898 -------------------------
2023-03-25 18:20:08,175 : [INFO]  ------------------------- Batch 186, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:08,196 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:08,201 : [INFO]  Batch number 186 model fetched from the server
2023-03-25 18:20:08,201 : [INFO]  ################ Batch 186: final global model evalution after 3 rounds ################
2023-03-25 18:20:10,051 : [INFO]  Batch 186: Training set : loss - 0.5948, accuracy - 0.6848, recall - 0.837, AUC - 0.8013, F1 - 0.7264, precision - 0.6417, training time - -12.0 seconds
2023-03-25 18:20:10,051 : [INFO]  Batch 186: Testing set : loss - 0.5739, accuracy - 0.7206, recall - 0.9314, AUC - 0.8773, F1 - 0.7692, precision - 0.6552
2023-03-25 18:20:10,062 : [INFO]  Batch 187 initialized 
2023-03-25 18:20:10,636 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:11,191 : [INFO]  ------------------------- Batch 187 training: round 1 -------------------------
2023-03-25 18:20:16,592 : [INFO]  ------------------------- Batch round 1, loss: 0.5791 -------------------------
2023-03-25 18:20:16,593 : [INFO]  ------------------------- Batch 187, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:16,603 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:16,606 : [INFO]  ------------------------- Batch 187 training: round 2 -------------------------
2023-03-25 18:20:19,485 : [INFO]  ------------------------- Batch round 2, loss: 0.579 -------------------------
2023-03-25 18:20:19,486 : [INFO]  ------------------------- Batch 187, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:19,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:19,540 : [INFO]  ------------------------- Batch 187 training: round 3 -------------------------
2023-03-25 18:20:22,485 : [INFO]  ------------------------- Batch round 3, loss: 0.5816 -------------------------
2023-03-25 18:20:22,485 : [INFO]  ------------------------- Batch 187, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:22,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:22,522 : [INFO]  Batch number 187 model fetched from the server
2023-03-25 18:20:22,522 : [INFO]  ################ Batch 187: final global model evalution after 3 rounds ################
2023-03-25 18:20:24,352 : [INFO]  Batch 187: Training set : loss - 0.5835, accuracy - 0.7065, recall - 0.8478, AUC - 0.8361, F1 - 0.7429, precision - 0.661, training time - -11.0 seconds
2023-03-25 18:20:24,352 : [INFO]  Batch 187: Testing set : loss - 0.5741, accuracy - 0.7108, recall - 0.9412, AUC - 0.8777, F1 - 0.7649, precision - 0.6443
2023-03-25 18:20:24,366 : [INFO]  Batch 188 initialized 
2023-03-25 18:20:24,934 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:25,504 : [INFO]  ------------------------- Batch 188 training: round 1 -------------------------
2023-03-25 18:20:31,202 : [INFO]  ------------------------- Batch round 1, loss: 0.5701 -------------------------
2023-03-25 18:20:31,202 : [INFO]  ------------------------- Batch 188, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:31,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:31,218 : [INFO]  ------------------------- Batch 188 training: round 2 -------------------------
2023-03-25 18:20:34,208 : [INFO]  ------------------------- Batch round 2, loss: 0.5761 -------------------------
2023-03-25 18:20:34,209 : [INFO]  ------------------------- Batch 188, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:34,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:34,258 : [INFO]  ------------------------- Batch 188 training: round 3 -------------------------
2023-03-25 18:20:37,149 : [INFO]  ------------------------- Batch round 3, loss: 0.5714 -------------------------
2023-03-25 18:20:37,149 : [INFO]  ------------------------- Batch 188, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:37,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:37,178 : [INFO]  Batch number 188 model fetched from the server
2023-03-25 18:20:37,178 : [INFO]  ################ Batch 188: final global model evalution after 3 rounds ################
2023-03-25 18:20:38,950 : [INFO]  Batch 188: Training set : loss - 0.5974, accuracy - 0.6685, recall - 0.8152, AUC - 0.7881, F1 - 0.7109, precision - 0.6303, training time - -12.0 seconds
2023-03-25 18:20:38,951 : [INFO]  Batch 188: Testing set : loss - 0.6004, accuracy - 0.652, recall - 0.8431, AUC - 0.8185, F1 - 0.7078, precision - 0.6099
2023-03-25 18:20:38,963 : [INFO]  Batch 189 initialized 
2023-03-25 18:20:39,562 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:40,170 : [INFO]  ------------------------- Batch 189 training: round 1 -------------------------
2023-03-25 18:20:45,665 : [INFO]  ------------------------- Batch round 1, loss: 0.5744 -------------------------
2023-03-25 18:20:45,665 : [INFO]  ------------------------- Batch 189, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:45,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:45,704 : [INFO]  ------------------------- Batch 189 training: round 2 -------------------------
2023-03-25 18:20:48,516 : [INFO]  ------------------------- Batch round 2, loss: 0.5752 -------------------------
2023-03-25 18:20:48,516 : [INFO]  ------------------------- Batch 189, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:48,596 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:48,599 : [INFO]  ------------------------- Batch 189 training: round 3 -------------------------
2023-03-25 18:20:51,475 : [INFO]  ------------------------- Batch round 3, loss: 0.5824 -------------------------
2023-03-25 18:20:51,475 : [INFO]  ------------------------- Batch 189, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:51,486 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:51,488 : [INFO]  Batch number 189 model fetched from the server
2023-03-25 18:20:51,488 : [INFO]  ################ Batch 189: final global model evalution after 3 rounds ################
2023-03-25 18:20:53,257 : [INFO]  Batch 189: Training set : loss - 0.5967, accuracy - 0.6522, recall - 0.8152, AUC - 0.8035, F1 - 0.7009, precision - 0.6148, training time - -11.0 seconds
2023-03-25 18:20:53,258 : [INFO]  Batch 189: Testing set : loss - 0.5994, accuracy - 0.6618, recall - 0.7647, AUC - 0.77, F1 - 0.6933, precision - 0.6341
2023-03-25 18:20:53,265 : [INFO]  Batch 190 initialized 
2023-03-25 18:20:53,822 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:54,430 : [INFO]  ------------------------- Batch 190 training: round 1 -------------------------
2023-03-25 18:21:00,044 : [INFO]  ------------------------- Batch round 1, loss: 0.5921 -------------------------
2023-03-25 18:21:00,044 : [INFO]  ------------------------- Batch 190, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:00,055 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:00,057 : [INFO]  ------------------------- Batch 190 training: round 2 -------------------------
2023-03-25 18:21:03,005 : [INFO]  ------------------------- Batch round 2, loss: 0.596 -------------------------
2023-03-25 18:21:03,005 : [INFO]  ------------------------- Batch 190, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:03,035 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:03,039 : [INFO]  ------------------------- Batch 190 training: round 3 -------------------------
2023-03-25 18:21:06,103 : [INFO]  ------------------------- Batch round 3, loss: 0.5916 -------------------------
2023-03-25 18:21:06,103 : [INFO]  ------------------------- Batch 190, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:06,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:06,119 : [INFO]  Batch number 190 model fetched from the server
2023-03-25 18:21:06,119 : [INFO]  ################ Batch 190: final global model evalution after 3 rounds ################
2023-03-25 18:21:07,991 : [INFO]  Batch 190: Training set : loss - 0.6038, accuracy - 0.7011, recall - 0.837, AUC - 0.7968, F1 - 0.7368, precision - 0.6581, training time - -12.0 seconds
2023-03-25 18:21:07,992 : [INFO]  Batch 190: Testing set : loss - 0.6229, accuracy - 0.6716, recall - 0.8137, AUC - 0.7467, F1 - 0.7124, precision - 0.6336
2023-03-25 18:21:08,004 : [INFO]  Batch 191 initialized 
2023-03-25 18:21:08,603 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:09,177 : [INFO]  ------------------------- Batch 191 training: round 1 -------------------------
2023-03-25 18:21:14,477 : [INFO]  ------------------------- Batch round 1, loss: 0.5409 -------------------------
2023-03-25 18:21:14,477 : [INFO]  ------------------------- Batch 191, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:14,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:14,566 : [INFO]  ------------------------- Batch 191 training: round 2 -------------------------
2023-03-25 18:21:17,173 : [INFO]  ------------------------- Batch round 2, loss: 0.5427 -------------------------
2023-03-25 18:21:17,173 : [INFO]  ------------------------- Batch 191, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:17,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:17,416 : [INFO]  ------------------------- Batch 191 training: round 3 -------------------------
2023-03-25 18:21:20,097 : [INFO]  ------------------------- Batch round 3, loss: 0.537 -------------------------
2023-03-25 18:21:20,097 : [INFO]  ------------------------- Batch 191, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:20,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:20,336 : [INFO]  Batch number 191 model fetched from the server
2023-03-25 18:21:20,336 : [INFO]  ################ Batch 191: final global model evalution after 3 rounds ################
2023-03-25 18:21:22,050 : [INFO]  Batch 191: Training set : loss - 0.5459, accuracy - 0.7826, recall - 0.9783, AUC - 0.9102, F1 - 0.8182, precision - 0.7031, training time - -11.0 seconds
2023-03-25 18:21:22,050 : [INFO]  Batch 191: Testing set : loss - 0.5927, accuracy - 0.6667, recall - 0.9216, AUC - 0.8768, F1 - 0.7344, precision - 0.6104
2023-03-25 18:21:22,067 : [INFO]  Batch 192 initialized 
2023-03-25 18:21:22,657 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:23,281 : [INFO]  ------------------------- Batch 192 training: round 1 -------------------------
2023-03-25 18:21:28,938 : [INFO]  ------------------------- Batch round 1, loss: 0.5794 -------------------------
2023-03-25 18:21:28,939 : [INFO]  ------------------------- Batch 192, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:28,987 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:28,990 : [INFO]  ------------------------- Batch 192 training: round 2 -------------------------
2023-03-25 18:21:31,879 : [INFO]  ------------------------- Batch round 2, loss: 0.5859 -------------------------
2023-03-25 18:21:31,879 : [INFO]  ------------------------- Batch 192, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:31,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:31,951 : [INFO]  ------------------------- Batch 192 training: round 3 -------------------------
2023-03-25 18:21:34,859 : [INFO]  ------------------------- Batch round 3, loss: 0.5775 -------------------------
2023-03-25 18:21:34,859 : [INFO]  ------------------------- Batch 192, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:34,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:34,874 : [INFO]  Batch number 192 model fetched from the server
2023-03-25 18:21:34,874 : [INFO]  ################ Batch 192: final global model evalution after 3 rounds ################
2023-03-25 18:21:36,779 : [INFO]  Batch 192: Training set : loss - 0.5915, accuracy - 0.6793, recall - 0.837, AUC - 0.8226, F1 - 0.723, precision - 0.6364, training time - -12.0 seconds
2023-03-25 18:21:36,779 : [INFO]  Batch 192: Testing set : loss - 0.5821, accuracy - 0.701, recall - 0.902, AUC - 0.8478, F1 - 0.751, precision - 0.6434
2023-03-25 18:21:36,789 : [INFO]  Batch 193 initialized 
2023-03-25 18:21:37,359 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:37,957 : [INFO]  ------------------------- Batch 193 training: round 1 -------------------------
2023-03-25 18:21:43,435 : [INFO]  ------------------------- Batch round 1, loss: 0.5787 -------------------------
2023-03-25 18:21:43,436 : [INFO]  ------------------------- Batch 193, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:43,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:43,459 : [INFO]  ------------------------- Batch 193 training: round 2 -------------------------
2023-03-25 18:21:46,297 : [INFO]  ------------------------- Batch round 2, loss: 0.5828 -------------------------
2023-03-25 18:21:46,298 : [INFO]  ------------------------- Batch 193, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:46,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:46,371 : [INFO]  ------------------------- Batch 193 training: round 3 -------------------------
2023-03-25 18:21:49,379 : [INFO]  ------------------------- Batch round 3, loss: 0.576 -------------------------
2023-03-25 18:21:49,379 : [INFO]  ------------------------- Batch 193, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:49,523 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:49,531 : [INFO]  Batch number 193 model fetched from the server
2023-03-25 18:21:49,532 : [INFO]  ################ Batch 193: final global model evalution after 3 rounds ################
2023-03-25 18:21:51,309 : [INFO]  Batch 193: Training set : loss - 0.5886, accuracy - 0.6957, recall - 0.9022, AUC - 0.8284, F1 - 0.7477, precision - 0.6385, training time - -12.0 seconds
2023-03-25 18:21:51,309 : [INFO]  Batch 193: Testing set : loss - 0.5896, accuracy - 0.7059, recall - 0.8725, AUC - 0.832, F1 - 0.7479, precision - 0.6544
2023-03-25 18:21:51,323 : [INFO]  Batch 194 initialized 
2023-03-25 18:21:51,894 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:52,500 : [INFO]  ------------------------- Batch 194 training: round 1 -------------------------
2023-03-25 18:21:57,926 : [INFO]  ------------------------- Batch round 1, loss: 0.5707 -------------------------
2023-03-25 18:21:57,926 : [INFO]  ------------------------- Batch 194, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:57,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:57,951 : [INFO]  ------------------------- Batch 194 training: round 2 -------------------------
2023-03-25 18:22:00,844 : [INFO]  ------------------------- Batch round 2, loss: 0.5749 -------------------------
2023-03-25 18:22:00,844 : [INFO]  ------------------------- Batch 194, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:00,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:00,859 : [INFO]  ------------------------- Batch 194 training: round 3 -------------------------
2023-03-25 18:22:03,797 : [INFO]  ------------------------- Batch round 3, loss: 0.5664 -------------------------
2023-03-25 18:22:03,797 : [INFO]  ------------------------- Batch 194, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:03,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:03,816 : [INFO]  Batch number 194 model fetched from the server
2023-03-25 18:22:03,816 : [INFO]  ################ Batch 194: final global model evalution after 3 rounds ################
2023-03-25 18:22:05,664 : [INFO]  Batch 194: Training set : loss - 0.5842, accuracy - 0.7174, recall - 0.913, AUC - 0.836, F1 - 0.7636, precision - 0.6562, training time - -11.0 seconds
2023-03-25 18:22:05,665 : [INFO]  Batch 194: Testing set : loss - 0.5424, accuracy - 0.7941, recall - 0.9706, AUC - 0.9271, F1 - 0.825, precision - 0.7174
2023-03-25 18:22:05,672 : [INFO]  Batch 195 initialized 
2023-03-25 18:22:06,234 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:06,860 : [INFO]  ------------------------- Batch 195 training: round 1 -------------------------
2023-03-25 18:22:12,526 : [INFO]  ------------------------- Batch round 1, loss: 0.5855 -------------------------
2023-03-25 18:22:12,526 : [INFO]  ------------------------- Batch 195, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:12,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:12,540 : [INFO]  ------------------------- Batch 195 training: round 2 -------------------------
2023-03-25 18:22:15,678 : [INFO]  ------------------------- Batch round 2, loss: 0.5822 -------------------------
2023-03-25 18:22:15,679 : [INFO]  ------------------------- Batch 195, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:15,689 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:15,692 : [INFO]  ------------------------- Batch 195 training: round 3 -------------------------
2023-03-25 18:22:18,706 : [INFO]  ------------------------- Batch round 3, loss: 0.5787 -------------------------
2023-03-25 18:22:18,706 : [INFO]  ------------------------- Batch 195, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:18,719 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:18,722 : [INFO]  Batch number 195 model fetched from the server
2023-03-25 18:22:18,723 : [INFO]  ################ Batch 195: final global model evalution after 3 rounds ################
2023-03-25 18:22:20,771 : [INFO]  Batch 195: Training set : loss - 0.5945, accuracy - 0.6848, recall - 0.913, AUC - 0.8128, F1 - 0.7434, precision - 0.6269, training time - -12.0 seconds
2023-03-25 18:22:20,771 : [INFO]  Batch 195: Testing set : loss - 0.5776, accuracy - 0.7304, recall - 0.9216, AUC - 0.8594, F1 - 0.7737, precision - 0.6667
2023-03-25 18:22:20,779 : [INFO]  Batch 196 initialized 
2023-03-25 18:22:21,371 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:21,947 : [INFO]  ------------------------- Batch 196 training: round 1 -------------------------
2023-03-25 18:22:27,606 : [INFO]  ------------------------- Batch round 1, loss: 0.5724 -------------------------
2023-03-25 18:22:27,607 : [INFO]  ------------------------- Batch 196, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:27,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:27,624 : [INFO]  ------------------------- Batch 196 training: round 2 -------------------------
2023-03-25 18:22:30,499 : [INFO]  ------------------------- Batch round 2, loss: 0.5775 -------------------------
2023-03-25 18:22:30,500 : [INFO]  ------------------------- Batch 196, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:30,534 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:30,537 : [INFO]  ------------------------- Batch 196 training: round 3 -------------------------
2023-03-25 18:22:33,360 : [INFO]  ------------------------- Batch round 3, loss: 0.5786 -------------------------
2023-03-25 18:22:33,360 : [INFO]  ------------------------- Batch 196, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:33,393 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:33,396 : [INFO]  Batch number 196 model fetched from the server
2023-03-25 18:22:33,396 : [INFO]  ################ Batch 196: final global model evalution after 3 rounds ################
2023-03-25 18:22:35,148 : [INFO]  Batch 196: Training set : loss - 0.5917, accuracy - 0.6848, recall - 0.8913, AUC - 0.83, F1 - 0.7387, precision - 0.6308, training time - -11.0 seconds
2023-03-25 18:22:35,148 : [INFO]  Batch 196: Testing set : loss - 0.5632, accuracy - 0.7304, recall - 0.9412, AUC - 0.8681, F1 - 0.7773, precision - 0.6621
2023-03-25 18:22:35,156 : [INFO]  Batch 197 initialized 
2023-03-25 18:22:35,711 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:36,322 : [INFO]  ------------------------- Batch 197 training: round 1 -------------------------
2023-03-25 18:22:41,846 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 18:22:41,846 : [INFO]  ------------------------- Batch 197, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:41,855 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:41,858 : [INFO]  ------------------------- Batch 197 training: round 2 -------------------------
2023-03-25 18:22:44,807 : [INFO]  ------------------------- Batch round 2, loss: 0.5687 -------------------------
2023-03-25 18:22:44,807 : [INFO]  ------------------------- Batch 197, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:44,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:44,820 : [INFO]  ------------------------- Batch 197 training: round 3 -------------------------
2023-03-25 18:22:47,908 : [INFO]  ------------------------- Batch round 3, loss: 0.5624 -------------------------
2023-03-25 18:22:47,908 : [INFO]  ------------------------- Batch 197, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:47,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:47,923 : [INFO]  Batch number 197 model fetched from the server
2023-03-25 18:22:47,924 : [INFO]  ################ Batch 197: final global model evalution after 3 rounds ################
2023-03-25 18:22:49,817 : [INFO]  Batch 197: Training set : loss - 0.5621, accuracy - 0.75, recall - 0.9783, AUC - 0.8875, F1 - 0.7965, precision - 0.6716, training time - -12.0 seconds
2023-03-25 18:22:49,817 : [INFO]  Batch 197: Testing set : loss - 0.5417, accuracy - 0.7549, recall - 0.9314, AUC - 0.9196, F1 - 0.7917, precision - 0.6884
2023-03-25 18:22:49,824 : [INFO]  Batch 198 initialized 
2023-03-25 18:22:50,407 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:51,000 : [INFO]  ------------------------- Batch 198 training: round 1 -------------------------
2023-03-25 18:22:56,437 : [INFO]  ------------------------- Batch round 1, loss: 0.606 -------------------------
2023-03-25 18:22:56,437 : [INFO]  ------------------------- Batch 198, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:56,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:56,453 : [INFO]  ------------------------- Batch 198 training: round 2 -------------------------
2023-03-25 18:22:59,218 : [INFO]  ------------------------- Batch round 2, loss: 0.6065 -------------------------
2023-03-25 18:22:59,218 : [INFO]  ------------------------- Batch 198, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:59,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:59,312 : [INFO]  ------------------------- Batch 198 training: round 3 -------------------------
2023-03-25 18:23:02,050 : [INFO]  ------------------------- Batch round 3, loss: 0.6083 -------------------------
2023-03-25 18:23:02,051 : [INFO]  ------------------------- Batch 198, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:02,194 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:02,197 : [INFO]  Batch number 198 model fetched from the server
2023-03-25 18:23:02,197 : [INFO]  ################ Batch 198: final global model evalution after 3 rounds ################
2023-03-25 18:23:03,964 : [INFO]  Batch 198: Training set : loss - 0.6208, accuracy - 0.6576, recall - 0.8587, AUC - 0.7557, F1 - 0.7149, precision - 0.6124, training time - -11.0 seconds
2023-03-25 18:23:03,964 : [INFO]  Batch 198: Testing set : loss - 0.5856, accuracy - 0.6569, recall - 0.8922, AUC - 0.849, F1 - 0.7222, precision - 0.6067
2023-03-25 18:23:03,973 : [INFO]  Batch 199 initialized 
2023-03-25 18:23:04,538 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:05,147 : [INFO]  ------------------------- Batch 199 training: round 1 -------------------------
2023-03-25 18:23:10,556 : [INFO]  ------------------------- Batch round 1, loss: 0.5735 -------------------------
2023-03-25 18:23:10,556 : [INFO]  ------------------------- Batch 199, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:10,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:10,572 : [INFO]  ------------------------- Batch 199 training: round 2 -------------------------
2023-03-25 18:23:13,412 : [INFO]  ------------------------- Batch round 2, loss: 0.5713 -------------------------
2023-03-25 18:23:13,412 : [INFO]  ------------------------- Batch 199, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:13,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:13,561 : [INFO]  ------------------------- Batch 199 training: round 3 -------------------------
2023-03-25 18:23:16,361 : [INFO]  ------------------------- Batch round 3, loss: 0.5689 -------------------------
2023-03-25 18:23:16,361 : [INFO]  ------------------------- Batch 199, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:16,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:16,435 : [INFO]  Batch number 199 model fetched from the server
2023-03-25 18:23:16,435 : [INFO]  ################ Batch 199: final global model evalution after 3 rounds ################
2023-03-25 18:23:18,217 : [INFO]  Batch 199: Training set : loss - 0.5809, accuracy - 0.7446, recall - 0.8696, AUC - 0.8198, F1 - 0.7729, precision - 0.6957, training time - -11.0 seconds
2023-03-25 18:23:18,217 : [INFO]  Batch 199: Testing set : loss - 0.5804, accuracy - 0.7157, recall - 0.8922, AUC - 0.8517, F1 - 0.7583, precision - 0.6594
2023-03-25 18:23:18,231 : [INFO]  Batch 200 initialized 
2023-03-25 18:23:18,797 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:19,425 : [INFO]  ------------------------- Batch 200 training: round 1 -------------------------
2023-03-25 18:23:24,776 : [INFO]  ------------------------- Batch round 1, loss: 0.5806 -------------------------
2023-03-25 18:23:24,776 : [INFO]  ------------------------- Batch 200, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:24,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:24,932 : [INFO]  ------------------------- Batch 200 training: round 2 -------------------------
2023-03-25 18:23:27,756 : [INFO]  ------------------------- Batch round 2, loss: 0.5887 -------------------------
2023-03-25 18:23:27,756 : [INFO]  ------------------------- Batch 200, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:27,927 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:27,929 : [INFO]  ------------------------- Batch 200 training: round 3 -------------------------
2023-03-25 18:23:30,742 : [INFO]  ------------------------- Batch round 3, loss: 0.5845 -------------------------
2023-03-25 18:23:30,742 : [INFO]  ------------------------- Batch 200, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:30,930 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:30,934 : [INFO]  Batch number 200 model fetched from the server
2023-03-25 18:23:30,934 : [INFO]  ################ Batch 200: final global model evalution after 3 rounds ################
2023-03-25 18:23:32,767 : [INFO]  Batch 200: Training set : loss - 0.599, accuracy - 0.6576, recall - 0.8261, AUC - 0.8031, F1 - 0.707, precision - 0.6179, training time - -12.0 seconds
2023-03-25 18:23:32,767 : [INFO]  Batch 200: Testing set : loss - 0.5842, accuracy - 0.7108, recall - 0.8627, AUC - 0.8225, F1 - 0.7489, precision - 0.6617
2023-03-25 18:23:32,781 : [INFO]  Batch 201 initialized 
2023-03-25 18:23:33,369 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:33,969 : [INFO]  ------------------------- Batch 201 training: round 1 -------------------------
2023-03-25 18:23:39,316 : [INFO]  ------------------------- Batch round 1, loss: 0.5785 -------------------------
2023-03-25 18:23:39,317 : [INFO]  ------------------------- Batch 201, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:39,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:39,335 : [INFO]  ------------------------- Batch 201 training: round 2 -------------------------
2023-03-25 18:23:42,189 : [INFO]  ------------------------- Batch round 2, loss: 0.5826 -------------------------
2023-03-25 18:23:42,190 : [INFO]  ------------------------- Batch 201, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:42,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:42,203 : [INFO]  ------------------------- Batch 201 training: round 3 -------------------------
2023-03-25 18:23:44,992 : [INFO]  ------------------------- Batch round 3, loss: 0.5851 -------------------------
2023-03-25 18:23:44,992 : [INFO]  ------------------------- Batch 201, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:45,187 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:45,189 : [INFO]  Batch number 201 model fetched from the server
2023-03-25 18:23:45,189 : [INFO]  ################ Batch 201: final global model evalution after 3 rounds ################
2023-03-25 18:23:46,878 : [INFO]  Batch 201: Training set : loss - 0.6023, accuracy - 0.6739, recall - 0.837, AUC - 0.7982, F1 - 0.7196, precision - 0.6311, training time - -11.0 seconds
2023-03-25 18:23:46,878 : [INFO]  Batch 201: Testing set : loss - 0.5943, accuracy - 0.6716, recall - 0.8137, AUC - 0.8007, F1 - 0.7124, precision - 0.6336
2023-03-25 18:23:46,893 : [INFO]  Batch 202 initialized 
2023-03-25 18:23:47,468 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:48,024 : [INFO]  ------------------------- Batch 202 training: round 1 -------------------------
2023-03-25 18:23:53,390 : [INFO]  ------------------------- Batch round 1, loss: 0.5672 -------------------------
2023-03-25 18:23:53,390 : [INFO]  ------------------------- Batch 202, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:53,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:53,727 : [INFO]  ------------------------- Batch 202 training: round 2 -------------------------
2023-03-25 18:23:56,523 : [INFO]  ------------------------- Batch round 2, loss: 0.5646 -------------------------
2023-03-25 18:23:56,523 : [INFO]  ------------------------- Batch 202, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:56,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:56,615 : [INFO]  ------------------------- Batch 202 training: round 3 -------------------------
2023-03-25 18:23:59,412 : [INFO]  ------------------------- Batch round 3, loss: 0.5644 -------------------------
2023-03-25 18:23:59,412 : [INFO]  ------------------------- Batch 202, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:59,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:59,618 : [INFO]  Batch number 202 model fetched from the server
2023-03-25 18:23:59,619 : [INFO]  ################ Batch 202: final global model evalution after 3 rounds ################
2023-03-25 18:24:01,481 : [INFO]  Batch 202: Training set : loss - 0.576, accuracy - 0.75, recall - 0.9239, AUC - 0.8507, F1 - 0.787, precision - 0.6855, training time - -12.0 seconds
2023-03-25 18:24:01,481 : [INFO]  Batch 202: Testing set : loss - 0.5929, accuracy - 0.6912, recall - 0.8922, AUC - 0.83, F1 - 0.7429, precision - 0.6364
2023-03-25 18:24:01,493 : [INFO]  Batch 203 initialized 
2023-03-25 18:24:02,068 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:02,690 : [INFO]  ------------------------- Batch 203 training: round 1 -------------------------
2023-03-25 18:24:08,102 : [INFO]  ------------------------- Batch round 1, loss: 0.5667 -------------------------
2023-03-25 18:24:08,103 : [INFO]  ------------------------- Batch 203, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:08,133 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:08,137 : [INFO]  ------------------------- Batch 203 training: round 2 -------------------------
2023-03-25 18:24:11,075 : [INFO]  ------------------------- Batch round 2, loss: 0.5707 -------------------------
2023-03-25 18:24:11,075 : [INFO]  ------------------------- Batch 203, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:11,098 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:11,101 : [INFO]  ------------------------- Batch 203 training: round 3 -------------------------
2023-03-25 18:24:13,951 : [INFO]  ------------------------- Batch round 3, loss: 0.5701 -------------------------
2023-03-25 18:24:13,951 : [INFO]  ------------------------- Batch 203, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:13,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:13,990 : [INFO]  Batch number 203 model fetched from the server
2023-03-25 18:24:13,991 : [INFO]  ################ Batch 203: final global model evalution after 3 rounds ################
2023-03-25 18:24:15,741 : [INFO]  Batch 203: Training set : loss - 0.5832, accuracy - 0.712, recall - 0.8804, AUC - 0.8435, F1 - 0.7535, precision - 0.6585, training time - -11.0 seconds
2023-03-25 18:24:15,741 : [INFO]  Batch 203: Testing set : loss - 0.5796, accuracy - 0.7255, recall - 0.9118, AUC - 0.8466, F1 - 0.7686, precision - 0.6643
2023-03-25 18:24:15,752 : [INFO]  Batch 204 initialized 
2023-03-25 18:24:16,326 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:16,928 : [INFO]  ------------------------- Batch 204 training: round 1 -------------------------
2023-03-25 18:24:22,296 : [INFO]  ------------------------- Batch round 1, loss: 0.5597 -------------------------
2023-03-25 18:24:22,296 : [INFO]  ------------------------- Batch 204, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:22,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:22,395 : [INFO]  ------------------------- Batch 204 training: round 2 -------------------------
2023-03-25 18:24:25,183 : [INFO]  ------------------------- Batch round 2, loss: 0.5631 -------------------------
2023-03-25 18:24:25,183 : [INFO]  ------------------------- Batch 204, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:25,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:25,331 : [INFO]  ------------------------- Batch 204 training: round 3 -------------------------
2023-03-25 18:24:28,121 : [INFO]  ------------------------- Batch round 3, loss: 0.5525 -------------------------
2023-03-25 18:24:28,122 : [INFO]  ------------------------- Batch 204, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:28,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:28,228 : [INFO]  Batch number 204 model fetched from the server
2023-03-25 18:24:28,228 : [INFO]  ################ Batch 204: final global model evalution after 3 rounds ################
2023-03-25 18:24:29,957 : [INFO]  Batch 204: Training set : loss - 0.5651, accuracy - 0.7446, recall - 0.8913, AUC - 0.854, F1 - 0.7773, precision - 0.6891, training time - -11.0 seconds
2023-03-25 18:24:29,957 : [INFO]  Batch 204: Testing set : loss - 0.605, accuracy - 0.6716, recall - 0.8431, AUC - 0.7962, F1 - 0.7197, precision - 0.6277
2023-03-25 18:24:29,974 : [INFO]  Batch 205 initialized 
2023-03-25 18:24:30,555 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:31,157 : [INFO]  ------------------------- Batch 205 training: round 1 -------------------------
2023-03-25 18:24:36,520 : [INFO]  ------------------------- Batch round 1, loss: 0.5577 -------------------------
2023-03-25 18:24:36,520 : [INFO]  ------------------------- Batch 205, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:36,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:36,627 : [INFO]  ------------------------- Batch 205 training: round 2 -------------------------
2023-03-25 18:24:39,439 : [INFO]  ------------------------- Batch round 2, loss: 0.562 -------------------------
2023-03-25 18:24:39,439 : [INFO]  ------------------------- Batch 205, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:39,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:39,531 : [INFO]  ------------------------- Batch 205 training: round 3 -------------------------
2023-03-25 18:24:42,367 : [INFO]  ------------------------- Batch round 3, loss: 0.5615 -------------------------
2023-03-25 18:24:42,367 : [INFO]  ------------------------- Batch 205, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:42,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:42,520 : [INFO]  Batch number 205 model fetched from the server
2023-03-25 18:24:42,520 : [INFO]  ################ Batch 205: final global model evalution after 3 rounds ################
2023-03-25 18:24:44,257 : [INFO]  Batch 205: Training set : loss - 0.568, accuracy - 0.7554, recall - 0.9022, AUC - 0.846, F1 - 0.7867, precision - 0.6975, training time - -11.0 seconds
2023-03-25 18:24:44,257 : [INFO]  Batch 205: Testing set : loss - 0.5665, accuracy - 0.7157, recall - 0.902, AUC - 0.8811, F1 - 0.7603, precision - 0.6571
2023-03-25 18:24:44,273 : [INFO]  Batch 206 initialized 
2023-03-25 18:24:44,838 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:45,452 : [INFO]  ------------------------- Batch 206 training: round 1 -------------------------
2023-03-25 18:24:50,748 : [INFO]  ------------------------- Batch round 1, loss: 0.5638 -------------------------
2023-03-25 18:24:50,748 : [INFO]  ------------------------- Batch 206, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:50,761 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:50,763 : [INFO]  ------------------------- Batch 206 training: round 2 -------------------------
2023-03-25 18:24:53,766 : [INFO]  ------------------------- Batch round 2, loss: 0.5709 -------------------------
2023-03-25 18:24:53,766 : [INFO]  ------------------------- Batch 206, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:53,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:53,782 : [INFO]  ------------------------- Batch 206 training: round 3 -------------------------
2023-03-25 18:24:56,550 : [INFO]  ------------------------- Batch round 3, loss: 0.5662 -------------------------
2023-03-25 18:24:56,550 : [INFO]  ------------------------- Batch 206, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:56,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:56,812 : [INFO]  Batch number 206 model fetched from the server
2023-03-25 18:24:56,812 : [INFO]  ################ Batch 206: final global model evalution after 3 rounds ################
2023-03-25 18:24:58,506 : [INFO]  Batch 206: Training set : loss - 0.5779, accuracy - 0.7228, recall - 0.9022, AUC - 0.8495, F1 - 0.765, precision - 0.664, training time - -11.0 seconds
2023-03-25 18:24:58,506 : [INFO]  Batch 206: Testing set : loss - 0.5868, accuracy - 0.6471, recall - 0.8333, AUC - 0.823, F1 - 0.7025, precision - 0.6071
2023-03-25 18:24:58,521 : [INFO]  Batch 207 initialized 
2023-03-25 18:24:59,077 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:59,707 : [INFO]  ------------------------- Batch 207 training: round 1 -------------------------
2023-03-25 18:25:05,149 : [INFO]  ------------------------- Batch round 1, loss: 0.613 -------------------------
2023-03-25 18:25:05,149 : [INFO]  ------------------------- Batch 207, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:05,262 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:05,265 : [INFO]  ------------------------- Batch 207 training: round 2 -------------------------
2023-03-25 18:25:08,295 : [INFO]  ------------------------- Batch round 2, loss: 0.6078 -------------------------
2023-03-25 18:25:08,295 : [INFO]  ------------------------- Batch 207, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:08,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:08,325 : [INFO]  ------------------------- Batch 207 training: round 3 -------------------------
2023-03-25 18:25:11,261 : [INFO]  ------------------------- Batch round 3, loss: 0.613 -------------------------
2023-03-25 18:25:11,261 : [INFO]  ------------------------- Batch 207, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:11,275 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:11,278 : [INFO]  Batch number 207 model fetched from the server
2023-03-25 18:25:11,278 : [INFO]  ################ Batch 207: final global model evalution after 3 rounds ################
2023-03-25 18:25:13,068 : [INFO]  Batch 207: Training set : loss - 0.626, accuracy - 0.6087, recall - 0.7174, AUC - 0.7228, F1 - 0.6471, precision - 0.5893, training time - -12.0 seconds
2023-03-25 18:25:13,068 : [INFO]  Batch 207: Testing set : loss - 0.5792, accuracy - 0.7255, recall - 0.9118, AUC - 0.8592, F1 - 0.7686, precision - 0.6643
2023-03-25 18:25:13,080 : [INFO]  Batch 208 initialized 
2023-03-25 18:25:13,654 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:14,276 : [INFO]  ------------------------- Batch 208 training: round 1 -------------------------
2023-03-25 18:25:19,729 : [INFO]  ------------------------- Batch round 1, loss: 0.6097 -------------------------
2023-03-25 18:25:19,729 : [INFO]  ------------------------- Batch 208, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:19,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:19,743 : [INFO]  ------------------------- Batch 208 training: round 2 -------------------------
2023-03-25 18:25:22,616 : [INFO]  ------------------------- Batch round 2, loss: 0.6132 -------------------------
2023-03-25 18:25:22,616 : [INFO]  ------------------------- Batch 208, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:22,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:22,633 : [INFO]  ------------------------- Batch 208 training: round 3 -------------------------
2023-03-25 18:25:25,540 : [INFO]  ------------------------- Batch round 3, loss: 0.6111 -------------------------
2023-03-25 18:25:25,540 : [INFO]  ------------------------- Batch 208, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:25,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:25,556 : [INFO]  Batch number 208 model fetched from the server
2023-03-25 18:25:25,556 : [INFO]  ################ Batch 208: final global model evalution after 3 rounds ################
2023-03-25 18:25:27,305 : [INFO]  Batch 208: Training set : loss - 0.6217, accuracy - 0.6413, recall - 0.7935, AUC - 0.7424, F1 - 0.6887, precision - 0.6083, training time - -11.0 seconds
2023-03-25 18:25:27,305 : [INFO]  Batch 208: Testing set : loss - 0.6017, accuracy - 0.6912, recall - 0.7941, AUC - 0.7858, F1 - 0.72, precision - 0.6585
2023-03-25 18:25:27,314 : [INFO]  Batch 209 initialized 
2023-03-25 18:25:27,877 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:28,508 : [INFO]  ------------------------- Batch 209 training: round 1 -------------------------
2023-03-25 18:25:33,899 : [INFO]  ------------------------- Batch round 1, loss: 0.5827 -------------------------
2023-03-25 18:25:33,899 : [INFO]  ------------------------- Batch 209, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:33,938 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:33,941 : [INFO]  ------------------------- Batch 209 training: round 2 -------------------------
2023-03-25 18:25:36,715 : [INFO]  ------------------------- Batch round 2, loss: 0.5728 -------------------------
2023-03-25 18:25:36,716 : [INFO]  ------------------------- Batch 209, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:36,759 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:36,762 : [INFO]  ------------------------- Batch 209 training: round 3 -------------------------
2023-03-25 18:25:39,690 : [INFO]  ------------------------- Batch round 3, loss: 0.58 -------------------------
2023-03-25 18:25:39,691 : [INFO]  ------------------------- Batch 209, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:39,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:39,753 : [INFO]  Batch number 209 model fetched from the server
2023-03-25 18:25:39,753 : [INFO]  ################ Batch 209: final global model evalution after 3 rounds ################
2023-03-25 18:25:41,560 : [INFO]  Batch 209: Training set : loss - 0.5854, accuracy - 0.7011, recall - 0.8696, AUC - 0.8196, F1 - 0.7442, precision - 0.6504, training time - -11.0 seconds
2023-03-25 18:25:41,560 : [INFO]  Batch 209: Testing set : loss - 0.579, accuracy - 0.6961, recall - 0.9118, AUC - 0.8462, F1 - 0.75, precision - 0.637
2023-03-25 18:25:41,574 : [INFO]  Batch 210 initialized 
2023-03-25 18:25:42,174 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:42,797 : [INFO]  ------------------------- Batch 210 training: round 1 -------------------------
2023-03-25 18:25:48,212 : [INFO]  ------------------------- Batch round 1, loss: 0.5512 -------------------------
2023-03-25 18:25:48,212 : [INFO]  ------------------------- Batch 210, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:48,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:48,228 : [INFO]  ------------------------- Batch 210 training: round 2 -------------------------
2023-03-25 18:25:51,062 : [INFO]  ------------------------- Batch round 2, loss: 0.5492 -------------------------
2023-03-25 18:25:51,062 : [INFO]  ------------------------- Batch 210, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:51,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:51,077 : [INFO]  ------------------------- Batch 210 training: round 3 -------------------------
2023-03-25 18:25:53,902 : [INFO]  ------------------------- Batch round 3, loss: 0.5506 -------------------------
2023-03-25 18:25:53,902 : [INFO]  ------------------------- Batch 210, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:53,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:53,918 : [INFO]  Batch number 210 model fetched from the server
2023-03-25 18:25:53,918 : [INFO]  ################ Batch 210: final global model evalution after 3 rounds ################
2023-03-25 18:25:55,636 : [INFO]  Batch 210: Training set : loss - 0.5571, accuracy - 0.7609, recall - 0.9457, AUC - 0.884, F1 - 0.7982, precision - 0.6905, training time - -11.0 seconds
2023-03-25 18:25:55,637 : [INFO]  Batch 210: Testing set : loss - 0.5762, accuracy - 0.7206, recall - 0.8922, AUC - 0.8319, F1 - 0.7615, precision - 0.6642
2023-03-25 18:25:55,651 : [INFO]  Batch 211 initialized 
2023-03-25 18:25:56,210 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:56,839 : [INFO]  ------------------------- Batch 211 training: round 1 -------------------------
2023-03-25 18:26:02,243 : [INFO]  ------------------------- Batch round 1, loss: 0.5555 -------------------------
2023-03-25 18:26:02,243 : [INFO]  ------------------------- Batch 211, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:02,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:02,256 : [INFO]  ------------------------- Batch 211 training: round 2 -------------------------
2023-03-25 18:26:05,173 : [INFO]  ------------------------- Batch round 2, loss: 0.5656 -------------------------
2023-03-25 18:26:05,173 : [INFO]  ------------------------- Batch 211, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:05,187 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:05,191 : [INFO]  ------------------------- Batch 211 training: round 3 -------------------------
2023-03-25 18:26:08,198 : [INFO]  ------------------------- Batch round 3, loss: 0.5612 -------------------------
2023-03-25 18:26:08,199 : [INFO]  ------------------------- Batch 211, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:08,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:08,217 : [INFO]  Batch number 211 model fetched from the server
2023-03-25 18:26:08,218 : [INFO]  ################ Batch 211: final global model evalution after 3 rounds ################
2023-03-25 18:26:10,028 : [INFO]  Batch 211: Training set : loss - 0.5783, accuracy - 0.712, recall - 0.8587, AUC - 0.8379, F1 - 0.7488, precision - 0.6639, training time - -11.0 seconds
2023-03-25 18:26:10,028 : [INFO]  Batch 211: Testing set : loss - 0.6169, accuracy - 0.652, recall - 0.8235, AUC - 0.7847, F1 - 0.7029, precision - 0.6131
2023-03-25 18:26:10,036 : [INFO]  Batch 212 initialized 
2023-03-25 18:26:10,579 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:11,196 : [INFO]  ------------------------- Batch 212 training: round 1 -------------------------
2023-03-25 18:26:16,576 : [INFO]  ------------------------- Batch round 1, loss: 0.5887 -------------------------
2023-03-25 18:26:16,576 : [INFO]  ------------------------- Batch 212, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:16,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:16,590 : [INFO]  ------------------------- Batch 212 training: round 2 -------------------------
2023-03-25 18:26:19,664 : [INFO]  ------------------------- Batch round 2, loss: 0.5899 -------------------------
2023-03-25 18:26:19,664 : [INFO]  ------------------------- Batch 212, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:19,678 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:19,680 : [INFO]  ------------------------- Batch 212 training: round 3 -------------------------
2023-03-25 18:26:22,612 : [INFO]  ------------------------- Batch round 3, loss: 0.5897 -------------------------
2023-03-25 18:26:22,613 : [INFO]  ------------------------- Batch 212, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:22,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:22,790 : [INFO]  Batch number 212 model fetched from the server
2023-03-25 18:26:22,790 : [INFO]  ################ Batch 212: final global model evalution after 3 rounds ################
2023-03-25 18:26:24,621 : [INFO]  Batch 212: Training set : loss - 0.6013, accuracy - 0.6793, recall - 0.8804, AUC - 0.8246, F1 - 0.733, precision - 0.6279, training time - -12.0 seconds
2023-03-25 18:26:24,621 : [INFO]  Batch 212: Testing set : loss - 0.5974, accuracy - 0.6716, recall - 0.9118, AUC - 0.8336, F1 - 0.7352, precision - 0.6159
2023-03-25 18:26:24,632 : [INFO]  Batch 213 initialized 
2023-03-25 18:26:25,221 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:25,855 : [INFO]  ------------------------- Batch 213 training: round 1 -------------------------
2023-03-25 18:26:31,311 : [INFO]  ------------------------- Batch round 1, loss: 0.5449 -------------------------
2023-03-25 18:26:31,311 : [INFO]  ------------------------- Batch 213, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:31,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:31,326 : [INFO]  ------------------------- Batch 213 training: round 2 -------------------------
2023-03-25 18:26:34,132 : [INFO]  ------------------------- Batch round 2, loss: 0.5491 -------------------------
2023-03-25 18:26:34,132 : [INFO]  ------------------------- Batch 213, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:34,185 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:34,189 : [INFO]  ------------------------- Batch 213 training: round 3 -------------------------
2023-03-25 18:26:37,036 : [INFO]  ------------------------- Batch round 3, loss: 0.5437 -------------------------
2023-03-25 18:26:37,036 : [INFO]  ------------------------- Batch 213, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:37,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:37,053 : [INFO]  Batch number 213 model fetched from the server
2023-03-25 18:26:37,053 : [INFO]  ################ Batch 213: final global model evalution after 3 rounds ################
2023-03-25 18:26:38,813 : [INFO]  Batch 213: Training set : loss - 0.56, accuracy - 0.7174, recall - 0.9239, AUC - 0.8788, F1 - 0.7658, precision - 0.6538, training time - -11.0 seconds
2023-03-25 18:26:38,814 : [INFO]  Batch 213: Testing set : loss - 0.5679, accuracy - 0.7206, recall - 0.8922, AUC - 0.8613, F1 - 0.7615, precision - 0.6642
2023-03-25 18:26:38,822 : [INFO]  Batch 214 initialized 
2023-03-25 18:26:39,371 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:40,032 : [INFO]  ------------------------- Batch 214 training: round 1 -------------------------
2023-03-25 18:26:45,449 : [INFO]  ------------------------- Batch round 1, loss: 0.5685 -------------------------
2023-03-25 18:26:45,449 : [INFO]  ------------------------- Batch 214, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:45,462 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:45,464 : [INFO]  ------------------------- Batch 214 training: round 2 -------------------------
2023-03-25 18:26:48,265 : [INFO]  ------------------------- Batch round 2, loss: 0.5718 -------------------------
2023-03-25 18:26:48,265 : [INFO]  ------------------------- Batch 214, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:48,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:48,357 : [INFO]  ------------------------- Batch 214 training: round 3 -------------------------
2023-03-25 18:26:51,202 : [INFO]  ------------------------- Batch round 3, loss: 0.5715 -------------------------
2023-03-25 18:26:51,202 : [INFO]  ------------------------- Batch 214, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:51,264 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:51,266 : [INFO]  Batch number 214 model fetched from the server
2023-03-25 18:26:51,267 : [INFO]  ################ Batch 214: final global model evalution after 3 rounds ################
2023-03-25 18:26:53,039 : [INFO]  Batch 214: Training set : loss - 0.5836, accuracy - 0.7011, recall - 0.9457, AUC - 0.831, F1 - 0.7598, precision - 0.635, training time - -11.0 seconds
2023-03-25 18:26:53,039 : [INFO]  Batch 214: Testing set : loss - 0.5799, accuracy - 0.6912, recall - 0.8333, AUC - 0.8229, F1 - 0.7296, precision - 0.6489
2023-03-25 18:26:53,052 : [INFO]  Batch 215 initialized 
2023-03-25 18:26:53,638 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:54,283 : [INFO]  ------------------------- Batch 215 training: round 1 -------------------------
2023-03-25 18:26:59,686 : [INFO]  ------------------------- Batch round 1, loss: 0.5637 -------------------------
2023-03-25 18:26:59,686 : [INFO]  ------------------------- Batch 215, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:59,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:59,742 : [INFO]  ------------------------- Batch 215 training: round 2 -------------------------
2023-03-25 18:27:02,608 : [INFO]  ------------------------- Batch round 2, loss: 0.5547 -------------------------
2023-03-25 18:27:02,609 : [INFO]  ------------------------- Batch 215, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:02,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:02,675 : [INFO]  ------------------------- Batch 215 training: round 3 -------------------------
2023-03-25 18:27:05,627 : [INFO]  ------------------------- Batch round 3, loss: 0.5536 -------------------------
2023-03-25 18:27:05,627 : [INFO]  ------------------------- Batch 215, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:05,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:05,724 : [INFO]  Batch number 215 model fetched from the server
2023-03-25 18:27:05,724 : [INFO]  ################ Batch 215: final global model evalution after 3 rounds ################
2023-03-25 18:27:07,470 : [INFO]  Batch 215: Training set : loss - 0.5627, accuracy - 0.7337, recall - 0.913, AUC - 0.8686, F1 - 0.7742, precision - 0.672, training time - -11.0 seconds
2023-03-25 18:27:07,470 : [INFO]  Batch 215: Testing set : loss - 0.5795, accuracy - 0.6912, recall - 0.9314, AUC - 0.8399, F1 - 0.751, precision - 0.6291
2023-03-25 18:27:07,486 : [INFO]  Batch 216 initialized 
2023-03-25 18:27:08,056 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:08,740 : [INFO]  ------------------------- Batch 216 training: round 1 -------------------------
2023-03-25 18:27:14,312 : [INFO]  ------------------------- Batch round 1, loss: 0.5675 -------------------------
2023-03-25 18:27:14,313 : [INFO]  ------------------------- Batch 216, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:14,390 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:14,394 : [INFO]  ------------------------- Batch 216 training: round 2 -------------------------
2023-03-25 18:27:17,247 : [INFO]  ------------------------- Batch round 2, loss: 0.5708 -------------------------
2023-03-25 18:27:17,247 : [INFO]  ------------------------- Batch 216, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:17,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:17,392 : [INFO]  ------------------------- Batch 216 training: round 3 -------------------------
2023-03-25 18:27:20,398 : [INFO]  ------------------------- Batch round 3, loss: 0.5758 -------------------------
2023-03-25 18:27:20,398 : [INFO]  ------------------------- Batch 216, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:20,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:20,413 : [INFO]  Batch number 216 model fetched from the server
2023-03-25 18:27:20,413 : [INFO]  ################ Batch 216: final global model evalution after 3 rounds ################
2023-03-25 18:27:22,191 : [INFO]  Batch 216: Training set : loss - 0.5706, accuracy - 0.7283, recall - 0.9022, AUC - 0.8475, F1 - 0.7685, precision - 0.6694, training time - -12.0 seconds
2023-03-25 18:27:22,192 : [INFO]  Batch 216: Testing set : loss - 0.5988, accuracy - 0.6814, recall - 0.8333, AUC - 0.8012, F1 - 0.7234, precision - 0.6391
2023-03-25 18:27:22,203 : [INFO]  Batch 217 initialized 
2023-03-25 18:27:22,762 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:23,401 : [INFO]  ------------------------- Batch 217 training: round 1 -------------------------
2023-03-25 18:27:28,921 : [INFO]  ------------------------- Batch round 1, loss: 0.5799 -------------------------
2023-03-25 18:27:28,922 : [INFO]  ------------------------- Batch 217, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:29,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:29,030 : [INFO]  ------------------------- Batch 217 training: round 2 -------------------------
2023-03-25 18:27:31,937 : [INFO]  ------------------------- Batch round 2, loss: 0.5894 -------------------------
2023-03-25 18:27:31,937 : [INFO]  ------------------------- Batch 217, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:31,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:31,994 : [INFO]  ------------------------- Batch 217 training: round 3 -------------------------
2023-03-25 18:27:34,890 : [INFO]  ------------------------- Batch round 3, loss: 0.5846 -------------------------
2023-03-25 18:27:34,890 : [INFO]  ------------------------- Batch 217, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:34,956 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:34,958 : [INFO]  Batch number 217 model fetched from the server
2023-03-25 18:27:34,958 : [INFO]  ################ Batch 217: final global model evalution after 3 rounds ################
2023-03-25 18:27:36,737 : [INFO]  Batch 217: Training set : loss - 0.5929, accuracy - 0.7065, recall - 0.8478, AUC - 0.802, F1 - 0.7429, precision - 0.661, training time - -12.0 seconds
2023-03-25 18:27:36,738 : [INFO]  Batch 217: Testing set : loss - 0.5675, accuracy - 0.7206, recall - 0.8725, AUC - 0.8595, F1 - 0.7574, precision - 0.6692
2023-03-25 18:27:36,752 : [INFO]  Batch 218 initialized 
2023-03-25 18:27:37,323 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:37,967 : [INFO]  ------------------------- Batch 218 training: round 1 -------------------------
2023-03-25 18:27:43,535 : [INFO]  ------------------------- Batch round 1, loss: 0.5737 -------------------------
2023-03-25 18:27:43,535 : [INFO]  ------------------------- Batch 218, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:43,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:43,553 : [INFO]  ------------------------- Batch 218 training: round 2 -------------------------
2023-03-25 18:27:46,458 : [INFO]  ------------------------- Batch round 2, loss: 0.5681 -------------------------
2023-03-25 18:27:46,458 : [INFO]  ------------------------- Batch 218, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:46,470 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:46,472 : [INFO]  ------------------------- Batch 218 training: round 3 -------------------------
2023-03-25 18:27:49,376 : [INFO]  ------------------------- Batch round 3, loss: 0.5738 -------------------------
2023-03-25 18:27:49,376 : [INFO]  ------------------------- Batch 218, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:49,387 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:49,390 : [INFO]  Batch number 218 model fetched from the server
2023-03-25 18:27:49,390 : [INFO]  ################ Batch 218: final global model evalution after 3 rounds ################
2023-03-25 18:27:51,193 : [INFO]  Batch 218: Training set : loss - 0.577, accuracy - 0.7174, recall - 0.8261, AUC - 0.8339, F1 - 0.7451, precision - 0.6786, training time - -11.0 seconds
2023-03-25 18:27:51,193 : [INFO]  Batch 218: Testing set : loss - 0.5604, accuracy - 0.7059, recall - 0.9412, AUC - 0.9017, F1 - 0.7619, precision - 0.64
2023-03-25 18:27:51,202 : [INFO]  Batch 219 initialized 
2023-03-25 18:27:51,843 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:52,505 : [INFO]  ------------------------- Batch 219 training: round 1 -------------------------
2023-03-25 18:27:57,868 : [INFO]  ------------------------- Batch round 1, loss: 0.5853 -------------------------
2023-03-25 18:27:57,868 : [INFO]  ------------------------- Batch 219, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:58,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:58,048 : [INFO]  ------------------------- Batch 219 training: round 2 -------------------------
2023-03-25 18:28:00,801 : [INFO]  ------------------------- Batch round 2, loss: 0.5751 -------------------------
2023-03-25 18:28:00,802 : [INFO]  ------------------------- Batch 219, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:00,961 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:00,964 : [INFO]  ------------------------- Batch 219 training: round 3 -------------------------
2023-03-25 18:28:03,801 : [INFO]  ------------------------- Batch round 3, loss: 0.5783 -------------------------
2023-03-25 18:28:03,801 : [INFO]  ------------------------- Batch 219, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:03,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:03,995 : [INFO]  Batch number 219 model fetched from the server
2023-03-25 18:28:03,995 : [INFO]  ################ Batch 219: final global model evalution after 3 rounds ################
2023-03-25 18:28:05,731 : [INFO]  Batch 219: Training set : loss - 0.594, accuracy - 0.6902, recall - 0.9348, AUC - 0.8196, F1 - 0.7511, precision - 0.6277, training time - -11.0 seconds
2023-03-25 18:28:05,731 : [INFO]  Batch 219: Testing set : loss - 0.6049, accuracy - 0.6373, recall - 0.8431, AUC - 0.7836, F1 - 0.6992, precision - 0.5972
2023-03-25 18:28:05,747 : [INFO]  Batch 220 initialized 
2023-03-25 18:28:06,295 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:06,918 : [INFO]  ------------------------- Batch 220 training: round 1 -------------------------
2023-03-25 18:28:12,514 : [INFO]  ------------------------- Batch round 1, loss: 0.5759 -------------------------
2023-03-25 18:28:12,514 : [INFO]  ------------------------- Batch 220, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:12,545 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:12,552 : [INFO]  ------------------------- Batch 220 training: round 2 -------------------------
2023-03-25 18:28:15,570 : [INFO]  ------------------------- Batch round 2, loss: 0.5774 -------------------------
2023-03-25 18:28:15,570 : [INFO]  ------------------------- Batch 220, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:15,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:15,587 : [INFO]  ------------------------- Batch 220 training: round 3 -------------------------
2023-03-25 18:28:18,541 : [INFO]  ------------------------- Batch round 3, loss: 0.5765 -------------------------
2023-03-25 18:28:18,541 : [INFO]  ------------------------- Batch 220, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:18,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:18,563 : [INFO]  Batch number 220 model fetched from the server
2023-03-25 18:28:18,563 : [INFO]  ################ Batch 220: final global model evalution after 3 rounds ################
2023-03-25 18:28:20,417 : [INFO]  Batch 220: Training set : loss - 0.5866, accuracy - 0.6522, recall - 0.8804, AUC - 0.8489, F1 - 0.7168, precision - 0.6045, training time - -12.0 seconds
2023-03-25 18:28:20,418 : [INFO]  Batch 220: Testing set : loss - 0.5786, accuracy - 0.7108, recall - 0.902, AUC - 0.85, F1 - 0.7572, precision - 0.6525
2023-03-25 18:28:20,430 : [INFO]  Batch 221 initialized 
2023-03-25 18:28:21,027 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:21,649 : [INFO]  ------------------------- Batch 221 training: round 1 -------------------------
2023-03-25 18:28:26,982 : [INFO]  ------------------------- Batch round 1, loss: 0.5602 -------------------------
2023-03-25 18:28:26,983 : [INFO]  ------------------------- Batch 221, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:27,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:27,079 : [INFO]  ------------------------- Batch 221 training: round 2 -------------------------
2023-03-25 18:28:29,794 : [INFO]  ------------------------- Batch round 2, loss: 0.5572 -------------------------
2023-03-25 18:28:29,794 : [INFO]  ------------------------- Batch 221, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:29,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:29,957 : [INFO]  ------------------------- Batch 221 training: round 3 -------------------------
2023-03-25 18:28:32,586 : [INFO]  ------------------------- Batch round 3, loss: 0.5539 -------------------------
2023-03-25 18:28:32,586 : [INFO]  ------------------------- Batch 221, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:32,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:32,790 : [INFO]  Batch number 221 model fetched from the server
2023-03-25 18:28:32,790 : [INFO]  ################ Batch 221: final global model evalution after 3 rounds ################
2023-03-25 18:28:34,466 : [INFO]  Batch 221: Training set : loss - 0.5658, accuracy - 0.7391, recall - 0.913, AUC - 0.87, F1 - 0.7778, precision - 0.6774, training time - -11.0 seconds
2023-03-25 18:28:34,467 : [INFO]  Batch 221: Testing set : loss - 0.5892, accuracy - 0.6814, recall - 0.8627, AUC - 0.8285, F1 - 0.7303, precision - 0.6331
2023-03-25 18:28:34,481 : [INFO]  Batch 222 initialized 
2023-03-25 18:28:35,041 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:35,651 : [INFO]  ------------------------- Batch 222 training: round 1 -------------------------
2023-03-25 18:28:40,986 : [INFO]  ------------------------- Batch round 1, loss: 0.5773 -------------------------
2023-03-25 18:28:40,987 : [INFO]  ------------------------- Batch 222, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:41,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:41,168 : [INFO]  ------------------------- Batch 222 training: round 2 -------------------------
2023-03-25 18:28:44,110 : [INFO]  ------------------------- Batch round 2, loss: 0.5765 -------------------------
2023-03-25 18:28:44,110 : [INFO]  ------------------------- Batch 222, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:44,194 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:44,197 : [INFO]  ------------------------- Batch 222 training: round 3 -------------------------
2023-03-25 18:28:47,085 : [INFO]  ------------------------- Batch round 3, loss: 0.5661 -------------------------
2023-03-25 18:28:47,085 : [INFO]  ------------------------- Batch 222, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:47,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:47,119 : [INFO]  Batch number 222 model fetched from the server
2023-03-25 18:28:47,119 : [INFO]  ################ Batch 222: final global model evalution after 3 rounds ################
2023-03-25 18:28:48,905 : [INFO]  Batch 222: Training set : loss - 0.5771, accuracy - 0.7174, recall - 0.8261, AUC - 0.8274, F1 - 0.7451, precision - 0.6786, training time - -11.0 seconds
2023-03-25 18:28:48,905 : [INFO]  Batch 222: Testing set : loss - 0.5925, accuracy - 0.6618, recall - 0.7941, AUC - 0.8076, F1 - 0.7013, precision - 0.6279
2023-03-25 18:28:48,920 : [INFO]  Batch 223 initialized 
2023-03-25 18:28:49,475 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:50,121 : [INFO]  ------------------------- Batch 223 training: round 1 -------------------------
2023-03-25 18:28:55,644 : [INFO]  ------------------------- Batch round 1, loss: 0.5695 -------------------------
2023-03-25 18:28:55,644 : [INFO]  ------------------------- Batch 223, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:55,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:55,658 : [INFO]  ------------------------- Batch 223 training: round 2 -------------------------
2023-03-25 18:28:58,527 : [INFO]  ------------------------- Batch round 2, loss: 0.5703 -------------------------
2023-03-25 18:28:58,527 : [INFO]  ------------------------- Batch 223, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:58,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:58,544 : [INFO]  ------------------------- Batch 223 training: round 3 -------------------------
2023-03-25 18:29:01,483 : [INFO]  ------------------------- Batch round 3, loss: 0.5722 -------------------------
2023-03-25 18:29:01,483 : [INFO]  ------------------------- Batch 223, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:01,495 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:01,498 : [INFO]  Batch number 223 model fetched from the server
2023-03-25 18:29:01,498 : [INFO]  ################ Batch 223: final global model evalution after 3 rounds ################
2023-03-25 18:29:03,316 : [INFO]  Batch 223: Training set : loss - 0.5796, accuracy - 0.7391, recall - 0.8696, AUC - 0.8172, F1 - 0.7692, precision - 0.6897, training time - -11.0 seconds
2023-03-25 18:29:03,317 : [INFO]  Batch 223: Testing set : loss - 0.5957, accuracy - 0.6716, recall - 0.7941, AUC - 0.8064, F1 - 0.7074, precision - 0.6378
2023-03-25 18:29:03,328 : [INFO]  Batch 224 initialized 
2023-03-25 18:29:03,901 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:04,563 : [INFO]  ------------------------- Batch 224 training: round 1 -------------------------
2023-03-25 18:29:10,256 : [INFO]  ------------------------- Batch round 1, loss: 0.579 -------------------------
2023-03-25 18:29:10,256 : [INFO]  ------------------------- Batch 224, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:10,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:10,272 : [INFO]  ------------------------- Batch 224 training: round 2 -------------------------
2023-03-25 18:29:13,148 : [INFO]  ------------------------- Batch round 2, loss: 0.5791 -------------------------
2023-03-25 18:29:13,148 : [INFO]  ------------------------- Batch 224, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:13,159 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:13,163 : [INFO]  ------------------------- Batch 224 training: round 3 -------------------------
2023-03-25 18:29:16,092 : [INFO]  ------------------------- Batch round 3, loss: 0.5843 -------------------------
2023-03-25 18:29:16,092 : [INFO]  ------------------------- Batch 224, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:16,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:16,122 : [INFO]  Batch number 224 model fetched from the server
2023-03-25 18:29:16,122 : [INFO]  ################ Batch 224: final global model evalution after 3 rounds ################
2023-03-25 18:29:18,009 : [INFO]  Batch 224: Training set : loss - 0.5892, accuracy - 0.7065, recall - 0.8587, AUC - 0.8175, F1 - 0.7453, precision - 0.6583, training time - -12.0 seconds
2023-03-25 18:29:18,010 : [INFO]  Batch 224: Testing set : loss - 0.5687, accuracy - 0.7157, recall - 0.8431, AUC - 0.8581, F1 - 0.7478, precision - 0.6719
2023-03-25 18:29:18,022 : [INFO]  Batch 225 initialized 
2023-03-25 18:29:18,590 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:19,220 : [INFO]  ------------------------- Batch 225 training: round 1 -------------------------
2023-03-25 18:29:24,626 : [INFO]  ------------------------- Batch round 1, loss: 0.5783 -------------------------
2023-03-25 18:29:24,626 : [INFO]  ------------------------- Batch 225, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:24,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:24,836 : [INFO]  ------------------------- Batch 225 training: round 2 -------------------------
2023-03-25 18:29:27,672 : [INFO]  ------------------------- Batch round 2, loss: 0.5831 -------------------------
2023-03-25 18:29:27,672 : [INFO]  ------------------------- Batch 225, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:27,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:27,835 : [INFO]  ------------------------- Batch 225 training: round 3 -------------------------
2023-03-25 18:29:30,702 : [INFO]  ------------------------- Batch round 3, loss: 0.5851 -------------------------
2023-03-25 18:29:30,702 : [INFO]  ------------------------- Batch 225, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:30,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:30,867 : [INFO]  Batch number 225 model fetched from the server
2023-03-25 18:29:30,867 : [INFO]  ################ Batch 225: final global model evalution after 3 rounds ################
2023-03-25 18:29:32,604 : [INFO]  Batch 225: Training set : loss - 0.5951, accuracy - 0.6576, recall - 0.8152, AUC - 0.7945, F1 - 0.7042, precision - 0.6198, training time - -12.0 seconds
2023-03-25 18:29:32,604 : [INFO]  Batch 225: Testing set : loss - 0.6103, accuracy - 0.6716, recall - 0.8039, AUC - 0.7614, F1 - 0.71, precision - 0.6357
2023-03-25 18:29:32,618 : [INFO]  Batch 226 initialized 
2023-03-25 18:29:33,198 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:33,817 : [INFO]  ------------------------- Batch 226 training: round 1 -------------------------
2023-03-25 18:29:39,154 : [INFO]  ------------------------- Batch round 1, loss: 0.592 -------------------------
2023-03-25 18:29:39,154 : [INFO]  ------------------------- Batch 226, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:39,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:39,373 : [INFO]  ------------------------- Batch 226 training: round 2 -------------------------
2023-03-25 18:29:42,200 : [INFO]  ------------------------- Batch round 2, loss: 0.5885 -------------------------
2023-03-25 18:29:42,200 : [INFO]  ------------------------- Batch 226, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:42,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:42,219 : [INFO]  ------------------------- Batch 226 training: round 3 -------------------------
2023-03-25 18:29:45,012 : [INFO]  ------------------------- Batch round 3, loss: 0.5891 -------------------------
2023-03-25 18:29:45,012 : [INFO]  ------------------------- Batch 226, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:45,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:45,028 : [INFO]  Batch number 226 model fetched from the server
2023-03-25 18:29:45,028 : [INFO]  ################ Batch 226: final global model evalution after 3 rounds ################
2023-03-25 18:29:46,772 : [INFO]  Batch 226: Training set : loss - 0.6069, accuracy - 0.6902, recall - 0.8587, AUC - 0.7762, F1 - 0.7349, precision - 0.6423, training time - -11.0 seconds
2023-03-25 18:29:46,773 : [INFO]  Batch 226: Testing set : loss - 0.5841, accuracy - 0.6618, recall - 0.8627, AUC - 0.8262, F1 - 0.7184, precision - 0.6154
2023-03-25 18:29:46,781 : [INFO]  Batch 227 initialized 
2023-03-25 18:29:47,349 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:47,993 : [INFO]  ------------------------- Batch 227 training: round 1 -------------------------
2023-03-25 18:29:53,390 : [INFO]  ------------------------- Batch round 1, loss: 0.5687 -------------------------
2023-03-25 18:29:53,390 : [INFO]  ------------------------- Batch 227, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:53,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:53,404 : [INFO]  ------------------------- Batch 227 training: round 2 -------------------------
2023-03-25 18:29:56,382 : [INFO]  ------------------------- Batch round 2, loss: 0.576 -------------------------
2023-03-25 18:29:56,383 : [INFO]  ------------------------- Batch 227, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:56,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:56,397 : [INFO]  ------------------------- Batch 227 training: round 3 -------------------------
2023-03-25 18:29:59,272 : [INFO]  ------------------------- Batch round 3, loss: 0.5741 -------------------------
2023-03-25 18:29:59,272 : [INFO]  ------------------------- Batch 227, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:59,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:59,287 : [INFO]  Batch number 227 model fetched from the server
2023-03-25 18:29:59,287 : [INFO]  ################ Batch 227: final global model evalution after 3 rounds ################
2023-03-25 18:30:01,089 : [INFO]  Batch 227: Training set : loss - 0.5802, accuracy - 0.6793, recall - 0.8587, AUC - 0.8469, F1 - 0.7281, precision - 0.632, training time - -11.0 seconds
2023-03-25 18:30:01,089 : [INFO]  Batch 227: Testing set : loss - 0.6059, accuracy - 0.6716, recall - 0.8529, AUC - 0.7724, F1 - 0.722, precision - 0.6259
2023-03-25 18:30:01,099 : [INFO]  Batch 228 initialized 
2023-03-25 18:30:01,681 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:02,336 : [INFO]  ------------------------- Batch 228 training: round 1 -------------------------
2023-03-25 18:30:08,056 : [INFO]  ------------------------- Batch round 1, loss: 0.5808 -------------------------
2023-03-25 18:30:08,056 : [INFO]  ------------------------- Batch 228, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:08,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:08,073 : [INFO]  ------------------------- Batch 228 training: round 2 -------------------------
2023-03-25 18:30:10,840 : [INFO]  ------------------------- Batch round 2, loss: 0.5792 -------------------------
2023-03-25 18:30:10,840 : [INFO]  ------------------------- Batch 228, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:10,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:10,936 : [INFO]  ------------------------- Batch 228 training: round 3 -------------------------
2023-03-25 18:30:13,730 : [INFO]  ------------------------- Batch round 3, loss: 0.582 -------------------------
2023-03-25 18:30:13,730 : [INFO]  ------------------------- Batch 228, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:13,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:13,799 : [INFO]  Batch number 228 model fetched from the server
2023-03-25 18:30:13,799 : [INFO]  ################ Batch 228: final global model evalution after 3 rounds ################
2023-03-25 18:30:15,604 : [INFO]  Batch 228: Training set : loss - 0.5944, accuracy - 0.7337, recall - 0.8913, AUC - 0.7844, F1 - 0.77, precision - 0.6777, training time - -11.0 seconds
2023-03-25 18:30:15,604 : [INFO]  Batch 228: Testing set : loss - 0.5794, accuracy - 0.701, recall - 0.8627, AUC - 0.8403, F1 - 0.7426, precision - 0.6519
2023-03-25 18:30:15,619 : [INFO]  Batch 229 initialized 
2023-03-25 18:30:16,179 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:16,825 : [INFO]  ------------------------- Batch 229 training: round 1 -------------------------
2023-03-25 18:30:22,376 : [INFO]  ------------------------- Batch round 1, loss: 0.5999 -------------------------
2023-03-25 18:30:22,376 : [INFO]  ------------------------- Batch 229, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:22,395 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:22,398 : [INFO]  ------------------------- Batch 229 training: round 2 -------------------------
2023-03-25 18:30:25,468 : [INFO]  ------------------------- Batch round 2, loss: 0.6033 -------------------------
2023-03-25 18:30:25,468 : [INFO]  ------------------------- Batch 229, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:25,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:25,511 : [INFO]  ------------------------- Batch 229 training: round 3 -------------------------
2023-03-25 18:30:28,599 : [INFO]  ------------------------- Batch round 3, loss: 0.5982 -------------------------
2023-03-25 18:30:28,599 : [INFO]  ------------------------- Batch 229, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:28,642 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:28,652 : [INFO]  Batch number 229 model fetched from the server
2023-03-25 18:30:28,652 : [INFO]  ################ Batch 229: final global model evalution after 3 rounds ################
2023-03-25 18:30:30,636 : [INFO]  Batch 229: Training set : loss - 0.6088, accuracy - 0.6685, recall - 0.8587, AUC - 0.8092, F1 - 0.7215, precision - 0.622, training time - -12.0 seconds
2023-03-25 18:30:30,636 : [INFO]  Batch 229: Testing set : loss - 0.5991, accuracy - 0.6912, recall - 0.8824, AUC - 0.8272, F1 - 0.7407, precision - 0.6383
2023-03-25 18:30:30,654 : [INFO]  Batch 230 initialized 
2023-03-25 18:30:31,251 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:31,885 : [INFO]  ------------------------- Batch 230 training: round 1 -------------------------
2023-03-25 18:30:37,356 : [INFO]  ------------------------- Batch round 1, loss: 0.5666 -------------------------
2023-03-25 18:30:37,356 : [INFO]  ------------------------- Batch 230, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:37,368 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:37,372 : [INFO]  ------------------------- Batch 230 training: round 2 -------------------------
2023-03-25 18:30:40,249 : [INFO]  ------------------------- Batch round 2, loss: 0.5656 -------------------------
2023-03-25 18:30:40,249 : [INFO]  ------------------------- Batch 230, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:40,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:40,272 : [INFO]  ------------------------- Batch 230 training: round 3 -------------------------
2023-03-25 18:30:43,167 : [INFO]  ------------------------- Batch round 3, loss: 0.5658 -------------------------
2023-03-25 18:30:43,168 : [INFO]  ------------------------- Batch 230, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:43,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:43,183 : [INFO]  Batch number 230 model fetched from the server
2023-03-25 18:30:43,184 : [INFO]  ################ Batch 230: final global model evalution after 3 rounds ################
2023-03-25 18:30:44,980 : [INFO]  Batch 230: Training set : loss - 0.5793, accuracy - 0.7337, recall - 0.8804, AUC - 0.8062, F1 - 0.7678, precision - 0.6807, training time - -11.0 seconds
2023-03-25 18:30:44,980 : [INFO]  Batch 230: Testing set : loss - 0.597, accuracy - 0.6961, recall - 0.8235, AUC - 0.7988, F1 - 0.7304, precision - 0.6562
2023-03-25 18:30:44,988 : [INFO]  Batch 231 initialized 
2023-03-25 18:30:45,550 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:46,205 : [INFO]  ------------------------- Batch 231 training: round 1 -------------------------
2023-03-25 18:30:51,526 : [INFO]  ------------------------- Batch round 1, loss: 0.6018 -------------------------
2023-03-25 18:30:51,526 : [INFO]  ------------------------- Batch 231, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:51,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:51,570 : [INFO]  ------------------------- Batch 231 training: round 2 -------------------------
2023-03-25 18:30:54,340 : [INFO]  ------------------------- Batch round 2, loss: 0.6055 -------------------------
2023-03-25 18:30:54,340 : [INFO]  ------------------------- Batch 231, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:54,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:54,413 : [INFO]  ------------------------- Batch 231 training: round 3 -------------------------
2023-03-25 18:30:57,208 : [INFO]  ------------------------- Batch round 3, loss: 0.6027 -------------------------
2023-03-25 18:30:57,209 : [INFO]  ------------------------- Batch 231, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:57,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:57,265 : [INFO]  Batch number 231 model fetched from the server
2023-03-25 18:30:57,265 : [INFO]  ################ Batch 231: final global model evalution after 3 rounds ################
2023-03-25 18:30:59,094 : [INFO]  Batch 231: Training set : loss - 0.6203, accuracy - 0.6576, recall - 0.8587, AUC - 0.7586, F1 - 0.7149, precision - 0.6124, training time - -11.0 seconds
2023-03-25 18:30:59,094 : [INFO]  Batch 231: Testing set : loss - 0.5842, accuracy - 0.7255, recall - 0.8725, AUC - 0.8462, F1 - 0.7607, precision - 0.6742
2023-03-25 18:30:59,107 : [INFO]  Batch 232 initialized 
2023-03-25 18:30:59,710 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:00,390 : [INFO]  ------------------------- Batch 232 training: round 1 -------------------------
2023-03-25 18:31:05,815 : [INFO]  ------------------------- Batch round 1, loss: 0.5641 -------------------------
2023-03-25 18:31:05,815 : [INFO]  ------------------------- Batch 232, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:05,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:05,834 : [INFO]  ------------------------- Batch 232 training: round 2 -------------------------
2023-03-25 18:31:08,815 : [INFO]  ------------------------- Batch round 2, loss: 0.5637 -------------------------
2023-03-25 18:31:08,815 : [INFO]  ------------------------- Batch 232, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:08,852 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:08,858 : [INFO]  ------------------------- Batch 232 training: round 3 -------------------------
2023-03-25 18:31:11,605 : [INFO]  ------------------------- Batch round 3, loss: 0.5628 -------------------------
2023-03-25 18:31:11,605 : [INFO]  ------------------------- Batch 232, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:11,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:11,665 : [INFO]  Batch number 232 model fetched from the server
2023-03-25 18:31:11,665 : [INFO]  ################ Batch 232: final global model evalution after 3 rounds ################
2023-03-25 18:31:13,404 : [INFO]  Batch 232: Training set : loss - 0.5685, accuracy - 0.7174, recall - 0.8913, AUC - 0.8757, F1 - 0.7593, precision - 0.6613, training time - -11.0 seconds
2023-03-25 18:31:13,404 : [INFO]  Batch 232: Testing set : loss - 0.581, accuracy - 0.701, recall - 0.9118, AUC - 0.8499, F1 - 0.753, precision - 0.6414
2023-03-25 18:31:13,414 : [INFO]  Batch 233 initialized 
2023-03-25 18:31:13,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:14,644 : [INFO]  ------------------------- Batch 233 training: round 1 -------------------------
2023-03-25 18:31:19,942 : [INFO]  ------------------------- Batch round 1, loss: 0.5671 -------------------------
2023-03-25 18:31:19,942 : [INFO]  ------------------------- Batch 233, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:20,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:20,038 : [INFO]  ------------------------- Batch 233 training: round 2 -------------------------
2023-03-25 18:31:22,902 : [INFO]  ------------------------- Batch round 2, loss: 0.5708 -------------------------
2023-03-25 18:31:22,902 : [INFO]  ------------------------- Batch 233, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:23,030 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:23,033 : [INFO]  ------------------------- Batch 233 training: round 3 -------------------------
2023-03-25 18:31:26,031 : [INFO]  ------------------------- Batch round 3, loss: 0.5648 -------------------------
2023-03-25 18:31:26,031 : [INFO]  ------------------------- Batch 233, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:26,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:26,055 : [INFO]  Batch number 233 model fetched from the server
2023-03-25 18:31:26,055 : [INFO]  ################ Batch 233: final global model evalution after 3 rounds ################
2023-03-25 18:31:27,835 : [INFO]  Batch 233: Training set : loss - 0.5791, accuracy - 0.7174, recall - 0.9239, AUC - 0.8448, F1 - 0.7658, precision - 0.6538, training time - -11.0 seconds
2023-03-25 18:31:27,836 : [INFO]  Batch 233: Testing set : loss - 0.5767, accuracy - 0.7108, recall - 0.8922, AUC - 0.8529, F1 - 0.7552, precision - 0.6547
2023-03-25 18:31:27,851 : [INFO]  Batch 234 initialized 
2023-03-25 18:31:28,419 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:29,110 : [INFO]  ------------------------- Batch 234 training: round 1 -------------------------
2023-03-25 18:31:34,540 : [INFO]  ------------------------- Batch round 1, loss: 0.6103 -------------------------
2023-03-25 18:31:34,540 : [INFO]  ------------------------- Batch 234, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:34,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:34,643 : [INFO]  ------------------------- Batch 234 training: round 2 -------------------------
2023-03-25 18:31:37,555 : [INFO]  ------------------------- Batch round 2, loss: 0.6076 -------------------------
2023-03-25 18:31:37,555 : [INFO]  ------------------------- Batch 234, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:37,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:37,707 : [INFO]  ------------------------- Batch 234 training: round 3 -------------------------
2023-03-25 18:31:40,533 : [INFO]  ------------------------- Batch round 3, loss: 0.6007 -------------------------
2023-03-25 18:31:40,533 : [INFO]  ------------------------- Batch 234, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:40,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:40,710 : [INFO]  Batch number 234 model fetched from the server
2023-03-25 18:31:40,710 : [INFO]  ################ Batch 234: final global model evalution after 3 rounds ################
2023-03-25 18:31:42,505 : [INFO]  Batch 234: Training set : loss - 0.627, accuracy - 0.6141, recall - 0.8587, AUC - 0.769, F1 - 0.69, precision - 0.5766, training time - -12.0 seconds
2023-03-25 18:31:42,505 : [INFO]  Batch 234: Testing set : loss - 0.5847, accuracy - 0.7059, recall - 0.8725, AUC - 0.8241, F1 - 0.7479, precision - 0.6544
2023-03-25 18:31:42,522 : [INFO]  Batch 235 initialized 
2023-03-25 18:31:43,128 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:43,804 : [INFO]  ------------------------- Batch 235 training: round 1 -------------------------
2023-03-25 18:31:49,204 : [INFO]  ------------------------- Batch round 1, loss: 0.5966 -------------------------
2023-03-25 18:31:49,204 : [INFO]  ------------------------- Batch 235, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:49,373 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:49,376 : [INFO]  ------------------------- Batch 235 training: round 2 -------------------------
2023-03-25 18:31:52,166 : [INFO]  ------------------------- Batch round 2, loss: 0.596 -------------------------
2023-03-25 18:31:52,167 : [INFO]  ------------------------- Batch 235, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:52,290 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:52,293 : [INFO]  ------------------------- Batch 235 training: round 3 -------------------------
2023-03-25 18:31:55,055 : [INFO]  ------------------------- Batch round 3, loss: 0.599 -------------------------
2023-03-25 18:31:55,056 : [INFO]  ------------------------- Batch 235, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:55,149 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:55,152 : [INFO]  Batch number 235 model fetched from the server
2023-03-25 18:31:55,152 : [INFO]  ################ Batch 235: final global model evalution after 3 rounds ################
2023-03-25 18:31:56,916 : [INFO]  Batch 235: Training set : loss - 0.6148, accuracy - 0.6413, recall - 0.7826, AUC - 0.7574, F1 - 0.6857, precision - 0.6102, training time - -11.0 seconds
2023-03-25 18:31:56,916 : [INFO]  Batch 235: Testing set : loss - 0.6101, accuracy - 0.6029, recall - 0.8529, AUC - 0.8019, F1 - 0.6824, precision - 0.5686
2023-03-25 18:31:56,925 : [INFO]  Batch 236 initialized 
2023-03-25 18:31:57,489 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:58,155 : [INFO]  ------------------------- Batch 236 training: round 1 -------------------------
2023-03-25 18:32:03,578 : [INFO]  ------------------------- Batch round 1, loss: 0.5819 -------------------------
2023-03-25 18:32:03,578 : [INFO]  ------------------------- Batch 236, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:03,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:03,592 : [INFO]  ------------------------- Batch 236 training: round 2 -------------------------
2023-03-25 18:32:06,470 : [INFO]  ------------------------- Batch round 2, loss: 0.5832 -------------------------
2023-03-25 18:32:06,471 : [INFO]  ------------------------- Batch 236, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:06,501 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:06,504 : [INFO]  ------------------------- Batch 236 training: round 3 -------------------------
2023-03-25 18:32:09,305 : [INFO]  ------------------------- Batch round 3, loss: 0.585 -------------------------
2023-03-25 18:32:09,306 : [INFO]  ------------------------- Batch 236, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:09,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:09,326 : [INFO]  Batch number 236 model fetched from the server
2023-03-25 18:32:09,326 : [INFO]  ################ Batch 236: final global model evalution after 3 rounds ################
2023-03-25 18:32:11,186 : [INFO]  Batch 236: Training set : loss - 0.6078, accuracy - 0.6576, recall - 0.7826, AUC - 0.7681, F1 - 0.6957, precision - 0.6261, training time - -11.0 seconds
2023-03-25 18:32:11,186 : [INFO]  Batch 236: Testing set : loss - 0.6041, accuracy - 0.6618, recall - 0.8431, AUC - 0.8036, F1 - 0.7137, precision - 0.6187
2023-03-25 18:32:11,193 : [INFO]  Batch 237 initialized 
2023-03-25 18:32:11,772 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:12,447 : [INFO]  ------------------------- Batch 237 training: round 1 -------------------------
2023-03-25 18:32:17,837 : [INFO]  ------------------------- Batch round 1, loss: 0.5956 -------------------------
2023-03-25 18:32:17,837 : [INFO]  ------------------------- Batch 237, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:17,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:17,853 : [INFO]  ------------------------- Batch 237 training: round 2 -------------------------
2023-03-25 18:32:20,687 : [INFO]  ------------------------- Batch round 2, loss: 0.5935 -------------------------
2023-03-25 18:32:20,687 : [INFO]  ------------------------- Batch 237, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:20,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:20,709 : [INFO]  ------------------------- Batch 237 training: round 3 -------------------------
2023-03-25 18:32:23,671 : [INFO]  ------------------------- Batch round 3, loss: 0.5964 -------------------------
2023-03-25 18:32:23,671 : [INFO]  ------------------------- Batch 237, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:23,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:23,723 : [INFO]  Batch number 237 model fetched from the server
2023-03-25 18:32:23,723 : [INFO]  ################ Batch 237: final global model evalution after 3 rounds ################
2023-03-25 18:32:25,464 : [INFO]  Batch 237: Training set : loss - 0.6042, accuracy - 0.6957, recall - 0.8696, AUC - 0.7724, F1 - 0.7407, precision - 0.6452, training time - -11.0 seconds
2023-03-25 18:32:25,464 : [INFO]  Batch 237: Testing set : loss - 0.5851, accuracy - 0.701, recall - 0.8039, AUC - 0.7945, F1 - 0.7289, precision - 0.6667
2023-03-25 18:32:25,477 : [INFO]  Batch 238 initialized 
2023-03-25 18:32:26,051 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:26,733 : [INFO]  ------------------------- Batch 238 training: round 1 -------------------------
2023-03-25 18:32:32,279 : [INFO]  ------------------------- Batch round 1, loss: 0.5738 -------------------------
2023-03-25 18:32:32,280 : [INFO]  ------------------------- Batch 238, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:32,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:32,325 : [INFO]  ------------------------- Batch 238 training: round 2 -------------------------
2023-03-25 18:32:35,047 : [INFO]  ------------------------- Batch round 2, loss: 0.5766 -------------------------
2023-03-25 18:32:35,047 : [INFO]  ------------------------- Batch 238, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:35,071 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:35,074 : [INFO]  ------------------------- Batch 238 training: round 3 -------------------------
2023-03-25 18:32:37,858 : [INFO]  ------------------------- Batch round 3, loss: 0.5645 -------------------------
2023-03-25 18:32:37,858 : [INFO]  ------------------------- Batch 238, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:37,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:37,872 : [INFO]  Batch number 238 model fetched from the server
2023-03-25 18:32:37,873 : [INFO]  ################ Batch 238: final global model evalution after 3 rounds ################
2023-03-25 18:32:39,617 : [INFO]  Batch 238: Training set : loss - 0.5758, accuracy - 0.7283, recall - 0.9022, AUC - 0.8412, F1 - 0.7685, precision - 0.6694, training time - -11.0 seconds
2023-03-25 18:32:39,617 : [INFO]  Batch 238: Testing set : loss - 0.5739, accuracy - 0.7206, recall - 0.9118, AUC - 0.8637, F1 - 0.7654, precision - 0.6596
2023-03-25 18:32:39,631 : [INFO]  Batch 239 initialized 
2023-03-25 18:32:40,196 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:40,871 : [INFO]  ------------------------- Batch 239 training: round 1 -------------------------
2023-03-25 18:32:46,365 : [INFO]  ------------------------- Batch round 1, loss: 0.5564 -------------------------
2023-03-25 18:32:46,365 : [INFO]  ------------------------- Batch 239, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:46,379 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:46,381 : [INFO]  ------------------------- Batch 239 training: round 2 -------------------------
2023-03-25 18:32:49,315 : [INFO]  ------------------------- Batch round 2, loss: 0.5618 -------------------------
2023-03-25 18:32:49,315 : [INFO]  ------------------------- Batch 239, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:49,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:49,331 : [INFO]  ------------------------- Batch 239 training: round 3 -------------------------
2023-03-25 18:32:52,240 : [INFO]  ------------------------- Batch round 3, loss: 0.5577 -------------------------
2023-03-25 18:32:52,240 : [INFO]  ------------------------- Batch 239, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:52,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:52,257 : [INFO]  Batch number 239 model fetched from the server
2023-03-25 18:32:52,257 : [INFO]  ################ Batch 239: final global model evalution after 3 rounds ################
2023-03-25 18:32:54,062 : [INFO]  Batch 239: Training set : loss - 0.5626, accuracy - 0.7337, recall - 0.8696, AUC - 0.8729, F1 - 0.7656, precision - 0.6838, training time - -11.0 seconds
2023-03-25 18:32:54,062 : [INFO]  Batch 239: Testing set : loss - 0.5639, accuracy - 0.7451, recall - 0.9118, AUC - 0.8591, F1 - 0.7815, precision - 0.6838
2023-03-25 18:32:54,071 : [INFO]  Batch 240 initialized 
2023-03-25 18:32:54,637 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:55,322 : [INFO]  ------------------------- Batch 240 training: round 1 -------------------------
2023-03-25 18:33:00,957 : [INFO]  ------------------------- Batch round 1, loss: 0.5856 -------------------------
2023-03-25 18:33:00,958 : [INFO]  ------------------------- Batch 240, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:00,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:00,975 : [INFO]  ------------------------- Batch 240 training: round 2 -------------------------
2023-03-25 18:33:03,993 : [INFO]  ------------------------- Batch round 2, loss: 0.5835 -------------------------
2023-03-25 18:33:03,993 : [INFO]  ------------------------- Batch 240, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:04,005 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:04,007 : [INFO]  ------------------------- Batch 240 training: round 3 -------------------------
2023-03-25 18:33:06,972 : [INFO]  ------------------------- Batch round 3, loss: 0.5841 -------------------------
2023-03-25 18:33:06,972 : [INFO]  ------------------------- Batch 240, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:06,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:06,996 : [INFO]  Batch number 240 model fetched from the server
2023-03-25 18:33:06,996 : [INFO]  ################ Batch 240: final global model evalution after 3 rounds ################
2023-03-25 18:33:08,806 : [INFO]  Batch 240: Training set : loss - 0.5905, accuracy - 0.7228, recall - 0.8913, AUC - 0.8161, F1 - 0.7628, precision - 0.6667, training time - -12.0 seconds
2023-03-25 18:33:08,807 : [INFO]  Batch 240: Testing set : loss - 0.5974, accuracy - 0.6618, recall - 0.7941, AUC - 0.8075, F1 - 0.7013, precision - 0.6279
2023-03-25 18:33:08,816 : [INFO]  Batch 241 initialized 
2023-03-25 18:33:09,376 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:10,048 : [INFO]  ------------------------- Batch 241 training: round 1 -------------------------
2023-03-25 18:33:15,450 : [INFO]  ------------------------- Batch round 1, loss: 0.5749 -------------------------
2023-03-25 18:33:15,450 : [INFO]  ------------------------- Batch 241, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:15,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:15,466 : [INFO]  ------------------------- Batch 241 training: round 2 -------------------------
2023-03-25 18:33:18,373 : [INFO]  ------------------------- Batch round 2, loss: 0.577 -------------------------
2023-03-25 18:33:18,373 : [INFO]  ------------------------- Batch 241, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:18,388 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:18,390 : [INFO]  ------------------------- Batch 241 training: round 3 -------------------------
2023-03-25 18:33:21,295 : [INFO]  ------------------------- Batch round 3, loss: 0.5748 -------------------------
2023-03-25 18:33:21,295 : [INFO]  ------------------------- Batch 241, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:21,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:21,330 : [INFO]  Batch number 241 model fetched from the server
2023-03-25 18:33:21,331 : [INFO]  ################ Batch 241: final global model evalution after 3 rounds ################
2023-03-25 18:33:23,103 : [INFO]  Batch 241: Training set : loss - 0.5875, accuracy - 0.7228, recall - 0.8804, AUC - 0.8261, F1 - 0.7606, precision - 0.6694, training time - -11.0 seconds
2023-03-25 18:33:23,103 : [INFO]  Batch 241: Testing set : loss - 0.5815, accuracy - 0.7157, recall - 0.8431, AUC - 0.835, F1 - 0.7478, precision - 0.6719
2023-03-25 18:33:23,118 : [INFO]  Batch 242 initialized 
2023-03-25 18:33:23,686 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:24,371 : [INFO]  ------------------------- Batch 242 training: round 1 -------------------------
2023-03-25 18:33:29,738 : [INFO]  ------------------------- Batch round 1, loss: 0.5657 -------------------------
2023-03-25 18:33:29,738 : [INFO]  ------------------------- Batch 242, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:29,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:29,752 : [INFO]  ------------------------- Batch 242 training: round 2 -------------------------
2023-03-25 18:33:32,639 : [INFO]  ------------------------- Batch round 2, loss: 0.5686 -------------------------
2023-03-25 18:33:32,639 : [INFO]  ------------------------- Batch 242, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:32,672 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:32,675 : [INFO]  ------------------------- Batch 242 training: round 3 -------------------------
2023-03-25 18:33:35,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5698 -------------------------
2023-03-25 18:33:35,579 : [INFO]  ------------------------- Batch 242, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:35,592 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:35,595 : [INFO]  Batch number 242 model fetched from the server
2023-03-25 18:33:35,595 : [INFO]  ################ Batch 242: final global model evalution after 3 rounds ################
2023-03-25 18:33:37,393 : [INFO]  Batch 242: Training set : loss - 0.5735, accuracy - 0.75, recall - 0.9457, AUC - 0.8559, F1 - 0.7909, precision - 0.6797, training time - -11.0 seconds
2023-03-25 18:33:37,393 : [INFO]  Batch 242: Testing set : loss - 0.5943, accuracy - 0.6863, recall - 0.8431, AUC - 0.8124, F1 - 0.7288, precision - 0.6418
2023-03-25 18:33:37,424 : [INFO]  Batch 243 initialized 
2023-03-25 18:33:37,998 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:38,646 : [INFO]  ------------------------- Batch 243 training: round 1 -------------------------
2023-03-25 18:33:44,202 : [INFO]  ------------------------- Batch round 1, loss: 0.602 -------------------------
2023-03-25 18:33:44,202 : [INFO]  ------------------------- Batch 243, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:44,220 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:44,222 : [INFO]  ------------------------- Batch 243 training: round 2 -------------------------
2023-03-25 18:33:47,124 : [INFO]  ------------------------- Batch round 2, loss: 0.6005 -------------------------
2023-03-25 18:33:47,124 : [INFO]  ------------------------- Batch 243, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:47,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:47,157 : [INFO]  ------------------------- Batch 243 training: round 3 -------------------------
2023-03-25 18:33:50,068 : [INFO]  ------------------------- Batch round 3, loss: 0.601 -------------------------
2023-03-25 18:33:50,068 : [INFO]  ------------------------- Batch 243, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:50,083 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:50,086 : [INFO]  Batch number 243 model fetched from the server
2023-03-25 18:33:50,086 : [INFO]  ################ Batch 243: final global model evalution after 3 rounds ################
2023-03-25 18:33:51,876 : [INFO]  Batch 243: Training set : loss - 0.6112, accuracy - 0.6739, recall - 0.8804, AUC - 0.7828, F1 - 0.7297, precision - 0.6231, training time - -11.0 seconds
2023-03-25 18:33:51,876 : [INFO]  Batch 243: Testing set : loss - 0.5619, accuracy - 0.7549, recall - 0.8627, AUC - 0.8592, F1 - 0.7788, precision - 0.7097
2023-03-25 18:33:51,889 : [INFO]  Batch 244 initialized 
2023-03-25 18:33:52,455 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:53,136 : [INFO]  ------------------------- Batch 244 training: round 1 -------------------------
2023-03-25 18:33:58,549 : [INFO]  ------------------------- Batch round 1, loss: 0.6125 -------------------------
2023-03-25 18:33:58,549 : [INFO]  ------------------------- Batch 244, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:58,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:58,563 : [INFO]  ------------------------- Batch 244 training: round 2 -------------------------
2023-03-25 18:34:01,688 : [INFO]  ------------------------- Batch round 2, loss: 0.6161 -------------------------
2023-03-25 18:34:01,688 : [INFO]  ------------------------- Batch 244, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:01,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:01,706 : [INFO]  ------------------------- Batch 244 training: round 3 -------------------------
2023-03-25 18:34:04,822 : [INFO]  ------------------------- Batch round 3, loss: 0.611 -------------------------
2023-03-25 18:34:04,822 : [INFO]  ------------------------- Batch 244, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:04,835 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:04,838 : [INFO]  Batch number 244 model fetched from the server
2023-03-25 18:34:04,838 : [INFO]  ################ Batch 244: final global model evalution after 3 rounds ################
2023-03-25 18:34:06,651 : [INFO]  Batch 244: Training set : loss - 0.6205, accuracy - 0.6902, recall - 0.8696, AUC - 0.7551, F1 - 0.7373, precision - 0.64, training time - -12.0 seconds
2023-03-25 18:34:06,651 : [INFO]  Batch 244: Testing set : loss - 0.6048, accuracy - 0.701, recall - 0.8725, AUC - 0.8008, F1 - 0.7448, precision - 0.6496
2023-03-25 18:34:06,660 : [INFO]  Batch 245 initialized 
2023-03-25 18:34:07,228 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:07,910 : [INFO]  ------------------------- Batch 245 training: round 1 -------------------------
2023-03-25 18:34:13,314 : [INFO]  ------------------------- Batch round 1, loss: 0.5659 -------------------------
2023-03-25 18:34:13,315 : [INFO]  ------------------------- Batch 245, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:13,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:13,378 : [INFO]  ------------------------- Batch 245 training: round 2 -------------------------
2023-03-25 18:34:16,263 : [INFO]  ------------------------- Batch round 2, loss: 0.5669 -------------------------
2023-03-25 18:34:16,263 : [INFO]  ------------------------- Batch 245, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:16,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:16,338 : [INFO]  ------------------------- Batch 245 training: round 3 -------------------------
2023-03-25 18:34:19,183 : [INFO]  ------------------------- Batch round 3, loss: 0.5695 -------------------------
2023-03-25 18:34:19,183 : [INFO]  ------------------------- Batch 245, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:19,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:19,242 : [INFO]  Batch number 245 model fetched from the server
2023-03-25 18:34:19,242 : [INFO]  ################ Batch 245: final global model evalution after 3 rounds ################
2023-03-25 18:34:21,013 : [INFO]  Batch 245: Training set : loss - 0.5787, accuracy - 0.6793, recall - 0.837, AUC - 0.8181, F1 - 0.723, precision - 0.6364, training time - -11.0 seconds
2023-03-25 18:34:21,014 : [INFO]  Batch 245: Testing set : loss - 0.5895, accuracy - 0.6765, recall - 0.8137, AUC - 0.8142, F1 - 0.7155, precision - 0.6385
2023-03-25 18:34:21,028 : [INFO]  Batch 246 initialized 
2023-03-25 18:34:21,574 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:22,240 : [INFO]  ------------------------- Batch 246 training: round 1 -------------------------
2023-03-25 18:34:27,788 : [INFO]  ------------------------- Batch round 1, loss: 0.5474 -------------------------
2023-03-25 18:34:27,789 : [INFO]  ------------------------- Batch 246, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:27,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:27,806 : [INFO]  ------------------------- Batch 246 training: round 2 -------------------------
2023-03-25 18:34:30,840 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-25 18:34:30,840 : [INFO]  ------------------------- Batch 246, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:30,853 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:30,856 : [INFO]  ------------------------- Batch 246 training: round 3 -------------------------
2023-03-25 18:34:33,854 : [INFO]  ------------------------- Batch round 3, loss: 0.5515 -------------------------
2023-03-25 18:34:33,854 : [INFO]  ------------------------- Batch 246, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:33,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:33,876 : [INFO]  Batch number 246 model fetched from the server
2023-03-25 18:34:33,877 : [INFO]  ################ Batch 246: final global model evalution after 3 rounds ################
2023-03-25 18:34:35,795 : [INFO]  Batch 246: Training set : loss - 0.5532, accuracy - 0.7717, recall - 0.913, AUC - 0.8927, F1 - 0.8, precision - 0.7119, training time - -12.0 seconds
2023-03-25 18:34:35,796 : [INFO]  Batch 246: Testing set : loss - 0.5719, accuracy - 0.7157, recall - 0.902, AUC - 0.8625, F1 - 0.7603, precision - 0.6571
2023-03-25 18:34:35,803 : [INFO]  Batch 247 initialized 
2023-03-25 18:34:36,377 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:37,075 : [INFO]  ------------------------- Batch 247 training: round 1 -------------------------
2023-03-25 18:34:42,668 : [INFO]  ------------------------- Batch round 1, loss: 0.5785 -------------------------
2023-03-25 18:34:42,668 : [INFO]  ------------------------- Batch 247, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:42,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:42,687 : [INFO]  ------------------------- Batch 247 training: round 2 -------------------------
2023-03-25 18:34:45,584 : [INFO]  ------------------------- Batch round 2, loss: 0.5727 -------------------------
2023-03-25 18:34:45,584 : [INFO]  ------------------------- Batch 247, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:45,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:45,639 : [INFO]  ------------------------- Batch 247 training: round 3 -------------------------
2023-03-25 18:34:48,538 : [INFO]  ------------------------- Batch round 3, loss: 0.5724 -------------------------
2023-03-25 18:34:48,538 : [INFO]  ------------------------- Batch 247, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:48,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:48,583 : [INFO]  Batch number 247 model fetched from the server
2023-03-25 18:34:48,583 : [INFO]  ################ Batch 247: final global model evalution after 3 rounds ################
2023-03-25 18:34:50,317 : [INFO]  Batch 247: Training set : loss - 0.5793, accuracy - 0.7011, recall - 0.8261, AUC - 0.8222, F1 - 0.7343, precision - 0.6609, training time - -12.0 seconds
2023-03-25 18:34:50,317 : [INFO]  Batch 247: Testing set : loss - 0.5896, accuracy - 0.6814, recall - 0.8137, AUC - 0.8203, F1 - 0.7186, precision - 0.6434
2023-03-25 18:34:50,332 : [INFO]  Batch 248 initialized 
2023-03-25 18:34:50,906 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:51,627 : [INFO]  ------------------------- Batch 248 training: round 1 -------------------------
2023-03-25 18:34:56,978 : [INFO]  ------------------------- Batch round 1, loss: 0.593 -------------------------
2023-03-25 18:34:56,979 : [INFO]  ------------------------- Batch 248, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:57,034 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:57,038 : [INFO]  ------------------------- Batch 248 training: round 2 -------------------------
2023-03-25 18:35:00,140 : [INFO]  ------------------------- Batch round 2, loss: 0.594 -------------------------
2023-03-25 18:35:00,140 : [INFO]  ------------------------- Batch 248, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:00,176 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:00,180 : [INFO]  ------------------------- Batch 248 training: round 3 -------------------------
2023-03-25 18:35:03,098 : [INFO]  ------------------------- Batch round 3, loss: 0.5927 -------------------------
2023-03-25 18:35:03,098 : [INFO]  ------------------------- Batch 248, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:03,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:03,244 : [INFO]  Batch number 248 model fetched from the server
2023-03-25 18:35:03,244 : [INFO]  ################ Batch 248: final global model evalution after 3 rounds ################
2023-03-25 18:35:05,083 : [INFO]  Batch 248: Training set : loss - 0.6038, accuracy - 0.6522, recall - 0.8043, AUC - 0.7805, F1 - 0.6981, precision - 0.6167, training time - -12.0 seconds
2023-03-25 18:35:05,084 : [INFO]  Batch 248: Testing set : loss - 0.589, accuracy - 0.6912, recall - 0.9118, AUC - 0.8614, F1 - 0.747, precision - 0.6327
2023-03-25 18:35:05,098 : [INFO]  Batch 249 initialized 
2023-03-25 18:35:05,700 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:06,405 : [INFO]  ------------------------- Batch 249 training: round 1 -------------------------
2023-03-25 18:35:12,070 : [INFO]  ------------------------- Batch round 1, loss: 0.5647 -------------------------
2023-03-25 18:35:12,071 : [INFO]  ------------------------- Batch 249, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:12,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:12,130 : [INFO]  ------------------------- Batch 249 training: round 2 -------------------------
2023-03-25 18:35:15,089 : [INFO]  ------------------------- Batch round 2, loss: 0.5635 -------------------------
2023-03-25 18:35:15,089 : [INFO]  ------------------------- Batch 249, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:15,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:15,104 : [INFO]  ------------------------- Batch 249 training: round 3 -------------------------
2023-03-25 18:35:17,928 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-25 18:35:17,928 : [INFO]  ------------------------- Batch 249, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:18,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:18,032 : [INFO]  Batch number 249 model fetched from the server
2023-03-25 18:35:18,033 : [INFO]  ################ Batch 249: final global model evalution after 3 rounds ################
2023-03-25 18:35:19,864 : [INFO]  Batch 249: Training set : loss - 0.5677, accuracy - 0.7391, recall - 0.9457, AUC - 0.8648, F1 - 0.7838, precision - 0.6692, training time - -12.0 seconds
2023-03-25 18:35:19,865 : [INFO]  Batch 249: Testing set : loss - 0.5739, accuracy - 0.7157, recall - 0.8627, AUC - 0.8503, F1 - 0.7521, precision - 0.6667
2023-03-25 18:35:19,879 : [INFO]  Batch 250 initialized 
2023-03-25 18:35:20,445 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:21,145 : [INFO]  ------------------------- Batch 250 training: round 1 -------------------------
2023-03-25 18:35:26,723 : [INFO]  ------------------------- Batch round 1, loss: 0.5755 -------------------------
2023-03-25 18:35:26,723 : [INFO]  ------------------------- Batch 250, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:26,736 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:26,739 : [INFO]  ------------------------- Batch 250 training: round 2 -------------------------
2023-03-25 18:35:29,804 : [INFO]  ------------------------- Batch round 2, loss: 0.5797 -------------------------
2023-03-25 18:35:29,804 : [INFO]  ------------------------- Batch 250, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:29,819 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:29,822 : [INFO]  ------------------------- Batch 250 training: round 3 -------------------------
2023-03-25 18:35:32,826 : [INFO]  ------------------------- Batch round 3, loss: 0.5775 -------------------------
2023-03-25 18:35:32,826 : [INFO]  ------------------------- Batch 250, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:32,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:32,843 : [INFO]  Batch number 250 model fetched from the server
2023-03-25 18:35:32,843 : [INFO]  ################ Batch 250: final global model evalution after 3 rounds ################
2023-03-25 18:35:34,700 : [INFO]  Batch 250: Training set : loss - 0.584, accuracy - 0.6848, recall - 0.8804, AUC - 0.8347, F1 - 0.7364, precision - 0.6328, training time - -12.0 seconds
2023-03-25 18:35:34,700 : [INFO]  Batch 250: Testing set : loss - 0.5774, accuracy - 0.7108, recall - 0.8922, AUC - 0.8485, F1 - 0.7552, precision - 0.6547
2023-03-25 18:35:34,708 : [INFO]  Batch 251 initialized 
2023-03-25 18:35:35,276 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:35,956 : [INFO]  ------------------------- Batch 251 training: round 1 -------------------------
2023-03-25 18:35:41,341 : [INFO]  ------------------------- Batch round 1, loss: 0.5939 -------------------------
2023-03-25 18:35:41,341 : [INFO]  ------------------------- Batch 251, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:41,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:41,532 : [INFO]  ------------------------- Batch 251 training: round 2 -------------------------
2023-03-25 18:35:44,364 : [INFO]  ------------------------- Batch round 2, loss: 0.5952 -------------------------
2023-03-25 18:35:44,364 : [INFO]  ------------------------- Batch 251, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:44,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:44,564 : [INFO]  ------------------------- Batch 251 training: round 3 -------------------------
2023-03-25 18:35:47,524 : [INFO]  ------------------------- Batch round 3, loss: 0.5983 -------------------------
2023-03-25 18:35:47,524 : [INFO]  ------------------------- Batch 251, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:47,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:47,564 : [INFO]  Batch number 251 model fetched from the server
2023-03-25 18:35:47,564 : [INFO]  ################ Batch 251: final global model evalution after 3 rounds ################
2023-03-25 18:35:49,405 : [INFO]  Batch 251: Training set : loss - 0.6082, accuracy - 0.6522, recall - 0.8261, AUC - 0.7844, F1 - 0.7037, precision - 0.6129, training time - -12.0 seconds
2023-03-25 18:35:49,405 : [INFO]  Batch 251: Testing set : loss - 0.5982, accuracy - 0.701, recall - 0.8725, AUC - 0.8076, F1 - 0.7448, precision - 0.6496
2023-03-25 18:35:49,415 : [INFO]  Batch 252 initialized 
2023-03-25 18:35:49,985 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:50,667 : [INFO]  ------------------------- Batch 252 training: round 1 -------------------------
2023-03-25 18:35:56,188 : [INFO]  ------------------------- Batch round 1, loss: 0.5875 -------------------------
2023-03-25 18:35:56,188 : [INFO]  ------------------------- Batch 252, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:56,203 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:56,206 : [INFO]  ------------------------- Batch 252 training: round 2 -------------------------
2023-03-25 18:35:59,097 : [INFO]  ------------------------- Batch round 2, loss: 0.5898 -------------------------
2023-03-25 18:35:59,097 : [INFO]  ------------------------- Batch 252, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:59,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:59,111 : [INFO]  ------------------------- Batch 252 training: round 3 -------------------------
2023-03-25 18:36:02,022 : [INFO]  ------------------------- Batch round 3, loss: 0.5856 -------------------------
2023-03-25 18:36:02,022 : [INFO]  ------------------------- Batch 252, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:02,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:02,040 : [INFO]  Batch number 252 model fetched from the server
2023-03-25 18:36:02,040 : [INFO]  ################ Batch 252: final global model evalution after 3 rounds ################
2023-03-25 18:36:03,845 : [INFO]  Batch 252: Training set : loss - 0.5883, accuracy - 0.7065, recall - 0.837, AUC - 0.8002, F1 - 0.7404, precision - 0.6638, training time - -11.0 seconds
2023-03-25 18:36:03,846 : [INFO]  Batch 252: Testing set : loss - 0.5786, accuracy - 0.7108, recall - 0.8922, AUC - 0.8478, F1 - 0.7552, precision - 0.6547
2023-03-25 18:36:03,855 : [INFO]  Batch 253 initialized 
2023-03-25 18:36:04,418 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:05,106 : [INFO]  ------------------------- Batch 253 training: round 1 -------------------------
2023-03-25 18:36:10,574 : [INFO]  ------------------------- Batch round 1, loss: 0.5951 -------------------------
2023-03-25 18:36:10,574 : [INFO]  ------------------------- Batch 253, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:10,644 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:10,647 : [INFO]  ------------------------- Batch 253 training: round 2 -------------------------
2023-03-25 18:36:13,698 : [INFO]  ------------------------- Batch round 2, loss: 0.5996 -------------------------
2023-03-25 18:36:13,698 : [INFO]  ------------------------- Batch 253, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:13,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:13,715 : [INFO]  ------------------------- Batch 253 training: round 3 -------------------------
2023-03-25 18:36:16,638 : [INFO]  ------------------------- Batch round 3, loss: 0.5953 -------------------------
2023-03-25 18:36:16,639 : [INFO]  ------------------------- Batch 253, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:16,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:16,662 : [INFO]  Batch number 253 model fetched from the server
2023-03-25 18:36:16,662 : [INFO]  ################ Batch 253: final global model evalution after 3 rounds ################
2023-03-25 18:36:18,454 : [INFO]  Batch 253: Training set : loss - 0.6109, accuracy - 0.6304, recall - 0.8152, AUC - 0.7777, F1 - 0.6881, precision - 0.5952, training time - -12.0 seconds
2023-03-25 18:36:18,454 : [INFO]  Batch 253: Testing set : loss - 0.6086, accuracy - 0.6225, recall - 0.7843, AUC - 0.791, F1 - 0.6751, precision - 0.5926
2023-03-25 18:36:18,474 : [INFO]  Batch 254 initialized 
2023-03-25 18:36:19,041 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:19,770 : [INFO]  ------------------------- Batch 254 training: round 1 -------------------------
2023-03-25 18:36:25,410 : [INFO]  ------------------------- Batch round 1, loss: 0.5981 -------------------------
2023-03-25 18:36:25,410 : [INFO]  ------------------------- Batch 254, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:25,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:25,448 : [INFO]  ------------------------- Batch 254 training: round 2 -------------------------
2023-03-25 18:36:28,429 : [INFO]  ------------------------- Batch round 2, loss: 0.6053 -------------------------
2023-03-25 18:36:28,429 : [INFO]  ------------------------- Batch 254, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:28,450 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:28,453 : [INFO]  ------------------------- Batch 254 training: round 3 -------------------------
2023-03-25 18:36:31,474 : [INFO]  ------------------------- Batch round 3, loss: 0.6117 -------------------------
2023-03-25 18:36:31,474 : [INFO]  ------------------------- Batch 254, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:31,490 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:31,493 : [INFO]  Batch number 254 model fetched from the server
2023-03-25 18:36:31,493 : [INFO]  ################ Batch 254: final global model evalution after 3 rounds ################
2023-03-25 18:36:33,291 : [INFO]  Batch 254: Training set : loss - 0.6197, accuracy - 0.6467, recall - 0.8043, AUC - 0.7418, F1 - 0.6948, precision - 0.6116, training time - -12.0 seconds
2023-03-25 18:36:33,291 : [INFO]  Batch 254: Testing set : loss - 0.616, accuracy - 0.6176, recall - 0.8529, AUC - 0.7935, F1 - 0.6905, precision - 0.58
2023-03-25 18:36:33,304 : [INFO]  Batch 255 initialized 
2023-03-25 18:36:33,868 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:34,569 : [INFO]  ------------------------- Batch 255 training: round 1 -------------------------
2023-03-25 18:36:40,264 : [INFO]  ------------------------- Batch round 1, loss: 0.58 -------------------------
2023-03-25 18:36:40,264 : [INFO]  ------------------------- Batch 255, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:40,321 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:40,325 : [INFO]  ------------------------- Batch 255 training: round 2 -------------------------
2023-03-25 18:36:43,239 : [INFO]  ------------------------- Batch round 2, loss: 0.5827 -------------------------
2023-03-25 18:36:43,239 : [INFO]  ------------------------- Batch 255, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:43,281 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:43,284 : [INFO]  ------------------------- Batch 255 training: round 3 -------------------------
2023-03-25 18:36:46,254 : [INFO]  ------------------------- Batch round 3, loss: 0.5832 -------------------------
2023-03-25 18:36:46,254 : [INFO]  ------------------------- Batch 255, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:46,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:46,274 : [INFO]  Batch number 255 model fetched from the server
2023-03-25 18:36:46,274 : [INFO]  ################ Batch 255: final global model evalution after 3 rounds ################
2023-03-25 18:36:48,087 : [INFO]  Batch 255: Training set : loss - 0.5883, accuracy - 0.7011, recall - 0.8478, AUC - 0.8181, F1 - 0.7393, precision - 0.6555, training time - -12.0 seconds
2023-03-25 18:36:48,087 : [INFO]  Batch 255: Testing set : loss - 0.6068, accuracy - 0.6471, recall - 0.8333, AUC - 0.8013, F1 - 0.7025, precision - 0.6071
2023-03-25 18:36:48,097 : [INFO]  Batch 256 initialized 
2023-03-25 18:36:48,663 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:49,384 : [INFO]  ------------------------- Batch 256 training: round 1 -------------------------
2023-03-25 18:36:54,862 : [INFO]  ------------------------- Batch round 1, loss: 0.576 -------------------------
2023-03-25 18:36:54,863 : [INFO]  ------------------------- Batch 256, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:54,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:54,980 : [INFO]  ------------------------- Batch 256 training: round 2 -------------------------
2023-03-25 18:36:57,768 : [INFO]  ------------------------- Batch round 2, loss: 0.5841 -------------------------
2023-03-25 18:36:57,768 : [INFO]  ------------------------- Batch 256, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:57,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:57,960 : [INFO]  ------------------------- Batch 256 training: round 3 -------------------------
2023-03-25 18:37:00,768 : [INFO]  ------------------------- Batch round 3, loss: 0.5819 -------------------------
2023-03-25 18:37:00,768 : [INFO]  ------------------------- Batch 256, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:00,882 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:00,885 : [INFO]  Batch number 256 model fetched from the server
2023-03-25 18:37:00,885 : [INFO]  ################ Batch 256: final global model evalution after 3 rounds ################
2023-03-25 18:37:02,655 : [INFO]  Batch 256: Training set : loss - 0.5891, accuracy - 0.6902, recall - 0.8696, AUC - 0.8039, F1 - 0.7373, precision - 0.64, training time - -12.0 seconds
2023-03-25 18:37:02,655 : [INFO]  Batch 256: Testing set : loss - 0.6048, accuracy - 0.6863, recall - 0.8529, AUC - 0.7935, F1 - 0.7311, precision - 0.6397
2023-03-25 18:37:02,670 : [INFO]  Batch 257 initialized 
2023-03-25 18:37:03,235 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:03,956 : [INFO]  ------------------------- Batch 257 training: round 1 -------------------------
2023-03-25 18:37:09,360 : [INFO]  ------------------------- Batch round 1, loss: 0.6236 -------------------------
2023-03-25 18:37:09,360 : [INFO]  ------------------------- Batch 257, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:09,375 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:09,379 : [INFO]  ------------------------- Batch 257 training: round 2 -------------------------
2023-03-25 18:37:12,223 : [INFO]  ------------------------- Batch round 2, loss: 0.6174 -------------------------
2023-03-25 18:37:12,223 : [INFO]  ------------------------- Batch 257, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:12,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:12,323 : [INFO]  ------------------------- Batch 257 training: round 3 -------------------------
2023-03-25 18:37:15,197 : [INFO]  ------------------------- Batch round 3, loss: 0.619 -------------------------
2023-03-25 18:37:15,197 : [INFO]  ------------------------- Batch 257, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:15,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:15,216 : [INFO]  Batch number 257 model fetched from the server
2023-03-25 18:37:15,216 : [INFO]  ################ Batch 257: final global model evalution after 3 rounds ################
2023-03-25 18:37:17,067 : [INFO]  Batch 257: Training set : loss - 0.6324, accuracy - 0.6304, recall - 0.8043, AUC - 0.7333, F1 - 0.6852, precision - 0.5968, training time - -11.0 seconds
2023-03-25 18:37:17,068 : [INFO]  Batch 257: Testing set : loss - 0.589, accuracy - 0.6961, recall - 0.8333, AUC - 0.8129, F1 - 0.7328, precision - 0.6538
2023-03-25 18:37:17,113 : [INFO]  Batch 258 initialized 
2023-03-25 18:37:17,707 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:18,416 : [INFO]  ------------------------- Batch 258 training: round 1 -------------------------
2023-03-25 18:37:24,110 : [INFO]  ------------------------- Batch round 1, loss: 0.5716 -------------------------
2023-03-25 18:37:24,110 : [INFO]  ------------------------- Batch 258, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:24,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:24,156 : [INFO]  ------------------------- Batch 258 training: round 2 -------------------------
2023-03-25 18:37:27,102 : [INFO]  ------------------------- Batch round 2, loss: 0.5751 -------------------------
2023-03-25 18:37:27,103 : [INFO]  ------------------------- Batch 258, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:27,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:27,163 : [INFO]  ------------------------- Batch 258 training: round 3 -------------------------
2023-03-25 18:37:30,032 : [INFO]  ------------------------- Batch round 3, loss: 0.5786 -------------------------
2023-03-25 18:37:30,032 : [INFO]  ------------------------- Batch 258, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:30,047 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:30,051 : [INFO]  Batch number 258 model fetched from the server
2023-03-25 18:37:30,051 : [INFO]  ################ Batch 258: final global model evalution after 3 rounds ################
2023-03-25 18:37:31,847 : [INFO]  Batch 258: Training set : loss - 0.5922, accuracy - 0.6957, recall - 0.8587, AUC - 0.8233, F1 - 0.7383, precision - 0.6475, training time - -12.0 seconds
2023-03-25 18:37:31,847 : [INFO]  Batch 258: Testing set : loss - 0.5991, accuracy - 0.6422, recall - 0.7647, AUC - 0.7753, F1 - 0.6812, precision - 0.6142
2023-03-25 18:37:31,861 : [INFO]  Batch 259 initialized 
2023-03-25 18:37:32,484 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:33,181 : [INFO]  ------------------------- Batch 259 training: round 1 -------------------------
2023-03-25 18:37:38,722 : [INFO]  ------------------------- Batch round 1, loss: 0.5863 -------------------------
2023-03-25 18:37:38,722 : [INFO]  ------------------------- Batch 259, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:38,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:38,737 : [INFO]  ------------------------- Batch 259 training: round 2 -------------------------
2023-03-25 18:37:41,770 : [INFO]  ------------------------- Batch round 2, loss: 0.5956 -------------------------
2023-03-25 18:37:41,771 : [INFO]  ------------------------- Batch 259, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:41,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:41,807 : [INFO]  ------------------------- Batch 259 training: round 3 -------------------------
2023-03-25 18:37:44,715 : [INFO]  ------------------------- Batch round 3, loss: 0.594 -------------------------
2023-03-25 18:37:44,715 : [INFO]  ------------------------- Batch 259, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:44,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:44,733 : [INFO]  Batch number 259 model fetched from the server
2023-03-25 18:37:44,733 : [INFO]  ################ Batch 259: final global model evalution after 3 rounds ################
2023-03-25 18:37:46,537 : [INFO]  Batch 259: Training set : loss - 0.6079, accuracy - 0.6793, recall - 0.8478, AUC - 0.7844, F1 - 0.7256, precision - 0.6341, training time - -12.0 seconds
2023-03-25 18:37:46,537 : [INFO]  Batch 259: Testing set : loss - 0.5817, accuracy - 0.6863, recall - 0.8137, AUC - 0.8368, F1 - 0.7217, precision - 0.6484
2023-03-25 18:37:46,547 : [INFO]  Batch 260 initialized 
2023-03-25 18:37:47,104 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:47,838 : [INFO]  ------------------------- Batch 260 training: round 1 -------------------------
2023-03-25 18:37:53,118 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-25 18:37:53,118 : [INFO]  ------------------------- Batch 260, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:53,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:53,224 : [INFO]  ------------------------- Batch 260 training: round 2 -------------------------
2023-03-25 18:37:56,239 : [INFO]  ------------------------- Batch round 2, loss: 0.5719 -------------------------
2023-03-25 18:37:56,239 : [INFO]  ------------------------- Batch 260, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:56,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:56,254 : [INFO]  ------------------------- Batch 260 training: round 3 -------------------------
2023-03-25 18:37:59,020 : [INFO]  ------------------------- Batch round 3, loss: 0.5715 -------------------------
2023-03-25 18:37:59,020 : [INFO]  ------------------------- Batch 260, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:59,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:59,125 : [INFO]  Batch number 260 model fetched from the server
2023-03-25 18:37:59,125 : [INFO]  ################ Batch 260: final global model evalution after 3 rounds ################
2023-03-25 18:38:00,884 : [INFO]  Batch 260: Training set : loss - 0.5783, accuracy - 0.7065, recall - 0.8696, AUC - 0.8405, F1 - 0.7477, precision - 0.6557, training time - -11.0 seconds
2023-03-25 18:38:00,884 : [INFO]  Batch 260: Testing set : loss - 0.6054, accuracy - 0.652, recall - 0.8039, AUC - 0.7749, F1 - 0.6979, precision - 0.6165
2023-03-25 18:38:00,903 : [INFO]  Batch 261 initialized 
2023-03-25 18:38:01,471 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:02,184 : [INFO]  ------------------------- Batch 261 training: round 1 -------------------------
2023-03-25 18:38:07,611 : [INFO]  ------------------------- Batch round 1, loss: 0.6149 -------------------------
2023-03-25 18:38:07,611 : [INFO]  ------------------------- Batch 261, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:07,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:07,629 : [INFO]  ------------------------- Batch 261 training: round 2 -------------------------
2023-03-25 18:38:10,474 : [INFO]  ------------------------- Batch round 2, loss: 0.6126 -------------------------
2023-03-25 18:38:10,474 : [INFO]  ------------------------- Batch 261, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:10,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:10,490 : [INFO]  ------------------------- Batch 261 training: round 3 -------------------------
2023-03-25 18:38:13,430 : [INFO]  ------------------------- Batch round 3, loss: 0.6094 -------------------------
2023-03-25 18:38:13,431 : [INFO]  ------------------------- Batch 261, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:13,478 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:13,486 : [INFO]  Batch number 261 model fetched from the server
2023-03-25 18:38:13,486 : [INFO]  ################ Batch 261: final global model evalution after 3 rounds ################
2023-03-25 18:38:15,371 : [INFO]  Batch 261: Training set : loss - 0.6284, accuracy - 0.6467, recall - 0.7391, AUC - 0.7213, F1 - 0.6766, precision - 0.6239, training time - -11.0 seconds
2023-03-25 18:38:15,371 : [INFO]  Batch 261: Testing set : loss - 0.5773, accuracy - 0.6912, recall - 0.8922, AUC - 0.8614, F1 - 0.7429, precision - 0.6364
2023-03-25 18:38:15,382 : [INFO]  Batch 262 initialized 
2023-03-25 18:38:15,963 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:16,657 : [INFO]  ------------------------- Batch 262 training: round 1 -------------------------
2023-03-25 18:38:21,943 : [INFO]  ------------------------- Batch round 1, loss: 0.6172 -------------------------
2023-03-25 18:38:21,943 : [INFO]  ------------------------- Batch 262, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:21,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:21,963 : [INFO]  ------------------------- Batch 262 training: round 2 -------------------------
2023-03-25 18:38:24,730 : [INFO]  ------------------------- Batch round 2, loss: 0.6157 -------------------------
2023-03-25 18:38:24,730 : [INFO]  ------------------------- Batch 262, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:24,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:24,828 : [INFO]  ------------------------- Batch 262 training: round 3 -------------------------
2023-03-25 18:38:27,734 : [INFO]  ------------------------- Batch round 3, loss: 0.6198 -------------------------
2023-03-25 18:38:27,734 : [INFO]  ------------------------- Batch 262, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:27,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:27,776 : [INFO]  Batch number 262 model fetched from the server
2023-03-25 18:38:27,777 : [INFO]  ################ Batch 262: final global model evalution after 3 rounds ################
2023-03-25 18:38:29,565 : [INFO]  Batch 262: Training set : loss - 0.6462, accuracy - 0.5652, recall - 0.8043, AUC - 0.7156, F1 - 0.6491, precision - 0.5441, training time - -11.0 seconds
2023-03-25 18:38:29,565 : [INFO]  Batch 262: Testing set : loss - 0.5962, accuracy - 0.6569, recall - 0.8333, AUC - 0.807, F1 - 0.7083, precision - 0.6159
2023-03-25 18:38:29,579 : [INFO]  Batch 263 initialized 
2023-03-25 18:38:30,159 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:30,900 : [INFO]  ------------------------- Batch 263 training: round 1 -------------------------
2023-03-25 18:38:36,371 : [INFO]  ------------------------- Batch round 1, loss: 0.618 -------------------------
2023-03-25 18:38:36,371 : [INFO]  ------------------------- Batch 263, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:36,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:36,436 : [INFO]  ------------------------- Batch 263 training: round 2 -------------------------
2023-03-25 18:38:39,323 : [INFO]  ------------------------- Batch round 2, loss: 0.6218 -------------------------
2023-03-25 18:38:39,323 : [INFO]  ------------------------- Batch 263, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:39,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:39,422 : [INFO]  ------------------------- Batch 263 training: round 3 -------------------------
2023-03-25 18:38:42,307 : [INFO]  ------------------------- Batch round 3, loss: 0.6205 -------------------------
2023-03-25 18:38:42,307 : [INFO]  ------------------------- Batch 263, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:42,388 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:42,391 : [INFO]  Batch number 263 model fetched from the server
2023-03-25 18:38:42,391 : [INFO]  ################ Batch 263: final global model evalution after 3 rounds ################
2023-03-25 18:38:44,201 : [INFO]  Batch 263: Training set : loss - 0.6464, accuracy - 0.6033, recall - 0.75, AUC - 0.7034, F1 - 0.654, precision - 0.5798, training time - -11.0 seconds
2023-03-25 18:38:44,201 : [INFO]  Batch 263: Testing set : loss - 0.6087, accuracy - 0.6618, recall - 0.7843, AUC - 0.7692, F1 - 0.6987, precision - 0.6299
2023-03-25 18:38:44,209 : [INFO]  Batch 264 initialized 
2023-03-25 18:38:44,784 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:45,493 : [INFO]  ------------------------- Batch 264 training: round 1 -------------------------
2023-03-25 18:38:51,059 : [INFO]  ------------------------- Batch round 1, loss: 0.6031 -------------------------
2023-03-25 18:38:51,059 : [INFO]  ------------------------- Batch 264, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:51,088 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:51,091 : [INFO]  ------------------------- Batch 264 training: round 2 -------------------------
2023-03-25 18:38:54,025 : [INFO]  ------------------------- Batch round 2, loss: 0.6062 -------------------------
2023-03-25 18:38:54,025 : [INFO]  ------------------------- Batch 264, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:54,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:54,046 : [INFO]  ------------------------- Batch 264 training: round 3 -------------------------
2023-03-25 18:38:57,061 : [INFO]  ------------------------- Batch round 3, loss: 0.6013 -------------------------
2023-03-25 18:38:57,061 : [INFO]  ------------------------- Batch 264, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:57,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:57,080 : [INFO]  Batch number 264 model fetched from the server
2023-03-25 18:38:57,080 : [INFO]  ################ Batch 264: final global model evalution after 3 rounds ################
2023-03-25 18:38:58,993 : [INFO]  Batch 264: Training set : loss - 0.6145, accuracy - 0.6413, recall - 0.8043, AUC - 0.7763, F1 - 0.6916, precision - 0.6066, training time - -12.0 seconds
2023-03-25 18:38:58,994 : [INFO]  Batch 264: Testing set : loss - 0.6198, accuracy - 0.6373, recall - 0.7745, AUC - 0.7472, F1 - 0.681, precision - 0.6077
2023-03-25 18:38:59,006 : [INFO]  Batch 265 initialized 
2023-03-25 18:38:59,606 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:00,331 : [INFO]  ------------------------- Batch 265 training: round 1 -------------------------
2023-03-25 18:39:05,821 : [INFO]  ------------------------- Batch round 1, loss: 0.6041 -------------------------
2023-03-25 18:39:05,821 : [INFO]  ------------------------- Batch 265, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:05,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:05,970 : [INFO]  ------------------------- Batch 265 training: round 2 -------------------------
2023-03-25 18:39:08,930 : [INFO]  ------------------------- Batch round 2, loss: 0.6089 -------------------------
2023-03-25 18:39:08,930 : [INFO]  ------------------------- Batch 265, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:08,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:08,946 : [INFO]  ------------------------- Batch 265 training: round 3 -------------------------
2023-03-25 18:39:11,843 : [INFO]  ------------------------- Batch round 3, loss: 0.6087 -------------------------
2023-03-25 18:39:11,843 : [INFO]  ------------------------- Batch 265, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:11,860 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:11,863 : [INFO]  Batch number 265 model fetched from the server
2023-03-25 18:39:11,864 : [INFO]  ################ Batch 265: final global model evalution after 3 rounds ################
2023-03-25 18:39:13,636 : [INFO]  Batch 265: Training set : loss - 0.6197, accuracy - 0.6576, recall - 0.7609, AUC - 0.729, F1 - 0.6897, precision - 0.6306, training time - -12.0 seconds
2023-03-25 18:39:13,637 : [INFO]  Batch 265: Testing set : loss - 0.6112, accuracy - 0.6471, recall - 0.7647, AUC - 0.7688, F1 - 0.6842, precision - 0.619
2023-03-25 18:39:13,650 : [INFO]  Batch 266 initialized 
2023-03-25 18:39:14,222 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:14,958 : [INFO]  ------------------------- Batch 266 training: round 1 -------------------------
2023-03-25 18:39:20,436 : [INFO]  ------------------------- Batch round 1, loss: 0.5957 -------------------------
2023-03-25 18:39:20,436 : [INFO]  ------------------------- Batch 266, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:20,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:20,453 : [INFO]  ------------------------- Batch 266 training: round 2 -------------------------
2023-03-25 18:39:23,407 : [INFO]  ------------------------- Batch round 2, loss: 0.5925 -------------------------
2023-03-25 18:39:23,408 : [INFO]  ------------------------- Batch 266, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:23,420 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:23,422 : [INFO]  ------------------------- Batch 266 training: round 3 -------------------------
2023-03-25 18:39:26,352 : [INFO]  ------------------------- Batch round 3, loss: 0.5901 -------------------------
2023-03-25 18:39:26,352 : [INFO]  ------------------------- Batch 266, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:26,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:26,371 : [INFO]  Batch number 266 model fetched from the server
2023-03-25 18:39:26,371 : [INFO]  ################ Batch 266: final global model evalution after 3 rounds ################
2023-03-25 18:39:28,223 : [INFO]  Batch 266: Training set : loss - 0.6056, accuracy - 0.6793, recall - 0.7826, AUC - 0.7758, F1 - 0.7094, precision - 0.6486, training time - -11.0 seconds
2023-03-25 18:39:28,223 : [INFO]  Batch 266: Testing set : loss - 0.6113, accuracy - 0.6667, recall - 0.7843, AUC - 0.7611, F1 - 0.7018, precision - 0.6349
2023-03-25 18:39:28,236 : [INFO]  Batch 267 initialized 
2023-03-25 18:39:28,839 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:29,571 : [INFO]  ------------------------- Batch 267 training: round 1 -------------------------
2023-03-25 18:39:34,991 : [INFO]  ------------------------- Batch round 1, loss: 0.5756 -------------------------
2023-03-25 18:39:34,991 : [INFO]  ------------------------- Batch 267, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:35,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:35,007 : [INFO]  ------------------------- Batch 267 training: round 2 -------------------------
2023-03-25 18:39:38,020 : [INFO]  ------------------------- Batch round 2, loss: 0.5709 -------------------------
2023-03-25 18:39:38,020 : [INFO]  ------------------------- Batch 267, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:38,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:38,039 : [INFO]  ------------------------- Batch 267 training: round 3 -------------------------
2023-03-25 18:39:40,976 : [INFO]  ------------------------- Batch round 3, loss: 0.5732 -------------------------
2023-03-25 18:39:40,976 : [INFO]  ------------------------- Batch 267, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:40,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:40,992 : [INFO]  Batch number 267 model fetched from the server
2023-03-25 18:39:40,992 : [INFO]  ################ Batch 267: final global model evalution after 3 rounds ################
2023-03-25 18:39:42,830 : [INFO]  Batch 267: Training set : loss - 0.5863, accuracy - 0.712, recall - 0.8696, AUC - 0.8246, F1 - 0.7512, precision - 0.6612, training time - -11.0 seconds
2023-03-25 18:39:42,830 : [INFO]  Batch 267: Testing set : loss - 0.5868, accuracy - 0.701, recall - 0.8431, AUC - 0.8163, F1 - 0.7382, precision - 0.6565
2023-03-25 18:39:42,841 : [INFO]  Batch 268 initialized 
2023-03-25 18:39:43,416 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:44,145 : [INFO]  ------------------------- Batch 268 training: round 1 -------------------------
2023-03-25 18:39:49,736 : [INFO]  ------------------------- Batch round 1, loss: 0.6273 -------------------------
2023-03-25 18:39:49,736 : [INFO]  ------------------------- Batch 268, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:49,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:49,753 : [INFO]  ------------------------- Batch 268 training: round 2 -------------------------
2023-03-25 18:39:52,735 : [INFO]  ------------------------- Batch round 2, loss: 0.6282 -------------------------
2023-03-25 18:39:52,735 : [INFO]  ------------------------- Batch 268, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:52,748 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:52,751 : [INFO]  ------------------------- Batch 268 training: round 3 -------------------------
2023-03-25 18:39:55,732 : [INFO]  ------------------------- Batch round 3, loss: 0.6294 -------------------------
2023-03-25 18:39:55,733 : [INFO]  ------------------------- Batch 268, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:55,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:55,749 : [INFO]  Batch number 268 model fetched from the server
2023-03-25 18:39:55,749 : [INFO]  ################ Batch 268: final global model evalution after 3 rounds ################
2023-03-25 18:39:57,563 : [INFO]  Batch 268: Training set : loss - 0.6361, accuracy - 0.6304, recall - 0.7717, AUC - 0.7069, F1 - 0.6762, precision - 0.6017, training time - -12.0 seconds
2023-03-25 18:39:57,564 : [INFO]  Batch 268: Testing set : loss - 0.612, accuracy - 0.6618, recall - 0.8333, AUC - 0.7864, F1 - 0.7113, precision - 0.6204
2023-03-25 18:39:57,572 : [INFO]  Batch 269 initialized 
2023-03-25 18:39:58,149 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:58,882 : [INFO]  ------------------------- Batch 269 training: round 1 -------------------------
2023-03-25 18:40:04,253 : [INFO]  ------------------------- Batch round 1, loss: 0.6048 -------------------------
2023-03-25 18:40:04,253 : [INFO]  ------------------------- Batch 269, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:04,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:04,271 : [INFO]  ------------------------- Batch 269 training: round 2 -------------------------
2023-03-25 18:40:07,238 : [INFO]  ------------------------- Batch round 2, loss: 0.6106 -------------------------
2023-03-25 18:40:07,239 : [INFO]  ------------------------- Batch 269, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:07,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:07,256 : [INFO]  ------------------------- Batch 269 training: round 3 -------------------------
2023-03-25 18:40:10,191 : [INFO]  ------------------------- Batch round 3, loss: 0.6041 -------------------------
2023-03-25 18:40:10,191 : [INFO]  ------------------------- Batch 269, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:10,206 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:10,208 : [INFO]  Batch number 269 model fetched from the server
2023-03-25 18:40:10,209 : [INFO]  ################ Batch 269: final global model evalution after 3 rounds ################
2023-03-25 18:40:12,090 : [INFO]  Batch 269: Training set : loss - 0.6086, accuracy - 0.6793, recall - 0.8152, AUC - 0.775, F1 - 0.7177, precision - 0.641, training time - -11.0 seconds
2023-03-25 18:40:12,090 : [INFO]  Batch 269: Testing set : loss - 0.6223, accuracy - 0.6422, recall - 0.8529, AUC - 0.7648, F1 - 0.7045, precision - 0.6
2023-03-25 18:40:12,100 : [INFO]  Batch 270 initialized 
2023-03-25 18:40:12,672 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:13,404 : [INFO]  ------------------------- Batch 270 training: round 1 -------------------------
2023-03-25 18:40:18,971 : [INFO]  ------------------------- Batch round 1, loss: 0.5962 -------------------------
2023-03-25 18:40:18,971 : [INFO]  ------------------------- Batch 270, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:18,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:18,989 : [INFO]  ------------------------- Batch 270 training: round 2 -------------------------
2023-03-25 18:40:21,924 : [INFO]  ------------------------- Batch round 2, loss: 0.5936 -------------------------
2023-03-25 18:40:21,924 : [INFO]  ------------------------- Batch 270, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:21,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:21,942 : [INFO]  ------------------------- Batch 270 training: round 3 -------------------------
2023-03-25 18:40:24,879 : [INFO]  ------------------------- Batch round 3, loss: 0.5956 -------------------------
2023-03-25 18:40:24,879 : [INFO]  ------------------------- Batch 270, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:24,894 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:24,897 : [INFO]  Batch number 270 model fetched from the server
2023-03-25 18:40:24,897 : [INFO]  ################ Batch 270: final global model evalution after 3 rounds ################
2023-03-25 18:40:26,785 : [INFO]  Batch 270: Training set : loss - 0.6166, accuracy - 0.6359, recall - 0.8043, AUC - 0.7535, F1 - 0.6884, precision - 0.6016, training time - -11.0 seconds
2023-03-25 18:40:26,785 : [INFO]  Batch 270: Testing set : loss - 0.6087, accuracy - 0.6569, recall - 0.8039, AUC - 0.7712, F1 - 0.7009, precision - 0.6212
2023-03-25 18:40:26,796 : [INFO]  Batch 271 initialized 
2023-03-25 18:40:27,359 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:28,099 : [INFO]  ------------------------- Batch 271 training: round 1 -------------------------
2023-03-25 18:40:33,687 : [INFO]  ------------------------- Batch round 1, loss: 0.6045 -------------------------
2023-03-25 18:40:33,687 : [INFO]  ------------------------- Batch 271, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:33,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:33,738 : [INFO]  ------------------------- Batch 271 training: round 2 -------------------------
2023-03-25 18:40:36,656 : [INFO]  ------------------------- Batch round 2, loss: 0.6124 -------------------------
2023-03-25 18:40:36,656 : [INFO]  ------------------------- Batch 271, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:36,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:36,696 : [INFO]  ------------------------- Batch 271 training: round 3 -------------------------
2023-03-25 18:40:39,777 : [INFO]  ------------------------- Batch round 3, loss: 0.6106 -------------------------
2023-03-25 18:40:39,777 : [INFO]  ------------------------- Batch 271, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:39,792 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:39,795 : [INFO]  Batch number 271 model fetched from the server
2023-03-25 18:40:39,796 : [INFO]  ################ Batch 271: final global model evalution after 3 rounds ################
2023-03-25 18:40:41,673 : [INFO]  Batch 271: Training set : loss - 0.6234, accuracy - 0.6413, recall - 0.8043, AUC - 0.7388, F1 - 0.6916, precision - 0.6066, training time - -12.0 seconds
2023-03-25 18:40:41,673 : [INFO]  Batch 271: Testing set : loss - 0.6318, accuracy - 0.6373, recall - 0.8529, AUC - 0.7358, F1 - 0.7016, precision - 0.5959
2023-03-25 18:40:41,688 : [INFO]  Batch 272 initialized 
2023-03-25 18:40:42,297 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:43,043 : [INFO]  ------------------------- Batch 272 training: round 1 -------------------------
2023-03-25 18:40:48,711 : [INFO]  ------------------------- Batch round 1, loss: 0.6023 -------------------------
2023-03-25 18:40:48,711 : [INFO]  ------------------------- Batch 272, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:48,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:48,727 : [INFO]  ------------------------- Batch 272 training: round 2 -------------------------
2023-03-25 18:40:51,721 : [INFO]  ------------------------- Batch round 2, loss: 0.6026 -------------------------
2023-03-25 18:40:51,721 : [INFO]  ------------------------- Batch 272, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:51,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:51,738 : [INFO]  ------------------------- Batch 272 training: round 3 -------------------------
2023-03-25 18:40:54,783 : [INFO]  ------------------------- Batch round 3, loss: 0.614 -------------------------
2023-03-25 18:40:54,783 : [INFO]  ------------------------- Batch 272, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:54,800 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:54,804 : [INFO]  Batch number 272 model fetched from the server
2023-03-25 18:40:54,804 : [INFO]  ################ Batch 272: final global model evalution after 3 rounds ################
2023-03-25 18:40:56,617 : [INFO]  Batch 272: Training set : loss - 0.6155, accuracy - 0.6957, recall - 0.8043, AUC - 0.7595, F1 - 0.7255, precision - 0.6607, training time - -12.0 seconds
2023-03-25 18:40:56,617 : [INFO]  Batch 272: Testing set : loss - 0.6252, accuracy - 0.6324, recall - 0.8235, AUC - 0.7615, F1 - 0.6914, precision - 0.5957
2023-03-25 18:40:56,628 : [INFO]  Batch 273 initialized 
2023-03-25 18:40:57,188 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:57,920 : [INFO]  ------------------------- Batch 273 training: round 1 -------------------------
2023-03-25 18:41:03,299 : [INFO]  ------------------------- Batch round 1, loss: 0.5807 -------------------------
2023-03-25 18:41:03,299 : [INFO]  ------------------------- Batch 273, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:03,453 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:03,455 : [INFO]  ------------------------- Batch 273 training: round 2 -------------------------
2023-03-25 18:41:06,267 : [INFO]  ------------------------- Batch round 2, loss: 0.5759 -------------------------
2023-03-25 18:41:06,267 : [INFO]  ------------------------- Batch 273, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:06,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:06,291 : [INFO]  ------------------------- Batch 273 training: round 3 -------------------------
2023-03-25 18:41:09,196 : [INFO]  ------------------------- Batch round 3, loss: 0.574 -------------------------
2023-03-25 18:41:09,196 : [INFO]  ------------------------- Batch 273, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:09,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:09,220 : [INFO]  Batch number 273 model fetched from the server
2023-03-25 18:41:09,220 : [INFO]  ################ Batch 273: final global model evalution after 3 rounds ################
2023-03-25 18:41:11,008 : [INFO]  Batch 273: Training set : loss - 0.5836, accuracy - 0.6902, recall - 0.8696, AUC - 0.8408, F1 - 0.7373, precision - 0.64, training time - -11.0 seconds
2023-03-25 18:41:11,008 : [INFO]  Batch 273: Testing set : loss - 0.6086, accuracy - 0.652, recall - 0.7451, AUC - 0.7618, F1 - 0.6816, precision - 0.6281
2023-03-25 18:41:11,016 : [INFO]  Batch 274 initialized 
2023-03-25 18:41:11,592 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:12,330 : [INFO]  ------------------------- Batch 274 training: round 1 -------------------------
2023-03-25 18:41:17,821 : [INFO]  ------------------------- Batch round 1, loss: 0.6545 -------------------------
2023-03-25 18:41:17,822 : [INFO]  ------------------------- Batch 274, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:17,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:17,842 : [INFO]  ------------------------- Batch 274 training: round 2 -------------------------
2023-03-25 18:41:20,713 : [INFO]  ------------------------- Batch round 2, loss: 0.6527 -------------------------
2023-03-25 18:41:20,713 : [INFO]  ------------------------- Batch 274, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:20,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:20,732 : [INFO]  ------------------------- Batch 274 training: round 3 -------------------------
2023-03-25 18:41:23,640 : [INFO]  ------------------------- Batch round 3, loss: 0.6554 -------------------------
2023-03-25 18:41:23,640 : [INFO]  ------------------------- Batch 274, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:23,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:23,661 : [INFO]  Batch number 274 model fetched from the server
2023-03-25 18:41:23,661 : [INFO]  ################ Batch 274: final global model evalution after 3 rounds ################
2023-03-25 18:41:25,468 : [INFO]  Batch 274: Training set : loss - 0.6696, accuracy - 0.538, recall - 0.75, AUC - 0.6572, F1 - 0.6188, precision - 0.5267, training time - -11.0 seconds
2023-03-25 18:41:25,468 : [INFO]  Batch 274: Testing set : loss - 0.6464, accuracy - 0.6127, recall - 0.7843, AUC - 0.6973, F1 - 0.6695, precision - 0.5839
2023-03-25 18:41:25,477 : [INFO]  Batch 275 initialized 
2023-03-25 18:41:26,034 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:26,785 : [INFO]  ------------------------- Batch 275 training: round 1 -------------------------
2023-03-25 18:41:32,186 : [INFO]  ------------------------- Batch round 1, loss: 0.59 -------------------------
2023-03-25 18:41:32,186 : [INFO]  ------------------------- Batch 275, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:32,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:32,271 : [INFO]  ------------------------- Batch 275 training: round 2 -------------------------
2023-03-25 18:41:35,117 : [INFO]  ------------------------- Batch round 2, loss: 0.5892 -------------------------
2023-03-25 18:41:35,117 : [INFO]  ------------------------- Batch 275, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:35,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:35,142 : [INFO]  ------------------------- Batch 275 training: round 3 -------------------------
2023-03-25 18:41:38,051 : [INFO]  ------------------------- Batch round 3, loss: 0.5886 -------------------------
2023-03-25 18:41:38,052 : [INFO]  ------------------------- Batch 275, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:38,186 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:38,189 : [INFO]  Batch number 275 model fetched from the server
2023-03-25 18:41:38,189 : [INFO]  ################ Batch 275: final global model evalution after 3 rounds ################
2023-03-25 18:41:39,960 : [INFO]  Batch 275: Training set : loss - 0.6033, accuracy - 0.6739, recall - 0.7717, AUC - 0.7732, F1 - 0.703, precision - 0.6455, training time - -11.0 seconds
2023-03-25 18:41:39,961 : [INFO]  Batch 275: Testing set : loss - 0.6353, accuracy - 0.6127, recall - 0.7549, AUC - 0.7207, F1 - 0.6609, precision - 0.5878
2023-03-25 18:41:39,973 : [INFO]  Batch 276 initialized 
2023-03-25 18:41:40,538 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:41,263 : [INFO]  ------------------------- Batch 276 training: round 1 -------------------------
2023-03-25 18:41:46,667 : [INFO]  ------------------------- Batch round 1, loss: 0.6115 -------------------------
2023-03-25 18:41:46,668 : [INFO]  ------------------------- Batch 276, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:46,681 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:46,683 : [INFO]  ------------------------- Batch 276 training: round 2 -------------------------
2023-03-25 18:41:49,535 : [INFO]  ------------------------- Batch round 2, loss: 0.6152 -------------------------
2023-03-25 18:41:49,535 : [INFO]  ------------------------- Batch 276, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:49,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:49,557 : [INFO]  ------------------------- Batch 276 training: round 3 -------------------------
2023-03-25 18:41:52,400 : [INFO]  ------------------------- Batch round 3, loss: 0.6079 -------------------------
2023-03-25 18:41:52,400 : [INFO]  ------------------------- Batch 276, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:52,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:52,418 : [INFO]  Batch number 276 model fetched from the server
2023-03-25 18:41:52,418 : [INFO]  ################ Batch 276: final global model evalution after 3 rounds ################
2023-03-25 18:41:54,138 : [INFO]  Batch 276: Training set : loss - 0.6387, accuracy - 0.5924, recall - 0.7391, AUC - 0.7091, F1 - 0.6445, precision - 0.5714, training time - -11.0 seconds
2023-03-25 18:41:54,138 : [INFO]  Batch 276: Testing set : loss - 0.6398, accuracy - 0.5833, recall - 0.7059, AUC - 0.7052, F1 - 0.6288, precision - 0.5669
2023-03-25 18:41:54,153 : [INFO]  Batch 277 initialized 
2023-03-25 18:41:54,723 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:55,461 : [INFO]  ------------------------- Batch 277 training: round 1 -------------------------
2023-03-25 18:42:00,990 : [INFO]  ------------------------- Batch round 1, loss: 0.6045 -------------------------
2023-03-25 18:42:00,990 : [INFO]  ------------------------- Batch 277, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:01,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:01,085 : [INFO]  ------------------------- Batch 277 training: round 2 -------------------------
2023-03-25 18:42:03,920 : [INFO]  ------------------------- Batch round 2, loss: 0.6102 -------------------------
2023-03-25 18:42:03,921 : [INFO]  ------------------------- Batch 277, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:03,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:03,998 : [INFO]  ------------------------- Batch 277 training: round 3 -------------------------
2023-03-25 18:42:06,891 : [INFO]  ------------------------- Batch round 3, loss: 0.6072 -------------------------
2023-03-25 18:42:06,891 : [INFO]  ------------------------- Batch 277, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:06,974 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:06,977 : [INFO]  Batch number 277 model fetched from the server
2023-03-25 18:42:06,977 : [INFO]  ################ Batch 277: final global model evalution after 3 rounds ################
2023-03-25 18:42:08,741 : [INFO]  Batch 277: Training set : loss - 0.6255, accuracy - 0.6522, recall - 0.8043, AUC - 0.7413, F1 - 0.6981, precision - 0.6167, training time - -12.0 seconds
2023-03-25 18:42:08,741 : [INFO]  Batch 277: Testing set : loss - 0.6261, accuracy - 0.6225, recall - 0.7451, AUC - 0.7362, F1 - 0.6638, precision - 0.5984
2023-03-25 18:42:08,756 : [INFO]  Batch 278 initialized 
2023-03-25 18:42:09,339 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:10,081 : [INFO]  ------------------------- Batch 278 training: round 1 -------------------------
2023-03-25 18:42:15,552 : [INFO]  ------------------------- Batch round 1, loss: 0.5942 -------------------------
2023-03-25 18:42:15,552 : [INFO]  ------------------------- Batch 278, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:15,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:15,605 : [INFO]  ------------------------- Batch 278 training: round 2 -------------------------
2023-03-25 18:42:18,518 : [INFO]  ------------------------- Batch round 2, loss: 0.6067 -------------------------
2023-03-25 18:42:18,518 : [INFO]  ------------------------- Batch 278, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:18,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:18,556 : [INFO]  ------------------------- Batch 278 training: round 3 -------------------------
2023-03-25 18:42:21,617 : [INFO]  ------------------------- Batch round 3, loss: 0.6047 -------------------------
2023-03-25 18:42:21,617 : [INFO]  ------------------------- Batch 278, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:21,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:21,640 : [INFO]  Batch number 278 model fetched from the server
2023-03-25 18:42:21,640 : [INFO]  ################ Batch 278: final global model evalution after 3 rounds ################
2023-03-25 18:42:23,491 : [INFO]  Batch 278: Training set : loss - 0.6315, accuracy - 0.6359, recall - 0.7826, AUC - 0.7289, F1 - 0.6825, precision - 0.605, training time - -12.0 seconds
2023-03-25 18:42:23,491 : [INFO]  Batch 278: Testing set : loss - 0.6339, accuracy - 0.6471, recall - 0.7451, AUC - 0.7093, F1 - 0.6786, precision - 0.623
2023-03-25 18:42:23,535 : [INFO]  Batch 279 initialized 
2023-03-25 18:42:24,119 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:24,884 : [INFO]  ------------------------- Batch 279 training: round 1 -------------------------
2023-03-25 18:42:30,424 : [INFO]  ------------------------- Batch round 1, loss: 0.5903 -------------------------
2023-03-25 18:42:30,424 : [INFO]  ------------------------- Batch 279, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:30,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:30,443 : [INFO]  ------------------------- Batch 279 training: round 2 -------------------------
2023-03-25 18:42:33,332 : [INFO]  ------------------------- Batch round 2, loss: 0.6007 -------------------------
2023-03-25 18:42:33,332 : [INFO]  ------------------------- Batch 279, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:33,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:33,348 : [INFO]  ------------------------- Batch 279 training: round 3 -------------------------
2023-03-25 18:42:36,206 : [INFO]  ------------------------- Batch round 3, loss: 0.597 -------------------------
2023-03-25 18:42:36,206 : [INFO]  ------------------------- Batch 279, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:36,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:36,222 : [INFO]  Batch number 279 model fetched from the server
2023-03-25 18:42:36,222 : [INFO]  ################ Batch 279: final global model evalution after 3 rounds ################
2023-03-25 18:42:38,017 : [INFO]  Batch 279: Training set : loss - 0.6141, accuracy - 0.6739, recall - 0.8587, AUC - 0.7824, F1 - 0.7248, precision - 0.627, training time - -11.0 seconds
2023-03-25 18:42:38,017 : [INFO]  Batch 279: Testing set : loss - 0.6444, accuracy - 0.5931, recall - 0.7353, AUC - 0.7058, F1 - 0.6438, precision - 0.5725
2023-03-25 18:42:38,025 : [INFO]  Batch 280 initialized 
2023-03-25 18:42:38,587 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:39,335 : [INFO]  ------------------------- Batch 280 training: round 1 -------------------------
2023-03-25 18:42:44,729 : [INFO]  ------------------------- Batch round 1, loss: 0.6143 -------------------------
2023-03-25 18:42:44,729 : [INFO]  ------------------------- Batch 280, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:44,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:44,819 : [INFO]  ------------------------- Batch 280 training: round 2 -------------------------
2023-03-25 18:42:47,625 : [INFO]  ------------------------- Batch round 2, loss: 0.6172 -------------------------
2023-03-25 18:42:47,625 : [INFO]  ------------------------- Batch 280, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:47,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:47,753 : [INFO]  ------------------------- Batch 280 training: round 3 -------------------------
2023-03-25 18:42:50,636 : [INFO]  ------------------------- Batch round 3, loss: 0.6148 -------------------------
2023-03-25 18:42:50,636 : [INFO]  ------------------------- Batch 280, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:50,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:50,735 : [INFO]  Batch number 280 model fetched from the server
2023-03-25 18:42:50,735 : [INFO]  ################ Batch 280: final global model evalution after 3 rounds ################
2023-03-25 18:42:52,488 : [INFO]  Batch 280: Training set : loss - 0.635, accuracy - 0.625, recall - 0.7826, AUC - 0.7221, F1 - 0.6761, precision - 0.595, training time - -11.0 seconds
2023-03-25 18:42:52,488 : [INFO]  Batch 280: Testing set : loss - 0.6555, accuracy - 0.549, recall - 0.6863, AUC - 0.6714, F1 - 0.6034, precision - 0.5385
2023-03-25 18:42:52,502 : [INFO]  Batch 281 initialized 
2023-03-25 18:42:53,101 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:53,860 : [INFO]  ------------------------- Batch 281 training: round 1 -------------------------
2023-03-25 18:42:59,400 : [INFO]  ------------------------- Batch round 1, loss: 0.6254 -------------------------
2023-03-25 18:42:59,401 : [INFO]  ------------------------- Batch 281, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:59,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:59,524 : [INFO]  ------------------------- Batch 281 training: round 2 -------------------------
2023-03-25 18:43:02,462 : [INFO]  ------------------------- Batch round 2, loss: 0.6339 -------------------------
2023-03-25 18:43:02,462 : [INFO]  ------------------------- Batch 281, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:02,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:02,479 : [INFO]  ------------------------- Batch 281 training: round 3 -------------------------
2023-03-25 18:43:05,328 : [INFO]  ------------------------- Batch round 3, loss: 0.6318 -------------------------
2023-03-25 18:43:05,329 : [INFO]  ------------------------- Batch 281, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:05,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:05,386 : [INFO]  Batch number 281 model fetched from the server
2023-03-25 18:43:05,386 : [INFO]  ################ Batch 281: final global model evalution after 3 rounds ################
2023-03-25 18:43:07,155 : [INFO]  Batch 281: Training set : loss - 0.6633, accuracy - 0.5489, recall - 0.7283, AUC - 0.6668, F1 - 0.6175, precision - 0.536, training time - -12.0 seconds
2023-03-25 18:43:07,156 : [INFO]  Batch 281: Testing set : loss - 0.6716, accuracy - 0.5245, recall - 0.7647, AUC - 0.6731, F1 - 0.6166, precision - 0.5166
2023-03-25 18:43:07,171 : [INFO]  Batch 282 initialized 
2023-03-25 18:43:07,735 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:08,480 : [INFO]  ------------------------- Batch 282 training: round 1 -------------------------
2023-03-25 18:43:13,905 : [INFO]  ------------------------- Batch round 1, loss: 0.6683 -------------------------
2023-03-25 18:43:13,905 : [INFO]  ------------------------- Batch 282, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:13,918 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:13,922 : [INFO]  ------------------------- Batch 282 training: round 2 -------------------------
2023-03-25 18:43:16,710 : [INFO]  ------------------------- Batch round 2, loss: 0.6564 -------------------------
2023-03-25 18:43:16,710 : [INFO]  ------------------------- Batch 282, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:16,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:16,798 : [INFO]  ------------------------- Batch 282 training: round 3 -------------------------
2023-03-25 18:43:19,454 : [INFO]  ------------------------- Batch round 3, loss: 0.6615 -------------------------
2023-03-25 18:43:19,454 : [INFO]  ------------------------- Batch 282, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:19,604 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:19,607 : [INFO]  Batch number 282 model fetched from the server
2023-03-25 18:43:19,607 : [INFO]  ################ Batch 282: final global model evalution after 3 rounds ################
2023-03-25 18:43:21,301 : [INFO]  Batch 282: Training set : loss - 0.6863, accuracy - 0.538, recall - 0.6522, AUC - 0.6089, F1 - 0.5854, precision - 0.531, training time - -11.0 seconds
2023-03-25 18:43:21,301 : [INFO]  Batch 282: Testing set : loss - 0.6653, accuracy - 0.5392, recall - 0.7059, AUC - 0.6572, F1 - 0.605, precision - 0.5294
2023-03-25 18:43:21,315 : [INFO]  Batch 283 initialized 
2023-03-25 18:43:21,884 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:22,642 : [INFO]  ------------------------- Batch 283 training: round 1 -------------------------
2023-03-25 18:43:27,931 : [INFO]  ------------------------- Batch round 1, loss: 0.6371 -------------------------
2023-03-25 18:43:27,931 : [INFO]  ------------------------- Batch 283, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:28,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:28,113 : [INFO]  ------------------------- Batch 283 training: round 2 -------------------------
2023-03-25 18:43:30,951 : [INFO]  ------------------------- Batch round 2, loss: 0.6436 -------------------------
2023-03-25 18:43:30,951 : [INFO]  ------------------------- Batch 283, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:31,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:31,147 : [INFO]  ------------------------- Batch 283 training: round 3 -------------------------
2023-03-25 18:43:34,041 : [INFO]  ------------------------- Batch round 3, loss: 0.6356 -------------------------
2023-03-25 18:43:34,041 : [INFO]  ------------------------- Batch 283, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:34,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:34,103 : [INFO]  Batch number 283 model fetched from the server
2023-03-25 18:43:34,103 : [INFO]  ################ Batch 283: final global model evalution after 3 rounds ################
2023-03-25 18:43:35,889 : [INFO]  Batch 283: Training set : loss - 0.671, accuracy - 0.5598, recall - 0.75, AUC - 0.6609, F1 - 0.6301, precision - 0.5433, training time - -11.0 seconds
2023-03-25 18:43:35,889 : [INFO]  Batch 283: Testing set : loss - 0.6778, accuracy - 0.5049, recall - 0.7157, AUC - 0.6406, F1 - 0.5911, precision - 0.5034
2023-03-25 18:43:35,906 : [INFO]  Batch 284 initialized 
2023-03-25 18:43:36,512 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:37,267 : [INFO]  ------------------------- Batch 284 training: round 1 -------------------------
2023-03-25 18:43:42,661 : [INFO]  ------------------------- Batch round 1, loss: 0.6299 -------------------------
2023-03-25 18:43:42,661 : [INFO]  ------------------------- Batch 284, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:42,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:42,722 : [INFO]  ------------------------- Batch 284 training: round 2 -------------------------
2023-03-25 18:43:45,613 : [INFO]  ------------------------- Batch round 2, loss: 0.6397 -------------------------
2023-03-25 18:43:45,613 : [INFO]  ------------------------- Batch 284, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:45,632 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:45,635 : [INFO]  ------------------------- Batch 284 training: round 3 -------------------------
2023-03-25 18:43:48,403 : [INFO]  ------------------------- Batch round 3, loss: 0.629 -------------------------
2023-03-25 18:43:48,403 : [INFO]  ------------------------- Batch 284, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:48,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:48,422 : [INFO]  Batch number 284 model fetched from the server
2023-03-25 18:43:48,422 : [INFO]  ################ Batch 284: final global model evalution after 3 rounds ################
2023-03-25 18:43:50,174 : [INFO]  Batch 284: Training set : loss - 0.6702, accuracy - 0.5489, recall - 0.7174, AUC - 0.6604, F1 - 0.614, precision - 0.5366, training time - -11.0 seconds
2023-03-25 18:43:50,175 : [INFO]  Batch 284: Testing set : loss - 0.7005, accuracy - 0.5245, recall - 0.6667, AUC - 0.5829, F1 - 0.5837, precision - 0.5191
2023-03-25 18:43:50,188 : [INFO]  Batch 285 initialized 
2023-03-25 18:43:50,779 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:51,557 : [INFO]  ------------------------- Batch 285 training: round 1 -------------------------
2023-03-25 18:43:56,865 : [INFO]  ------------------------- Batch round 1, loss: 0.6548 -------------------------
2023-03-25 18:43:56,865 : [INFO]  ------------------------- Batch 285, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:57,045 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:57,048 : [INFO]  ------------------------- Batch 285 training: round 2 -------------------------
2023-03-25 18:43:59,674 : [INFO]  ------------------------- Batch round 2, loss: 0.6524 -------------------------
2023-03-25 18:43:59,674 : [INFO]  ------------------------- Batch 285, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:59,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:59,999 : [INFO]  ------------------------- Batch 285 training: round 3 -------------------------
2023-03-25 18:44:02,672 : [INFO]  ------------------------- Batch round 3, loss: 0.6495 -------------------------
2023-03-25 18:44:02,673 : [INFO]  ------------------------- Batch 285, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:02,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:02,953 : [INFO]  Batch number 285 model fetched from the server
2023-03-25 18:44:02,953 : [INFO]  ################ Batch 285: final global model evalution after 3 rounds ################
2023-03-25 18:44:04,702 : [INFO]  Batch 285: Training set : loss - 0.6847, accuracy - 0.5272, recall - 0.6957, AUC - 0.6261, F1 - 0.5953, precision - 0.5203, training time - -11.0 seconds
2023-03-25 18:44:04,703 : [INFO]  Batch 285: Testing set : loss - 0.7258, accuracy - 0.4559, recall - 0.6569, AUC - 0.5144, F1 - 0.5469, precision - 0.4685
2023-03-25 18:44:04,718 : [INFO]  Batch 286 initialized 
2023-03-25 18:44:05,324 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:06,087 : [INFO]  ------------------------- Batch 286 training: round 1 -------------------------
2023-03-25 18:44:11,079 : [INFO]  ------------------------- Batch round 1, loss: 0.5919 -------------------------
2023-03-25 18:44:11,080 : [INFO]  ------------------------- Batch 286, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:11,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:11,432 : [INFO]  ------------------------- Batch 286 training: round 2 -------------------------
2023-03-25 18:44:14,086 : [INFO]  ------------------------- Batch round 2, loss: 0.5996 -------------------------
2023-03-25 18:44:14,087 : [INFO]  ------------------------- Batch 286, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:14,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:14,168 : [INFO]  ------------------------- Batch 286 training: round 3 -------------------------
2023-03-25 18:44:16,603 : [INFO]  ------------------------- Batch round 3, loss: 0.5961 -------------------------
2023-03-25 18:44:16,603 : [INFO]  ------------------------- Batch 286, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:16,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:16,965 : [INFO]  Batch number 286 model fetched from the server
2023-03-25 18:44:16,965 : [INFO]  ################ Batch 286: final global model evalution after 3 rounds ################
2023-03-25 18:44:18,673 : [INFO]  Batch 286: Training set : loss - 0.6249, accuracy - 0.6196, recall - 0.8043, AUC - 0.77, F1 - 0.6789, precision - 0.5873, training time - -11.0 seconds
2023-03-25 18:44:18,673 : [INFO]  Batch 286: Testing set : loss - 0.683, accuracy - 0.5539, recall - 0.6961, AUC - 0.6328, F1 - 0.6094, precision - 0.542
2023-03-25 18:44:18,689 : [INFO]  Batch 287 initialized 
2023-03-25 18:44:19,277 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:20,021 : [INFO]  ------------------------- Batch 287 training: round 1 -------------------------
2023-03-25 18:44:25,758 : [INFO]  ------------------------- Batch round 1, loss: 0.6333 -------------------------
2023-03-25 18:44:25,759 : [INFO]  ------------------------- Batch 287, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:25,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:25,775 : [INFO]  ------------------------- Batch 287 training: round 2 -------------------------
2023-03-25 18:44:28,662 : [INFO]  ------------------------- Batch round 2, loss: 0.6354 -------------------------
2023-03-25 18:44:28,662 : [INFO]  ------------------------- Batch 287, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:28,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:28,679 : [INFO]  ------------------------- Batch 287 training: round 3 -------------------------
2023-03-25 18:44:31,598 : [INFO]  ------------------------- Batch round 3, loss: 0.6273 -------------------------
2023-03-25 18:44:31,598 : [INFO]  ------------------------- Batch 287, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:31,613 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:31,617 : [INFO]  Batch number 287 model fetched from the server
2023-03-25 18:44:31,617 : [INFO]  ################ Batch 287: final global model evalution after 3 rounds ################
2023-03-25 18:44:33,379 : [INFO]  Batch 287: Training set : loss - 0.638, accuracy - 0.6033, recall - 0.7065, AUC - 0.7044, F1 - 0.6404, precision - 0.5856, training time - -12.0 seconds
2023-03-25 18:44:33,379 : [INFO]  Batch 287: Testing set : loss - 0.6185, accuracy - 0.6814, recall - 0.7647, AUC - 0.7476, F1 - 0.7059, precision - 0.6555
2023-03-25 18:44:33,394 : [INFO]  Batch 288 initialized 
2023-03-25 18:44:33,980 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:34,763 : [INFO]  ------------------------- Batch 288 training: round 1 -------------------------
2023-03-25 18:44:40,080 : [INFO]  ------------------------- Batch round 1, loss: 0.6359 -------------------------
2023-03-25 18:44:40,080 : [INFO]  ------------------------- Batch 288, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:40,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:40,148 : [INFO]  ------------------------- Batch 288 training: round 2 -------------------------
2023-03-25 18:44:42,940 : [INFO]  ------------------------- Batch round 2, loss: 0.6434 -------------------------
2023-03-25 18:44:42,940 : [INFO]  ------------------------- Batch 288, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:42,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:42,960 : [INFO]  ------------------------- Batch 288 training: round 3 -------------------------
2023-03-25 18:44:45,756 : [INFO]  ------------------------- Batch round 3, loss: 0.6384 -------------------------
2023-03-25 18:44:45,756 : [INFO]  ------------------------- Batch 288, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:45,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:45,779 : [INFO]  Batch number 288 model fetched from the server
2023-03-25 18:44:45,779 : [INFO]  ################ Batch 288: final global model evalution after 3 rounds ################
2023-03-25 18:44:47,530 : [INFO]  Batch 288: Training set : loss - 0.6543, accuracy - 0.587, recall - 0.6522, AUC - 0.6682, F1 - 0.6122, precision - 0.5769, training time - -11.0 seconds
2023-03-25 18:44:47,530 : [INFO]  Batch 288: Testing set : loss - 0.6194, accuracy - 0.6422, recall - 0.6471, AUC - 0.7094, F1 - 0.6439, precision - 0.6408
2023-03-25 18:44:47,547 : [INFO]  Batch 289 initialized 
2023-03-25 18:44:48,156 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:48,966 : [INFO]  ------------------------- Batch 289 training: round 1 -------------------------
2023-03-25 18:44:54,357 : [INFO]  ------------------------- Batch round 1, loss: 0.6092 -------------------------
2023-03-25 18:44:54,357 : [INFO]  ------------------------- Batch 289, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:54,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:54,374 : [INFO]  ------------------------- Batch 289 training: round 2 -------------------------
2023-03-25 18:44:57,129 : [INFO]  ------------------------- Batch round 2, loss: 0.5992 -------------------------
2023-03-25 18:44:57,129 : [INFO]  ------------------------- Batch 289, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:57,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:57,178 : [INFO]  ------------------------- Batch 289 training: round 3 -------------------------
2023-03-25 18:45:00,020 : [INFO]  ------------------------- Batch round 3, loss: 0.606 -------------------------
2023-03-25 18:45:00,020 : [INFO]  ------------------------- Batch 289, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:00,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:00,041 : [INFO]  Batch number 289 model fetched from the server
2023-03-25 18:45:00,041 : [INFO]  ################ Batch 289: final global model evalution after 3 rounds ################
2023-03-25 18:45:01,810 : [INFO]  Batch 289: Training set : loss - 0.6173, accuracy - 0.6467, recall - 0.7174, AUC - 0.7473, F1 - 0.6701, precision - 0.6286, training time - -11.0 seconds
2023-03-25 18:45:01,810 : [INFO]  Batch 289: Testing set : loss - 0.6037, accuracy - 0.6667, recall - 0.7353, AUC - 0.7735, F1 - 0.6881, precision - 0.6466
2023-03-25 18:45:01,820 : [INFO]  Batch 290 initialized 
2023-03-25 18:45:02,409 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:03,197 : [INFO]  ------------------------- Batch 290 training: round 1 -------------------------
2023-03-25 18:45:08,495 : [INFO]  ------------------------- Batch round 1, loss: 0.6095 -------------------------
2023-03-25 18:45:08,496 : [INFO]  ------------------------- Batch 290, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:08,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:08,517 : [INFO]  ------------------------- Batch 290 training: round 2 -------------------------
2023-03-25 18:45:11,336 : [INFO]  ------------------------- Batch round 2, loss: 0.6091 -------------------------
2023-03-25 18:45:11,336 : [INFO]  ------------------------- Batch 290, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:11,355 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:11,358 : [INFO]  ------------------------- Batch 290 training: round 3 -------------------------
2023-03-25 18:45:14,127 : [INFO]  ------------------------- Batch round 3, loss: 0.6116 -------------------------
2023-03-25 18:45:14,128 : [INFO]  ------------------------- Batch 290, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:14,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:14,148 : [INFO]  Batch number 290 model fetched from the server
2023-03-25 18:45:14,148 : [INFO]  ################ Batch 290: final global model evalution after 3 rounds ################
2023-03-25 18:45:15,885 : [INFO]  Batch 290: Training set : loss - 0.6185, accuracy - 0.6413, recall - 0.7609, AUC - 0.7517, F1 - 0.6796, precision - 0.614, training time - -11.0 seconds
2023-03-25 18:45:15,885 : [INFO]  Batch 290: Testing set : loss - 0.6312, accuracy - 0.6176, recall - 0.7353, AUC - 0.7246, F1 - 0.6579, precision - 0.5952
2023-03-25 18:45:15,902 : [INFO]  Batch 291 initialized 
2023-03-25 18:45:16,523 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:17,294 : [INFO]  ------------------------- Batch 291 training: round 1 -------------------------
2023-03-25 18:45:22,646 : [INFO]  ------------------------- Batch round 1, loss: 0.6499 -------------------------
2023-03-25 18:45:22,646 : [INFO]  ------------------------- Batch 291, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:22,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:22,666 : [INFO]  ------------------------- Batch 291 training: round 2 -------------------------
2023-03-25 18:45:25,420 : [INFO]  ------------------------- Batch round 2, loss: 0.6452 -------------------------
2023-03-25 18:45:25,420 : [INFO]  ------------------------- Batch 291, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:25,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:25,437 : [INFO]  ------------------------- Batch 291 training: round 3 -------------------------
2023-03-25 18:45:28,089 : [INFO]  ------------------------- Batch round 3, loss: 0.6413 -------------------------
2023-03-25 18:45:28,089 : [INFO]  ------------------------- Batch 291, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:28,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:28,108 : [INFO]  Batch number 291 model fetched from the server
2023-03-25 18:45:28,108 : [INFO]  ################ Batch 291: final global model evalution after 3 rounds ################
2023-03-25 18:45:29,847 : [INFO]  Batch 291: Training set : loss - 0.6724, accuracy - 0.587, recall - 0.6739, AUC - 0.6391, F1 - 0.62, precision - 0.5741, training time - -11.0 seconds
2023-03-25 18:45:29,848 : [INFO]  Batch 291: Testing set : loss - 0.6316, accuracy - 0.6029, recall - 0.7843, AUC - 0.7422, F1 - 0.6639, precision - 0.5755
2023-03-25 18:45:29,857 : [INFO]  Batch 292 initialized 
2023-03-25 18:45:30,432 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:31,197 : [INFO]  ------------------------- Batch 292 training: round 1 -------------------------
2023-03-25 18:45:36,461 : [INFO]  ------------------------- Batch round 1, loss: 0.5903 -------------------------
2023-03-25 18:45:36,461 : [INFO]  ------------------------- Batch 292, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:36,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:36,484 : [INFO]  ------------------------- Batch 292 training: round 2 -------------------------
2023-03-25 18:45:39,201 : [INFO]  ------------------------- Batch round 2, loss: 0.59 -------------------------
2023-03-25 18:45:39,201 : [INFO]  ------------------------- Batch 292, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:39,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:39,221 : [INFO]  ------------------------- Batch 292 training: round 3 -------------------------
2023-03-25 18:45:41,950 : [INFO]  ------------------------- Batch round 3, loss: 0.5959 -------------------------
2023-03-25 18:45:41,950 : [INFO]  ------------------------- Batch 292, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:41,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:41,970 : [INFO]  Batch number 292 model fetched from the server
2023-03-25 18:45:41,970 : [INFO]  ################ Batch 292: final global model evalution after 3 rounds ################
2023-03-25 18:45:43,708 : [INFO]  Batch 292: Training set : loss - 0.6016, accuracy - 0.6359, recall - 0.8043, AUC - 0.7934, F1 - 0.6884, precision - 0.6016, training time - -11.0 seconds
2023-03-25 18:45:43,708 : [INFO]  Batch 292: Testing set : loss - 0.5686, accuracy - 0.7402, recall - 0.8333, AUC - 0.8492, F1 - 0.7623, precision - 0.7025
2023-03-25 18:45:43,720 : [INFO]  Batch 293 initialized 
2023-03-25 18:45:44,312 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:45,078 : [INFO]  ------------------------- Batch 293 training: round 1 -------------------------
2023-03-25 18:45:50,244 : [INFO]  ------------------------- Batch round 1, loss: 0.6095 -------------------------
2023-03-25 18:45:50,244 : [INFO]  ------------------------- Batch 293, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:50,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:50,388 : [INFO]  ------------------------- Batch 293 training: round 2 -------------------------
2023-03-25 18:45:53,004 : [INFO]  ------------------------- Batch round 2, loss: 0.6094 -------------------------
2023-03-25 18:45:53,004 : [INFO]  ------------------------- Batch 293, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:53,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:53,148 : [INFO]  ------------------------- Batch 293 training: round 3 -------------------------
2023-03-25 18:45:55,829 : [INFO]  ------------------------- Batch round 3, loss: 0.6087 -------------------------
2023-03-25 18:45:55,829 : [INFO]  ------------------------- Batch 293, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:56,005 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:56,008 : [INFO]  Batch number 293 model fetched from the server
2023-03-25 18:45:56,008 : [INFO]  ################ Batch 293: final global model evalution after 3 rounds ################
2023-03-25 18:45:57,705 : [INFO]  Batch 293: Training set : loss - 0.6188, accuracy - 0.663, recall - 0.7717, AUC - 0.7581, F1 - 0.6961, precision - 0.6339, training time - -11.0 seconds
2023-03-25 18:45:57,705 : [INFO]  Batch 293: Testing set : loss - 0.6534, accuracy - 0.5686, recall - 0.6961, AUC - 0.6738, F1 - 0.6174, precision - 0.5547
2023-03-25 18:45:57,721 : [INFO]  Batch 294 initialized 
2023-03-25 18:45:58,304 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:59,070 : [INFO]  ------------------------- Batch 294 training: round 1 -------------------------
2023-03-25 18:46:04,330 : [INFO]  ------------------------- Batch round 1, loss: 0.5903 -------------------------
2023-03-25 18:46:04,330 : [INFO]  ------------------------- Batch 294, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:04,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:04,354 : [INFO]  ------------------------- Batch 294 training: round 2 -------------------------
2023-03-25 18:46:07,042 : [INFO]  ------------------------- Batch round 2, loss: 0.5962 -------------------------
2023-03-25 18:46:07,042 : [INFO]  ------------------------- Batch 294, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:07,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:07,256 : [INFO]  ------------------------- Batch 294 training: round 3 -------------------------
2023-03-25 18:46:10,031 : [INFO]  ------------------------- Batch round 3, loss: 0.5909 -------------------------
2023-03-25 18:46:10,032 : [INFO]  ------------------------- Batch 294, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:10,049 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:10,051 : [INFO]  Batch number 294 model fetched from the server
2023-03-25 18:46:10,052 : [INFO]  ################ Batch 294: final global model evalution after 3 rounds ################
2023-03-25 18:46:11,826 : [INFO]  Batch 294: Training set : loss - 0.602, accuracy - 0.6793, recall - 0.8804, AUC - 0.8068, F1 - 0.733, precision - 0.6279, training time - -11.0 seconds
2023-03-25 18:46:11,826 : [INFO]  Batch 294: Testing set : loss - 0.6389, accuracy - 0.598, recall - 0.7549, AUC - 0.7257, F1 - 0.6525, precision - 0.5746
2023-03-25 18:46:11,843 : [INFO]  Batch 295 initialized 
2023-03-25 18:46:12,436 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:13,228 : [INFO]  ------------------------- Batch 295 training: round 1 -------------------------
2023-03-25 18:46:18,461 : [INFO]  ------------------------- Batch round 1, loss: 0.6044 -------------------------
2023-03-25 18:46:18,461 : [INFO]  ------------------------- Batch 295, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:18,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:18,516 : [INFO]  ------------------------- Batch 295 training: round 2 -------------------------
2023-03-25 18:46:21,142 : [INFO]  ------------------------- Batch round 2, loss: 0.6145 -------------------------
2023-03-25 18:46:21,142 : [INFO]  ------------------------- Batch 295, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:21,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:21,272 : [INFO]  ------------------------- Batch 295 training: round 3 -------------------------
2023-03-25 18:46:23,956 : [INFO]  ------------------------- Batch round 3, loss: 0.6087 -------------------------
2023-03-25 18:46:23,956 : [INFO]  ------------------------- Batch 295, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:24,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:24,084 : [INFO]  Batch number 295 model fetched from the server
2023-03-25 18:46:24,084 : [INFO]  ################ Batch 295: final global model evalution after 3 rounds ################
2023-03-25 18:46:25,759 : [INFO]  Batch 295: Training set : loss - 0.6185, accuracy - 0.663, recall - 0.7609, AUC - 0.7549, F1 - 0.6931, precision - 0.6364, training time - -11.0 seconds
2023-03-25 18:46:25,759 : [INFO]  Batch 295: Testing set : loss - 0.6231, accuracy - 0.6324, recall - 0.7451, AUC - 0.7314, F1 - 0.6696, precision - 0.608
2023-03-25 18:46:25,774 : [INFO]  Batch 296 initialized 
2023-03-25 18:46:26,374 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:27,161 : [INFO]  ------------------------- Batch 296 training: round 1 -------------------------
2023-03-25 18:46:32,489 : [INFO]  ------------------------- Batch round 1, loss: 0.6162 -------------------------
2023-03-25 18:46:32,490 : [INFO]  ------------------------- Batch 296, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:32,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:32,510 : [INFO]  ------------------------- Batch 296 training: round 2 -------------------------
2023-03-25 18:46:35,288 : [INFO]  ------------------------- Batch round 2, loss: 0.6162 -------------------------
2023-03-25 18:46:35,288 : [INFO]  ------------------------- Batch 296, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:35,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:35,304 : [INFO]  ------------------------- Batch 296 training: round 3 -------------------------
2023-03-25 18:46:38,099 : [INFO]  ------------------------- Batch round 3, loss: 0.614 -------------------------
2023-03-25 18:46:38,099 : [INFO]  ------------------------- Batch 296, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:38,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:38,121 : [INFO]  Batch number 296 model fetched from the server
2023-03-25 18:46:38,121 : [INFO]  ################ Batch 296: final global model evalution after 3 rounds ################
2023-03-25 18:46:39,881 : [INFO]  Batch 296: Training set : loss - 0.6252, accuracy - 0.6304, recall - 0.6739, AUC - 0.7232, F1 - 0.6458, precision - 0.62, training time - -11.0 seconds
2023-03-25 18:46:39,881 : [INFO]  Batch 296: Testing set : loss - 0.6259, accuracy - 0.6422, recall - 0.8137, AUC - 0.7544, F1 - 0.6946, precision - 0.6058
2023-03-25 18:46:39,897 : [INFO]  Batch 297 initialized 
2023-03-25 18:46:40,486 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:41,292 : [INFO]  ------------------------- Batch 297 training: round 1 -------------------------
2023-03-25 18:46:46,538 : [INFO]  ------------------------- Batch round 1, loss: 0.6131 -------------------------
2023-03-25 18:46:46,538 : [INFO]  ------------------------- Batch 297, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:46,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:46,570 : [INFO]  ------------------------- Batch 297 training: round 2 -------------------------
2023-03-25 18:46:49,241 : [INFO]  ------------------------- Batch round 2, loss: 0.6086 -------------------------
2023-03-25 18:46:49,242 : [INFO]  ------------------------- Batch 297, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:49,308 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:49,311 : [INFO]  ------------------------- Batch 297 training: round 3 -------------------------
2023-03-25 18:46:51,997 : [INFO]  ------------------------- Batch round 3, loss: 0.6139 -------------------------
2023-03-25 18:46:51,997 : [INFO]  ------------------------- Batch 297, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:52,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:52,016 : [INFO]  Batch number 297 model fetched from the server
2023-03-25 18:46:52,016 : [INFO]  ################ Batch 297: final global model evalution after 3 rounds ################
2023-03-25 18:46:53,730 : [INFO]  Batch 297: Training set : loss - 0.6242, accuracy - 0.6576, recall - 0.7717, AUC - 0.7355, F1 - 0.6927, precision - 0.6283, training time - -11.0 seconds
2023-03-25 18:46:53,730 : [INFO]  Batch 297: Testing set : loss - 0.6301, accuracy - 0.6176, recall - 0.7059, AUC - 0.7101, F1 - 0.6486, precision - 0.6
2023-03-25 18:46:53,746 : [INFO]  Batch 298 initialized 
2023-03-25 18:46:54,328 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:55,140 : [INFO]  ------------------------- Batch 298 training: round 1 -------------------------
2023-03-25 18:47:00,501 : [INFO]  ------------------------- Batch round 1, loss: 0.5965 -------------------------
2023-03-25 18:47:00,501 : [INFO]  ------------------------- Batch 298, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:00,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:00,518 : [INFO]  ------------------------- Batch 298 training: round 2 -------------------------
2023-03-25 18:47:03,227 : [INFO]  ------------------------- Batch round 2, loss: 0.6037 -------------------------
2023-03-25 18:47:03,228 : [INFO]  ------------------------- Batch 298, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:03,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:03,250 : [INFO]  ------------------------- Batch 298 training: round 3 -------------------------
2023-03-25 18:47:05,943 : [INFO]  ------------------------- Batch round 3, loss: 0.5978 -------------------------
2023-03-25 18:47:05,944 : [INFO]  ------------------------- Batch 298, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:05,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:05,970 : [INFO]  Batch number 298 model fetched from the server
2023-03-25 18:47:05,971 : [INFO]  ################ Batch 298: final global model evalution after 3 rounds ################
2023-03-25 18:47:07,676 : [INFO]  Batch 298: Training set : loss - 0.6053, accuracy - 0.6902, recall - 0.8152, AUC - 0.7908, F1 - 0.7246, precision - 0.6522, training time - -11.0 seconds
2023-03-25 18:47:07,676 : [INFO]  Batch 298: Testing set : loss - 0.6061, accuracy - 0.652, recall - 0.7647, AUC - 0.7726, F1 - 0.6872, precision - 0.624
2023-03-25 18:47:07,692 : [INFO]  Batch 299 initialized 
2023-03-25 18:47:08,284 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:09,074 : [INFO]  ------------------------- Batch 299 training: round 1 -------------------------
2023-03-25 18:47:14,257 : [INFO]  ------------------------- Batch round 1, loss: 0.5987 -------------------------
2023-03-25 18:47:14,257 : [INFO]  ------------------------- Batch 299, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:14,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:14,291 : [INFO]  ------------------------- Batch 299 training: round 2 -------------------------
2023-03-25 18:47:17,008 : [INFO]  ------------------------- Batch round 2, loss: 0.5976 -------------------------
2023-03-25 18:47:17,008 : [INFO]  ------------------------- Batch 299, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:17,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:17,029 : [INFO]  ------------------------- Batch 299 training: round 3 -------------------------
2023-03-25 18:47:19,639 : [INFO]  ------------------------- Batch round 3, loss: 0.6016 -------------------------
2023-03-25 18:47:19,639 : [INFO]  ------------------------- Batch 299, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:19,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:19,728 : [INFO]  Batch number 299 model fetched from the server
2023-03-25 18:47:19,728 : [INFO]  ################ Batch 299: final global model evalution after 3 rounds ################
2023-03-25 18:47:21,448 : [INFO]  Batch 299: Training set : loss - 0.6073, accuracy - 0.663, recall - 0.8261, AUC - 0.7878, F1 - 0.7103, precision - 0.623, training time - -11.0 seconds
2023-03-25 18:47:21,448 : [INFO]  Batch 299: Testing set : loss - 0.624, accuracy - 0.6127, recall - 0.7647, AUC - 0.7431, F1 - 0.6638, precision - 0.5865
2023-03-25 18:47:21,458 : [INFO]  Batch 300 initialized 
2023-03-25 18:47:22,038 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:22,850 : [INFO]  ------------------------- Batch 300 training: round 1 -------------------------
2023-03-25 18:47:28,163 : [INFO]  ------------------------- Batch round 1, loss: 0.5892 -------------------------
2023-03-25 18:47:28,163 : [INFO]  ------------------------- Batch 300, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:28,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:28,216 : [INFO]  ------------------------- Batch 300 training: round 2 -------------------------
2023-03-25 18:47:30,954 : [INFO]  ------------------------- Batch round 2, loss: 0.5936 -------------------------
2023-03-25 18:47:30,954 : [INFO]  ------------------------- Batch 300, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:30,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:30,971 : [INFO]  ------------------------- Batch 300 training: round 3 -------------------------
2023-03-25 18:47:33,676 : [INFO]  ------------------------- Batch round 3, loss: 0.5937 -------------------------
2023-03-25 18:47:33,676 : [INFO]  ------------------------- Batch 300, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:33,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:33,695 : [INFO]  Batch number 300 model fetched from the server
2023-03-25 18:47:33,696 : [INFO]  ################ Batch 300: final global model evalution after 3 rounds ################
2023-03-25 18:47:35,406 : [INFO]  Batch 300: Training set : loss - 0.5992, accuracy - 0.6848, recall - 0.8043, AUC - 0.7853, F1 - 0.7184, precision - 0.6491, training time - -11.0 seconds
2023-03-25 18:47:35,406 : [INFO]  Batch 300: Testing set : loss - 0.592, accuracy - 0.6716, recall - 0.7353, AUC - 0.7885, F1 - 0.6912, precision - 0.6522
2023-03-25 18:47:35,421 : [INFO]  Batch 301 initialized 
2023-03-25 18:47:36,046 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:36,826 : [INFO]  ------------------------- Batch 301 training: round 1 -------------------------
2023-03-25 18:47:42,035 : [INFO]  ------------------------- Batch round 1, loss: 0.5705 -------------------------
2023-03-25 18:47:42,035 : [INFO]  ------------------------- Batch 301, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:42,119 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:42,122 : [INFO]  ------------------------- Batch 301 training: round 2 -------------------------
2023-03-25 18:47:44,897 : [INFO]  ------------------------- Batch round 2, loss: 0.574 -------------------------
2023-03-25 18:47:44,897 : [INFO]  ------------------------- Batch 301, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:44,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:44,957 : [INFO]  ------------------------- Batch 301 training: round 3 -------------------------
2023-03-25 18:47:47,654 : [INFO]  ------------------------- Batch round 3, loss: 0.5747 -------------------------
2023-03-25 18:47:47,654 : [INFO]  ------------------------- Batch 301, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:47,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:47,696 : [INFO]  Batch number 301 model fetched from the server
2023-03-25 18:47:47,696 : [INFO]  ################ Batch 301: final global model evalution after 3 rounds ################
2023-03-25 18:47:49,449 : [INFO]  Batch 301: Training set : loss - 0.5844, accuracy - 0.6739, recall - 0.7609, AUC - 0.8042, F1 - 0.7, precision - 0.6481, training time - -11.0 seconds
2023-03-25 18:47:49,449 : [INFO]  Batch 301: Testing set : loss - 0.6064, accuracy - 0.6618, recall - 0.7745, AUC - 0.7788, F1 - 0.696, precision - 0.632
2023-03-25 18:47:49,460 : [INFO]  Batch 302 initialized 
2023-03-25 18:47:50,094 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:50,860 : [INFO]  ------------------------- Batch 302 training: round 1 -------------------------
2023-03-25 18:47:56,084 : [INFO]  ------------------------- Batch round 1, loss: 0.6092 -------------------------
2023-03-25 18:47:56,085 : [INFO]  ------------------------- Batch 302, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:56,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:56,184 : [INFO]  ------------------------- Batch 302 training: round 2 -------------------------
2023-03-25 18:47:58,830 : [INFO]  ------------------------- Batch round 2, loss: 0.6119 -------------------------
2023-03-25 18:47:58,830 : [INFO]  ------------------------- Batch 302, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:58,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:58,854 : [INFO]  ------------------------- Batch 302 training: round 3 -------------------------
2023-03-25 18:48:01,477 : [INFO]  ------------------------- Batch round 3, loss: 0.6042 -------------------------
2023-03-25 18:48:01,477 : [INFO]  ------------------------- Batch 302, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:01,492 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:01,495 : [INFO]  Batch number 302 model fetched from the server
2023-03-25 18:48:01,495 : [INFO]  ################ Batch 302: final global model evalution after 3 rounds ################
2023-03-25 18:48:03,167 : [INFO]  Batch 302: Training set : loss - 0.6268, accuracy - 0.5761, recall - 0.7391, AUC - 0.7433, F1 - 0.6355, precision - 0.5574, training time - -11.0 seconds
2023-03-25 18:48:03,167 : [INFO]  Batch 302: Testing set : loss - 0.6002, accuracy - 0.652, recall - 0.7941, AUC - 0.7932, F1 - 0.6953, precision - 0.6183
2023-03-25 18:48:03,180 : [INFO]  Batch 303 initialized 
2023-03-25 18:48:03,706 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:04,442 : [INFO]  ------------------------- Batch 303 training: round 1 -------------------------
2023-03-25 18:48:09,627 : [INFO]  ------------------------- Batch round 1, loss: 0.6122 -------------------------
2023-03-25 18:48:09,627 : [INFO]  ------------------------- Batch 303, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:09,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:09,870 : [INFO]  ------------------------- Batch 303 training: round 2 -------------------------
2023-03-25 18:48:12,403 : [INFO]  ------------------------- Batch round 2, loss: 0.6139 -------------------------
2023-03-25 18:48:12,403 : [INFO]  ------------------------- Batch 303, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:12,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:12,421 : [INFO]  ------------------------- Batch 303 training: round 3 -------------------------
2023-03-25 18:48:14,930 : [INFO]  ------------------------- Batch round 3, loss: 0.6136 -------------------------
2023-03-25 18:48:14,930 : [INFO]  ------------------------- Batch 303, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:14,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:14,951 : [INFO]  Batch number 303 model fetched from the server
2023-03-25 18:48:14,951 : [INFO]  ################ Batch 303: final global model evalution after 3 rounds ################
2023-03-25 18:48:16,610 : [INFO]  Batch 303: Training set : loss - 0.6225, accuracy - 0.6087, recall - 0.6957, AUC - 0.7345, F1 - 0.64, precision - 0.5926, training time - -11.0 seconds
2023-03-25 18:48:16,610 : [INFO]  Batch 303: Testing set : loss - 0.6109, accuracy - 0.6667, recall - 0.7745, AUC - 0.7564, F1 - 0.6991, precision - 0.6371
2023-03-25 18:48:16,623 : [INFO]  Batch 304 initialized 
2023-03-25 18:48:17,212 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:17,998 : [INFO]  ------------------------- Batch 304 training: round 1 -------------------------
2023-03-25 18:48:23,197 : [INFO]  ------------------------- Batch round 1, loss: 0.6007 -------------------------
2023-03-25 18:48:23,197 : [INFO]  ------------------------- Batch 304, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:23,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:23,220 : [INFO]  ------------------------- Batch 304 training: round 2 -------------------------
2023-03-25 18:48:25,871 : [INFO]  ------------------------- Batch round 2, loss: 0.6083 -------------------------
2023-03-25 18:48:25,871 : [INFO]  ------------------------- Batch 304, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:26,047 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:26,050 : [INFO]  ------------------------- Batch 304 training: round 3 -------------------------
2023-03-25 18:48:28,604 : [INFO]  ------------------------- Batch round 3, loss: 0.6029 -------------------------
2023-03-25 18:48:28,605 : [INFO]  ------------------------- Batch 304, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:28,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:28,699 : [INFO]  Batch number 304 model fetched from the server
2023-03-25 18:48:28,700 : [INFO]  ################ Batch 304: final global model evalution after 3 rounds ################
2023-03-25 18:48:30,383 : [INFO]  Batch 304: Training set : loss - 0.6168, accuracy - 0.6359, recall - 0.7717, AUC - 0.7621, F1 - 0.6794, precision - 0.6068, training time - -11.0 seconds
2023-03-25 18:48:30,384 : [INFO]  Batch 304: Testing set : loss - 0.6376, accuracy - 0.6078, recall - 0.7843, AUC - 0.7217, F1 - 0.6667, precision - 0.5797
2023-03-25 18:48:30,397 : [INFO]  Batch 305 initialized 
2023-03-25 18:48:30,975 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:31,782 : [INFO]  ------------------------- Batch 305 training: round 1 -------------------------
2023-03-25 18:48:36,920 : [INFO]  ------------------------- Batch round 1, loss: 0.5994 -------------------------
2023-03-25 18:48:36,920 : [INFO]  ------------------------- Batch 305, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:36,934 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:36,937 : [INFO]  ------------------------- Batch 305 training: round 2 -------------------------
2023-03-25 18:48:39,582 : [INFO]  ------------------------- Batch round 2, loss: 0.6062 -------------------------
2023-03-25 18:48:39,582 : [INFO]  ------------------------- Batch 305, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:39,599 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:39,602 : [INFO]  ------------------------- Batch 305 training: round 3 -------------------------
2023-03-25 18:48:42,226 : [INFO]  ------------------------- Batch round 3, loss: 0.6018 -------------------------
2023-03-25 18:48:42,226 : [INFO]  ------------------------- Batch 305, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:42,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:42,243 : [INFO]  Batch number 305 model fetched from the server
2023-03-25 18:48:42,243 : [INFO]  ################ Batch 305: final global model evalution after 3 rounds ################
2023-03-25 18:48:43,907 : [INFO]  Batch 305: Training set : loss - 0.6112, accuracy - 0.6467, recall - 0.7826, AUC - 0.7621, F1 - 0.689, precision - 0.6154, training time - -10.0 seconds
2023-03-25 18:48:43,908 : [INFO]  Batch 305: Testing set : loss - 0.6427, accuracy - 0.598, recall - 0.7451, AUC - 0.7188, F1 - 0.6496, precision - 0.5758
2023-03-25 18:48:43,924 : [INFO]  Batch 306 initialized 
2023-03-25 18:48:44,492 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:45,303 : [INFO]  ------------------------- Batch 306 training: round 1 -------------------------
2023-03-25 18:48:50,703 : [INFO]  ------------------------- Batch round 1, loss: 0.5865 -------------------------
2023-03-25 18:48:50,703 : [INFO]  ------------------------- Batch 306, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:50,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:50,724 : [INFO]  ------------------------- Batch 306 training: round 2 -------------------------
2023-03-25 18:48:53,366 : [INFO]  ------------------------- Batch round 2, loss: 0.5919 -------------------------
2023-03-25 18:48:53,367 : [INFO]  ------------------------- Batch 306, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:53,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:53,385 : [INFO]  ------------------------- Batch 306 training: round 3 -------------------------
2023-03-25 18:48:56,120 : [INFO]  ------------------------- Batch round 3, loss: 0.5905 -------------------------
2023-03-25 18:48:56,120 : [INFO]  ------------------------- Batch 306, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:56,135 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:56,139 : [INFO]  Batch number 306 model fetched from the server
2023-03-25 18:48:56,139 : [INFO]  ################ Batch 306: final global model evalution after 3 rounds ################
2023-03-25 18:48:57,873 : [INFO]  Batch 306: Training set : loss - 0.592, accuracy - 0.7446, recall - 0.8478, AUC - 0.8061, F1 - 0.7685, precision - 0.7027, training time - -11.0 seconds
2023-03-25 18:48:57,873 : [INFO]  Batch 306: Testing set : loss - 0.5996, accuracy - 0.6765, recall - 0.8235, AUC - 0.7946, F1 - 0.7179, precision - 0.6364
2023-03-25 18:48:57,887 : [INFO]  Batch 307 initialized 
2023-03-25 18:48:58,488 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:59,292 : [INFO]  ------------------------- Batch 307 training: round 1 -------------------------
2023-03-25 18:49:04,627 : [INFO]  ------------------------- Batch round 1, loss: 0.6074 -------------------------
2023-03-25 18:49:04,628 : [INFO]  ------------------------- Batch 307, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:04,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:04,656 : [INFO]  ------------------------- Batch 307 training: round 2 -------------------------
2023-03-25 18:49:07,555 : [INFO]  ------------------------- Batch round 2, loss: 0.6051 -------------------------
2023-03-25 18:49:07,555 : [INFO]  ------------------------- Batch 307, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:07,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:07,572 : [INFO]  ------------------------- Batch 307 training: round 3 -------------------------
2023-03-25 18:49:10,231 : [INFO]  ------------------------- Batch round 3, loss: 0.6067 -------------------------
2023-03-25 18:49:10,231 : [INFO]  ------------------------- Batch 307, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:10,292 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:10,296 : [INFO]  Batch number 307 model fetched from the server
2023-03-25 18:49:10,297 : [INFO]  ################ Batch 307: final global model evalution after 3 rounds ################
2023-03-25 18:49:12,026 : [INFO]  Batch 307: Training set : loss - 0.6179, accuracy - 0.6467, recall - 0.7609, AUC - 0.7563, F1 - 0.6829, precision - 0.6195, training time - -11.0 seconds
2023-03-25 18:49:12,027 : [INFO]  Batch 307: Testing set : loss - 0.5955, accuracy - 0.6618, recall - 0.8235, AUC - 0.8108, F1 - 0.7089, precision - 0.6222
2023-03-25 18:49:12,041 : [INFO]  Batch 308 initialized 
2023-03-25 18:49:12,624 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:13,401 : [INFO]  ------------------------- Batch 308 training: round 1 -------------------------
2023-03-25 18:49:18,400 : [INFO]  ------------------------- Batch round 1, loss: 0.5901 -------------------------
2023-03-25 18:49:18,401 : [INFO]  ------------------------- Batch 308, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:18,515 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:18,518 : [INFO]  ------------------------- Batch 308 training: round 2 -------------------------
2023-03-25 18:49:20,967 : [INFO]  ------------------------- Batch round 2, loss: 0.596 -------------------------
2023-03-25 18:49:20,967 : [INFO]  ------------------------- Batch 308, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:21,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:21,132 : [INFO]  ------------------------- Batch 308 training: round 3 -------------------------
2023-03-25 18:49:23,877 : [INFO]  ------------------------- Batch round 3, loss: 0.5968 -------------------------
2023-03-25 18:49:23,878 : [INFO]  ------------------------- Batch 308, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:24,037 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:24,042 : [INFO]  Batch number 308 model fetched from the server
2023-03-25 18:49:24,043 : [INFO]  ################ Batch 308: final global model evalution after 3 rounds ################
2023-03-25 18:49:25,731 : [INFO]  Batch 308: Training set : loss - 0.5992, accuracy - 0.6522, recall - 0.7717, AUC - 0.7923, F1 - 0.6893, precision - 0.6228, training time - -11.0 seconds
2023-03-25 18:49:25,731 : [INFO]  Batch 308: Testing set : loss - 0.6219, accuracy - 0.6275, recall - 0.7549, AUC - 0.751, F1 - 0.6696, precision - 0.6016
2023-03-25 18:49:25,771 : [INFO]  Batch 309 initialized 
2023-03-25 18:49:26,376 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:27,197 : [INFO]  ------------------------- Batch 309 training: round 1 -------------------------
2023-03-25 18:49:32,456 : [INFO]  ------------------------- Batch round 1, loss: 0.6453 -------------------------
2023-03-25 18:49:32,456 : [INFO]  ------------------------- Batch 309, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:32,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:32,483 : [INFO]  ------------------------- Batch 309 training: round 2 -------------------------
2023-03-25 18:49:35,171 : [INFO]  ------------------------- Batch round 2, loss: 0.647 -------------------------
2023-03-25 18:49:35,171 : [INFO]  ------------------------- Batch 309, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:35,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:35,218 : [INFO]  ------------------------- Batch 309 training: round 3 -------------------------
2023-03-25 18:49:37,843 : [INFO]  ------------------------- Batch round 3, loss: 0.6475 -------------------------
2023-03-25 18:49:37,843 : [INFO]  ------------------------- Batch 309, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:37,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:37,867 : [INFO]  Batch number 309 model fetched from the server
2023-03-25 18:49:37,867 : [INFO]  ################ Batch 309: final global model evalution after 3 rounds ################
2023-03-25 18:49:39,526 : [INFO]  Batch 309: Training set : loss - 0.6576, accuracy - 0.6033, recall - 0.75, AUC - 0.683, F1 - 0.654, precision - 0.5798, training time - -11.0 seconds
2023-03-25 18:49:39,526 : [INFO]  Batch 309: Testing set : loss - 0.6019, accuracy - 0.6373, recall - 0.8333, AUC - 0.8084, F1 - 0.6967, precision - 0.5986
2023-03-25 18:49:39,547 : [INFO]  Batch 310 initialized 
2023-03-25 18:49:40,125 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:40,927 : [INFO]  ------------------------- Batch 310 training: round 1 -------------------------
2023-03-25 18:49:46,151 : [INFO]  ------------------------- Batch round 1, loss: 0.6083 -------------------------
2023-03-25 18:49:46,151 : [INFO]  ------------------------- Batch 310, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:46,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:46,213 : [INFO]  ------------------------- Batch 310 training: round 2 -------------------------
2023-03-25 18:49:48,862 : [INFO]  ------------------------- Batch round 2, loss: 0.61 -------------------------
2023-03-25 18:49:48,862 : [INFO]  ------------------------- Batch 310, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:48,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:48,883 : [INFO]  ------------------------- Batch 310 training: round 3 -------------------------
2023-03-25 18:49:51,457 : [INFO]  ------------------------- Batch round 3, loss: 0.6025 -------------------------
2023-03-25 18:49:51,458 : [INFO]  ------------------------- Batch 310, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:51,478 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:51,481 : [INFO]  Batch number 310 model fetched from the server
2023-03-25 18:49:51,481 : [INFO]  ################ Batch 310: final global model evalution after 3 rounds ################
2023-03-25 18:49:53,194 : [INFO]  Batch 310: Training set : loss - 0.6238, accuracy - 0.6467, recall - 0.7609, AUC - 0.7332, F1 - 0.6829, precision - 0.6195, training time - -11.0 seconds
2023-03-25 18:49:53,194 : [INFO]  Batch 310: Testing set : loss - 0.6106, accuracy - 0.6863, recall - 0.7451, AUC - 0.7536, F1 - 0.7037, precision - 0.6667
2023-03-25 18:49:53,213 : [INFO]  Batch 311 initialized 
2023-03-25 18:49:53,805 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:54,622 : [INFO]  ------------------------- Batch 311 training: round 1 -------------------------
2023-03-25 18:49:59,867 : [INFO]  ------------------------- Batch round 1, loss: 0.621 -------------------------
2023-03-25 18:49:59,867 : [INFO]  ------------------------- Batch 311, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:59,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:59,888 : [INFO]  ------------------------- Batch 311 training: round 2 -------------------------
2023-03-25 18:50:02,509 : [INFO]  ------------------------- Batch round 2, loss: 0.6163 -------------------------
2023-03-25 18:50:02,509 : [INFO]  ------------------------- Batch 311, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:02,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:02,528 : [INFO]  ------------------------- Batch 311 training: round 3 -------------------------
2023-03-25 18:50:05,131 : [INFO]  ------------------------- Batch round 3, loss: 0.6137 -------------------------
2023-03-25 18:50:05,131 : [INFO]  ------------------------- Batch 311, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:05,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:05,157 : [INFO]  Batch number 311 model fetched from the server
2023-03-25 18:50:05,157 : [INFO]  ################ Batch 311: final global model evalution after 3 rounds ################
2023-03-25 18:50:06,797 : [INFO]  Batch 311: Training set : loss - 0.6282, accuracy - 0.6033, recall - 0.7391, AUC - 0.7364, F1 - 0.6507, precision - 0.5812, training time - -11.0 seconds
2023-03-25 18:50:06,797 : [INFO]  Batch 311: Testing set : loss - 0.5974, accuracy - 0.7059, recall - 0.8333, AUC - 0.8094, F1 - 0.7391, precision - 0.6641
2023-03-25 18:50:06,810 : [INFO]  Batch 312 initialized 
2023-03-25 18:50:07,381 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:08,171 : [INFO]  ------------------------- Batch 312 training: round 1 -------------------------
2023-03-25 18:50:13,329 : [INFO]  ------------------------- Batch round 1, loss: 0.5884 -------------------------
2023-03-25 18:50:13,329 : [INFO]  ------------------------- Batch 312, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:13,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:13,372 : [INFO]  ------------------------- Batch 312 training: round 2 -------------------------
2023-03-25 18:50:15,922 : [INFO]  ------------------------- Batch round 2, loss: 0.5906 -------------------------
2023-03-25 18:50:15,922 : [INFO]  ------------------------- Batch 312, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:15,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:15,988 : [INFO]  ------------------------- Batch 312 training: round 3 -------------------------
2023-03-25 18:50:18,647 : [INFO]  ------------------------- Batch round 3, loss: 0.5836 -------------------------
2023-03-25 18:50:18,647 : [INFO]  ------------------------- Batch 312, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:18,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:18,671 : [INFO]  Batch number 312 model fetched from the server
2023-03-25 18:50:18,672 : [INFO]  ################ Batch 312: final global model evalution after 3 rounds ################
2023-03-25 18:50:20,341 : [INFO]  Batch 312: Training set : loss - 0.5962, accuracy - 0.6957, recall - 0.7717, AUC - 0.7836, F1 - 0.7172, precision - 0.6698, training time - -11.0 seconds
2023-03-25 18:50:20,342 : [INFO]  Batch 312: Testing set : loss - 0.6044, accuracy - 0.6765, recall - 0.7843, AUC - 0.7742, F1 - 0.708, precision - 0.6452
2023-03-25 18:50:20,359 : [INFO]  Batch 313 initialized 
2023-03-25 18:50:20,950 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:21,764 : [INFO]  ------------------------- Batch 313 training: round 1 -------------------------
2023-03-25 18:50:26,976 : [INFO]  ------------------------- Batch round 1, loss: 0.6045 -------------------------
2023-03-25 18:50:26,976 : [INFO]  ------------------------- Batch 313, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:27,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:27,051 : [INFO]  ------------------------- Batch 313 training: round 2 -------------------------
2023-03-25 18:50:29,645 : [INFO]  ------------------------- Batch round 2, loss: 0.6043 -------------------------
2023-03-25 18:50:29,645 : [INFO]  ------------------------- Batch 313, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:29,666 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:29,668 : [INFO]  ------------------------- Batch 313 training: round 3 -------------------------
2023-03-25 18:50:32,315 : [INFO]  ------------------------- Batch round 3, loss: 0.6147 -------------------------
2023-03-25 18:50:32,315 : [INFO]  ------------------------- Batch 313, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:32,361 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:32,364 : [INFO]  Batch number 313 model fetched from the server
2023-03-25 18:50:32,364 : [INFO]  ################ Batch 313: final global model evalution after 3 rounds ################
2023-03-25 18:50:34,172 : [INFO]  Batch 313: Training set : loss - 0.6268, accuracy - 0.6196, recall - 0.7391, AUC - 0.7353, F1 - 0.6602, precision - 0.5965, training time - -11.0 seconds
2023-03-25 18:50:34,173 : [INFO]  Batch 313: Testing set : loss - 0.6198, accuracy - 0.6667, recall - 0.7647, AUC - 0.7442, F1 - 0.6964, precision - 0.6393
2023-03-25 18:50:34,182 : [INFO]  Batch 314 initialized 
2023-03-25 18:50:34,775 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:35,587 : [INFO]  ------------------------- Batch 314 training: round 1 -------------------------
2023-03-25 18:50:40,783 : [INFO]  ------------------------- Batch round 1, loss: 0.5994 -------------------------
2023-03-25 18:50:40,783 : [INFO]  ------------------------- Batch 314, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:40,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:40,807 : [INFO]  ------------------------- Batch 314 training: round 2 -------------------------
2023-03-25 18:50:43,428 : [INFO]  ------------------------- Batch round 2, loss: 0.6045 -------------------------
2023-03-25 18:50:43,428 : [INFO]  ------------------------- Batch 314, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:43,444 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:43,447 : [INFO]  ------------------------- Batch 314 training: round 3 -------------------------
2023-03-25 18:50:46,097 : [INFO]  ------------------------- Batch round 3, loss: 0.6006 -------------------------
2023-03-25 18:50:46,098 : [INFO]  ------------------------- Batch 314, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:46,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:46,119 : [INFO]  Batch number 314 model fetched from the server
2023-03-25 18:50:46,119 : [INFO]  ################ Batch 314: final global model evalution after 3 rounds ################
2023-03-25 18:50:47,752 : [INFO]  Batch 314: Training set : loss - 0.6132, accuracy - 0.6359, recall - 0.7391, AUC - 0.7436, F1 - 0.67, precision - 0.6126, training time - -11.0 seconds
2023-03-25 18:50:47,752 : [INFO]  Batch 314: Testing set : loss - 0.5874, accuracy - 0.6716, recall - 0.8039, AUC - 0.8124, F1 - 0.71, precision - 0.6357
2023-03-25 18:50:47,768 : [INFO]  Batch 315 initialized 
2023-03-25 18:50:48,350 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:49,078 : [INFO]  ------------------------- Batch 315 training: round 1 -------------------------
2023-03-25 18:50:54,299 : [INFO]  ------------------------- Batch round 1, loss: 0.5983 -------------------------
2023-03-25 18:50:54,299 : [INFO]  ------------------------- Batch 315, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:54,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:54,579 : [INFO]  ------------------------- Batch 315 training: round 2 -------------------------
2023-03-25 18:50:57,182 : [INFO]  ------------------------- Batch round 2, loss: 0.6036 -------------------------
2023-03-25 18:50:57,183 : [INFO]  ------------------------- Batch 315, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:57,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:57,234 : [INFO]  ------------------------- Batch 315 training: round 3 -------------------------
2023-03-25 18:50:59,776 : [INFO]  ------------------------- Batch round 3, loss: 0.6084 -------------------------
2023-03-25 18:50:59,776 : [INFO]  ------------------------- Batch 315, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:59,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:59,853 : [INFO]  Batch number 315 model fetched from the server
2023-03-25 18:50:59,854 : [INFO]  ################ Batch 315: final global model evalution after 3 rounds ################
2023-03-25 18:51:01,528 : [INFO]  Batch 315: Training set : loss - 0.6139, accuracy - 0.6359, recall - 0.7609, AUC - 0.7583, F1 - 0.6763, precision - 0.6087, training time - -11.0 seconds
2023-03-25 18:51:01,528 : [INFO]  Batch 315: Testing set : loss - 0.5953, accuracy - 0.6716, recall - 0.7647, AUC - 0.7904, F1 - 0.6996, precision - 0.6446
2023-03-25 18:51:01,543 : [INFO]  Batch 316 initialized 
2023-03-25 18:51:02,118 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:02,960 : [INFO]  ------------------------- Batch 316 training: round 1 -------------------------
2023-03-25 18:51:08,167 : [INFO]  ------------------------- Batch round 1, loss: 0.608 -------------------------
2023-03-25 18:51:08,167 : [INFO]  ------------------------- Batch 316, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:08,182 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:08,185 : [INFO]  ------------------------- Batch 316 training: round 2 -------------------------
2023-03-25 18:51:10,795 : [INFO]  ------------------------- Batch round 2, loss: 0.6108 -------------------------
2023-03-25 18:51:10,795 : [INFO]  ------------------------- Batch 316, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:10,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:10,815 : [INFO]  ------------------------- Batch 316 training: round 3 -------------------------
2023-03-25 18:51:13,527 : [INFO]  ------------------------- Batch round 3, loss: 0.6124 -------------------------
2023-03-25 18:51:13,527 : [INFO]  ------------------------- Batch 316, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:13,549 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:13,558 : [INFO]  Batch number 316 model fetched from the server
2023-03-25 18:51:13,559 : [INFO]  ################ Batch 316: final global model evalution after 3 rounds ################
2023-03-25 18:51:15,248 : [INFO]  Batch 316: Training set : loss - 0.6267, accuracy - 0.6359, recall - 0.75, AUC - 0.7364, F1 - 0.6732, precision - 0.6106, training time - -11.0 seconds
2023-03-25 18:51:15,248 : [INFO]  Batch 316: Testing set : loss - 0.613, accuracy - 0.6667, recall - 0.7843, AUC - 0.7737, F1 - 0.7018, precision - 0.6349
2023-03-25 18:51:15,257 : [INFO]  Batch 317 initialized 
2023-03-25 18:51:15,843 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:16,665 : [INFO]  ------------------------- Batch 317 training: round 1 -------------------------
2023-03-25 18:51:21,730 : [INFO]  ------------------------- Batch round 1, loss: 0.6079 -------------------------
2023-03-25 18:51:21,730 : [INFO]  ------------------------- Batch 317, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:21,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:21,892 : [INFO]  ------------------------- Batch 317 training: round 2 -------------------------
2023-03-25 18:51:24,570 : [INFO]  ------------------------- Batch round 2, loss: 0.609 -------------------------
2023-03-25 18:51:24,570 : [INFO]  ------------------------- Batch 317, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:24,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:24,671 : [INFO]  ------------------------- Batch 317 training: round 3 -------------------------
2023-03-25 18:51:27,091 : [INFO]  ------------------------- Batch round 3, loss: 0.609 -------------------------
2023-03-25 18:51:27,092 : [INFO]  ------------------------- Batch 317, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:27,202 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:27,204 : [INFO]  Batch number 317 model fetched from the server
2023-03-25 18:51:27,204 : [INFO]  ################ Batch 317: final global model evalution after 3 rounds ################
2023-03-25 18:51:28,263 : [INFO]  Batch 317: Training set : loss - 0.6189, accuracy - 0.6304, recall - 0.7826, AUC - 0.7561, F1 - 0.6792, precision - 0.6, training time - -11.0 seconds
2023-03-25 18:51:28,263 : [INFO]  Batch 317: Testing set : loss - 0.5643, accuracy - 0.7108, recall - 0.8137, AUC - 0.8472, F1 - 0.7378, precision - 0.6748
2023-03-25 18:51:28,271 : [INFO]  Batch 318 initialized 
2023-03-25 18:51:28,628 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:29,443 : [INFO]  ------------------------- Batch 318 training: round 1 -------------------------
2023-03-25 18:51:33,690 : [INFO]  ------------------------- Batch round 1, loss: 0.5994 -------------------------
2023-03-25 18:51:33,693 : [INFO]  ------------------------- Batch 318, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:33,704 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:33,707 : [INFO]  ------------------------- Batch 318 training: round 2 -------------------------
2023-03-25 18:51:35,438 : [INFO]  ------------------------- Batch round 2, loss: 0.5986 -------------------------
2023-03-25 18:51:35,438 : [INFO]  ------------------------- Batch 318, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:35,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:35,450 : [INFO]  ------------------------- Batch 318 training: round 3 -------------------------
2023-03-25 18:51:37,177 : [INFO]  ------------------------- Batch round 3, loss: 0.599 -------------------------
2023-03-25 18:51:37,177 : [INFO]  ------------------------- Batch 318, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:37,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:37,190 : [INFO]  Batch number 318 model fetched from the server
2023-03-25 18:51:37,190 : [INFO]  ################ Batch 318: final global model evalution after 3 rounds ################
2023-03-25 18:51:38,226 : [INFO]  Batch 318: Training set : loss - 0.6058, accuracy - 0.663, recall - 0.7935, AUC - 0.7851, F1 - 0.7019, precision - 0.6293, training time - -8.0 seconds
2023-03-25 18:51:38,226 : [INFO]  Batch 318: Testing set : loss - 0.6114, accuracy - 0.6765, recall - 0.7941, AUC - 0.7689, F1 - 0.7105, precision - 0.6429
2023-03-25 18:51:38,244 : [INFO]  Batch 319 initialized 
2023-03-25 18:51:38,616 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:39,506 : [INFO]  ------------------------- Batch 319 training: round 1 -------------------------
2023-03-25 18:51:42,825 : [INFO]  ------------------------- Batch round 1, loss: 0.6022 -------------------------
2023-03-25 18:51:42,826 : [INFO]  ------------------------- Batch 319, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:42,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:42,838 : [INFO]  ------------------------- Batch 319 training: round 2 -------------------------
2023-03-25 18:51:44,491 : [INFO]  ------------------------- Batch round 2, loss: 0.6024 -------------------------
2023-03-25 18:51:44,492 : [INFO]  ------------------------- Batch 319, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:44,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:44,550 : [INFO]  ------------------------- Batch 319 training: round 3 -------------------------
2023-03-25 18:51:46,199 : [INFO]  ------------------------- Batch round 3, loss: 0.6057 -------------------------
2023-03-25 18:51:46,199 : [INFO]  ------------------------- Batch 319, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:46,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:46,217 : [INFO]  Batch number 319 model fetched from the server
2023-03-25 18:51:46,217 : [INFO]  ################ Batch 319: final global model evalution after 3 rounds ################
2023-03-25 18:51:47,237 : [INFO]  Batch 319: Training set : loss - 0.6113, accuracy - 0.6304, recall - 0.6957, AUC - 0.7421, F1 - 0.6531, precision - 0.6154, training time - -7.0 seconds
2023-03-25 18:51:47,238 : [INFO]  Batch 319: Testing set : loss - 0.5966, accuracy - 0.6667, recall - 0.7255, AUC - 0.7776, F1 - 0.6852, precision - 0.6491
2023-03-25 18:51:47,256 : [INFO]  Batch 320 initialized 
2023-03-25 18:51:47,627 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:48,409 : [INFO]  ------------------------- Batch 320 training: round 1 -------------------------
2023-03-25 18:51:51,787 : [INFO]  ------------------------- Batch round 1, loss: 0.5921 -------------------------
2023-03-25 18:51:51,788 : [INFO]  ------------------------- Batch 320, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:51,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:51,898 : [INFO]  ------------------------- Batch 320 training: round 2 -------------------------
2023-03-25 18:51:53,595 : [INFO]  ------------------------- Batch round 2, loss: 0.5924 -------------------------
2023-03-25 18:51:53,595 : [INFO]  ------------------------- Batch 320, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:53,605 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:53,607 : [INFO]  ------------------------- Batch 320 training: round 3 -------------------------
2023-03-25 18:51:55,226 : [INFO]  ------------------------- Batch round 3, loss: 0.5953 -------------------------
2023-03-25 18:51:55,226 : [INFO]  ------------------------- Batch 320, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:55,326 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:55,328 : [INFO]  Batch number 320 model fetched from the server
2023-03-25 18:51:55,328 : [INFO]  ################ Batch 320: final global model evalution after 3 rounds ################
2023-03-25 18:51:56,334 : [INFO]  Batch 320: Training set : loss - 0.6034, accuracy - 0.7065, recall - 0.837, AUC - 0.7927, F1 - 0.7404, precision - 0.6638, training time - -7.0 seconds
2023-03-25 18:51:56,335 : [INFO]  Batch 320: Testing set : loss - 0.612, accuracy - 0.6569, recall - 0.7647, AUC - 0.7639, F1 - 0.6903, precision - 0.629
2023-03-25 18:51:56,363 : [INFO]  Batch 321 initialized 
2023-03-25 18:51:56,729 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:57,551 : [INFO]  ------------------------- Batch 321 training: round 1 -------------------------
2023-03-25 18:52:00,896 : [INFO]  ------------------------- Batch round 1, loss: 0.59 -------------------------
2023-03-25 18:52:00,896 : [INFO]  ------------------------- Batch 321, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:00,906 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:00,908 : [INFO]  ------------------------- Batch 321 training: round 2 -------------------------
2023-03-25 18:52:02,504 : [INFO]  ------------------------- Batch round 2, loss: 0.5932 -------------------------
2023-03-25 18:52:02,504 : [INFO]  ------------------------- Batch 321, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:02,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:02,521 : [INFO]  ------------------------- Batch 321 training: round 3 -------------------------
2023-03-25 18:52:04,233 : [INFO]  ------------------------- Batch round 3, loss: 0.5906 -------------------------
2023-03-25 18:52:04,233 : [INFO]  ------------------------- Batch 321, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:04,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:04,254 : [INFO]  Batch number 321 model fetched from the server
2023-03-25 18:52:04,254 : [INFO]  ################ Batch 321: final global model evalution after 3 rounds ################
2023-03-25 18:52:05,452 : [INFO]  Batch 321: Training set : loss - 0.6022, accuracy - 0.6848, recall - 0.8043, AUC - 0.7902, F1 - 0.7184, precision - 0.6491, training time - -7.0 seconds
2023-03-25 18:52:05,452 : [INFO]  Batch 321: Testing set : loss - 0.5967, accuracy - 0.6618, recall - 0.7941, AUC - 0.7898, F1 - 0.7013, precision - 0.6279
2023-03-25 18:52:05,465 : [INFO]  Batch 322 initialized 
2023-03-25 18:52:05,898 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:06,724 : [INFO]  ------------------------- Batch 322 training: round 1 -------------------------
2023-03-25 18:52:10,362 : [INFO]  ------------------------- Batch round 1, loss: 0.5757 -------------------------
2023-03-25 18:52:10,362 : [INFO]  ------------------------- Batch 322, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:10,375 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:10,377 : [INFO]  ------------------------- Batch 322 training: round 2 -------------------------
2023-03-25 18:52:12,268 : [INFO]  ------------------------- Batch round 2, loss: 0.5742 -------------------------
2023-03-25 18:52:12,268 : [INFO]  ------------------------- Batch 322, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:12,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:12,331 : [INFO]  ------------------------- Batch 322 training: round 3 -------------------------
2023-03-25 18:52:14,201 : [INFO]  ------------------------- Batch round 3, loss: 0.5736 -------------------------
2023-03-25 18:52:14,201 : [INFO]  ------------------------- Batch 322, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:14,270 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:14,273 : [INFO]  Batch number 322 model fetched from the server
2023-03-25 18:52:14,273 : [INFO]  ################ Batch 322: final global model evalution after 3 rounds ################
2023-03-25 18:52:15,465 : [INFO]  Batch 322: Training set : loss - 0.5836, accuracy - 0.6793, recall - 0.8478, AUC - 0.8369, F1 - 0.7256, precision - 0.6341, training time - -8.0 seconds
2023-03-25 18:52:15,465 : [INFO]  Batch 322: Testing set : loss - 0.6068, accuracy - 0.6667, recall - 0.7745, AUC - 0.7783, F1 - 0.6991, precision - 0.6371
2023-03-25 18:52:15,479 : [INFO]  Batch 323 initialized 
2023-03-25 18:52:15,915 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:16,747 : [INFO]  ------------------------- Batch 323 training: round 1 -------------------------
2023-03-25 18:52:20,479 : [INFO]  ------------------------- Batch round 1, loss: 0.5926 -------------------------
2023-03-25 18:52:20,479 : [INFO]  ------------------------- Batch 323, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:20,531 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:20,534 : [INFO]  ------------------------- Batch 323 training: round 2 -------------------------
2023-03-25 18:52:22,420 : [INFO]  ------------------------- Batch round 2, loss: 0.5997 -------------------------
2023-03-25 18:52:22,420 : [INFO]  ------------------------- Batch 323, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:22,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:22,441 : [INFO]  ------------------------- Batch 323 training: round 3 -------------------------
2023-03-25 18:52:24,394 : [INFO]  ------------------------- Batch round 3, loss: 0.595 -------------------------
2023-03-25 18:52:24,394 : [INFO]  ------------------------- Batch 323, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:24,437 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:24,439 : [INFO]  Batch number 323 model fetched from the server
2023-03-25 18:52:24,439 : [INFO]  ################ Batch 323: final global model evalution after 3 rounds ################
2023-03-25 18:52:25,695 : [INFO]  Batch 323: Training set : loss - 0.6093, accuracy - 0.6685, recall - 0.8152, AUC - 0.805, F1 - 0.7109, precision - 0.6303, training time - -8.0 seconds
2023-03-25 18:52:25,695 : [INFO]  Batch 323: Testing set : loss - 0.6049, accuracy - 0.6618, recall - 0.7941, AUC - 0.7847, F1 - 0.7013, precision - 0.6279
2023-03-25 18:52:25,708 : [INFO]  Batch 324 initialized 
2023-03-25 18:52:26,170 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:27,015 : [INFO]  ------------------------- Batch 324 training: round 1 -------------------------
2023-03-25 18:52:30,598 : [INFO]  ------------------------- Batch round 1, loss: 0.6131 -------------------------
2023-03-25 18:52:30,598 : [INFO]  ------------------------- Batch 324, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:30,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:30,743 : [INFO]  ------------------------- Batch 324 training: round 2 -------------------------
2023-03-25 18:52:32,687 : [INFO]  ------------------------- Batch round 2, loss: 0.6092 -------------------------
2023-03-25 18:52:32,687 : [INFO]  ------------------------- Batch 324, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:32,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:32,733 : [INFO]  ------------------------- Batch 324 training: round 3 -------------------------
2023-03-25 18:52:34,601 : [INFO]  ------------------------- Batch round 3, loss: 0.6126 -------------------------
2023-03-25 18:52:34,602 : [INFO]  ------------------------- Batch 324, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:34,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:34,658 : [INFO]  Batch number 324 model fetched from the server
2023-03-25 18:52:34,658 : [INFO]  ################ Batch 324: final global model evalution after 3 rounds ################
2023-03-25 18:52:35,904 : [INFO]  Batch 324: Training set : loss - 0.6173, accuracy - 0.6902, recall - 0.7717, AUC - 0.7406, F1 - 0.7136, precision - 0.6636, training time - -8.0 seconds
2023-03-25 18:52:35,904 : [INFO]  Batch 324: Testing set : loss - 0.5798, accuracy - 0.7108, recall - 0.8235, AUC - 0.8198, F1 - 0.7401, precision - 0.672
2023-03-25 18:52:35,917 : [INFO]  Batch 325 initialized 
2023-03-25 18:52:36,376 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:37,196 : [INFO]  ------------------------- Batch 325 training: round 1 -------------------------
2023-03-25 18:52:40,728 : [INFO]  ------------------------- Batch round 1, loss: 0.6023 -------------------------
2023-03-25 18:52:40,728 : [INFO]  ------------------------- Batch 325, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:40,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:40,842 : [INFO]  ------------------------- Batch 325 training: round 2 -------------------------
2023-03-25 18:52:42,595 : [INFO]  ------------------------- Batch round 2, loss: 0.6024 -------------------------
2023-03-25 18:52:42,595 : [INFO]  ------------------------- Batch 325, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:42,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:42,706 : [INFO]  ------------------------- Batch 325 training: round 3 -------------------------
2023-03-25 18:52:44,501 : [INFO]  ------------------------- Batch round 3, loss: 0.5962 -------------------------
2023-03-25 18:52:44,501 : [INFO]  ------------------------- Batch 325, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:44,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:44,558 : [INFO]  Batch number 325 model fetched from the server
2023-03-25 18:52:44,558 : [INFO]  ################ Batch 325: final global model evalution after 3 rounds ################
2023-03-25 18:52:45,808 : [INFO]  Batch 325: Training set : loss - 0.6077, accuracy - 0.6739, recall - 0.8587, AUC - 0.8003, F1 - 0.7248, precision - 0.627, training time - -7.0 seconds
2023-03-25 18:52:45,808 : [INFO]  Batch 325: Testing set : loss - 0.6, accuracy - 0.6716, recall - 0.8235, AUC - 0.7936, F1 - 0.7149, precision - 0.6316
2023-03-25 18:52:45,821 : [INFO]  Batch 326 initialized 
2023-03-25 18:52:46,266 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:47,118 : [INFO]  ------------------------- Batch 326 training: round 1 -------------------------
2023-03-25 18:52:50,789 : [INFO]  ------------------------- Batch round 1, loss: 0.6235 -------------------------
2023-03-25 18:52:50,789 : [INFO]  ------------------------- Batch 326, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:50,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:50,804 : [INFO]  ------------------------- Batch 326 training: round 2 -------------------------
2023-03-25 18:52:52,787 : [INFO]  ------------------------- Batch round 2, loss: 0.6197 -------------------------
2023-03-25 18:52:52,787 : [INFO]  ------------------------- Batch 326, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:52,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:52,818 : [INFO]  ------------------------- Batch 326 training: round 3 -------------------------
2023-03-25 18:52:54,756 : [INFO]  ------------------------- Batch round 3, loss: 0.6152 -------------------------
2023-03-25 18:52:54,756 : [INFO]  ------------------------- Batch 326, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:54,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:54,772 : [INFO]  Batch number 326 model fetched from the server
2023-03-25 18:52:54,772 : [INFO]  ################ Batch 326: final global model evalution after 3 rounds ################
2023-03-25 18:52:56,052 : [INFO]  Batch 326: Training set : loss - 0.6318, accuracy - 0.6087, recall - 0.6848, AUC - 0.719, F1 - 0.6364, precision - 0.5943, training time - -8.0 seconds
2023-03-25 18:52:56,052 : [INFO]  Batch 326: Testing set : loss - 0.6057, accuracy - 0.6422, recall - 0.8137, AUC - 0.7968, F1 - 0.6946, precision - 0.6058
2023-03-25 18:52:56,059 : [INFO]  Batch 327 initialized 
2023-03-25 18:52:56,514 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:57,337 : [INFO]  ------------------------- Batch 327 training: round 1 -------------------------
2023-03-25 18:53:01,067 : [INFO]  ------------------------- Batch round 1, loss: 0.6041 -------------------------
2023-03-25 18:53:01,067 : [INFO]  ------------------------- Batch 327, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:01,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:01,089 : [INFO]  ------------------------- Batch 327 training: round 2 -------------------------
2023-03-25 18:53:03,030 : [INFO]  ------------------------- Batch round 2, loss: 0.6098 -------------------------
2023-03-25 18:53:03,030 : [INFO]  ------------------------- Batch 327, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:03,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:03,046 : [INFO]  ------------------------- Batch 327 training: round 3 -------------------------
2023-03-25 18:53:05,113 : [INFO]  ------------------------- Batch round 3, loss: 0.6025 -------------------------
2023-03-25 18:53:05,113 : [INFO]  ------------------------- Batch 327, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:05,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:05,128 : [INFO]  Batch number 327 model fetched from the server
2023-03-25 18:53:05,128 : [INFO]  ################ Batch 327: final global model evalution after 3 rounds ################
2023-03-25 18:53:06,388 : [INFO]  Batch 327: Training set : loss - 0.6181, accuracy - 0.6196, recall - 0.8261, AUC - 0.7707, F1 - 0.6847, precision - 0.5846, training time - -8.0 seconds
2023-03-25 18:53:06,388 : [INFO]  Batch 327: Testing set : loss - 0.6076, accuracy - 0.6569, recall - 0.8039, AUC - 0.7785, F1 - 0.7009, precision - 0.6212
2023-03-25 18:53:06,396 : [INFO]  Batch 328 initialized 
2023-03-25 18:53:06,866 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:07,700 : [INFO]  ------------------------- Batch 328 training: round 1 -------------------------
2023-03-25 18:53:11,346 : [INFO]  ------------------------- Batch round 1, loss: 0.5984 -------------------------
2023-03-25 18:53:11,346 : [INFO]  ------------------------- Batch 328, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:11,416 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:11,418 : [INFO]  ------------------------- Batch 328 training: round 2 -------------------------
2023-03-25 18:53:13,326 : [INFO]  ------------------------- Batch round 2, loss: 0.5959 -------------------------
2023-03-25 18:53:13,326 : [INFO]  ------------------------- Batch 328, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:13,375 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:13,377 : [INFO]  ------------------------- Batch 328 training: round 3 -------------------------
2023-03-25 18:53:15,243 : [INFO]  ------------------------- Batch round 3, loss: 0.5953 -------------------------
2023-03-25 18:53:15,244 : [INFO]  ------------------------- Batch 328, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:15,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:15,325 : [INFO]  Batch number 328 model fetched from the server
2023-03-25 18:53:15,326 : [INFO]  ################ Batch 328: final global model evalution after 3 rounds ################
2023-03-25 18:53:16,513 : [INFO]  Batch 328: Training set : loss - 0.6053, accuracy - 0.6467, recall - 0.7391, AUC - 0.7498, F1 - 0.6766, precision - 0.6239, training time - -8.0 seconds
2023-03-25 18:53:16,514 : [INFO]  Batch 328: Testing set : loss - 0.5873, accuracy - 0.6716, recall - 0.8137, AUC - 0.8297, F1 - 0.7124, precision - 0.6336
2023-03-25 18:53:16,521 : [INFO]  Batch 329 initialized 
2023-03-25 18:53:16,973 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:17,774 : [INFO]  ------------------------- Batch 329 training: round 1 -------------------------
2023-03-25 18:53:21,500 : [INFO]  ------------------------- Batch round 1, loss: 0.5671 -------------------------
2023-03-25 18:53:21,500 : [INFO]  ------------------------- Batch 329, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:21,639 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:21,641 : [INFO]  ------------------------- Batch 329 training: round 2 -------------------------
2023-03-25 18:53:23,591 : [INFO]  ------------------------- Batch round 2, loss: 0.564 -------------------------
2023-03-25 18:53:23,591 : [INFO]  ------------------------- Batch 329, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:23,650 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:23,652 : [INFO]  ------------------------- Batch 329 training: round 3 -------------------------
2023-03-25 18:53:25,588 : [INFO]  ------------------------- Batch round 3, loss: 0.5632 -------------------------
2023-03-25 18:53:25,588 : [INFO]  ------------------------- Batch 329, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:25,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:25,624 : [INFO]  Batch number 329 model fetched from the server
2023-03-25 18:53:25,624 : [INFO]  ################ Batch 329: final global model evalution after 3 rounds ################
2023-03-25 18:53:26,898 : [INFO]  Batch 329: Training set : loss - 0.5683, accuracy - 0.6902, recall - 0.8696, AUC - 0.8607, F1 - 0.7373, precision - 0.64, training time - -8.0 seconds
2023-03-25 18:53:26,899 : [INFO]  Batch 329: Testing set : loss - 0.5937, accuracy - 0.701, recall - 0.7843, AUC - 0.7944, F1 - 0.724, precision - 0.6723
2023-03-25 18:53:26,908 : [INFO]  Batch 330 initialized 
2023-03-25 18:53:27,362 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:28,212 : [INFO]  ------------------------- Batch 330 training: round 1 -------------------------
2023-03-25 18:53:31,894 : [INFO]  ------------------------- Batch round 1, loss: 0.57 -------------------------
2023-03-25 18:53:31,894 : [INFO]  ------------------------- Batch 330, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:31,912 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:31,914 : [INFO]  ------------------------- Batch 330 training: round 2 -------------------------
2023-03-25 18:53:33,798 : [INFO]  ------------------------- Batch round 2, loss: 0.5671 -------------------------
2023-03-25 18:53:33,799 : [INFO]  ------------------------- Batch 330, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:33,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:33,814 : [INFO]  ------------------------- Batch 330 training: round 3 -------------------------
2023-03-25 18:53:35,737 : [INFO]  ------------------------- Batch round 3, loss: 0.5632 -------------------------
2023-03-25 18:53:35,737 : [INFO]  ------------------------- Batch 330, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:35,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:35,753 : [INFO]  Batch number 330 model fetched from the server
2023-03-25 18:53:35,753 : [INFO]  ################ Batch 330: final global model evalution after 3 rounds ################
2023-03-25 18:53:36,982 : [INFO]  Batch 330: Training set : loss - 0.5704, accuracy - 0.75, recall - 0.8696, AUC - 0.8342, F1 - 0.7767, precision - 0.7018, training time - -8.0 seconds
2023-03-25 18:53:36,982 : [INFO]  Batch 330: Testing set : loss - 0.5896, accuracy - 0.6814, recall - 0.8333, AUC - 0.8143, F1 - 0.7234, precision - 0.6391
2023-03-25 18:53:36,989 : [INFO]  Batch 331 initialized 
2023-03-25 18:53:37,438 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:38,287 : [INFO]  ------------------------- Batch 331 training: round 1 -------------------------
2023-03-25 18:53:41,879 : [INFO]  ------------------------- Batch round 1, loss: 0.6061 -------------------------
2023-03-25 18:53:41,879 : [INFO]  ------------------------- Batch 331, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:41,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:41,895 : [INFO]  ------------------------- Batch 331 training: round 2 -------------------------
2023-03-25 18:53:44,089 : [INFO]  ------------------------- Batch round 2, loss: 0.6138 -------------------------
2023-03-25 18:53:44,089 : [INFO]  ------------------------- Batch 331, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:44,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:44,100 : [INFO]  ------------------------- Batch 331 training: round 3 -------------------------
2023-03-25 18:53:45,934 : [INFO]  ------------------------- Batch round 3, loss: 0.6077 -------------------------
2023-03-25 18:53:45,934 : [INFO]  ------------------------- Batch 331, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:45,952 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:45,954 : [INFO]  Batch number 331 model fetched from the server
2023-03-25 18:53:45,955 : [INFO]  ################ Batch 331: final global model evalution after 3 rounds ################
2023-03-25 18:53:47,183 : [INFO]  Batch 331: Training set : loss - 0.617, accuracy - 0.625, recall - 0.8261, AUC - 0.7849, F1 - 0.6878, precision - 0.5891, training time - -8.0 seconds
2023-03-25 18:53:47,184 : [INFO]  Batch 331: Testing set : loss - 0.6034, accuracy - 0.6814, recall - 0.8529, AUC - 0.8032, F1 - 0.728, precision - 0.635
2023-03-25 18:53:47,199 : [INFO]  Batch 332 initialized 
2023-03-25 18:53:47,650 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:48,518 : [INFO]  ------------------------- Batch 332 training: round 1 -------------------------
2023-03-25 18:53:52,212 : [INFO]  ------------------------- Batch round 1, loss: 0.6006 -------------------------
2023-03-25 18:53:52,213 : [INFO]  ------------------------- Batch 332, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:52,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:52,244 : [INFO]  ------------------------- Batch 332 training: round 2 -------------------------
2023-03-25 18:53:54,122 : [INFO]  ------------------------- Batch round 2, loss: 0.6029 -------------------------
2023-03-25 18:53:54,122 : [INFO]  ------------------------- Batch 332, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:54,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:54,162 : [INFO]  ------------------------- Batch 332 training: round 3 -------------------------
2023-03-25 18:53:56,044 : [INFO]  ------------------------- Batch round 3, loss: 0.6001 -------------------------
2023-03-25 18:53:56,044 : [INFO]  ------------------------- Batch 332, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:56,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:56,097 : [INFO]  Batch number 332 model fetched from the server
2023-03-25 18:53:56,097 : [INFO]  ################ Batch 332: final global model evalution after 3 rounds ################
2023-03-25 18:53:57,391 : [INFO]  Batch 332: Training set : loss - 0.6129, accuracy - 0.6467, recall - 0.837, AUC - 0.7882, F1 - 0.7032, precision - 0.6063, training time - -8.0 seconds
2023-03-25 18:53:57,392 : [INFO]  Batch 332: Testing set : loss - 0.5905, accuracy - 0.7108, recall - 0.8431, AUC - 0.8145, F1 - 0.7446, precision - 0.6667
2023-03-25 18:53:57,407 : [INFO]  Batch 333 initialized 
2023-03-25 18:53:57,920 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:58,765 : [INFO]  ------------------------- Batch 333 training: round 1 -------------------------
2023-03-25 18:54:02,496 : [INFO]  ------------------------- Batch round 1, loss: 0.5935 -------------------------
2023-03-25 18:54:02,496 : [INFO]  ------------------------- Batch 333, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:02,748 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:02,750 : [INFO]  ------------------------- Batch 333 training: round 2 -------------------------
2023-03-25 18:54:04,677 : [INFO]  ------------------------- Batch round 2, loss: 0.5961 -------------------------
2023-03-25 18:54:04,677 : [INFO]  ------------------------- Batch 333, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:04,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:04,692 : [INFO]  ------------------------- Batch 333 training: round 3 -------------------------
2023-03-25 18:54:06,671 : [INFO]  ------------------------- Batch round 3, loss: 0.5927 -------------------------
2023-03-25 18:54:06,671 : [INFO]  ------------------------- Batch 333, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:06,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:06,689 : [INFO]  Batch number 333 model fetched from the server
2023-03-25 18:54:06,689 : [INFO]  ################ Batch 333: final global model evalution after 3 rounds ################
2023-03-25 18:54:07,920 : [INFO]  Batch 333: Training set : loss - 0.6072, accuracy - 0.6196, recall - 0.7283, AUC - 0.7619, F1 - 0.6569, precision - 0.5982, training time - -8.0 seconds
2023-03-25 18:54:07,920 : [INFO]  Batch 333: Testing set : loss - 0.5902, accuracy - 0.6863, recall - 0.8529, AUC - 0.8233, F1 - 0.7311, precision - 0.6397
2023-03-25 18:54:07,930 : [INFO]  Batch 334 initialized 
2023-03-25 18:54:08,383 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:09,225 : [INFO]  ------------------------- Batch 334 training: round 1 -------------------------
2023-03-25 18:54:12,840 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-25 18:54:12,840 : [INFO]  ------------------------- Batch 334, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:12,854 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:12,857 : [INFO]  ------------------------- Batch 334 training: round 2 -------------------------
2023-03-25 18:54:14,737 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 18:54:14,737 : [INFO]  ------------------------- Batch 334, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:14,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:14,754 : [INFO]  ------------------------- Batch 334 training: round 3 -------------------------
2023-03-25 18:54:16,604 : [INFO]  ------------------------- Batch round 3, loss: 0.5626 -------------------------
2023-03-25 18:54:16,605 : [INFO]  ------------------------- Batch 334, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:16,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:16,624 : [INFO]  Batch number 334 model fetched from the server
2023-03-25 18:54:16,624 : [INFO]  ################ Batch 334: final global model evalution after 3 rounds ################
2023-03-25 18:54:17,863 : [INFO]  Batch 334: Training set : loss - 0.5727, accuracy - 0.7337, recall - 0.837, AUC - 0.8286, F1 - 0.7586, precision - 0.6937, training time - -7.0 seconds
2023-03-25 18:54:17,863 : [INFO]  Batch 334: Testing set : loss - 0.6022, accuracy - 0.6618, recall - 0.7843, AUC - 0.7937, F1 - 0.6987, precision - 0.6299
2023-03-25 18:54:17,871 : [INFO]  Batch 335 initialized 
2023-03-25 18:54:18,325 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:19,186 : [INFO]  ------------------------- Batch 335 training: round 1 -------------------------
2023-03-25 18:54:22,949 : [INFO]  ------------------------- Batch round 1, loss: 0.6034 -------------------------
2023-03-25 18:54:22,949 : [INFO]  ------------------------- Batch 335, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:22,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:22,969 : [INFO]  ------------------------- Batch 335 training: round 2 -------------------------
2023-03-25 18:54:25,014 : [INFO]  ------------------------- Batch round 2, loss: 0.6024 -------------------------
2023-03-25 18:54:25,015 : [INFO]  ------------------------- Batch 335, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:25,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:25,082 : [INFO]  ------------------------- Batch 335 training: round 3 -------------------------
2023-03-25 18:54:27,057 : [INFO]  ------------------------- Batch round 3, loss: 0.6 -------------------------
2023-03-25 18:54:27,057 : [INFO]  ------------------------- Batch 335, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:27,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:27,110 : [INFO]  Batch number 335 model fetched from the server
2023-03-25 18:54:27,110 : [INFO]  ################ Batch 335: final global model evalution after 3 rounds ################
2023-03-25 18:54:28,361 : [INFO]  Batch 335: Training set : loss - 0.6186, accuracy - 0.6033, recall - 0.7609, AUC - 0.765, F1 - 0.6573, precision - 0.5785, training time - -8.0 seconds
2023-03-25 18:54:28,362 : [INFO]  Batch 335: Testing set : loss - 0.611, accuracy - 0.6373, recall - 0.7843, AUC - 0.7669, F1 - 0.6838, precision - 0.6061
2023-03-25 18:54:28,369 : [INFO]  Batch 336 initialized 
2023-03-25 18:54:28,829 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:29,701 : [INFO]  ------------------------- Batch 336 training: round 1 -------------------------
2023-03-25 18:54:33,293 : [INFO]  ------------------------- Batch round 1, loss: 0.5897 -------------------------
2023-03-25 18:54:33,293 : [INFO]  ------------------------- Batch 336, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:33,307 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:33,310 : [INFO]  ------------------------- Batch 336 training: round 2 -------------------------
2023-03-25 18:54:35,220 : [INFO]  ------------------------- Batch round 2, loss: 0.5959 -------------------------
2023-03-25 18:54:35,220 : [INFO]  ------------------------- Batch 336, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:35,241 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:35,243 : [INFO]  ------------------------- Batch 336 training: round 3 -------------------------
2023-03-25 18:54:37,252 : [INFO]  ------------------------- Batch round 3, loss: 0.5912 -------------------------
2023-03-25 18:54:37,252 : [INFO]  ------------------------- Batch 336, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:37,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:37,269 : [INFO]  Batch number 336 model fetched from the server
2023-03-25 18:54:37,269 : [INFO]  ################ Batch 336: final global model evalution after 3 rounds ################
2023-03-25 18:54:38,521 : [INFO]  Batch 336: Training set : loss - 0.5988, accuracy - 0.6902, recall - 0.8152, AUC - 0.7936, F1 - 0.7246, precision - 0.6522, training time - -8.0 seconds
2023-03-25 18:54:38,521 : [INFO]  Batch 336: Testing set : loss - 0.5954, accuracy - 0.6912, recall - 0.8235, AUC - 0.8116, F1 - 0.7273, precision - 0.6512
2023-03-25 18:54:38,538 : [INFO]  Batch 337 initialized 
2023-03-25 18:54:38,990 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:39,873 : [INFO]  ------------------------- Batch 337 training: round 1 -------------------------
2023-03-25 18:54:43,469 : [INFO]  ------------------------- Batch round 1, loss: 0.6013 -------------------------
2023-03-25 18:54:43,469 : [INFO]  ------------------------- Batch 337, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:43,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:43,486 : [INFO]  ------------------------- Batch 337 training: round 2 -------------------------
2023-03-25 18:54:45,391 : [INFO]  ------------------------- Batch round 2, loss: 0.6042 -------------------------
2023-03-25 18:54:45,391 : [INFO]  ------------------------- Batch 337, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:45,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:45,409 : [INFO]  ------------------------- Batch 337 training: round 3 -------------------------
2023-03-25 18:54:47,288 : [INFO]  ------------------------- Batch round 3, loss: 0.5999 -------------------------
2023-03-25 18:54:47,288 : [INFO]  ------------------------- Batch 337, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:47,305 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:47,307 : [INFO]  Batch number 337 model fetched from the server
2023-03-25 18:54:47,307 : [INFO]  ################ Batch 337: final global model evalution after 3 rounds ################
2023-03-25 18:54:48,527 : [INFO]  Batch 337: Training set : loss - 0.6117, accuracy - 0.6522, recall - 0.7174, AUC - 0.7363, F1 - 0.6735, precision - 0.6346, training time - -7.0 seconds
2023-03-25 18:54:48,527 : [INFO]  Batch 337: Testing set : loss - 0.5883, accuracy - 0.6961, recall - 0.7843, AUC - 0.8047, F1 - 0.7207, precision - 0.6667
2023-03-25 18:54:48,542 : [INFO]  Batch 338 initialized 
2023-03-25 18:54:48,994 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:49,870 : [INFO]  ------------------------- Batch 338 training: round 1 -------------------------
2023-03-25 18:54:53,538 : [INFO]  ------------------------- Batch round 1, loss: 0.5696 -------------------------
2023-03-25 18:54:53,538 : [INFO]  ------------------------- Batch 338, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:53,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:53,554 : [INFO]  ------------------------- Batch 338 training: round 2 -------------------------
2023-03-25 18:54:55,497 : [INFO]  ------------------------- Batch round 2, loss: 0.5701 -------------------------
2023-03-25 18:54:55,497 : [INFO]  ------------------------- Batch 338, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:55,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:55,513 : [INFO]  ------------------------- Batch 338 training: round 3 -------------------------
2023-03-25 18:54:57,482 : [INFO]  ------------------------- Batch round 3, loss: 0.567 -------------------------
2023-03-25 18:54:57,482 : [INFO]  ------------------------- Batch 338, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:57,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:57,498 : [INFO]  Batch number 338 model fetched from the server
2023-03-25 18:54:57,498 : [INFO]  ################ Batch 338: final global model evalution after 3 rounds ################
2023-03-25 18:54:58,751 : [INFO]  Batch 338: Training set : loss - 0.5789, accuracy - 0.6848, recall - 0.8478, AUC - 0.8325, F1 - 0.729, precision - 0.6393, training time - -8.0 seconds
2023-03-25 18:54:58,751 : [INFO]  Batch 338: Testing set : loss - 0.6011, accuracy - 0.6961, recall - 0.7843, AUC - 0.7761, F1 - 0.7207, precision - 0.6667
2023-03-25 18:54:58,761 : [INFO]  Batch 339 initialized 
2023-03-25 18:54:59,215 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:00,087 : [INFO]  ------------------------- Batch 339 training: round 1 -------------------------
2023-03-25 18:55:03,733 : [INFO]  ------------------------- Batch round 1, loss: 0.6001 -------------------------
2023-03-25 18:55:03,733 : [INFO]  ------------------------- Batch 339, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:03,756 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:03,758 : [INFO]  ------------------------- Batch 339 training: round 2 -------------------------
2023-03-25 18:55:05,675 : [INFO]  ------------------------- Batch round 2, loss: 0.5944 -------------------------
2023-03-25 18:55:05,675 : [INFO]  ------------------------- Batch 339, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:05,689 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:05,691 : [INFO]  ------------------------- Batch 339 training: round 3 -------------------------
2023-03-25 18:55:07,603 : [INFO]  ------------------------- Batch round 3, loss: 0.5968 -------------------------
2023-03-25 18:55:07,603 : [INFO]  ------------------------- Batch 339, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:07,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:07,620 : [INFO]  Batch number 339 model fetched from the server
2023-03-25 18:55:07,620 : [INFO]  ################ Batch 339: final global model evalution after 3 rounds ################
2023-03-25 18:55:08,923 : [INFO]  Batch 339: Training set : loss - 0.6074, accuracy - 0.6576, recall - 0.8152, AUC - 0.7919, F1 - 0.7042, precision - 0.6198, training time - -8.0 seconds
2023-03-25 18:55:08,923 : [INFO]  Batch 339: Testing set : loss - 0.6064, accuracy - 0.6127, recall - 0.8039, AUC - 0.805, F1 - 0.6749, precision - 0.5816
2023-03-25 18:55:08,931 : [INFO]  Batch 340 initialized 
2023-03-25 18:55:09,398 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:10,286 : [INFO]  ------------------------- Batch 340 training: round 1 -------------------------
2023-03-25 18:55:14,077 : [INFO]  ------------------------- Batch round 1, loss: 0.6042 -------------------------
2023-03-25 18:55:14,077 : [INFO]  ------------------------- Batch 340, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:14,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:14,093 : [INFO]  ------------------------- Batch 340 training: round 2 -------------------------
2023-03-25 18:55:15,961 : [INFO]  ------------------------- Batch round 2, loss: 0.6035 -------------------------
2023-03-25 18:55:15,961 : [INFO]  ------------------------- Batch 340, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:15,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:15,978 : [INFO]  ------------------------- Batch 340 training: round 3 -------------------------
2023-03-25 18:55:17,882 : [INFO]  ------------------------- Batch round 3, loss: 0.6064 -------------------------
2023-03-25 18:55:17,882 : [INFO]  ------------------------- Batch 340, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:17,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:17,903 : [INFO]  Batch number 340 model fetched from the server
2023-03-25 18:55:17,903 : [INFO]  ################ Batch 340: final global model evalution after 3 rounds ################
2023-03-25 18:55:19,153 : [INFO]  Batch 340: Training set : loss - 0.617, accuracy - 0.6413, recall - 0.7609, AUC - 0.7628, F1 - 0.6796, precision - 0.614, training time - -8.0 seconds
2023-03-25 18:55:19,153 : [INFO]  Batch 340: Testing set : loss - 0.6027, accuracy - 0.6569, recall - 0.8039, AUC - 0.7881, F1 - 0.7009, precision - 0.6212
2023-03-25 18:55:19,160 : [INFO]  Batch 341 initialized 
2023-03-25 18:55:19,625 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:20,481 : [INFO]  ------------------------- Batch 341 training: round 1 -------------------------
2023-03-25 18:55:24,108 : [INFO]  ------------------------- Batch round 1, loss: 0.5854 -------------------------
2023-03-25 18:55:24,108 : [INFO]  ------------------------- Batch 341, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:24,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:24,216 : [INFO]  ------------------------- Batch 341 training: round 2 -------------------------
2023-03-25 18:55:26,070 : [INFO]  ------------------------- Batch round 2, loss: 0.5872 -------------------------
2023-03-25 18:55:26,070 : [INFO]  ------------------------- Batch 341, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:26,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:26,129 : [INFO]  ------------------------- Batch 341 training: round 3 -------------------------
2023-03-25 18:55:27,978 : [INFO]  ------------------------- Batch round 3, loss: 0.5824 -------------------------
2023-03-25 18:55:27,978 : [INFO]  ------------------------- Batch 341, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:28,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:28,045 : [INFO]  Batch number 341 model fetched from the server
2023-03-25 18:55:28,045 : [INFO]  ################ Batch 341: final global model evalution after 3 rounds ################
2023-03-25 18:55:29,335 : [INFO]  Batch 341: Training set : loss - 0.5921, accuracy - 0.6685, recall - 0.7717, AUC - 0.7942, F1 - 0.6995, precision - 0.6396, training time - -8.0 seconds
2023-03-25 18:55:29,336 : [INFO]  Batch 341: Testing set : loss - 0.6111, accuracy - 0.6471, recall - 0.7843, AUC - 0.7715, F1 - 0.6897, precision - 0.6154
2023-03-25 18:55:29,344 : [INFO]  Batch 342 initialized 
2023-03-25 18:55:29,803 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:30,680 : [INFO]  ------------------------- Batch 342 training: round 1 -------------------------
2023-03-25 18:55:34,349 : [INFO]  ------------------------- Batch round 1, loss: 0.5818 -------------------------
2023-03-25 18:55:34,349 : [INFO]  ------------------------- Batch 342, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:34,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:34,379 : [INFO]  ------------------------- Batch 342 training: round 2 -------------------------
2023-03-25 18:55:36,331 : [INFO]  ------------------------- Batch round 2, loss: 0.5845 -------------------------
2023-03-25 18:55:36,332 : [INFO]  ------------------------- Batch 342, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:36,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:36,359 : [INFO]  ------------------------- Batch 342 training: round 3 -------------------------
2023-03-25 18:55:38,262 : [INFO]  ------------------------- Batch round 3, loss: 0.5834 -------------------------
2023-03-25 18:55:38,263 : [INFO]  ------------------------- Batch 342, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:38,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:38,280 : [INFO]  Batch number 342 model fetched from the server
2023-03-25 18:55:38,280 : [INFO]  ################ Batch 342: final global model evalution after 3 rounds ################
2023-03-25 18:55:39,513 : [INFO]  Batch 342: Training set : loss - 0.59, accuracy - 0.6739, recall - 0.8043, AUC - 0.8238, F1 - 0.7115, precision - 0.6379, training time - -8.0 seconds
2023-03-25 18:55:39,514 : [INFO]  Batch 342: Testing set : loss - 0.5871, accuracy - 0.701, recall - 0.8627, AUC - 0.8291, F1 - 0.7426, precision - 0.6519
2023-03-25 18:55:39,527 : [INFO]  Batch 343 initialized 
2023-03-25 18:55:39,976 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:40,853 : [INFO]  ------------------------- Batch 343 training: round 1 -------------------------
2023-03-25 18:55:44,483 : [INFO]  ------------------------- Batch round 1, loss: 0.5823 -------------------------
2023-03-25 18:55:44,483 : [INFO]  ------------------------- Batch 343, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:44,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:44,498 : [INFO]  ------------------------- Batch 343 training: round 2 -------------------------
2023-03-25 18:55:46,369 : [INFO]  ------------------------- Batch round 2, loss: 0.59 -------------------------
2023-03-25 18:55:46,369 : [INFO]  ------------------------- Batch 343, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:46,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:46,384 : [INFO]  ------------------------- Batch 343 training: round 3 -------------------------
2023-03-25 18:55:48,319 : [INFO]  ------------------------- Batch round 3, loss: 0.5815 -------------------------
2023-03-25 18:55:48,319 : [INFO]  ------------------------- Batch 343, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:48,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:48,334 : [INFO]  Batch number 343 model fetched from the server
2023-03-25 18:55:48,334 : [INFO]  ################ Batch 343: final global model evalution after 3 rounds ################
2023-03-25 18:55:49,547 : [INFO]  Batch 343: Training set : loss - 0.5894, accuracy - 0.663, recall - 0.7717, AUC - 0.7951, F1 - 0.6961, precision - 0.6339, training time - -7.0 seconds
2023-03-25 18:55:49,547 : [INFO]  Batch 343: Testing set : loss - 0.5901, accuracy - 0.6912, recall - 0.8039, AUC - 0.8108, F1 - 0.7225, precision - 0.656
2023-03-25 18:55:49,557 : [INFO]  Batch 344 initialized 
2023-03-25 18:55:50,009 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:50,885 : [INFO]  ------------------------- Batch 344 training: round 1 -------------------------
2023-03-25 18:55:54,453 : [INFO]  ------------------------- Batch round 1, loss: 0.6147 -------------------------
2023-03-25 18:55:54,453 : [INFO]  ------------------------- Batch 344, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:54,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:54,469 : [INFO]  ------------------------- Batch 344 training: round 2 -------------------------
2023-03-25 18:55:56,388 : [INFO]  ------------------------- Batch round 2, loss: 0.6117 -------------------------
2023-03-25 18:55:56,388 : [INFO]  ------------------------- Batch 344, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:56,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:56,405 : [INFO]  ------------------------- Batch 344 training: round 3 -------------------------
2023-03-25 18:55:58,312 : [INFO]  ------------------------- Batch round 3, loss: 0.6105 -------------------------
2023-03-25 18:55:58,312 : [INFO]  ------------------------- Batch 344, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:58,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:58,329 : [INFO]  Batch number 344 model fetched from the server
2023-03-25 18:55:58,329 : [INFO]  ################ Batch 344: final global model evalution after 3 rounds ################
2023-03-25 18:55:59,528 : [INFO]  Batch 344: Training set : loss - 0.6291, accuracy - 0.6413, recall - 0.8152, AUC - 0.7483, F1 - 0.6944, precision - 0.6048, training time - -7.0 seconds
2023-03-25 18:55:59,528 : [INFO]  Batch 344: Testing set : loss - 0.5758, accuracy - 0.6912, recall - 0.8529, AUC - 0.8456, F1 - 0.7342, precision - 0.6444
2023-03-25 18:55:59,538 : [INFO]  Batch 345 initialized 
2023-03-25 18:56:00,003 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:00,901 : [INFO]  ------------------------- Batch 345 training: round 1 -------------------------
2023-03-25 18:56:04,522 : [INFO]  ------------------------- Batch round 1, loss: 0.5891 -------------------------
2023-03-25 18:56:04,522 : [INFO]  ------------------------- Batch 345, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:04,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:04,538 : [INFO]  ------------------------- Batch 345 training: round 2 -------------------------
2023-03-25 18:56:06,445 : [INFO]  ------------------------- Batch round 2, loss: 0.5912 -------------------------
2023-03-25 18:56:06,445 : [INFO]  ------------------------- Batch 345, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:06,459 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:06,461 : [INFO]  ------------------------- Batch 345 training: round 3 -------------------------
2023-03-25 18:56:08,345 : [INFO]  ------------------------- Batch round 3, loss: 0.5899 -------------------------
2023-03-25 18:56:08,345 : [INFO]  ------------------------- Batch 345, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:08,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:08,366 : [INFO]  Batch number 345 model fetched from the server
2023-03-25 18:56:08,366 : [INFO]  ################ Batch 345: final global model evalution after 3 rounds ################
2023-03-25 18:56:09,618 : [INFO]  Batch 345: Training set : loss - 0.6012, accuracy - 0.7011, recall - 0.8261, AUC - 0.7916, F1 - 0.7343, precision - 0.6609, training time - -7.0 seconds
2023-03-25 18:56:09,619 : [INFO]  Batch 345: Testing set : loss - 0.6127, accuracy - 0.6225, recall - 0.6863, AUC - 0.7472, F1 - 0.6452, precision - 0.6087
2023-03-25 18:56:09,644 : [INFO]  Batch 346 initialized 
2023-03-25 18:56:10,086 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:10,962 : [INFO]  ------------------------- Batch 346 training: round 1 -------------------------
2023-03-25 18:56:14,623 : [INFO]  ------------------------- Batch round 1, loss: 0.5925 -------------------------
2023-03-25 18:56:14,623 : [INFO]  ------------------------- Batch 346, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:14,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:14,639 : [INFO]  ------------------------- Batch 346 training: round 2 -------------------------
2023-03-25 18:56:16,567 : [INFO]  ------------------------- Batch round 2, loss: 0.6002 -------------------------
2023-03-25 18:56:16,567 : [INFO]  ------------------------- Batch 346, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:16,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:16,583 : [INFO]  ------------------------- Batch 346 training: round 3 -------------------------
2023-03-25 18:56:18,506 : [INFO]  ------------------------- Batch round 3, loss: 0.5976 -------------------------
2023-03-25 18:56:18,506 : [INFO]  ------------------------- Batch 346, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:18,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:18,554 : [INFO]  Batch number 346 model fetched from the server
2023-03-25 18:56:18,554 : [INFO]  ################ Batch 346: final global model evalution after 3 rounds ################
2023-03-25 18:56:19,840 : [INFO]  Batch 346: Training set : loss - 0.6064, accuracy - 0.6522, recall - 0.7826, AUC - 0.7854, F1 - 0.6923, precision - 0.6207, training time - -8.0 seconds
2023-03-25 18:56:19,840 : [INFO]  Batch 346: Testing set : loss - 0.5781, accuracy - 0.7157, recall - 0.8725, AUC - 0.8537, F1 - 0.7542, precision - 0.6642
2023-03-25 18:56:19,847 : [INFO]  Batch 347 initialized 
2023-03-25 18:56:20,297 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:21,176 : [INFO]  ------------------------- Batch 347 training: round 1 -------------------------
2023-03-25 18:56:24,898 : [INFO]  ------------------------- Batch round 1, loss: 0.5764 -------------------------
2023-03-25 18:56:24,898 : [INFO]  ------------------------- Batch 347, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:24,912 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:24,913 : [INFO]  ------------------------- Batch 347 training: round 2 -------------------------
2023-03-25 18:56:26,930 : [INFO]  ------------------------- Batch round 2, loss: 0.5778 -------------------------
2023-03-25 18:56:26,930 : [INFO]  ------------------------- Batch 347, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:27,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:27,282 : [INFO]  ------------------------- Batch 347 training: round 3 -------------------------
2023-03-25 18:56:29,287 : [INFO]  ------------------------- Batch round 3, loss: 0.5789 -------------------------
2023-03-25 18:56:29,287 : [INFO]  ------------------------- Batch 347, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:29,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:29,306 : [INFO]  Batch number 347 model fetched from the server
2023-03-25 18:56:29,307 : [INFO]  ################ Batch 347: final global model evalution after 3 rounds ################
2023-03-25 18:56:30,637 : [INFO]  Batch 347: Training set : loss - 0.5933, accuracy - 0.6739, recall - 0.7174, AUC - 0.7761, F1 - 0.6875, precision - 0.66, training time - -8.0 seconds
2023-03-25 18:56:30,638 : [INFO]  Batch 347: Testing set : loss - 0.5974, accuracy - 0.6569, recall - 0.8039, AUC - 0.7975, F1 - 0.7009, precision - 0.6212
2023-03-25 18:56:30,653 : [INFO]  Batch 348 initialized 
2023-03-25 18:56:31,140 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:32,114 : [INFO]  ------------------------- Batch 348 training: round 1 -------------------------
2023-03-25 18:56:35,804 : [INFO]  ------------------------- Batch round 1, loss: 0.5561 -------------------------
2023-03-25 18:56:35,804 : [INFO]  ------------------------- Batch 348, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:35,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:35,907 : [INFO]  ------------------------- Batch 348 training: round 2 -------------------------
2023-03-25 18:56:37,771 : [INFO]  ------------------------- Batch round 2, loss: 0.5607 -------------------------
2023-03-25 18:56:37,772 : [INFO]  ------------------------- Batch 348, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:37,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:37,887 : [INFO]  ------------------------- Batch 348 training: round 3 -------------------------
2023-03-25 18:56:39,683 : [INFO]  ------------------------- Batch round 3, loss: 0.5535 -------------------------
2023-03-25 18:56:39,683 : [INFO]  ------------------------- Batch 348, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:39,792 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:39,799 : [INFO]  Batch number 348 model fetched from the server
2023-03-25 18:56:39,800 : [INFO]  ################ Batch 348: final global model evalution after 3 rounds ################
2023-03-25 18:56:41,002 : [INFO]  Batch 348: Training set : loss - 0.5652, accuracy - 0.7609, recall - 0.8587, AUC - 0.8591, F1 - 0.7822, precision - 0.7182, training time - -8.0 seconds
2023-03-25 18:56:41,002 : [INFO]  Batch 348: Testing set : loss - 0.611, accuracy - 0.6716, recall - 0.8039, AUC - 0.7805, F1 - 0.71, precision - 0.6357
2023-03-25 18:56:41,012 : [INFO]  Batch 349 initialized 
2023-03-25 18:56:41,467 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:42,333 : [INFO]  ------------------------- Batch 349 training: round 1 -------------------------
2023-03-25 18:56:46,002 : [INFO]  ------------------------- Batch round 1, loss: 0.5782 -------------------------
2023-03-25 18:56:46,002 : [INFO]  ------------------------- Batch 349, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:46,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:46,100 : [INFO]  ------------------------- Batch 349 training: round 2 -------------------------
2023-03-25 18:56:47,901 : [INFO]  ------------------------- Batch round 2, loss: 0.5812 -------------------------
2023-03-25 18:56:47,901 : [INFO]  ------------------------- Batch 349, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:48,010 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:48,012 : [INFO]  ------------------------- Batch 349 training: round 3 -------------------------
2023-03-25 18:56:49,884 : [INFO]  ------------------------- Batch round 3, loss: 0.5775 -------------------------
2023-03-25 18:56:49,884 : [INFO]  ------------------------- Batch 349, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:49,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:49,994 : [INFO]  Batch number 349 model fetched from the server
2023-03-25 18:56:49,994 : [INFO]  ################ Batch 349: final global model evalution after 3 rounds ################
2023-03-25 18:56:51,220 : [INFO]  Batch 349: Training set : loss - 0.583, accuracy - 0.6957, recall - 0.8478, AUC - 0.836, F1 - 0.7358, precision - 0.65, training time - -8.0 seconds
2023-03-25 18:56:51,220 : [INFO]  Batch 349: Testing set : loss - 0.5885, accuracy - 0.7059, recall - 0.8137, AUC - 0.8217, F1 - 0.7345, precision - 0.6694
2023-03-25 18:56:51,232 : [INFO]  Batch 350 initialized 
2023-03-25 18:56:51,701 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:52,599 : [INFO]  ------------------------- Batch 350 training: round 1 -------------------------
2023-03-25 18:56:56,171 : [INFO]  ------------------------- Batch round 1, loss: 0.589 -------------------------
2023-03-25 18:56:56,171 : [INFO]  ------------------------- Batch 350, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:56,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:56,220 : [INFO]  ------------------------- Batch 350 training: round 2 -------------------------
2023-03-25 18:56:58,085 : [INFO]  ------------------------- Batch round 2, loss: 0.5929 -------------------------
2023-03-25 18:56:58,085 : [INFO]  ------------------------- Batch 350, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:58,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:58,101 : [INFO]  ------------------------- Batch 350 training: round 3 -------------------------
2023-03-25 18:56:59,961 : [INFO]  ------------------------- Batch round 3, loss: 0.5893 -------------------------
2023-03-25 18:56:59,961 : [INFO]  ------------------------- Batch 350, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:59,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:59,978 : [INFO]  Batch number 350 model fetched from the server
2023-03-25 18:56:59,978 : [INFO]  ################ Batch 350: final global model evalution after 3 rounds ################
2023-03-25 18:57:01,203 : [INFO]  Batch 350: Training set : loss - 0.598, accuracy - 0.6739, recall - 0.8043, AUC - 0.803, F1 - 0.7115, precision - 0.6379, training time - -7.0 seconds
2023-03-25 18:57:01,203 : [INFO]  Batch 350: Testing set : loss - 0.5991, accuracy - 0.652, recall - 0.7745, AUC - 0.7892, F1 - 0.69, precision - 0.622
2023-03-25 18:57:01,211 : [INFO]  Batch 351 initialized 
2023-03-25 18:57:01,668 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:02,540 : [INFO]  ------------------------- Batch 351 training: round 1 -------------------------
2023-03-25 18:57:06,199 : [INFO]  ------------------------- Batch round 1, loss: 0.5938 -------------------------
2023-03-25 18:57:06,199 : [INFO]  ------------------------- Batch 351, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:06,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:06,218 : [INFO]  ------------------------- Batch 351 training: round 2 -------------------------
2023-03-25 18:57:08,070 : [INFO]  ------------------------- Batch round 2, loss: 0.5994 -------------------------
2023-03-25 18:57:08,070 : [INFO]  ------------------------- Batch 351, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:08,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:08,088 : [INFO]  ------------------------- Batch 351 training: round 3 -------------------------
2023-03-25 18:57:09,949 : [INFO]  ------------------------- Batch round 3, loss: 0.5931 -------------------------
2023-03-25 18:57:09,950 : [INFO]  ------------------------- Batch 351, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:09,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:09,966 : [INFO]  Batch number 351 model fetched from the server
2023-03-25 18:57:09,966 : [INFO]  ################ Batch 351: final global model evalution after 3 rounds ################
2023-03-25 18:57:11,210 : [INFO]  Batch 351: Training set : loss - 0.6157, accuracy - 0.6141, recall - 0.75, AUC - 0.7618, F1 - 0.6603, precision - 0.5897, training time - -7.0 seconds
2023-03-25 18:57:11,210 : [INFO]  Batch 351: Testing set : loss - 0.5862, accuracy - 0.6667, recall - 0.7941, AUC - 0.8145, F1 - 0.7043, precision - 0.6328
2023-03-25 18:57:11,217 : [INFO]  Batch 352 initialized 
2023-03-25 18:57:11,660 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:12,553 : [INFO]  ------------------------- Batch 352 training: round 1 -------------------------
2023-03-25 18:57:16,076 : [INFO]  ------------------------- Batch round 1, loss: 0.5914 -------------------------
2023-03-25 18:57:16,076 : [INFO]  ------------------------- Batch 352, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:16,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:16,093 : [INFO]  ------------------------- Batch 352 training: round 2 -------------------------
2023-03-25 18:57:18,024 : [INFO]  ------------------------- Batch round 2, loss: 0.5897 -------------------------
2023-03-25 18:57:18,024 : [INFO]  ------------------------- Batch 352, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:18,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:18,040 : [INFO]  ------------------------- Batch 352 training: round 3 -------------------------
2023-03-25 18:57:19,860 : [INFO]  ------------------------- Batch round 3, loss: 0.5892 -------------------------
2023-03-25 18:57:19,860 : [INFO]  ------------------------- Batch 352, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:20,153 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:20,155 : [INFO]  Batch number 352 model fetched from the server
2023-03-25 18:57:20,155 : [INFO]  ################ Batch 352: final global model evalution after 3 rounds ################
2023-03-25 18:57:21,327 : [INFO]  Batch 352: Training set : loss - 0.5985, accuracy - 0.663, recall - 0.7391, AUC - 0.7798, F1 - 0.6869, precision - 0.6415, training time - -8.0 seconds
2023-03-25 18:57:21,327 : [INFO]  Batch 352: Testing set : loss - 0.5868, accuracy - 0.6569, recall - 0.7941, AUC - 0.8129, F1 - 0.6983, precision - 0.6231
2023-03-25 18:57:21,365 : [INFO]  Batch 353 initialized 
2023-03-25 18:57:21,813 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:22,710 : [INFO]  ------------------------- Batch 353 training: round 1 -------------------------
2023-03-25 18:57:26,389 : [INFO]  ------------------------- Batch round 1, loss: 0.5829 -------------------------
2023-03-25 18:57:26,390 : [INFO]  ------------------------- Batch 353, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:26,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:26,407 : [INFO]  ------------------------- Batch 353 training: round 2 -------------------------
2023-03-25 18:57:28,379 : [INFO]  ------------------------- Batch round 2, loss: 0.5823 -------------------------
2023-03-25 18:57:28,379 : [INFO]  ------------------------- Batch 353, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:28,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:28,398 : [INFO]  ------------------------- Batch 353 training: round 3 -------------------------
2023-03-25 18:57:30,252 : [INFO]  ------------------------- Batch round 3, loss: 0.5839 -------------------------
2023-03-25 18:57:30,252 : [INFO]  ------------------------- Batch 353, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:30,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:30,269 : [INFO]  Batch number 353 model fetched from the server
2023-03-25 18:57:30,269 : [INFO]  ################ Batch 353: final global model evalution after 3 rounds ################
2023-03-25 18:57:31,511 : [INFO]  Batch 353: Training set : loss - 0.5937, accuracy - 0.663, recall - 0.7935, AUC - 0.7936, F1 - 0.7019, precision - 0.6293, training time - -8.0 seconds
2023-03-25 18:57:31,511 : [INFO]  Batch 353: Testing set : loss - 0.5721, accuracy - 0.6814, recall - 0.8235, AUC - 0.8469, F1 - 0.721, precision - 0.6412
2023-03-25 18:57:31,531 : [INFO]  Batch 354 initialized 
2023-03-25 18:57:32,078 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:33,045 : [INFO]  ------------------------- Batch 354 training: round 1 -------------------------
2023-03-25 18:57:36,870 : [INFO]  ------------------------- Batch round 1, loss: 0.6039 -------------------------
2023-03-25 18:57:36,870 : [INFO]  ------------------------- Batch 354, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:36,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:36,921 : [INFO]  ------------------------- Batch 354 training: round 2 -------------------------
2023-03-25 18:57:38,777 : [INFO]  ------------------------- Batch round 2, loss: 0.6007 -------------------------
2023-03-25 18:57:38,777 : [INFO]  ------------------------- Batch 354, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:38,847 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:38,850 : [INFO]  ------------------------- Batch 354 training: round 3 -------------------------
2023-03-25 18:57:40,714 : [INFO]  ------------------------- Batch round 3, loss: 0.6058 -------------------------
2023-03-25 18:57:40,714 : [INFO]  ------------------------- Batch 354, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:40,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:40,777 : [INFO]  Batch number 354 model fetched from the server
2023-03-25 18:57:40,777 : [INFO]  ################ Batch 354: final global model evalution after 3 rounds ################
2023-03-25 18:57:41,972 : [INFO]  Batch 354: Training set : loss - 0.6153, accuracy - 0.6522, recall - 0.7935, AUC - 0.7741, F1 - 0.6952, precision - 0.6186, training time - -8.0 seconds
2023-03-25 18:57:41,972 : [INFO]  Batch 354: Testing set : loss - 0.5937, accuracy - 0.6716, recall - 0.8333, AUC - 0.8208, F1 - 0.7173, precision - 0.6296
2023-03-25 18:57:41,981 : [INFO]  Batch 355 initialized 
2023-03-25 18:57:42,484 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:43,382 : [INFO]  ------------------------- Batch 355 training: round 1 -------------------------
2023-03-25 18:57:46,891 : [INFO]  ------------------------- Batch round 1, loss: 0.5694 -------------------------
2023-03-25 18:57:46,891 : [INFO]  ------------------------- Batch 355, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:46,981 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:46,984 : [INFO]  ------------------------- Batch 355 training: round 2 -------------------------
2023-03-25 18:57:48,765 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 18:57:48,765 : [INFO]  ------------------------- Batch 355, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:48,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:48,781 : [INFO]  ------------------------- Batch 355 training: round 3 -------------------------
2023-03-25 18:57:50,590 : [INFO]  ------------------------- Batch round 3, loss: 0.5684 -------------------------
2023-03-25 18:57:50,590 : [INFO]  ------------------------- Batch 355, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:50,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:50,623 : [INFO]  Batch number 355 model fetched from the server
2023-03-25 18:57:50,623 : [INFO]  ################ Batch 355: final global model evalution after 3 rounds ################
2023-03-25 18:57:51,848 : [INFO]  Batch 355: Training set : loss - 0.5735, accuracy - 0.6685, recall - 0.8152, AUC - 0.8268, F1 - 0.7109, precision - 0.6303, training time - -7.0 seconds
2023-03-25 18:57:51,849 : [INFO]  Batch 355: Testing set : loss - 0.5812, accuracy - 0.7108, recall - 0.8039, AUC - 0.8119, F1 - 0.7354, precision - 0.6777
2023-03-25 18:57:51,860 : [INFO]  Batch 356 initialized 
2023-03-25 18:57:52,348 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:53,255 : [INFO]  ------------------------- Batch 356 training: round 1 -------------------------
2023-03-25 18:57:56,775 : [INFO]  ------------------------- Batch round 1, loss: 0.5752 -------------------------
2023-03-25 18:57:56,775 : [INFO]  ------------------------- Batch 356, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:56,860 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:56,862 : [INFO]  ------------------------- Batch 356 training: round 2 -------------------------
2023-03-25 18:57:58,736 : [INFO]  ------------------------- Batch round 2, loss: 0.582 -------------------------
2023-03-25 18:57:58,736 : [INFO]  ------------------------- Batch 356, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:58,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:58,805 : [INFO]  ------------------------- Batch 356 training: round 3 -------------------------
2023-03-25 18:58:00,627 : [INFO]  ------------------------- Batch round 3, loss: 0.5829 -------------------------
2023-03-25 18:58:00,627 : [INFO]  ------------------------- Batch 356, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:00,677 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:00,679 : [INFO]  Batch number 356 model fetched from the server
2023-03-25 18:58:00,679 : [INFO]  ################ Batch 356: final global model evalution after 3 rounds ################
2023-03-25 18:58:01,907 : [INFO]  Batch 356: Training set : loss - 0.594, accuracy - 0.6957, recall - 0.8152, AUC - 0.8024, F1 - 0.7282, precision - 0.6579, training time - -7.0 seconds
2023-03-25 18:58:01,907 : [INFO]  Batch 356: Testing set : loss - 0.6114, accuracy - 0.6225, recall - 0.8039, AUC - 0.7715, F1 - 0.6805, precision - 0.5899
2023-03-25 18:58:01,914 : [INFO]  Batch 357 initialized 
2023-03-25 18:58:02,368 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:03,253 : [INFO]  ------------------------- Batch 357 training: round 1 -------------------------
2023-03-25 18:58:06,945 : [INFO]  ------------------------- Batch round 1, loss: 0.5738 -------------------------
2023-03-25 18:58:06,945 : [INFO]  ------------------------- Batch 357, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:06,960 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:06,962 : [INFO]  ------------------------- Batch 357 training: round 2 -------------------------
2023-03-25 18:58:08,837 : [INFO]  ------------------------- Batch round 2, loss: 0.5718 -------------------------
2023-03-25 18:58:08,837 : [INFO]  ------------------------- Batch 357, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:08,852 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:08,854 : [INFO]  ------------------------- Batch 357 training: round 3 -------------------------
2023-03-25 18:58:10,728 : [INFO]  ------------------------- Batch round 3, loss: 0.5747 -------------------------
2023-03-25 18:58:10,728 : [INFO]  ------------------------- Batch 357, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:10,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:10,747 : [INFO]  Batch number 357 model fetched from the server
2023-03-25 18:58:10,747 : [INFO]  ################ Batch 357: final global model evalution after 3 rounds ################
2023-03-25 18:58:11,965 : [INFO]  Batch 357: Training set : loss - 0.5845, accuracy - 0.6685, recall - 0.7935, AUC - 0.8082, F1 - 0.7053, precision - 0.6348, training time - -7.0 seconds
2023-03-25 18:58:11,965 : [INFO]  Batch 357: Testing set : loss - 0.589, accuracy - 0.6716, recall - 0.7745, AUC - 0.7978, F1 - 0.7022, precision - 0.6423
2023-03-25 18:58:11,976 : [INFO]  Batch 358 initialized 
2023-03-25 18:58:12,422 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:13,312 : [INFO]  ------------------------- Batch 358 training: round 1 -------------------------
2023-03-25 18:58:16,808 : [INFO]  ------------------------- Batch round 1, loss: 0.5805 -------------------------
2023-03-25 18:58:16,808 : [INFO]  ------------------------- Batch 358, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:16,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:16,888 : [INFO]  ------------------------- Batch 358 training: round 2 -------------------------
2023-03-25 18:58:18,729 : [INFO]  ------------------------- Batch round 2, loss: 0.5819 -------------------------
2023-03-25 18:58:18,729 : [INFO]  ------------------------- Batch 358, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:18,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:18,783 : [INFO]  ------------------------- Batch 358 training: round 3 -------------------------
2023-03-25 18:58:20,638 : [INFO]  ------------------------- Batch round 3, loss: 0.5735 -------------------------
2023-03-25 18:58:20,638 : [INFO]  ------------------------- Batch 358, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:20,666 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:20,668 : [INFO]  Batch number 358 model fetched from the server
2023-03-25 18:58:20,669 : [INFO]  ################ Batch 358: final global model evalution after 3 rounds ################
2023-03-25 18:58:21,873 : [INFO]  Batch 358: Training set : loss - 0.5863, accuracy - 0.6685, recall - 0.8478, AUC - 0.8199, F1 - 0.7189, precision - 0.624, training time - -7.0 seconds
2023-03-25 18:58:21,873 : [INFO]  Batch 358: Testing set : loss - 0.591, accuracy - 0.6814, recall - 0.8235, AUC - 0.8301, F1 - 0.721, precision - 0.6412
2023-03-25 18:58:21,888 : [INFO]  Batch 359 initialized 
2023-03-25 18:58:22,338 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:23,197 : [INFO]  ------------------------- Batch 359 training: round 1 -------------------------
2023-03-25 18:58:26,899 : [INFO]  ------------------------- Batch round 1, loss: 0.5821 -------------------------
2023-03-25 18:58:26,899 : [INFO]  ------------------------- Batch 359, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:26,912 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:26,914 : [INFO]  ------------------------- Batch 359 training: round 2 -------------------------
2023-03-25 18:58:28,758 : [INFO]  ------------------------- Batch round 2, loss: 0.577 -------------------------
2023-03-25 18:58:28,758 : [INFO]  ------------------------- Batch 359, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:28,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:28,780 : [INFO]  ------------------------- Batch 359 training: round 3 -------------------------
2023-03-25 18:58:30,626 : [INFO]  ------------------------- Batch round 3, loss: 0.5804 -------------------------
2023-03-25 18:58:30,626 : [INFO]  ------------------------- Batch 359, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:30,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:30,646 : [INFO]  Batch number 359 model fetched from the server
2023-03-25 18:58:30,646 : [INFO]  ################ Batch 359: final global model evalution after 3 rounds ################
2023-03-25 18:58:31,920 : [INFO]  Batch 359: Training set : loss - 0.5923, accuracy - 0.6685, recall - 0.8478, AUC - 0.823, F1 - 0.7189, precision - 0.624, training time - -7.0 seconds
2023-03-25 18:58:31,920 : [INFO]  Batch 359: Testing set : loss - 0.5883, accuracy - 0.6667, recall - 0.8725, AUC - 0.8342, F1 - 0.7236, precision - 0.6181
2023-03-25 18:58:31,932 : [INFO]  Batch 360 initialized 
2023-03-25 18:58:32,386 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:33,255 : [INFO]  ------------------------- Batch 360 training: round 1 -------------------------
2023-03-25 18:58:36,822 : [INFO]  ------------------------- Batch round 1, loss: 0.5869 -------------------------
2023-03-25 18:58:36,822 : [INFO]  ------------------------- Batch 360, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:36,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:36,838 : [INFO]  ------------------------- Batch 360 training: round 2 -------------------------
2023-03-25 18:58:38,686 : [INFO]  ------------------------- Batch round 2, loss: 0.5904 -------------------------
2023-03-25 18:58:38,686 : [INFO]  ------------------------- Batch 360, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:38,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:38,709 : [INFO]  ------------------------- Batch 360 training: round 3 -------------------------
2023-03-25 18:58:40,567 : [INFO]  ------------------------- Batch round 3, loss: 0.5921 -------------------------
2023-03-25 18:58:40,568 : [INFO]  ------------------------- Batch 360, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:40,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:40,591 : [INFO]  Batch number 360 model fetched from the server
2023-03-25 18:58:40,591 : [INFO]  ################ Batch 360: final global model evalution after 3 rounds ################
2023-03-25 18:58:41,871 : [INFO]  Batch 360: Training set : loss - 0.6119, accuracy - 0.6359, recall - 0.7826, AUC - 0.784, F1 - 0.6825, precision - 0.605, training time - -7.0 seconds
2023-03-25 18:58:41,871 : [INFO]  Batch 360: Testing set : loss - 0.5878, accuracy - 0.6912, recall - 0.8039, AUC - 0.8079, F1 - 0.7225, precision - 0.656
2023-03-25 18:58:41,879 : [INFO]  Batch 361 initialized 
2023-03-25 18:58:42,342 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:43,203 : [INFO]  ------------------------- Batch 361 training: round 1 -------------------------
2023-03-25 18:58:46,757 : [INFO]  ------------------------- Batch round 1, loss: 0.5726 -------------------------
2023-03-25 18:58:46,757 : [INFO]  ------------------------- Batch 361, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:46,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:46,774 : [INFO]  ------------------------- Batch 361 training: round 2 -------------------------
2023-03-25 18:58:48,640 : [INFO]  ------------------------- Batch round 2, loss: 0.5761 -------------------------
2023-03-25 18:58:48,640 : [INFO]  ------------------------- Batch 361, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:48,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:48,694 : [INFO]  ------------------------- Batch 361 training: round 3 -------------------------
2023-03-25 18:58:50,537 : [INFO]  ------------------------- Batch round 3, loss: 0.5749 -------------------------
2023-03-25 18:58:50,537 : [INFO]  ------------------------- Batch 361, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:50,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:50,586 : [INFO]  Batch number 361 model fetched from the server
2023-03-25 18:58:50,586 : [INFO]  ################ Batch 361: final global model evalution after 3 rounds ################
2023-03-25 18:58:51,830 : [INFO]  Batch 361: Training set : loss - 0.5818, accuracy - 0.7011, recall - 0.8478, AUC - 0.826, F1 - 0.7393, precision - 0.6555, training time - -7.0 seconds
2023-03-25 18:58:51,830 : [INFO]  Batch 361: Testing set : loss - 0.5686, accuracy - 0.7108, recall - 0.7941, AUC - 0.8308, F1 - 0.733, precision - 0.6807
2023-03-25 18:58:51,838 : [INFO]  Batch 362 initialized 
2023-03-25 18:58:52,285 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:53,159 : [INFO]  ------------------------- Batch 362 training: round 1 -------------------------
2023-03-25 18:58:56,914 : [INFO]  ------------------------- Batch round 1, loss: 0.5877 -------------------------
2023-03-25 18:58:56,914 : [INFO]  ------------------------- Batch 362, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:56,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:56,931 : [INFO]  ------------------------- Batch 362 training: round 2 -------------------------
2023-03-25 18:58:58,859 : [INFO]  ------------------------- Batch round 2, loss: 0.5853 -------------------------
2023-03-25 18:58:58,859 : [INFO]  ------------------------- Batch 362, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:58,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:58,876 : [INFO]  ------------------------- Batch 362 training: round 3 -------------------------
2023-03-25 18:59:00,781 : [INFO]  ------------------------- Batch round 3, loss: 0.5939 -------------------------
2023-03-25 18:59:00,781 : [INFO]  ------------------------- Batch 362, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:00,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:00,799 : [INFO]  Batch number 362 model fetched from the server
2023-03-25 18:59:00,799 : [INFO]  ################ Batch 362: final global model evalution after 3 rounds ################
2023-03-25 18:59:02,053 : [INFO]  Batch 362: Training set : loss - 0.5993, accuracy - 0.6685, recall - 0.837, AUC - 0.808, F1 - 0.7163, precision - 0.626, training time - -8.0 seconds
2023-03-25 18:59:02,053 : [INFO]  Batch 362: Testing set : loss - 0.5816, accuracy - 0.7059, recall - 0.8137, AUC - 0.8266, F1 - 0.7345, precision - 0.6694
2023-03-25 18:59:02,060 : [INFO]  Batch 363 initialized 
2023-03-25 18:59:02,536 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:03,453 : [INFO]  ------------------------- Batch 363 training: round 1 -------------------------
2023-03-25 18:59:07,125 : [INFO]  ------------------------- Batch round 1, loss: 0.5883 -------------------------
2023-03-25 18:59:07,125 : [INFO]  ------------------------- Batch 363, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:07,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:07,141 : [INFO]  ------------------------- Batch 363 training: round 2 -------------------------
2023-03-25 18:59:09,009 : [INFO]  ------------------------- Batch round 2, loss: 0.601 -------------------------
2023-03-25 18:59:09,009 : [INFO]  ------------------------- Batch 363, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:09,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:09,052 : [INFO]  ------------------------- Batch 363 training: round 3 -------------------------
2023-03-25 18:59:10,922 : [INFO]  ------------------------- Batch round 3, loss: 0.5942 -------------------------
2023-03-25 18:59:10,922 : [INFO]  ------------------------- Batch 363, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:10,938 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:10,940 : [INFO]  Batch number 363 model fetched from the server
2023-03-25 18:59:10,940 : [INFO]  ################ Batch 363: final global model evalution after 3 rounds ################
2023-03-25 18:59:12,180 : [INFO]  Batch 363: Training set : loss - 0.6073, accuracy - 0.6467, recall - 0.837, AUC - 0.7959, F1 - 0.7032, precision - 0.6063, training time - -7.0 seconds
2023-03-25 18:59:12,180 : [INFO]  Batch 363: Testing set : loss - 0.608, accuracy - 0.6176, recall - 0.7745, AUC - 0.7922, F1 - 0.6695, precision - 0.5896
2023-03-25 18:59:12,204 : [INFO]  Batch 364 initialized 
2023-03-25 18:59:12,669 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:13,577 : [INFO]  ------------------------- Batch 364 training: round 1 -------------------------
2023-03-25 18:59:17,231 : [INFO]  ------------------------- Batch round 1, loss: 0.5911 -------------------------
2023-03-25 18:59:17,231 : [INFO]  ------------------------- Batch 364, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:17,246 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:17,249 : [INFO]  ------------------------- Batch 364 training: round 2 -------------------------
2023-03-25 18:59:19,157 : [INFO]  ------------------------- Batch round 2, loss: 0.5916 -------------------------
2023-03-25 18:59:19,157 : [INFO]  ------------------------- Batch 364, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:19,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:19,190 : [INFO]  ------------------------- Batch 364 training: round 3 -------------------------
2023-03-25 18:59:21,064 : [INFO]  ------------------------- Batch round 3, loss: 0.5858 -------------------------
2023-03-25 18:59:21,064 : [INFO]  ------------------------- Batch 364, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:21,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:21,081 : [INFO]  Batch number 364 model fetched from the server
2023-03-25 18:59:21,081 : [INFO]  ################ Batch 364: final global model evalution after 3 rounds ################
2023-03-25 18:59:22,316 : [INFO]  Batch 364: Training set : loss - 0.6034, accuracy - 0.625, recall - 0.7717, AUC - 0.7825, F1 - 0.673, precision - 0.5966, training time - -8.0 seconds
2023-03-25 18:59:22,316 : [INFO]  Batch 364: Testing set : loss - 0.5706, accuracy - 0.7353, recall - 0.8627, AUC - 0.8416, F1 - 0.7652, precision - 0.6875
2023-03-25 18:59:22,327 : [INFO]  Batch 365 initialized 
2023-03-25 18:59:22,780 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:23,672 : [INFO]  ------------------------- Batch 365 training: round 1 -------------------------
2023-03-25 18:59:27,109 : [INFO]  ------------------------- Batch round 1, loss: 0.5726 -------------------------
2023-03-25 18:59:27,109 : [INFO]  ------------------------- Batch 365, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:27,459 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:27,461 : [INFO]  ------------------------- Batch 365 training: round 2 -------------------------
2023-03-25 18:59:29,236 : [INFO]  ------------------------- Batch round 2, loss: 0.5756 -------------------------
2023-03-25 18:59:29,236 : [INFO]  ------------------------- Batch 365, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:29,289 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:29,292 : [INFO]  ------------------------- Batch 365 training: round 3 -------------------------
2023-03-25 18:59:31,075 : [INFO]  ------------------------- Batch round 3, loss: 0.5763 -------------------------
2023-03-25 18:59:31,075 : [INFO]  ------------------------- Batch 365, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:31,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:31,158 : [INFO]  Batch number 365 model fetched from the server
2023-03-25 18:59:31,158 : [INFO]  ################ Batch 365: final global model evalution after 3 rounds ################
2023-03-25 18:59:32,368 : [INFO]  Batch 365: Training set : loss - 0.5789, accuracy - 0.6793, recall - 0.8478, AUC - 0.8289, F1 - 0.7256, precision - 0.6341, training time - -7.0 seconds
2023-03-25 18:59:32,368 : [INFO]  Batch 365: Testing set : loss - 0.5924, accuracy - 0.7108, recall - 0.8333, AUC - 0.8038, F1 - 0.7424, precision - 0.6693
2023-03-25 18:59:32,376 : [INFO]  Batch 366 initialized 
2023-03-25 18:59:32,829 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:33,742 : [INFO]  ------------------------- Batch 366 training: round 1 -------------------------
2023-03-25 18:59:37,203 : [INFO]  ------------------------- Batch round 1, loss: 0.5942 -------------------------
2023-03-25 18:59:37,204 : [INFO]  ------------------------- Batch 366, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:37,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:37,234 : [INFO]  ------------------------- Batch 366 training: round 2 -------------------------
2023-03-25 18:59:39,076 : [INFO]  ------------------------- Batch round 2, loss: 0.5879 -------------------------
2023-03-25 18:59:39,076 : [INFO]  ------------------------- Batch 366, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:39,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:39,093 : [INFO]  ------------------------- Batch 366 training: round 3 -------------------------
2023-03-25 18:59:40,896 : [INFO]  ------------------------- Batch round 3, loss: 0.5903 -------------------------
2023-03-25 18:59:40,896 : [INFO]  ------------------------- Batch 366, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:40,910 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:40,912 : [INFO]  Batch number 366 model fetched from the server
2023-03-25 18:59:40,912 : [INFO]  ################ Batch 366: final global model evalution after 3 rounds ################
2023-03-25 18:59:42,115 : [INFO]  Batch 366: Training set : loss - 0.6045, accuracy - 0.663, recall - 0.8913, AUC - 0.8293, F1 - 0.7257, precision - 0.6119, training time - -7.0 seconds
2023-03-25 18:59:42,115 : [INFO]  Batch 366: Testing set : loss - 0.601, accuracy - 0.6373, recall - 0.7451, AUC - 0.7753, F1 - 0.6726, precision - 0.6129
2023-03-25 18:59:42,124 : [INFO]  Batch 367 initialized 
2023-03-25 18:59:42,584 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:43,484 : [INFO]  ------------------------- Batch 367 training: round 1 -------------------------
2023-03-25 18:59:46,932 : [INFO]  ------------------------- Batch round 1, loss: 0.5676 -------------------------
2023-03-25 18:59:46,932 : [INFO]  ------------------------- Batch 367, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:46,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:46,948 : [INFO]  ------------------------- Batch 367 training: round 2 -------------------------
2023-03-25 18:59:48,705 : [INFO]  ------------------------- Batch round 2, loss: 0.5595 -------------------------
2023-03-25 18:59:48,706 : [INFO]  ------------------------- Batch 367, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:48,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:48,751 : [INFO]  ------------------------- Batch 367 training: round 3 -------------------------
2023-03-25 18:59:50,462 : [INFO]  ------------------------- Batch round 3, loss: 0.5647 -------------------------
2023-03-25 18:59:50,462 : [INFO]  ------------------------- Batch 367, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:50,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:50,511 : [INFO]  Batch number 367 model fetched from the server
2023-03-25 18:59:50,511 : [INFO]  ################ Batch 367: final global model evalution after 3 rounds ################
2023-03-25 18:59:51,677 : [INFO]  Batch 367: Training set : loss - 0.5652, accuracy - 0.7283, recall - 0.8804, AUC - 0.8553, F1 - 0.7642, precision - 0.675, training time - -7.0 seconds
2023-03-25 18:59:51,677 : [INFO]  Batch 367: Testing set : loss - 0.5945, accuracy - 0.6569, recall - 0.8137, AUC - 0.8059, F1 - 0.7034, precision - 0.6194
2023-03-25 18:59:51,696 : [INFO]  Batch 368 initialized 
2023-03-25 18:59:52,154 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:53,043 : [INFO]  ------------------------- Batch 368 training: round 1 -------------------------
2023-03-25 18:59:56,662 : [INFO]  ------------------------- Batch round 1, loss: 0.598 -------------------------
2023-03-25 18:59:56,662 : [INFO]  ------------------------- Batch 368, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:56,677 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:56,679 : [INFO]  ------------------------- Batch 368 training: round 2 -------------------------
2023-03-25 18:59:58,521 : [INFO]  ------------------------- Batch round 2, loss: 0.5932 -------------------------
2023-03-25 18:59:58,521 : [INFO]  ------------------------- Batch 368, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:58,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:58,539 : [INFO]  ------------------------- Batch 368 training: round 3 -------------------------
2023-03-25 19:00:00,415 : [INFO]  ------------------------- Batch round 3, loss: 0.5998 -------------------------
2023-03-25 19:00:00,415 : [INFO]  ------------------------- Batch 368, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:00,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:00,433 : [INFO]  Batch number 368 model fetched from the server
2023-03-25 19:00:00,433 : [INFO]  ################ Batch 368: final global model evalution after 3 rounds ################
2023-03-25 19:00:01,657 : [INFO]  Batch 368: Training set : loss - 0.6067, accuracy - 0.663, recall - 0.7826, AUC - 0.7726, F1 - 0.699, precision - 0.6316, training time - -7.0 seconds
2023-03-25 19:00:01,658 : [INFO]  Batch 368: Testing set : loss - 0.5748, accuracy - 0.6912, recall - 0.8333, AUC - 0.8346, F1 - 0.7296, precision - 0.6489
2023-03-25 19:00:01,669 : [INFO]  Batch 369 initialized 
2023-03-25 19:00:02,142 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:03,073 : [INFO]  ------------------------- Batch 369 training: round 1 -------------------------
2023-03-25 19:00:06,652 : [INFO]  ------------------------- Batch round 1, loss: 0.573 -------------------------
2023-03-25 19:00:06,652 : [INFO]  ------------------------- Batch 369, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:06,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:06,679 : [INFO]  ------------------------- Batch 369 training: round 2 -------------------------
2023-03-25 19:00:08,514 : [INFO]  ------------------------- Batch round 2, loss: 0.5793 -------------------------
2023-03-25 19:00:08,515 : [INFO]  ------------------------- Batch 369, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:08,571 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:08,573 : [INFO]  ------------------------- Batch 369 training: round 3 -------------------------
2023-03-25 19:00:10,414 : [INFO]  ------------------------- Batch round 3, loss: 0.5745 -------------------------
2023-03-25 19:00:10,414 : [INFO]  ------------------------- Batch 369, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:10,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:10,476 : [INFO]  Batch number 369 model fetched from the server
2023-03-25 19:00:10,477 : [INFO]  ################ Batch 369: final global model evalution after 3 rounds ################
2023-03-25 19:00:11,709 : [INFO]  Batch 369: Training set : loss - 0.5803, accuracy - 0.6848, recall - 0.8043, AUC - 0.8095, F1 - 0.7184, precision - 0.6491, training time - -7.0 seconds
2023-03-25 19:00:11,709 : [INFO]  Batch 369: Testing set : loss - 0.6046, accuracy - 0.6373, recall - 0.7451, AUC - 0.7713, F1 - 0.6726, precision - 0.6129
2023-03-25 19:00:11,716 : [INFO]  Batch 370 initialized 
2023-03-25 19:00:12,167 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:13,073 : [INFO]  ------------------------- Batch 370 training: round 1 -------------------------
2023-03-25 19:00:16,608 : [INFO]  ------------------------- Batch round 1, loss: 0.5789 -------------------------
2023-03-25 19:00:16,609 : [INFO]  ------------------------- Batch 370, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:16,677 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:16,679 : [INFO]  ------------------------- Batch 370 training: round 2 -------------------------
2023-03-25 19:00:18,492 : [INFO]  ------------------------- Batch round 2, loss: 0.5702 -------------------------
2023-03-25 19:00:18,492 : [INFO]  ------------------------- Batch 370, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:18,585 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:18,587 : [INFO]  ------------------------- Batch 370 training: round 3 -------------------------
2023-03-25 19:00:20,594 : [INFO]  ------------------------- Batch round 3, loss: 0.5769 -------------------------
2023-03-25 19:00:20,594 : [INFO]  ------------------------- Batch 370, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:20,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:20,611 : [INFO]  Batch number 370 model fetched from the server
2023-03-25 19:00:20,611 : [INFO]  ################ Batch 370: final global model evalution after 3 rounds ################
2023-03-25 19:00:21,814 : [INFO]  Batch 370: Training set : loss - 0.583, accuracy - 0.7011, recall - 0.8587, AUC - 0.842, F1 - 0.7418, precision - 0.6529, training time - -8.0 seconds
2023-03-25 19:00:21,815 : [INFO]  Batch 370: Testing set : loss - 0.5637, accuracy - 0.7255, recall - 0.8725, AUC - 0.8667, F1 - 0.7607, precision - 0.6742
2023-03-25 19:00:21,829 : [INFO]  Batch 371 initialized 
2023-03-25 19:00:22,281 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:23,200 : [INFO]  ------------------------- Batch 371 training: round 1 -------------------------
2023-03-25 19:00:26,666 : [INFO]  ------------------------- Batch round 1, loss: 0.571 -------------------------
2023-03-25 19:00:26,666 : [INFO]  ------------------------- Batch 371, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:26,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:26,767 : [INFO]  ------------------------- Batch 371 training: round 2 -------------------------
2023-03-25 19:00:28,811 : [INFO]  ------------------------- Batch round 2, loss: 0.5703 -------------------------
2023-03-25 19:00:28,812 : [INFO]  ------------------------- Batch 371, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:28,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:28,828 : [INFO]  ------------------------- Batch 371 training: round 3 -------------------------
2023-03-25 19:00:30,653 : [INFO]  ------------------------- Batch round 3, loss: 0.5715 -------------------------
2023-03-25 19:00:30,653 : [INFO]  ------------------------- Batch 371, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:30,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:30,720 : [INFO]  Batch number 371 model fetched from the server
2023-03-25 19:00:30,720 : [INFO]  ################ Batch 371: final global model evalution after 3 rounds ################
2023-03-25 19:00:31,950 : [INFO]  Batch 371: Training set : loss - 0.575, accuracy - 0.7283, recall - 0.9022, AUC - 0.8541, F1 - 0.7685, precision - 0.6694, training time - -8.0 seconds
2023-03-25 19:00:31,950 : [INFO]  Batch 371: Testing set : loss - 0.5823, accuracy - 0.6716, recall - 0.8039, AUC - 0.8092, F1 - 0.71, precision - 0.6357
2023-03-25 19:00:31,961 : [INFO]  Batch 372 initialized 
2023-03-25 19:00:32,418 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:33,351 : [INFO]  ------------------------- Batch 372 training: round 1 -------------------------
2023-03-25 19:00:37,005 : [INFO]  ------------------------- Batch round 1, loss: 0.5781 -------------------------
2023-03-25 19:00:37,005 : [INFO]  ------------------------- Batch 372, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:37,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:37,022 : [INFO]  ------------------------- Batch 372 training: round 2 -------------------------
2023-03-25 19:00:38,871 : [INFO]  ------------------------- Batch round 2, loss: 0.5872 -------------------------
2023-03-25 19:00:38,871 : [INFO]  ------------------------- Batch 372, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:38,930 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:38,932 : [INFO]  ------------------------- Batch 372 training: round 3 -------------------------
2023-03-25 19:00:40,711 : [INFO]  ------------------------- Batch round 3, loss: 0.5873 -------------------------
2023-03-25 19:00:40,711 : [INFO]  ------------------------- Batch 372, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:40,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:40,772 : [INFO]  Batch number 372 model fetched from the server
2023-03-25 19:00:40,772 : [INFO]  ################ Batch 372: final global model evalution after 3 rounds ################
2023-03-25 19:00:41,961 : [INFO]  Batch 372: Training set : loss - 0.5981, accuracy - 0.6576, recall - 0.8152, AUC - 0.8034, F1 - 0.7042, precision - 0.6198, training time - -7.0 seconds
2023-03-25 19:00:41,961 : [INFO]  Batch 372: Testing set : loss - 0.6037, accuracy - 0.6225, recall - 0.7745, AUC - 0.7932, F1 - 0.6723, precision - 0.594
2023-03-25 19:00:41,975 : [INFO]  Batch 373 initialized 
2023-03-25 19:00:42,428 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:43,331 : [INFO]  ------------------------- Batch 373 training: round 1 -------------------------
2023-03-25 19:00:46,926 : [INFO]  ------------------------- Batch round 1, loss: 0.5958 -------------------------
2023-03-25 19:00:46,926 : [INFO]  ------------------------- Batch 373, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:47,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:47,071 : [INFO]  ------------------------- Batch 373 training: round 2 -------------------------
2023-03-25 19:00:48,867 : [INFO]  ------------------------- Batch round 2, loss: 0.5922 -------------------------
2023-03-25 19:00:48,868 : [INFO]  ------------------------- Batch 373, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:49,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:49,024 : [INFO]  ------------------------- Batch 373 training: round 3 -------------------------
2023-03-25 19:00:50,888 : [INFO]  ------------------------- Batch round 3, loss: 0.5952 -------------------------
2023-03-25 19:00:50,889 : [INFO]  ------------------------- Batch 373, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:51,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:51,044 : [INFO]  Batch number 373 model fetched from the server
2023-03-25 19:00:51,044 : [INFO]  ################ Batch 373: final global model evalution after 3 rounds ################
2023-03-25 19:00:52,224 : [INFO]  Batch 373: Training set : loss - 0.6091, accuracy - 0.6359, recall - 0.7935, AUC - 0.7832, F1 - 0.6854, precision - 0.6033, training time - -8.0 seconds
2023-03-25 19:00:52,224 : [INFO]  Batch 373: Testing set : loss - 0.57, accuracy - 0.7353, recall - 0.8529, AUC - 0.8381, F1 - 0.7632, precision - 0.6905
2023-03-25 19:00:52,239 : [INFO]  Batch 374 initialized 
2023-03-25 19:00:52,705 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:53,629 : [INFO]  ------------------------- Batch 374 training: round 1 -------------------------
2023-03-25 19:00:57,113 : [INFO]  ------------------------- Batch round 1, loss: 0.5825 -------------------------
2023-03-25 19:00:57,114 : [INFO]  ------------------------- Batch 374, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:57,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:57,182 : [INFO]  ------------------------- Batch 374 training: round 2 -------------------------
2023-03-25 19:00:59,038 : [INFO]  ------------------------- Batch round 2, loss: 0.5851 -------------------------
2023-03-25 19:00:59,038 : [INFO]  ------------------------- Batch 374, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:59,103 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:59,105 : [INFO]  ------------------------- Batch 374 training: round 3 -------------------------
2023-03-25 19:01:00,957 : [INFO]  ------------------------- Batch round 3, loss: 0.5816 -------------------------
2023-03-25 19:01:00,957 : [INFO]  ------------------------- Batch 374, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:00,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:00,997 : [INFO]  Batch number 374 model fetched from the server
2023-03-25 19:01:00,998 : [INFO]  ################ Batch 374: final global model evalution after 3 rounds ################
2023-03-25 19:01:02,200 : [INFO]  Batch 374: Training set : loss - 0.5938, accuracy - 0.6739, recall - 0.837, AUC - 0.8155, F1 - 0.7196, precision - 0.6311, training time - -7.0 seconds
2023-03-25 19:01:02,200 : [INFO]  Batch 374: Testing set : loss - 0.5895, accuracy - 0.6961, recall - 0.7745, AUC - 0.8026, F1 - 0.7182, precision - 0.6695
2023-03-25 19:01:02,209 : [INFO]  Batch 375 initialized 
2023-03-25 19:01:02,663 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:03,596 : [INFO]  ------------------------- Batch 375 training: round 1 -------------------------
2023-03-25 19:01:07,117 : [INFO]  ------------------------- Batch round 1, loss: 0.5866 -------------------------
2023-03-25 19:01:07,118 : [INFO]  ------------------------- Batch 375, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:07,132 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:07,134 : [INFO]  ------------------------- Batch 375 training: round 2 -------------------------
2023-03-25 19:01:08,951 : [INFO]  ------------------------- Batch round 2, loss: 0.5827 -------------------------
2023-03-25 19:01:08,951 : [INFO]  ------------------------- Batch 375, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:08,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:08,967 : [INFO]  ------------------------- Batch 375 training: round 3 -------------------------
2023-03-25 19:01:10,820 : [INFO]  ------------------------- Batch round 3, loss: 0.5871 -------------------------
2023-03-25 19:01:10,820 : [INFO]  ------------------------- Batch 375, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:10,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:10,837 : [INFO]  Batch number 375 model fetched from the server
2023-03-25 19:01:10,837 : [INFO]  ################ Batch 375: final global model evalution after 3 rounds ################
2023-03-25 19:01:12,062 : [INFO]  Batch 375: Training set : loss - 0.5952, accuracy - 0.6467, recall - 0.7717, AUC - 0.7937, F1 - 0.686, precision - 0.6174, training time - -7.0 seconds
2023-03-25 19:01:12,062 : [INFO]  Batch 375: Testing set : loss - 0.5946, accuracy - 0.6814, recall - 0.8431, AUC - 0.8179, F1 - 0.7257, precision - 0.637
2023-03-25 19:01:12,070 : [INFO]  Batch 376 initialized 
2023-03-25 19:01:12,531 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:13,466 : [INFO]  ------------------------- Batch 376 training: round 1 -------------------------
2023-03-25 19:01:17,056 : [INFO]  ------------------------- Batch round 1, loss: 0.5745 -------------------------
2023-03-25 19:01:17,056 : [INFO]  ------------------------- Batch 376, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:17,071 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:17,073 : [INFO]  ------------------------- Batch 376 training: round 2 -------------------------
2023-03-25 19:01:18,929 : [INFO]  ------------------------- Batch round 2, loss: 0.582 -------------------------
2023-03-25 19:01:18,930 : [INFO]  ------------------------- Batch 376, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:18,944 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:18,946 : [INFO]  ------------------------- Batch 376 training: round 3 -------------------------
2023-03-25 19:01:20,789 : [INFO]  ------------------------- Batch round 3, loss: 0.5751 -------------------------
2023-03-25 19:01:20,789 : [INFO]  ------------------------- Batch 376, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:20,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:20,806 : [INFO]  Batch number 376 model fetched from the server
2023-03-25 19:01:20,806 : [INFO]  ################ Batch 376: final global model evalution after 3 rounds ################
2023-03-25 19:01:22,017 : [INFO]  Batch 376: Training set : loss - 0.5842, accuracy - 0.7174, recall - 0.8043, AUC - 0.8134, F1 - 0.74, precision - 0.6852, training time - -7.0 seconds
2023-03-25 19:01:22,017 : [INFO]  Batch 376: Testing set : loss - 0.5784, accuracy - 0.6814, recall - 0.8333, AUC - 0.8462, F1 - 0.7234, precision - 0.6391
2023-03-25 19:01:22,031 : [INFO]  Batch 377 initialized 
2023-03-25 19:01:22,478 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:23,420 : [INFO]  ------------------------- Batch 377 training: round 1 -------------------------
2023-03-25 19:01:26,797 : [INFO]  ------------------------- Batch round 1, loss: 0.5734 -------------------------
2023-03-25 19:01:26,798 : [INFO]  ------------------------- Batch 377, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:26,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:26,863 : [INFO]  ------------------------- Batch 377 training: round 2 -------------------------
2023-03-25 19:01:28,642 : [INFO]  ------------------------- Batch round 2, loss: 0.5729 -------------------------
2023-03-25 19:01:28,643 : [INFO]  ------------------------- Batch 377, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:28,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:28,746 : [INFO]  ------------------------- Batch 377 training: round 3 -------------------------
2023-03-25 19:01:30,509 : [INFO]  ------------------------- Batch round 3, loss: 0.5682 -------------------------
2023-03-25 19:01:30,510 : [INFO]  ------------------------- Batch 377, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:30,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:30,595 : [INFO]  Batch number 377 model fetched from the server
2023-03-25 19:01:30,595 : [INFO]  ################ Batch 377: final global model evalution after 3 rounds ################
2023-03-25 19:01:31,814 : [INFO]  Batch 377: Training set : loss - 0.5831, accuracy - 0.6522, recall - 0.8152, AUC - 0.8269, F1 - 0.7009, precision - 0.6148, training time - -7.0 seconds
2023-03-25 19:01:31,814 : [INFO]  Batch 377: Testing set : loss - 0.5642, accuracy - 0.7157, recall - 0.8824, AUC - 0.881, F1 - 0.7563, precision - 0.6618
2023-03-25 19:01:31,822 : [INFO]  Batch 378 initialized 
2023-03-25 19:01:32,286 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:33,248 : [INFO]  ------------------------- Batch 378 training: round 1 -------------------------
2023-03-25 19:01:36,727 : [INFO]  ------------------------- Batch round 1, loss: 0.577 -------------------------
2023-03-25 19:01:36,727 : [INFO]  ------------------------- Batch 378, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:36,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:36,761 : [INFO]  ------------------------- Batch 378 training: round 2 -------------------------
2023-03-25 19:01:38,566 : [INFO]  ------------------------- Batch round 2, loss: 0.5808 -------------------------
2023-03-25 19:01:38,566 : [INFO]  ------------------------- Batch 378, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:38,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:38,639 : [INFO]  ------------------------- Batch 378 training: round 3 -------------------------
2023-03-25 19:01:40,391 : [INFO]  ------------------------- Batch round 3, loss: 0.5797 -------------------------
2023-03-25 19:01:40,392 : [INFO]  ------------------------- Batch 378, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:40,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:40,460 : [INFO]  Batch number 378 model fetched from the server
2023-03-25 19:01:40,460 : [INFO]  ################ Batch 378: final global model evalution after 3 rounds ################
2023-03-25 19:01:41,652 : [INFO]  Batch 378: Training set : loss - 0.5855, accuracy - 0.7011, recall - 0.837, AUC - 0.8457, F1 - 0.7368, precision - 0.6581, training time - -7.0 seconds
2023-03-25 19:01:41,652 : [INFO]  Batch 378: Testing set : loss - 0.5941, accuracy - 0.6667, recall - 0.7843, AUC - 0.8118, F1 - 0.7018, precision - 0.6349
2023-03-25 19:01:41,675 : [INFO]  Batch 379 initialized 
2023-03-25 19:01:42,121 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:43,032 : [INFO]  ------------------------- Batch 379 training: round 1 -------------------------
2023-03-25 19:01:46,519 : [INFO]  ------------------------- Batch round 1, loss: 0.5616 -------------------------
2023-03-25 19:01:46,519 : [INFO]  ------------------------- Batch 379, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:46,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:46,655 : [INFO]  ------------------------- Batch 379 training: round 2 -------------------------
2023-03-25 19:01:48,300 : [INFO]  ------------------------- Batch round 2, loss: 0.5611 -------------------------
2023-03-25 19:01:48,300 : [INFO]  ------------------------- Batch 379, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:48,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:48,775 : [INFO]  ------------------------- Batch 379 training: round 3 -------------------------
2023-03-25 19:01:50,450 : [INFO]  ------------------------- Batch round 3, loss: 0.5572 -------------------------
2023-03-25 19:01:50,450 : [INFO]  ------------------------- Batch 379, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:50,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:50,657 : [INFO]  Batch number 379 model fetched from the server
2023-03-25 19:01:50,658 : [INFO]  ################ Batch 379: final global model evalution after 3 rounds ################
2023-03-25 19:01:51,867 : [INFO]  Batch 379: Training set : loss - 0.5752, accuracy - 0.712, recall - 0.8696, AUC - 0.8426, F1 - 0.7512, precision - 0.6612, training time - -8.0 seconds
2023-03-25 19:01:51,867 : [INFO]  Batch 379: Testing set : loss - 0.5797, accuracy - 0.6961, recall - 0.8039, AUC - 0.8209, F1 - 0.7257, precision - 0.6613
2023-03-25 19:01:51,880 : [INFO]  Batch 380 initialized 
2023-03-25 19:01:52,326 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:53,272 : [INFO]  ------------------------- Batch 380 training: round 1 -------------------------
2023-03-25 19:01:56,792 : [INFO]  ------------------------- Batch round 1, loss: 0.5866 -------------------------
2023-03-25 19:01:56,792 : [INFO]  ------------------------- Batch 380, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:56,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:56,812 : [INFO]  ------------------------- Batch 380 training: round 2 -------------------------
2023-03-25 19:01:58,583 : [INFO]  ------------------------- Batch round 2, loss: 0.5866 -------------------------
2023-03-25 19:01:58,583 : [INFO]  ------------------------- Batch 380, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:58,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:58,614 : [INFO]  ------------------------- Batch 380 training: round 3 -------------------------
2023-03-25 19:02:00,406 : [INFO]  ------------------------- Batch round 3, loss: 0.5866 -------------------------
2023-03-25 19:02:00,406 : [INFO]  ------------------------- Batch 380, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:00,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:00,429 : [INFO]  Batch number 380 model fetched from the server
2023-03-25 19:02:00,429 : [INFO]  ################ Batch 380: final global model evalution after 3 rounds ################
2023-03-25 19:02:01,637 : [INFO]  Batch 380: Training set : loss - 0.6005, accuracy - 0.6685, recall - 0.8696, AUC - 0.831, F1 - 0.724, precision - 0.6202, training time - -7.0 seconds
2023-03-25 19:02:01,638 : [INFO]  Batch 380: Testing set : loss - 0.585, accuracy - 0.6716, recall - 0.8235, AUC - 0.8189, F1 - 0.7149, precision - 0.6316
2023-03-25 19:02:01,649 : [INFO]  Batch 381 initialized 
2023-03-25 19:02:02,129 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:03,065 : [INFO]  ------------------------- Batch 381 training: round 1 -------------------------
2023-03-25 19:02:06,540 : [INFO]  ------------------------- Batch round 1, loss: 0.598 -------------------------
2023-03-25 19:02:06,540 : [INFO]  ------------------------- Batch 381, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:06,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:06,579 : [INFO]  ------------------------- Batch 381 training: round 2 -------------------------
2023-03-25 19:02:08,315 : [INFO]  ------------------------- Batch round 2, loss: 0.6002 -------------------------
2023-03-25 19:02:08,315 : [INFO]  ------------------------- Batch 381, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:08,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:08,450 : [INFO]  ------------------------- Batch 381 training: round 3 -------------------------
2023-03-25 19:02:10,184 : [INFO]  ------------------------- Batch round 3, loss: 0.6064 -------------------------
2023-03-25 19:02:10,184 : [INFO]  ------------------------- Batch 381, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:10,283 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:10,288 : [INFO]  Batch number 381 model fetched from the server
2023-03-25 19:02:10,288 : [INFO]  ################ Batch 381: final global model evalution after 3 rounds ################
2023-03-25 19:02:11,471 : [INFO]  Batch 381: Training set : loss - 0.6093, accuracy - 0.663, recall - 0.8261, AUC - 0.7906, F1 - 0.7103, precision - 0.623, training time - -7.0 seconds
2023-03-25 19:02:11,471 : [INFO]  Batch 381: Testing set : loss - 0.5595, accuracy - 0.7206, recall - 0.8725, AUC - 0.8802, F1 - 0.7574, precision - 0.6692
2023-03-25 19:02:11,486 : [INFO]  Batch 382 initialized 
2023-03-25 19:02:11,967 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:12,904 : [INFO]  ------------------------- Batch 382 training: round 1 -------------------------
2023-03-25 19:02:16,440 : [INFO]  ------------------------- Batch round 1, loss: 0.5996 -------------------------
2023-03-25 19:02:16,440 : [INFO]  ------------------------- Batch 382, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:16,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:16,457 : [INFO]  ------------------------- Batch 382 training: round 2 -------------------------
2023-03-25 19:02:18,284 : [INFO]  ------------------------- Batch round 2, loss: 0.6069 -------------------------
2023-03-25 19:02:18,284 : [INFO]  ------------------------- Batch 382, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:18,299 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:18,301 : [INFO]  ------------------------- Batch 382 training: round 3 -------------------------
2023-03-25 19:02:20,110 : [INFO]  ------------------------- Batch round 3, loss: 0.6008 -------------------------
2023-03-25 19:02:20,110 : [INFO]  ------------------------- Batch 382, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:20,125 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:20,127 : [INFO]  Batch number 382 model fetched from the server
2023-03-25 19:02:20,127 : [INFO]  ################ Batch 382: final global model evalution after 3 rounds ################
2023-03-25 19:02:21,308 : [INFO]  Batch 382: Training set : loss - 0.617, accuracy - 0.6685, recall - 0.8261, AUC - 0.7818, F1 - 0.7136, precision - 0.6281, training time - -7.0 seconds
2023-03-25 19:02:21,308 : [INFO]  Batch 382: Testing set : loss - 0.585, accuracy - 0.6618, recall - 0.7647, AUC - 0.8033, F1 - 0.6933, precision - 0.6341
2023-03-25 19:02:21,323 : [INFO]  Batch 383 initialized 
2023-03-25 19:02:21,792 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:22,727 : [INFO]  ------------------------- Batch 383 training: round 1 -------------------------
2023-03-25 19:02:26,451 : [INFO]  ------------------------- Batch round 1, loss: 0.5617 -------------------------
2023-03-25 19:02:26,451 : [INFO]  ------------------------- Batch 383, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:26,465 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:26,467 : [INFO]  ------------------------- Batch 383 training: round 2 -------------------------
2023-03-25 19:02:28,326 : [INFO]  ------------------------- Batch round 2, loss: 0.5592 -------------------------
2023-03-25 19:02:28,326 : [INFO]  ------------------------- Batch 383, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:28,341 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:28,344 : [INFO]  ------------------------- Batch 383 training: round 3 -------------------------
2023-03-25 19:02:30,203 : [INFO]  ------------------------- Batch round 3, loss: 0.5564 -------------------------
2023-03-25 19:02:30,203 : [INFO]  ------------------------- Batch 383, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:30,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:30,221 : [INFO]  Batch number 383 model fetched from the server
2023-03-25 19:02:30,221 : [INFO]  ################ Batch 383: final global model evalution after 3 rounds ################
2023-03-25 19:02:31,431 : [INFO]  Batch 383: Training set : loss - 0.567, accuracy - 0.7391, recall - 0.8478, AUC - 0.8475, F1 - 0.7647, precision - 0.6964, training time - -7.0 seconds
2023-03-25 19:02:31,431 : [INFO]  Batch 383: Testing set : loss - 0.5675, accuracy - 0.7059, recall - 0.902, AUC - 0.8663, F1 - 0.7541, precision - 0.6479
2023-03-25 19:02:31,446 : [INFO]  Batch 384 initialized 
2023-03-25 19:02:31,897 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:32,824 : [INFO]  ------------------------- Batch 384 training: round 1 -------------------------
2023-03-25 19:02:36,355 : [INFO]  ------------------------- Batch round 1, loss: 0.5833 -------------------------
2023-03-25 19:02:36,355 : [INFO]  ------------------------- Batch 384, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:36,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:36,374 : [INFO]  ------------------------- Batch 384 training: round 2 -------------------------
2023-03-25 19:02:38,222 : [INFO]  ------------------------- Batch round 2, loss: 0.5792 -------------------------
2023-03-25 19:02:38,222 : [INFO]  ------------------------- Batch 384, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:38,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:38,239 : [INFO]  ------------------------- Batch 384 training: round 3 -------------------------
2023-03-25 19:02:40,003 : [INFO]  ------------------------- Batch round 3, loss: 0.5799 -------------------------
2023-03-25 19:02:40,003 : [INFO]  ------------------------- Batch 384, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:40,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:40,021 : [INFO]  Batch number 384 model fetched from the server
2023-03-25 19:02:40,021 : [INFO]  ################ Batch 384: final global model evalution after 3 rounds ################
2023-03-25 19:02:41,264 : [INFO]  Batch 384: Training set : loss - 0.5932, accuracy - 0.6685, recall - 0.8587, AUC - 0.8332, F1 - 0.7215, precision - 0.622, training time - -7.0 seconds
2023-03-25 19:02:41,265 : [INFO]  Batch 384: Testing set : loss - 0.5832, accuracy - 0.6912, recall - 0.8039, AUC - 0.823, F1 - 0.7225, precision - 0.656
2023-03-25 19:02:41,277 : [INFO]  Batch 385 initialized 
2023-03-25 19:02:41,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:42,696 : [INFO]  ------------------------- Batch 385 training: round 1 -------------------------
2023-03-25 19:02:46,202 : [INFO]  ------------------------- Batch round 1, loss: 0.5983 -------------------------
2023-03-25 19:02:46,202 : [INFO]  ------------------------- Batch 385, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:46,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:46,219 : [INFO]  ------------------------- Batch 385 training: round 2 -------------------------
2023-03-25 19:02:48,030 : [INFO]  ------------------------- Batch round 2, loss: 0.5924 -------------------------
2023-03-25 19:02:48,030 : [INFO]  ------------------------- Batch 385, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:48,047 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:48,049 : [INFO]  ------------------------- Batch 385 training: round 3 -------------------------
2023-03-25 19:02:49,875 : [INFO]  ------------------------- Batch round 3, loss: 0.5938 -------------------------
2023-03-25 19:02:49,875 : [INFO]  ------------------------- Batch 385, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:49,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:49,892 : [INFO]  Batch number 385 model fetched from the server
2023-03-25 19:02:49,893 : [INFO]  ################ Batch 385: final global model evalution after 3 rounds ################
2023-03-25 19:02:51,108 : [INFO]  Batch 385: Training set : loss - 0.6045, accuracy - 0.6848, recall - 0.837, AUC - 0.8081, F1 - 0.7264, precision - 0.6417, training time - -7.0 seconds
2023-03-25 19:02:51,108 : [INFO]  Batch 385: Testing set : loss - 0.5673, accuracy - 0.7255, recall - 0.8333, AUC - 0.8527, F1 - 0.7522, precision - 0.6855
2023-03-25 19:02:51,116 : [INFO]  Batch 386 initialized 
2023-03-25 19:02:51,566 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:52,498 : [INFO]  ------------------------- Batch 386 training: round 1 -------------------------
2023-03-25 19:02:55,960 : [INFO]  ------------------------- Batch round 1, loss: 0.5848 -------------------------
2023-03-25 19:02:55,960 : [INFO]  ------------------------- Batch 386, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:55,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:55,978 : [INFO]  ------------------------- Batch 386 training: round 2 -------------------------
2023-03-25 19:02:57,892 : [INFO]  ------------------------- Batch round 2, loss: 0.5954 -------------------------
2023-03-25 19:02:57,893 : [INFO]  ------------------------- Batch 386, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:57,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:57,915 : [INFO]  ------------------------- Batch 386 training: round 3 -------------------------
2023-03-25 19:02:59,785 : [INFO]  ------------------------- Batch round 3, loss: 0.5931 -------------------------
2023-03-25 19:02:59,785 : [INFO]  ------------------------- Batch 386, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:59,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:59,804 : [INFO]  Batch number 386 model fetched from the server
2023-03-25 19:02:59,804 : [INFO]  ################ Batch 386: final global model evalution after 3 rounds ################
2023-03-25 19:03:00,997 : [INFO]  Batch 386: Training set : loss - 0.6032, accuracy - 0.6576, recall - 0.7174, AUC - 0.7683, F1 - 0.6769, precision - 0.6408, training time - -7.0 seconds
2023-03-25 19:03:00,997 : [INFO]  Batch 386: Testing set : loss - 0.5799, accuracy - 0.701, recall - 0.8431, AUC - 0.8405, F1 - 0.7382, precision - 0.6565
2023-03-25 19:03:01,016 : [INFO]  Batch 387 initialized 
2023-03-25 19:03:01,475 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:02,406 : [INFO]  ------------------------- Batch 387 training: round 1 -------------------------
2023-03-25 19:03:05,965 : [INFO]  ------------------------- Batch round 1, loss: 0.5579 -------------------------
2023-03-25 19:03:05,965 : [INFO]  ------------------------- Batch 387, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:06,002 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:06,005 : [INFO]  ------------------------- Batch 387 training: round 2 -------------------------
2023-03-25 19:03:07,859 : [INFO]  ------------------------- Batch round 2, loss: 0.5533 -------------------------
2023-03-25 19:03:07,859 : [INFO]  ------------------------- Batch 387, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:07,875 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:07,877 : [INFO]  ------------------------- Batch 387 training: round 3 -------------------------
2023-03-25 19:03:09,715 : [INFO]  ------------------------- Batch round 3, loss: 0.5566 -------------------------
2023-03-25 19:03:09,715 : [INFO]  ------------------------- Batch 387, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:09,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:09,752 : [INFO]  Batch number 387 model fetched from the server
2023-03-25 19:03:09,752 : [INFO]  ################ Batch 387: final global model evalution after 3 rounds ################
2023-03-25 19:03:10,990 : [INFO]  Batch 387: Training set : loss - 0.5585, accuracy - 0.7554, recall - 0.8913, AUC - 0.8778, F1 - 0.7847, precision - 0.7009, training time - -7.0 seconds
2023-03-25 19:03:10,990 : [INFO]  Batch 387: Testing set : loss - 0.5737, accuracy - 0.7402, recall - 0.7941, AUC - 0.8144, F1 - 0.7535, precision - 0.7168
2023-03-25 19:03:11,039 : [INFO]  Batch 388 initialized 
2023-03-25 19:03:11,482 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:12,421 : [INFO]  ------------------------- Batch 388 training: round 1 -------------------------
2023-03-25 19:03:15,882 : [INFO]  ------------------------- Batch round 1, loss: 0.5904 -------------------------
2023-03-25 19:03:15,882 : [INFO]  ------------------------- Batch 388, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:15,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:15,899 : [INFO]  ------------------------- Batch 388 training: round 2 -------------------------
2023-03-25 19:03:17,696 : [INFO]  ------------------------- Batch round 2, loss: 0.5934 -------------------------
2023-03-25 19:03:17,696 : [INFO]  ------------------------- Batch 388, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:17,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:17,715 : [INFO]  ------------------------- Batch 388 training: round 3 -------------------------
2023-03-25 19:03:19,529 : [INFO]  ------------------------- Batch round 3, loss: 0.5958 -------------------------
2023-03-25 19:03:19,529 : [INFO]  ------------------------- Batch 388, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:19,545 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:19,548 : [INFO]  Batch number 388 model fetched from the server
2023-03-25 19:03:19,548 : [INFO]  ################ Batch 388: final global model evalution after 3 rounds ################
2023-03-25 19:03:20,758 : [INFO]  Batch 388: Training set : loss - 0.6012, accuracy - 0.6522, recall - 0.8478, AUC - 0.8055, F1 - 0.7091, precision - 0.6094, training time - -7.0 seconds
2023-03-25 19:03:20,758 : [INFO]  Batch 388: Testing set : loss - 0.6142, accuracy - 0.6569, recall - 0.7451, AUC - 0.7381, F1 - 0.6847, precision - 0.6333
2023-03-25 19:03:20,766 : [INFO]  Batch 389 initialized 
2023-03-25 19:03:21,221 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:22,167 : [INFO]  ------------------------- Batch 389 training: round 1 -------------------------
2023-03-25 19:03:25,652 : [INFO]  ------------------------- Batch round 1, loss: 0.5602 -------------------------
2023-03-25 19:03:25,652 : [INFO]  ------------------------- Batch 389, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:25,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:25,706 : [INFO]  ------------------------- Batch 389 training: round 2 -------------------------
2023-03-25 19:03:27,531 : [INFO]  ------------------------- Batch round 2, loss: 0.557 -------------------------
2023-03-25 19:03:27,531 : [INFO]  ------------------------- Batch 389, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:27,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:27,618 : [INFO]  ------------------------- Batch 389 training: round 3 -------------------------
2023-03-25 19:03:29,383 : [INFO]  ------------------------- Batch round 3, loss: 0.5568 -------------------------
2023-03-25 19:03:29,383 : [INFO]  ------------------------- Batch 389, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:29,449 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:29,451 : [INFO]  Batch number 389 model fetched from the server
2023-03-25 19:03:29,451 : [INFO]  ################ Batch 389: final global model evalution after 3 rounds ################
2023-03-25 19:03:30,654 : [INFO]  Batch 389: Training set : loss - 0.5681, accuracy - 0.712, recall - 0.8696, AUC - 0.8524, F1 - 0.7512, precision - 0.6612, training time - -7.0 seconds
2023-03-25 19:03:30,655 : [INFO]  Batch 389: Testing set : loss - 0.5778, accuracy - 0.701, recall - 0.7843, AUC - 0.8053, F1 - 0.724, precision - 0.6723
2023-03-25 19:03:30,666 : [INFO]  Batch 390 initialized 
2023-03-25 19:03:31,153 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:32,096 : [INFO]  ------------------------- Batch 390 training: round 1 -------------------------
2023-03-25 19:03:35,571 : [INFO]  ------------------------- Batch round 1, loss: 0.5563 -------------------------
2023-03-25 19:03:35,571 : [INFO]  ------------------------- Batch 390, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:35,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:35,593 : [INFO]  ------------------------- Batch 390 training: round 2 -------------------------
2023-03-25 19:03:37,386 : [INFO]  ------------------------- Batch round 2, loss: 0.5529 -------------------------
2023-03-25 19:03:37,386 : [INFO]  ------------------------- Batch 390, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:37,405 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:37,407 : [INFO]  ------------------------- Batch 390 training: round 3 -------------------------
2023-03-25 19:03:39,210 : [INFO]  ------------------------- Batch round 3, loss: 0.5608 -------------------------
2023-03-25 19:03:39,211 : [INFO]  ------------------------- Batch 390, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:39,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:39,266 : [INFO]  Batch number 390 model fetched from the server
2023-03-25 19:03:39,266 : [INFO]  ################ Batch 390: final global model evalution after 3 rounds ################
2023-03-25 19:03:40,456 : [INFO]  Batch 390: Training set : loss - 0.563, accuracy - 0.7283, recall - 0.8587, AUC - 0.8616, F1 - 0.7596, precision - 0.681, training time - -7.0 seconds
2023-03-25 19:03:40,456 : [INFO]  Batch 390: Testing set : loss - 0.6048, accuracy - 0.6471, recall - 0.8529, AUC - 0.8227, F1 - 0.7073, precision - 0.6042
2023-03-25 19:03:40,470 : [INFO]  Batch 391 initialized 
2023-03-25 19:03:40,924 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:41,838 : [INFO]  ------------------------- Batch 391 training: round 1 -------------------------
2023-03-25 19:03:45,381 : [INFO]  ------------------------- Batch round 1, loss: 0.5693 -------------------------
2023-03-25 19:03:45,381 : [INFO]  ------------------------- Batch 391, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:45,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:45,401 : [INFO]  ------------------------- Batch 391 training: round 2 -------------------------
2023-03-25 19:03:47,203 : [INFO]  ------------------------- Batch round 2, loss: 0.5696 -------------------------
2023-03-25 19:03:47,203 : [INFO]  ------------------------- Batch 391, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:47,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:47,221 : [INFO]  ------------------------- Batch 391 training: round 3 -------------------------
2023-03-25 19:03:49,035 : [INFO]  ------------------------- Batch round 3, loss: 0.5688 -------------------------
2023-03-25 19:03:49,035 : [INFO]  ------------------------- Batch 391, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:49,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:49,053 : [INFO]  Batch number 391 model fetched from the server
2023-03-25 19:03:49,053 : [INFO]  ################ Batch 391: final global model evalution after 3 rounds ################
2023-03-25 19:03:50,229 : [INFO]  Batch 391: Training set : loss - 0.5852, accuracy - 0.6793, recall - 0.837, AUC - 0.8381, F1 - 0.723, precision - 0.6364, training time - -7.0 seconds
2023-03-25 19:03:50,230 : [INFO]  Batch 391: Testing set : loss - 0.553, accuracy - 0.7451, recall - 0.8922, AUC - 0.8822, F1 - 0.7778, precision - 0.6894
2023-03-25 19:03:50,237 : [INFO]  Batch 392 initialized 
2023-03-25 19:03:50,704 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:51,651 : [INFO]  ------------------------- Batch 392 training: round 1 -------------------------
2023-03-25 19:03:55,246 : [INFO]  ------------------------- Batch round 1, loss: 0.5679 -------------------------
2023-03-25 19:03:55,246 : [INFO]  ------------------------- Batch 392, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:55,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:55,263 : [INFO]  ------------------------- Batch 392 training: round 2 -------------------------
2023-03-25 19:03:57,132 : [INFO]  ------------------------- Batch round 2, loss: 0.5708 -------------------------
2023-03-25 19:03:57,132 : [INFO]  ------------------------- Batch 392, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:57,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:57,150 : [INFO]  ------------------------- Batch 392 training: round 3 -------------------------
2023-03-25 19:03:59,011 : [INFO]  ------------------------- Batch round 3, loss: 0.5686 -------------------------
2023-03-25 19:03:59,011 : [INFO]  ------------------------- Batch 392, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:59,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:59,028 : [INFO]  Batch number 392 model fetched from the server
2023-03-25 19:03:59,029 : [INFO]  ################ Batch 392: final global model evalution after 3 rounds ################
2023-03-25 19:04:00,227 : [INFO]  Batch 392: Training set : loss - 0.5817, accuracy - 0.6576, recall - 0.8152, AUC - 0.8325, F1 - 0.7042, precision - 0.6198, training time - -7.0 seconds
2023-03-25 19:04:00,227 : [INFO]  Batch 392: Testing set : loss - 0.5851, accuracy - 0.7157, recall - 0.8039, AUC - 0.8098, F1 - 0.7387, precision - 0.6833
2023-03-25 19:04:00,245 : [INFO]  Batch 393 initialized 
2023-03-25 19:04:00,699 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:01,647 : [INFO]  ------------------------- Batch 393 training: round 1 -------------------------
2023-03-25 19:04:05,225 : [INFO]  ------------------------- Batch round 1, loss: 0.5969 -------------------------
2023-03-25 19:04:05,225 : [INFO]  ------------------------- Batch 393, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:05,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:05,274 : [INFO]  ------------------------- Batch 393 training: round 2 -------------------------
2023-03-25 19:04:07,178 : [INFO]  ------------------------- Batch round 2, loss: 0.5989 -------------------------
2023-03-25 19:04:07,178 : [INFO]  ------------------------- Batch 393, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:07,193 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:07,195 : [INFO]  ------------------------- Batch 393 training: round 3 -------------------------
2023-03-25 19:04:09,195 : [INFO]  ------------------------- Batch round 3, loss: 0.6 -------------------------
2023-03-25 19:04:09,195 : [INFO]  ------------------------- Batch 393, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:09,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:09,234 : [INFO]  Batch number 393 model fetched from the server
2023-03-25 19:04:09,234 : [INFO]  ################ Batch 393: final global model evalution after 3 rounds ################
2023-03-25 19:04:10,455 : [INFO]  Batch 393: Training set : loss - 0.6189, accuracy - 0.6413, recall - 0.7609, AUC - 0.7525, F1 - 0.6796, precision - 0.614, training time - -8.0 seconds
2023-03-25 19:04:10,455 : [INFO]  Batch 393: Testing set : loss - 0.5661, accuracy - 0.7108, recall - 0.8333, AUC - 0.8395, F1 - 0.7424, precision - 0.6693
2023-03-25 19:04:10,463 : [INFO]  Batch 394 initialized 
2023-03-25 19:04:10,927 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:11,859 : [INFO]  ------------------------- Batch 394 training: round 1 -------------------------
2023-03-25 19:04:15,508 : [INFO]  ------------------------- Batch round 1, loss: 0.5709 -------------------------
2023-03-25 19:04:15,508 : [INFO]  ------------------------- Batch 394, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:15,545 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:15,547 : [INFO]  ------------------------- Batch 394 training: round 2 -------------------------
2023-03-25 19:04:17,373 : [INFO]  ------------------------- Batch round 2, loss: 0.5682 -------------------------
2023-03-25 19:04:17,373 : [INFO]  ------------------------- Batch 394, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:17,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:17,391 : [INFO]  ------------------------- Batch 394 training: round 3 -------------------------
2023-03-25 19:04:19,199 : [INFO]  ------------------------- Batch round 3, loss: 0.5666 -------------------------
2023-03-25 19:04:19,199 : [INFO]  ------------------------- Batch 394, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:19,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:19,217 : [INFO]  Batch number 394 model fetched from the server
2023-03-25 19:04:19,217 : [INFO]  ################ Batch 394: final global model evalution after 3 rounds ################
2023-03-25 19:04:20,430 : [INFO]  Batch 394: Training set : loss - 0.5747, accuracy - 0.7174, recall - 0.8152, AUC - 0.8365, F1 - 0.7426, precision - 0.6818, training time - -7.0 seconds
2023-03-25 19:04:20,430 : [INFO]  Batch 394: Testing set : loss - 0.5569, accuracy - 0.7304, recall - 0.8627, AUC - 0.8745, F1 - 0.7619, precision - 0.6822
2023-03-25 19:04:20,438 : [INFO]  Batch 395 initialized 
2023-03-25 19:04:20,949 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:21,906 : [INFO]  ------------------------- Batch 395 training: round 1 -------------------------
2023-03-25 19:04:25,557 : [INFO]  ------------------------- Batch round 1, loss: 0.6087 -------------------------
2023-03-25 19:04:25,557 : [INFO]  ------------------------- Batch 395, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:25,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:25,575 : [INFO]  ------------------------- Batch 395 training: round 2 -------------------------
2023-03-25 19:04:27,463 : [INFO]  ------------------------- Batch round 2, loss: 0.6022 -------------------------
2023-03-25 19:04:27,463 : [INFO]  ------------------------- Batch 395, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:27,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:27,487 : [INFO]  ------------------------- Batch 395 training: round 3 -------------------------
2023-03-25 19:04:29,295 : [INFO]  ------------------------- Batch round 3, loss: 0.5999 -------------------------
2023-03-25 19:04:29,295 : [INFO]  ------------------------- Batch 395, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:29,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:29,331 : [INFO]  Batch number 395 model fetched from the server
2023-03-25 19:04:29,331 : [INFO]  ################ Batch 395: final global model evalution after 3 rounds ################
2023-03-25 19:04:30,536 : [INFO]  Batch 395: Training set : loss - 0.6148, accuracy - 0.6141, recall - 0.8043, AUC - 0.7792, F1 - 0.6758, precision - 0.5827, training time - -7.0 seconds
2023-03-25 19:04:30,536 : [INFO]  Batch 395: Testing set : loss - 0.5944, accuracy - 0.6814, recall - 0.8333, AUC - 0.812, F1 - 0.7234, precision - 0.6391
2023-03-25 19:04:30,549 : [INFO]  Batch 396 initialized 
2023-03-25 19:04:31,020 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:31,962 : [INFO]  ------------------------- Batch 396 training: round 1 -------------------------
2023-03-25 19:04:35,344 : [INFO]  ------------------------- Batch round 1, loss: 0.5403 -------------------------
2023-03-25 19:04:35,344 : [INFO]  ------------------------- Batch 396, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:35,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:35,540 : [INFO]  ------------------------- Batch 396 training: round 2 -------------------------
2023-03-25 19:04:37,258 : [INFO]  ------------------------- Batch round 2, loss: 0.5413 -------------------------
2023-03-25 19:04:37,258 : [INFO]  ------------------------- Batch 396, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:37,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:37,416 : [INFO]  ------------------------- Batch 396 training: round 3 -------------------------
2023-03-25 19:04:39,149 : [INFO]  ------------------------- Batch round 3, loss: 0.5394 -------------------------
2023-03-25 19:04:39,149 : [INFO]  ------------------------- Batch 396, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:39,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:39,293 : [INFO]  Batch number 396 model fetched from the server
2023-03-25 19:04:39,294 : [INFO]  ################ Batch 396: final global model evalution after 3 rounds ################
2023-03-25 19:04:40,499 : [INFO]  Batch 396: Training set : loss - 0.5476, accuracy - 0.7554, recall - 0.9239, AUC - 0.9072, F1 - 0.7907, precision - 0.6911, training time - -7.0 seconds
2023-03-25 19:04:40,499 : [INFO]  Batch 396: Testing set : loss - 0.5767, accuracy - 0.7157, recall - 0.8431, AUC - 0.8478, F1 - 0.7478, precision - 0.6719
2023-03-25 19:04:40,513 : [INFO]  Batch 397 initialized 
2023-03-25 19:04:40,984 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:41,935 : [INFO]  ------------------------- Batch 397 training: round 1 -------------------------
2023-03-25 19:04:45,590 : [INFO]  ------------------------- Batch round 1, loss: 0.565 -------------------------
2023-03-25 19:04:45,591 : [INFO]  ------------------------- Batch 397, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:45,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:45,633 : [INFO]  ------------------------- Batch 397 training: round 2 -------------------------
2023-03-25 19:04:47,483 : [INFO]  ------------------------- Batch round 2, loss: 0.5566 -------------------------
2023-03-25 19:04:47,483 : [INFO]  ------------------------- Batch 397, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:47,499 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:47,501 : [INFO]  ------------------------- Batch 397 training: round 3 -------------------------
2023-03-25 19:04:49,327 : [INFO]  ------------------------- Batch round 3, loss: 0.5537 -------------------------
2023-03-25 19:04:49,327 : [INFO]  ------------------------- Batch 397, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:49,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:49,345 : [INFO]  Batch number 397 model fetched from the server
2023-03-25 19:04:49,345 : [INFO]  ################ Batch 397: final global model evalution after 3 rounds ################
2023-03-25 19:04:50,584 : [INFO]  Batch 397: Training set : loss - 0.5649, accuracy - 0.7391, recall - 0.8696, AUC - 0.8668, F1 - 0.7692, precision - 0.6897, training time - -7.0 seconds
2023-03-25 19:04:50,584 : [INFO]  Batch 397: Testing set : loss - 0.6116, accuracy - 0.6471, recall - 0.7941, AUC - 0.7741, F1 - 0.6923, precision - 0.6136
2023-03-25 19:04:50,592 : [INFO]  Batch 398 initialized 
2023-03-25 19:04:51,062 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:52,057 : [INFO]  ------------------------- Batch 398 training: round 1 -------------------------
2023-03-25 19:04:55,562 : [INFO]  ------------------------- Batch round 1, loss: 0.5632 -------------------------
2023-03-25 19:04:55,562 : [INFO]  ------------------------- Batch 398, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:55,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:55,672 : [INFO]  ------------------------- Batch 398 training: round 2 -------------------------
2023-03-25 19:04:57,480 : [INFO]  ------------------------- Batch round 2, loss: 0.5659 -------------------------
2023-03-25 19:04:57,480 : [INFO]  ------------------------- Batch 398, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:57,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:57,551 : [INFO]  ------------------------- Batch 398 training: round 3 -------------------------
2023-03-25 19:04:59,395 : [INFO]  ------------------------- Batch round 3, loss: 0.5693 -------------------------
2023-03-25 19:04:59,395 : [INFO]  ------------------------- Batch 398, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:59,483 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:59,486 : [INFO]  Batch number 398 model fetched from the server
2023-03-25 19:04:59,486 : [INFO]  ################ Batch 398: final global model evalution after 3 rounds ################
2023-03-25 19:05:00,682 : [INFO]  Batch 398: Training set : loss - 0.5705, accuracy - 0.7228, recall - 0.8696, AUC - 0.8537, F1 - 0.7583, precision - 0.6723, training time - -7.0 seconds
2023-03-25 19:05:00,682 : [INFO]  Batch 398: Testing set : loss - 0.5954, accuracy - 0.6912, recall - 0.8137, AUC - 0.8047, F1 - 0.7249, precision - 0.6535
2023-03-25 19:05:00,712 : [INFO]  Batch 399 initialized 
2023-03-25 19:05:01,201 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:02,168 : [INFO]  ------------------------- Batch 399 training: round 1 -------------------------
2023-03-25 19:05:05,713 : [INFO]  ------------------------- Batch round 1, loss: 0.5965 -------------------------
2023-03-25 19:05:05,714 : [INFO]  ------------------------- Batch 399, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:05,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:05,735 : [INFO]  ------------------------- Batch 399 training: round 2 -------------------------
2023-03-25 19:05:07,562 : [INFO]  ------------------------- Batch round 2, loss: 0.6031 -------------------------
2023-03-25 19:05:07,562 : [INFO]  ------------------------- Batch 399, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:07,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:07,581 : [INFO]  ------------------------- Batch 399 training: round 3 -------------------------
2023-03-25 19:05:09,387 : [INFO]  ------------------------- Batch round 3, loss: 0.5974 -------------------------
2023-03-25 19:05:09,387 : [INFO]  ------------------------- Batch 399, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:09,408 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:09,410 : [INFO]  Batch number 399 model fetched from the server
2023-03-25 19:05:09,410 : [INFO]  ################ Batch 399: final global model evalution after 3 rounds ################
2023-03-25 19:05:10,624 : [INFO]  Batch 399: Training set : loss - 0.6198, accuracy - 0.6196, recall - 0.7717, AUC - 0.7563, F1 - 0.6698, precision - 0.5917, training time - -7.0 seconds
2023-03-25 19:05:10,624 : [INFO]  Batch 399: Testing set : loss - 0.5807, accuracy - 0.6471, recall - 0.8137, AUC - 0.8307, F1 - 0.6975, precision - 0.6103
2023-03-25 19:05:10,632 : [INFO]  Batch 400 initialized 
2023-03-25 19:05:11,088 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:12,068 : [INFO]  ------------------------- Batch 400 training: round 1 -------------------------
2023-03-25 19:05:15,834 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-25 19:05:15,834 : [INFO]  ------------------------- Batch 400, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:15,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:15,854 : [INFO]  ------------------------- Batch 400 training: round 2 -------------------------
2023-03-25 19:05:17,768 : [INFO]  ------------------------- Batch round 2, loss: 0.562 -------------------------
2023-03-25 19:05:17,768 : [INFO]  ------------------------- Batch 400, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:17,784 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:17,786 : [INFO]  ------------------------- Batch 400 training: round 3 -------------------------
2023-03-25 19:05:19,637 : [INFO]  ------------------------- Batch round 3, loss: 0.5622 -------------------------
2023-03-25 19:05:19,637 : [INFO]  ------------------------- Batch 400, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:19,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:19,655 : [INFO]  Batch number 400 model fetched from the server
2023-03-25 19:05:19,655 : [INFO]  ################ Batch 400: final global model evalution after 3 rounds ################
2023-03-25 19:05:20,859 : [INFO]  Batch 400: Training set : loss - 0.5674, accuracy - 0.7174, recall - 0.8261, AUC - 0.8443, F1 - 0.7451, precision - 0.6786, training time - -8.0 seconds
2023-03-25 19:05:20,859 : [INFO]  Batch 400: Testing set : loss - 0.5859, accuracy - 0.6961, recall - 0.902, AUC - 0.8415, F1 - 0.748, precision - 0.6389
2023-03-25 19:05:20,871 : [INFO]  Batch 401 initialized 
2023-03-25 19:05:21,402 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:22,361 : [INFO]  ------------------------- Batch 401 training: round 1 -------------------------
2023-03-25 19:05:25,963 : [INFO]  ------------------------- Batch round 1, loss: 0.5956 -------------------------
2023-03-25 19:05:25,963 : [INFO]  ------------------------- Batch 401, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:26,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:26,045 : [INFO]  ------------------------- Batch 401 training: round 2 -------------------------
2023-03-25 19:05:27,865 : [INFO]  ------------------------- Batch round 2, loss: 0.593 -------------------------
2023-03-25 19:05:27,865 : [INFO]  ------------------------- Batch 401, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:27,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:27,893 : [INFO]  ------------------------- Batch 401 training: round 3 -------------------------
2023-03-25 19:05:29,866 : [INFO]  ------------------------- Batch round 3, loss: 0.5909 -------------------------
2023-03-25 19:05:29,866 : [INFO]  ------------------------- Batch 401, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:29,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:29,916 : [INFO]  Batch number 401 model fetched from the server
2023-03-25 19:05:29,916 : [INFO]  ################ Batch 401: final global model evalution after 3 rounds ################
2023-03-25 19:05:31,157 : [INFO]  Batch 401: Training set : loss - 0.6085, accuracy - 0.6739, recall - 0.7935, AUC - 0.7795, F1 - 0.7087, precision - 0.6404, training time - -8.0 seconds
2023-03-25 19:05:31,157 : [INFO]  Batch 401: Testing set : loss - 0.5696, accuracy - 0.6863, recall - 0.8431, AUC - 0.8476, F1 - 0.7288, precision - 0.6418
2023-03-25 19:05:31,169 : [INFO]  Batch 402 initialized 
2023-03-25 19:05:31,655 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:32,562 : [INFO]  ------------------------- Batch 402 training: round 1 -------------------------
2023-03-25 19:05:36,208 : [INFO]  ------------------------- Batch round 1, loss: 0.5557 -------------------------
2023-03-25 19:05:36,208 : [INFO]  ------------------------- Batch 402, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:36,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:36,421 : [INFO]  ------------------------- Batch 402 training: round 2 -------------------------
2023-03-25 19:05:38,257 : [INFO]  ------------------------- Batch round 2, loss: 0.5532 -------------------------
2023-03-25 19:05:38,257 : [INFO]  ------------------------- Batch 402, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:38,314 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:38,316 : [INFO]  ------------------------- Batch 402 training: round 3 -------------------------
2023-03-25 19:05:40,180 : [INFO]  ------------------------- Batch round 3, loss: 0.5549 -------------------------
2023-03-25 19:05:40,180 : [INFO]  ------------------------- Batch 402, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:40,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:40,218 : [INFO]  Batch number 402 model fetched from the server
2023-03-25 19:05:40,219 : [INFO]  ################ Batch 402: final global model evalution after 3 rounds ################
2023-03-25 19:05:41,416 : [INFO]  Batch 402: Training set : loss - 0.5604, accuracy - 0.7174, recall - 0.8478, AUC - 0.8662, F1 - 0.75, precision - 0.6724, training time - -8.0 seconds
2023-03-25 19:05:41,417 : [INFO]  Batch 402: Testing set : loss - 0.5818, accuracy - 0.701, recall - 0.8039, AUC - 0.8266, F1 - 0.7289, precision - 0.6667
2023-03-25 19:05:41,431 : [INFO]  Batch 403 initialized 
2023-03-25 19:05:41,949 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:42,897 : [INFO]  ------------------------- Batch 403 training: round 1 -------------------------
2023-03-25 19:05:46,519 : [INFO]  ------------------------- Batch round 1, loss: 0.6138 -------------------------
2023-03-25 19:05:46,519 : [INFO]  ------------------------- Batch 403, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:46,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:46,537 : [INFO]  ------------------------- Batch 403 training: round 2 -------------------------
2023-03-25 19:05:48,397 : [INFO]  ------------------------- Batch round 2, loss: 0.6203 -------------------------
2023-03-25 19:05:48,397 : [INFO]  ------------------------- Batch 403, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:48,416 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:48,418 : [INFO]  ------------------------- Batch 403 training: round 3 -------------------------
2023-03-25 19:05:50,312 : [INFO]  ------------------------- Batch round 3, loss: 0.6236 -------------------------
2023-03-25 19:05:50,312 : [INFO]  ------------------------- Batch 403, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:50,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:50,346 : [INFO]  Batch number 403 model fetched from the server
2023-03-25 19:05:50,347 : [INFO]  ################ Batch 403: final global model evalution after 3 rounds ################
2023-03-25 19:05:51,677 : [INFO]  Batch 403: Training set : loss - 0.6324, accuracy - 0.5924, recall - 0.6957, AUC - 0.7023, F1 - 0.6305, precision - 0.5766, training time - -7.0 seconds
2023-03-25 19:05:51,678 : [INFO]  Batch 403: Testing set : loss - 0.568, accuracy - 0.7108, recall - 0.8725, AUC - 0.8566, F1 - 0.7511, precision - 0.6593
2023-03-25 19:05:51,687 : [INFO]  Batch 404 initialized 
2023-03-25 19:05:52,146 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:53,120 : [INFO]  ------------------------- Batch 404 training: round 1 -------------------------
2023-03-25 19:05:56,699 : [INFO]  ------------------------- Batch round 1, loss: 0.5895 -------------------------
2023-03-25 19:05:56,699 : [INFO]  ------------------------- Batch 404, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:56,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:56,718 : [INFO]  ------------------------- Batch 404 training: round 2 -------------------------
2023-03-25 19:05:58,607 : [INFO]  ------------------------- Batch round 2, loss: 0.5894 -------------------------
2023-03-25 19:05:58,607 : [INFO]  ------------------------- Batch 404, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:58,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:58,626 : [INFO]  ------------------------- Batch 404 training: round 3 -------------------------
2023-03-25 19:06:00,505 : [INFO]  ------------------------- Batch round 3, loss: 0.5883 -------------------------
2023-03-25 19:06:00,506 : [INFO]  ------------------------- Batch 404, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:00,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:00,523 : [INFO]  Batch number 404 model fetched from the server
2023-03-25 19:06:00,523 : [INFO]  ################ Batch 404: final global model evalution after 3 rounds ################
2023-03-25 19:06:01,733 : [INFO]  Batch 404: Training set : loss - 0.5955, accuracy - 0.6685, recall - 0.8043, AUC - 0.8045, F1 - 0.7081, precision - 0.6325, training time - -7.0 seconds
2023-03-25 19:06:01,734 : [INFO]  Batch 404: Testing set : loss - 0.5853, accuracy - 0.652, recall - 0.8333, AUC - 0.8394, F1 - 0.7054, precision - 0.6115
2023-03-25 19:06:01,741 : [INFO]  Batch 405 initialized 
2023-03-25 19:06:02,206 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:03,177 : [INFO]  ------------------------- Batch 405 training: round 1 -------------------------
2023-03-25 19:06:06,704 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-25 19:06:06,704 : [INFO]  ------------------------- Batch 405, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:06,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:06,722 : [INFO]  ------------------------- Batch 405 training: round 2 -------------------------
2023-03-25 19:06:08,460 : [INFO]  ------------------------- Batch round 2, loss: 0.5715 -------------------------
2023-03-25 19:06:08,460 : [INFO]  ------------------------- Batch 405, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:08,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:08,479 : [INFO]  ------------------------- Batch 405 training: round 3 -------------------------
2023-03-25 19:06:10,208 : [INFO]  ------------------------- Batch round 3, loss: 0.5643 -------------------------
2023-03-25 19:06:10,209 : [INFO]  ------------------------- Batch 405, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:10,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:10,253 : [INFO]  Batch number 405 model fetched from the server
2023-03-25 19:06:10,253 : [INFO]  ################ Batch 405: final global model evalution after 3 rounds ################
2023-03-25 19:06:11,421 : [INFO]  Batch 405: Training set : loss - 0.5808, accuracy - 0.6957, recall - 0.8478, AUC - 0.8426, F1 - 0.7358, precision - 0.65, training time - -7.0 seconds
2023-03-25 19:06:11,421 : [INFO]  Batch 405: Testing set : loss - 0.5876, accuracy - 0.652, recall - 0.8137, AUC - 0.8329, F1 - 0.7004, precision - 0.6148
2023-03-25 19:06:11,436 : [INFO]  Batch 406 initialized 
2023-03-25 19:06:11,892 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:12,852 : [INFO]  ------------------------- Batch 406 training: round 1 -------------------------
2023-03-25 19:06:16,275 : [INFO]  ------------------------- Batch round 1, loss: 0.5746 -------------------------
2023-03-25 19:06:16,275 : [INFO]  ------------------------- Batch 406, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:16,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:16,378 : [INFO]  ------------------------- Batch 406 training: round 2 -------------------------
2023-03-25 19:06:18,135 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-25 19:06:18,135 : [INFO]  ------------------------- Batch 406, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:18,151 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:18,154 : [INFO]  ------------------------- Batch 406 training: round 3 -------------------------
2023-03-25 19:06:19,950 : [INFO]  ------------------------- Batch round 3, loss: 0.5715 -------------------------
2023-03-25 19:06:19,950 : [INFO]  ------------------------- Batch 406, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:19,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:19,967 : [INFO]  Batch number 406 model fetched from the server
2023-03-25 19:06:19,967 : [INFO]  ################ Batch 406: final global model evalution after 3 rounds ################
2023-03-25 19:06:21,148 : [INFO]  Batch 406: Training set : loss - 0.5846, accuracy - 0.7065, recall - 0.8478, AUC - 0.8276, F1 - 0.7429, precision - 0.661, training time - -7.0 seconds
2023-03-25 19:06:21,148 : [INFO]  Batch 406: Testing set : loss - 0.5678, accuracy - 0.7157, recall - 0.8725, AUC - 0.8652, F1 - 0.7542, precision - 0.6642
2023-03-25 19:06:21,161 : [INFO]  Batch 407 initialized 
2023-03-25 19:06:21,624 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:22,589 : [INFO]  ------------------------- Batch 407 training: round 1 -------------------------
2023-03-25 19:06:26,180 : [INFO]  ------------------------- Batch round 1, loss: 0.5848 -------------------------
2023-03-25 19:06:26,180 : [INFO]  ------------------------- Batch 407, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:26,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:26,287 : [INFO]  ------------------------- Batch 407 training: round 2 -------------------------
2023-03-25 19:06:28,062 : [INFO]  ------------------------- Batch round 2, loss: 0.5868 -------------------------
2023-03-25 19:06:28,062 : [INFO]  ------------------------- Batch 407, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:28,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:28,146 : [INFO]  ------------------------- Batch 407 training: round 3 -------------------------
2023-03-25 19:06:29,946 : [INFO]  ------------------------- Batch round 3, loss: 0.5834 -------------------------
2023-03-25 19:06:29,946 : [INFO]  ------------------------- Batch 407, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:30,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:30,300 : [INFO]  Batch number 407 model fetched from the server
2023-03-25 19:06:30,300 : [INFO]  ################ Batch 407: final global model evalution after 3 rounds ################
2023-03-25 19:06:31,499 : [INFO]  Batch 407: Training set : loss - 0.5879, accuracy - 0.6957, recall - 0.8261, AUC - 0.8096, F1 - 0.7308, precision - 0.6552, training time - -8.0 seconds
2023-03-25 19:06:31,499 : [INFO]  Batch 407: Testing set : loss - 0.5984, accuracy - 0.6324, recall - 0.8039, AUC - 0.8155, F1 - 0.6862, precision - 0.5985
2023-03-25 19:06:31,509 : [INFO]  Batch 408 initialized 
2023-03-25 19:06:31,977 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:32,941 : [INFO]  ------------------------- Batch 408 training: round 1 -------------------------
2023-03-25 19:06:36,519 : [INFO]  ------------------------- Batch round 1, loss: 0.5683 -------------------------
2023-03-25 19:06:36,519 : [INFO]  ------------------------- Batch 408, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:36,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:36,574 : [INFO]  ------------------------- Batch 408 training: round 2 -------------------------
2023-03-25 19:06:38,358 : [INFO]  ------------------------- Batch round 2, loss: 0.5678 -------------------------
2023-03-25 19:06:38,358 : [INFO]  ------------------------- Batch 408, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:38,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:38,403 : [INFO]  ------------------------- Batch 408 training: round 3 -------------------------
2023-03-25 19:06:40,223 : [INFO]  ------------------------- Batch round 3, loss: 0.5655 -------------------------
2023-03-25 19:06:40,223 : [INFO]  ------------------------- Batch 408, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:40,274 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:40,276 : [INFO]  Batch number 408 model fetched from the server
2023-03-25 19:06:40,276 : [INFO]  ################ Batch 408: final global model evalution after 3 rounds ################
2023-03-25 19:06:41,477 : [INFO]  Batch 408: Training set : loss - 0.5741, accuracy - 0.7011, recall - 0.837, AUC - 0.8384, F1 - 0.7368, precision - 0.6581, training time - -7.0 seconds
2023-03-25 19:06:41,477 : [INFO]  Batch 408: Testing set : loss - 0.5732, accuracy - 0.7108, recall - 0.8529, AUC - 0.8481, F1 - 0.7468, precision - 0.6641
2023-03-25 19:06:41,492 : [INFO]  Batch 409 initialized 
2023-03-25 19:06:41,955 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:42,924 : [INFO]  ------------------------- Batch 409 training: round 1 -------------------------
2023-03-25 19:06:46,407 : [INFO]  ------------------------- Batch round 1, loss: 0.5783 -------------------------
2023-03-25 19:06:46,408 : [INFO]  ------------------------- Batch 409, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:46,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:46,426 : [INFO]  ------------------------- Batch 409 training: round 2 -------------------------
2023-03-25 19:06:48,296 : [INFO]  ------------------------- Batch round 2, loss: 0.5811 -------------------------
2023-03-25 19:06:48,297 : [INFO]  ------------------------- Batch 409, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:48,313 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:48,315 : [INFO]  ------------------------- Batch 409 training: round 3 -------------------------
2023-03-25 19:06:50,152 : [INFO]  ------------------------- Batch round 3, loss: 0.5902 -------------------------
2023-03-25 19:06:50,152 : [INFO]  ------------------------- Batch 409, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:50,168 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:50,170 : [INFO]  Batch number 409 model fetched from the server
2023-03-25 19:06:50,170 : [INFO]  ################ Batch 409: final global model evalution after 3 rounds ################
2023-03-25 19:06:51,379 : [INFO]  Batch 409: Training set : loss - 0.5907, accuracy - 0.663, recall - 0.7935, AUC - 0.8064, F1 - 0.7019, precision - 0.6293, training time - -7.0 seconds
2023-03-25 19:06:51,379 : [INFO]  Batch 409: Testing set : loss - 0.5595, accuracy - 0.7255, recall - 0.9118, AUC - 0.8918, F1 - 0.7686, precision - 0.6643
2023-03-25 19:06:51,388 : [INFO]  Batch 410 initialized 
2023-03-25 19:06:51,846 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:52,860 : [INFO]  ------------------------- Batch 410 training: round 1 -------------------------
2023-03-25 19:06:56,421 : [INFO]  ------------------------- Batch round 1, loss: 0.5706 -------------------------
2023-03-25 19:06:56,421 : [INFO]  ------------------------- Batch 410, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:56,437 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:56,439 : [INFO]  ------------------------- Batch 410 training: round 2 -------------------------
2023-03-25 19:06:58,251 : [INFO]  ------------------------- Batch round 2, loss: 0.5655 -------------------------
2023-03-25 19:06:58,251 : [INFO]  ------------------------- Batch 410, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:58,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:58,269 : [INFO]  ------------------------- Batch 410 training: round 3 -------------------------
2023-03-25 19:07:00,118 : [INFO]  ------------------------- Batch round 3, loss: 0.564 -------------------------
2023-03-25 19:07:00,118 : [INFO]  ------------------------- Batch 410, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:00,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:00,136 : [INFO]  Batch number 410 model fetched from the server
2023-03-25 19:07:00,136 : [INFO]  ################ Batch 410: final global model evalution after 3 rounds ################
2023-03-25 19:07:01,357 : [INFO]  Batch 410: Training set : loss - 0.5779, accuracy - 0.7174, recall - 0.837, AUC - 0.8377, F1 - 0.7476, precision - 0.6754, training time - -7.0 seconds
2023-03-25 19:07:01,357 : [INFO]  Batch 410: Testing set : loss - 0.5915, accuracy - 0.6471, recall - 0.7941, AUC - 0.8146, F1 - 0.6923, precision - 0.6136
2023-03-25 19:07:01,365 : [INFO]  Batch 411 initialized 
2023-03-25 19:07:01,822 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:02,795 : [INFO]  ------------------------- Batch 411 training: round 1 -------------------------
2023-03-25 19:07:06,338 : [INFO]  ------------------------- Batch round 1, loss: 0.545 -------------------------
2023-03-25 19:07:06,338 : [INFO]  ------------------------- Batch 411, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:06,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:06,367 : [INFO]  ------------------------- Batch 411 training: round 2 -------------------------
2023-03-25 19:07:08,183 : [INFO]  ------------------------- Batch round 2, loss: 0.5461 -------------------------
2023-03-25 19:07:08,183 : [INFO]  ------------------------- Batch 411, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:08,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:08,202 : [INFO]  ------------------------- Batch 411 training: round 3 -------------------------
2023-03-25 19:07:10,031 : [INFO]  ------------------------- Batch round 3, loss: 0.5406 -------------------------
2023-03-25 19:07:10,032 : [INFO]  ------------------------- Batch 411, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:10,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:10,054 : [INFO]  Batch number 411 model fetched from the server
2023-03-25 19:07:10,055 : [INFO]  ################ Batch 411: final global model evalution after 3 rounds ################
2023-03-25 19:07:11,253 : [INFO]  Batch 411: Training set : loss - 0.5494, accuracy - 0.7554, recall - 0.8587, AUC - 0.8809, F1 - 0.7783, precision - 0.7117, training time - -7.0 seconds
2023-03-25 19:07:11,253 : [INFO]  Batch 411: Testing set : loss - 0.596, accuracy - 0.6765, recall - 0.8333, AUC - 0.8129, F1 - 0.7203, precision - 0.6343
2023-03-25 19:07:11,265 : [INFO]  Batch 412 initialized 
2023-03-25 19:07:11,715 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:12,697 : [INFO]  ------------------------- Batch 412 training: round 1 -------------------------
2023-03-25 19:07:16,209 : [INFO]  ------------------------- Batch round 1, loss: 0.5866 -------------------------
2023-03-25 19:07:16,209 : [INFO]  ------------------------- Batch 412, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:16,241 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:16,243 : [INFO]  ------------------------- Batch 412 training: round 2 -------------------------
2023-03-25 19:07:18,040 : [INFO]  ------------------------- Batch round 2, loss: 0.5893 -------------------------
2023-03-25 19:07:18,040 : [INFO]  ------------------------- Batch 412, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:18,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:18,058 : [INFO]  ------------------------- Batch 412 training: round 3 -------------------------
2023-03-25 19:07:19,879 : [INFO]  ------------------------- Batch round 3, loss: 0.5912 -------------------------
2023-03-25 19:07:19,879 : [INFO]  ------------------------- Batch 412, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:19,894 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:19,896 : [INFO]  Batch number 412 model fetched from the server
2023-03-25 19:07:19,896 : [INFO]  ################ Batch 412: final global model evalution after 3 rounds ################
2023-03-25 19:07:21,096 : [INFO]  Batch 412: Training set : loss - 0.6014, accuracy - 0.6413, recall - 0.7065, AUC - 0.7566, F1 - 0.6633, precision - 0.625, training time - -7.0 seconds
2023-03-25 19:07:21,096 : [INFO]  Batch 412: Testing set : loss - 0.5704, accuracy - 0.7108, recall - 0.8039, AUC - 0.8407, F1 - 0.7354, precision - 0.6777
2023-03-25 19:07:21,106 : [INFO]  Batch 413 initialized 
2023-03-25 19:07:21,568 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:22,530 : [INFO]  ------------------------- Batch 413 training: round 1 -------------------------
2023-03-25 19:07:26,140 : [INFO]  ------------------------- Batch round 1, loss: 0.546 -------------------------
2023-03-25 19:07:26,140 : [INFO]  ------------------------- Batch 413, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:26,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:26,158 : [INFO]  ------------------------- Batch 413 training: round 2 -------------------------
2023-03-25 19:07:27,970 : [INFO]  ------------------------- Batch round 2, loss: 0.5472 -------------------------
2023-03-25 19:07:27,970 : [INFO]  ------------------------- Batch 413, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:28,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:28,007 : [INFO]  ------------------------- Batch 413 training: round 3 -------------------------
2023-03-25 19:07:29,849 : [INFO]  ------------------------- Batch round 3, loss: 0.5443 -------------------------
2023-03-25 19:07:29,849 : [INFO]  ------------------------- Batch 413, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:29,881 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:29,883 : [INFO]  Batch number 413 model fetched from the server
2023-03-25 19:07:29,883 : [INFO]  ################ Batch 413: final global model evalution after 3 rounds ################
2023-03-25 19:07:31,106 : [INFO]  Batch 413: Training set : loss - 0.5547, accuracy - 0.7174, recall - 0.8478, AUC - 0.8811, F1 - 0.75, precision - 0.6724, training time - -7.0 seconds
2023-03-25 19:07:31,106 : [INFO]  Batch 413: Testing set : loss - 0.5614, accuracy - 0.701, recall - 0.8922, AUC - 0.8724, F1 - 0.749, precision - 0.6454
2023-03-25 19:07:31,118 : [INFO]  Batch 414 initialized 
2023-03-25 19:07:31,570 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:32,542 : [INFO]  ------------------------- Batch 414 training: round 1 -------------------------
2023-03-25 19:07:36,040 : [INFO]  ------------------------- Batch round 1, loss: 0.5823 -------------------------
2023-03-25 19:07:36,040 : [INFO]  ------------------------- Batch 414, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:36,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:36,058 : [INFO]  ------------------------- Batch 414 training: round 2 -------------------------
2023-03-25 19:07:37,889 : [INFO]  ------------------------- Batch round 2, loss: 0.5843 -------------------------
2023-03-25 19:07:37,889 : [INFO]  ------------------------- Batch 414, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:37,910 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:37,912 : [INFO]  ------------------------- Batch 414 training: round 3 -------------------------
2023-03-25 19:07:39,689 : [INFO]  ------------------------- Batch round 3, loss: 0.5805 -------------------------
2023-03-25 19:07:39,689 : [INFO]  ------------------------- Batch 414, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:39,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:39,708 : [INFO]  Batch number 414 model fetched from the server
2023-03-25 19:07:39,708 : [INFO]  ################ Batch 414: final global model evalution after 3 rounds ################
2023-03-25 19:07:40,899 : [INFO]  Batch 414: Training set : loss - 0.5935, accuracy - 0.712, recall - 0.8696, AUC - 0.8149, F1 - 0.7512, precision - 0.6612, training time - -7.0 seconds
2023-03-25 19:07:40,899 : [INFO]  Batch 414: Testing set : loss - 0.589, accuracy - 0.6814, recall - 0.7647, AUC - 0.8017, F1 - 0.7059, precision - 0.6555
2023-03-25 19:07:40,913 : [INFO]  Batch 415 initialized 
2023-03-25 19:07:41,362 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:42,324 : [INFO]  ------------------------- Batch 415 training: round 1 -------------------------
2023-03-25 19:07:45,767 : [INFO]  ------------------------- Batch round 1, loss: 0.5654 -------------------------
2023-03-25 19:07:45,767 : [INFO]  ------------------------- Batch 415, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:45,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:45,830 : [INFO]  ------------------------- Batch 415 training: round 2 -------------------------
2023-03-25 19:07:47,645 : [INFO]  ------------------------- Batch round 2, loss: 0.56 -------------------------
2023-03-25 19:07:47,645 : [INFO]  ------------------------- Batch 415, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:47,679 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:47,682 : [INFO]  ------------------------- Batch 415 training: round 3 -------------------------
2023-03-25 19:07:49,464 : [INFO]  ------------------------- Batch round 3, loss: 0.5666 -------------------------
2023-03-25 19:07:49,464 : [INFO]  ------------------------- Batch 415, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:49,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:49,530 : [INFO]  Batch number 415 model fetched from the server
2023-03-25 19:07:49,530 : [INFO]  ################ Batch 415: final global model evalution after 3 rounds ################
2023-03-25 19:07:50,753 : [INFO]  Batch 415: Training set : loss - 0.5681, accuracy - 0.712, recall - 0.8152, AUC - 0.8306, F1 - 0.7389, precision - 0.6757, training time - -7.0 seconds
2023-03-25 19:07:50,753 : [INFO]  Batch 415: Testing set : loss - 0.5903, accuracy - 0.6863, recall - 0.8039, AUC - 0.8187, F1 - 0.7193, precision - 0.6508
2023-03-25 19:07:50,768 : [INFO]  Batch 416 initialized 
2023-03-25 19:07:51,213 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:52,203 : [INFO]  ------------------------- Batch 416 training: round 1 -------------------------
2023-03-25 19:07:55,707 : [INFO]  ------------------------- Batch round 1, loss: 0.5845 -------------------------
2023-03-25 19:07:55,708 : [INFO]  ------------------------- Batch 416, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:55,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:55,748 : [INFO]  ------------------------- Batch 416 training: round 2 -------------------------
2023-03-25 19:07:57,713 : [INFO]  ------------------------- Batch round 2, loss: 0.5843 -------------------------
2023-03-25 19:07:57,713 : [INFO]  ------------------------- Batch 416, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:57,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:57,735 : [INFO]  ------------------------- Batch 416 training: round 3 -------------------------
2023-03-25 19:07:59,598 : [INFO]  ------------------------- Batch round 3, loss: 0.59 -------------------------
2023-03-25 19:07:59,598 : [INFO]  ------------------------- Batch 416, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:59,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:59,619 : [INFO]  Batch number 416 model fetched from the server
2023-03-25 19:07:59,619 : [INFO]  ################ Batch 416: final global model evalution after 3 rounds ################
2023-03-25 19:08:00,856 : [INFO]  Batch 416: Training set : loss - 0.5986, accuracy - 0.6576, recall - 0.7717, AUC - 0.7939, F1 - 0.6927, precision - 0.6283, training time - -7.0 seconds
2023-03-25 19:08:00,856 : [INFO]  Batch 416: Testing set : loss - 0.601, accuracy - 0.6324, recall - 0.7843, AUC - 0.784, F1 - 0.6809, precision - 0.6015
2023-03-25 19:08:00,870 : [INFO]  Batch 417 initialized 
2023-03-25 19:08:01,321 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:02,287 : [INFO]  ------------------------- Batch 417 training: round 1 -------------------------
2023-03-25 19:08:05,889 : [INFO]  ------------------------- Batch round 1, loss: 0.5574 -------------------------
2023-03-25 19:08:05,889 : [INFO]  ------------------------- Batch 417, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:05,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:05,990 : [INFO]  ------------------------- Batch 417 training: round 2 -------------------------
2023-03-25 19:08:07,945 : [INFO]  ------------------------- Batch round 2, loss: 0.5573 -------------------------
2023-03-25 19:08:07,945 : [INFO]  ------------------------- Batch 417, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:07,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:07,982 : [INFO]  ------------------------- Batch 417 training: round 3 -------------------------
2023-03-25 19:08:09,804 : [INFO]  ------------------------- Batch round 3, loss: 0.5618 -------------------------
2023-03-25 19:08:09,804 : [INFO]  ------------------------- Batch 417, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:09,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:09,873 : [INFO]  Batch number 417 model fetched from the server
2023-03-25 19:08:09,873 : [INFO]  ################ Batch 417: final global model evalution after 3 rounds ################
2023-03-25 19:08:11,108 : [INFO]  Batch 417: Training set : loss - 0.5693, accuracy - 0.7337, recall - 0.8478, AUC - 0.8521, F1 - 0.761, precision - 0.6903, training time - -8.0 seconds
2023-03-25 19:08:11,108 : [INFO]  Batch 417: Testing set : loss - 0.5837, accuracy - 0.6716, recall - 0.8431, AUC - 0.8274, F1 - 0.7197, precision - 0.6277
2023-03-25 19:08:11,117 : [INFO]  Batch 418 initialized 
2023-03-25 19:08:11,592 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:12,559 : [INFO]  ------------------------- Batch 418 training: round 1 -------------------------
2023-03-25 19:08:16,103 : [INFO]  ------------------------- Batch round 1, loss: 0.5816 -------------------------
2023-03-25 19:08:16,103 : [INFO]  ------------------------- Batch 418, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:16,119 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:16,121 : [INFO]  ------------------------- Batch 418 training: round 2 -------------------------
2023-03-25 19:08:17,904 : [INFO]  ------------------------- Batch round 2, loss: 0.5841 -------------------------
2023-03-25 19:08:17,904 : [INFO]  ------------------------- Batch 418, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:17,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:17,923 : [INFO]  ------------------------- Batch 418 training: round 3 -------------------------
2023-03-25 19:08:19,733 : [INFO]  ------------------------- Batch round 3, loss: 0.5818 -------------------------
2023-03-25 19:08:19,733 : [INFO]  ------------------------- Batch 418, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:19,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:19,752 : [INFO]  Batch number 418 model fetched from the server
2023-03-25 19:08:19,752 : [INFO]  ################ Batch 418: final global model evalution after 3 rounds ################
2023-03-25 19:08:20,956 : [INFO]  Batch 418: Training set : loss - 0.5932, accuracy - 0.6739, recall - 0.7935, AUC - 0.8043, F1 - 0.7087, precision - 0.6404, training time - -7.0 seconds
2023-03-25 19:08:20,957 : [INFO]  Batch 418: Testing set : loss - 0.6048, accuracy - 0.6324, recall - 0.7647, AUC - 0.7757, F1 - 0.6753, precision - 0.6047
2023-03-25 19:08:20,965 : [INFO]  Batch 419 initialized 
2023-03-25 19:08:21,421 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:22,409 : [INFO]  ------------------------- Batch 419 training: round 1 -------------------------
2023-03-25 19:08:25,906 : [INFO]  ------------------------- Batch round 1, loss: 0.5756 -------------------------
2023-03-25 19:08:25,906 : [INFO]  ------------------------- Batch 419, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:25,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:25,924 : [INFO]  ------------------------- Batch 419 training: round 2 -------------------------
2023-03-25 19:08:27,721 : [INFO]  ------------------------- Batch round 2, loss: 0.5785 -------------------------
2023-03-25 19:08:27,721 : [INFO]  ------------------------- Batch 419, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:27,737 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:27,739 : [INFO]  ------------------------- Batch 419 training: round 3 -------------------------
2023-03-25 19:08:29,502 : [INFO]  ------------------------- Batch round 3, loss: 0.5727 -------------------------
2023-03-25 19:08:29,502 : [INFO]  ------------------------- Batch 419, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:29,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:29,583 : [INFO]  Batch number 419 model fetched from the server
2023-03-25 19:08:29,583 : [INFO]  ################ Batch 419: final global model evalution after 3 rounds ################
2023-03-25 19:08:30,739 : [INFO]  Batch 419: Training set : loss - 0.5878, accuracy - 0.6902, recall - 0.8043, AUC - 0.8131, F1 - 0.722, precision - 0.6549, training time - -7.0 seconds
2023-03-25 19:08:30,739 : [INFO]  Batch 419: Testing set : loss - 0.5842, accuracy - 0.6716, recall - 0.8039, AUC - 0.8244, F1 - 0.71, precision - 0.6357
2023-03-25 19:08:30,753 : [INFO]  Batch 420 initialized 
2023-03-25 19:08:31,205 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:32,195 : [INFO]  ------------------------- Batch 420 training: round 1 -------------------------
2023-03-25 19:08:35,690 : [INFO]  ------------------------- Batch round 1, loss: 0.5685 -------------------------
2023-03-25 19:08:35,690 : [INFO]  ------------------------- Batch 420, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:35,838 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:35,846 : [INFO]  ------------------------- Batch 420 training: round 2 -------------------------
2023-03-25 19:08:37,649 : [INFO]  ------------------------- Batch round 2, loss: 0.5686 -------------------------
2023-03-25 19:08:37,649 : [INFO]  ------------------------- Batch 420, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:37,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:37,672 : [INFO]  ------------------------- Batch 420 training: round 3 -------------------------
2023-03-25 19:08:39,487 : [INFO]  ------------------------- Batch round 3, loss: 0.5697 -------------------------
2023-03-25 19:08:39,487 : [INFO]  ------------------------- Batch 420, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:39,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:39,537 : [INFO]  Batch number 420 model fetched from the server
2023-03-25 19:08:39,537 : [INFO]  ################ Batch 420: final global model evalution after 3 rounds ################
2023-03-25 19:08:40,718 : [INFO]  Batch 420: Training set : loss - 0.5813, accuracy - 0.6739, recall - 0.8152, AUC - 0.8264, F1 - 0.7143, precision - 0.6356, training time - -7.0 seconds
2023-03-25 19:08:40,718 : [INFO]  Batch 420: Testing set : loss - 0.5881, accuracy - 0.6569, recall - 0.8039, AUC - 0.8259, F1 - 0.7009, precision - 0.6212
2023-03-25 19:08:40,737 : [INFO]  Batch 421 initialized 
2023-03-25 19:08:41,218 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:42,261 : [INFO]  ------------------------- Batch 421 training: round 1 -------------------------
2023-03-25 19:08:45,747 : [INFO]  ------------------------- Batch round 1, loss: 0.5929 -------------------------
2023-03-25 19:08:45,747 : [INFO]  ------------------------- Batch 421, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:45,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:45,765 : [INFO]  ------------------------- Batch 421 training: round 2 -------------------------
2023-03-25 19:08:47,549 : [INFO]  ------------------------- Batch round 2, loss: 0.5895 -------------------------
2023-03-25 19:08:47,549 : [INFO]  ------------------------- Batch 421, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:47,594 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:47,596 : [INFO]  ------------------------- Batch 421 training: round 3 -------------------------
2023-03-25 19:08:49,438 : [INFO]  ------------------------- Batch round 3, loss: 0.5873 -------------------------
2023-03-25 19:08:49,438 : [INFO]  ------------------------- Batch 421, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:49,454 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:49,456 : [INFO]  Batch number 421 model fetched from the server
2023-03-25 19:08:49,456 : [INFO]  ################ Batch 421: final global model evalution after 3 rounds ################
2023-03-25 19:08:50,642 : [INFO]  Batch 421: Training set : loss - 0.6019, accuracy - 0.6413, recall - 0.7717, AUC - 0.7889, F1 - 0.6827, precision - 0.6121, training time - -7.0 seconds
2023-03-25 19:08:50,643 : [INFO]  Batch 421: Testing set : loss - 0.5921, accuracy - 0.6765, recall - 0.8333, AUC - 0.8257, F1 - 0.7203, precision - 0.6343
2023-03-25 19:08:50,651 : [INFO]  Batch 422 initialized 
2023-03-25 19:08:51,106 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:52,110 : [INFO]  ------------------------- Batch 422 training: round 1 -------------------------
2023-03-25 19:08:55,572 : [INFO]  ------------------------- Batch round 1, loss: 0.5684 -------------------------
2023-03-25 19:08:55,573 : [INFO]  ------------------------- Batch 422, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:55,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:55,656 : [INFO]  ------------------------- Batch 422 training: round 2 -------------------------
2023-03-25 19:08:57,394 : [INFO]  ------------------------- Batch round 2, loss: 0.5708 -------------------------
2023-03-25 19:08:57,394 : [INFO]  ------------------------- Batch 422, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:57,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:57,487 : [INFO]  ------------------------- Batch 422 training: round 3 -------------------------
2023-03-25 19:08:59,297 : [INFO]  ------------------------- Batch round 3, loss: 0.5714 -------------------------
2023-03-25 19:08:59,297 : [INFO]  ------------------------- Batch 422, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:59,320 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:59,323 : [INFO]  Batch number 422 model fetched from the server
2023-03-25 19:08:59,323 : [INFO]  ################ Batch 422: final global model evalution after 3 rounds ################
2023-03-25 19:09:00,509 : [INFO]  Batch 422: Training set : loss - 0.5764, accuracy - 0.663, recall - 0.7609, AUC - 0.812, F1 - 0.6931, precision - 0.6364, training time - -7.0 seconds
2023-03-25 19:09:00,509 : [INFO]  Batch 422: Testing set : loss - 0.5824, accuracy - 0.6765, recall - 0.8137, AUC - 0.8205, F1 - 0.7155, precision - 0.6385
2023-03-25 19:09:00,523 : [INFO]  Batch 423 initialized 
2023-03-25 19:09:00,987 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:01,979 : [INFO]  ------------------------- Batch 423 training: round 1 -------------------------
2023-03-25 19:09:05,464 : [INFO]  ------------------------- Batch round 1, loss: 0.5927 -------------------------
2023-03-25 19:09:05,464 : [INFO]  ------------------------- Batch 423, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:05,515 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:05,518 : [INFO]  ------------------------- Batch 423 training: round 2 -------------------------
2023-03-25 19:09:07,246 : [INFO]  ------------------------- Batch round 2, loss: 0.5842 -------------------------
2023-03-25 19:09:07,246 : [INFO]  ------------------------- Batch 423, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:07,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:07,344 : [INFO]  ------------------------- Batch 423 training: round 3 -------------------------
2023-03-25 19:09:09,054 : [INFO]  ------------------------- Batch round 3, loss: 0.5862 -------------------------
2023-03-25 19:09:09,054 : [INFO]  ------------------------- Batch 423, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:09,183 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:09,185 : [INFO]  Batch number 423 model fetched from the server
2023-03-25 19:09:09,186 : [INFO]  ################ Batch 423: final global model evalution after 3 rounds ################
2023-03-25 19:09:10,370 : [INFO]  Batch 423: Training set : loss - 0.5958, accuracy - 0.6902, recall - 0.8478, AUC - 0.8107, F1 - 0.7324, precision - 0.6446, training time - -7.0 seconds
2023-03-25 19:09:10,370 : [INFO]  Batch 423: Testing set : loss - 0.5772, accuracy - 0.7157, recall - 0.8235, AUC - 0.8318, F1 - 0.7434, precision - 0.6774
2023-03-25 19:09:10,381 : [INFO]  Batch 424 initialized 
2023-03-25 19:09:10,834 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:11,810 : [INFO]  ------------------------- Batch 424 training: round 1 -------------------------
2023-03-25 19:09:15,215 : [INFO]  ------------------------- Batch round 1, loss: 0.5971 -------------------------
2023-03-25 19:09:15,215 : [INFO]  ------------------------- Batch 424, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:15,246 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:15,248 : [INFO]  ------------------------- Batch 424 training: round 2 -------------------------
2023-03-25 19:09:17,003 : [INFO]  ------------------------- Batch round 2, loss: 0.6017 -------------------------
2023-03-25 19:09:17,003 : [INFO]  ------------------------- Batch 424, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:17,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:17,033 : [INFO]  ------------------------- Batch 424 training: round 3 -------------------------
2023-03-25 19:09:18,810 : [INFO]  ------------------------- Batch round 3, loss: 0.6038 -------------------------
2023-03-25 19:09:18,810 : [INFO]  ------------------------- Batch 424, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:18,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:18,828 : [INFO]  Batch number 424 model fetched from the server
2023-03-25 19:09:18,828 : [INFO]  ################ Batch 424: final global model evalution after 3 rounds ################
2023-03-25 19:09:20,037 : [INFO]  Batch 424: Training set : loss - 0.6139, accuracy - 0.663, recall - 0.7717, AUC - 0.7621, F1 - 0.6961, precision - 0.6339, training time - -7.0 seconds
2023-03-25 19:09:20,037 : [INFO]  Batch 424: Testing set : loss - 0.5749, accuracy - 0.6765, recall - 0.8137, AUC - 0.8363, F1 - 0.7155, precision - 0.6385
2023-03-25 19:09:20,054 : [INFO]  Batch 425 initialized 
2023-03-25 19:09:20,512 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:21,497 : [INFO]  ------------------------- Batch 425 training: round 1 -------------------------
2023-03-25 19:09:25,105 : [INFO]  ------------------------- Batch round 1, loss: 0.5709 -------------------------
2023-03-25 19:09:25,105 : [INFO]  ------------------------- Batch 425, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:25,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:25,124 : [INFO]  ------------------------- Batch 425 training: round 2 -------------------------
2023-03-25 19:09:26,992 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-25 19:09:26,992 : [INFO]  ------------------------- Batch 425, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:27,010 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:27,013 : [INFO]  ------------------------- Batch 425 training: round 3 -------------------------
2023-03-25 19:09:28,923 : [INFO]  ------------------------- Batch round 3, loss: 0.5738 -------------------------
2023-03-25 19:09:28,923 : [INFO]  ------------------------- Batch 425, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:28,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:28,942 : [INFO]  Batch number 425 model fetched from the server
2023-03-25 19:09:28,942 : [INFO]  ################ Batch 425: final global model evalution after 3 rounds ################
2023-03-25 19:09:30,178 : [INFO]  Batch 425: Training set : loss - 0.5868, accuracy - 0.6793, recall - 0.8152, AUC - 0.8226, F1 - 0.7177, precision - 0.641, training time - -7.0 seconds
2023-03-25 19:09:30,178 : [INFO]  Batch 425: Testing set : loss - 0.5837, accuracy - 0.701, recall - 0.8431, AUC - 0.8277, F1 - 0.7382, precision - 0.6565
2023-03-25 19:09:30,185 : [INFO]  Batch 426 initialized 
2023-03-25 19:09:30,656 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:31,647 : [INFO]  ------------------------- Batch 426 training: round 1 -------------------------
2023-03-25 19:09:35,314 : [INFO]  ------------------------- Batch round 1, loss: 0.5849 -------------------------
2023-03-25 19:09:35,314 : [INFO]  ------------------------- Batch 426, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:35,346 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:35,349 : [INFO]  ------------------------- Batch 426 training: round 2 -------------------------
2023-03-25 19:09:37,200 : [INFO]  ------------------------- Batch round 2, loss: 0.592 -------------------------
2023-03-25 19:09:37,200 : [INFO]  ------------------------- Batch 426, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:37,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:37,219 : [INFO]  ------------------------- Batch 426 training: round 3 -------------------------
2023-03-25 19:09:39,077 : [INFO]  ------------------------- Batch round 3, loss: 0.5853 -------------------------
2023-03-25 19:09:39,077 : [INFO]  ------------------------- Batch 426, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:39,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:39,097 : [INFO]  Batch number 426 model fetched from the server
2023-03-25 19:09:39,097 : [INFO]  ################ Batch 426: final global model evalution after 3 rounds ################
2023-03-25 19:09:40,311 : [INFO]  Batch 426: Training set : loss - 0.603, accuracy - 0.6413, recall - 0.7609, AUC - 0.7745, F1 - 0.6796, precision - 0.614, training time - -7.0 seconds
2023-03-25 19:09:40,311 : [INFO]  Batch 426: Testing set : loss - 0.6063, accuracy - 0.6765, recall - 0.7941, AUC - 0.7854, F1 - 0.7105, precision - 0.6429
2023-03-25 19:09:40,321 : [INFO]  Batch 427 initialized 
2023-03-25 19:09:40,775 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:41,762 : [INFO]  ------------------------- Batch 427 training: round 1 -------------------------
2023-03-25 19:09:45,265 : [INFO]  ------------------------- Batch round 1, loss: 0.6086 -------------------------
2023-03-25 19:09:45,265 : [INFO]  ------------------------- Batch 427, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:45,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:45,290 : [INFO]  ------------------------- Batch 427 training: round 2 -------------------------
2023-03-25 19:09:47,045 : [INFO]  ------------------------- Batch round 2, loss: 0.6094 -------------------------
2023-03-25 19:09:47,045 : [INFO]  ------------------------- Batch 427, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:47,063 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:47,065 : [INFO]  ------------------------- Batch 427 training: round 3 -------------------------
2023-03-25 19:09:48,830 : [INFO]  ------------------------- Batch round 3, loss: 0.6101 -------------------------
2023-03-25 19:09:48,831 : [INFO]  ------------------------- Batch 427, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:48,887 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:48,889 : [INFO]  Batch number 427 model fetched from the server
2023-03-25 19:09:48,889 : [INFO]  ################ Batch 427: final global model evalution after 3 rounds ################
2023-03-25 19:09:50,103 : [INFO]  Batch 427: Training set : loss - 0.6177, accuracy - 0.6467, recall - 0.8043, AUC - 0.7692, F1 - 0.6948, precision - 0.6116, training time - -7.0 seconds
2023-03-25 19:09:50,104 : [INFO]  Batch 427: Testing set : loss - 0.5838, accuracy - 0.6814, recall - 0.8039, AUC - 0.8152, F1 - 0.7162, precision - 0.6457
2023-03-25 19:09:50,112 : [INFO]  Batch 428 initialized 
2023-03-25 19:09:50,576 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:51,600 : [INFO]  ------------------------- Batch 428 training: round 1 -------------------------
2023-03-25 19:09:55,216 : [INFO]  ------------------------- Batch round 1, loss: 0.5799 -------------------------
2023-03-25 19:09:55,216 : [INFO]  ------------------------- Batch 428, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:55,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:55,235 : [INFO]  ------------------------- Batch 428 training: round 2 -------------------------
2023-03-25 19:09:57,113 : [INFO]  ------------------------- Batch round 2, loss: 0.5794 -------------------------
2023-03-25 19:09:57,113 : [INFO]  ------------------------- Batch 428, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:57,129 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:57,131 : [INFO]  ------------------------- Batch 428 training: round 3 -------------------------
2023-03-25 19:09:59,086 : [INFO]  ------------------------- Batch round 3, loss: 0.5788 -------------------------
2023-03-25 19:09:59,087 : [INFO]  ------------------------- Batch 428, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:59,103 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:59,106 : [INFO]  Batch number 428 model fetched from the server
2023-03-25 19:09:59,106 : [INFO]  ################ Batch 428: final global model evalution after 3 rounds ################
2023-03-25 19:10:00,306 : [INFO]  Batch 428: Training set : loss - 0.5954, accuracy - 0.6576, recall - 0.7935, AUC - 0.7957, F1 - 0.6986, precision - 0.6239, training time - -8.0 seconds
2023-03-25 19:10:00,306 : [INFO]  Batch 428: Testing set : loss - 0.5911, accuracy - 0.652, recall - 0.8137, AUC - 0.8126, F1 - 0.7004, precision - 0.6148
2023-03-25 19:10:00,315 : [INFO]  Batch 429 initialized 
2023-03-25 19:10:00,795 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:01,795 : [INFO]  ------------------------- Batch 429 training: round 1 -------------------------
2023-03-25 19:10:05,212 : [INFO]  ------------------------- Batch round 1, loss: 0.5442 -------------------------
2023-03-25 19:10:05,213 : [INFO]  ------------------------- Batch 429, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:05,246 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:05,249 : [INFO]  ------------------------- Batch 429 training: round 2 -------------------------
2023-03-25 19:10:06,943 : [INFO]  ------------------------- Batch round 2, loss: 0.5418 -------------------------
2023-03-25 19:10:06,943 : [INFO]  ------------------------- Batch 429, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:07,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:07,043 : [INFO]  ------------------------- Batch 429 training: round 3 -------------------------
2023-03-25 19:10:08,754 : [INFO]  ------------------------- Batch round 3, loss: 0.54 -------------------------
2023-03-25 19:10:08,754 : [INFO]  ------------------------- Batch 429, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:08,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:08,818 : [INFO]  Batch number 429 model fetched from the server
2023-03-25 19:10:08,818 : [INFO]  ################ Batch 429: final global model evalution after 3 rounds ################
2023-03-25 19:10:10,006 : [INFO]  Batch 429: Training set : loss - 0.5462, accuracy - 0.7772, recall - 0.8913, AUC - 0.8808, F1 - 0.8, precision - 0.7257, training time - -7.0 seconds
2023-03-25 19:10:10,007 : [INFO]  Batch 429: Testing set : loss - 0.5931, accuracy - 0.6373, recall - 0.8431, AUC - 0.8253, F1 - 0.6992, precision - 0.5972
2023-03-25 19:10:10,017 : [INFO]  Batch 430 initialized 
2023-03-25 19:10:10,475 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:11,466 : [INFO]  ------------------------- Batch 430 training: round 1 -------------------------
2023-03-25 19:10:14,936 : [INFO]  ------------------------- Batch round 1, loss: 0.5745 -------------------------
2023-03-25 19:10:14,937 : [INFO]  ------------------------- Batch 430, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:14,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:14,957 : [INFO]  ------------------------- Batch 430 training: round 2 -------------------------
2023-03-25 19:10:16,766 : [INFO]  ------------------------- Batch round 2, loss: 0.5737 -------------------------
2023-03-25 19:10:16,766 : [INFO]  ------------------------- Batch 430, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:16,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:16,786 : [INFO]  ------------------------- Batch 430 training: round 3 -------------------------
2023-03-25 19:10:18,626 : [INFO]  ------------------------- Batch round 3, loss: 0.5748 -------------------------
2023-03-25 19:10:18,626 : [INFO]  ------------------------- Batch 430, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:18,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:18,645 : [INFO]  Batch number 430 model fetched from the server
2023-03-25 19:10:18,645 : [INFO]  ################ Batch 430: final global model evalution after 3 rounds ################
2023-03-25 19:10:19,818 : [INFO]  Batch 430: Training set : loss - 0.5845, accuracy - 0.6467, recall - 0.8152, AUC - 0.8201, F1 - 0.6977, precision - 0.6098, training time - -7.0 seconds
2023-03-25 19:10:19,818 : [INFO]  Batch 430: Testing set : loss - 0.5904, accuracy - 0.6814, recall - 0.7941, AUC - 0.8078, F1 - 0.7137, precision - 0.648
2023-03-25 19:10:19,833 : [INFO]  Batch 431 initialized 
2023-03-25 19:10:20,297 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:21,312 : [INFO]  ------------------------- Batch 431 training: round 1 -------------------------
2023-03-25 19:10:24,857 : [INFO]  ------------------------- Batch round 1, loss: 0.5677 -------------------------
2023-03-25 19:10:24,857 : [INFO]  ------------------------- Batch 431, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:24,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:24,875 : [INFO]  ------------------------- Batch 431 training: round 2 -------------------------
2023-03-25 19:10:26,662 : [INFO]  ------------------------- Batch round 2, loss: 0.5686 -------------------------
2023-03-25 19:10:26,662 : [INFO]  ------------------------- Batch 431, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:26,681 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:26,686 : [INFO]  ------------------------- Batch 431 training: round 3 -------------------------
2023-03-25 19:10:28,506 : [INFO]  ------------------------- Batch round 3, loss: 0.5706 -------------------------
2023-03-25 19:10:28,506 : [INFO]  ------------------------- Batch 431, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:28,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:28,524 : [INFO]  Batch number 431 model fetched from the server
2023-03-25 19:10:28,524 : [INFO]  ################ Batch 431: final global model evalution after 3 rounds ################
2023-03-25 19:10:29,719 : [INFO]  Batch 431: Training set : loss - 0.5795, accuracy - 0.6848, recall - 0.837, AUC - 0.8293, F1 - 0.7264, precision - 0.6417, training time - -7.0 seconds
2023-03-25 19:10:29,719 : [INFO]  Batch 431: Testing set : loss - 0.6207, accuracy - 0.6078, recall - 0.7549, AUC - 0.7665, F1 - 0.6581, precision - 0.5833
2023-03-25 19:10:29,729 : [INFO]  Batch 432 initialized 
2023-03-25 19:10:30,183 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:31,189 : [INFO]  ------------------------- Batch 432 training: round 1 -------------------------
2023-03-25 19:10:34,673 : [INFO]  ------------------------- Batch round 1, loss: 0.579 -------------------------
2023-03-25 19:10:34,674 : [INFO]  ------------------------- Batch 432, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:34,698 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:34,700 : [INFO]  ------------------------- Batch 432 training: round 2 -------------------------
2023-03-25 19:10:36,499 : [INFO]  ------------------------- Batch round 2, loss: 0.5797 -------------------------
2023-03-25 19:10:36,499 : [INFO]  ------------------------- Batch 432, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:36,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:36,531 : [INFO]  ------------------------- Batch 432 training: round 3 -------------------------
2023-03-25 19:10:38,282 : [INFO]  ------------------------- Batch round 3, loss: 0.5817 -------------------------
2023-03-25 19:10:38,282 : [INFO]  ------------------------- Batch 432, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:38,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:38,326 : [INFO]  Batch number 432 model fetched from the server
2023-03-25 19:10:38,326 : [INFO]  ################ Batch 432: final global model evalution after 3 rounds ################
2023-03-25 19:10:39,493 : [INFO]  Batch 432: Training set : loss - 0.5914, accuracy - 0.6522, recall - 0.8478, AUC - 0.8277, F1 - 0.7091, precision - 0.6094, training time - -7.0 seconds
2023-03-25 19:10:39,493 : [INFO]  Batch 432: Testing set : loss - 0.5901, accuracy - 0.6765, recall - 0.8039, AUC - 0.8131, F1 - 0.713, precision - 0.6406
2023-03-25 19:10:39,507 : [INFO]  Batch 433 initialized 
2023-03-25 19:10:39,974 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:40,997 : [INFO]  ------------------------- Batch 433 training: round 1 -------------------------
2023-03-25 19:10:44,825 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-25 19:10:44,825 : [INFO]  ------------------------- Batch 433, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:44,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:44,867 : [INFO]  ------------------------- Batch 433 training: round 2 -------------------------
2023-03-25 19:10:46,718 : [INFO]  ------------------------- Batch round 2, loss: 0.5724 -------------------------
2023-03-25 19:10:46,718 : [INFO]  ------------------------- Batch 433, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:46,760 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:46,763 : [INFO]  ------------------------- Batch 433 training: round 3 -------------------------
2023-03-25 19:10:48,609 : [INFO]  ------------------------- Batch round 3, loss: 0.5729 -------------------------
2023-03-25 19:10:48,609 : [INFO]  ------------------------- Batch 433, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:48,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:48,627 : [INFO]  Batch number 433 model fetched from the server
2023-03-25 19:10:48,627 : [INFO]  ################ Batch 433: final global model evalution after 3 rounds ################
2023-03-25 19:10:49,871 : [INFO]  Batch 433: Training set : loss - 0.5868, accuracy - 0.6957, recall - 0.8043, AUC - 0.8081, F1 - 0.7255, precision - 0.6607, training time - -8.0 seconds
2023-03-25 19:10:49,871 : [INFO]  Batch 433: Testing set : loss - 0.5953, accuracy - 0.6667, recall - 0.8039, AUC - 0.7999, F1 - 0.7069, precision - 0.6308
2023-03-25 19:10:49,880 : [INFO]  Batch 434 initialized 
2023-03-25 19:10:50,358 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:51,433 : [INFO]  ------------------------- Batch 434 training: round 1 -------------------------
2023-03-25 19:10:54,892 : [INFO]  ------------------------- Batch round 1, loss: 0.5586 -------------------------
2023-03-25 19:10:54,893 : [INFO]  ------------------------- Batch 434, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:54,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:54,911 : [INFO]  ------------------------- Batch 434 training: round 2 -------------------------
2023-03-25 19:10:56,697 : [INFO]  ------------------------- Batch round 2, loss: 0.5548 -------------------------
2023-03-25 19:10:56,697 : [INFO]  ------------------------- Batch 434, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:56,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:56,716 : [INFO]  ------------------------- Batch 434 training: round 3 -------------------------
2023-03-25 19:10:58,478 : [INFO]  ------------------------- Batch round 3, loss: 0.5512 -------------------------
2023-03-25 19:10:58,478 : [INFO]  ------------------------- Batch 434, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:58,495 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:58,499 : [INFO]  Batch number 434 model fetched from the server
2023-03-25 19:10:58,499 : [INFO]  ################ Batch 434: final global model evalution after 3 rounds ################
2023-03-25 19:10:59,679 : [INFO]  Batch 434: Training set : loss - 0.5605, accuracy - 0.7283, recall - 0.8804, AUC - 0.8617, F1 - 0.7642, precision - 0.675, training time - -7.0 seconds
2023-03-25 19:10:59,679 : [INFO]  Batch 434: Testing set : loss - 0.5844, accuracy - 0.6569, recall - 0.8137, AUC - 0.8301, F1 - 0.7034, precision - 0.6194
2023-03-25 19:10:59,689 : [INFO]  Batch 435 initialized 
2023-03-25 19:11:00,159 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:01,170 : [INFO]  ------------------------- Batch 435 training: round 1 -------------------------
2023-03-25 19:11:04,648 : [INFO]  ------------------------- Batch round 1, loss: 0.5889 -------------------------
2023-03-25 19:11:04,648 : [INFO]  ------------------------- Batch 435, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:04,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:04,666 : [INFO]  ------------------------- Batch 435 training: round 2 -------------------------
2023-03-25 19:11:06,447 : [INFO]  ------------------------- Batch round 2, loss: 0.5921 -------------------------
2023-03-25 19:11:06,447 : [INFO]  ------------------------- Batch 435, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:06,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:06,466 : [INFO]  ------------------------- Batch 435 training: round 3 -------------------------
2023-03-25 19:11:08,281 : [INFO]  ------------------------- Batch round 3, loss: 0.59 -------------------------
2023-03-25 19:11:08,281 : [INFO]  ------------------------- Batch 435, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:08,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:08,299 : [INFO]  Batch number 435 model fetched from the server
2023-03-25 19:11:08,300 : [INFO]  ################ Batch 435: final global model evalution after 3 rounds ################
2023-03-25 19:11:09,479 : [INFO]  Batch 435: Training set : loss - 0.6052, accuracy - 0.6413, recall - 0.7717, AUC - 0.7836, F1 - 0.6827, precision - 0.6121, training time - -7.0 seconds
2023-03-25 19:11:09,479 : [INFO]  Batch 435: Testing set : loss - 0.5919, accuracy - 0.6716, recall - 0.8137, AUC - 0.8096, F1 - 0.7124, precision - 0.6336
2023-03-25 19:11:09,486 : [INFO]  Batch 436 initialized 
2023-03-25 19:11:09,942 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:10,958 : [INFO]  ------------------------- Batch 436 training: round 1 -------------------------
2023-03-25 19:11:14,392 : [INFO]  ------------------------- Batch round 1, loss: 0.5721 -------------------------
2023-03-25 19:11:14,392 : [INFO]  ------------------------- Batch 436, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:14,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:14,457 : [INFO]  ------------------------- Batch 436 training: round 2 -------------------------
2023-03-25 19:11:16,267 : [INFO]  ------------------------- Batch round 2, loss: 0.5788 -------------------------
2023-03-25 19:11:16,267 : [INFO]  ------------------------- Batch 436, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:16,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:16,321 : [INFO]  ------------------------- Batch 436 training: round 3 -------------------------
2023-03-25 19:11:18,104 : [INFO]  ------------------------- Batch round 3, loss: 0.5738 -------------------------
2023-03-25 19:11:18,104 : [INFO]  ------------------------- Batch 436, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:18,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:18,172 : [INFO]  Batch number 436 model fetched from the server
2023-03-25 19:11:18,172 : [INFO]  ################ Batch 436: final global model evalution after 3 rounds ################
2023-03-25 19:11:19,359 : [INFO]  Batch 436: Training set : loss - 0.5826, accuracy - 0.6957, recall - 0.837, AUC - 0.8395, F1 - 0.7333, precision - 0.6525, training time - -7.0 seconds
2023-03-25 19:11:19,359 : [INFO]  Batch 436: Testing set : loss - 0.5863, accuracy - 0.6814, recall - 0.8627, AUC - 0.8438, F1 - 0.7303, precision - 0.6331
2023-03-25 19:11:19,369 : [INFO]  Batch 437 initialized 
2023-03-25 19:11:19,819 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:20,828 : [INFO]  ------------------------- Batch 437 training: round 1 -------------------------
2023-03-25 19:11:24,332 : [INFO]  ------------------------- Batch round 1, loss: 0.5926 -------------------------
2023-03-25 19:11:24,332 : [INFO]  ------------------------- Batch 437, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:24,453 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:24,456 : [INFO]  ------------------------- Batch 437 training: round 2 -------------------------
2023-03-25 19:11:26,267 : [INFO]  ------------------------- Batch round 2, loss: 0.6003 -------------------------
2023-03-25 19:11:26,267 : [INFO]  ------------------------- Batch 437, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:26,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:26,377 : [INFO]  ------------------------- Batch 437 training: round 3 -------------------------
2023-03-25 19:11:28,159 : [INFO]  ------------------------- Batch round 3, loss: 0.5962 -------------------------
2023-03-25 19:11:28,160 : [INFO]  ------------------------- Batch 437, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:28,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:28,250 : [INFO]  Batch number 437 model fetched from the server
2023-03-25 19:11:28,250 : [INFO]  ################ Batch 437: final global model evalution after 3 rounds ################
2023-03-25 19:11:29,453 : [INFO]  Batch 437: Training set : loss - 0.6086, accuracy - 0.6467, recall - 0.8152, AUC - 0.8035, F1 - 0.6977, precision - 0.6098, training time - -7.0 seconds
2023-03-25 19:11:29,453 : [INFO]  Batch 437: Testing set : loss - 0.5692, accuracy - 0.7059, recall - 0.8039, AUC - 0.8324, F1 - 0.7321, precision - 0.6721
2023-03-25 19:11:29,461 : [INFO]  Batch 438 initialized 
2023-03-25 19:11:29,915 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:30,928 : [INFO]  ------------------------- Batch 438 training: round 1 -------------------------
2023-03-25 19:11:34,426 : [INFO]  ------------------------- Batch round 1, loss: 0.5742 -------------------------
2023-03-25 19:11:34,426 : [INFO]  ------------------------- Batch 438, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:34,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:34,447 : [INFO]  ------------------------- Batch 438 training: round 2 -------------------------
2023-03-25 19:11:36,236 : [INFO]  ------------------------- Batch round 2, loss: 0.5679 -------------------------
2023-03-25 19:11:36,237 : [INFO]  ------------------------- Batch 438, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:36,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:36,258 : [INFO]  ------------------------- Batch 438 training: round 3 -------------------------
2023-03-25 19:11:38,065 : [INFO]  ------------------------- Batch round 3, loss: 0.5735 -------------------------
2023-03-25 19:11:38,065 : [INFO]  ------------------------- Batch 438, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:38,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:38,084 : [INFO]  Batch number 438 model fetched from the server
2023-03-25 19:11:38,084 : [INFO]  ################ Batch 438: final global model evalution after 3 rounds ################
2023-03-25 19:11:39,297 : [INFO]  Batch 438: Training set : loss - 0.5805, accuracy - 0.7174, recall - 0.8804, AUC - 0.8392, F1 - 0.757, precision - 0.6639, training time - -7.0 seconds
2023-03-25 19:11:39,298 : [INFO]  Batch 438: Testing set : loss - 0.5756, accuracy - 0.6912, recall - 0.8529, AUC - 0.847, F1 - 0.7342, precision - 0.6444
2023-03-25 19:11:39,306 : [INFO]  Batch 439 initialized 
2023-03-25 19:11:39,795 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:40,789 : [INFO]  ------------------------- Batch 439 training: round 1 -------------------------
2023-03-25 19:11:44,306 : [INFO]  ------------------------- Batch round 1, loss: 0.5572 -------------------------
2023-03-25 19:11:44,306 : [INFO]  ------------------------- Batch 439, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:44,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:44,324 : [INFO]  ------------------------- Batch 439 training: round 2 -------------------------
2023-03-25 19:11:46,159 : [INFO]  ------------------------- Batch round 2, loss: 0.5597 -------------------------
2023-03-25 19:11:46,159 : [INFO]  ------------------------- Batch 439, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:46,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:46,177 : [INFO]  ------------------------- Batch 439 training: round 3 -------------------------
2023-03-25 19:11:48,013 : [INFO]  ------------------------- Batch round 3, loss: 0.558 -------------------------
2023-03-25 19:11:48,013 : [INFO]  ------------------------- Batch 439, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:48,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:48,031 : [INFO]  Batch number 439 model fetched from the server
2023-03-25 19:11:48,031 : [INFO]  ################ Batch 439: final global model evalution after 3 rounds ################
2023-03-25 19:11:49,222 : [INFO]  Batch 439: Training set : loss - 0.569, accuracy - 0.6848, recall - 0.8261, AUC - 0.8412, F1 - 0.7238, precision - 0.6441, training time - -7.0 seconds
2023-03-25 19:11:49,222 : [INFO]  Batch 439: Testing set : loss - 0.5824, accuracy - 0.6814, recall - 0.8725, AUC - 0.8465, F1 - 0.7325, precision - 0.6312
2023-03-25 19:11:49,232 : [INFO]  Batch 440 initialized 
2023-03-25 19:11:49,688 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:50,718 : [INFO]  ------------------------- Batch 440 training: round 1 -------------------------
2023-03-25 19:11:54,098 : [INFO]  ------------------------- Batch round 1, loss: 0.5456 -------------------------
2023-03-25 19:11:54,098 : [INFO]  ------------------------- Batch 440, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:54,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:54,123 : [INFO]  ------------------------- Batch 440 training: round 2 -------------------------
2023-03-25 19:11:55,922 : [INFO]  ------------------------- Batch round 2, loss: 0.5403 -------------------------
2023-03-25 19:11:55,922 : [INFO]  ------------------------- Batch 440, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:55,941 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:55,943 : [INFO]  ------------------------- Batch 440 training: round 3 -------------------------
2023-03-25 19:11:57,712 : [INFO]  ------------------------- Batch round 3, loss: 0.5522 -------------------------
2023-03-25 19:11:57,712 : [INFO]  ------------------------- Batch 440, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:57,729 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:57,731 : [INFO]  Batch number 440 model fetched from the server
2023-03-25 19:11:57,731 : [INFO]  ################ Batch 440: final global model evalution after 3 rounds ################
2023-03-25 19:11:58,927 : [INFO]  Batch 440: Training set : loss - 0.5533, accuracy - 0.7283, recall - 0.8261, AUC - 0.8619, F1 - 0.7525, precision - 0.6909, training time - -7.0 seconds
2023-03-25 19:11:58,927 : [INFO]  Batch 440: Testing set : loss - 0.5642, accuracy - 0.7157, recall - 0.8431, AUC - 0.8553, F1 - 0.7478, precision - 0.6719
2023-03-25 19:11:58,940 : [INFO]  Batch 441 initialized 
2023-03-25 19:11:59,401 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:00,411 : [INFO]  ------------------------- Batch 441 training: round 1 -------------------------
2023-03-25 19:12:03,861 : [INFO]  ------------------------- Batch round 1, loss: 0.5734 -------------------------
2023-03-25 19:12:03,861 : [INFO]  ------------------------- Batch 441, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:03,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:03,887 : [INFO]  ------------------------- Batch 441 training: round 2 -------------------------
2023-03-25 19:12:05,723 : [INFO]  ------------------------- Batch round 2, loss: 0.5777 -------------------------
2023-03-25 19:12:05,723 : [INFO]  ------------------------- Batch 441, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:05,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:05,743 : [INFO]  ------------------------- Batch 441 training: round 3 -------------------------
2023-03-25 19:12:07,503 : [INFO]  ------------------------- Batch round 3, loss: 0.577 -------------------------
2023-03-25 19:12:07,503 : [INFO]  ------------------------- Batch 441, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:07,523 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:07,525 : [INFO]  Batch number 441 model fetched from the server
2023-03-25 19:12:07,525 : [INFO]  ################ Batch 441: final global model evalution after 3 rounds ################
2023-03-25 19:12:08,697 : [INFO]  Batch 441: Training set : loss - 0.591, accuracy - 0.6522, recall - 0.8478, AUC - 0.8419, F1 - 0.7091, precision - 0.6094, training time - -7.0 seconds
2023-03-25 19:12:08,697 : [INFO]  Batch 441: Testing set : loss - 0.565, accuracy - 0.7108, recall - 0.8627, AUC - 0.8607, F1 - 0.7489, precision - 0.6617
2023-03-25 19:12:08,716 : [INFO]  Batch 442 initialized 
2023-03-25 19:12:09,171 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:10,179 : [INFO]  ------------------------- Batch 442 training: round 1 -------------------------
2023-03-25 19:12:13,726 : [INFO]  ------------------------- Batch round 1, loss: 0.5991 -------------------------
2023-03-25 19:12:13,727 : [INFO]  ------------------------- Batch 442, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:13,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:13,745 : [INFO]  ------------------------- Batch 442 training: round 2 -------------------------
2023-03-25 19:12:15,565 : [INFO]  ------------------------- Batch round 2, loss: 0.5938 -------------------------
2023-03-25 19:12:15,565 : [INFO]  ------------------------- Batch 442, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:15,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:15,585 : [INFO]  ------------------------- Batch 442 training: round 3 -------------------------
2023-03-25 19:12:17,887 : [INFO]  ------------------------- Batch round 3, loss: 0.6012 -------------------------
2023-03-25 19:12:17,887 : [INFO]  ------------------------- Batch 442, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:17,904 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:17,905 : [INFO]  Batch number 442 model fetched from the server
2023-03-25 19:12:17,905 : [INFO]  ################ Batch 442: final global model evalution after 3 rounds ################
2023-03-25 19:12:19,081 : [INFO]  Batch 442: Training set : loss - 0.6124, accuracy - 0.6304, recall - 0.8043, AUC - 0.7821, F1 - 0.6852, precision - 0.5968, training time - -8.0 seconds
2023-03-25 19:12:19,081 : [INFO]  Batch 442: Testing set : loss - 0.5467, accuracy - 0.7353, recall - 0.8529, AUC - 0.8884, F1 - 0.7632, precision - 0.6905
2023-03-25 19:12:19,092 : [INFO]  Batch 443 initialized 
2023-03-25 19:12:19,539 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:20,563 : [INFO]  ------------------------- Batch 443 training: round 1 -------------------------
2023-03-25 19:12:24,073 : [INFO]  ------------------------- Batch round 1, loss: 0.553 -------------------------
2023-03-25 19:12:24,073 : [INFO]  ------------------------- Batch 443, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:24,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:24,092 : [INFO]  ------------------------- Batch 443 training: round 2 -------------------------
2023-03-25 19:12:25,848 : [INFO]  ------------------------- Batch round 2, loss: 0.5472 -------------------------
2023-03-25 19:12:25,849 : [INFO]  ------------------------- Batch 443, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:25,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:25,882 : [INFO]  ------------------------- Batch 443 training: round 3 -------------------------
2023-03-25 19:12:27,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5485 -------------------------
2023-03-25 19:12:27,579 : [INFO]  ------------------------- Batch 443, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:27,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:27,670 : [INFO]  Batch number 443 model fetched from the server
2023-03-25 19:12:27,671 : [INFO]  ################ Batch 443: final global model evalution after 3 rounds ################
2023-03-25 19:12:28,895 : [INFO]  Batch 443: Training set : loss - 0.559, accuracy - 0.7174, recall - 0.8696, AUC - 0.8722, F1 - 0.7547, precision - 0.6667, training time - -7.0 seconds
2023-03-25 19:12:28,895 : [INFO]  Batch 443: Testing set : loss - 0.5809, accuracy - 0.6716, recall - 0.8529, AUC - 0.8484, F1 - 0.722, precision - 0.6259
2023-03-25 19:12:28,902 : [INFO]  Batch 444 initialized 
2023-03-25 19:12:29,349 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:30,391 : [INFO]  ------------------------- Batch 444 training: round 1 -------------------------
2023-03-25 19:12:33,823 : [INFO]  ------------------------- Batch round 1, loss: 0.5834 -------------------------
2023-03-25 19:12:33,823 : [INFO]  ------------------------- Batch 444, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:33,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:33,842 : [INFO]  ------------------------- Batch 444 training: round 2 -------------------------
2023-03-25 19:12:35,652 : [INFO]  ------------------------- Batch round 2, loss: 0.5817 -------------------------
2023-03-25 19:12:35,652 : [INFO]  ------------------------- Batch 444, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:35,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:35,671 : [INFO]  ------------------------- Batch 444 training: round 3 -------------------------
2023-03-25 19:12:37,474 : [INFO]  ------------------------- Batch round 3, loss: 0.5766 -------------------------
2023-03-25 19:12:37,474 : [INFO]  ------------------------- Batch 444, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:37,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:37,493 : [INFO]  Batch number 444 model fetched from the server
2023-03-25 19:12:37,493 : [INFO]  ################ Batch 444: final global model evalution after 3 rounds ################
2023-03-25 19:12:38,701 : [INFO]  Batch 444: Training set : loss - 0.5934, accuracy - 0.6576, recall - 0.8152, AUC - 0.8006, F1 - 0.7042, precision - 0.6198, training time - -7.0 seconds
2023-03-25 19:12:38,701 : [INFO]  Batch 444: Testing set : loss - 0.607, accuracy - 0.6127, recall - 0.7843, AUC - 0.7927, F1 - 0.6695, precision - 0.5839
2023-03-25 19:12:38,711 : [INFO]  Batch 445 initialized 
2023-03-25 19:12:39,166 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:40,179 : [INFO]  ------------------------- Batch 445 training: round 1 -------------------------
2023-03-25 19:12:43,643 : [INFO]  ------------------------- Batch round 1, loss: 0.5681 -------------------------
2023-03-25 19:12:43,643 : [INFO]  ------------------------- Batch 445, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:43,660 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:43,662 : [INFO]  ------------------------- Batch 445 training: round 2 -------------------------
2023-03-25 19:12:45,447 : [INFO]  ------------------------- Batch round 2, loss: 0.5557 -------------------------
2023-03-25 19:12:45,447 : [INFO]  ------------------------- Batch 445, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:45,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:45,466 : [INFO]  ------------------------- Batch 445 training: round 3 -------------------------
2023-03-25 19:12:47,246 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-25 19:12:47,246 : [INFO]  ------------------------- Batch 445, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:47,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:47,268 : [INFO]  Batch number 445 model fetched from the server
2023-03-25 19:12:47,268 : [INFO]  ################ Batch 445: final global model evalution after 3 rounds ################
2023-03-25 19:12:48,507 : [INFO]  Batch 445: Training set : loss - 0.5701, accuracy - 0.6902, recall - 0.8152, AUC - 0.8477, F1 - 0.7246, precision - 0.6522, training time - -7.0 seconds
2023-03-25 19:12:48,507 : [INFO]  Batch 445: Testing set : loss - 0.5708, accuracy - 0.7108, recall - 0.8333, AUC - 0.8471, F1 - 0.7424, precision - 0.6693
2023-03-25 19:12:48,521 : [INFO]  Batch 446 initialized 
2023-03-25 19:12:48,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:50,005 : [INFO]  ------------------------- Batch 446 training: round 1 -------------------------
2023-03-25 19:12:53,421 : [INFO]  ------------------------- Batch round 1, loss: 0.5584 -------------------------
2023-03-25 19:12:53,421 : [INFO]  ------------------------- Batch 446, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:53,475 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:53,478 : [INFO]  ------------------------- Batch 446 training: round 2 -------------------------
2023-03-25 19:12:55,229 : [INFO]  ------------------------- Batch round 2, loss: 0.5686 -------------------------
2023-03-25 19:12:55,229 : [INFO]  ------------------------- Batch 446, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:55,264 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:55,266 : [INFO]  ------------------------- Batch 446 training: round 3 -------------------------
2023-03-25 19:12:57,058 : [INFO]  ------------------------- Batch round 3, loss: 0.5655 -------------------------
2023-03-25 19:12:57,058 : [INFO]  ------------------------- Batch 446, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:57,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:57,089 : [INFO]  Batch number 446 model fetched from the server
2023-03-25 19:12:57,089 : [INFO]  ################ Batch 446: final global model evalution after 3 rounds ################
2023-03-25 19:12:58,302 : [INFO]  Batch 446: Training set : loss - 0.5807, accuracy - 0.6739, recall - 0.837, AUC - 0.836, F1 - 0.7196, precision - 0.6311, training time - -7.0 seconds
2023-03-25 19:12:58,303 : [INFO]  Batch 446: Testing set : loss - 0.6087, accuracy - 0.6225, recall - 0.7941, AUC - 0.7924, F1 - 0.6778, precision - 0.5912
2023-03-25 19:12:58,317 : [INFO]  Batch 447 initialized 
2023-03-25 19:12:58,779 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:59,838 : [INFO]  ------------------------- Batch 447 training: round 1 -------------------------
2023-03-25 19:13:03,299 : [INFO]  ------------------------- Batch round 1, loss: 0.5436 -------------------------
2023-03-25 19:13:03,299 : [INFO]  ------------------------- Batch 447, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:03,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:03,324 : [INFO]  ------------------------- Batch 447 training: round 2 -------------------------
2023-03-25 19:13:05,129 : [INFO]  ------------------------- Batch round 2, loss: 0.5453 -------------------------
2023-03-25 19:13:05,129 : [INFO]  ------------------------- Batch 447, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:05,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:05,190 : [INFO]  ------------------------- Batch 447 training: round 3 -------------------------
2023-03-25 19:13:06,961 : [INFO]  ------------------------- Batch round 3, loss: 0.5453 -------------------------
2023-03-25 19:13:06,961 : [INFO]  ------------------------- Batch 447, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:07,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:07,101 : [INFO]  Batch number 447 model fetched from the server
2023-03-25 19:13:07,101 : [INFO]  ################ Batch 447: final global model evalution after 3 rounds ################
2023-03-25 19:13:08,310 : [INFO]  Batch 447: Training set : loss - 0.5563, accuracy - 0.7391, recall - 0.8587, AUC - 0.8632, F1 - 0.767, precision - 0.693, training time - -7.0 seconds
2023-03-25 19:13:08,310 : [INFO]  Batch 447: Testing set : loss - 0.5592, accuracy - 0.7157, recall - 0.8431, AUC - 0.8603, F1 - 0.7478, precision - 0.6719
2023-03-25 19:13:08,321 : [INFO]  Batch 448 initialized 
2023-03-25 19:13:08,787 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:09,834 : [INFO]  ------------------------- Batch 448 training: round 1 -------------------------
2023-03-25 19:13:13,379 : [INFO]  ------------------------- Batch round 1, loss: 0.5693 -------------------------
2023-03-25 19:13:13,379 : [INFO]  ------------------------- Batch 448, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:13,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:13,398 : [INFO]  ------------------------- Batch 448 training: round 2 -------------------------
2023-03-25 19:13:15,176 : [INFO]  ------------------------- Batch round 2, loss: 0.5662 -------------------------
2023-03-25 19:13:15,176 : [INFO]  ------------------------- Batch 448, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:15,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:15,253 : [INFO]  ------------------------- Batch 448 training: round 3 -------------------------
2023-03-25 19:13:17,061 : [INFO]  ------------------------- Batch round 3, loss: 0.5613 -------------------------
2023-03-25 19:13:17,061 : [INFO]  ------------------------- Batch 448, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:17,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:17,108 : [INFO]  Batch number 448 model fetched from the server
2023-03-25 19:13:17,108 : [INFO]  ################ Batch 448: final global model evalution after 3 rounds ################
2023-03-25 19:13:18,306 : [INFO]  Batch 448: Training set : loss - 0.5783, accuracy - 0.6848, recall - 0.837, AUC - 0.8403, F1 - 0.7264, precision - 0.6417, training time - -7.0 seconds
2023-03-25 19:13:18,306 : [INFO]  Batch 448: Testing set : loss - 0.5871, accuracy - 0.6912, recall - 0.7843, AUC - 0.8027, F1 - 0.7175, precision - 0.6612
2023-03-25 19:13:18,320 : [INFO]  Batch 449 initialized 
2023-03-25 19:13:18,787 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:19,837 : [INFO]  ------------------------- Batch 449 training: round 1 -------------------------
2023-03-25 19:13:23,466 : [INFO]  ------------------------- Batch round 1, loss: 0.5622 -------------------------
2023-03-25 19:13:23,466 : [INFO]  ------------------------- Batch 449, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:23,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:23,489 : [INFO]  ------------------------- Batch 449 training: round 2 -------------------------
2023-03-25 19:13:25,560 : [INFO]  ------------------------- Batch round 2, loss: 0.5677 -------------------------
2023-03-25 19:13:25,560 : [INFO]  ------------------------- Batch 449, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:25,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:25,578 : [INFO]  ------------------------- Batch 449 training: round 3 -------------------------
2023-03-25 19:13:27,390 : [INFO]  ------------------------- Batch round 3, loss: 0.5712 -------------------------
2023-03-25 19:13:27,390 : [INFO]  ------------------------- Batch 449, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:27,407 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:27,409 : [INFO]  Batch number 449 model fetched from the server
2023-03-25 19:13:27,409 : [INFO]  ################ Batch 449: final global model evalution after 3 rounds ################
2023-03-25 19:13:28,598 : [INFO]  Batch 449: Training set : loss - 0.5778, accuracy - 0.6467, recall - 0.837, AUC - 0.8511, F1 - 0.7032, precision - 0.6063, training time - -8.0 seconds
2023-03-25 19:13:28,599 : [INFO]  Batch 449: Testing set : loss - 0.562, accuracy - 0.7255, recall - 0.8725, AUC - 0.8685, F1 - 0.7607, precision - 0.6742
2023-03-25 19:13:28,613 : [INFO]  Batch 450 initialized 
2023-03-25 19:13:29,073 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:30,111 : [INFO]  ------------------------- Batch 450 training: round 1 -------------------------
2023-03-25 19:13:33,484 : [INFO]  ------------------------- Batch round 1, loss: 0.5614 -------------------------
2023-03-25 19:13:33,484 : [INFO]  ------------------------- Batch 450, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:33,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:33,523 : [INFO]  ------------------------- Batch 450 training: round 2 -------------------------
2023-03-25 19:13:35,260 : [INFO]  ------------------------- Batch round 2, loss: 0.5605 -------------------------
2023-03-25 19:13:35,260 : [INFO]  ------------------------- Batch 450, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:35,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:35,281 : [INFO]  ------------------------- Batch 450 training: round 3 -------------------------
2023-03-25 19:13:36,984 : [INFO]  ------------------------- Batch round 3, loss: 0.558 -------------------------
2023-03-25 19:13:36,984 : [INFO]  ------------------------- Batch 450, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:37,008 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:37,010 : [INFO]  Batch number 450 model fetched from the server
2023-03-25 19:13:37,010 : [INFO]  ################ Batch 450: final global model evalution after 3 rounds ################
2023-03-25 19:13:38,194 : [INFO]  Batch 450: Training set : loss - 0.5672, accuracy - 0.712, recall - 0.8804, AUC - 0.8629, F1 - 0.7535, precision - 0.6585, training time - -7.0 seconds
2023-03-25 19:13:38,194 : [INFO]  Batch 450: Testing set : loss - 0.5709, accuracy - 0.7157, recall - 0.8529, AUC - 0.8545, F1 - 0.75, precision - 0.6692
2023-03-25 19:13:38,206 : [INFO]  Batch 451 initialized 
2023-03-25 19:13:38,654 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:39,695 : [INFO]  ------------------------- Batch 451 training: round 1 -------------------------
2023-03-25 19:13:43,116 : [INFO]  ------------------------- Batch round 1, loss: 0.5485 -------------------------
2023-03-25 19:13:43,116 : [INFO]  ------------------------- Batch 451, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:43,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:43,165 : [INFO]  ------------------------- Batch 451 training: round 2 -------------------------
2023-03-25 19:13:44,900 : [INFO]  ------------------------- Batch round 2, loss: 0.5481 -------------------------
2023-03-25 19:13:44,900 : [INFO]  ------------------------- Batch 451, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:44,956 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:44,958 : [INFO]  ------------------------- Batch 451 training: round 3 -------------------------
2023-03-25 19:13:46,737 : [INFO]  ------------------------- Batch round 3, loss: 0.5496 -------------------------
2023-03-25 19:13:46,738 : [INFO]  ------------------------- Batch 451, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:46,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:46,775 : [INFO]  Batch number 451 model fetched from the server
2023-03-25 19:13:46,775 : [INFO]  ################ Batch 451: final global model evalution after 3 rounds ################
2023-03-25 19:13:47,990 : [INFO]  Batch 451: Training set : loss - 0.5585, accuracy - 0.7174, recall - 0.8913, AUC - 0.8866, F1 - 0.7593, precision - 0.6613, training time - -7.0 seconds
2023-03-25 19:13:47,991 : [INFO]  Batch 451: Testing set : loss - 0.5947, accuracy - 0.6716, recall - 0.8431, AUC - 0.8289, F1 - 0.7197, precision - 0.6277
2023-03-25 19:13:47,999 : [INFO]  Batch 452 initialized 
2023-03-25 19:13:48,463 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:49,489 : [INFO]  ------------------------- Batch 452 training: round 1 -------------------------
2023-03-25 19:13:52,929 : [INFO]  ------------------------- Batch round 1, loss: 0.5522 -------------------------
2023-03-25 19:13:52,929 : [INFO]  ------------------------- Batch 452, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:52,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:52,949 : [INFO]  ------------------------- Batch 452 training: round 2 -------------------------
2023-03-25 19:13:54,716 : [INFO]  ------------------------- Batch round 2, loss: 0.5523 -------------------------
2023-03-25 19:13:54,716 : [INFO]  ------------------------- Batch 452, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:54,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:54,775 : [INFO]  ------------------------- Batch 452 training: round 3 -------------------------
2023-03-25 19:13:56,543 : [INFO]  ------------------------- Batch round 3, loss: 0.5523 -------------------------
2023-03-25 19:13:56,543 : [INFO]  ------------------------- Batch 452, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:56,563 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:56,566 : [INFO]  Batch number 452 model fetched from the server
2023-03-25 19:13:56,566 : [INFO]  ################ Batch 452: final global model evalution after 3 rounds ################
2023-03-25 19:13:57,756 : [INFO]  Batch 452: Training set : loss - 0.5662, accuracy - 0.7391, recall - 0.9239, AUC - 0.8879, F1 - 0.7798, precision - 0.6746, training time - -7.0 seconds
2023-03-25 19:13:57,758 : [INFO]  Batch 452: Testing set : loss - 0.5795, accuracy - 0.7206, recall - 0.8627, AUC - 0.8435, F1 - 0.7554, precision - 0.6718
2023-03-25 19:13:57,770 : [INFO]  Batch 453 initialized 
2023-03-25 19:13:58,230 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:59,252 : [INFO]  ------------------------- Batch 453 training: round 1 -------------------------
2023-03-25 19:14:02,667 : [INFO]  ------------------------- Batch round 1, loss: 0.5548 -------------------------
2023-03-25 19:14:02,667 : [INFO]  ------------------------- Batch 453, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:02,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:02,686 : [INFO]  ------------------------- Batch 453 training: round 2 -------------------------
2023-03-25 19:14:04,459 : [INFO]  ------------------------- Batch round 2, loss: 0.5621 -------------------------
2023-03-25 19:14:04,459 : [INFO]  ------------------------- Batch 453, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:04,476 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:04,479 : [INFO]  ------------------------- Batch 453 training: round 3 -------------------------
2023-03-25 19:14:06,234 : [INFO]  ------------------------- Batch round 3, loss: 0.5627 -------------------------
2023-03-25 19:14:06,234 : [INFO]  ------------------------- Batch 453, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:06,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:06,254 : [INFO]  Batch number 453 model fetched from the server
2023-03-25 19:14:06,254 : [INFO]  ################ Batch 453: final global model evalution after 3 rounds ################
2023-03-25 19:14:07,584 : [INFO]  Batch 453: Training set : loss - 0.5719, accuracy - 0.6685, recall - 0.8587, AUC - 0.8731, F1 - 0.7215, precision - 0.622, training time - -7.0 seconds
2023-03-25 19:14:07,584 : [INFO]  Batch 453: Testing set : loss - 0.5723, accuracy - 0.6961, recall - 0.8627, AUC - 0.8594, F1 - 0.7395, precision - 0.6471
2023-03-25 19:14:07,597 : [INFO]  Batch 454 initialized 
2023-03-25 19:14:08,077 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:09,086 : [INFO]  ------------------------- Batch 454 training: round 1 -------------------------
2023-03-25 19:14:12,666 : [INFO]  ------------------------- Batch round 1, loss: 0.5846 -------------------------
2023-03-25 19:14:12,666 : [INFO]  ------------------------- Batch 454, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:12,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:12,685 : [INFO]  ------------------------- Batch 454 training: round 2 -------------------------
2023-03-25 19:14:14,453 : [INFO]  ------------------------- Batch round 2, loss: 0.5799 -------------------------
2023-03-25 19:14:14,454 : [INFO]  ------------------------- Batch 454, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:14,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:14,473 : [INFO]  ------------------------- Batch 454 training: round 3 -------------------------
2023-03-25 19:14:16,219 : [INFO]  ------------------------- Batch round 3, loss: 0.5866 -------------------------
2023-03-25 19:14:16,220 : [INFO]  ------------------------- Batch 454, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:16,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:16,239 : [INFO]  Batch number 454 model fetched from the server
2023-03-25 19:14:16,239 : [INFO]  ################ Batch 454: final global model evalution after 3 rounds ################
2023-03-25 19:14:17,443 : [INFO]  Batch 454: Training set : loss - 0.6058, accuracy - 0.6413, recall - 0.8152, AUC - 0.8121, F1 - 0.6944, precision - 0.6048, training time - -7.0 seconds
2023-03-25 19:14:17,444 : [INFO]  Batch 454: Testing set : loss - 0.6011, accuracy - 0.6667, recall - 0.7745, AUC - 0.7907, F1 - 0.6991, precision - 0.6371
2023-03-25 19:14:17,460 : [INFO]  Batch 455 initialized 
2023-03-25 19:14:17,927 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:18,977 : [INFO]  ------------------------- Batch 455 training: round 1 -------------------------
2023-03-25 19:14:22,456 : [INFO]  ------------------------- Batch round 1, loss: 0.5671 -------------------------
2023-03-25 19:14:22,456 : [INFO]  ------------------------- Batch 455, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:22,473 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:22,474 : [INFO]  ------------------------- Batch 455 training: round 2 -------------------------
2023-03-25 19:14:24,277 : [INFO]  ------------------------- Batch round 2, loss: 0.5647 -------------------------
2023-03-25 19:14:24,277 : [INFO]  ------------------------- Batch 455, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:24,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:24,297 : [INFO]  ------------------------- Batch 455 training: round 3 -------------------------
2023-03-25 19:14:26,119 : [INFO]  ------------------------- Batch round 3, loss: 0.5702 -------------------------
2023-03-25 19:14:26,119 : [INFO]  ------------------------- Batch 455, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:26,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:26,139 : [INFO]  Batch number 455 model fetched from the server
2023-03-25 19:14:26,139 : [INFO]  ################ Batch 455: final global model evalution after 3 rounds ################
2023-03-25 19:14:27,281 : [INFO]  Batch 455: Training set : loss - 0.5788, accuracy - 0.6793, recall - 0.837, AUC - 0.8267, F1 - 0.723, precision - 0.6364, training time - -7.0 seconds
2023-03-25 19:14:27,281 : [INFO]  Batch 455: Testing set : loss - 0.569, accuracy - 0.7304, recall - 0.902, AUC - 0.89, F1 - 0.7699, precision - 0.6715
2023-03-25 19:14:27,295 : [INFO]  Batch 456 initialized 
2023-03-25 19:14:27,786 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:28,846 : [INFO]  ------------------------- Batch 456 training: round 1 -------------------------
2023-03-25 19:14:32,254 : [INFO]  ------------------------- Batch round 1, loss: 0.5544 -------------------------
2023-03-25 19:14:32,254 : [INFO]  ------------------------- Batch 456, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:32,273 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:32,275 : [INFO]  ------------------------- Batch 456 training: round 2 -------------------------
2023-03-25 19:14:34,142 : [INFO]  ------------------------- Batch round 2, loss: 0.5587 -------------------------
2023-03-25 19:14:34,142 : [INFO]  ------------------------- Batch 456, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:34,159 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:34,161 : [INFO]  ------------------------- Batch 456 training: round 3 -------------------------
2023-03-25 19:14:35,931 : [INFO]  ------------------------- Batch round 3, loss: 0.5541 -------------------------
2023-03-25 19:14:35,931 : [INFO]  ------------------------- Batch 456, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:35,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:35,955 : [INFO]  Batch number 456 model fetched from the server
2023-03-25 19:14:35,955 : [INFO]  ################ Batch 456: final global model evalution after 3 rounds ################
2023-03-25 19:14:37,181 : [INFO]  Batch 456: Training set : loss - 0.5628, accuracy - 0.7283, recall - 0.8261, AUC - 0.8474, F1 - 0.7525, precision - 0.6909, training time - -7.0 seconds
2023-03-25 19:14:37,181 : [INFO]  Batch 456: Testing set : loss - 0.5811, accuracy - 0.6863, recall - 0.8431, AUC - 0.8383, F1 - 0.7288, precision - 0.6418
2023-03-25 19:14:37,198 : [INFO]  Batch 457 initialized 
2023-03-25 19:14:37,663 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:38,753 : [INFO]  ------------------------- Batch 457 training: round 1 -------------------------
2023-03-25 19:14:42,118 : [INFO]  ------------------------- Batch round 1, loss: 0.5628 -------------------------
2023-03-25 19:14:42,118 : [INFO]  ------------------------- Batch 457, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:42,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:42,230 : [INFO]  ------------------------- Batch 457 training: round 2 -------------------------
2023-03-25 19:14:43,963 : [INFO]  ------------------------- Batch round 2, loss: 0.5635 -------------------------
2023-03-25 19:14:43,963 : [INFO]  ------------------------- Batch 457, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:44,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:44,024 : [INFO]  ------------------------- Batch 457 training: round 3 -------------------------
2023-03-25 19:14:45,760 : [INFO]  ------------------------- Batch round 3, loss: 0.5664 -------------------------
2023-03-25 19:14:45,760 : [INFO]  ------------------------- Batch 457, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:45,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:45,797 : [INFO]  Batch number 457 model fetched from the server
2023-03-25 19:14:45,797 : [INFO]  ################ Batch 457: final global model evalution after 3 rounds ################
2023-03-25 19:14:47,010 : [INFO]  Batch 457: Training set : loss - 0.5699, accuracy - 0.6848, recall - 0.837, AUC - 0.8342, F1 - 0.7264, precision - 0.6417, training time - -7.0 seconds
2023-03-25 19:14:47,010 : [INFO]  Batch 457: Testing set : loss - 0.5992, accuracy - 0.6863, recall - 0.8333, AUC - 0.8062, F1 - 0.7265, precision - 0.6439
2023-03-25 19:14:47,025 : [INFO]  Batch 458 initialized 
2023-03-25 19:14:47,495 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:48,543 : [INFO]  ------------------------- Batch 458 training: round 1 -------------------------
2023-03-25 19:14:52,000 : [INFO]  ------------------------- Batch round 1, loss: 0.5567 -------------------------
2023-03-25 19:14:52,000 : [INFO]  ------------------------- Batch 458, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:52,060 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:52,062 : [INFO]  ------------------------- Batch 458 training: round 2 -------------------------
2023-03-25 19:14:53,808 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-25 19:14:53,808 : [INFO]  ------------------------- Batch 458, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:53,843 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:53,846 : [INFO]  ------------------------- Batch 458 training: round 3 -------------------------
2023-03-25 19:14:55,597 : [INFO]  ------------------------- Batch round 3, loss: 0.5576 -------------------------
2023-03-25 19:14:55,597 : [INFO]  ------------------------- Batch 458, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:55,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:55,664 : [INFO]  Batch number 458 model fetched from the server
2023-03-25 19:14:55,665 : [INFO]  ################ Batch 458: final global model evalution after 3 rounds ################
2023-03-25 19:14:56,876 : [INFO]  Batch 458: Training set : loss - 0.5645, accuracy - 0.6739, recall - 0.913, AUC - 0.9064, F1 - 0.7368, precision - 0.6176, training time - -7.0 seconds
2023-03-25 19:14:56,876 : [INFO]  Batch 458: Testing set : loss - 0.5616, accuracy - 0.7059, recall - 0.8824, AUC - 0.8936, F1 - 0.75, precision - 0.6522
2023-03-25 19:14:56,917 : [INFO]  Batch 459 initialized 
2023-03-25 19:14:57,373 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:58,421 : [INFO]  ------------------------- Batch 459 training: round 1 -------------------------
2023-03-25 19:15:01,857 : [INFO]  ------------------------- Batch round 1, loss: 0.555 -------------------------
2023-03-25 19:15:01,857 : [INFO]  ------------------------- Batch 459, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:01,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:01,915 : [INFO]  ------------------------- Batch 459 training: round 2 -------------------------
2023-03-25 19:15:03,666 : [INFO]  ------------------------- Batch round 2, loss: 0.5537 -------------------------
2023-03-25 19:15:03,666 : [INFO]  ------------------------- Batch 459, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:03,746 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:03,749 : [INFO]  ------------------------- Batch 459 training: round 3 -------------------------
2023-03-25 19:15:05,554 : [INFO]  ------------------------- Batch round 3, loss: 0.551 -------------------------
2023-03-25 19:15:05,554 : [INFO]  ------------------------- Batch 459, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:05,587 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:05,590 : [INFO]  Batch number 459 model fetched from the server
2023-03-25 19:15:05,590 : [INFO]  ################ Batch 459: final global model evalution after 3 rounds ################
2023-03-25 19:15:06,829 : [INFO]  Batch 459: Training set : loss - 0.5595, accuracy - 0.7446, recall - 0.913, AUC - 0.8927, F1 - 0.7814, precision - 0.6829, training time - -7.0 seconds
2023-03-25 19:15:06,829 : [INFO]  Batch 459: Testing set : loss - 0.5737, accuracy - 0.7157, recall - 0.8431, AUC - 0.8508, F1 - 0.7478, precision - 0.6719
2023-03-25 19:15:06,839 : [INFO]  Batch 460 initialized 
2023-03-25 19:15:07,307 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:08,393 : [INFO]  ------------------------- Batch 460 training: round 1 -------------------------
2023-03-25 19:15:11,932 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-25 19:15:11,933 : [INFO]  ------------------------- Batch 460, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:11,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:11,952 : [INFO]  ------------------------- Batch 460 training: round 2 -------------------------
2023-03-25 19:15:13,769 : [INFO]  ------------------------- Batch round 2, loss: 0.5635 -------------------------
2023-03-25 19:15:13,769 : [INFO]  ------------------------- Batch 460, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:13,788 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:13,790 : [INFO]  ------------------------- Batch 460 training: round 3 -------------------------
2023-03-25 19:15:15,611 : [INFO]  ------------------------- Batch round 3, loss: 0.5589 -------------------------
2023-03-25 19:15:15,611 : [INFO]  ------------------------- Batch 460, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:15,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:15,630 : [INFO]  Batch number 460 model fetched from the server
2023-03-25 19:15:15,630 : [INFO]  ################ Batch 460: final global model evalution after 3 rounds ################
2023-03-25 19:15:16,858 : [INFO]  Batch 460: Training set : loss - 0.5767, accuracy - 0.7065, recall - 0.837, AUC - 0.8406, F1 - 0.7404, precision - 0.6638, training time - -7.0 seconds
2023-03-25 19:15:16,858 : [INFO]  Batch 460: Testing set : loss - 0.5929, accuracy - 0.652, recall - 0.8039, AUC - 0.8089, F1 - 0.6979, precision - 0.6165
2023-03-25 19:15:16,871 : [INFO]  Batch 461 initialized 
2023-03-25 19:15:17,331 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:18,401 : [INFO]  ------------------------- Batch 461 training: round 1 -------------------------
2023-03-25 19:15:21,945 : [INFO]  ------------------------- Batch round 1, loss: 0.5649 -------------------------
2023-03-25 19:15:21,945 : [INFO]  ------------------------- Batch 461, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:21,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:21,970 : [INFO]  ------------------------- Batch 461 training: round 2 -------------------------
2023-03-25 19:15:23,868 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 19:15:23,868 : [INFO]  ------------------------- Batch 461, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:23,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:23,888 : [INFO]  ------------------------- Batch 461 training: round 3 -------------------------
2023-03-25 19:15:25,695 : [INFO]  ------------------------- Batch round 3, loss: 0.5698 -------------------------
2023-03-25 19:15:25,695 : [INFO]  ------------------------- Batch 461, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:25,713 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:25,715 : [INFO]  Batch number 461 model fetched from the server
2023-03-25 19:15:25,715 : [INFO]  ################ Batch 461: final global model evalution after 3 rounds ################
2023-03-25 19:15:26,919 : [INFO]  Batch 461: Training set : loss - 0.5848, accuracy - 0.6739, recall - 0.7826, AUC - 0.8039, F1 - 0.7059, precision - 0.6429, training time - -7.0 seconds
2023-03-25 19:15:26,919 : [INFO]  Batch 461: Testing set : loss - 0.5883, accuracy - 0.6765, recall - 0.8235, AUC - 0.8226, F1 - 0.7179, precision - 0.6364
2023-03-25 19:15:26,927 : [INFO]  Batch 462 initialized 
2023-03-25 19:15:27,400 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:28,504 : [INFO]  ------------------------- Batch 462 training: round 1 -------------------------
2023-03-25 19:15:32,005 : [INFO]  ------------------------- Batch round 1, loss: 0.5684 -------------------------
2023-03-25 19:15:32,005 : [INFO]  ------------------------- Batch 462, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:32,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:32,025 : [INFO]  ------------------------- Batch 462 training: round 2 -------------------------
2023-03-25 19:15:33,758 : [INFO]  ------------------------- Batch round 2, loss: 0.5622 -------------------------
2023-03-25 19:15:33,759 : [INFO]  ------------------------- Batch 462, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:33,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:33,850 : [INFO]  ------------------------- Batch 462 training: round 3 -------------------------
2023-03-25 19:15:35,625 : [INFO]  ------------------------- Batch round 3, loss: 0.5596 -------------------------
2023-03-25 19:15:35,625 : [INFO]  ------------------------- Batch 462, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:35,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:35,718 : [INFO]  Batch number 462 model fetched from the server
2023-03-25 19:15:35,719 : [INFO]  ################ Batch 462: final global model evalution after 3 rounds ################
2023-03-25 19:15:36,890 : [INFO]  Batch 462: Training set : loss - 0.5715, accuracy - 0.712, recall - 0.8478, AUC - 0.8427, F1 - 0.7464, precision - 0.6667, training time - -7.0 seconds
2023-03-25 19:15:36,890 : [INFO]  Batch 462: Testing set : loss - 0.5894, accuracy - 0.6716, recall - 0.8431, AUC - 0.831, F1 - 0.7197, precision - 0.6277
2023-03-25 19:15:36,907 : [INFO]  Batch 463 initialized 
2023-03-25 19:15:37,387 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:38,469 : [INFO]  ------------------------- Batch 463 training: round 1 -------------------------
2023-03-25 19:15:41,941 : [INFO]  ------------------------- Batch round 1, loss: 0.5508 -------------------------
2023-03-25 19:15:41,941 : [INFO]  ------------------------- Batch 463, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:41,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:41,965 : [INFO]  ------------------------- Batch 463 training: round 2 -------------------------
2023-03-25 19:15:43,762 : [INFO]  ------------------------- Batch round 2, loss: 0.5511 -------------------------
2023-03-25 19:15:43,762 : [INFO]  ------------------------- Batch 463, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:43,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:43,781 : [INFO]  ------------------------- Batch 463 training: round 3 -------------------------
2023-03-25 19:15:45,671 : [INFO]  ------------------------- Batch round 3, loss: 0.5496 -------------------------
2023-03-25 19:15:45,671 : [INFO]  ------------------------- Batch 463, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:45,689 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:45,691 : [INFO]  Batch number 463 model fetched from the server
2023-03-25 19:15:45,691 : [INFO]  ################ Batch 463: final global model evalution after 3 rounds ################
2023-03-25 19:15:46,886 : [INFO]  Batch 463: Training set : loss - 0.5649, accuracy - 0.7174, recall - 0.8913, AUC - 0.87, F1 - 0.7593, precision - 0.6613, training time - -7.0 seconds
2023-03-25 19:15:46,886 : [INFO]  Batch 463: Testing set : loss - 0.5816, accuracy - 0.6667, recall - 0.7843, AUC - 0.8201, F1 - 0.7018, precision - 0.6349
2023-03-25 19:15:46,893 : [INFO]  Batch 464 initialized 
2023-03-25 19:15:47,361 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:48,432 : [INFO]  ------------------------- Batch 464 training: round 1 -------------------------
2023-03-25 19:15:51,884 : [INFO]  ------------------------- Batch round 1, loss: 0.5428 -------------------------
2023-03-25 19:15:51,884 : [INFO]  ------------------------- Batch 464, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:51,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:51,945 : [INFO]  ------------------------- Batch 464 training: round 2 -------------------------
2023-03-25 19:15:53,658 : [INFO]  ------------------------- Batch round 2, loss: 0.5443 -------------------------
2023-03-25 19:15:53,658 : [INFO]  ------------------------- Batch 464, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:53,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:53,776 : [INFO]  ------------------------- Batch 464 training: round 3 -------------------------
2023-03-25 19:15:55,492 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 19:15:55,492 : [INFO]  ------------------------- Batch 464, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:55,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:55,580 : [INFO]  Batch number 464 model fetched from the server
2023-03-25 19:15:55,580 : [INFO]  ################ Batch 464: final global model evalution after 3 rounds ################
2023-03-25 19:15:56,747 : [INFO]  Batch 464: Training set : loss - 0.5487, accuracy - 0.7283, recall - 0.8696, AUC - 0.8809, F1 - 0.7619, precision - 0.678, training time - -7.0 seconds
2023-03-25 19:15:56,747 : [INFO]  Batch 464: Testing set : loss - 0.5696, accuracy - 0.6961, recall - 0.8725, AUC - 0.8729, F1 - 0.7417, precision - 0.6449
2023-03-25 19:15:56,761 : [INFO]  Batch 465 initialized 
2023-03-25 19:15:57,309 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:58,373 : [INFO]  ------------------------- Batch 465 training: round 1 -------------------------
2023-03-25 19:16:01,849 : [INFO]  ------------------------- Batch round 1, loss: 0.5729 -------------------------
2023-03-25 19:16:01,849 : [INFO]  ------------------------- Batch 465, round 1: Sent local model to the server -------------------------
2023-03-25 19:16:01,868 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:01,870 : [INFO]  ------------------------- Batch 465 training: round 2 -------------------------
2023-03-25 19:16:03,593 : [INFO]  ------------------------- Batch round 2, loss: 0.574 -------------------------
2023-03-25 19:16:03,593 : [INFO]  ------------------------- Batch 465, round 2: Sent local model to the server -------------------------
2023-03-25 19:16:03,636 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:03,639 : [INFO]  ------------------------- Batch 465 training: round 3 -------------------------
2023-03-25 19:16:05,405 : [INFO]  ------------------------- Batch round 3, loss: 0.5708 -------------------------
2023-03-25 19:16:05,406 : [INFO]  ------------------------- Batch 465, round 3: Sent local model to the server -------------------------
2023-03-25 19:16:05,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:05,459 : [INFO]  Batch number 465 model fetched from the server
2023-03-25 19:16:05,459 : [INFO]  ################ Batch 465: final global model evalution after 3 rounds ################
2023-03-25 19:16:06,642 : [INFO]  Batch 465: Training set : loss - 0.5837, accuracy - 0.6576, recall - 0.837, AUC - 0.83, F1 - 0.7097, precision - 0.616, training time - -7.0 seconds
2023-03-25 19:16:06,642 : [INFO]  Batch 465: Testing set : loss - 0.6028, accuracy - 0.6324, recall - 0.7647, AUC - 0.7919, F1 - 0.6753, precision - 0.6047
2023-03-25 19:16:06,651 : [INFO]  Batch 466 initialized 
2023-03-25 19:16:07,105 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:16:08,172 : [INFO]  ------------------------- Batch 466 training: round 1 -------------------------
2023-03-25 19:16:11,662 : [INFO]  ------------------------- Batch round 1, loss: 0.5588 -------------------------
2023-03-25 19:16:11,662 : [INFO]  ------------------------- Batch 466, round 1: Sent local model to the server -------------------------
2023-03-25 19:16:11,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:11,699 : [INFO]  ------------------------- Batch 466 training: round 2 -------------------------
2023-03-25 19:16:13,521 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-25 19:16:13,521 : [INFO]  ------------------------- Batch 466, round 2: Sent local model to the server -------------------------
2023-03-25 19:16:13,599 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:13,602 : [INFO]  ------------------------- Batch 466 training: round 3 -------------------------
2023-03-25 19:16:15,378 : [INFO]  ------------------------- Batch round 3, loss: 0.557 -------------------------
2023-03-25 19:16:15,378 : [INFO]  ------------------------- Batch 466, round 3: Sent local model to the server -------------------------
2023-03-25 19:16:15,430 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:15,432 : [INFO]  Batch number 466 model fetched from the server
2023-03-25 19:16:15,432 : [INFO]  ################ Batch 466: final global model evalution after 3 rounds ################
2023-03-25 19:16:16,670 : [INFO]  Batch 466: Training set : loss - 0.5664, accuracy - 0.7228, recall - 0.8804, AUC - 0.854, F1 - 0.7606, precision - 0.6694, training time - -7.0 seconds
2023-03-25 19:16:16,671 : [INFO]  Batch 466: Testing set : loss - 0.5861, accuracy - 0.6765, recall - 0.8333, AUC - 0.8441, F1 - 0.7203, precision - 0.6343
2023-03-25 19:16:16,687 : [INFO]  Result report : Accuracy - 0.6819 (0.0407), Recall - 0.848 (0.0593), AUC - 0.8203 (0.0491), F1 - 0.7269 (0.036), Precision - 0.6373 (0.0324)
2023-03-25 19:16:16,688 : [INFO]  Result report : Accuracy - 0.6819 (0.0407), Recall - 0.848 (0.0593), AUC - 0.8203 (0.0491), F1 - 0.7269 (0.036), Precision - 0.6373 (0.0324), Mean time for a batch - 10.03 (1.86) seconds
2023-03-25 19:16:16,688 : [INFO]  Distributed training done!
2023-03-25 19:16:16,688 : [INFO]  Training report : Total elapsed time 6956.097779857999 seconds, graph name facebook, graph ID 1, partition ID 1, training epochs 6, epochs 6
