2023-03-25 13:05:52,642 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 13:05:52,645 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 1, epochs 6
2023-03-25 13:05:55,346 : [INFO]  Model initialized for training
2023-03-25 13:06:07,186 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:06:07,311 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:06:07,312 : [INFO]  Connected to the server
2023-03-25 13:06:07,404 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:06:07,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:06:07,415 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:06:07,415 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:06:25,858 : [INFO]  ------------------------- Training round 1, loss: 0.6558 -------------------------
2023-03-25 13:06:25,858 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:06:58,172 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:06:58,175 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:07:20,634 : [INFO]  ------------------------- Training round 2, loss: 0.613 -------------------------
2023-03-25 13:07:20,634 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:07:20,835 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:07:20,838 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:07:43,497 : [INFO]  ------------------------- Training round 3, loss: 0.601 -------------------------
2023-03-25 13:07:43,497 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:07:43,585 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:07:43,587 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:08:06,103 : [INFO]  ------------------------- Training round 4, loss: 0.5961 -------------------------
2023-03-25 13:08:06,103 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:08:06,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:08:06,289 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:08:29,005 : [INFO]  ------------------------- Training round 5, loss: 0.594 -------------------------
2023-03-25 13:08:29,005 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:08:29,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:08:29,080 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:09:13,536 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.7, recall - 0.89, AUC - 0.84, F1 - 0.75, precision - 0.64, training time - -142.0 seconds
2023-03-25 13:09:13,536 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.89, AUC - 0.84, F1 - 0.74, precision - 0.64
2023-03-25 13:09:13,549 : [INFO]  Batch 1 initialized 
2023-03-25 13:09:14,007 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:09:14,135 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:09:14,136 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:09:18,536 : [INFO]  ------------------------- Batch round 1, loss: 0.5869 -------------------------
2023-03-25 13:09:18,536 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:09:19,767 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:19,771 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:09:22,091 : [INFO]  ------------------------- Batch round 2, loss: 0.5751 -------------------------
2023-03-25 13:09:22,091 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:09:22,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:22,268 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:09:24,711 : [INFO]  ------------------------- Batch round 3, loss: 0.566 -------------------------
2023-03-25 13:09:24,712 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:09:24,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:24,871 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:09:24,871 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:09:26,796 : [INFO]  Batch 1: Training set : loss - 0.5639, accuracy - 0.7283, recall - 0.9348, AUC - 0.8895, F1 - 0.7748, precision - 0.6615, training time - -11.0 seconds
2023-03-25 13:09:26,796 : [INFO]  Batch 1: Testing set : loss - 0.5503, accuracy - 0.7304, recall - 0.9216, AUC - 0.9028, F1 - 0.7737, precision - 0.6667
2023-03-25 13:09:26,802 : [INFO]  Batch 2 initialized 
2023-03-25 13:09:27,273 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:09:27,405 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:09:31,662 : [INFO]  ------------------------- Batch round 1, loss: 0.5723 -------------------------
2023-03-25 13:09:31,662 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:09:31,673 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:31,680 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:09:33,756 : [INFO]  ------------------------- Batch round 2, loss: 0.5574 -------------------------
2023-03-25 13:09:33,756 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:09:33,775 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:33,777 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:09:35,821 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 13:09:35,822 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:09:35,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:35,842 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:09:35,842 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:09:37,193 : [INFO]  Batch 2: Training set : loss - 0.5448, accuracy - 0.75, recall - 0.9239, AUC - 0.893, F1 - 0.787, precision - 0.6855, training time - -8.0 seconds
2023-03-25 13:09:37,193 : [INFO]  Batch 2: Testing set : loss - 0.5306, accuracy - 0.7647, recall - 0.951, AUC - 0.9189, F1 - 0.8017, precision - 0.6929
2023-03-25 13:09:37,199 : [INFO]  Batch 3 initialized 
2023-03-25 13:09:37,623 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:09:37,891 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:09:41,853 : [INFO]  ------------------------- Batch round 1, loss: 0.5607 -------------------------
2023-03-25 13:09:41,853 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:09:41,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:41,858 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:09:44,136 : [INFO]  ------------------------- Batch round 2, loss: 0.5467 -------------------------
2023-03-25 13:09:44,136 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:09:44,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:44,140 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:09:46,352 : [INFO]  ------------------------- Batch round 3, loss: 0.5428 -------------------------
2023-03-25 13:09:46,353 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:09:46,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:09:46,358 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:09:46,358 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:09:47,902 : [INFO]  Batch 3: Training set : loss - 0.5414, accuracy - 0.7663, recall - 0.9565, AUC - 0.9236, F1 - 0.8037, precision - 0.6929, training time - -8.0 seconds
2023-03-25 13:09:47,902 : [INFO]  Batch 3: Testing set : loss - 0.5641, accuracy - 0.6765, recall - 0.9216, AUC - 0.9171, F1 - 0.7402, precision - 0.6184
2023-03-25 13:09:47,916 : [INFO]  Batch 4 initialized 
2023-03-25 13:09:48,719 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:09:49,023 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
