2023-03-25 15:06:18,988 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 15:06:18,988 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 8, epochs 8
2023-03-25 15:06:22,424 : [INFO]  Model initialized for training
2023-03-25 15:06:39,219 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:06:39,420 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 15:06:39,420 : [INFO]  Connected to the server
2023-03-25 15:06:39,550 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 15:06:39,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:06:39,561 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 15:06:39,561 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 15:10:19,053 : [INFO]  ------------------------- Training round 1, loss: 0.6144 -------------------------
2023-03-25 15:10:19,053 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 15:10:20,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:10:20,627 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 15:13:43,203 : [INFO]  ------------------------- Training round 2, loss: 0.5927 -------------------------
2023-03-25 15:13:43,203 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 15:13:43,206 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:13:43,207 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 15:17:15,867 : [INFO]  ------------------------- Training round 3, loss: 0.5894 -------------------------
2023-03-25 15:17:15,867 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 15:17:15,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:17:15,871 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 15:20:57,198 : [INFO]  ------------------------- Training round 4, loss: 0.5886 -------------------------
2023-03-25 15:20:57,198 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 15:20:57,201 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:20:57,203 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 15:24:25,289 : [INFO]  ------------------------- Training round 5, loss: 0.5866 -------------------------
2023-03-25 15:24:25,289 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 15:24:25,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:24:25,298 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 15:25:14,462 : [INFO]  Initially trained model: Training set : loss - 0.58, accuracy - 0.71, recall - 0.88, AUC - 0.84, F1 - 0.75, precision - 0.66, training time - -1066.0 seconds
2023-03-25 15:25:14,462 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.87, AUC - 0.84, F1 - 0.74, precision - 0.65
2023-03-25 15:25:14,468 : [INFO]  Batch 1 initialized 
2023-03-25 15:25:14,875 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:25:15,183 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 15:25:15,183 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 15:25:19,649 : [INFO]  ------------------------- Batch round 1, loss: 0.5884 -------------------------
2023-03-25 15:25:19,650 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 15:25:19,738 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:19,740 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 15:25:22,516 : [INFO]  ------------------------- Batch round 2, loss: 0.5675 -------------------------
2023-03-25 15:25:22,516 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 15:25:22,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:22,664 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 15:25:25,509 : [INFO]  ------------------------- Batch round 3, loss: 0.5577 -------------------------
2023-03-25 15:25:25,509 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 15:25:25,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:25,616 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 15:25:25,616 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 15:25:27,005 : [INFO]  Batch 1: Training set : loss - 0.5608, accuracy - 0.7717, recall - 0.9239, AUC - 0.8605, F1 - 0.8019, precision - 0.7083, training time - -10.0 seconds
2023-03-25 15:25:27,005 : [INFO]  Batch 1: Testing set : loss - 0.5572, accuracy - 0.7304, recall - 0.8922, AUC - 0.8819, F1 - 0.7679, precision - 0.6741
2023-03-25 15:25:27,015 : [INFO]  Batch 2 initialized 
2023-03-25 15:25:27,445 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:25:27,601 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 15:25:33,083 : [INFO]  ------------------------- Batch round 1, loss: 0.5453 -------------------------
2023-03-25 15:25:33,083 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 15:25:33,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:33,089 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 15:25:35,814 : [INFO]  ------------------------- Batch round 2, loss: 0.5372 -------------------------
2023-03-25 15:25:35,814 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 15:25:35,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:35,819 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 15:25:38,533 : [INFO]  ------------------------- Batch round 3, loss: 0.5326 -------------------------
2023-03-25 15:25:38,533 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 15:25:38,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:38,538 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 15:25:38,538 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 15:25:39,884 : [INFO]  Batch 2: Training set : loss - 0.5301, accuracy - 0.8152, recall - 0.9565, AUC - 0.8951, F1 - 0.8381, precision - 0.7458, training time - -11.0 seconds
2023-03-25 15:25:39,885 : [INFO]  Batch 2: Testing set : loss - 0.5396, accuracy - 0.7843, recall - 0.951, AUC - 0.9155, F1 - 0.8151, precision - 0.7132
2023-03-25 15:25:39,890 : [INFO]  Batch 3 initialized 
2023-03-25 15:25:40,315 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:25:40,533 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 15:25:45,849 : [INFO]  ------------------------- Batch round 1, loss: 0.5458 -------------------------
2023-03-25 15:25:45,849 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 15:25:45,853 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:45,855 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 15:25:49,016 : [INFO]  ------------------------- Batch round 2, loss: 0.5384 -------------------------
2023-03-25 15:25:49,016 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 15:25:49,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:49,022 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 15:25:52,285 : [INFO]  ------------------------- Batch round 3, loss: 0.5401 -------------------------
2023-03-25 15:25:52,285 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 15:25:52,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:52,290 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 15:25:52,290 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 15:25:53,639 : [INFO]  Batch 3: Training set : loss - 0.5423, accuracy - 0.7826, recall - 0.9565, AUC - 0.9265, F1 - 0.8148, precision - 0.7097, training time - -12.0 seconds
2023-03-25 15:25:53,640 : [INFO]  Batch 3: Testing set : loss - 0.5677, accuracy - 0.6863, recall - 0.9118, AUC - 0.8969, F1 - 0.744, precision - 0.6284
2023-03-25 15:25:53,652 : [INFO]  Batch 4 initialized 
2023-03-25 15:25:54,159 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:25:54,369 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 15:25:59,319 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-25 15:25:59,319 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 15:25:59,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:25:59,324 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 15:26:02,338 : [INFO]  ------------------------- Batch round 2, loss: 0.5472 -------------------------
2023-03-25 15:26:02,338 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 15:26:02,346 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:02,347 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 15:26:05,112 : [INFO]  ------------------------- Batch round 3, loss: 0.5372 -------------------------
2023-03-25 15:26:05,113 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 15:26:05,123 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:05,125 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 15:26:05,125 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 15:26:06,478 : [INFO]  Batch 4: Training set : loss - 0.5378, accuracy - 0.7609, recall - 0.9239, AUC - 0.9149, F1 - 0.7944, precision - 0.6967, training time - -11.0 seconds
2023-03-25 15:26:06,478 : [INFO]  Batch 4: Testing set : loss - 0.5476, accuracy - 0.7549, recall - 0.951, AUC - 0.9307, F1 - 0.7951, precision - 0.6831
2023-03-25 15:26:06,488 : [INFO]  Batch 5 initialized 
2023-03-25 15:26:06,908 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:26:07,134 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 15:26:12,065 : [INFO]  ------------------------- Batch round 1, loss: 0.5582 -------------------------
2023-03-25 15:26:12,065 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 15:26:12,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:12,076 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 15:26:14,770 : [INFO]  ------------------------- Batch round 2, loss: 0.5466 -------------------------
2023-03-25 15:26:14,770 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 15:26:14,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:14,785 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 15:26:17,589 : [INFO]  ------------------------- Batch round 3, loss: 0.5378 -------------------------
2023-03-25 15:26:17,589 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 15:26:17,592 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:17,594 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 15:26:17,594 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 15:26:18,939 : [INFO]  Batch 5: Training set : loss - 0.5317, accuracy - 0.7935, recall - 0.9457, AUC - 0.9035, F1 - 0.8208, precision - 0.725, training time - -10.0 seconds
2023-03-25 15:26:18,939 : [INFO]  Batch 5: Testing set : loss - 0.542, accuracy - 0.7451, recall - 0.9118, AUC - 0.9085, F1 - 0.7815, precision - 0.6838
2023-03-25 15:26:18,945 : [INFO]  Batch 6 initialized 
2023-03-25 15:26:19,707 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:26:19,961 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 15:26:25,247 : [INFO]  ------------------------- Batch round 1, loss: 0.545 -------------------------
2023-03-25 15:26:25,247 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 15:26:25,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:25,252 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 15:26:28,273 : [INFO]  ------------------------- Batch round 2, loss: 0.5336 -------------------------
2023-03-25 15:26:28,273 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 15:26:28,277 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:28,280 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 15:26:32,157 : [INFO]  ------------------------- Batch round 3, loss: 0.5257 -------------------------
2023-03-25 15:26:32,157 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 15:26:32,164 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:32,166 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 15:26:32,167 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 15:26:33,921 : [INFO]  Batch 6: Training set : loss - 0.5199, accuracy - 0.7989, recall - 0.9239, AUC - 0.9026, F1 - 0.8213, precision - 0.7391, training time - -12.0 seconds
2023-03-25 15:26:33,922 : [INFO]  Batch 6: Testing set : loss - 0.5587, accuracy - 0.7108, recall - 0.902, AUC - 0.8788, F1 - 0.7572, precision - 0.6525
2023-03-25 15:26:33,929 : [INFO]  Batch 7 initialized 
2023-03-25 15:26:34,599 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:26:34,953 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 15:26:40,755 : [INFO]  ------------------------- Batch round 1, loss: 0.5389 -------------------------
2023-03-25 15:26:40,755 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 15:26:40,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:40,760 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 15:26:44,293 : [INFO]  ------------------------- Batch round 2, loss: 0.5232 -------------------------
2023-03-25 15:26:44,293 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 15:26:44,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:44,485 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 15:26:47,954 : [INFO]  ------------------------- Batch round 3, loss: 0.5176 -------------------------
2023-03-25 15:26:47,954 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 15:26:47,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:47,960 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 15:26:47,960 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 15:26:49,695 : [INFO]  Batch 7: Training set : loss - 0.5131, accuracy - 0.8152, recall - 0.9348, AUC - 0.9151, F1 - 0.835, precision - 0.7544, training time - -13.0 seconds
2023-03-25 15:26:49,695 : [INFO]  Batch 7: Testing set : loss - 0.5843, accuracy - 0.6912, recall - 0.9118, AUC - 0.8535, F1 - 0.747, precision - 0.6327
2023-03-25 15:26:49,707 : [INFO]  Batch 8 initialized 
2023-03-25 15:26:50,313 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:26:50,764 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 15:26:57,304 : [INFO]  ------------------------- Batch round 1, loss: 0.5587 -------------------------
2023-03-25 15:26:57,304 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 15:26:57,307 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:26:57,311 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 15:27:00,824 : [INFO]  ------------------------- Batch round 2, loss: 0.5498 -------------------------
2023-03-25 15:27:00,824 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 15:27:01,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:01,088 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 15:27:04,602 : [INFO]  ------------------------- Batch round 3, loss: 0.5471 -------------------------
2023-03-25 15:27:04,602 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 15:27:04,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:04,712 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 15:27:04,712 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 15:27:06,061 : [INFO]  Batch 8: Training set : loss - 0.5437, accuracy - 0.7717, recall - 0.9239, AUC - 0.8998, F1 - 0.8019, precision - 0.7083, training time - -14.0 seconds
2023-03-25 15:27:06,062 : [INFO]  Batch 8: Testing set : loss - 0.5836, accuracy - 0.6814, recall - 0.8922, AUC - 0.8522, F1 - 0.7368, precision - 0.6276
2023-03-25 15:27:06,069 : [INFO]  Batch 9 initialized 
2023-03-25 15:27:06,519 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:27:06,919 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 15:27:12,465 : [INFO]  ------------------------- Batch round 1, loss: 0.5942 -------------------------
2023-03-25 15:27:12,465 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 15:27:12,468 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:12,470 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 15:27:15,527 : [INFO]  ------------------------- Batch round 2, loss: 0.5805 -------------------------
2023-03-25 15:27:15,527 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 15:27:15,530 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:15,532 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 15:27:18,667 : [INFO]  ------------------------- Batch round 3, loss: 0.5636 -------------------------
2023-03-25 15:27:18,667 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 15:27:18,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:18,672 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 15:27:18,672 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 15:27:20,406 : [INFO]  Batch 9: Training set : loss - 0.5579, accuracy - 0.7663, recall - 0.8804, AUC - 0.8641, F1 - 0.7902, precision - 0.7168, training time - -12.0 seconds
2023-03-25 15:27:20,406 : [INFO]  Batch 9: Testing set : loss - 0.6223, accuracy - 0.6225, recall - 0.8529, AUC - 0.7851, F1 - 0.6932, precision - 0.5839
2023-03-25 15:27:20,413 : [INFO]  Batch 10 initialized 
2023-03-25 15:27:20,923 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:27:21,290 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 15:27:27,166 : [INFO]  ------------------------- Batch round 1, loss: 0.5551 -------------------------
2023-03-25 15:27:27,166 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 15:27:27,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:27,172 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 15:27:30,497 : [INFO]  ------------------------- Batch round 2, loss: 0.5412 -------------------------
2023-03-25 15:27:30,497 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 15:27:30,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:30,591 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 15:27:34,133 : [INFO]  ------------------------- Batch round 3, loss: 0.5277 -------------------------
2023-03-25 15:27:34,133 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 15:27:34,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:34,138 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 15:27:34,139 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 15:27:35,781 : [INFO]  Batch 10: Training set : loss - 0.5241, accuracy - 0.8043, recall - 0.9239, AUC - 0.8932, F1 - 0.8252, precision - 0.7456, training time - -13.0 seconds
2023-03-25 15:27:35,781 : [INFO]  Batch 10: Testing set : loss - 0.5751, accuracy - 0.6961, recall - 0.8725, AUC - 0.8614, F1 - 0.7417, precision - 0.6449
2023-03-25 15:27:35,789 : [INFO]  Batch 11 initialized 
2023-03-25 15:27:36,324 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:27:36,586 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 15:27:41,814 : [INFO]  ------------------------- Batch round 1, loss: 0.5608 -------------------------
2023-03-25 15:27:41,814 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 15:27:41,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:41,942 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 15:27:44,686 : [INFO]  ------------------------- Batch round 2, loss: 0.5529 -------------------------
2023-03-25 15:27:44,686 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 15:27:44,784 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:44,786 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 15:27:47,887 : [INFO]  ------------------------- Batch round 3, loss: 0.549 -------------------------
2023-03-25 15:27:47,887 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 15:27:47,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:47,891 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 15:27:47,891 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 15:27:49,151 : [INFO]  Batch 11: Training set : loss - 0.5499, accuracy - 0.7609, recall - 0.9022, AUC - 0.8709, F1 - 0.7905, precision - 0.7034, training time - -11.0 seconds
2023-03-25 15:27:49,152 : [INFO]  Batch 11: Testing set : loss - 0.5849, accuracy - 0.6667, recall - 0.9216, AUC - 0.8729, F1 - 0.7344, precision - 0.6104
2023-03-25 15:27:49,191 : [INFO]  Batch 12 initialized 
2023-03-25 15:27:49,610 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:27:49,853 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 15:27:54,483 : [INFO]  ------------------------- Batch round 1, loss: 0.5555 -------------------------
2023-03-25 15:27:54,483 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 15:27:54,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:54,983 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 15:27:58,009 : [INFO]  ------------------------- Batch round 2, loss: 0.5341 -------------------------
2023-03-25 15:27:58,009 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 15:27:58,178 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:27:58,179 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 15:28:00,947 : [INFO]  ------------------------- Batch round 3, loss: 0.5382 -------------------------
2023-03-25 15:28:00,947 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 15:28:01,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:01,129 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 15:28:01,129 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 15:28:02,524 : [INFO]  Batch 12: Training set : loss - 0.5282, accuracy - 0.7935, recall - 0.9022, AUC - 0.892, F1 - 0.8137, precision - 0.7411, training time - -11.0 seconds
2023-03-25 15:28:02,524 : [INFO]  Batch 12: Testing set : loss - 0.579, accuracy - 0.6961, recall - 0.8529, AUC - 0.8509, F1 - 0.7373, precision - 0.6493
2023-03-25 15:28:02,533 : [INFO]  Batch 13 initialized 
2023-03-25 15:28:02,997 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:28:03,268 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 15:28:08,818 : [INFO]  ------------------------- Batch round 1, loss: 0.5506 -------------------------
2023-03-25 15:28:08,818 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 15:28:08,842 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:08,847 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 15:28:12,745 : [INFO]  ------------------------- Batch round 2, loss: 0.5344 -------------------------
2023-03-25 15:28:12,745 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 15:28:12,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:12,751 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 15:28:15,910 : [INFO]  ------------------------- Batch round 3, loss: 0.5278 -------------------------
2023-03-25 15:28:15,910 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 15:28:15,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:15,916 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 15:28:15,916 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 15:28:17,445 : [INFO]  Batch 13: Training set : loss - 0.5304, accuracy - 0.75, recall - 0.9239, AUC - 0.9083, F1 - 0.787, precision - 0.6855, training time - -13.0 seconds
2023-03-25 15:28:17,445 : [INFO]  Batch 13: Testing set : loss - 0.5581, accuracy - 0.7108, recall - 0.9314, AUC - 0.9118, F1 - 0.7631, precision - 0.6463
2023-03-25 15:28:17,452 : [INFO]  Batch 14 initialized 
2023-03-25 15:28:17,897 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:28:18,160 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 15:28:23,606 : [INFO]  ------------------------- Batch round 1, loss: 0.5434 -------------------------
2023-03-25 15:28:23,606 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 15:28:23,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:23,613 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 15:28:26,673 : [INFO]  ------------------------- Batch round 2, loss: 0.5266 -------------------------
2023-03-25 15:28:26,673 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 15:28:26,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:26,679 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 15:28:29,473 : [INFO]  ------------------------- Batch round 3, loss: 0.5296 -------------------------
2023-03-25 15:28:29,473 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 15:28:29,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:29,554 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 15:28:29,554 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 15:28:30,915 : [INFO]  Batch 14: Training set : loss - 0.5249, accuracy - 0.7717, recall - 0.9565, AUC - 0.8941, F1 - 0.8073, precision - 0.6984, training time - -11.0 seconds
2023-03-25 15:28:30,915 : [INFO]  Batch 14: Testing set : loss - 0.559, accuracy - 0.7157, recall - 0.9118, AUC - 0.8986, F1 - 0.7623, precision - 0.6549
2023-03-25 15:28:30,927 : [INFO]  Batch 15 initialized 
2023-03-25 15:28:31,427 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:28:31,707 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 15:28:36,743 : [INFO]  ------------------------- Batch round 1, loss: 0.5837 -------------------------
2023-03-25 15:28:36,743 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 15:28:36,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:36,942 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 15:28:39,939 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 15:28:39,939 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 15:28:40,113 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:40,115 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 15:28:43,393 : [INFO]  ------------------------- Batch round 3, loss: 0.567 -------------------------
2023-03-25 15:28:43,393 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 15:28:43,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:43,399 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 15:28:43,399 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 15:28:44,985 : [INFO]  Batch 15: Training set : loss - 0.5703, accuracy - 0.75, recall - 0.9565, AUC - 0.8697, F1 - 0.7928, precision - 0.6769, training time - -12.0 seconds
2023-03-25 15:28:44,985 : [INFO]  Batch 15: Testing set : loss - 0.5597, accuracy - 0.7157, recall - 0.9412, AUC - 0.8962, F1 - 0.768, precision - 0.6486
2023-03-25 15:28:44,998 : [INFO]  Batch 16 initialized 
2023-03-25 15:28:45,472 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:28:45,755 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 15:28:50,739 : [INFO]  ------------------------- Batch round 1, loss: 0.5695 -------------------------
2023-03-25 15:28:50,739 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 15:28:50,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:50,745 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 15:28:53,698 : [INFO]  ------------------------- Batch round 2, loss: 0.5719 -------------------------
2023-03-25 15:28:53,698 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 15:28:53,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:53,903 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 15:28:57,050 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-25 15:28:57,050 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 15:28:57,054 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:28:57,056 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 15:28:57,056 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 15:28:58,839 : [INFO]  Batch 16: Training set : loss - 0.562, accuracy - 0.7337, recall - 0.8804, AUC - 0.8515, F1 - 0.7678, precision - 0.6807, training time - -11.0 seconds
2023-03-25 15:28:58,839 : [INFO]  Batch 16: Testing set : loss - 0.5716, accuracy - 0.6716, recall - 0.8627, AUC - 0.8696, F1 - 0.7243, precision - 0.6241
2023-03-25 15:28:58,890 : [INFO]  Batch 17 initialized 
2023-03-25 15:28:59,688 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:29:00,009 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 15:29:04,998 : [INFO]  ------------------------- Batch round 1, loss: 0.5299 -------------------------
2023-03-25 15:29:04,998 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 15:29:05,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:05,002 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 15:29:07,889 : [INFO]  ------------------------- Batch round 2, loss: 0.5165 -------------------------
2023-03-25 15:29:07,889 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 15:29:08,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:08,092 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 15:29:11,068 : [INFO]  ------------------------- Batch round 3, loss: 0.5041 -------------------------
2023-03-25 15:29:11,068 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 15:29:11,289 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:11,291 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 15:29:11,291 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 15:29:12,868 : [INFO]  Batch 17: Training set : loss - 0.5074, accuracy - 0.8152, recall - 0.9674, AUC - 0.9332, F1 - 0.8396, precision - 0.7417, training time - -11.0 seconds
2023-03-25 15:29:12,868 : [INFO]  Batch 17: Testing set : loss - 0.5464, accuracy - 0.7598, recall - 0.9902, AUC - 0.9125, F1 - 0.8048, precision - 0.6779
2023-03-25 15:29:12,878 : [INFO]  Batch 18 initialized 
2023-03-25 15:29:13,322 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:29:13,605 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 15:29:18,741 : [INFO]  ------------------------- Batch round 1, loss: 0.5948 -------------------------
2023-03-25 15:29:18,742 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 15:29:18,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:18,747 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 15:29:21,885 : [INFO]  ------------------------- Batch round 2, loss: 0.5731 -------------------------
2023-03-25 15:29:21,885 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 15:29:21,888 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:21,890 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 15:29:25,813 : [INFO]  ------------------------- Batch round 3, loss: 0.565 -------------------------
2023-03-25 15:29:25,813 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 15:29:25,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:25,821 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 15:29:25,821 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 15:29:27,293 : [INFO]  Batch 18: Training set : loss - 0.5786, accuracy - 0.6902, recall - 0.8913, AUC - 0.8422, F1 - 0.7421, precision - 0.6357, training time - -12.0 seconds
2023-03-25 15:29:27,293 : [INFO]  Batch 18: Testing set : loss - 0.6118, accuracy - 0.6667, recall - 0.8333, AUC - 0.7878, F1 - 0.7143, precision - 0.625
2023-03-25 15:29:27,299 : [INFO]  Batch 19 initialized 
2023-03-25 15:29:27,801 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:29:28,137 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 15:29:33,489 : [INFO]  ------------------------- Batch round 1, loss: 0.5786 -------------------------
2023-03-25 15:29:33,489 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 15:29:33,492 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:33,494 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 15:29:36,553 : [INFO]  ------------------------- Batch round 2, loss: 0.5647 -------------------------
2023-03-25 15:29:36,553 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 15:29:36,556 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:36,558 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 15:29:39,578 : [INFO]  ------------------------- Batch round 3, loss: 0.5542 -------------------------
2023-03-25 15:29:39,578 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 15:29:39,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:39,583 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 15:29:39,583 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 15:29:41,102 : [INFO]  Batch 19: Training set : loss - 0.554, accuracy - 0.7609, recall - 0.9348, AUC - 0.8617, F1 - 0.7963, precision - 0.6935, training time - -11.0 seconds
2023-03-25 15:29:41,102 : [INFO]  Batch 19: Testing set : loss - 0.5818, accuracy - 0.6863, recall - 0.8922, AUC - 0.8467, F1 - 0.7398, precision - 0.6319
2023-03-25 15:29:41,108 : [INFO]  Batch 20 initialized 
2023-03-25 15:29:41,562 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:29:41,851 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 15:29:46,732 : [INFO]  ------------------------- Batch round 1, loss: 0.5797 -------------------------
2023-03-25 15:29:46,732 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 15:29:46,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:46,737 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 15:29:50,977 : [INFO]  ------------------------- Batch round 2, loss: 0.5619 -------------------------
2023-03-25 15:29:50,977 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 15:29:50,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:50,982 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 15:29:54,327 : [INFO]  ------------------------- Batch round 3, loss: 0.5568 -------------------------
2023-03-25 15:29:54,327 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 15:29:54,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:29:54,337 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 15:29:54,337 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 15:29:55,914 : [INFO]  Batch 20: Training set : loss - 0.5555, accuracy - 0.7446, recall - 0.913, AUC - 0.8719, F1 - 0.7814, precision - 0.6829, training time - -12.0 seconds
2023-03-25 15:29:55,915 : [INFO]  Batch 20: Testing set : loss - 0.5701, accuracy - 0.7304, recall - 0.9314, AUC - 0.8733, F1 - 0.7755, precision - 0.6643
2023-03-25 15:29:55,920 : [INFO]  Batch 21 initialized 
2023-03-25 15:29:56,367 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:29:56,644 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 15:30:01,723 : [INFO]  ------------------------- Batch round 1, loss: 0.605 -------------------------
2023-03-25 15:30:01,723 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 15:30:01,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:01,728 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 15:30:04,652 : [INFO]  ------------------------- Batch round 2, loss: 0.5986 -------------------------
2023-03-25 15:30:04,653 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 15:30:04,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:04,657 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 15:30:07,598 : [INFO]  ------------------------- Batch round 3, loss: 0.5895 -------------------------
2023-03-25 15:30:07,599 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 15:30:07,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:07,767 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 15:30:07,767 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 15:30:09,102 : [INFO]  Batch 21: Training set : loss - 0.5945, accuracy - 0.7011, recall - 0.913, AUC - 0.8442, F1 - 0.7534, precision - 0.6412, training time - -11.0 seconds
2023-03-25 15:30:09,103 : [INFO]  Batch 21: Testing set : loss - 0.5563, accuracy - 0.7255, recall - 0.9804, AUC - 0.951, F1 - 0.7812, precision - 0.6494
2023-03-25 15:30:09,111 : [INFO]  Batch 22 initialized 
2023-03-25 15:30:09,662 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:30:10,014 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 15:30:15,954 : [INFO]  ------------------------- Batch round 1, loss: 0.5997 -------------------------
2023-03-25 15:30:15,954 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 15:30:15,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:15,963 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 15:30:19,141 : [INFO]  ------------------------- Batch round 2, loss: 0.5795 -------------------------
2023-03-25 15:30:19,141 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 15:30:19,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:19,253 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 15:30:22,299 : [INFO]  ------------------------- Batch round 3, loss: 0.5666 -------------------------
2023-03-25 15:30:22,299 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 15:30:22,414 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:22,416 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 15:30:22,416 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 15:30:23,990 : [INFO]  Batch 22: Training set : loss - 0.5762, accuracy - 0.6902, recall - 0.8913, AUC - 0.8553, F1 - 0.7421, precision - 0.6357, training time - -12.0 seconds
2023-03-25 15:30:23,990 : [INFO]  Batch 22: Testing set : loss - 0.597, accuracy - 0.6716, recall - 0.8431, AUC - 0.8235, F1 - 0.7197, precision - 0.6277
2023-03-25 15:30:24,004 : [INFO]  Batch 23 initialized 
2023-03-25 15:30:24,531 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:30:24,883 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 15:30:30,026 : [INFO]  ------------------------- Batch round 1, loss: 0.5903 -------------------------
2023-03-25 15:30:30,026 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 15:30:30,113 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:30,116 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 15:30:33,958 : [INFO]  ------------------------- Batch round 2, loss: 0.5783 -------------------------
2023-03-25 15:30:33,958 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 15:30:33,961 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:33,963 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 15:30:37,419 : [INFO]  ------------------------- Batch round 3, loss: 0.5672 -------------------------
2023-03-25 15:30:37,419 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 15:30:37,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:37,519 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 15:30:37,520 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 15:30:39,104 : [INFO]  Batch 23: Training set : loss - 0.56, accuracy - 0.75, recall - 0.8913, AUC - 0.8604, F1 - 0.781, precision - 0.6949, training time - -13.0 seconds
2023-03-25 15:30:39,104 : [INFO]  Batch 23: Testing set : loss - 0.6066, accuracy - 0.6422, recall - 0.8235, AUC - 0.7866, F1 - 0.6971, precision - 0.6043
2023-03-25 15:30:39,111 : [INFO]  Batch 24 initialized 
2023-03-25 15:30:39,601 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:30:39,867 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 15:30:45,598 : [INFO]  ------------------------- Batch round 1, loss: 0.5845 -------------------------
2023-03-25 15:30:45,598 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 15:30:45,753 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:45,756 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 15:30:49,028 : [INFO]  ------------------------- Batch round 2, loss: 0.5795 -------------------------
2023-03-25 15:30:49,028 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 15:30:49,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:49,062 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 15:30:52,107 : [INFO]  ------------------------- Batch round 3, loss: 0.5687 -------------------------
2023-03-25 15:30:52,107 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 15:30:52,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:30:52,124 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 15:30:52,124 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 15:30:53,591 : [INFO]  Batch 24: Training set : loss - 0.58, accuracy - 0.7391, recall - 0.8478, AUC - 0.7957, F1 - 0.7647, precision - 0.6964, training time - -12.0 seconds
2023-03-25 15:30:53,591 : [INFO]  Batch 24: Testing set : loss - 0.5844, accuracy - 0.6912, recall - 0.8235, AUC - 0.8162, F1 - 0.7273, precision - 0.6512
2023-03-25 15:30:53,605 : [INFO]  Batch 25 initialized 
2023-03-25 15:30:54,140 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:30:54,434 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 15:31:00,563 : [INFO]  ------------------------- Batch round 1, loss: 0.6233 -------------------------
2023-03-25 15:31:00,563 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 15:31:00,805 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:00,807 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 15:31:04,604 : [INFO]  ------------------------- Batch round 2, loss: 0.5952 -------------------------
2023-03-25 15:31:04,604 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 15:31:04,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:04,609 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 15:31:08,294 : [INFO]  ------------------------- Batch round 3, loss: 0.5889 -------------------------
2023-03-25 15:31:08,294 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 15:31:08,405 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:08,407 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 15:31:08,407 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 15:31:09,914 : [INFO]  Batch 25: Training set : loss - 0.5916, accuracy - 0.7011, recall - 0.8587, AUC - 0.7987, F1 - 0.7418, precision - 0.6529, training time - -14.0 seconds
2023-03-25 15:31:09,914 : [INFO]  Batch 25: Testing set : loss - 0.6104, accuracy - 0.6716, recall - 0.8235, AUC - 0.7947, F1 - 0.7149, precision - 0.6316
2023-03-25 15:31:09,927 : [INFO]  Batch 26 initialized 
2023-03-25 15:31:10,467 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:31:10,788 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 15:31:16,375 : [INFO]  ------------------------- Batch round 1, loss: 0.5746 -------------------------
2023-03-25 15:31:16,376 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 15:31:16,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:16,390 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 15:31:19,847 : [INFO]  ------------------------- Batch round 2, loss: 0.5549 -------------------------
2023-03-25 15:31:19,847 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 15:31:19,887 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:19,889 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 15:31:22,892 : [INFO]  ------------------------- Batch round 3, loss: 0.5422 -------------------------
2023-03-25 15:31:22,893 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 15:31:23,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:23,329 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 15:31:23,330 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 15:31:24,852 : [INFO]  Batch 26: Training set : loss - 0.542, accuracy - 0.7989, recall - 0.8913, AUC - 0.8649, F1 - 0.8159, precision - 0.7523, training time - -13.0 seconds
2023-03-25 15:31:24,853 : [INFO]  Batch 26: Testing set : loss - 0.5404, accuracy - 0.75, recall - 0.951, AUC - 0.9229, F1 - 0.7918, precision - 0.6783
2023-03-25 15:31:24,864 : [INFO]  Batch 27 initialized 
2023-03-25 15:31:25,293 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:31:25,588 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 15:31:30,445 : [INFO]  ------------------------- Batch round 1, loss: 0.5868 -------------------------
2023-03-25 15:31:30,445 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 15:31:30,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:30,451 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 15:31:33,619 : [INFO]  ------------------------- Batch round 2, loss: 0.5665 -------------------------
2023-03-25 15:31:33,619 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 15:31:33,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:33,624 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 15:31:36,875 : [INFO]  ------------------------- Batch round 3, loss: 0.5536 -------------------------
2023-03-25 15:31:36,875 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 15:31:36,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:36,883 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 15:31:36,883 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 15:31:38,744 : [INFO]  Batch 27: Training set : loss - 0.5472, accuracy - 0.7609, recall - 0.9565, AUC - 0.8704, F1 - 0.8, precision - 0.6875, training time - -11.0 seconds
2023-03-25 15:31:38,744 : [INFO]  Batch 27: Testing set : loss - 0.6173, accuracy - 0.652, recall - 0.8039, AUC - 0.7865, F1 - 0.6979, precision - 0.6165
2023-03-25 15:31:38,750 : [INFO]  Batch 28 initialized 
2023-03-25 15:31:39,338 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:31:39,619 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 15:31:45,029 : [INFO]  ------------------------- Batch round 1, loss: 0.5875 -------------------------
2023-03-25 15:31:45,029 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 15:31:45,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:45,233 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 15:31:48,324 : [INFO]  ------------------------- Batch round 2, loss: 0.5691 -------------------------
2023-03-25 15:31:48,324 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 15:31:48,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:48,329 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 15:31:51,261 : [INFO]  ------------------------- Batch round 3, loss: 0.5614 -------------------------
2023-03-25 15:31:51,261 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 15:31:51,264 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:51,266 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 15:31:51,266 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 15:31:52,837 : [INFO]  Batch 28: Training set : loss - 0.5502, accuracy - 0.7663, recall - 0.9022, AUC - 0.8612, F1 - 0.7943, precision - 0.7094, training time - -12.0 seconds
2023-03-25 15:31:52,837 : [INFO]  Batch 28: Testing set : loss - 0.61, accuracy - 0.6324, recall - 0.8627, AUC - 0.8041, F1 - 0.7012, precision - 0.5906
2023-03-25 15:31:52,847 : [INFO]  Batch 29 initialized 
2023-03-25 15:31:53,577 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:31:54,036 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 15:31:59,353 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 15:31:59,353 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 15:31:59,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:31:59,358 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 15:32:02,305 : [INFO]  ------------------------- Batch round 2, loss: 0.5605 -------------------------
2023-03-25 15:32:02,305 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 15:32:02,308 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:02,309 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 15:32:05,314 : [INFO]  ------------------------- Batch round 3, loss: 0.5555 -------------------------
2023-03-25 15:32:05,314 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 15:32:05,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:05,318 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 15:32:05,318 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 15:32:06,717 : [INFO]  Batch 29: Training set : loss - 0.5475, accuracy - 0.7717, recall - 0.913, AUC - 0.9005, F1 - 0.8, precision - 0.7119, training time - -11.0 seconds
2023-03-25 15:32:06,717 : [INFO]  Batch 29: Testing set : loss - 0.5615, accuracy - 0.7647, recall - 0.902, AUC - 0.8691, F1 - 0.7931, precision - 0.7077
2023-03-25 15:32:06,723 : [INFO]  Batch 30 initialized 
2023-03-25 15:32:07,195 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:32:07,474 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 15:32:12,062 : [INFO]  ------------------------- Batch round 1, loss: 0.5835 -------------------------
2023-03-25 15:32:12,063 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 15:32:12,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:12,067 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 15:32:15,020 : [INFO]  ------------------------- Batch round 2, loss: 0.5739 -------------------------
2023-03-25 15:32:15,020 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 15:32:15,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:15,027 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 15:32:17,927 : [INFO]  ------------------------- Batch round 3, loss: 0.5719 -------------------------
2023-03-25 15:32:17,927 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 15:32:17,930 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:17,933 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 15:32:17,933 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 15:32:19,301 : [INFO]  Batch 30: Training set : loss - 0.5658, accuracy - 0.75, recall - 0.8478, AUC - 0.7968, F1 - 0.7723, precision - 0.7091, training time - -10.0 seconds
2023-03-25 15:32:19,301 : [INFO]  Batch 30: Testing set : loss - 0.5851, accuracy - 0.6814, recall - 0.8725, AUC - 0.8442, F1 - 0.7325, precision - 0.6312
2023-03-25 15:32:19,307 : [INFO]  Batch 31 initialized 
2023-03-25 15:32:19,744 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:32:20,057 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 15:32:24,724 : [INFO]  ------------------------- Batch round 1, loss: 0.5688 -------------------------
2023-03-25 15:32:24,724 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 15:32:24,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:24,892 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 15:32:27,714 : [INFO]  ------------------------- Batch round 2, loss: 0.5595 -------------------------
2023-03-25 15:32:27,715 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 15:32:27,813 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:27,815 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 15:32:30,725 : [INFO]  ------------------------- Batch round 3, loss: 0.5382 -------------------------
2023-03-25 15:32:30,726 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 15:32:30,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:30,834 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 15:32:30,834 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 15:32:32,146 : [INFO]  Batch 31: Training set : loss - 0.5345, accuracy - 0.788, recall - 0.913, AUC - 0.8892, F1 - 0.8116, precision - 0.7304, training time - -11.0 seconds
2023-03-25 15:32:32,146 : [INFO]  Batch 31: Testing set : loss - 0.5654, accuracy - 0.7304, recall - 0.8824, AUC - 0.866, F1 - 0.766, precision - 0.6767
2023-03-25 15:32:32,160 : [INFO]  Batch 32 initialized 
2023-03-25 15:32:32,593 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:32:32,891 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 15:32:37,659 : [INFO]  ------------------------- Batch round 1, loss: 0.5672 -------------------------
2023-03-25 15:32:37,659 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 15:32:37,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:37,664 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 15:32:40,423 : [INFO]  ------------------------- Batch round 2, loss: 0.5606 -------------------------
2023-03-25 15:32:40,424 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 15:32:40,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:40,613 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 15:32:43,395 : [INFO]  ------------------------- Batch round 3, loss: 0.5428 -------------------------
2023-03-25 15:32:43,395 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 15:32:43,569 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:32:43,570 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 15:32:43,571 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 15:32:44,873 : [INFO]  Batch 32: Training set : loss - 0.5401, accuracy - 0.7935, recall - 0.9239, AUC - 0.8771, F1 - 0.8173, precision - 0.7328, training time - -11.0 seconds
2023-03-25 15:32:44,873 : [INFO]  Batch 32: Testing set : loss - 0.5614, accuracy - 0.7206, recall - 0.9412, AUC - 0.9023, F1 - 0.7711, precision - 0.6531
2023-03-25 15:32:44,883 : [INFO]  Batch 33 initialized 
2023-03-25 15:32:45,332 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:32:45,631 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
