2023-03-25 13:20:03,073 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 13:20:03,073 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 1, epochs 6
2023-03-25 13:20:06,196 : [INFO]  Model initialized for training
2023-03-25 13:20:20,371 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:20:20,507 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:20:20,507 : [INFO]  Connected to the server
2023-03-25 13:20:20,589 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:20:20,589 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:20:20,597 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:20:20,597 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:20:48,729 : [INFO]  ------------------------- Training round 1, loss: 0.6513 -------------------------
2023-03-25 13:20:48,730 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:20:55,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:20:55,695 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:21:36,721 : [INFO]  ------------------------- Training round 2, loss: 0.6062 -------------------------
2023-03-25 13:21:36,721 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:21:36,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:21:36,740 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:21:58,111 : [INFO]  ------------------------- Training round 3, loss: 0.5975 -------------------------
2023-03-25 13:21:58,111 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:21:58,114 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:21:58,115 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:22:22,047 : [INFO]  ------------------------- Training round 4, loss: 0.5955 -------------------------
2023-03-25 13:22:22,047 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:22:22,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:22:22,052 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:22:46,524 : [INFO]  ------------------------- Training round 5, loss: 0.5919 -------------------------
2023-03-25 13:22:46,524 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:23:03,098 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:03,104 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:23:47,672 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.7, recall - 0.89, AUC - 0.84, F1 - 0.75, precision - 0.65, training time - -163.0 seconds
2023-03-25 13:23:47,672 : [INFO]  Initially trained model: Testing set : loss - 0.58, accuracy - 0.7, recall - 0.89, AUC - 0.85, F1 - 0.75, precision - 0.64
2023-03-25 13:23:47,684 : [INFO]  Batch 1 initialized 
2023-03-25 13:23:48,149 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:23:48,265 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:23:48,265 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:23:52,392 : [INFO]  ------------------------- Batch round 1, loss: 0.5924 -------------------------
2023-03-25 13:23:52,392 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:23:52,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:52,399 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:23:54,757 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 13:23:54,757 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:23:54,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:54,842 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:23:57,080 : [INFO]  ------------------------- Batch round 3, loss: 0.5628 -------------------------
2023-03-25 13:23:57,080 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:23:57,249 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:57,251 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:23:57,251 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:23:58,562 : [INFO]  Batch 1: Training set : loss - 0.5566, accuracy - 0.75, recall - 0.9348, AUC - 0.8782, F1 - 0.789, precision - 0.6825, training time - -9.0 seconds
2023-03-25 13:23:58,562 : [INFO]  Batch 1: Testing set : loss - 0.5469, accuracy - 0.7451, recall - 0.9314, AUC - 0.9034, F1 - 0.7851, precision - 0.6786
2023-03-25 13:23:58,575 : [INFO]  Batch 2 initialized 
2023-03-25 13:23:59,096 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:23:59,327 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:24:03,462 : [INFO]  ------------------------- Batch round 1, loss: 0.5537 -------------------------
2023-03-25 13:24:03,463 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:03,466 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:03,468 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:24:05,668 : [INFO]  ------------------------- Batch round 2, loss: 0.5429 -------------------------
2023-03-25 13:24:05,668 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:05,672 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:05,674 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:24:07,945 : [INFO]  ------------------------- Batch round 3, loss: 0.5255 -------------------------
2023-03-25 13:24:07,945 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:07,949 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:07,951 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:24:07,951 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:24:09,260 : [INFO]  Batch 2: Training set : loss - 0.5161, accuracy - 0.8152, recall - 0.9565, AUC - 0.9218, F1 - 0.8381, precision - 0.7458, training time - -9.0 seconds
2023-03-25 13:24:09,260 : [INFO]  Batch 2: Testing set : loss - 0.53, accuracy - 0.7647, recall - 0.9608, AUC - 0.9198, F1 - 0.8033, precision - 0.6901
2023-03-25 13:24:09,296 : [INFO]  Batch 3 initialized 
2023-03-25 13:24:09,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:09,999 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:24:14,175 : [INFO]  ------------------------- Batch round 1, loss: 0.5503 -------------------------
2023-03-25 13:24:14,176 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:14,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:14,181 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:24:16,525 : [INFO]  ------------------------- Batch round 2, loss: 0.5374 -------------------------
2023-03-25 13:24:16,525 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:16,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:16,530 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:24:18,922 : [INFO]  ------------------------- Batch round 3, loss: 0.5264 -------------------------
2023-03-25 13:24:18,923 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:18,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:18,928 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:24:18,928 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:24:20,382 : [INFO]  Batch 3: Training set : loss - 0.5219, accuracy - 0.788, recall - 0.9239, AUC - 0.9327, F1 - 0.8134, precision - 0.7265, training time - -9.0 seconds
2023-03-25 13:24:20,382 : [INFO]  Batch 3: Testing set : loss - 0.5518, accuracy - 0.75, recall - 0.9314, AUC - 0.9189, F1 - 0.7884, precision - 0.6835
2023-03-25 13:24:20,389 : [INFO]  Batch 4 initialized 
2023-03-25 13:24:20,899 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:21,195 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 13:24:25,382 : [INFO]  ------------------------- Batch round 1, loss: 0.5441 -------------------------
2023-03-25 13:24:25,383 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:25,386 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:25,388 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 13:24:27,744 : [INFO]  ------------------------- Batch round 2, loss: 0.5287 -------------------------
2023-03-25 13:24:27,744 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:27,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:27,777 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 13:24:30,006 : [INFO]  ------------------------- Batch round 3, loss: 0.5263 -------------------------
2023-03-25 13:24:30,006 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:30,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:30,102 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 13:24:30,102 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 13:24:31,457 : [INFO]  Batch 4: Training set : loss - 0.5242, accuracy - 0.7989, recall - 0.9565, AUC - 0.9198, F1 - 0.8263, precision - 0.7273, training time - -9.0 seconds
2023-03-25 13:24:31,457 : [INFO]  Batch 4: Testing set : loss - 0.5455, accuracy - 0.7353, recall - 0.9118, AUC - 0.9109, F1 - 0.775, precision - 0.6739
2023-03-25 13:24:31,467 : [INFO]  Batch 5 initialized 
2023-03-25 13:24:31,895 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:32,150 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 13:24:36,364 : [INFO]  ------------------------- Batch round 1, loss: 0.5355 -------------------------
2023-03-25 13:24:36,365 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:36,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:36,379 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 13:24:38,968 : [INFO]  ------------------------- Batch round 2, loss: 0.5296 -------------------------
2023-03-25 13:24:38,968 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:38,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:38,982 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 13:24:41,154 : [INFO]  ------------------------- Batch round 3, loss: 0.5233 -------------------------
2023-03-25 13:24:41,154 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:41,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:41,539 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 13:24:41,539 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 13:24:42,861 : [INFO]  Batch 5: Training set : loss - 0.5232, accuracy - 0.7935, recall - 0.9348, AUC - 0.914, F1 - 0.819, precision - 0.7288, training time - -9.0 seconds
2023-03-25 13:24:42,861 : [INFO]  Batch 5: Testing set : loss - 0.5608, accuracy - 0.6569, recall - 0.8922, AUC - 0.8948, F1 - 0.7222, precision - 0.6067
2023-03-25 13:24:42,869 : [INFO]  Batch 6 initialized 
2023-03-25 13:24:43,305 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:43,539 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 13:24:47,738 : [INFO]  ------------------------- Batch round 1, loss: 0.539 -------------------------
2023-03-25 13:24:47,738 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:47,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:47,743 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 13:24:50,120 : [INFO]  ------------------------- Batch round 2, loss: 0.5214 -------------------------
2023-03-25 13:24:50,120 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:50,124 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:50,125 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 13:24:52,249 : [INFO]  ------------------------- Batch round 3, loss: 0.518 -------------------------
2023-03-25 13:24:52,249 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:52,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:52,254 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 13:24:52,254 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 13:24:53,580 : [INFO]  Batch 6: Training set : loss - 0.5034, accuracy - 0.8261, recall - 0.9674, AUC - 0.9364, F1 - 0.8476, precision - 0.7542, training time - -9.0 seconds
2023-03-25 13:24:53,580 : [INFO]  Batch 6: Testing set : loss - 0.56, accuracy - 0.7157, recall - 0.9314, AUC - 0.9023, F1 - 0.7661, precision - 0.6507
2023-03-25 13:24:53,586 : [INFO]  Batch 7 initialized 
2023-03-25 13:24:54,009 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:54,237 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 13:24:58,393 : [INFO]  ------------------------- Batch round 1, loss: 0.534 -------------------------
2023-03-25 13:24:58,393 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:58,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:58,399 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 13:25:00,989 : [INFO]  ------------------------- Batch round 2, loss: 0.5194 -------------------------
2023-03-25 13:25:00,989 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:00,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:00,997 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 13:25:03,930 : [INFO]  ------------------------- Batch round 3, loss: 0.5157 -------------------------
2023-03-25 13:25:03,930 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:04,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:04,057 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 13:25:04,057 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 13:25:05,630 : [INFO]  Batch 7: Training set : loss - 0.5113, accuracy - 0.7989, recall - 0.9565, AUC - 0.9143, F1 - 0.8263, precision - 0.7273, training time - -10.0 seconds
2023-03-25 13:25:05,630 : [INFO]  Batch 7: Testing set : loss - 0.5703, accuracy - 0.7451, recall - 0.902, AUC - 0.8638, F1 - 0.7797, precision - 0.6866
2023-03-25 13:25:05,646 : [INFO]  Batch 8 initialized 
2023-03-25 13:25:06,151 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:06,397 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 13:25:10,591 : [INFO]  ------------------------- Batch round 1, loss: 0.5669 -------------------------
2023-03-25 13:25:10,591 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:10,594 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:10,596 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 13:25:12,870 : [INFO]  ------------------------- Batch round 2, loss: 0.5551 -------------------------
2023-03-25 13:25:12,870 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:12,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:12,881 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 13:25:15,049 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 13:25:15,049 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:15,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:15,055 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 13:25:15,055 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 13:25:16,728 : [INFO]  Batch 8: Training set : loss - 0.5475, accuracy - 0.7609, recall - 0.9239, AUC - 0.8889, F1 - 0.7944, precision - 0.6967, training time - -9.0 seconds
2023-03-25 13:25:16,729 : [INFO]  Batch 8: Testing set : loss - 0.5695, accuracy - 0.7157, recall - 0.9314, AUC - 0.8858, F1 - 0.7661, precision - 0.6507
2023-03-25 13:25:16,736 : [INFO]  Batch 9 initialized 
2023-03-25 13:25:17,229 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:17,535 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 13:25:22,698 : [INFO]  ------------------------- Batch round 1, loss: 0.571 -------------------------
2023-03-25 13:25:22,698 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:22,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:22,704 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 13:25:25,254 : [INFO]  ------------------------- Batch round 2, loss: 0.5578 -------------------------
2023-03-25 13:25:25,254 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:25,258 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:25,262 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 13:25:27,815 : [INFO]  ------------------------- Batch round 3, loss: 0.5499 -------------------------
2023-03-25 13:25:27,815 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:27,819 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:27,821 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 13:25:27,821 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 13:25:29,810 : [INFO]  Batch 9: Training set : loss - 0.5381, accuracy - 0.788, recall - 0.9457, AUC - 0.9113, F1 - 0.8169, precision - 0.719, training time - -10.0 seconds
2023-03-25 13:25:29,810 : [INFO]  Batch 9: Testing set : loss - 0.6211, accuracy - 0.6324, recall - 0.8431, AUC - 0.7984, F1 - 0.6964, precision - 0.5931
2023-03-25 13:25:29,822 : [INFO]  Batch 10 initialized 
2023-03-25 13:25:30,450 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:30,763 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 13:25:35,043 : [INFO]  ------------------------- Batch round 1, loss: 0.5451 -------------------------
2023-03-25 13:25:35,043 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:35,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:35,049 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 13:25:37,656 : [INFO]  ------------------------- Batch round 2, loss: 0.5358 -------------------------
2023-03-25 13:25:37,656 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:37,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:37,661 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 13:25:39,969 : [INFO]  ------------------------- Batch round 3, loss: 0.525 -------------------------
2023-03-25 13:25:39,969 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:40,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:40,184 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 13:25:40,184 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 13:25:42,075 : [INFO]  Batch 10: Training set : loss - 0.5201, accuracy - 0.788, recall - 0.9348, AUC - 0.8958, F1 - 0.8152, precision - 0.7227, training time - -9.0 seconds
2023-03-25 13:25:42,075 : [INFO]  Batch 10: Testing set : loss - 0.5641, accuracy - 0.6961, recall - 0.8824, AUC - 0.8838, F1 - 0.7438, precision - 0.6429
2023-03-25 13:25:42,081 : [INFO]  Batch 11 initialized 
2023-03-25 13:25:42,522 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:42,838 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 13:25:47,447 : [INFO]  ------------------------- Batch round 1, loss: 0.5778 -------------------------
2023-03-25 13:25:47,447 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:47,450 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:47,452 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 13:25:49,751 : [INFO]  ------------------------- Batch round 2, loss: 0.5615 -------------------------
2023-03-25 13:25:49,751 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:49,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:49,806 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 13:25:53,362 : [INFO]  ------------------------- Batch round 3, loss: 0.5584 -------------------------
2023-03-25 13:25:53,362 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:53,370 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:53,375 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 13:25:53,375 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 13:25:54,605 : [INFO]  Batch 11: Training set : loss - 0.5476, accuracy - 0.7609, recall - 0.9348, AUC - 0.8773, F1 - 0.7963, precision - 0.6935, training time - -11.0 seconds
2023-03-25 13:25:54,605 : [INFO]  Batch 11: Testing set : loss - 0.5704, accuracy - 0.7059, recall - 0.9314, AUC - 0.9104, F1 - 0.76, precision - 0.6419
2023-03-25 13:25:54,615 : [INFO]  Batch 12 initialized 
2023-03-25 13:25:55,055 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:55,337 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 13:25:59,999 : [INFO]  ------------------------- Batch round 1, loss: 0.5542 -------------------------
2023-03-25 13:25:59,999 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 13:26:00,088 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:00,090 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 13:26:02,420 : [INFO]  ------------------------- Batch round 2, loss: 0.5492 -------------------------
2023-03-25 13:26:02,420 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 13:26:02,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:02,572 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 13:26:05,784 : [INFO]  ------------------------- Batch round 3, loss: 0.5403 -------------------------
2023-03-25 13:26:05,785 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 13:26:05,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:05,789 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 13:26:05,789 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 13:26:07,254 : [INFO]  Batch 12: Training set : loss - 0.5318, accuracy - 0.7935, recall - 0.913, AUC - 0.8904, F1 - 0.8155, precision - 0.7368, training time - -10.0 seconds
2023-03-25 13:26:07,254 : [INFO]  Batch 12: Testing set : loss - 0.5674, accuracy - 0.7206, recall - 0.8824, AUC - 0.8719, F1 - 0.7595, precision - 0.6667
2023-03-25 13:26:07,260 : [INFO]  Batch 13 initialized 
2023-03-25 13:26:08,140 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:26:08,445 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 13:26:12,734 : [INFO]  ------------------------- Batch round 1, loss: 0.541 -------------------------
2023-03-25 13:26:12,734 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 13:26:12,737 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:12,740 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 13:26:15,436 : [INFO]  ------------------------- Batch round 2, loss: 0.5365 -------------------------
2023-03-25 13:26:15,436 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 13:26:15,478 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:15,480 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 13:26:18,400 : [INFO]  ------------------------- Batch round 3, loss: 0.5225 -------------------------
2023-03-25 13:26:18,400 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 13:26:18,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:18,406 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 13:26:18,406 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 13:26:20,548 : [INFO]  Batch 13: Training set : loss - 0.5217, accuracy - 0.8152, recall - 0.9457, AUC - 0.9181, F1 - 0.8365, precision - 0.75, training time - -10.0 seconds
2023-03-25 13:26:20,548 : [INFO]  Batch 13: Testing set : loss - 0.5705, accuracy - 0.6569, recall - 0.902, AUC - 0.8952, F1 - 0.7244, precision - 0.6053
2023-03-25 13:26:20,555 : [INFO]  Batch 14 initialized 
2023-03-25 13:26:21,015 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:26:21,217 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
