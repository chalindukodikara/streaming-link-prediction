2023-03-27 14:43:48,835 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-27 14:43:48,835 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 6, epochs 6
2023-03-27 14:43:52,781 : [INFO]  Model initialized for training
2023-03-27 14:43:56,611 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:43:56,643 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-27 14:43:56,644 : [INFO]  Connected to the server
2023-03-27 14:43:56,743 : [INFO]  Distributed training for streaming graphs started!
2023-03-27 14:43:56,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:43:56,751 : [INFO]  ################################## Initial model training started ##################################
2023-03-27 14:43:56,751 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-27 14:44:13,942 : [INFO]  ------------------------- Training round 1, loss: 0.7026 -------------------------
2023-03-27 14:44:13,942 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-27 14:44:17,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:44:17,427 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-27 14:44:38,479 : [INFO]  ------------------------- Training round 2, loss: 0.6281 -------------------------
2023-03-27 14:44:38,479 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-27 14:44:38,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:44:38,521 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-27 14:44:59,861 : [INFO]  ------------------------- Training round 3, loss: 0.6032 -------------------------
2023-03-27 14:44:59,861 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-27 14:44:59,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:44:59,873 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-27 14:45:23,545 : [INFO]  ------------------------- Training round 4, loss: 0.5925 -------------------------
2023-03-27 14:45:23,545 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-27 14:45:23,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:45:23,564 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-27 14:45:44,945 : [INFO]  ------------------------- Training round 5, loss: 0.5876 -------------------------
2023-03-27 14:45:44,945 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-27 14:45:45,013 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:45:45,018 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-27 14:46:06,593 : [INFO]  ------------------------- Training round 6, loss: 0.5813 -------------------------
2023-03-27 14:46:06,593 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-27 14:46:06,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:06,784 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-27 14:46:15,135 : [INFO]  Initially trained model: Training set : loss - 0.57, accuracy - 0.74, recall - 0.92, AUC - 0.86, F1 - 0.78, precision - 0.67, training time - -130.0 seconds
2023-03-27 14:46:15,135 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.72, recall - 0.91, AUC - 0.85, F1 - 0.77, precision - 0.66
2023-03-27 14:46:15,139 : [INFO]  Batch 1 initialized 
2023-03-27 14:46:15,812 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:16,068 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-27 14:46:16,069 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-27 14:46:21,801 : [INFO]  ------------------------- Batch round 1, loss: 0.5855 -------------------------
2023-03-27 14:46:21,801 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-27 14:46:21,923 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:21,925 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-27 14:46:24,281 : [INFO]  ------------------------- Batch round 2, loss: 0.5732 -------------------------
2023-03-27 14:46:24,281 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-27 14:46:24,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:24,286 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-27 14:46:26,754 : [INFO]  ------------------------- Batch round 3, loss: 0.5721 -------------------------
2023-03-27 14:46:26,754 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-27 14:46:26,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:26,761 : [INFO]  Batch number 1 model fetched from the server
2023-03-27 14:46:26,761 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-27 14:46:28,750 : [INFO]  Batch 1: Training set : loss - 0.5588, accuracy - 0.7391, recall - 0.9348, AUC - 0.8436, F1 - 0.7818, precision - 0.6719, training time - -11.0 seconds
2023-03-27 14:46:28,750 : [INFO]  Batch 1: Testing set : loss - 0.5663, accuracy - 0.75, recall - 0.9706, AUC - 0.8303, F1 - 0.7952, precision - 0.6735
2023-03-27 14:46:28,765 : [INFO]  Batch 2 initialized 
2023-03-27 14:46:29,423 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:29,603 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-27 14:46:34,887 : [INFO]  ------------------------- Batch round 1, loss: 0.6 -------------------------
2023-03-27 14:46:34,888 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-27 14:46:35,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:35,027 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-27 14:46:37,679 : [INFO]  ------------------------- Batch round 2, loss: 0.5982 -------------------------
2023-03-27 14:46:37,680 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-27 14:46:37,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:37,757 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-27 14:46:40,416 : [INFO]  ------------------------- Batch round 3, loss: 0.5904 -------------------------
2023-03-27 14:46:40,416 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-27 14:46:40,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:40,570 : [INFO]  Batch number 2 model fetched from the server
2023-03-27 14:46:40,570 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-27 14:46:42,647 : [INFO]  Batch 2: Training set : loss - 0.5862, accuracy - 0.7011, recall - 0.8804, AUC - 0.8207, F1 - 0.7465, precision - 0.648, training time - -11.0 seconds
2023-03-27 14:46:42,647 : [INFO]  Batch 2: Testing set : loss - 0.5926, accuracy - 0.701, recall - 0.9314, AUC - 0.8155, F1 - 0.757, precision - 0.6376
2023-03-27 14:46:42,651 : [INFO]  Batch 3 initialized 
2023-03-27 14:46:43,285 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:43,633 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-27 14:46:49,287 : [INFO]  ------------------------- Batch round 1, loss: 0.5929 -------------------------
2023-03-27 14:46:49,288 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-27 14:46:49,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:49,351 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-27 14:46:51,749 : [INFO]  ------------------------- Batch round 2, loss: 0.5876 -------------------------
2023-03-27 14:46:51,749 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-27 14:46:51,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:51,928 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-27 14:46:54,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5817 -------------------------
2023-03-27 14:46:54,579 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-27 14:46:54,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:54,717 : [INFO]  Batch number 3 model fetched from the server
2023-03-27 14:46:54,717 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-27 14:46:56,488 : [INFO]  Batch 3: Training set : loss - 0.5724, accuracy - 0.7609, recall - 0.9239, AUC - 0.8249, F1 - 0.7944, precision - 0.6967, training time - -11.0 seconds
2023-03-27 14:46:56,488 : [INFO]  Batch 3: Testing set : loss - 0.5823, accuracy - 0.7157, recall - 0.9314, AUC - 0.8125, F1 - 0.7661, precision - 0.6507
2023-03-27 14:46:56,492 : [INFO]  Batch 4 initialized 
2023-03-27 14:46:57,108 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:57,522 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-27 14:47:02,956 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-27 14:47:02,956 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:02,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:02,968 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-27 14:47:05,688 : [INFO]  ------------------------- Batch round 2, loss: 0.5604 -------------------------
2023-03-27 14:47:05,688 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:05,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:05,693 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-27 14:47:08,648 : [INFO]  ------------------------- Batch round 3, loss: 0.5566 -------------------------
2023-03-27 14:47:08,648 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:08,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:08,658 : [INFO]  Batch number 4 model fetched from the server
2023-03-27 14:47:08,658 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-27 14:47:10,938 : [INFO]  Batch 4: Training set : loss - 0.5521, accuracy - 0.7391, recall - 0.9457, AUC - 0.8944, F1 - 0.7838, precision - 0.6692, training time - -11.0 seconds
2023-03-27 14:47:10,938 : [INFO]  Batch 4: Testing set : loss - 0.5374, accuracy - 0.7745, recall - 0.951, AUC - 0.8949, F1 - 0.8083, precision - 0.7029
2023-03-27 14:47:10,942 : [INFO]  Batch 5 initialized 
2023-03-27 14:47:11,606 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:12,069 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-27 14:47:17,828 : [INFO]  ------------------------- Batch round 1, loss: 0.5724 -------------------------
2023-03-27 14:47:17,828 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:17,934 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:17,937 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-27 14:47:20,968 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-27 14:47:20,969 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:21,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:21,108 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-27 14:47:23,608 : [INFO]  ------------------------- Batch round 3, loss: 0.5662 -------------------------
2023-03-27 14:47:23,608 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:23,646 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:23,650 : [INFO]  Batch number 5 model fetched from the server
2023-03-27 14:47:23,650 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-27 14:47:25,304 : [INFO]  Batch 5: Training set : loss - 0.5576, accuracy - 0.75, recall - 0.9457, AUC - 0.8608, F1 - 0.7909, precision - 0.6797, training time - -12.0 seconds
2023-03-27 14:47:25,305 : [INFO]  Batch 5: Testing set : loss - 0.5767, accuracy - 0.7157, recall - 0.902, AUC - 0.8438, F1 - 0.7603, precision - 0.6571
2023-03-27 14:47:25,313 : [INFO]  Batch 6 initialized 
2023-03-27 14:47:26,051 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:26,473 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-27 14:47:31,247 : [INFO]  ------------------------- Batch round 1, loss: 0.5765 -------------------------
2023-03-27 14:47:31,249 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:31,280 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:31,286 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-27 14:47:33,661 : [INFO]  ------------------------- Batch round 2, loss: 0.5736 -------------------------
2023-03-27 14:47:33,661 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:33,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:33,675 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-27 14:47:36,296 : [INFO]  ------------------------- Batch round 3, loss: 0.5713 -------------------------
2023-03-27 14:47:36,297 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:36,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:36,367 : [INFO]  Batch number 6 model fetched from the server
2023-03-27 14:47:36,367 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-27 14:47:38,203 : [INFO]  Batch 6: Training set : loss - 0.5691, accuracy - 0.7174, recall - 0.9565, AUC - 0.8592, F1 - 0.7719, precision - 0.6471, training time - -10.0 seconds
2023-03-27 14:47:38,203 : [INFO]  Batch 6: Testing set : loss - 0.5838, accuracy - 0.7255, recall - 0.9118, AUC - 0.8135, F1 - 0.7686, precision - 0.6643
2023-03-27 14:47:38,209 : [INFO]  Batch 7 initialized 
2023-03-27 14:47:39,008 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:39,362 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-27 14:47:44,439 : [INFO]  ------------------------- Batch round 1, loss: 0.579 -------------------------
2023-03-27 14:47:44,440 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:44,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:44,816 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-27 14:47:47,506 : [INFO]  ------------------------- Batch round 2, loss: 0.5772 -------------------------
2023-03-27 14:47:47,508 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:47,597 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:47,600 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-27 14:47:50,237 : [INFO]  ------------------------- Batch round 3, loss: 0.573 -------------------------
2023-03-27 14:47:50,238 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:50,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:50,410 : [INFO]  Batch number 7 model fetched from the server
2023-03-27 14:47:50,411 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-27 14:47:52,151 : [INFO]  Batch 7: Training set : loss - 0.5715, accuracy - 0.7391, recall - 0.9457, AUC - 0.8243, F1 - 0.7838, precision - 0.6692, training time - -11.0 seconds
2023-03-27 14:47:52,152 : [INFO]  Batch 7: Testing set : loss - 0.5453, accuracy - 0.7549, recall - 0.9216, AUC - 0.8682, F1 - 0.7899, precision - 0.6912
2023-03-27 14:47:52,160 : [INFO]  Batch 8 initialized 
2023-03-27 14:47:52,771 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:53,026 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-27 14:47:57,560 : [INFO]  ------------------------- Batch round 1, loss: 0.5675 -------------------------
2023-03-27 14:47:57,563 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:57,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:57,652 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-27 14:48:00,645 : [INFO]  ------------------------- Batch round 2, loss: 0.5652 -------------------------
2023-03-27 14:48:00,645 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:00,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:00,696 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-27 14:48:03,072 : [INFO]  ------------------------- Batch round 3, loss: 0.5611 -------------------------
2023-03-27 14:48:03,072 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:03,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:03,203 : [INFO]  Batch number 8 model fetched from the server
2023-03-27 14:48:03,204 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-27 14:48:05,058 : [INFO]  Batch 8: Training set : loss - 0.557, accuracy - 0.7663, recall - 0.913, AUC - 0.8511, F1 - 0.7962, precision - 0.7059, training time - -10.0 seconds
2023-03-27 14:48:05,058 : [INFO]  Batch 8: Testing set : loss - 0.6146, accuracy - 0.6814, recall - 0.8824, AUC - 0.7663, F1 - 0.7347, precision - 0.6294
2023-03-27 14:48:05,066 : [INFO]  Batch 9 initialized 
2023-03-27 14:48:05,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:48:05,877 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-27 14:48:11,195 : [INFO]  ------------------------- Batch round 1, loss: 0.5648 -------------------------
2023-03-27 14:48:11,195 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-27 14:48:11,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:11,218 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-27 14:48:13,965 : [INFO]  ------------------------- Batch round 2, loss: 0.5522 -------------------------
2023-03-27 14:48:13,966 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:13,989 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:13,991 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-27 14:48:16,784 : [INFO]  ------------------------- Batch round 3, loss: 0.5496 -------------------------
2023-03-27 14:48:16,785 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:16,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:16,792 : [INFO]  Batch number 9 model fetched from the server
2023-03-27 14:48:16,793 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-27 14:48:18,304 : [INFO]  Batch 9: Training set : loss - 0.5465, accuracy - 0.7663, recall - 0.9565, AUC - 0.8671, F1 - 0.8037, precision - 0.6929, training time - -11.0 seconds
2023-03-27 14:48:18,304 : [INFO]  Batch 9: Testing set : loss - 0.5763, accuracy - 0.7255, recall - 0.9216, AUC - 0.8241, F1 - 0.7705, precision - 0.662
2023-03-27 14:48:18,309 : [INFO]  Batch 10 initialized 
2023-03-27 14:48:18,839 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:48:19,144 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-27 14:48:23,964 : [INFO]  ------------------------- Batch round 1, loss: 0.5736 -------------------------
2023-03-27 14:48:23,965 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-27 14:48:24,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:24,054 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-27 14:48:26,434 : [INFO]  ------------------------- Batch round 2, loss: 0.5707 -------------------------
2023-03-27 14:48:26,434 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:26,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:26,754 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-27 14:48:29,804 : [INFO]  ------------------------- Batch round 3, loss: 0.5683 -------------------------
2023-03-27 14:48:29,804 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:29,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:29,844 : [INFO]  Batch number 10 model fetched from the server
2023-03-27 14:48:29,844 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-27 14:48:31,613 : [INFO]  Batch 10: Training set : loss - 0.5629, accuracy - 0.7609, recall - 0.9022, AUC - 0.8492, F1 - 0.7905, precision - 0.7034, training time - -11.0 seconds
2023-03-27 14:48:31,613 : [INFO]  Batch 10: Testing set : loss - 0.5655, accuracy - 0.7598, recall - 0.8922, AUC - 0.8225, F1 - 0.7879, precision - 0.7054
2023-03-27 14:48:31,617 : [INFO]  Batch 11 initialized 
2023-03-27 14:48:32,320 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:48:32,698 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-27 14:48:38,003 : [INFO]  ------------------------- Batch round 1, loss: 0.5468 -------------------------
2023-03-27 14:48:38,004 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-27 14:48:38,315 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:38,317 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-27 14:48:40,886 : [INFO]  ------------------------- Batch round 2, loss: 0.5392 -------------------------
2023-03-27 14:48:40,886 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:40,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:40,894 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-27 14:48:44,651 : [INFO]  ------------------------- Batch round 3, loss: 0.5387 -------------------------
2023-03-27 14:48:44,651 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:44,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:44,723 : [INFO]  Batch number 11 model fetched from the server
2023-03-27 14:48:44,723 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
