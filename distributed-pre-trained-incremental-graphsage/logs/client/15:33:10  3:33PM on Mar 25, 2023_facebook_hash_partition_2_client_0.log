2023-03-25 15:33:10,072 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 15:33:10,072 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 6, epochs 6
2023-03-25 15:33:14,136 : [INFO]  Model initialized for training
2023-03-25 15:33:30,155 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:33:30,283 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 15:33:30,284 : [INFO]  Connected to the server
2023-03-25 15:33:30,366 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 15:33:30,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:33:30,374 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 15:33:30,374 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 15:35:57,049 : [INFO]  ------------------------- Training round 1, loss: 0.6222 -------------------------
2023-03-25 15:35:57,049 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 15:35:57,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:35:57,053 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 15:38:17,488 : [INFO]  ------------------------- Training round 2, loss: 0.5953 -------------------------
2023-03-25 15:38:17,488 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 15:38:17,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:38:17,492 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 15:40:37,918 : [INFO]  ------------------------- Training round 3, loss: 0.5918 -------------------------
2023-03-25 15:40:37,918 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 15:40:37,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:40:37,923 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 15:42:57,942 : [INFO]  ------------------------- Training round 4, loss: 0.5905 -------------------------
2023-03-25 15:42:57,943 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 15:42:57,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:42:57,947 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 15:45:18,155 : [INFO]  ------------------------- Training round 5, loss: 0.5888 -------------------------
2023-03-25 15:45:18,155 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 15:45:18,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:45:18,160 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 15:46:06,078 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.7, recall - 0.86, AUC - 0.83, F1 - 0.74, precision - 0.65, training time - -708.0 seconds
2023-03-25 15:46:06,079 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 15:46:06,085 : [INFO]  Batch 1 initialized 
2023-03-25 15:46:06,536 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:06,644 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 15:46:06,644 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 15:46:09,908 : [INFO]  ------------------------- Batch round 1, loss: 0.5865 -------------------------
2023-03-25 15:46:09,908 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:09,910 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:09,912 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 15:46:12,178 : [INFO]  ------------------------- Batch round 2, loss: 0.5814 -------------------------
2023-03-25 15:46:12,178 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:12,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:12,182 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 15:46:14,468 : [INFO]  ------------------------- Batch round 3, loss: 0.567 -------------------------
2023-03-25 15:46:14,468 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:14,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:14,473 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 15:46:14,473 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 15:46:15,803 : [INFO]  Batch 1: Training set : loss - 0.5706, accuracy - 0.7337, recall - 0.913, AUC - 0.87, F1 - 0.7742, precision - 0.672, training time - -8.0 seconds
2023-03-25 15:46:15,804 : [INFO]  Batch 1: Testing set : loss - 0.5641, accuracy - 0.7549, recall - 0.8725, AUC - 0.8661, F1 - 0.7807, precision - 0.7063
2023-03-25 15:46:15,809 : [INFO]  Batch 2 initialized 
2023-03-25 15:46:16,252 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:16,394 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 15:46:20,696 : [INFO]  ------------------------- Batch round 1, loss: 0.5633 -------------------------
2023-03-25 15:46:20,696 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:20,699 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:20,700 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 15:46:22,741 : [INFO]  ------------------------- Batch round 2, loss: 0.5543 -------------------------
2023-03-25 15:46:22,741 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:22,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:22,746 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 15:46:25,064 : [INFO]  ------------------------- Batch round 3, loss: 0.5414 -------------------------
2023-03-25 15:46:25,064 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:25,067 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:25,068 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 15:46:25,069 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 15:46:26,355 : [INFO]  Batch 2: Training set : loss - 0.5453, accuracy - 0.7772, recall - 0.9565, AUC - 0.8846, F1 - 0.8111, precision - 0.704, training time - -9.0 seconds
2023-03-25 15:46:26,355 : [INFO]  Batch 2: Testing set : loss - 0.57, accuracy - 0.7206, recall - 0.9216, AUC - 0.8741, F1 - 0.7673, precision - 0.6573
2023-03-25 15:46:26,363 : [INFO]  Batch 3 initialized 
2023-03-25 15:46:26,790 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:27,011 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 15:46:30,903 : [INFO]  ------------------------- Batch round 1, loss: 0.5382 -------------------------
2023-03-25 15:46:30,903 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:31,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:31,160 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 15:46:33,190 : [INFO]  ------------------------- Batch round 2, loss: 0.5325 -------------------------
2023-03-25 15:46:33,190 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:33,442 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:33,444 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 15:46:35,584 : [INFO]  ------------------------- Batch round 3, loss: 0.5314 -------------------------
2023-03-25 15:46:35,585 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:35,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:35,589 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 15:46:35,590 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 15:46:36,944 : [INFO]  Batch 3: Training set : loss - 0.5271, accuracy - 0.7935, recall - 0.9022, AUC - 0.894, F1 - 0.8137, precision - 0.7411, training time - -9.0 seconds
2023-03-25 15:46:36,944 : [INFO]  Batch 3: Testing set : loss - 0.5547, accuracy - 0.7304, recall - 0.9412, AUC - 0.8725, F1 - 0.7773, precision - 0.6621
2023-03-25 15:46:36,951 : [INFO]  Batch 4 initialized 
2023-03-25 15:46:37,373 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:37,587 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 15:46:41,505 : [INFO]  ------------------------- Batch round 1, loss: 0.5641 -------------------------
2023-03-25 15:46:41,505 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:41,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:41,510 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 15:46:43,666 : [INFO]  ------------------------- Batch round 2, loss: 0.5528 -------------------------
2023-03-25 15:46:43,666 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:43,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:43,672 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 15:46:45,860 : [INFO]  ------------------------- Batch round 3, loss: 0.5481 -------------------------
2023-03-25 15:46:45,860 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:45,863 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:45,865 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 15:46:45,866 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 15:46:47,177 : [INFO]  Batch 4: Training set : loss - 0.5449, accuracy - 0.7826, recall - 0.9348, AUC - 0.9084, F1 - 0.8113, precision - 0.7167, training time - -8.0 seconds
2023-03-25 15:46:47,178 : [INFO]  Batch 4: Testing set : loss - 0.5689, accuracy - 0.7451, recall - 0.9608, AUC - 0.8964, F1 - 0.7903, precision - 0.6712
2023-03-25 15:46:47,183 : [INFO]  Batch 5 initialized 
2023-03-25 15:46:47,605 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:47,828 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 15:46:51,747 : [INFO]  ------------------------- Batch round 1, loss: 0.5374 -------------------------
2023-03-25 15:46:51,747 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:51,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:51,752 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 15:46:53,997 : [INFO]  ------------------------- Batch round 2, loss: 0.5245 -------------------------
2023-03-25 15:46:53,997 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:54,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:54,003 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 15:46:56,189 : [INFO]  ------------------------- Batch round 3, loss: 0.5203 -------------------------
2023-03-25 15:46:56,189 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:56,192 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:56,193 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 15:46:56,194 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 15:46:57,544 : [INFO]  Batch 5: Training set : loss - 0.5178, accuracy - 0.7826, recall - 0.9457, AUC - 0.9353, F1 - 0.8131, precision - 0.7131, training time - -8.0 seconds
2023-03-25 15:46:57,544 : [INFO]  Batch 5: Testing set : loss - 0.577, accuracy - 0.7206, recall - 0.8725, AUC - 0.8366, F1 - 0.7574, precision - 0.6692
2023-03-25 15:46:57,550 : [INFO]  Batch 6 initialized 
2023-03-25 15:46:57,994 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:58,201 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 15:47:02,101 : [INFO]  ------------------------- Batch round 1, loss: 0.5678 -------------------------
2023-03-25 15:47:02,101 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:02,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:02,108 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 15:47:04,392 : [INFO]  ------------------------- Batch round 2, loss: 0.5521 -------------------------
2023-03-25 15:47:04,392 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:04,395 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:04,397 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 15:47:06,514 : [INFO]  ------------------------- Batch round 3, loss: 0.5593 -------------------------
2023-03-25 15:47:06,514 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:06,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:06,519 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 15:47:06,519 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 15:47:07,824 : [INFO]  Batch 6: Training set : loss - 0.5581, accuracy - 0.7663, recall - 0.9457, AUC - 0.89, F1 - 0.8018, precision - 0.696, training time - -8.0 seconds
2023-03-25 15:47:07,824 : [INFO]  Batch 6: Testing set : loss - 0.5627, accuracy - 0.7402, recall - 0.9118, AUC - 0.8849, F1 - 0.7782, precision - 0.6788
2023-03-25 15:47:07,829 : [INFO]  Batch 7 initialized 
2023-03-25 15:47:08,291 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:08,528 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 15:47:12,706 : [INFO]  ------------------------- Batch round 1, loss: 0.5735 -------------------------
2023-03-25 15:47:12,706 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:12,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:12,711 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 15:47:15,003 : [INFO]  ------------------------- Batch round 2, loss: 0.565 -------------------------
2023-03-25 15:47:15,003 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:15,006 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:15,008 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 15:47:17,268 : [INFO]  ------------------------- Batch round 3, loss: 0.5547 -------------------------
2023-03-25 15:47:17,268 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:17,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:17,273 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 15:47:17,273 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 15:47:18,614 : [INFO]  Batch 7: Training set : loss - 0.5527, accuracy - 0.7609, recall - 0.9565, AUC - 0.8745, F1 - 0.8, precision - 0.6875, training time - -9.0 seconds
2023-03-25 15:47:18,614 : [INFO]  Batch 7: Testing set : loss - 0.5904, accuracy - 0.7108, recall - 0.8725, AUC - 0.8258, F1 - 0.7511, precision - 0.6593
2023-03-25 15:47:18,619 : [INFO]  Batch 8 initialized 
2023-03-25 15:47:19,073 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:19,296 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 15:47:23,308 : [INFO]  ------------------------- Batch round 1, loss: 0.5737 -------------------------
2023-03-25 15:47:23,308 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:23,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:23,312 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 15:47:25,523 : [INFO]  ------------------------- Batch round 2, loss: 0.5602 -------------------------
2023-03-25 15:47:25,523 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:25,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:25,527 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 15:47:27,737 : [INFO]  ------------------------- Batch round 3, loss: 0.5595 -------------------------
2023-03-25 15:47:27,737 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:27,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:27,742 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 15:47:27,742 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 15:47:29,083 : [INFO]  Batch 8: Training set : loss - 0.5574, accuracy - 0.7609, recall - 0.8913, AUC - 0.8814, F1 - 0.7885, precision - 0.7069, training time - -8.0 seconds
2023-03-25 15:47:29,083 : [INFO]  Batch 8: Testing set : loss - 0.5699, accuracy - 0.7549, recall - 0.902, AUC - 0.8607, F1 - 0.7863, precision - 0.697
2023-03-25 15:47:29,088 : [INFO]  Batch 9 initialized 
2023-03-25 15:47:29,530 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:29,751 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 15:47:33,698 : [INFO]  ------------------------- Batch round 1, loss: 0.5593 -------------------------
2023-03-25 15:47:33,698 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:33,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:33,891 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 15:47:36,155 : [INFO]  ------------------------- Batch round 2, loss: 0.5423 -------------------------
2023-03-25 15:47:36,155 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:36,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:36,161 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 15:47:38,319 : [INFO]  ------------------------- Batch round 3, loss: 0.525 -------------------------
2023-03-25 15:47:38,320 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:38,602 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:38,604 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 15:47:38,604 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 15:47:39,927 : [INFO]  Batch 9: Training set : loss - 0.5236, accuracy - 0.788, recall - 0.9457, AUC - 0.9301, F1 - 0.8169, precision - 0.719, training time - -9.0 seconds
2023-03-25 15:47:39,928 : [INFO]  Batch 9: Testing set : loss - 0.5611, accuracy - 0.7157, recall - 0.8725, AUC - 0.8715, F1 - 0.7542, precision - 0.6642
2023-03-25 15:47:39,933 : [INFO]  Batch 10 initialized 
2023-03-25 15:47:40,378 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:40,613 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 15:47:44,553 : [INFO]  ------------------------- Batch round 1, loss: 0.5524 -------------------------
2023-03-25 15:47:44,553 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:44,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:44,558 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 15:47:46,776 : [INFO]  ------------------------- Batch round 2, loss: 0.5438 -------------------------
2023-03-25 15:47:46,776 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:46,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:46,781 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 15:47:48,899 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-25 15:47:48,899 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:49,173 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:49,176 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 15:47:49,176 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 15:47:50,493 : [INFO]  Batch 10: Training set : loss - 0.5313, accuracy - 0.7989, recall - 0.9674, AUC - 0.9034, F1 - 0.8279, precision - 0.7236, training time - -9.0 seconds
2023-03-25 15:47:50,494 : [INFO]  Batch 10: Testing set : loss - 0.5516, accuracy - 0.7353, recall - 0.8922, AUC - 0.8785, F1 - 0.7712, precision - 0.6791
2023-03-25 15:47:50,500 : [INFO]  Batch 11 initialized 
2023-03-25 15:47:50,920 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:51,175 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 15:47:55,110 : [INFO]  ------------------------- Batch round 1, loss: 0.5759 -------------------------
2023-03-25 15:47:55,110 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:55,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:55,275 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 15:47:57,432 : [INFO]  ------------------------- Batch round 2, loss: 0.5621 -------------------------
2023-03-25 15:47:57,432 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:57,435 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:57,437 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 15:47:59,632 : [INFO]  ------------------------- Batch round 3, loss: 0.5517 -------------------------
2023-03-25 15:47:59,632 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:59,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:59,636 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 15:47:59,636 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 15:48:00,996 : [INFO]  Batch 11: Training set : loss - 0.5583, accuracy - 0.7554, recall - 0.9348, AUC - 0.884, F1 - 0.7926, precision - 0.688, training time - -8.0 seconds
2023-03-25 15:48:00,996 : [INFO]  Batch 11: Testing set : loss - 0.5491, accuracy - 0.75, recall - 0.9118, AUC - 0.9, F1 - 0.7848, precision - 0.6889
2023-03-25 15:48:01,004 : [INFO]  Batch 12 initialized 
2023-03-25 15:48:01,422 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:01,665 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 15:48:05,709 : [INFO]  ------------------------- Batch round 1, loss: 0.5624 -------------------------
2023-03-25 15:48:05,710 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:05,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:05,715 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 15:48:08,047 : [INFO]  ------------------------- Batch round 2, loss: 0.5574 -------------------------
2023-03-25 15:48:08,047 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:08,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:08,052 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 15:48:10,368 : [INFO]  ------------------------- Batch round 3, loss: 0.547 -------------------------
2023-03-25 15:48:10,368 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:10,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:10,373 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 15:48:10,373 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 15:48:11,759 : [INFO]  Batch 12: Training set : loss - 0.5444, accuracy - 0.7717, recall - 0.8478, AUC - 0.8615, F1 - 0.7879, precision - 0.7358, training time - -9.0 seconds
2023-03-25 15:48:11,759 : [INFO]  Batch 12: Testing set : loss - 0.5885, accuracy - 0.6863, recall - 0.8333, AUC - 0.8108, F1 - 0.7265, precision - 0.6439
2023-03-25 15:48:11,765 : [INFO]  Batch 13 initialized 
2023-03-25 15:48:12,236 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:12,453 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 15:48:16,395 : [INFO]  ------------------------- Batch round 1, loss: 0.5954 -------------------------
2023-03-25 15:48:16,395 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:16,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:16,401 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 15:48:18,612 : [INFO]  ------------------------- Batch round 2, loss: 0.587 -------------------------
2023-03-25 15:48:18,612 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:18,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:18,617 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 15:48:20,799 : [INFO]  ------------------------- Batch round 3, loss: 0.5799 -------------------------
2023-03-25 15:48:20,799 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:20,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:20,805 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 15:48:20,805 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 15:48:22,166 : [INFO]  Batch 13: Training set : loss - 0.5794, accuracy - 0.7283, recall - 0.913, AUC - 0.8293, F1 - 0.7706, precision - 0.6667, training time - -8.0 seconds
2023-03-25 15:48:22,167 : [INFO]  Batch 13: Testing set : loss - 0.5846, accuracy - 0.6912, recall - 0.8137, AUC - 0.8161, F1 - 0.7249, precision - 0.6535
2023-03-25 15:48:22,172 : [INFO]  Batch 14 initialized 
2023-03-25 15:48:22,602 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:22,847 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 15:48:26,815 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-25 15:48:26,815 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:26,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:26,819 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 15:48:28,967 : [INFO]  ------------------------- Batch round 2, loss: 0.5429 -------------------------
2023-03-25 15:48:28,967 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:28,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:28,973 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 15:48:31,112 : [INFO]  ------------------------- Batch round 3, loss: 0.5387 -------------------------
2023-03-25 15:48:31,112 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:31,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:31,118 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 15:48:31,118 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 15:48:32,538 : [INFO]  Batch 14: Training set : loss - 0.5341, accuracy - 0.788, recall - 0.9239, AUC - 0.8926, F1 - 0.8134, precision - 0.7265, training time - -8.0 seconds
2023-03-25 15:48:32,539 : [INFO]  Batch 14: Testing set : loss - 0.5671, accuracy - 0.7108, recall - 0.8922, AUC - 0.8699, F1 - 0.7552, precision - 0.6547
2023-03-25 15:48:32,544 : [INFO]  Batch 15 initialized 
2023-03-25 15:48:33,007 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:33,242 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 15:48:37,247 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 15:48:37,247 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:37,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:37,251 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 15:48:39,507 : [INFO]  ------------------------- Batch round 2, loss: 0.562 -------------------------
2023-03-25 15:48:39,507 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:39,510 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:39,511 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 15:48:41,822 : [INFO]  ------------------------- Batch round 3, loss: 0.5551 -------------------------
2023-03-25 15:48:41,823 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:41,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:41,828 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 15:48:41,828 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 15:48:43,187 : [INFO]  Batch 15: Training set : loss - 0.555, accuracy - 0.7663, recall - 0.9457, AUC - 0.8761, F1 - 0.8018, precision - 0.696, training time - -9.0 seconds
2023-03-25 15:48:43,187 : [INFO]  Batch 15: Testing set : loss - 0.5818, accuracy - 0.701, recall - 0.8137, AUC - 0.8314, F1 - 0.7313, precision - 0.664
2023-03-25 15:48:43,193 : [INFO]  Batch 16 initialized 
2023-03-25 15:48:43,634 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:43,874 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 15:48:47,728 : [INFO]  ------------------------- Batch round 1, loss: 0.5589 -------------------------
2023-03-25 15:48:47,728 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:47,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:47,954 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 15:48:50,038 : [INFO]  ------------------------- Batch round 2, loss: 0.5525 -------------------------
2023-03-25 15:48:50,038 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:50,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:50,043 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 15:48:52,194 : [INFO]  ------------------------- Batch round 3, loss: 0.5442 -------------------------
2023-03-25 15:48:52,194 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:52,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:52,199 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 15:48:52,199 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 15:48:53,533 : [INFO]  Batch 16: Training set : loss - 0.5407, accuracy - 0.7554, recall - 0.9239, AUC - 0.894, F1 - 0.7907, precision - 0.6911, training time - -8.0 seconds
2023-03-25 15:48:53,533 : [INFO]  Batch 16: Testing set : loss - 0.5433, accuracy - 0.7451, recall - 0.9412, AUC - 0.9195, F1 - 0.7869, precision - 0.6761
2023-03-25 15:48:53,538 : [INFO]  Batch 17 initialized 
2023-03-25 15:48:53,969 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:54,234 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 15:48:58,144 : [INFO]  ------------------------- Batch round 1, loss: 0.5606 -------------------------
2023-03-25 15:48:58,145 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:58,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:58,151 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 15:49:00,295 : [INFO]  ------------------------- Batch round 2, loss: 0.5459 -------------------------
2023-03-25 15:49:00,295 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:00,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:00,300 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 15:49:02,479 : [INFO]  ------------------------- Batch round 3, loss: 0.5426 -------------------------
2023-03-25 15:49:02,479 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:02,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:02,484 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 15:49:02,484 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 15:49:03,795 : [INFO]  Batch 17: Training set : loss - 0.5366, accuracy - 0.7772, recall - 0.9565, AUC - 0.8928, F1 - 0.8111, precision - 0.704, training time - -8.0 seconds
2023-03-25 15:49:03,796 : [INFO]  Batch 17: Testing set : loss - 0.5702, accuracy - 0.7157, recall - 0.8824, AUC - 0.8689, F1 - 0.7563, precision - 0.6618
2023-03-25 15:49:03,802 : [INFO]  Batch 18 initialized 
2023-03-25 15:49:04,239 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:04,507 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 15:49:08,355 : [INFO]  ------------------------- Batch round 1, loss: 0.5827 -------------------------
2023-03-25 15:49:08,355 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:08,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:08,379 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 15:49:10,560 : [INFO]  ------------------------- Batch round 2, loss: 0.5654 -------------------------
2023-03-25 15:49:10,560 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:10,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:10,648 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 15:49:12,764 : [INFO]  ------------------------- Batch round 3, loss: 0.5591 -------------------------
2023-03-25 15:49:12,764 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:12,841 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:12,843 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 15:49:12,843 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 15:49:14,167 : [INFO]  Batch 18: Training set : loss - 0.5664, accuracy - 0.712, recall - 0.9239, AUC - 0.8588, F1 - 0.7623, precision - 0.6489, training time - -8.0 seconds
2023-03-25 15:49:14,167 : [INFO]  Batch 18: Testing set : loss - 0.6005, accuracy - 0.6765, recall - 0.902, AUC - 0.8513, F1 - 0.736, precision - 0.6216
2023-03-25 15:49:14,173 : [INFO]  Batch 19 initialized 
2023-03-25 15:49:14,627 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:14,881 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 15:49:18,913 : [INFO]  ------------------------- Batch round 1, loss: 0.5826 -------------------------
2023-03-25 15:49:18,913 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:18,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:18,918 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 15:49:21,127 : [INFO]  ------------------------- Batch round 2, loss: 0.579 -------------------------
2023-03-25 15:49:21,127 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:21,130 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:21,132 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 15:49:23,361 : [INFO]  ------------------------- Batch round 3, loss: 0.5676 -------------------------
2023-03-25 15:49:23,361 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:23,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:23,366 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 15:49:23,366 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 15:49:24,788 : [INFO]  Batch 19: Training set : loss - 0.5706, accuracy - 0.7337, recall - 0.8587, AUC - 0.8101, F1 - 0.7633, precision - 0.687, training time - -8.0 seconds
2023-03-25 15:49:24,789 : [INFO]  Batch 19: Testing set : loss - 0.5963, accuracy - 0.6618, recall - 0.8431, AUC - 0.8124, F1 - 0.7137, precision - 0.6187
2023-03-25 15:49:24,794 : [INFO]  Batch 20 initialized 
2023-03-25 15:49:25,234 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:25,485 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 15:49:29,448 : [INFO]  ------------------------- Batch round 1, loss: 0.5449 -------------------------
2023-03-25 15:49:29,448 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:29,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:29,631 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 15:49:31,832 : [INFO]  ------------------------- Batch round 2, loss: 0.54 -------------------------
2023-03-25 15:49:31,832 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:31,835 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:31,837 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 15:49:34,359 : [INFO]  ------------------------- Batch round 3, loss: 0.529 -------------------------
2023-03-25 15:49:34,359 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:34,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:34,367 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 15:49:34,367 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 15:49:35,770 : [INFO]  Batch 20: Training set : loss - 0.5359, accuracy - 0.75, recall - 0.9783, AUC - 0.9203, F1 - 0.7965, precision - 0.6716, training time - -9.0 seconds
2023-03-25 15:49:35,770 : [INFO]  Batch 20: Testing set : loss - 0.5764, accuracy - 0.6961, recall - 0.9314, AUC - 0.889, F1 - 0.754, precision - 0.6333
2023-03-25 15:49:35,775 : [INFO]  Batch 21 initialized 
2023-03-25 15:49:36,198 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:36,483 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 15:49:40,454 : [INFO]  ------------------------- Batch round 1, loss: 0.598 -------------------------
2023-03-25 15:49:40,454 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:40,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:40,459 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 15:49:42,706 : [INFO]  ------------------------- Batch round 2, loss: 0.5864 -------------------------
2023-03-25 15:49:42,706 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:42,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:42,711 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 15:49:45,004 : [INFO]  ------------------------- Batch round 3, loss: 0.5781 -------------------------
2023-03-25 15:49:45,004 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:45,007 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:45,009 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 15:49:45,009 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 15:49:46,335 : [INFO]  Batch 21: Training set : loss - 0.5794, accuracy - 0.7337, recall - 0.8913, AUC - 0.8052, F1 - 0.77, precision - 0.6777, training time - -9.0 seconds
2023-03-25 15:49:46,335 : [INFO]  Batch 21: Testing set : loss - 0.5656, accuracy - 0.7157, recall - 0.8922, AUC - 0.8475, F1 - 0.7583, precision - 0.6594
2023-03-25 15:49:46,340 : [INFO]  Batch 22 initialized 
2023-03-25 15:49:46,788 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:47,056 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 15:49:51,125 : [INFO]  ------------------------- Batch round 1, loss: 0.5968 -------------------------
2023-03-25 15:49:51,125 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:51,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:51,130 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 15:49:53,522 : [INFO]  ------------------------- Batch round 2, loss: 0.5826 -------------------------
2023-03-25 15:49:53,522 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:53,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:53,528 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 15:49:55,804 : [INFO]  ------------------------- Batch round 3, loss: 0.5758 -------------------------
2023-03-25 15:49:55,804 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:55,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:55,874 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 15:49:55,874 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 15:49:57,327 : [INFO]  Batch 22: Training set : loss - 0.5578, accuracy - 0.7554, recall - 0.9022, AUC - 0.8466, F1 - 0.7867, precision - 0.6975, training time - -9.0 seconds
2023-03-25 15:49:57,327 : [INFO]  Batch 22: Testing set : loss - 0.6396, accuracy - 0.6275, recall - 0.8529, AUC - 0.78, F1 - 0.696, precision - 0.5878
2023-03-25 15:49:57,332 : [INFO]  Batch 23 initialized 
2023-03-25 15:49:57,764 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:58,013 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 15:50:02,167 : [INFO]  ------------------------- Batch round 1, loss: 0.5726 -------------------------
2023-03-25 15:50:02,167 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:02,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:02,172 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 15:50:04,465 : [INFO]  ------------------------- Batch round 2, loss: 0.5657 -------------------------
2023-03-25 15:50:04,465 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:04,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:04,574 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 15:50:06,894 : [INFO]  ------------------------- Batch round 3, loss: 0.5491 -------------------------
2023-03-25 15:50:06,894 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:06,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:06,900 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 15:50:06,900 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 15:50:08,294 : [INFO]  Batch 23: Training set : loss - 0.5469, accuracy - 0.7717, recall - 0.9348, AUC - 0.88, F1 - 0.8037, precision - 0.7049, training time - -9.0 seconds
2023-03-25 15:50:08,294 : [INFO]  Batch 23: Testing set : loss - 0.5767, accuracy - 0.7206, recall - 0.9118, AUC - 0.8636, F1 - 0.7654, precision - 0.6596
2023-03-25 15:50:08,301 : [INFO]  Batch 24 initialized 
2023-03-25 15:50:08,745 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:09,010 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 15:50:13,104 : [INFO]  ------------------------- Batch round 1, loss: 0.5904 -------------------------
2023-03-25 15:50:13,104 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:13,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:13,109 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 15:50:15,319 : [INFO]  ------------------------- Batch round 2, loss: 0.576 -------------------------
2023-03-25 15:50:15,319 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:15,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:15,454 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 15:50:17,819 : [INFO]  ------------------------- Batch round 3, loss: 0.5679 -------------------------
2023-03-25 15:50:17,819 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:17,822 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:17,824 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 15:50:17,824 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 15:50:19,179 : [INFO]  Batch 24: Training set : loss - 0.5717, accuracy - 0.712, recall - 0.9239, AUC - 0.845, F1 - 0.7623, precision - 0.6489, training time - -9.0 seconds
2023-03-25 15:50:19,180 : [INFO]  Batch 24: Testing set : loss - 0.5927, accuracy - 0.6912, recall - 0.902, AUC - 0.8355, F1 - 0.7449, precision - 0.6345
2023-03-25 15:50:19,184 : [INFO]  Batch 25 initialized 
2023-03-25 15:50:19,614 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:19,893 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 15:50:24,225 : [INFO]  ------------------------- Batch round 1, loss: 0.5628 -------------------------
2023-03-25 15:50:24,225 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:24,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:24,230 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 15:50:26,524 : [INFO]  ------------------------- Batch round 2, loss: 0.5586 -------------------------
2023-03-25 15:50:26,524 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:26,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:26,529 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 15:50:28,870 : [INFO]  ------------------------- Batch round 3, loss: 0.5478 -------------------------
2023-03-25 15:50:28,871 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:28,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:28,875 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 15:50:28,875 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 15:50:30,242 : [INFO]  Batch 25: Training set : loss - 0.5411, accuracy - 0.7609, recall - 0.9022, AUC - 0.8811, F1 - 0.7905, precision - 0.7034, training time - -9.0 seconds
2023-03-25 15:50:30,243 : [INFO]  Batch 25: Testing set : loss - 0.5741, accuracy - 0.75, recall - 0.9216, AUC - 0.8653, F1 - 0.7866, precision - 0.6861
2023-03-25 15:50:30,248 : [INFO]  Batch 26 initialized 
2023-03-25 15:50:30,689 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:30,964 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 15:50:35,088 : [INFO]  ------------------------- Batch round 1, loss: 0.5861 -------------------------
2023-03-25 15:50:35,088 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:35,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:35,093 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 15:50:37,363 : [INFO]  ------------------------- Batch round 2, loss: 0.5776 -------------------------
2023-03-25 15:50:37,363 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:37,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:37,745 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 15:50:40,014 : [INFO]  ------------------------- Batch round 3, loss: 0.5659 -------------------------
2023-03-25 15:50:40,014 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:40,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:40,018 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 15:50:40,018 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 15:50:41,429 : [INFO]  Batch 26: Training set : loss - 0.57, accuracy - 0.7228, recall - 0.913, AUC - 0.8556, F1 - 0.7671, precision - 0.6614, training time - -9.0 seconds
2023-03-25 15:50:41,429 : [INFO]  Batch 26: Testing set : loss - 0.5864, accuracy - 0.6814, recall - 0.9216, AUC - 0.8585, F1 - 0.7431, precision - 0.6225
2023-03-25 15:50:41,436 : [INFO]  Batch 27 initialized 
2023-03-25 15:50:41,887 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:42,147 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 15:50:46,329 : [INFO]  ------------------------- Batch round 1, loss: 0.6306 -------------------------
2023-03-25 15:50:46,329 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:46,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:46,333 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 15:50:48,546 : [INFO]  ------------------------- Batch round 2, loss: 0.6082 -------------------------
2023-03-25 15:50:48,547 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:48,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:48,555 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 15:50:50,786 : [INFO]  ------------------------- Batch round 3, loss: 0.5978 -------------------------
2023-03-25 15:50:50,786 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:50,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:50,791 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 15:50:50,791 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 15:50:52,122 : [INFO]  Batch 27: Training set : loss - 0.6062, accuracy - 0.6793, recall - 0.9239, AUC - 0.8226, F1 - 0.7424, precision - 0.6204, training time - -9.0 seconds
2023-03-25 15:50:52,122 : [INFO]  Batch 27: Testing set : loss - 0.6088, accuracy - 0.652, recall - 0.9314, AUC - 0.8317, F1 - 0.728, precision - 0.5975
2023-03-25 15:50:52,130 : [INFO]  Batch 28 initialized 
2023-03-25 15:50:52,560 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:52,844 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 15:50:56,880 : [INFO]  ------------------------- Batch round 1, loss: 0.576 -------------------------
2023-03-25 15:50:56,880 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:56,883 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:56,884 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 15:50:59,154 : [INFO]  ------------------------- Batch round 2, loss: 0.5576 -------------------------
2023-03-25 15:50:59,154 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:59,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:59,159 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 15:51:01,406 : [INFO]  ------------------------- Batch round 3, loss: 0.5552 -------------------------
2023-03-25 15:51:01,407 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:01,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:01,412 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 15:51:01,412 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 15:51:02,826 : [INFO]  Batch 28: Training set : loss - 0.5413, accuracy - 0.7772, recall - 0.8696, AUC - 0.8677, F1 - 0.796, precision - 0.7339, training time - -9.0 seconds
2023-03-25 15:51:02,826 : [INFO]  Batch 28: Testing set : loss - 0.5756, accuracy - 0.7255, recall - 0.8725, AUC - 0.8396, F1 - 0.7607, precision - 0.6742
2023-03-25 15:51:02,832 : [INFO]  Batch 29 initialized 
2023-03-25 15:51:03,277 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:03,559 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 15:51:07,406 : [INFO]  ------------------------- Batch round 1, loss: 0.5586 -------------------------
2023-03-25 15:51:07,406 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:07,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:07,432 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 15:51:09,901 : [INFO]  ------------------------- Batch round 2, loss: 0.545 -------------------------
2023-03-25 15:51:09,901 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:09,904 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:09,906 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 15:51:12,002 : [INFO]  ------------------------- Batch round 3, loss: 0.5371 -------------------------
2023-03-25 15:51:12,002 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:12,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:12,084 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 15:51:12,084 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 15:51:13,394 : [INFO]  Batch 29: Training set : loss - 0.5325, accuracy - 0.8043, recall - 0.9565, AUC - 0.9151, F1 - 0.8302, precision - 0.7333, training time - -9.0 seconds
2023-03-25 15:51:13,394 : [INFO]  Batch 29: Testing set : loss - 0.567, accuracy - 0.7451, recall - 0.9118, AUC - 0.8587, F1 - 0.7815, precision - 0.6838
2023-03-25 15:51:13,399 : [INFO]  Batch 30 initialized 
2023-03-25 15:51:13,846 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:14,128 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 15:51:18,145 : [INFO]  ------------------------- Batch round 1, loss: 0.584 -------------------------
2023-03-25 15:51:18,145 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:18,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:18,150 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 15:51:20,369 : [INFO]  ------------------------- Batch round 2, loss: 0.5602 -------------------------
2023-03-25 15:51:20,369 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:20,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:20,374 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 15:51:22,623 : [INFO]  ------------------------- Batch round 3, loss: 0.5506 -------------------------
2023-03-25 15:51:22,623 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:22,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:22,628 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 15:51:22,628 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 15:51:24,058 : [INFO]  Batch 30: Training set : loss - 0.5545, accuracy - 0.7935, recall - 0.9022, AUC - 0.8811, F1 - 0.8137, precision - 0.7411, training time - -8.0 seconds
2023-03-25 15:51:24,058 : [INFO]  Batch 30: Testing set : loss - 0.5346, accuracy - 0.7843, recall - 0.9216, AUC - 0.9258, F1 - 0.8103, precision - 0.7231
2023-03-25 15:51:24,063 : [INFO]  Batch 31 initialized 
2023-03-25 15:51:24,505 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:24,809 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 15:51:28,925 : [INFO]  ------------------------- Batch round 1, loss: 0.6034 -------------------------
2023-03-25 15:51:28,925 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:28,928 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:28,929 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 15:51:31,237 : [INFO]  ------------------------- Batch round 2, loss: 0.5825 -------------------------
2023-03-25 15:51:31,237 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:31,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:31,242 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 15:51:33,595 : [INFO]  ------------------------- Batch round 3, loss: 0.5749 -------------------------
2023-03-25 15:51:33,595 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:33,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:33,600 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 15:51:33,600 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 15:51:35,009 : [INFO]  Batch 31: Training set : loss - 0.5674, accuracy - 0.7337, recall - 0.8478, AUC - 0.8437, F1 - 0.761, precision - 0.6903, training time - -9.0 seconds
2023-03-25 15:51:35,009 : [INFO]  Batch 31: Testing set : loss - 0.5809, accuracy - 0.7108, recall - 0.8725, AUC - 0.8574, F1 - 0.7511, precision - 0.6593
2023-03-25 15:51:35,017 : [INFO]  Batch 32 initialized 
2023-03-25 15:51:35,458 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:35,738 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 15:51:39,842 : [INFO]  ------------------------- Batch round 1, loss: 0.5906 -------------------------
2023-03-25 15:51:39,842 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:39,845 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:39,847 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 15:51:42,103 : [INFO]  ------------------------- Batch round 2, loss: 0.5797 -------------------------
2023-03-25 15:51:42,103 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:42,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:42,107 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 15:51:44,425 : [INFO]  ------------------------- Batch round 3, loss: 0.5772 -------------------------
2023-03-25 15:51:44,425 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:44,428 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:44,430 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 15:51:44,430 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 15:51:45,800 : [INFO]  Batch 32: Training set : loss - 0.5708, accuracy - 0.7337, recall - 0.8804, AUC - 0.8534, F1 - 0.7678, precision - 0.6807, training time - -9.0 seconds
2023-03-25 15:51:45,800 : [INFO]  Batch 32: Testing set : loss - 0.5633, accuracy - 0.7696, recall - 0.8824, AUC - 0.8556, F1 - 0.793, precision - 0.72
2023-03-25 15:51:45,808 : [INFO]  Batch 33 initialized 
2023-03-25 15:51:46,259 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:46,537 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 15:51:50,570 : [INFO]  ------------------------- Batch round 1, loss: 0.5914 -------------------------
2023-03-25 15:51:50,570 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:50,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:50,574 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 15:51:52,828 : [INFO]  ------------------------- Batch round 2, loss: 0.5857 -------------------------
2023-03-25 15:51:52,828 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:52,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:52,833 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 15:51:55,056 : [INFO]  ------------------------- Batch round 3, loss: 0.5777 -------------------------
2023-03-25 15:51:55,056 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:55,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:55,061 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 15:51:55,061 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 15:51:56,440 : [INFO]  Batch 33: Training set : loss - 0.5841, accuracy - 0.7283, recall - 0.913, AUC - 0.757, F1 - 0.7706, precision - 0.6667, training time - -9.0 seconds
2023-03-25 15:51:56,440 : [INFO]  Batch 33: Testing set : loss - 0.5846, accuracy - 0.6765, recall - 0.8824, AUC - 0.799, F1 - 0.7317, precision - 0.625
2023-03-25 15:51:56,474 : [INFO]  Batch 34 initialized 
2023-03-25 15:51:56,951 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:57,217 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 15:52:01,205 : [INFO]  ------------------------- Batch round 1, loss: 0.5775 -------------------------
2023-03-25 15:52:01,205 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:01,208 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:01,210 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 15:52:03,369 : [INFO]  ------------------------- Batch round 2, loss: 0.5676 -------------------------
2023-03-25 15:52:03,369 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:03,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:03,374 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 15:52:05,814 : [INFO]  ------------------------- Batch round 3, loss: 0.5578 -------------------------
2023-03-25 15:52:05,814 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:05,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:05,819 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 15:52:05,819 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 15:52:07,162 : [INFO]  Batch 34: Training set : loss - 0.5625, accuracy - 0.7337, recall - 0.9022, AUC - 0.8739, F1 - 0.7721, precision - 0.6748, training time - -9.0 seconds
2023-03-25 15:52:07,162 : [INFO]  Batch 34: Testing set : loss - 0.5358, accuracy - 0.7647, recall - 0.9314, AUC - 0.922, F1 - 0.7983, precision - 0.6985
2023-03-25 15:52:07,169 : [INFO]  Batch 35 initialized 
2023-03-25 15:52:07,586 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:07,896 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 15:52:11,856 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 15:52:11,856 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:12,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:12,073 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 15:52:14,235 : [INFO]  ------------------------- Batch round 2, loss: 0.556 -------------------------
2023-03-25 15:52:14,235 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:14,238 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:14,240 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 15:52:16,458 : [INFO]  ------------------------- Batch round 3, loss: 0.5482 -------------------------
2023-03-25 15:52:16,458 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:16,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:16,463 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 15:52:16,463 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 15:52:17,805 : [INFO]  Batch 35: Training set : loss - 0.5502, accuracy - 0.7283, recall - 0.8804, AUC - 0.896, F1 - 0.7642, precision - 0.675, training time - -9.0 seconds
2023-03-25 15:52:17,805 : [INFO]  Batch 35: Testing set : loss - 0.5802, accuracy - 0.6863, recall - 0.8235, AUC - 0.8294, F1 - 0.7241, precision - 0.6462
2023-03-25 15:52:17,816 : [INFO]  Batch 36 initialized 
2023-03-25 15:52:18,264 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:18,563 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 15:52:22,589 : [INFO]  ------------------------- Batch round 1, loss: 0.5511 -------------------------
2023-03-25 15:52:22,590 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:22,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:22,595 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 15:52:24,842 : [INFO]  ------------------------- Batch round 2, loss: 0.5466 -------------------------
2023-03-25 15:52:24,843 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:24,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:24,851 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 15:52:27,023 : [INFO]  ------------------------- Batch round 3, loss: 0.5419 -------------------------
2023-03-25 15:52:27,023 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:27,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:27,028 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 15:52:27,028 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-25 15:52:28,393 : [INFO]  Batch 36: Training set : loss - 0.538, accuracy - 0.7989, recall - 0.9022, AUC - 0.8915, F1 - 0.8177, precision - 0.7477, training time - -8.0 seconds
2023-03-25 15:52:28,393 : [INFO]  Batch 36: Testing set : loss - 0.5658, accuracy - 0.75, recall - 0.8725, AUC - 0.8478, F1 - 0.7773, precision - 0.7008
2023-03-25 15:52:28,403 : [INFO]  Batch 37 initialized 
2023-03-25 15:52:28,837 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:29,134 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 15:52:33,078 : [INFO]  ------------------------- Batch round 1, loss: 0.559 -------------------------
2023-03-25 15:52:33,078 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:33,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:33,083 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 15:52:35,308 : [INFO]  ------------------------- Batch round 2, loss: 0.5543 -------------------------
2023-03-25 15:52:35,309 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:35,312 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:35,313 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 15:52:37,510 : [INFO]  ------------------------- Batch round 3, loss: 0.5385 -------------------------
2023-03-25 15:52:37,510 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:37,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:37,515 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 15:52:37,515 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-25 15:52:38,936 : [INFO]  Batch 37: Training set : loss - 0.535, accuracy - 0.7772, recall - 0.9239, AUC - 0.9054, F1 - 0.8057, precision - 0.7143, training time - -8.0 seconds
2023-03-25 15:52:38,936 : [INFO]  Batch 37: Testing set : loss - 0.5878, accuracy - 0.701, recall - 0.8922, AUC - 0.8592, F1 - 0.749, precision - 0.6454
2023-03-25 15:52:38,945 : [INFO]  Batch 38 initialized 
2023-03-25 15:52:39,363 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:39,671 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 15:52:43,746 : [INFO]  ------------------------- Batch round 1, loss: 0.5973 -------------------------
2023-03-25 15:52:43,746 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:43,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:43,750 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 15:52:46,174 : [INFO]  ------------------------- Batch round 2, loss: 0.582 -------------------------
2023-03-25 15:52:46,174 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:46,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:46,179 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 15:52:48,441 : [INFO]  ------------------------- Batch round 3, loss: 0.5676 -------------------------
2023-03-25 15:52:48,441 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:48,444 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:48,445 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 15:52:48,445 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-25 15:52:49,829 : [INFO]  Batch 38: Training set : loss - 0.5624, accuracy - 0.7283, recall - 0.9348, AUC - 0.855, F1 - 0.7748, precision - 0.6615, training time - -9.0 seconds
2023-03-25 15:52:49,829 : [INFO]  Batch 38: Testing set : loss - 0.5809, accuracy - 0.6863, recall - 0.8922, AUC - 0.8609, F1 - 0.7398, precision - 0.6319
2023-03-25 15:52:49,862 : [INFO]  Batch 39 initialized 
2023-03-25 15:52:50,337 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:50,616 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 15:52:54,535 : [INFO]  ------------------------- Batch round 1, loss: 0.5377 -------------------------
2023-03-25 15:52:54,535 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:54,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:54,543 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 15:52:56,646 : [INFO]  ------------------------- Batch round 2, loss: 0.5267 -------------------------
2023-03-25 15:52:56,646 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:56,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:56,651 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 15:52:58,828 : [INFO]  ------------------------- Batch round 3, loss: 0.5268 -------------------------
2023-03-25 15:52:58,828 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:58,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:58,833 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 15:52:58,833 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-25 15:53:00,159 : [INFO]  Batch 39: Training set : loss - 0.5225, accuracy - 0.8043, recall - 0.9783, AUC - 0.9026, F1 - 0.8333, precision - 0.7258, training time - -8.0 seconds
2023-03-25 15:53:00,159 : [INFO]  Batch 39: Testing set : loss - 0.5442, accuracy - 0.7598, recall - 0.9412, AUC - 0.9109, F1 - 0.7967, precision - 0.6906
2023-03-25 15:53:00,166 : [INFO]  Batch 40 initialized 
2023-03-25 15:53:00,598 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:00,900 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 15:53:05,050 : [INFO]  ------------------------- Batch round 1, loss: 0.5677 -------------------------
2023-03-25 15:53:05,050 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:05,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:05,055 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 15:53:07,390 : [INFO]  ------------------------- Batch round 2, loss: 0.5523 -------------------------
2023-03-25 15:53:07,390 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:07,472 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:07,473 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 15:53:09,790 : [INFO]  ------------------------- Batch round 3, loss: 0.5448 -------------------------
2023-03-25 15:53:09,790 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:09,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:09,795 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 15:53:09,795 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-25 15:53:11,181 : [INFO]  Batch 40: Training set : loss - 0.5475, accuracy - 0.8098, recall - 0.9891, AUC - 0.9161, F1 - 0.8387, precision - 0.728, training time - -9.0 seconds
2023-03-25 15:53:11,182 : [INFO]  Batch 40: Testing set : loss - 0.5829, accuracy - 0.7108, recall - 0.951, AUC - 0.8841, F1 - 0.7668, precision - 0.6424
2023-03-25 15:53:11,190 : [INFO]  Batch 41 initialized 
2023-03-25 15:53:11,629 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:11,923 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 15:53:15,912 : [INFO]  ------------------------- Batch round 1, loss: 0.5451 -------------------------
2023-03-25 15:53:15,913 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:15,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:15,917 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 15:53:18,164 : [INFO]  ------------------------- Batch round 2, loss: 0.5324 -------------------------
2023-03-25 15:53:18,164 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:18,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:18,169 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 15:53:20,373 : [INFO]  ------------------------- Batch round 3, loss: 0.5268 -------------------------
2023-03-25 15:53:20,373 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:20,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:20,380 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 15:53:20,380 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-25 15:53:21,751 : [INFO]  Batch 41: Training set : loss - 0.5257, accuracy - 0.7717, recall - 0.9239, AUC - 0.9153, F1 - 0.8019, precision - 0.7083, training time - -8.0 seconds
2023-03-25 15:53:21,751 : [INFO]  Batch 41: Testing set : loss - 0.569, accuracy - 0.7108, recall - 0.951, AUC - 0.8985, F1 - 0.7668, precision - 0.6424
2023-03-25 15:53:21,759 : [INFO]  Batch 42 initialized 
2023-03-25 15:53:22,205 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:22,520 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 15:53:26,587 : [INFO]  ------------------------- Batch round 1, loss: 0.6082 -------------------------
2023-03-25 15:53:26,587 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:26,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:26,592 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 15:53:28,793 : [INFO]  ------------------------- Batch round 2, loss: 0.5983 -------------------------
2023-03-25 15:53:28,794 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:28,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:28,799 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 15:53:31,202 : [INFO]  ------------------------- Batch round 3, loss: 0.6004 -------------------------
2023-03-25 15:53:31,202 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:31,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:31,206 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 15:53:31,206 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-25 15:53:32,547 : [INFO]  Batch 42: Training set : loss - 0.5925, accuracy - 0.7011, recall - 0.8804, AUC - 0.8266, F1 - 0.7465, precision - 0.648, training time - -9.0 seconds
2023-03-25 15:53:32,548 : [INFO]  Batch 42: Testing set : loss - 0.5718, accuracy - 0.6716, recall - 0.8333, AUC - 0.8316, F1 - 0.7173, precision - 0.6296
2023-03-25 15:53:32,556 : [INFO]  Batch 43 initialized 
2023-03-25 15:53:32,994 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:33,316 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 15:53:37,231 : [INFO]  ------------------------- Batch round 1, loss: 0.5545 -------------------------
2023-03-25 15:53:37,231 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:37,234 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:37,237 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 15:53:39,414 : [INFO]  ------------------------- Batch round 2, loss: 0.5461 -------------------------
2023-03-25 15:53:39,414 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:39,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:39,419 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 15:53:41,608 : [INFO]  ------------------------- Batch round 3, loss: 0.5369 -------------------------
2023-03-25 15:53:41,608 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:41,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:41,612 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 15:53:41,613 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-25 15:53:42,961 : [INFO]  Batch 43: Training set : loss - 0.537, accuracy - 0.7609, recall - 0.9674, AUC - 0.9224, F1 - 0.8018, precision - 0.6846, training time - -8.0 seconds
2023-03-25 15:53:42,961 : [INFO]  Batch 43: Testing set : loss - 0.5565, accuracy - 0.7304, recall - 0.9608, AUC - 0.9088, F1 - 0.7809, precision - 0.6577
2023-03-25 15:53:42,968 : [INFO]  Batch 44 initialized 
2023-03-25 15:53:43,401 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:43,713 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 15:53:47,846 : [INFO]  ------------------------- Batch round 1, loss: 0.5458 -------------------------
2023-03-25 15:53:47,846 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:47,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:47,851 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 15:53:50,020 : [INFO]  ------------------------- Batch round 2, loss: 0.5393 -------------------------
2023-03-25 15:53:50,020 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:50,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:50,024 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 15:53:52,186 : [INFO]  ------------------------- Batch round 3, loss: 0.5285 -------------------------
2023-03-25 15:53:52,186 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:52,306 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:52,308 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 15:53:52,308 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-25 15:53:53,672 : [INFO]  Batch 44: Training set : loss - 0.525, accuracy - 0.8043, recall - 0.9565, AUC - 0.9217, F1 - 0.8302, precision - 0.7333, training time - -9.0 seconds
2023-03-25 15:53:53,672 : [INFO]  Batch 44: Testing set : loss - 0.5371, accuracy - 0.7794, recall - 0.9216, AUC - 0.8946, F1 - 0.8069, precision - 0.7176
2023-03-25 15:53:53,679 : [INFO]  Batch 45 initialized 
2023-03-25 15:53:54,102 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:54,422 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 15:53:58,498 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 15:53:58,498 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:58,501 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:58,502 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 15:54:00,798 : [INFO]  ------------------------- Batch round 2, loss: 0.5635 -------------------------
2023-03-25 15:54:00,799 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:00,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:00,803 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 15:54:03,047 : [INFO]  ------------------------- Batch round 3, loss: 0.5641 -------------------------
2023-03-25 15:54:03,047 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:03,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:03,141 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 15:54:03,142 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-25 15:54:04,501 : [INFO]  Batch 45: Training set : loss - 0.558, accuracy - 0.7663, recall - 0.8913, AUC - 0.8775, F1 - 0.7923, precision - 0.713, training time - -9.0 seconds
2023-03-25 15:54:04,501 : [INFO]  Batch 45: Testing set : loss - 0.5378, accuracy - 0.7794, recall - 0.951, AUC - 0.921, F1 - 0.8117, precision - 0.708
2023-03-25 15:54:04,508 : [INFO]  Batch 46 initialized 
2023-03-25 15:54:04,934 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:05,253 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 15:54:09,256 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 15:54:09,256 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:09,260 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:09,261 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 15:54:11,464 : [INFO]  ------------------------- Batch round 2, loss: 0.5633 -------------------------
2023-03-25 15:54:11,464 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:11,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:11,469 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 15:54:13,761 : [INFO]  ------------------------- Batch round 3, loss: 0.5516 -------------------------
2023-03-25 15:54:13,761 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:13,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:13,766 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 15:54:13,766 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-25 15:54:15,169 : [INFO]  Batch 46: Training set : loss - 0.5604, accuracy - 0.75, recall - 0.8913, AUC - 0.882, F1 - 0.781, precision - 0.6949, training time - -9.0 seconds
2023-03-25 15:54:15,170 : [INFO]  Batch 46: Testing set : loss - 0.5978, accuracy - 0.6912, recall - 0.902, AUC - 0.8407, F1 - 0.7449, precision - 0.6345
2023-03-25 15:54:15,178 : [INFO]  Batch 47 initialized 
2023-03-25 15:54:15,616 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:15,923 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 15:54:19,847 : [INFO]  ------------------------- Batch round 1, loss: 0.5655 -------------------------
2023-03-25 15:54:19,847 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:19,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:19,852 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 15:54:22,022 : [INFO]  ------------------------- Batch round 2, loss: 0.5644 -------------------------
2023-03-25 15:54:22,022 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:22,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:22,028 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 15:54:24,252 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 15:54:24,252 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:24,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:24,257 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 15:54:24,257 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-25 15:54:25,636 : [INFO]  Batch 47: Training set : loss - 0.567, accuracy - 0.7283, recall - 0.9022, AUC - 0.8879, F1 - 0.7685, precision - 0.6694, training time - -8.0 seconds
2023-03-25 15:54:25,636 : [INFO]  Batch 47: Testing set : loss - 0.6031, accuracy - 0.6569, recall - 0.902, AUC - 0.8584, F1 - 0.7244, precision - 0.6053
2023-03-25 15:54:25,642 : [INFO]  Batch 48 initialized 
2023-03-25 15:54:26,072 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:26,407 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 15:54:30,333 : [INFO]  ------------------------- Batch round 1, loss: 0.5297 -------------------------
2023-03-25 15:54:30,333 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:30,336 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:30,338 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 15:54:32,578 : [INFO]  ------------------------- Batch round 2, loss: 0.5213 -------------------------
2023-03-25 15:54:32,578 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:32,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:32,583 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 15:54:34,755 : [INFO]  ------------------------- Batch round 3, loss: 0.5094 -------------------------
2023-03-25 15:54:34,755 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:34,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:34,760 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 15:54:34,760 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-25 15:54:36,100 : [INFO]  Batch 48: Training set : loss - 0.5128, accuracy - 0.8424, recall - 1.0, AUC - 0.9449, F1 - 0.8638, precision - 0.7603, training time - -8.0 seconds
2023-03-25 15:54:36,101 : [INFO]  Batch 48: Testing set : loss - 0.5697, accuracy - 0.701, recall - 0.9216, AUC - 0.9008, F1 - 0.755, precision - 0.6395
2023-03-25 15:54:36,109 : [INFO]  Batch 49 initialized 
2023-03-25 15:54:36,549 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:36,882 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 15:54:40,902 : [INFO]  ------------------------- Batch round 1, loss: 0.5811 -------------------------
2023-03-25 15:54:40,902 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:40,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:40,908 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 15:54:43,143 : [INFO]  ------------------------- Batch round 2, loss: 0.5676 -------------------------
2023-03-25 15:54:43,143 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:43,146 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:43,148 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 15:54:45,377 : [INFO]  ------------------------- Batch round 3, loss: 0.5616 -------------------------
2023-03-25 15:54:45,377 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:45,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:45,382 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 15:54:45,382 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-25 15:54:46,735 : [INFO]  Batch 49: Training set : loss - 0.567, accuracy - 0.712, recall - 0.913, AUC - 0.8764, F1 - 0.7602, precision - 0.6512, training time - -8.0 seconds
2023-03-25 15:54:46,735 : [INFO]  Batch 49: Testing set : loss - 0.5944, accuracy - 0.6814, recall - 0.8725, AUC - 0.8287, F1 - 0.7325, precision - 0.6312
2023-03-25 15:54:46,746 : [INFO]  Batch 50 initialized 
2023-03-25 15:54:47,183 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:47,524 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 15:54:51,482 : [INFO]  ------------------------- Batch round 1, loss: 0.5577 -------------------------
2023-03-25 15:54:51,482 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:51,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:51,487 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 15:54:53,711 : [INFO]  ------------------------- Batch round 2, loss: 0.5498 -------------------------
2023-03-25 15:54:53,711 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:53,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:53,716 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 15:54:55,865 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-25 15:54:55,865 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:55,868 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:55,870 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 15:54:55,870 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-25 15:54:57,211 : [INFO]  Batch 50: Training set : loss - 0.5335, accuracy - 0.7717, recall - 0.9457, AUC - 0.9163, F1 - 0.8056, precision - 0.7016, training time - -8.0 seconds
2023-03-25 15:54:57,211 : [INFO]  Batch 50: Testing set : loss - 0.578, accuracy - 0.6912, recall - 0.951, AUC - 0.8909, F1 - 0.7549, precision - 0.6258
2023-03-25 15:54:57,218 : [INFO]  Batch 51 initialized 
2023-03-25 15:54:57,650 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:57,983 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 15:55:01,931 : [INFO]  ------------------------- Batch round 1, loss: 0.5775 -------------------------
2023-03-25 15:55:01,931 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:01,934 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:01,936 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 15:55:04,128 : [INFO]  ------------------------- Batch round 2, loss: 0.569 -------------------------
2023-03-25 15:55:04,128 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:04,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:04,133 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 15:55:06,376 : [INFO]  ------------------------- Batch round 3, loss: 0.5686 -------------------------
2023-03-25 15:55:06,376 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:06,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:06,382 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 15:55:06,382 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-25 15:55:07,746 : [INFO]  Batch 51: Training set : loss - 0.5782, accuracy - 0.7065, recall - 0.8804, AUC - 0.8375, F1 - 0.75, precision - 0.6532, training time - -8.0 seconds
2023-03-25 15:55:07,746 : [INFO]  Batch 51: Testing set : loss - 0.6086, accuracy - 0.6422, recall - 0.8627, AUC - 0.7985, F1 - 0.7068, precision - 0.5986
2023-03-25 15:55:07,753 : [INFO]  Batch 52 initialized 
2023-03-25 15:55:08,190 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:08,519 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 15:55:12,478 : [INFO]  ------------------------- Batch round 1, loss: 0.5478 -------------------------
2023-03-25 15:55:12,479 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:12,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:12,483 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 15:55:14,652 : [INFO]  ------------------------- Batch round 2, loss: 0.5401 -------------------------
2023-03-25 15:55:14,652 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:14,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:14,657 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 15:55:16,777 : [INFO]  ------------------------- Batch round 3, loss: 0.5278 -------------------------
2023-03-25 15:55:16,778 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:16,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:16,783 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 15:55:16,783 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-25 15:55:18,099 : [INFO]  Batch 52: Training set : loss - 0.5314, accuracy - 0.7663, recall - 0.9457, AUC - 0.9259, F1 - 0.8018, precision - 0.696, training time - -8.0 seconds
2023-03-25 15:55:18,099 : [INFO]  Batch 52: Testing set : loss - 0.5664, accuracy - 0.7206, recall - 0.902, AUC - 0.8797, F1 - 0.7635, precision - 0.6619
2023-03-25 15:55:18,107 : [INFO]  Batch 53 initialized 
2023-03-25 15:55:18,553 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:18,903 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 15:55:22,955 : [INFO]  ------------------------- Batch round 1, loss: 0.5815 -------------------------
2023-03-25 15:55:22,956 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:22,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:22,960 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 15:55:25,165 : [INFO]  ------------------------- Batch round 2, loss: 0.5755 -------------------------
2023-03-25 15:55:25,165 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:25,168 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:25,170 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 15:55:27,414 : [INFO]  ------------------------- Batch round 3, loss: 0.5686 -------------------------
2023-03-25 15:55:27,415 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:27,417 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:27,419 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 15:55:27,419 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-25 15:55:28,777 : [INFO]  Batch 53: Training set : loss - 0.563, accuracy - 0.7228, recall - 0.9022, AUC - 0.8579, F1 - 0.765, precision - 0.664, training time - -9.0 seconds
2023-03-25 15:55:28,778 : [INFO]  Batch 53: Testing set : loss - 0.6013, accuracy - 0.6814, recall - 0.8627, AUC - 0.8121, F1 - 0.7303, precision - 0.6331
2023-03-25 15:55:28,783 : [INFO]  Batch 54 initialized 
2023-03-25 15:55:29,217 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:29,557 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 15:55:33,579 : [INFO]  ------------------------- Batch round 1, loss: 0.5941 -------------------------
2023-03-25 15:55:33,579 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:33,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:33,584 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 15:55:36,028 : [INFO]  ------------------------- Batch round 2, loss: 0.5791 -------------------------
2023-03-25 15:55:36,028 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:36,031 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:36,033 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 15:55:38,254 : [INFO]  ------------------------- Batch round 3, loss: 0.5723 -------------------------
2023-03-25 15:55:38,254 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:38,257 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:38,259 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 15:55:38,259 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-25 15:55:39,627 : [INFO]  Batch 54: Training set : loss - 0.573, accuracy - 0.712, recall - 0.8587, AUC - 0.8365, F1 - 0.7488, precision - 0.6639, training time - -9.0 seconds
2023-03-25 15:55:39,627 : [INFO]  Batch 54: Testing set : loss - 0.5663, accuracy - 0.7402, recall - 0.8725, AUC - 0.8737, F1 - 0.7706, precision - 0.6899
2023-03-25 15:55:39,653 : [INFO]  Batch 55 initialized 
2023-03-25 15:55:40,200 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:40,507 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 15:55:44,672 : [INFO]  ------------------------- Batch round 1, loss: 0.5415 -------------------------
2023-03-25 15:55:44,672 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:44,675 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:44,677 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 15:55:47,156 : [INFO]  ------------------------- Batch round 2, loss: 0.5271 -------------------------
2023-03-25 15:55:47,156 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:47,159 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:47,160 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 15:55:49,286 : [INFO]  ------------------------- Batch round 3, loss: 0.5208 -------------------------
2023-03-25 15:55:49,286 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:49,289 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:49,292 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 15:55:49,292 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-25 15:55:50,669 : [INFO]  Batch 55: Training set : loss - 0.5228, accuracy - 0.8152, recall - 0.9674, AUC - 0.9174, F1 - 0.8396, precision - 0.7417, training time - -9.0 seconds
2023-03-25 15:55:50,670 : [INFO]  Batch 55: Testing set : loss - 0.5911, accuracy - 0.701, recall - 0.8922, AUC - 0.8414, F1 - 0.749, precision - 0.6454
2023-03-25 15:55:50,675 : [INFO]  Batch 56 initialized 
2023-03-25 15:55:51,126 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:51,451 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 15:55:55,348 : [INFO]  ------------------------- Batch round 1, loss: 0.5738 -------------------------
2023-03-25 15:55:55,348 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:55,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:55,353 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 15:55:57,542 : [INFO]  ------------------------- Batch round 2, loss: 0.5632 -------------------------
2023-03-25 15:55:57,543 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:57,546 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:57,548 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 15:55:59,704 : [INFO]  ------------------------- Batch round 3, loss: 0.5535 -------------------------
2023-03-25 15:55:59,704 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:59,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:59,709 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 15:55:59,709 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-25 15:56:01,054 : [INFO]  Batch 56: Training set : loss - 0.5584, accuracy - 0.7554, recall - 0.9457, AUC - 0.8645, F1 - 0.7945, precision - 0.685, training time - -8.0 seconds
2023-03-25 15:56:01,054 : [INFO]  Batch 56: Testing set : loss - 0.549, accuracy - 0.7157, recall - 0.8824, AUC - 0.8846, F1 - 0.7563, precision - 0.6618
2023-03-25 15:56:01,060 : [INFO]  Batch 57 initialized 
2023-03-25 15:56:01,498 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:01,847 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 15:56:05,768 : [INFO]  ------------------------- Batch round 1, loss: 0.5398 -------------------------
2023-03-25 15:56:05,768 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:05,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:05,780 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 15:56:07,936 : [INFO]  ------------------------- Batch round 2, loss: 0.5307 -------------------------
2023-03-25 15:56:07,936 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:07,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:07,942 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 15:56:10,157 : [INFO]  ------------------------- Batch round 3, loss: 0.5274 -------------------------
2023-03-25 15:56:10,157 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:10,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:10,193 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 15:56:10,193 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-25 15:56:11,567 : [INFO]  Batch 57: Training set : loss - 0.5172, accuracy - 0.8043, recall - 0.9348, AUC - 0.933, F1 - 0.8269, precision - 0.7414, training time - -8.0 seconds
2023-03-25 15:56:11,568 : [INFO]  Batch 57: Testing set : loss - 0.5714, accuracy - 0.7206, recall - 0.8529, AUC - 0.8637, F1 - 0.7532, precision - 0.6744
2023-03-25 15:56:11,576 : [INFO]  Batch 58 initialized 
2023-03-25 15:56:12,007 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:12,354 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 15:56:16,307 : [INFO]  ------------------------- Batch round 1, loss: 0.5502 -------------------------
2023-03-25 15:56:16,307 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:16,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:16,312 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 15:56:18,429 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-25 15:56:18,429 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:18,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:18,434 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 15:56:20,558 : [INFO]  ------------------------- Batch round 3, loss: 0.5339 -------------------------
2023-03-25 15:56:20,558 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:20,562 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:20,563 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 15:56:20,563 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-25 15:56:21,892 : [INFO]  Batch 58: Training set : loss - 0.5332, accuracy - 0.7663, recall - 0.9348, AUC - 0.8845, F1 - 0.8, precision - 0.6992, training time - -8.0 seconds
2023-03-25 15:56:21,892 : [INFO]  Batch 58: Testing set : loss - 0.5627, accuracy - 0.7108, recall - 0.9118, AUC - 0.8872, F1 - 0.7592, precision - 0.6503
2023-03-25 15:56:21,903 : [INFO]  Batch 59 initialized 
2023-03-25 15:56:22,334 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:22,678 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 15:56:26,660 : [INFO]  ------------------------- Batch round 1, loss: 0.5657 -------------------------
2023-03-25 15:56:26,660 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:26,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:26,665 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 15:56:28,803 : [INFO]  ------------------------- Batch round 2, loss: 0.5576 -------------------------
2023-03-25 15:56:28,803 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:28,806 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:28,808 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 15:56:30,936 : [INFO]  ------------------------- Batch round 3, loss: 0.5479 -------------------------
2023-03-25 15:56:30,936 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:30,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:30,941 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 15:56:30,941 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-25 15:56:32,322 : [INFO]  Batch 59: Training set : loss - 0.5484, accuracy - 0.7554, recall - 0.913, AUC - 0.8797, F1 - 0.7887, precision - 0.6942, training time - -8.0 seconds
2023-03-25 15:56:32,322 : [INFO]  Batch 59: Testing set : loss - 0.5532, accuracy - 0.7353, recall - 0.9118, AUC - 0.8917, F1 - 0.775, precision - 0.6739
2023-03-25 15:56:32,330 : [INFO]  Batch 60 initialized 
2023-03-25 15:56:32,784 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:33,121 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 15:56:37,073 : [INFO]  ------------------------- Batch round 1, loss: 0.568 -------------------------
2023-03-25 15:56:37,073 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:37,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:37,078 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 15:56:39,288 : [INFO]  ------------------------- Batch round 2, loss: 0.5522 -------------------------
2023-03-25 15:56:39,288 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:39,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:39,292 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 15:56:41,468 : [INFO]  ------------------------- Batch round 3, loss: 0.5379 -------------------------
2023-03-25 15:56:41,468 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:41,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:41,474 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 15:56:41,474 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-25 15:56:42,821 : [INFO]  Batch 60: Training set : loss - 0.5297, accuracy - 0.788, recall - 0.9457, AUC - 0.9119, F1 - 0.8169, precision - 0.719, training time - -8.0 seconds
2023-03-25 15:56:42,821 : [INFO]  Batch 60: Testing set : loss - 0.5714, accuracy - 0.7255, recall - 0.8725, AUC - 0.8524, F1 - 0.7607, precision - 0.6742
2023-03-25 15:56:42,829 : [INFO]  Batch 61 initialized 
2023-03-25 15:56:43,258 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:43,612 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 15:56:47,615 : [INFO]  ------------------------- Batch round 1, loss: 0.618 -------------------------
2023-03-25 15:56:47,615 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:47,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:47,620 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 15:56:49,883 : [INFO]  ------------------------- Batch round 2, loss: 0.6093 -------------------------
2023-03-25 15:56:49,883 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:49,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:49,887 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 15:56:52,114 : [INFO]  ------------------------- Batch round 3, loss: 0.5963 -------------------------
2023-03-25 15:56:52,114 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:52,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:52,119 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 15:56:52,119 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-25 15:56:53,530 : [INFO]  Batch 61: Training set : loss - 0.6075, accuracy - 0.6739, recall - 0.8913, AUC - 0.8011, F1 - 0.7321, precision - 0.6212, training time - -9.0 seconds
2023-03-25 15:56:53,530 : [INFO]  Batch 61: Testing set : loss - 0.5824, accuracy - 0.6863, recall - 0.902, AUC - 0.8522, F1 - 0.7419, precision - 0.6301
2023-03-25 15:56:53,536 : [INFO]  Batch 62 initialized 
2023-03-25 15:56:53,961 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:54,311 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 15:56:58,396 : [INFO]  ------------------------- Batch round 1, loss: 0.5646 -------------------------
2023-03-25 15:56:58,396 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:58,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:58,401 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 15:57:00,645 : [INFO]  ------------------------- Batch round 2, loss: 0.5575 -------------------------
2023-03-25 15:57:00,645 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:00,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:00,650 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 15:57:02,928 : [INFO]  ------------------------- Batch round 3, loss: 0.5439 -------------------------
2023-03-25 15:57:02,928 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:02,931 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:02,933 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 15:57:02,933 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-25 15:57:04,317 : [INFO]  Batch 62: Training set : loss - 0.544, accuracy - 0.7609, recall - 0.913, AUC - 0.8777, F1 - 0.7925, precision - 0.7, training time - -9.0 seconds
2023-03-25 15:57:04,317 : [INFO]  Batch 62: Testing set : loss - 0.5996, accuracy - 0.6765, recall - 0.8333, AUC - 0.8093, F1 - 0.7203, precision - 0.6343
2023-03-25 15:57:04,323 : [INFO]  Batch 63 initialized 
2023-03-25 15:57:04,775 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:05,111 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 15:57:09,072 : [INFO]  ------------------------- Batch round 1, loss: 0.5704 -------------------------
2023-03-25 15:57:09,072 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:09,075 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:09,077 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 15:57:11,292 : [INFO]  ------------------------- Batch round 2, loss: 0.5557 -------------------------
2023-03-25 15:57:11,292 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:11,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:11,297 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 15:57:13,464 : [INFO]  ------------------------- Batch round 3, loss: 0.5443 -------------------------
2023-03-25 15:57:13,464 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:13,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:13,468 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 15:57:13,469 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-25 15:57:14,855 : [INFO]  Batch 63: Training set : loss - 0.5453, accuracy - 0.7609, recall - 0.9239, AUC - 0.8862, F1 - 0.7944, precision - 0.6967, training time - -8.0 seconds
2023-03-25 15:57:14,855 : [INFO]  Batch 63: Testing set : loss - 0.6058, accuracy - 0.6618, recall - 0.8431, AUC - 0.7845, F1 - 0.7137, precision - 0.6187
2023-03-25 15:57:14,865 : [INFO]  Batch 64 initialized 
2023-03-25 15:57:15,301 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:15,650 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 15:57:19,616 : [INFO]  ------------------------- Batch round 1, loss: 0.5591 -------------------------
2023-03-25 15:57:19,616 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:19,619 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:19,621 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 15:57:21,776 : [INFO]  ------------------------- Batch round 2, loss: 0.5399 -------------------------
2023-03-25 15:57:21,776 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:21,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:21,781 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 15:57:23,957 : [INFO]  ------------------------- Batch round 3, loss: 0.5396 -------------------------
2023-03-25 15:57:23,957 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:23,961 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:23,963 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 15:57:23,963 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-25 15:57:25,306 : [INFO]  Batch 64: Training set : loss - 0.5366, accuracy - 0.7826, recall - 0.9348, AUC - 0.8898, F1 - 0.8113, precision - 0.7167, training time - -8.0 seconds
2023-03-25 15:57:25,307 : [INFO]  Batch 64: Testing set : loss - 0.561, accuracy - 0.7157, recall - 0.902, AUC - 0.8751, F1 - 0.7603, precision - 0.6571
2023-03-25 15:57:25,318 : [INFO]  Batch 65 initialized 
2023-03-25 15:57:25,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:26,114 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 15:57:30,131 : [INFO]  ------------------------- Batch round 1, loss: 0.5787 -------------------------
2023-03-25 15:57:30,131 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:30,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:30,136 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 15:57:32,365 : [INFO]  ------------------------- Batch round 2, loss: 0.5607 -------------------------
2023-03-25 15:57:32,365 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:32,368 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:32,370 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 15:57:34,567 : [INFO]  ------------------------- Batch round 3, loss: 0.5574 -------------------------
2023-03-25 15:57:34,568 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:34,571 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:34,572 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 15:57:34,572 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-25 15:57:35,945 : [INFO]  Batch 65: Training set : loss - 0.5559, accuracy - 0.7011, recall - 0.9457, AUC - 0.8907, F1 - 0.7598, precision - 0.635, training time - -8.0 seconds
2023-03-25 15:57:35,945 : [INFO]  Batch 65: Testing set : loss - 0.5699, accuracy - 0.7059, recall - 0.9314, AUC - 0.892, F1 - 0.76, precision - 0.6419
2023-03-25 15:57:35,951 : [INFO]  Batch 66 initialized 
2023-03-25 15:57:36,407 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:36,749 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 15:57:40,659 : [INFO]  ------------------------- Batch round 1, loss: 0.5545 -------------------------
2023-03-25 15:57:40,659 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:40,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:40,664 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 15:57:42,819 : [INFO]  ------------------------- Batch round 2, loss: 0.5535 -------------------------
2023-03-25 15:57:42,819 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:42,822 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:42,824 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 15:57:44,956 : [INFO]  ------------------------- Batch round 3, loss: 0.5493 -------------------------
2023-03-25 15:57:44,956 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:44,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:44,961 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 15:57:44,961 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-25 15:57:46,306 : [INFO]  Batch 66: Training set : loss - 0.544, accuracy - 0.75, recall - 0.9457, AUC - 0.9026, F1 - 0.7909, precision - 0.6797, training time - -8.0 seconds
2023-03-25 15:57:46,307 : [INFO]  Batch 66: Testing set : loss - 0.5503, accuracy - 0.7647, recall - 0.9412, AUC - 0.9035, F1 - 0.8, precision - 0.6957
2023-03-25 15:57:46,314 : [INFO]  Batch 67 initialized 
2023-03-25 15:57:46,747 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:47,112 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 15:57:51,003 : [INFO]  ------------------------- Batch round 1, loss: 0.5728 -------------------------
2023-03-25 15:57:51,003 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:51,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:51,100 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 15:57:53,283 : [INFO]  ------------------------- Batch round 2, loss: 0.5567 -------------------------
2023-03-25 15:57:53,283 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:53,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:53,337 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 15:57:55,457 : [INFO]  ------------------------- Batch round 3, loss: 0.55 -------------------------
2023-03-25 15:57:55,457 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:55,556 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:55,557 : [INFO]  Batch number 67 model fetched from the server
2023-03-25 15:57:55,558 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-25 15:57:56,877 : [INFO]  Batch 67: Training set : loss - 0.5563, accuracy - 0.7174, recall - 0.9457, AUC - 0.8744, F1 - 0.7699, precision - 0.6493, training time - -8.0 seconds
2023-03-25 15:57:56,877 : [INFO]  Batch 67: Testing set : loss - 0.5527, accuracy - 0.7549, recall - 0.9314, AUC - 0.8701, F1 - 0.7917, precision - 0.6884
2023-03-25 15:57:56,892 : [INFO]  Batch 68 initialized 
2023-03-25 15:57:57,335 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:57,694 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-25 15:58:01,714 : [INFO]  ------------------------- Batch round 1, loss: 0.547 -------------------------
2023-03-25 15:58:01,714 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:01,865 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:01,867 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-25 15:58:04,094 : [INFO]  ------------------------- Batch round 2, loss: 0.536 -------------------------
2023-03-25 15:58:04,094 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:04,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:04,099 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-25 15:58:06,297 : [INFO]  ------------------------- Batch round 3, loss: 0.5352 -------------------------
2023-03-25 15:58:06,297 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:06,300 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:06,302 : [INFO]  Batch number 68 model fetched from the server
2023-03-25 15:58:06,302 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-25 15:58:07,713 : [INFO]  Batch 68: Training set : loss - 0.5347, accuracy - 0.7772, recall - 0.9457, AUC - 0.8983, F1 - 0.8093, precision - 0.7073, training time - -9.0 seconds
2023-03-25 15:58:07,713 : [INFO]  Batch 68: Testing set : loss - 0.5591, accuracy - 0.7304, recall - 0.8922, AUC - 0.8849, F1 - 0.7679, precision - 0.6741
2023-03-25 15:58:07,719 : [INFO]  Batch 69 initialized 
2023-03-25 15:58:08,173 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:08,516 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-25 15:58:12,487 : [INFO]  ------------------------- Batch round 1, loss: 0.5637 -------------------------
2023-03-25 15:58:12,487 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:12,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:12,492 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-25 15:58:14,657 : [INFO]  ------------------------- Batch round 2, loss: 0.5593 -------------------------
2023-03-25 15:58:14,657 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:14,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:14,662 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-25 15:58:16,877 : [INFO]  ------------------------- Batch round 3, loss: 0.5481 -------------------------
2023-03-25 15:58:16,877 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:16,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:16,882 : [INFO]  Batch number 69 model fetched from the server
2023-03-25 15:58:16,883 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-25 15:58:18,252 : [INFO]  Batch 69: Training set : loss - 0.555, accuracy - 0.7554, recall - 0.9565, AUC - 0.8984, F1 - 0.7964, precision - 0.6822, training time - -8.0 seconds
2023-03-25 15:58:18,252 : [INFO]  Batch 69: Testing set : loss - 0.5908, accuracy - 0.6912, recall - 0.9216, AUC - 0.8558, F1 - 0.749, precision - 0.6309
2023-03-25 15:58:18,260 : [INFO]  Batch 70 initialized 
2023-03-25 15:58:18,702 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:19,064 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-25 15:58:22,997 : [INFO]  ------------------------- Batch round 1, loss: 0.5432 -------------------------
2023-03-25 15:58:22,997 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:23,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:23,002 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-25 15:58:25,191 : [INFO]  ------------------------- Batch round 2, loss: 0.5333 -------------------------
2023-03-25 15:58:25,192 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:25,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:25,196 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-25 15:58:27,346 : [INFO]  ------------------------- Batch round 3, loss: 0.5235 -------------------------
2023-03-25 15:58:27,346 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:27,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:27,566 : [INFO]  Batch number 70 model fetched from the server
2023-03-25 15:58:27,566 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-25 15:58:28,905 : [INFO]  Batch 70: Training set : loss - 0.5205, accuracy - 0.8261, recall - 0.9783, AUC - 0.9205, F1 - 0.8491, precision - 0.75, training time - -9.0 seconds
2023-03-25 15:58:28,905 : [INFO]  Batch 70: Testing set : loss - 0.5801, accuracy - 0.7255, recall - 0.9314, AUC - 0.8653, F1 - 0.7724, precision - 0.6597
2023-03-25 15:58:28,913 : [INFO]  Batch 71 initialized 
2023-03-25 15:58:29,351 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:29,720 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-25 15:58:33,688 : [INFO]  ------------------------- Batch round 1, loss: 0.5458 -------------------------
2023-03-25 15:58:33,688 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:33,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:33,693 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-25 15:58:35,822 : [INFO]  ------------------------- Batch round 2, loss: 0.5382 -------------------------
2023-03-25 15:58:35,822 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:35,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:35,961 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-25 15:58:38,158 : [INFO]  ------------------------- Batch round 3, loss: 0.5309 -------------------------
2023-03-25 15:58:38,158 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:38,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:38,164 : [INFO]  Batch number 71 model fetched from the server
2023-03-25 15:58:38,164 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-25 15:58:39,532 : [INFO]  Batch 71: Training set : loss - 0.5317, accuracy - 0.7717, recall - 0.8696, AUC - 0.8826, F1 - 0.7921, precision - 0.7273, training time - -8.0 seconds
2023-03-25 15:58:39,533 : [INFO]  Batch 71: Testing set : loss - 0.6157, accuracy - 0.6324, recall - 0.7745, AUC - 0.7701, F1 - 0.6781, precision - 0.6031
2023-03-25 15:58:39,544 : [INFO]  Batch 72 initialized 
2023-03-25 15:58:39,985 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:40,342 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-25 15:58:44,388 : [INFO]  ------------------------- Batch round 1, loss: 0.5605 -------------------------
2023-03-25 15:58:44,389 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:44,391 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:44,393 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-25 15:58:46,630 : [INFO]  ------------------------- Batch round 2, loss: 0.5413 -------------------------
2023-03-25 15:58:46,630 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:46,633 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:46,634 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-25 15:58:48,848 : [INFO]  ------------------------- Batch round 3, loss: 0.5329 -------------------------
2023-03-25 15:58:48,849 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:48,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:48,853 : [INFO]  Batch number 72 model fetched from the server
2023-03-25 15:58:48,853 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-25 15:58:50,215 : [INFO]  Batch 72: Training set : loss - 0.5308, accuracy - 0.7772, recall - 0.9348, AUC - 0.889, F1 - 0.8075, precision - 0.7107, training time - -9.0 seconds
2023-03-25 15:58:50,215 : [INFO]  Batch 72: Testing set : loss - 0.593, accuracy - 0.6667, recall - 0.8431, AUC - 0.8106, F1 - 0.7167, precision - 0.6232
2023-03-25 15:58:50,224 : [INFO]  Batch 73 initialized 
2023-03-25 15:58:50,716 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:51,065 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-25 15:58:54,976 : [INFO]  ------------------------- Batch round 1, loss: 0.5693 -------------------------
2023-03-25 15:58:54,976 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:54,979 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:54,981 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-25 15:58:57,215 : [INFO]  ------------------------- Batch round 2, loss: 0.5577 -------------------------
2023-03-25 15:58:57,216 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:57,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:57,220 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-25 15:58:59,419 : [INFO]  ------------------------- Batch round 3, loss: 0.5556 -------------------------
2023-03-25 15:58:59,419 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:59,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:59,424 : [INFO]  Batch number 73 model fetched from the server
2023-03-25 15:58:59,424 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-25 15:59:00,747 : [INFO]  Batch 73: Training set : loss - 0.5439, accuracy - 0.7935, recall - 0.9457, AUC - 0.8983, F1 - 0.8208, precision - 0.725, training time - -8.0 seconds
2023-03-25 15:59:00,748 : [INFO]  Batch 73: Testing set : loss - 0.5936, accuracy - 0.6618, recall - 0.8824, AUC - 0.8339, F1 - 0.7229, precision - 0.6122
2023-03-25 15:59:00,754 : [INFO]  Batch 74 initialized 
2023-03-25 15:59:01,214 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:01,578 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-25 15:59:05,476 : [INFO]  ------------------------- Batch round 1, loss: 0.5476 -------------------------
2023-03-25 15:59:05,476 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:05,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:05,481 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-25 15:59:07,660 : [INFO]  ------------------------- Batch round 2, loss: 0.5341 -------------------------
2023-03-25 15:59:07,660 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:07,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:07,664 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-25 15:59:09,825 : [INFO]  ------------------------- Batch round 3, loss: 0.5295 -------------------------
2023-03-25 15:59:09,826 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:09,829 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:09,830 : [INFO]  Batch number 74 model fetched from the server
2023-03-25 15:59:09,830 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-25 15:59:11,212 : [INFO]  Batch 74: Training set : loss - 0.5236, accuracy - 0.837, recall - 0.913, AUC - 0.8795, F1 - 0.8485, precision - 0.7925, training time - -8.0 seconds
2023-03-25 15:59:11,212 : [INFO]  Batch 74: Testing set : loss - 0.5484, accuracy - 0.7255, recall - 0.9118, AUC - 0.8911, F1 - 0.7686, precision - 0.6643
2023-03-25 15:59:11,218 : [INFO]  Batch 75 initialized 
2023-03-25 15:59:11,657 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:12,026 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-25 15:59:15,964 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-25 15:59:15,964 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:15,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:15,969 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-25 15:59:18,179 : [INFO]  ------------------------- Batch round 2, loss: 0.5401 -------------------------
2023-03-25 15:59:18,179 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:18,186 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:18,188 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-25 15:59:20,363 : [INFO]  ------------------------- Batch round 3, loss: 0.5345 -------------------------
2023-03-25 15:59:20,363 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:20,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:20,656 : [INFO]  Batch number 75 model fetched from the server
2023-03-25 15:59:20,657 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-25 15:59:21,963 : [INFO]  Batch 75: Training set : loss - 0.5311, accuracy - 0.7989, recall - 0.9783, AUC - 0.9208, F1 - 0.8295, precision - 0.72, training time - -9.0 seconds
2023-03-25 15:59:21,963 : [INFO]  Batch 75: Testing set : loss - 0.5593, accuracy - 0.7353, recall - 0.9118, AUC - 0.8896, F1 - 0.775, precision - 0.6739
2023-03-25 15:59:21,972 : [INFO]  Batch 76 initialized 
2023-03-25 15:59:22,405 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:22,785 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-25 15:59:26,800 : [INFO]  ------------------------- Batch round 1, loss: 0.5467 -------------------------
2023-03-25 15:59:26,800 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:26,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:26,805 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-25 15:59:29,024 : [INFO]  ------------------------- Batch round 2, loss: 0.5329 -------------------------
2023-03-25 15:59:29,024 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:29,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:29,029 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-25 15:59:31,227 : [INFO]  ------------------------- Batch round 3, loss: 0.5284 -------------------------
2023-03-25 15:59:31,228 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:31,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:31,232 : [INFO]  Batch number 76 model fetched from the server
2023-03-25 15:59:31,232 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-25 15:59:32,569 : [INFO]  Batch 76: Training set : loss - 0.531, accuracy - 0.7826, recall - 0.9022, AUC - 0.878, F1 - 0.8058, precision - 0.7281, training time - -8.0 seconds
2023-03-25 15:59:32,569 : [INFO]  Batch 76: Testing set : loss - 0.5714, accuracy - 0.7157, recall - 0.8627, AUC - 0.8658, F1 - 0.7521, precision - 0.6667
2023-03-25 15:59:32,575 : [INFO]  Batch 77 initialized 
2023-03-25 15:59:33,003 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:33,400 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-25 15:59:37,390 : [INFO]  ------------------------- Batch round 1, loss: 0.5549 -------------------------
2023-03-25 15:59:37,390 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:37,393 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:37,396 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-25 15:59:39,512 : [INFO]  ------------------------- Batch round 2, loss: 0.5381 -------------------------
2023-03-25 15:59:39,512 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:39,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:39,517 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-25 15:59:41,598 : [INFO]  ------------------------- Batch round 3, loss: 0.5329 -------------------------
2023-03-25 15:59:41,598 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:41,858 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:41,860 : [INFO]  Batch number 77 model fetched from the server
2023-03-25 15:59:41,860 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-25 15:59:43,184 : [INFO]  Batch 77: Training set : loss - 0.5294, accuracy - 0.8043, recall - 0.9565, AUC - 0.8991, F1 - 0.8302, precision - 0.7333, training time - -8.0 seconds
2023-03-25 15:59:43,185 : [INFO]  Batch 77: Testing set : loss - 0.5566, accuracy - 0.7647, recall - 0.9118, AUC - 0.8449, F1 - 0.7949, precision - 0.7045
2023-03-25 15:59:43,196 : [INFO]  Batch 78 initialized 
2023-03-25 15:59:43,627 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:44,015 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-25 15:59:48,020 : [INFO]  ------------------------- Batch round 1, loss: 0.5838 -------------------------
2023-03-25 15:59:48,021 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:48,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:48,026 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-25 15:59:50,175 : [INFO]  ------------------------- Batch round 2, loss: 0.5502 -------------------------
2023-03-25 15:59:50,175 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:50,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:50,181 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-25 15:59:52,330 : [INFO]  ------------------------- Batch round 3, loss: 0.5516 -------------------------
2023-03-25 15:59:52,330 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:52,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:52,336 : [INFO]  Batch number 78 model fetched from the server
2023-03-25 15:59:52,336 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-25 15:59:53,679 : [INFO]  Batch 78: Training set : loss - 0.5489, accuracy - 0.7609, recall - 0.9239, AUC - 0.8762, F1 - 0.7944, precision - 0.6967, training time - -8.0 seconds
2023-03-25 15:59:53,679 : [INFO]  Batch 78: Testing set : loss - 0.6081, accuracy - 0.6667, recall - 0.8824, AUC - 0.8093, F1 - 0.7258, precision - 0.6164
2023-03-25 15:59:53,686 : [INFO]  Batch 79 initialized 
2023-03-25 15:59:54,110 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:54,515 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-25 15:59:58,435 : [INFO]  ------------------------- Batch round 1, loss: 0.5925 -------------------------
2023-03-25 15:59:58,435 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:58,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:58,466 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-25 16:00:00,867 : [INFO]  ------------------------- Batch round 2, loss: 0.5704 -------------------------
2023-03-25 16:00:00,867 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:00,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:00,872 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-25 16:00:03,021 : [INFO]  ------------------------- Batch round 3, loss: 0.5635 -------------------------
2023-03-25 16:00:03,021 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:03,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:03,072 : [INFO]  Batch number 79 model fetched from the server
2023-03-25 16:00:03,072 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-25 16:00:04,430 : [INFO]  Batch 79: Training set : loss - 0.5599, accuracy - 0.7609, recall - 0.9348, AUC - 0.8683, F1 - 0.7963, precision - 0.6935, training time - -9.0 seconds
2023-03-25 16:00:04,430 : [INFO]  Batch 79: Testing set : loss - 0.5683, accuracy - 0.7059, recall - 0.9216, AUC - 0.8711, F1 - 0.7581, precision - 0.6438
2023-03-25 16:00:04,442 : [INFO]  Batch 80 initialized 
2023-03-25 16:00:04,868 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:05,247 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-25 16:00:09,509 : [INFO]  ------------------------- Batch round 1, loss: 0.574 -------------------------
2023-03-25 16:00:09,509 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:09,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:09,514 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-25 16:00:11,806 : [INFO]  ------------------------- Batch round 2, loss: 0.5583 -------------------------
2023-03-25 16:00:11,807 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:11,810 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:11,811 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-25 16:00:14,057 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 16:00:14,057 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:14,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:14,107 : [INFO]  Batch number 80 model fetched from the server
2023-03-25 16:00:14,108 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-25 16:00:15,523 : [INFO]  Batch 80: Training set : loss - 0.5473, accuracy - 0.7609, recall - 0.8696, AUC - 0.8616, F1 - 0.7843, precision - 0.7143, training time - -9.0 seconds
2023-03-25 16:00:15,523 : [INFO]  Batch 80: Testing set : loss - 0.5708, accuracy - 0.7206, recall - 0.8922, AUC - 0.8662, F1 - 0.7615, precision - 0.6642
2023-03-25 16:00:15,532 : [INFO]  Batch 81 initialized 
2023-03-25 16:00:15,977 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:16,343 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-25 16:00:20,353 : [INFO]  ------------------------- Batch round 1, loss: 0.5638 -------------------------
2023-03-25 16:00:20,353 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:20,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:20,359 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-25 16:00:22,512 : [INFO]  ------------------------- Batch round 2, loss: 0.5518 -------------------------
2023-03-25 16:00:22,512 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:22,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:22,961 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-25 16:00:25,204 : [INFO]  ------------------------- Batch round 3, loss: 0.5502 -------------------------
2023-03-25 16:00:25,204 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:25,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:25,209 : [INFO]  Batch number 81 model fetched from the server
2023-03-25 16:00:25,209 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-25 16:00:26,566 : [INFO]  Batch 81: Training set : loss - 0.5412, accuracy - 0.7663, recall - 0.913, AUC - 0.8821, F1 - 0.7962, precision - 0.7059, training time - -9.0 seconds
2023-03-25 16:00:26,566 : [INFO]  Batch 81: Testing set : loss - 0.5762, accuracy - 0.7108, recall - 0.8235, AUC - 0.8403, F1 - 0.7401, precision - 0.672
2023-03-25 16:00:26,572 : [INFO]  Batch 82 initialized 
2023-03-25 16:00:27,018 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:27,401 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-25 16:00:31,671 : [INFO]  ------------------------- Batch round 1, loss: 0.565 -------------------------
2023-03-25 16:00:31,671 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:31,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:31,675 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-25 16:00:33,760 : [INFO]  ------------------------- Batch round 2, loss: 0.558 -------------------------
2023-03-25 16:00:33,760 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:33,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:33,765 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-25 16:00:35,993 : [INFO]  ------------------------- Batch round 3, loss: 0.5477 -------------------------
2023-03-25 16:00:35,994 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:35,997 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:35,998 : [INFO]  Batch number 82 model fetched from the server
2023-03-25 16:00:35,998 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-25 16:00:37,339 : [INFO]  Batch 82: Training set : loss - 0.555, accuracy - 0.7554, recall - 0.8696, AUC - 0.8564, F1 - 0.7805, precision - 0.708, training time - -9.0 seconds
2023-03-25 16:00:37,339 : [INFO]  Batch 82: Testing set : loss - 0.5894, accuracy - 0.7059, recall - 0.8431, AUC - 0.8187, F1 - 0.7414, precision - 0.6615
2023-03-25 16:00:37,345 : [INFO]  Batch 83 initialized 
2023-03-25 16:00:37,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:38,174 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-25 16:00:42,186 : [INFO]  ------------------------- Batch round 1, loss: 0.5648 -------------------------
2023-03-25 16:00:42,186 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:42,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:42,191 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-25 16:00:44,341 : [INFO]  ------------------------- Batch round 2, loss: 0.5601 -------------------------
2023-03-25 16:00:44,341 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:44,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:44,521 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-25 16:00:46,761 : [INFO]  ------------------------- Batch round 3, loss: 0.5456 -------------------------
2023-03-25 16:00:46,761 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:46,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:46,766 : [INFO]  Batch number 83 model fetched from the server
2023-03-25 16:00:46,766 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-25 16:00:48,102 : [INFO]  Batch 83: Training set : loss - 0.5458, accuracy - 0.7663, recall - 0.9239, AUC - 0.8686, F1 - 0.7981, precision - 0.7025, training time - -9.0 seconds
2023-03-25 16:00:48,102 : [INFO]  Batch 83: Testing set : loss - 0.5564, accuracy - 0.7647, recall - 0.8824, AUC - 0.8622, F1 - 0.7895, precision - 0.7143
2023-03-25 16:00:48,107 : [INFO]  Batch 84 initialized 
2023-03-25 16:00:48,544 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:48,935 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-25 16:00:52,998 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 16:00:52,999 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:53,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:53,003 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-25 16:00:55,247 : [INFO]  ------------------------- Batch round 2, loss: 0.561 -------------------------
2023-03-25 16:00:55,247 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:55,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:55,252 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-25 16:00:57,487 : [INFO]  ------------------------- Batch round 3, loss: 0.555 -------------------------
2023-03-25 16:00:57,487 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:57,490 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:57,492 : [INFO]  Batch number 84 model fetched from the server
2023-03-25 16:00:57,492 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-25 16:00:58,862 : [INFO]  Batch 84: Training set : loss - 0.5515, accuracy - 0.7717, recall - 0.8913, AUC - 0.8834, F1 - 0.7961, precision - 0.7193, training time - -9.0 seconds
2023-03-25 16:00:58,862 : [INFO]  Batch 84: Testing set : loss - 0.5773, accuracy - 0.7108, recall - 0.9118, AUC - 0.8332, F1 - 0.7592, precision - 0.6503
2023-03-25 16:00:58,868 : [INFO]  Batch 85 initialized 
2023-03-25 16:00:59,315 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:59,698 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-25 16:01:03,603 : [INFO]  ------------------------- Batch round 1, loss: 0.5341 -------------------------
2023-03-25 16:01:03,604 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:03,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:03,608 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-25 16:01:05,760 : [INFO]  ------------------------- Batch round 2, loss: 0.525 -------------------------
2023-03-25 16:01:05,760 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:05,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:05,765 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-25 16:01:07,929 : [INFO]  ------------------------- Batch round 3, loss: 0.5199 -------------------------
2023-03-25 16:01:07,929 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:07,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:07,934 : [INFO]  Batch number 85 model fetched from the server
2023-03-25 16:01:07,934 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-25 16:01:09,243 : [INFO]  Batch 85: Training set : loss - 0.5197, accuracy - 0.7989, recall - 0.9457, AUC - 0.9186, F1 - 0.8246, precision - 0.7311, training time - -8.0 seconds
2023-03-25 16:01:09,243 : [INFO]  Batch 85: Testing set : loss - 0.5312, accuracy - 0.7794, recall - 0.9314, AUC - 0.9161, F1 - 0.8085, precision - 0.7143
2023-03-25 16:01:09,252 : [INFO]  Batch 86 initialized 
2023-03-25 16:01:09,684 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:10,081 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-25 16:01:14,096 : [INFO]  ------------------------- Batch round 1, loss: 0.5637 -------------------------
2023-03-25 16:01:14,096 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:14,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:14,101 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-25 16:01:16,416 : [INFO]  ------------------------- Batch round 2, loss: 0.5602 -------------------------
2023-03-25 16:01:16,417 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:16,420 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:16,421 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-25 16:01:18,616 : [INFO]  ------------------------- Batch round 3, loss: 0.5461 -------------------------
2023-03-25 16:01:18,616 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:18,792 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:18,794 : [INFO]  Batch number 86 model fetched from the server
2023-03-25 16:01:18,794 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-25 16:01:20,139 : [INFO]  Batch 86: Training set : loss - 0.561, accuracy - 0.7663, recall - 0.9674, AUC - 0.8979, F1 - 0.8054, precision - 0.6899, training time - -9.0 seconds
2023-03-25 16:01:20,140 : [INFO]  Batch 86: Testing set : loss - 0.586, accuracy - 0.7304, recall - 0.9804, AUC - 0.8936, F1 - 0.7843, precision - 0.6536
2023-03-25 16:01:20,146 : [INFO]  Batch 87 initialized 
2023-03-25 16:01:20,575 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:20,972 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-25 16:01:24,875 : [INFO]  ------------------------- Batch round 1, loss: 0.575 -------------------------
2023-03-25 16:01:24,875 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:24,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:24,880 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-25 16:01:27,023 : [INFO]  ------------------------- Batch round 2, loss: 0.5534 -------------------------
2023-03-25 16:01:27,023 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:27,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:27,029 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-25 16:01:29,210 : [INFO]  ------------------------- Batch round 3, loss: 0.5433 -------------------------
2023-03-25 16:01:29,210 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:29,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:29,215 : [INFO]  Batch number 87 model fetched from the server
2023-03-25 16:01:29,215 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-25 16:01:30,550 : [INFO]  Batch 87: Training set : loss - 0.5521, accuracy - 0.7609, recall - 0.9348, AUC - 0.8831, F1 - 0.7963, precision - 0.6935, training time - -8.0 seconds
2023-03-25 16:01:30,550 : [INFO]  Batch 87: Testing set : loss - 0.5411, accuracy - 0.75, recall - 0.9608, AUC - 0.8985, F1 - 0.7935, precision - 0.6759
2023-03-25 16:01:30,557 : [INFO]  Batch 88 initialized 
2023-03-25 16:01:30,992 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:31,399 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-25 16:01:35,443 : [INFO]  ------------------------- Batch round 1, loss: 0.5627 -------------------------
2023-03-25 16:01:35,443 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:35,446 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:35,447 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-25 16:01:37,634 : [INFO]  ------------------------- Batch round 2, loss: 0.5515 -------------------------
2023-03-25 16:01:37,634 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:37,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:37,639 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-25 16:01:39,856 : [INFO]  ------------------------- Batch round 3, loss: 0.5462 -------------------------
2023-03-25 16:01:39,856 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:39,859 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:39,861 : [INFO]  Batch number 88 model fetched from the server
2023-03-25 16:01:39,861 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-25 16:01:41,211 : [INFO]  Batch 88: Training set : loss - 0.5412, accuracy - 0.7717, recall - 0.9457, AUC - 0.8992, F1 - 0.8056, precision - 0.7016, training time - -8.0 seconds
2023-03-25 16:01:41,211 : [INFO]  Batch 88: Testing set : loss - 0.5458, accuracy - 0.7647, recall - 0.9216, AUC - 0.8992, F1 - 0.7966, precision - 0.7015
2023-03-25 16:01:41,219 : [INFO]  Batch 89 initialized 
2023-03-25 16:01:41,681 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:42,061 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-25 16:01:45,960 : [INFO]  ------------------------- Batch round 1, loss: 0.5455 -------------------------
2023-03-25 16:01:45,960 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:45,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:45,965 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-25 16:01:48,078 : [INFO]  ------------------------- Batch round 2, loss: 0.5274 -------------------------
2023-03-25 16:01:48,078 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:48,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:48,083 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-25 16:01:50,165 : [INFO]  ------------------------- Batch round 3, loss: 0.5191 -------------------------
2023-03-25 16:01:50,165 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:50,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:50,170 : [INFO]  Batch number 89 model fetched from the server
2023-03-25 16:01:50,170 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-25 16:01:51,507 : [INFO]  Batch 89: Training set : loss - 0.5129, accuracy - 0.8098, recall - 0.9457, AUC - 0.9006, F1 - 0.8325, precision - 0.7436, training time - -8.0 seconds
2023-03-25 16:01:51,507 : [INFO]  Batch 89: Testing set : loss - 0.5389, accuracy - 0.7745, recall - 0.9412, AUC - 0.905, F1 - 0.8067, precision - 0.7059
2023-03-25 16:01:51,514 : [INFO]  Batch 90 initialized 
2023-03-25 16:01:51,941 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:52,344 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-25 16:01:56,521 : [INFO]  ------------------------- Batch round 1, loss: 0.5759 -------------------------
2023-03-25 16:01:56,521 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:56,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:56,525 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-25 16:01:58,687 : [INFO]  ------------------------- Batch round 2, loss: 0.5586 -------------------------
2023-03-25 16:01:58,687 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:58,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:58,692 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-25 16:02:00,883 : [INFO]  ------------------------- Batch round 3, loss: 0.5473 -------------------------
2023-03-25 16:02:00,884 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:00,887 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:00,890 : [INFO]  Batch number 90 model fetched from the server
2023-03-25 16:02:00,890 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-25 16:02:02,246 : [INFO]  Batch 90: Training set : loss - 0.5472, accuracy - 0.7446, recall - 0.8696, AUC - 0.8601, F1 - 0.7729, precision - 0.6957, training time - -9.0 seconds
2023-03-25 16:02:02,246 : [INFO]  Batch 90: Testing set : loss - 0.6182, accuracy - 0.6667, recall - 0.7843, AUC - 0.7479, F1 - 0.7018, precision - 0.6349
2023-03-25 16:02:02,252 : [INFO]  Batch 91 initialized 
2023-03-25 16:02:02,689 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:03,089 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-25 16:02:07,115 : [INFO]  ------------------------- Batch round 1, loss: 0.5771 -------------------------
2023-03-25 16:02:07,115 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:07,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:07,120 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-25 16:02:09,388 : [INFO]  ------------------------- Batch round 2, loss: 0.5605 -------------------------
2023-03-25 16:02:09,388 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:09,391 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:09,393 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-25 16:02:11,631 : [INFO]  ------------------------- Batch round 3, loss: 0.5564 -------------------------
2023-03-25 16:02:11,631 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:11,634 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:11,636 : [INFO]  Batch number 91 model fetched from the server
2023-03-25 16:02:11,636 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-25 16:02:13,008 : [INFO]  Batch 91: Training set : loss - 0.5661, accuracy - 0.7174, recall - 0.8913, AUC - 0.8599, F1 - 0.7593, precision - 0.6613, training time - -9.0 seconds
2023-03-25 16:02:13,008 : [INFO]  Batch 91: Testing set : loss - 0.6095, accuracy - 0.6324, recall - 0.8725, AUC - 0.8305, F1 - 0.7036, precision - 0.5894
2023-03-25 16:02:13,014 : [INFO]  Batch 92 initialized 
2023-03-25 16:02:13,444 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:13,847 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-25 16:02:17,826 : [INFO]  ------------------------- Batch round 1, loss: 0.5307 -------------------------
2023-03-25 16:02:17,826 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:17,858 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:17,860 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-25 16:02:20,038 : [INFO]  ------------------------- Batch round 2, loss: 0.5138 -------------------------
2023-03-25 16:02:20,038 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:20,149 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:20,151 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-25 16:02:22,309 : [INFO]  ------------------------- Batch round 3, loss: 0.5122 -------------------------
2023-03-25 16:02:22,309 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:22,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:22,371 : [INFO]  Batch number 92 model fetched from the server
2023-03-25 16:02:22,371 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-25 16:02:23,710 : [INFO]  Batch 92: Training set : loss - 0.5148, accuracy - 0.7826, recall - 0.913, AUC - 0.909, F1 - 0.8077, precision - 0.7241, training time - -9.0 seconds
2023-03-25 16:02:23,710 : [INFO]  Batch 92: Testing set : loss - 0.5601, accuracy - 0.7206, recall - 0.9118, AUC - 0.8713, F1 - 0.7654, precision - 0.6596
2023-03-25 16:02:23,722 : [INFO]  Batch 93 initialized 
2023-03-25 16:02:24,160 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:24,566 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-25 16:02:28,524 : [INFO]  ------------------------- Batch round 1, loss: 0.5341 -------------------------
2023-03-25 16:02:28,524 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:28,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:28,529 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-25 16:02:30,722 : [INFO]  ------------------------- Batch round 2, loss: 0.5198 -------------------------
2023-03-25 16:02:30,722 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:30,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:30,958 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-25 16:02:33,147 : [INFO]  ------------------------- Batch round 3, loss: 0.5196 -------------------------
2023-03-25 16:02:33,147 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:33,150 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:33,152 : [INFO]  Batch number 93 model fetched from the server
2023-03-25 16:02:33,152 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-25 16:02:34,531 : [INFO]  Batch 93: Training set : loss - 0.5129, accuracy - 0.788, recall - 0.9783, AUC - 0.9352, F1 - 0.8219, precision - 0.7087, training time - -9.0 seconds
2023-03-25 16:02:34,532 : [INFO]  Batch 93: Testing set : loss - 0.5796, accuracy - 0.6765, recall - 0.8627, AUC - 0.8516, F1 - 0.7273, precision - 0.6286
2023-03-25 16:02:34,544 : [INFO]  Batch 94 initialized 
2023-03-25 16:02:34,992 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:35,392 : [INFO]  ------------------------- Batch 94 training: round 1 -------------------------
2023-03-25 16:02:39,339 : [INFO]  ------------------------- Batch round 1, loss: 0.5755 -------------------------
2023-03-25 16:02:39,339 : [INFO]  ------------------------- Batch 94, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:39,446 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:39,447 : [INFO]  ------------------------- Batch 94 training: round 2 -------------------------
2023-03-25 16:02:41,688 : [INFO]  ------------------------- Batch round 2, loss: 0.5678 -------------------------
2023-03-25 16:02:41,688 : [INFO]  ------------------------- Batch 94, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:41,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:41,693 : [INFO]  ------------------------- Batch 94 training: round 3 -------------------------
2023-03-25 16:02:43,916 : [INFO]  ------------------------- Batch round 3, loss: 0.5596 -------------------------
2023-03-25 16:02:43,916 : [INFO]  ------------------------- Batch 94, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:43,920 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:43,921 : [INFO]  Batch number 94 model fetched from the server
2023-03-25 16:02:43,921 : [INFO]  ################ Batch 94: final global model evalution after 3 rounds ################
2023-03-25 16:02:45,279 : [INFO]  Batch 94: Training set : loss - 0.5588, accuracy - 0.7283, recall - 0.913, AUC - 0.8418, F1 - 0.7706, precision - 0.6667, training time - -9.0 seconds
2023-03-25 16:02:45,279 : [INFO]  Batch 94: Testing set : loss - 0.57, accuracy - 0.7157, recall - 0.9216, AUC - 0.8809, F1 - 0.7642, precision - 0.6528
2023-03-25 16:02:45,286 : [INFO]  Batch 95 initialized 
2023-03-25 16:02:45,732 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:46,129 : [INFO]  ------------------------- Batch 95 training: round 1 -------------------------
2023-03-25 16:02:50,125 : [INFO]  ------------------------- Batch round 1, loss: 0.5617 -------------------------
2023-03-25 16:02:50,125 : [INFO]  ------------------------- Batch 95, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:50,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:50,130 : [INFO]  ------------------------- Batch 95 training: round 2 -------------------------
2023-03-25 16:02:52,428 : [INFO]  ------------------------- Batch round 2, loss: 0.5513 -------------------------
2023-03-25 16:02:52,428 : [INFO]  ------------------------- Batch 95, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:52,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:52,433 : [INFO]  ------------------------- Batch 95 training: round 3 -------------------------
2023-03-25 16:02:54,736 : [INFO]  ------------------------- Batch round 3, loss: 0.5398 -------------------------
2023-03-25 16:02:54,736 : [INFO]  ------------------------- Batch 95, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:54,739 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:54,740 : [INFO]  Batch number 95 model fetched from the server
2023-03-25 16:02:54,740 : [INFO]  ################ Batch 95: final global model evalution after 3 rounds ################
2023-03-25 16:02:56,075 : [INFO]  Batch 95: Training set : loss - 0.5432, accuracy - 0.75, recall - 0.9674, AUC - 0.8911, F1 - 0.7946, precision - 0.6742, training time - -9.0 seconds
2023-03-25 16:02:56,076 : [INFO]  Batch 95: Testing set : loss - 0.5602, accuracy - 0.652, recall - 0.8922, AUC - 0.8871, F1 - 0.7194, precision - 0.6026
2023-03-25 16:02:56,081 : [INFO]  Batch 96 initialized 
2023-03-25 16:02:56,526 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:56,928 : [INFO]  ------------------------- Batch 96 training: round 1 -------------------------
2023-03-25 16:03:00,990 : [INFO]  ------------------------- Batch round 1, loss: 0.5726 -------------------------
2023-03-25 16:03:00,991 : [INFO]  ------------------------- Batch 96, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:00,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:00,995 : [INFO]  ------------------------- Batch 96 training: round 2 -------------------------
2023-03-25 16:03:03,290 : [INFO]  ------------------------- Batch round 2, loss: 0.5601 -------------------------
2023-03-25 16:03:03,290 : [INFO]  ------------------------- Batch 96, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:03,293 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:03,295 : [INFO]  ------------------------- Batch 96 training: round 3 -------------------------
2023-03-25 16:03:05,562 : [INFO]  ------------------------- Batch round 3, loss: 0.5486 -------------------------
2023-03-25 16:03:05,562 : [INFO]  ------------------------- Batch 96, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:05,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:05,567 : [INFO]  Batch number 96 model fetched from the server
2023-03-25 16:03:05,567 : [INFO]  ################ Batch 96: final global model evalution after 3 rounds ################
2023-03-25 16:03:06,951 : [INFO]  Batch 96: Training set : loss - 0.5518, accuracy - 0.7554, recall - 0.9348, AUC - 0.8753, F1 - 0.7926, precision - 0.688, training time - -9.0 seconds
2023-03-25 16:03:06,951 : [INFO]  Batch 96: Testing set : loss - 0.5847, accuracy - 0.6863, recall - 0.9412, AUC - 0.8856, F1 - 0.75, precision - 0.6234
2023-03-25 16:03:06,961 : [INFO]  Batch 97 initialized 
2023-03-25 16:03:07,387 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:07,810 : [INFO]  ------------------------- Batch 97 training: round 1 -------------------------
2023-03-25 16:03:11,719 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 16:03:11,719 : [INFO]  ------------------------- Batch 97, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:11,722 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:11,723 : [INFO]  ------------------------- Batch 97 training: round 2 -------------------------
2023-03-25 16:03:13,945 : [INFO]  ------------------------- Batch round 2, loss: 0.5615 -------------------------
2023-03-25 16:03:13,945 : [INFO]  ------------------------- Batch 97, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:13,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:13,950 : [INFO]  ------------------------- Batch 97 training: round 3 -------------------------
2023-03-25 16:03:16,113 : [INFO]  ------------------------- Batch round 3, loss: 0.5543 -------------------------
2023-03-25 16:03:16,113 : [INFO]  ------------------------- Batch 97, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:16,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:16,117 : [INFO]  Batch number 97 model fetched from the server
2023-03-25 16:03:16,118 : [INFO]  ################ Batch 97: final global model evalution after 3 rounds ################
2023-03-25 16:03:17,441 : [INFO]  Batch 97: Training set : loss - 0.5448, accuracy - 0.788, recall - 0.9239, AUC - 0.854, F1 - 0.8134, precision - 0.7265, training time - -8.0 seconds
2023-03-25 16:03:17,441 : [INFO]  Batch 97: Testing set : loss - 0.5804, accuracy - 0.6961, recall - 0.9412, AUC - 0.8842, F1 - 0.7559, precision - 0.6316
2023-03-25 16:03:17,449 : [INFO]  Batch 98 initialized 
2023-03-25 16:03:17,898 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:18,299 : [INFO]  ------------------------- Batch 98 training: round 1 -------------------------
2023-03-25 16:03:22,347 : [INFO]  ------------------------- Batch round 1, loss: 0.5558 -------------------------
2023-03-25 16:03:22,347 : [INFO]  ------------------------- Batch 98, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:22,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:22,353 : [INFO]  ------------------------- Batch 98 training: round 2 -------------------------
2023-03-25 16:03:24,614 : [INFO]  ------------------------- Batch round 2, loss: 0.541 -------------------------
2023-03-25 16:03:24,614 : [INFO]  ------------------------- Batch 98, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:24,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:24,619 : [INFO]  ------------------------- Batch 98 training: round 3 -------------------------
2023-03-25 16:03:26,894 : [INFO]  ------------------------- Batch round 3, loss: 0.5338 -------------------------
2023-03-25 16:03:26,894 : [INFO]  ------------------------- Batch 98, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:26,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:26,899 : [INFO]  Batch number 98 model fetched from the server
2023-03-25 16:03:26,899 : [INFO]  ################ Batch 98: final global model evalution after 3 rounds ################
2023-03-25 16:03:28,245 : [INFO]  Batch 98: Training set : loss - 0.5231, accuracy - 0.7772, recall - 0.9022, AUC - 0.8924, F1 - 0.8019, precision - 0.7217, training time - -9.0 seconds
2023-03-25 16:03:28,245 : [INFO]  Batch 98: Testing set : loss - 0.5549, accuracy - 0.7402, recall - 0.9412, AUC - 0.8905, F1 - 0.7837, precision - 0.6713
2023-03-25 16:03:28,253 : [INFO]  Batch 99 initialized 
2023-03-25 16:03:28,690 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:29,104 : [INFO]  ------------------------- Batch 99 training: round 1 -------------------------
2023-03-25 16:03:33,083 : [INFO]  ------------------------- Batch round 1, loss: 0.5322 -------------------------
2023-03-25 16:03:33,083 : [INFO]  ------------------------- Batch 99, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:33,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:33,088 : [INFO]  ------------------------- Batch 99 training: round 2 -------------------------
2023-03-25 16:03:35,277 : [INFO]  ------------------------- Batch round 2, loss: 0.5212 -------------------------
2023-03-25 16:03:35,278 : [INFO]  ------------------------- Batch 99, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:35,281 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:35,283 : [INFO]  ------------------------- Batch 99 training: round 3 -------------------------
2023-03-25 16:03:37,442 : [INFO]  ------------------------- Batch round 3, loss: 0.5137 -------------------------
2023-03-25 16:03:37,442 : [INFO]  ------------------------- Batch 99, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:37,446 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:37,447 : [INFO]  Batch number 99 model fetched from the server
2023-03-25 16:03:37,447 : [INFO]  ################ Batch 99: final global model evalution after 3 rounds ################
2023-03-25 16:03:38,780 : [INFO]  Batch 99: Training set : loss - 0.5188, accuracy - 0.7935, recall - 0.9457, AUC - 0.9233, F1 - 0.8208, precision - 0.725, training time - -8.0 seconds
2023-03-25 16:03:38,780 : [INFO]  Batch 99: Testing set : loss - 0.5808, accuracy - 0.701, recall - 0.9118, AUC - 0.8505, F1 - 0.753, precision - 0.6414
2023-03-25 16:03:38,787 : [INFO]  Batch 100 initialized 
2023-03-25 16:03:39,216 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:39,642 : [INFO]  ------------------------- Batch 100 training: round 1 -------------------------
2023-03-25 16:03:43,659 : [INFO]  ------------------------- Batch round 1, loss: 0.5758 -------------------------
2023-03-25 16:03:43,660 : [INFO]  ------------------------- Batch 100, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:43,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:43,664 : [INFO]  ------------------------- Batch 100 training: round 2 -------------------------
2023-03-25 16:03:45,865 : [INFO]  ------------------------- Batch round 2, loss: 0.5606 -------------------------
2023-03-25 16:03:45,865 : [INFO]  ------------------------- Batch 100, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:45,868 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:45,869 : [INFO]  ------------------------- Batch 100 training: round 3 -------------------------
2023-03-25 16:03:48,111 : [INFO]  ------------------------- Batch round 3, loss: 0.5537 -------------------------
2023-03-25 16:03:48,111 : [INFO]  ------------------------- Batch 100, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:48,114 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:48,116 : [INFO]  Batch number 100 model fetched from the server
2023-03-25 16:03:48,116 : [INFO]  ################ Batch 100: final global model evalution after 3 rounds ################
2023-03-25 16:03:49,482 : [INFO]  Batch 100: Training set : loss - 0.5562, accuracy - 0.7772, recall - 0.9348, AUC - 0.8738, F1 - 0.8075, precision - 0.7107, training time - -8.0 seconds
2023-03-25 16:03:49,482 : [INFO]  Batch 100: Testing set : loss - 0.5658, accuracy - 0.7353, recall - 0.8824, AUC - 0.8703, F1 - 0.7692, precision - 0.6818
2023-03-25 16:03:49,489 : [INFO]  Batch 101 initialized 
2023-03-25 16:03:49,929 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:50,343 : [INFO]  ------------------------- Batch 101 training: round 1 -------------------------
2023-03-25 16:03:54,256 : [INFO]  ------------------------- Batch round 1, loss: 0.5523 -------------------------
2023-03-25 16:03:54,256 : [INFO]  ------------------------- Batch 101, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:54,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:54,262 : [INFO]  ------------------------- Batch 101 training: round 2 -------------------------
2023-03-25 16:03:56,389 : [INFO]  ------------------------- Batch round 2, loss: 0.5356 -------------------------
2023-03-25 16:03:56,389 : [INFO]  ------------------------- Batch 101, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:56,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:56,395 : [INFO]  ------------------------- Batch 101 training: round 3 -------------------------
2023-03-25 16:03:58,516 : [INFO]  ------------------------- Batch round 3, loss: 0.5321 -------------------------
2023-03-25 16:03:58,516 : [INFO]  ------------------------- Batch 101, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:58,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:58,520 : [INFO]  Batch number 101 model fetched from the server
2023-03-25 16:03:58,520 : [INFO]  ################ Batch 101: final global model evalution after 3 rounds ################
2023-03-25 16:03:59,996 : [INFO]  Batch 101: Training set : loss - 0.5276, accuracy - 0.7989, recall - 0.9783, AUC - 0.8993, F1 - 0.8295, precision - 0.72, training time - -8.0 seconds
2023-03-25 16:03:59,997 : [INFO]  Batch 101: Testing set : loss - 0.5396, accuracy - 0.7549, recall - 0.9608, AUC - 0.929, F1 - 0.7967, precision - 0.6806
2023-03-25 16:04:00,007 : [INFO]  Batch 102 initialized 
2023-03-25 16:04:00,484 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:00,913 : [INFO]  ------------------------- Batch 102 training: round 1 -------------------------
2023-03-25 16:04:04,932 : [INFO]  ------------------------- Batch round 1, loss: 0.5533 -------------------------
2023-03-25 16:04:04,933 : [INFO]  ------------------------- Batch 102, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:04,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:04,938 : [INFO]  ------------------------- Batch 102 training: round 2 -------------------------
2023-03-25 16:04:07,170 : [INFO]  ------------------------- Batch round 2, loss: 0.5452 -------------------------
2023-03-25 16:04:07,171 : [INFO]  ------------------------- Batch 102, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:07,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:07,176 : [INFO]  ------------------------- Batch 102 training: round 3 -------------------------
2023-03-25 16:04:09,398 : [INFO]  ------------------------- Batch round 3, loss: 0.5327 -------------------------
2023-03-25 16:04:09,398 : [INFO]  ------------------------- Batch 102, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:09,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:09,403 : [INFO]  Batch number 102 model fetched from the server
2023-03-25 16:04:09,403 : [INFO]  ################ Batch 102: final global model evalution after 3 rounds ################
2023-03-25 16:04:10,841 : [INFO]  Batch 102: Training set : loss - 0.5325, accuracy - 0.7554, recall - 0.8913, AUC - 0.8798, F1 - 0.7847, precision - 0.7009, training time - -8.0 seconds
2023-03-25 16:04:10,842 : [INFO]  Batch 102: Testing set : loss - 0.5858, accuracy - 0.6765, recall - 0.8235, AUC - 0.8164, F1 - 0.7179, precision - 0.6364
2023-03-25 16:04:10,850 : [INFO]  Batch 103 initialized 
2023-03-25 16:04:11,282 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:11,717 : [INFO]  ------------------------- Batch 103 training: round 1 -------------------------
2023-03-25 16:04:15,759 : [INFO]  ------------------------- Batch round 1, loss: 0.5632 -------------------------
2023-03-25 16:04:15,759 : [INFO]  ------------------------- Batch 103, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:15,762 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:15,764 : [INFO]  ------------------------- Batch 103 training: round 2 -------------------------
2023-03-25 16:04:17,964 : [INFO]  ------------------------- Batch round 2, loss: 0.5472 -------------------------
2023-03-25 16:04:17,965 : [INFO]  ------------------------- Batch 103, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:17,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:17,969 : [INFO]  ------------------------- Batch 103 training: round 3 -------------------------
2023-03-25 16:04:20,187 : [INFO]  ------------------------- Batch round 3, loss: 0.542 -------------------------
2023-03-25 16:04:20,188 : [INFO]  ------------------------- Batch 103, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:20,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:20,193 : [INFO]  Batch number 103 model fetched from the server
2023-03-25 16:04:20,193 : [INFO]  ################ Batch 103: final global model evalution after 3 rounds ################
2023-03-25 16:04:21,535 : [INFO]  Batch 103: Training set : loss - 0.5429, accuracy - 0.7663, recall - 0.913, AUC - 0.8777, F1 - 0.7962, precision - 0.7059, training time - -8.0 seconds
2023-03-25 16:04:21,535 : [INFO]  Batch 103: Testing set : loss - 0.5826, accuracy - 0.6667, recall - 0.8039, AUC - 0.8181, F1 - 0.7069, precision - 0.6308
2023-03-25 16:04:21,541 : [INFO]  Batch 104 initialized 
2023-03-25 16:04:21,979 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:22,391 : [INFO]  ------------------------- Batch 104 training: round 1 -------------------------
2023-03-25 16:04:26,353 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 16:04:26,353 : [INFO]  ------------------------- Batch 104, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:26,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:26,358 : [INFO]  ------------------------- Batch 104 training: round 2 -------------------------
2023-03-25 16:04:28,555 : [INFO]  ------------------------- Batch round 2, loss: 0.5536 -------------------------
2023-03-25 16:04:28,555 : [INFO]  ------------------------- Batch 104, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:28,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:28,559 : [INFO]  ------------------------- Batch 104 training: round 3 -------------------------
2023-03-25 16:04:30,764 : [INFO]  ------------------------- Batch round 3, loss: 0.5517 -------------------------
2023-03-25 16:04:30,764 : [INFO]  ------------------------- Batch 104, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:30,767 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:30,769 : [INFO]  Batch number 104 model fetched from the server
2023-03-25 16:04:30,769 : [INFO]  ################ Batch 104: final global model evalution after 3 rounds ################
2023-03-25 16:04:32,127 : [INFO]  Batch 104: Training set : loss - 0.5443, accuracy - 0.788, recall - 0.8913, AUC - 0.8911, F1 - 0.8079, precision - 0.7387, training time - -8.0 seconds
2023-03-25 16:04:32,127 : [INFO]  Batch 104: Testing set : loss - 0.6, accuracy - 0.652, recall - 0.8137, AUC - 0.7856, F1 - 0.7004, precision - 0.6148
2023-03-25 16:04:32,134 : [INFO]  Batch 105 initialized 
2023-03-25 16:04:32,562 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:33,001 : [INFO]  ------------------------- Batch 105 training: round 1 -------------------------
2023-03-25 16:04:36,917 : [INFO]  ------------------------- Batch round 1, loss: 0.5498 -------------------------
2023-03-25 16:04:36,917 : [INFO]  ------------------------- Batch 105, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:36,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:36,956 : [INFO]  ------------------------- Batch 105 training: round 2 -------------------------
2023-03-25 16:04:39,146 : [INFO]  ------------------------- Batch round 2, loss: 0.5172 -------------------------
2023-03-25 16:04:39,146 : [INFO]  ------------------------- Batch 105, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:39,183 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:39,185 : [INFO]  ------------------------- Batch 105 training: round 3 -------------------------
2023-03-25 16:04:41,371 : [INFO]  ------------------------- Batch round 3, loss: 0.5071 -------------------------
2023-03-25 16:04:41,371 : [INFO]  ------------------------- Batch 105, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:41,375 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:41,376 : [INFO]  Batch number 105 model fetched from the server
2023-03-25 16:04:41,376 : [INFO]  ################ Batch 105: final global model evalution after 3 rounds ################
2023-03-25 16:04:42,743 : [INFO]  Batch 105: Training set : loss - 0.5062, accuracy - 0.8043, recall - 0.9674, AUC - 0.9366, F1 - 0.8318, precision - 0.7295, training time - -8.0 seconds
2023-03-25 16:04:42,743 : [INFO]  Batch 105: Testing set : loss - 0.5895, accuracy - 0.6814, recall - 0.8529, AUC - 0.843, F1 - 0.728, precision - 0.635
2023-03-25 16:04:42,749 : [INFO]  Batch 106 initialized 
2023-03-25 16:04:43,182 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:43,615 : [INFO]  ------------------------- Batch 106 training: round 1 -------------------------
2023-03-25 16:04:47,628 : [INFO]  ------------------------- Batch round 1, loss: 0.5687 -------------------------
2023-03-25 16:04:47,628 : [INFO]  ------------------------- Batch 106, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:47,631 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:47,632 : [INFO]  ------------------------- Batch 106 training: round 2 -------------------------
2023-03-25 16:04:49,830 : [INFO]  ------------------------- Batch round 2, loss: 0.5605 -------------------------
2023-03-25 16:04:49,830 : [INFO]  ------------------------- Batch 106, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:49,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:49,835 : [INFO]  ------------------------- Batch 106 training: round 3 -------------------------
2023-03-25 16:04:52,072 : [INFO]  ------------------------- Batch round 3, loss: 0.5492 -------------------------
2023-03-25 16:04:52,073 : [INFO]  ------------------------- Batch 106, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:52,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:52,079 : [INFO]  Batch number 106 model fetched from the server
2023-03-25 16:04:52,079 : [INFO]  ################ Batch 106: final global model evalution after 3 rounds ################
2023-03-25 16:04:53,440 : [INFO]  Batch 106: Training set : loss - 0.5406, accuracy - 0.788, recall - 0.9674, AUC - 0.8759, F1 - 0.8203, precision - 0.712, training time - -8.0 seconds
2023-03-25 16:04:53,440 : [INFO]  Batch 106: Testing set : loss - 0.6067, accuracy - 0.6716, recall - 0.8725, AUC - 0.8097, F1 - 0.7265, precision - 0.6224
2023-03-25 16:04:53,449 : [INFO]  Batch 107 initialized 
2023-03-25 16:04:53,883 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:54,322 : [INFO]  ------------------------- Batch 107 training: round 1 -------------------------
2023-03-25 16:04:58,330 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-25 16:04:58,330 : [INFO]  ------------------------- Batch 107, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:58,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:58,335 : [INFO]  ------------------------- Batch 107 training: round 2 -------------------------
2023-03-25 16:05:00,585 : [INFO]  ------------------------- Batch round 2, loss: 0.5497 -------------------------
2023-03-25 16:05:00,585 : [INFO]  ------------------------- Batch 107, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:00,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:00,590 : [INFO]  ------------------------- Batch 107 training: round 3 -------------------------
2023-03-25 16:05:02,854 : [INFO]  ------------------------- Batch round 3, loss: 0.5417 -------------------------
2023-03-25 16:05:02,854 : [INFO]  ------------------------- Batch 107, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:02,857 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:02,858 : [INFO]  Batch number 107 model fetched from the server
2023-03-25 16:05:02,858 : [INFO]  ################ Batch 107: final global model evalution after 3 rounds ################
2023-03-25 16:05:04,265 : [INFO]  Batch 107: Training set : loss - 0.5359, accuracy - 0.7772, recall - 0.9022, AUC - 0.8713, F1 - 0.8019, precision - 0.7217, training time - -9.0 seconds
2023-03-25 16:05:04,265 : [INFO]  Batch 107: Testing set : loss - 0.5915, accuracy - 0.7157, recall - 0.8529, AUC - 0.8118, F1 - 0.75, precision - 0.6692
2023-03-25 16:05:04,271 : [INFO]  Batch 108 initialized 
2023-03-25 16:05:04,696 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:05,136 : [INFO]  ------------------------- Batch 108 training: round 1 -------------------------
2023-03-25 16:05:09,124 : [INFO]  ------------------------- Batch round 1, loss: 0.6077 -------------------------
2023-03-25 16:05:09,124 : [INFO]  ------------------------- Batch 108, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:09,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:09,129 : [INFO]  ------------------------- Batch 108 training: round 2 -------------------------
2023-03-25 16:05:11,333 : [INFO]  ------------------------- Batch round 2, loss: 0.5967 -------------------------
2023-03-25 16:05:11,333 : [INFO]  ------------------------- Batch 108, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:11,336 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:11,338 : [INFO]  ------------------------- Batch 108 training: round 3 -------------------------
2023-03-25 16:05:13,547 : [INFO]  ------------------------- Batch round 3, loss: 0.5837 -------------------------
2023-03-25 16:05:13,547 : [INFO]  ------------------------- Batch 108, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:13,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:13,551 : [INFO]  Batch number 108 model fetched from the server
2023-03-25 16:05:13,551 : [INFO]  ################ Batch 108: final global model evalution after 3 rounds ################
2023-03-25 16:05:14,922 : [INFO]  Batch 108: Training set : loss - 0.5908, accuracy - 0.7283, recall - 0.9239, AUC - 0.7932, F1 - 0.7727, precision - 0.6641, training time - -8.0 seconds
2023-03-25 16:05:14,922 : [INFO]  Batch 108: Testing set : loss - 0.5988, accuracy - 0.6765, recall - 0.8431, AUC - 0.7978, F1 - 0.7227, precision - 0.6324
2023-03-25 16:05:14,963 : [INFO]  Batch 109 initialized 
2023-03-25 16:05:15,467 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:15,880 : [INFO]  ------------------------- Batch 109 training: round 1 -------------------------
2023-03-25 16:05:19,800 : [INFO]  ------------------------- Batch round 1, loss: 0.5712 -------------------------
2023-03-25 16:05:19,800 : [INFO]  ------------------------- Batch 109, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:19,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:19,806 : [INFO]  ------------------------- Batch 109 training: round 2 -------------------------
2023-03-25 16:05:21,991 : [INFO]  ------------------------- Batch round 2, loss: 0.553 -------------------------
2023-03-25 16:05:21,991 : [INFO]  ------------------------- Batch 109, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:21,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:21,996 : [INFO]  ------------------------- Batch 109 training: round 3 -------------------------
2023-03-25 16:05:24,419 : [INFO]  ------------------------- Batch round 3, loss: 0.5373 -------------------------
2023-03-25 16:05:24,419 : [INFO]  ------------------------- Batch 109, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:24,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:24,423 : [INFO]  Batch number 109 model fetched from the server
2023-03-25 16:05:24,423 : [INFO]  ################ Batch 109: final global model evalution after 3 rounds ################
2023-03-25 16:05:25,732 : [INFO]  Batch 109: Training set : loss - 0.5426, accuracy - 0.7663, recall - 0.9348, AUC - 0.8918, F1 - 0.8, precision - 0.6992, training time - -9.0 seconds
2023-03-25 16:05:25,733 : [INFO]  Batch 109: Testing set : loss - 0.5998, accuracy - 0.6863, recall - 0.8725, AUC - 0.8047, F1 - 0.7355, precision - 0.6357
2023-03-25 16:05:25,741 : [INFO]  Batch 110 initialized 
2023-03-25 16:05:26,174 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:26,624 : [INFO]  ------------------------- Batch 110 training: round 1 -------------------------
2023-03-25 16:05:30,643 : [INFO]  ------------------------- Batch round 1, loss: 0.5572 -------------------------
2023-03-25 16:05:30,644 : [INFO]  ------------------------- Batch 110, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:30,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:30,649 : [INFO]  ------------------------- Batch 110 training: round 2 -------------------------
2023-03-25 16:05:32,912 : [INFO]  ------------------------- Batch round 2, loss: 0.5408 -------------------------
2023-03-25 16:05:32,912 : [INFO]  ------------------------- Batch 110, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:32,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:32,917 : [INFO]  ------------------------- Batch 110 training: round 3 -------------------------
2023-03-25 16:05:35,136 : [INFO]  ------------------------- Batch round 3, loss: 0.5375 -------------------------
2023-03-25 16:05:35,136 : [INFO]  ------------------------- Batch 110, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:35,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:35,141 : [INFO]  Batch number 110 model fetched from the server
2023-03-25 16:05:35,141 : [INFO]  ################ Batch 110: final global model evalution after 3 rounds ################
2023-03-25 16:05:36,493 : [INFO]  Batch 110: Training set : loss - 0.5301, accuracy - 0.8315, recall - 0.9022, AUC - 0.8946, F1 - 0.8426, precision - 0.7905, training time - -9.0 seconds
2023-03-25 16:05:36,493 : [INFO]  Batch 110: Testing set : loss - 0.5831, accuracy - 0.7549, recall - 0.8627, AUC - 0.7955, F1 - 0.7788, precision - 0.7097
2023-03-25 16:05:36,499 : [INFO]  Batch 111 initialized 
2023-03-25 16:05:36,951 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:37,377 : [INFO]  ------------------------- Batch 111 training: round 1 -------------------------
2023-03-25 16:05:41,322 : [INFO]  ------------------------- Batch round 1, loss: 0.5572 -------------------------
2023-03-25 16:05:41,323 : [INFO]  ------------------------- Batch 111, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:41,326 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:41,327 : [INFO]  ------------------------- Batch 111 training: round 2 -------------------------
2023-03-25 16:05:43,523 : [INFO]  ------------------------- Batch round 2, loss: 0.5418 -------------------------
2023-03-25 16:05:43,523 : [INFO]  ------------------------- Batch 111, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:43,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:43,529 : [INFO]  ------------------------- Batch 111 training: round 3 -------------------------
2023-03-25 16:05:45,702 : [INFO]  ------------------------- Batch round 3, loss: 0.5413 -------------------------
2023-03-25 16:05:45,702 : [INFO]  ------------------------- Batch 111, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:45,705 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:45,707 : [INFO]  Batch number 111 model fetched from the server
2023-03-25 16:05:45,707 : [INFO]  ################ Batch 111: final global model evalution after 3 rounds ################
2023-03-25 16:05:47,063 : [INFO]  Batch 111: Training set : loss - 0.5391, accuracy - 0.7609, recall - 0.9239, AUC - 0.8452, F1 - 0.7944, precision - 0.6967, training time - -8.0 seconds
2023-03-25 16:05:47,063 : [INFO]  Batch 111: Testing set : loss - 0.549, accuracy - 0.7598, recall - 0.9216, AUC - 0.8619, F1 - 0.7932, precision - 0.6963
2023-03-25 16:05:47,071 : [INFO]  Batch 112 initialized 
2023-03-25 16:05:47,506 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:47,956 : [INFO]  ------------------------- Batch 112 training: round 1 -------------------------
2023-03-25 16:05:51,923 : [INFO]  ------------------------- Batch round 1, loss: 0.5398 -------------------------
2023-03-25 16:05:51,923 : [INFO]  ------------------------- Batch 112, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:51,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:51,928 : [INFO]  ------------------------- Batch 112 training: round 2 -------------------------
2023-03-25 16:05:54,087 : [INFO]  ------------------------- Batch round 2, loss: 0.5234 -------------------------
2023-03-25 16:05:54,087 : [INFO]  ------------------------- Batch 112, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:54,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:54,092 : [INFO]  ------------------------- Batch 112 training: round 3 -------------------------
2023-03-25 16:05:56,261 : [INFO]  ------------------------- Batch round 3, loss: 0.5185 -------------------------
2023-03-25 16:05:56,261 : [INFO]  ------------------------- Batch 112, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:56,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:56,270 : [INFO]  Batch number 112 model fetched from the server
2023-03-25 16:05:56,270 : [INFO]  ################ Batch 112: final global model evalution after 3 rounds ################
2023-03-25 16:05:57,645 : [INFO]  Batch 112: Training set : loss - 0.5157, accuracy - 0.788, recall - 0.9783, AUC - 0.946, F1 - 0.8219, precision - 0.7087, training time - -8.0 seconds
2023-03-25 16:05:57,645 : [INFO]  Batch 112: Testing set : loss - 0.5461, accuracy - 0.7843, recall - 0.9216, AUC - 0.8578, F1 - 0.8103, precision - 0.7231
2023-03-25 16:05:57,656 : [INFO]  Batch 113 initialized 
2023-03-25 16:05:58,047 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:58,422 : [INFO]  ------------------------- Batch 113 training: round 1 -------------------------
2023-03-25 16:06:02,573 : [INFO]  ------------------------- Batch round 1, loss: 0.5387 -------------------------
2023-03-25 16:06:02,574 : [INFO]  ------------------------- Batch 113, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:02,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:02,722 : [INFO]  ------------------------- Batch 113 training: round 2 -------------------------
2023-03-25 16:06:04,948 : [INFO]  ------------------------- Batch round 2, loss: 0.5257 -------------------------
2023-03-25 16:06:04,949 : [INFO]  ------------------------- Batch 113, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:05,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:05,044 : [INFO]  ------------------------- Batch 113 training: round 3 -------------------------
2023-03-25 16:06:07,324 : [INFO]  ------------------------- Batch round 3, loss: 0.5286 -------------------------
2023-03-25 16:06:07,324 : [INFO]  ------------------------- Batch 113, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:07,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:07,467 : [INFO]  Batch number 113 model fetched from the server
2023-03-25 16:06:07,467 : [INFO]  ################ Batch 113: final global model evalution after 3 rounds ################
2023-03-25 16:06:08,776 : [INFO]  Batch 113: Training set : loss - 0.5289, accuracy - 0.75, recall - 0.9022, AUC - 0.9034, F1 - 0.783, precision - 0.6917, training time - -9.0 seconds
2023-03-25 16:06:08,776 : [INFO]  Batch 113: Testing set : loss - 0.5788, accuracy - 0.7059, recall - 0.8922, AUC - 0.8461, F1 - 0.7521, precision - 0.65
2023-03-25 16:06:08,786 : [INFO]  Batch 114 initialized 
2023-03-25 16:06:09,225 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:09,668 : [INFO]  ------------------------- Batch 114 training: round 1 -------------------------
2023-03-25 16:06:13,689 : [INFO]  ------------------------- Batch round 1, loss: 0.5558 -------------------------
2023-03-25 16:06:13,689 : [INFO]  ------------------------- Batch 114, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:13,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:13,694 : [INFO]  ------------------------- Batch 114 training: round 2 -------------------------
2023-03-25 16:06:15,884 : [INFO]  ------------------------- Batch round 2, loss: 0.5457 -------------------------
2023-03-25 16:06:15,884 : [INFO]  ------------------------- Batch 114, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:15,887 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:15,889 : [INFO]  ------------------------- Batch 114 training: round 3 -------------------------
2023-03-25 16:06:18,037 : [INFO]  ------------------------- Batch round 3, loss: 0.5364 -------------------------
2023-03-25 16:06:18,037 : [INFO]  ------------------------- Batch 114, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:18,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:18,216 : [INFO]  Batch number 114 model fetched from the server
2023-03-25 16:06:18,216 : [INFO]  ################ Batch 114: final global model evalution after 3 rounds ################
2023-03-25 16:06:19,560 : [INFO]  Batch 114: Training set : loss - 0.5436, accuracy - 0.7391, recall - 0.8913, AUC - 0.8651, F1 - 0.7736, precision - 0.6833, training time - -9.0 seconds
2023-03-25 16:06:19,560 : [INFO]  Batch 114: Testing set : loss - 0.5278, accuracy - 0.75, recall - 0.9118, AUC - 0.9269, F1 - 0.7848, precision - 0.6889
2023-03-25 16:06:19,568 : [INFO]  Batch 115 initialized 
2023-03-25 16:06:19,997 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:20,448 : [INFO]  ------------------------- Batch 115 training: round 1 -------------------------
2023-03-25 16:06:24,478 : [INFO]  ------------------------- Batch round 1, loss: 0.5576 -------------------------
2023-03-25 16:06:24,478 : [INFO]  ------------------------- Batch 115, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:24,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:24,483 : [INFO]  ------------------------- Batch 115 training: round 2 -------------------------
2023-03-25 16:06:26,718 : [INFO]  ------------------------- Batch round 2, loss: 0.552 -------------------------
2023-03-25 16:06:26,718 : [INFO]  ------------------------- Batch 115, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:26,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:26,827 : [INFO]  ------------------------- Batch 115 training: round 3 -------------------------
2023-03-25 16:06:29,075 : [INFO]  ------------------------- Batch round 3, loss: 0.5492 -------------------------
2023-03-25 16:06:29,075 : [INFO]  ------------------------- Batch 115, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:29,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:29,080 : [INFO]  Batch number 115 model fetched from the server
2023-03-25 16:06:29,080 : [INFO]  ################ Batch 115: final global model evalution after 3 rounds ################
2023-03-25 16:06:30,425 : [INFO]  Batch 115: Training set : loss - 0.5464, accuracy - 0.7446, recall - 0.9022, AUC - 0.8716, F1 - 0.7793, precision - 0.686, training time - -9.0 seconds
2023-03-25 16:06:30,426 : [INFO]  Batch 115: Testing set : loss - 0.5831, accuracy - 0.6863, recall - 0.8725, AUC - 0.8615, F1 - 0.7355, precision - 0.6357
2023-03-25 16:06:30,432 : [INFO]  Batch 116 initialized 
2023-03-25 16:06:30,876 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:31,321 : [INFO]  ------------------------- Batch 116 training: round 1 -------------------------
2023-03-25 16:06:35,327 : [INFO]  ------------------------- Batch round 1, loss: 0.5659 -------------------------
2023-03-25 16:06:35,327 : [INFO]  ------------------------- Batch 116, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:35,330 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:35,332 : [INFO]  ------------------------- Batch 116 training: round 2 -------------------------
2023-03-25 16:06:37,576 : [INFO]  ------------------------- Batch round 2, loss: 0.5445 -------------------------
2023-03-25 16:06:37,576 : [INFO]  ------------------------- Batch 116, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:37,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:37,581 : [INFO]  ------------------------- Batch 116 training: round 3 -------------------------
2023-03-25 16:06:39,783 : [INFO]  ------------------------- Batch round 3, loss: 0.5412 -------------------------
2023-03-25 16:06:39,783 : [INFO]  ------------------------- Batch 116, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:39,786 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:39,788 : [INFO]  Batch number 116 model fetched from the server
2023-03-25 16:06:39,788 : [INFO]  ################ Batch 116: final global model evalution after 3 rounds ################
2023-03-25 16:06:41,163 : [INFO]  Batch 116: Training set : loss - 0.5357, accuracy - 0.7935, recall - 0.9348, AUC - 0.8743, F1 - 0.819, precision - 0.7288, training time - -8.0 seconds
2023-03-25 16:06:41,164 : [INFO]  Batch 116: Testing set : loss - 0.5556, accuracy - 0.7255, recall - 0.8627, AUC - 0.8775, F1 - 0.7586, precision - 0.6769
2023-03-25 16:06:41,173 : [INFO]  Batch 117 initialized 
2023-03-25 16:06:41,617 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:42,051 : [INFO]  ------------------------- Batch 117 training: round 1 -------------------------
2023-03-25 16:06:46,046 : [INFO]  ------------------------- Batch round 1, loss: 0.5796 -------------------------
2023-03-25 16:06:46,046 : [INFO]  ------------------------- Batch 117, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:46,049 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:46,051 : [INFO]  ------------------------- Batch 117 training: round 2 -------------------------
2023-03-25 16:06:48,264 : [INFO]  ------------------------- Batch round 2, loss: 0.5767 -------------------------
2023-03-25 16:06:48,264 : [INFO]  ------------------------- Batch 117, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:48,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:48,269 : [INFO]  ------------------------- Batch 117 training: round 3 -------------------------
2023-03-25 16:06:50,473 : [INFO]  ------------------------- Batch round 3, loss: 0.5685 -------------------------
2023-03-25 16:06:50,473 : [INFO]  ------------------------- Batch 117, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:50,476 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:50,478 : [INFO]  Batch number 117 model fetched from the server
2023-03-25 16:06:50,478 : [INFO]  ################ Batch 117: final global model evalution after 3 rounds ################
2023-03-25 16:06:51,799 : [INFO]  Batch 117: Training set : loss - 0.5714, accuracy - 0.7337, recall - 0.9022, AUC - 0.8293, F1 - 0.7721, precision - 0.6748, training time - -8.0 seconds
2023-03-25 16:06:51,799 : [INFO]  Batch 117: Testing set : loss - 0.5874, accuracy - 0.6814, recall - 0.8725, AUC - 0.8482, F1 - 0.7325, precision - 0.6312
2023-03-25 16:06:51,805 : [INFO]  Batch 118 initialized 
2023-03-25 16:06:52,232 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:52,698 : [INFO]  ------------------------- Batch 118 training: round 1 -------------------------
2023-03-25 16:06:56,709 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-25 16:06:56,709 : [INFO]  ------------------------- Batch 118, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:56,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:56,714 : [INFO]  ------------------------- Batch 118 training: round 2 -------------------------
2023-03-25 16:06:58,921 : [INFO]  ------------------------- Batch round 2, loss: 0.5499 -------------------------
2023-03-25 16:06:58,921 : [INFO]  ------------------------- Batch 118, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:58,925 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:58,926 : [INFO]  ------------------------- Batch 118 training: round 3 -------------------------
2023-03-25 16:07:01,146 : [INFO]  ------------------------- Batch round 3, loss: 0.5339 -------------------------
2023-03-25 16:07:01,146 : [INFO]  ------------------------- Batch 118, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:01,149 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:01,151 : [INFO]  Batch number 118 model fetched from the server
2023-03-25 16:07:01,151 : [INFO]  ################ Batch 118: final global model evalution after 3 rounds ################
2023-03-25 16:07:02,574 : [INFO]  Batch 118: Training set : loss - 0.5338, accuracy - 0.7772, recall - 0.8696, AUC - 0.871, F1 - 0.796, precision - 0.7339, training time - -8.0 seconds
2023-03-25 16:07:02,575 : [INFO]  Batch 118: Testing set : loss - 0.5809, accuracy - 0.6716, recall - 0.8431, AUC - 0.8445, F1 - 0.7197, precision - 0.6277
2023-03-25 16:07:02,585 : [INFO]  Batch 119 initialized 
2023-03-25 16:07:03,029 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:03,469 : [INFO]  ------------------------- Batch 119 training: round 1 -------------------------
2023-03-25 16:07:07,396 : [INFO]  ------------------------- Batch round 1, loss: 0.5413 -------------------------
2023-03-25 16:07:07,396 : [INFO]  ------------------------- Batch 119, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:07,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:07,401 : [INFO]  ------------------------- Batch 119 training: round 2 -------------------------
2023-03-25 16:07:09,538 : [INFO]  ------------------------- Batch round 2, loss: 0.5278 -------------------------
2023-03-25 16:07:09,539 : [INFO]  ------------------------- Batch 119, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:09,602 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:09,605 : [INFO]  ------------------------- Batch 119 training: round 3 -------------------------
2023-03-25 16:07:11,756 : [INFO]  ------------------------- Batch round 3, loss: 0.5143 -------------------------
2023-03-25 16:07:11,756 : [INFO]  ------------------------- Batch 119, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:11,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:11,821 : [INFO]  Batch number 119 model fetched from the server
2023-03-25 16:07:11,821 : [INFO]  ################ Batch 119: final global model evalution after 3 rounds ################
2023-03-25 16:07:13,160 : [INFO]  Batch 119: Training set : loss - 0.5122, accuracy - 0.7935, recall - 0.9783, AUC - 0.9404, F1 - 0.8257, precision - 0.7143, training time - -8.0 seconds
2023-03-25 16:07:13,160 : [INFO]  Batch 119: Testing set : loss - 0.5726, accuracy - 0.7206, recall - 0.902, AUC - 0.8677, F1 - 0.7635, precision - 0.6619
2023-03-25 16:07:13,173 : [INFO]  Batch 120 initialized 
2023-03-25 16:07:13,617 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:14,096 : [INFO]  ------------------------- Batch 120 training: round 1 -------------------------
2023-03-25 16:07:18,160 : [INFO]  ------------------------- Batch round 1, loss: 0.5442 -------------------------
2023-03-25 16:07:18,160 : [INFO]  ------------------------- Batch 120, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:18,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:18,166 : [INFO]  ------------------------- Batch 120 training: round 2 -------------------------
2023-03-25 16:07:20,429 : [INFO]  ------------------------- Batch round 2, loss: 0.5391 -------------------------
2023-03-25 16:07:20,429 : [INFO]  ------------------------- Batch 120, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:20,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:20,434 : [INFO]  ------------------------- Batch 120 training: round 3 -------------------------
2023-03-25 16:07:22,945 : [INFO]  ------------------------- Batch round 3, loss: 0.5282 -------------------------
2023-03-25 16:07:22,945 : [INFO]  ------------------------- Batch 120, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:22,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:22,949 : [INFO]  Batch number 120 model fetched from the server
2023-03-25 16:07:22,949 : [INFO]  ################ Batch 120: final global model evalution after 3 rounds ################
2023-03-25 16:07:24,304 : [INFO]  Batch 120: Training set : loss - 0.5209, accuracy - 0.7826, recall - 0.8804, AUC - 0.9008, F1 - 0.802, precision - 0.7364, training time - -9.0 seconds
2023-03-25 16:07:24,304 : [INFO]  Batch 120: Testing set : loss - 0.5607, accuracy - 0.7059, recall - 0.9216, AUC - 0.8922, F1 - 0.7581, precision - 0.6438
2023-03-25 16:07:24,310 : [INFO]  Batch 121 initialized 
2023-03-25 16:07:24,742 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:25,202 : [INFO]  ------------------------- Batch 121 training: round 1 -------------------------
2023-03-25 16:07:29,025 : [INFO]  ------------------------- Batch round 1, loss: 0.5356 -------------------------
2023-03-25 16:07:29,025 : [INFO]  ------------------------- Batch 121, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:29,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:29,357 : [INFO]  ------------------------- Batch 121 training: round 2 -------------------------
2023-03-25 16:07:31,460 : [INFO]  ------------------------- Batch round 2, loss: 0.531 -------------------------
2023-03-25 16:07:31,460 : [INFO]  ------------------------- Batch 121, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:31,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:31,544 : [INFO]  ------------------------- Batch 121 training: round 3 -------------------------
2023-03-25 16:07:33,663 : [INFO]  ------------------------- Batch round 3, loss: 0.5226 -------------------------
2023-03-25 16:07:33,663 : [INFO]  ------------------------- Batch 121, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:33,755 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:33,757 : [INFO]  Batch number 121 model fetched from the server
2023-03-25 16:07:33,757 : [INFO]  ################ Batch 121: final global model evalution after 3 rounds ################
2023-03-25 16:07:35,073 : [INFO]  Batch 121: Training set : loss - 0.5244, accuracy - 0.788, recall - 0.9891, AUC - 0.9086, F1 - 0.8235, precision - 0.7054, training time - -9.0 seconds
2023-03-25 16:07:35,073 : [INFO]  Batch 121: Testing set : loss - 0.5346, accuracy - 0.7402, recall - 0.9314, AUC - 0.9142, F1 - 0.7819, precision - 0.6738
2023-03-25 16:07:35,085 : [INFO]  Batch 122 initialized 
2023-03-25 16:07:35,510 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:36,002 : [INFO]  ------------------------- Batch 122 training: round 1 -------------------------
2023-03-25 16:07:40,096 : [INFO]  ------------------------- Batch round 1, loss: 0.5772 -------------------------
2023-03-25 16:07:40,096 : [INFO]  ------------------------- Batch 122, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:40,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:40,101 : [INFO]  ------------------------- Batch 122 training: round 2 -------------------------
2023-03-25 16:07:42,406 : [INFO]  ------------------------- Batch round 2, loss: 0.5649 -------------------------
2023-03-25 16:07:42,406 : [INFO]  ------------------------- Batch 122, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:42,409 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:42,411 : [INFO]  ------------------------- Batch 122 training: round 3 -------------------------
2023-03-25 16:07:44,694 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 16:07:44,694 : [INFO]  ------------------------- Batch 122, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:44,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:44,699 : [INFO]  Batch number 122 model fetched from the server
2023-03-25 16:07:44,699 : [INFO]  ################ Batch 122: final global model evalution after 3 rounds ################
2023-03-25 16:07:46,033 : [INFO]  Batch 122: Training set : loss - 0.5517, accuracy - 0.7554, recall - 0.9022, AUC - 0.8443, F1 - 0.7867, precision - 0.6975, training time - -9.0 seconds
2023-03-25 16:07:46,033 : [INFO]  Batch 122: Testing set : loss - 0.5457, accuracy - 0.7451, recall - 0.951, AUC - 0.8804, F1 - 0.7886, precision - 0.6736
2023-03-25 16:07:46,042 : [INFO]  Batch 123 initialized 
2023-03-25 16:07:46,467 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:46,935 : [INFO]  ------------------------- Batch 123 training: round 1 -------------------------
2023-03-25 16:07:50,948 : [INFO]  ------------------------- Batch round 1, loss: 0.5703 -------------------------
2023-03-25 16:07:50,948 : [INFO]  ------------------------- Batch 123, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:50,951 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:50,953 : [INFO]  ------------------------- Batch 123 training: round 2 -------------------------
2023-03-25 16:07:53,208 : [INFO]  ------------------------- Batch round 2, loss: 0.5562 -------------------------
2023-03-25 16:07:53,208 : [INFO]  ------------------------- Batch 123, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:53,211 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:53,214 : [INFO]  ------------------------- Batch 123 training: round 3 -------------------------
2023-03-25 16:07:55,490 : [INFO]  ------------------------- Batch round 3, loss: 0.5473 -------------------------
2023-03-25 16:07:55,490 : [INFO]  ------------------------- Batch 123, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:55,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:55,495 : [INFO]  Batch number 123 model fetched from the server
2023-03-25 16:07:55,495 : [INFO]  ################ Batch 123: final global model evalution after 3 rounds ################
2023-03-25 16:07:56,838 : [INFO]  Batch 123: Training set : loss - 0.5433, accuracy - 0.7826, recall - 0.913, AUC - 0.8697, F1 - 0.8077, precision - 0.7241, training time - -9.0 seconds
2023-03-25 16:07:56,838 : [INFO]  Batch 123: Testing set : loss - 0.5781, accuracy - 0.6912, recall - 0.902, AUC - 0.8508, F1 - 0.7449, precision - 0.6345
2023-03-25 16:07:56,846 : [INFO]  Batch 124 initialized 
2023-03-25 16:07:57,286 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:57,737 : [INFO]  ------------------------- Batch 124 training: round 1 -------------------------
2023-03-25 16:08:01,877 : [INFO]  ------------------------- Batch round 1, loss: 0.5853 -------------------------
2023-03-25 16:08:01,878 : [INFO]  ------------------------- Batch 124, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:01,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:01,882 : [INFO]  ------------------------- Batch 124 training: round 2 -------------------------
2023-03-25 16:08:04,214 : [INFO]  ------------------------- Batch round 2, loss: 0.5725 -------------------------
2023-03-25 16:08:04,214 : [INFO]  ------------------------- Batch 124, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:04,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:04,219 : [INFO]  ------------------------- Batch 124 training: round 3 -------------------------
2023-03-25 16:08:06,532 : [INFO]  ------------------------- Batch round 3, loss: 0.5658 -------------------------
2023-03-25 16:08:06,532 : [INFO]  ------------------------- Batch 124, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:06,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:06,537 : [INFO]  Batch number 124 model fetched from the server
2023-03-25 16:08:06,537 : [INFO]  ################ Batch 124: final global model evalution after 3 rounds ################
2023-03-25 16:08:07,935 : [INFO]  Batch 124: Training set : loss - 0.5554, accuracy - 0.7717, recall - 0.8587, AUC - 0.8315, F1 - 0.79, precision - 0.7315, training time - -9.0 seconds
2023-03-25 16:08:07,935 : [INFO]  Batch 124: Testing set : loss - 0.5565, accuracy - 0.7157, recall - 0.902, AUC - 0.8601, F1 - 0.7603, precision - 0.6571
2023-03-25 16:08:07,943 : [INFO]  Batch 125 initialized 
2023-03-25 16:08:08,370 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:08,832 : [INFO]  ------------------------- Batch 125 training: round 1 -------------------------
2023-03-25 16:08:12,936 : [INFO]  ------------------------- Batch round 1, loss: 0.5838 -------------------------
2023-03-25 16:08:12,936 : [INFO]  ------------------------- Batch 125, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:12,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:12,941 : [INFO]  ------------------------- Batch 125 training: round 2 -------------------------
2023-03-25 16:08:15,282 : [INFO]  ------------------------- Batch round 2, loss: 0.5665 -------------------------
2023-03-25 16:08:15,282 : [INFO]  ------------------------- Batch 125, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:15,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:15,287 : [INFO]  ------------------------- Batch 125 training: round 3 -------------------------
2023-03-25 16:08:17,623 : [INFO]  ------------------------- Batch round 3, loss: 0.5629 -------------------------
2023-03-25 16:08:17,623 : [INFO]  ------------------------- Batch 125, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:17,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:17,628 : [INFO]  Batch number 125 model fetched from the server
2023-03-25 16:08:17,628 : [INFO]  ################ Batch 125: final global model evalution after 3 rounds ################
2023-03-25 16:08:19,060 : [INFO]  Batch 125: Training set : loss - 0.5522, accuracy - 0.7663, recall - 0.9348, AUC - 0.879, F1 - 0.8, precision - 0.6992, training time - -9.0 seconds
2023-03-25 16:08:19,060 : [INFO]  Batch 125: Testing set : loss - 0.5866, accuracy - 0.7108, recall - 0.902, AUC - 0.8501, F1 - 0.7572, precision - 0.6525
2023-03-25 16:08:19,066 : [INFO]  Batch 126 initialized 
2023-03-25 16:08:19,521 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:19,991 : [INFO]  ------------------------- Batch 126 training: round 1 -------------------------
2023-03-25 16:08:24,089 : [INFO]  ------------------------- Batch round 1, loss: 0.6294 -------------------------
2023-03-25 16:08:24,089 : [INFO]  ------------------------- Batch 126, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:24,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:24,093 : [INFO]  ------------------------- Batch 126 training: round 2 -------------------------
2023-03-25 16:08:26,376 : [INFO]  ------------------------- Batch round 2, loss: 0.6157 -------------------------
2023-03-25 16:08:26,377 : [INFO]  ------------------------- Batch 126, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:26,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:26,381 : [INFO]  ------------------------- Batch 126 training: round 3 -------------------------
2023-03-25 16:08:28,620 : [INFO]  ------------------------- Batch round 3, loss: 0.6096 -------------------------
2023-03-25 16:08:28,620 : [INFO]  ------------------------- Batch 126, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:28,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:28,624 : [INFO]  Batch number 126 model fetched from the server
2023-03-25 16:08:28,624 : [INFO]  ################ Batch 126: final global model evalution after 3 rounds ################
2023-03-25 16:08:30,028 : [INFO]  Batch 126: Training set : loss - 0.6047, accuracy - 0.7011, recall - 0.8913, AUC - 0.8012, F1 - 0.7489, precision - 0.6457, training time - -9.0 seconds
2023-03-25 16:08:30,028 : [INFO]  Batch 126: Testing set : loss - 0.6216, accuracy - 0.6716, recall - 0.902, AUC - 0.7849, F1 - 0.7331, precision - 0.6174
2023-03-25 16:08:30,048 : [INFO]  Batch 127 initialized 
2023-03-25 16:08:30,528 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:30,986 : [INFO]  ------------------------- Batch 127 training: round 1 -------------------------
2023-03-25 16:08:34,961 : [INFO]  ------------------------- Batch round 1, loss: 0.5817 -------------------------
2023-03-25 16:08:34,961 : [INFO]  ------------------------- Batch 127, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:34,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:34,965 : [INFO]  ------------------------- Batch 127 training: round 2 -------------------------
2023-03-25 16:08:37,176 : [INFO]  ------------------------- Batch round 2, loss: 0.5736 -------------------------
2023-03-25 16:08:37,176 : [INFO]  ------------------------- Batch 127, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:37,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:37,181 : [INFO]  ------------------------- Batch 127 training: round 3 -------------------------
2023-03-25 16:08:39,408 : [INFO]  ------------------------- Batch round 3, loss: 0.5626 -------------------------
2023-03-25 16:08:39,408 : [INFO]  ------------------------- Batch 127, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:39,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:39,413 : [INFO]  Batch number 127 model fetched from the server
2023-03-25 16:08:39,413 : [INFO]  ################ Batch 127: final global model evalution after 3 rounds ################
2023-03-25 16:08:40,766 : [INFO]  Batch 127: Training set : loss - 0.567, accuracy - 0.7554, recall - 0.8587, AUC - 0.8032, F1 - 0.7783, precision - 0.7117, training time - -8.0 seconds
2023-03-25 16:08:40,766 : [INFO]  Batch 127: Testing set : loss - 0.6149, accuracy - 0.6618, recall - 0.7843, AUC - 0.7194, F1 - 0.6987, precision - 0.6299
2023-03-25 16:08:40,775 : [INFO]  Batch 128 initialized 
2023-03-25 16:08:41,210 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:41,678 : [INFO]  ------------------------- Batch 128 training: round 1 -------------------------
2023-03-25 16:08:45,616 : [INFO]  ------------------------- Batch round 1, loss: 0.5606 -------------------------
2023-03-25 16:08:45,616 : [INFO]  ------------------------- Batch 128, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:45,619 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:45,620 : [INFO]  ------------------------- Batch 128 training: round 2 -------------------------
2023-03-25 16:08:47,775 : [INFO]  ------------------------- Batch round 2, loss: 0.5566 -------------------------
2023-03-25 16:08:47,775 : [INFO]  ------------------------- Batch 128, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:47,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:47,781 : [INFO]  ------------------------- Batch 128 training: round 3 -------------------------
2023-03-25 16:08:50,154 : [INFO]  ------------------------- Batch round 3, loss: 0.5529 -------------------------
2023-03-25 16:08:50,154 : [INFO]  ------------------------- Batch 128, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:50,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:50,158 : [INFO]  Batch number 128 model fetched from the server
2023-03-25 16:08:50,158 : [INFO]  ################ Batch 128: final global model evalution after 3 rounds ################
2023-03-25 16:08:51,446 : [INFO]  Batch 128: Training set : loss - 0.5543, accuracy - 0.7446, recall - 0.913, AUC - 0.8627, F1 - 0.7814, precision - 0.6829, training time - -8.0 seconds
2023-03-25 16:08:51,446 : [INFO]  Batch 128: Testing set : loss - 0.5685, accuracy - 0.7402, recall - 0.8431, AUC - 0.8368, F1 - 0.7644, precision - 0.6992
2023-03-25 16:08:51,452 : [INFO]  Batch 129 initialized 
2023-03-25 16:08:51,922 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:52,383 : [INFO]  ------------------------- Batch 129 training: round 1 -------------------------
2023-03-25 16:08:56,350 : [INFO]  ------------------------- Batch round 1, loss: 0.5567 -------------------------
2023-03-25 16:08:56,351 : [INFO]  ------------------------- Batch 129, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:56,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:56,355 : [INFO]  ------------------------- Batch 129 training: round 2 -------------------------
2023-03-25 16:08:58,583 : [INFO]  ------------------------- Batch round 2, loss: 0.5471 -------------------------
2023-03-25 16:08:58,583 : [INFO]  ------------------------- Batch 129, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:58,586 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:58,588 : [INFO]  ------------------------- Batch 129 training: round 3 -------------------------
2023-03-25 16:09:00,836 : [INFO]  ------------------------- Batch round 3, loss: 0.5386 -------------------------
2023-03-25 16:09:00,836 : [INFO]  ------------------------- Batch 129, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:00,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:00,840 : [INFO]  Batch number 129 model fetched from the server
2023-03-25 16:09:00,840 : [INFO]  ################ Batch 129: final global model evalution after 3 rounds ################
2023-03-25 16:09:02,201 : [INFO]  Batch 129: Training set : loss - 0.5302, accuracy - 0.7935, recall - 0.9348, AUC - 0.8905, F1 - 0.819, precision - 0.7288, training time - -8.0 seconds
2023-03-25 16:09:02,201 : [INFO]  Batch 129: Testing set : loss - 0.5535, accuracy - 0.7402, recall - 0.9314, AUC - 0.8872, F1 - 0.7819, precision - 0.6738
2023-03-25 16:09:02,210 : [INFO]  Batch 130 initialized 
2023-03-25 16:09:02,644 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:03,126 : [INFO]  ------------------------- Batch 130 training: round 1 -------------------------
2023-03-25 16:09:07,134 : [INFO]  ------------------------- Batch round 1, loss: 0.5772 -------------------------
2023-03-25 16:09:07,135 : [INFO]  ------------------------- Batch 130, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:07,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:07,139 : [INFO]  ------------------------- Batch 130 training: round 2 -------------------------
2023-03-25 16:09:09,544 : [INFO]  ------------------------- Batch round 2, loss: 0.5628 -------------------------
2023-03-25 16:09:09,544 : [INFO]  ------------------------- Batch 130, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:09,547 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:09,548 : [INFO]  ------------------------- Batch 130 training: round 3 -------------------------
2023-03-25 16:09:11,721 : [INFO]  ------------------------- Batch round 3, loss: 0.5568 -------------------------
2023-03-25 16:09:11,721 : [INFO]  ------------------------- Batch 130, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:11,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:11,725 : [INFO]  Batch number 130 model fetched from the server
2023-03-25 16:09:11,725 : [INFO]  ################ Batch 130: final global model evalution after 3 rounds ################
2023-03-25 16:09:13,081 : [INFO]  Batch 130: Training set : loss - 0.5557, accuracy - 0.7174, recall - 0.8696, AUC - 0.8697, F1 - 0.7547, precision - 0.6667, training time - -9.0 seconds
2023-03-25 16:09:13,081 : [INFO]  Batch 130: Testing set : loss - 0.5762, accuracy - 0.7059, recall - 0.8431, AUC - 0.8163, F1 - 0.7414, precision - 0.6615
2023-03-25 16:09:13,090 : [INFO]  Batch 131 initialized 
2023-03-25 16:09:13,547 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:14,013 : [INFO]  ------------------------- Batch 131 training: round 1 -------------------------
2023-03-25 16:09:18,050 : [INFO]  ------------------------- Batch round 1, loss: 0.5667 -------------------------
2023-03-25 16:09:18,050 : [INFO]  ------------------------- Batch 131, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:18,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:18,055 : [INFO]  ------------------------- Batch 131 training: round 2 -------------------------
2023-03-25 16:09:20,288 : [INFO]  ------------------------- Batch round 2, loss: 0.5444 -------------------------
2023-03-25 16:09:20,288 : [INFO]  ------------------------- Batch 131, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:20,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:20,293 : [INFO]  ------------------------- Batch 131 training: round 3 -------------------------
2023-03-25 16:09:22,548 : [INFO]  ------------------------- Batch round 3, loss: 0.5374 -------------------------
2023-03-25 16:09:22,548 : [INFO]  ------------------------- Batch 131, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:22,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:22,552 : [INFO]  Batch number 131 model fetched from the server
2023-03-25 16:09:22,552 : [INFO]  ################ Batch 131: final global model evalution after 3 rounds ################
2023-03-25 16:09:23,924 : [INFO]  Batch 131: Training set : loss - 0.5366, accuracy - 0.7772, recall - 0.8913, AUC - 0.8798, F1 - 0.8, precision - 0.7257, training time - -9.0 seconds
2023-03-25 16:09:23,924 : [INFO]  Batch 131: Testing set : loss - 0.5749, accuracy - 0.6961, recall - 0.8922, AUC - 0.8502, F1 - 0.7459, precision - 0.6408
2023-03-25 16:09:23,936 : [INFO]  Batch 132 initialized 
2023-03-25 16:09:24,390 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:24,853 : [INFO]  ------------------------- Batch 132 training: round 1 -------------------------
2023-03-25 16:09:28,899 : [INFO]  ------------------------- Batch round 1, loss: 0.5737 -------------------------
2023-03-25 16:09:28,899 : [INFO]  ------------------------- Batch 132, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:28,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:28,903 : [INFO]  ------------------------- Batch 132 training: round 2 -------------------------
2023-03-25 16:09:31,126 : [INFO]  ------------------------- Batch round 2, loss: 0.554 -------------------------
2023-03-25 16:09:31,126 : [INFO]  ------------------------- Batch 132, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:31,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:31,326 : [INFO]  ------------------------- Batch 132 training: round 3 -------------------------
2023-03-25 16:09:33,558 : [INFO]  ------------------------- Batch round 3, loss: 0.5481 -------------------------
2023-03-25 16:09:33,558 : [INFO]  ------------------------- Batch 132, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:33,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:33,564 : [INFO]  Batch number 132 model fetched from the server
2023-03-25 16:09:33,564 : [INFO]  ################ Batch 132: final global model evalution after 3 rounds ################
2023-03-25 16:09:34,941 : [INFO]  Batch 132: Training set : loss - 0.5406, accuracy - 0.7446, recall - 0.913, AUC - 0.8862, F1 - 0.7814, precision - 0.6829, training time - -9.0 seconds
2023-03-25 16:09:34,942 : [INFO]  Batch 132: Testing set : loss - 0.5827, accuracy - 0.6912, recall - 0.902, AUC - 0.8723, F1 - 0.7449, precision - 0.6345
2023-03-25 16:09:34,948 : [INFO]  Batch 133 initialized 
2023-03-25 16:09:35,388 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:35,861 : [INFO]  ------------------------- Batch 133 training: round 1 -------------------------
2023-03-25 16:09:39,777 : [INFO]  ------------------------- Batch round 1, loss: 0.5987 -------------------------
2023-03-25 16:09:39,777 : [INFO]  ------------------------- Batch 133, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:39,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:39,782 : [INFO]  ------------------------- Batch 133 training: round 2 -------------------------
2023-03-25 16:09:41,935 : [INFO]  ------------------------- Batch round 2, loss: 0.58 -------------------------
2023-03-25 16:09:41,935 : [INFO]  ------------------------- Batch 133, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:41,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:41,940 : [INFO]  ------------------------- Batch 133 training: round 3 -------------------------
2023-03-25 16:09:44,091 : [INFO]  ------------------------- Batch round 3, loss: 0.566 -------------------------
2023-03-25 16:09:44,091 : [INFO]  ------------------------- Batch 133, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:44,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:44,096 : [INFO]  Batch number 133 model fetched from the server
2023-03-25 16:09:44,096 : [INFO]  ################ Batch 133: final global model evalution after 3 rounds ################
2023-03-25 16:09:45,439 : [INFO]  Batch 133: Training set : loss - 0.5694, accuracy - 0.7609, recall - 0.9348, AUC - 0.8441, F1 - 0.7963, precision - 0.6935, training time - -8.0 seconds
2023-03-25 16:09:45,440 : [INFO]  Batch 133: Testing set : loss - 0.545, accuracy - 0.7255, recall - 0.9608, AUC - 0.9245, F1 - 0.7778, precision - 0.6533
2023-03-25 16:09:45,446 : [INFO]  Batch 134 initialized 
2023-03-25 16:09:45,878 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:46,382 : [INFO]  ------------------------- Batch 134 training: round 1 -------------------------
2023-03-25 16:09:50,312 : [INFO]  ------------------------- Batch round 1, loss: 0.5541 -------------------------
2023-03-25 16:09:50,312 : [INFO]  ------------------------- Batch 134, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:50,499 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:50,501 : [INFO]  ------------------------- Batch 134 training: round 2 -------------------------
2023-03-25 16:09:52,721 : [INFO]  ------------------------- Batch round 2, loss: 0.5412 -------------------------
2023-03-25 16:09:52,721 : [INFO]  ------------------------- Batch 134, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:52,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:52,726 : [INFO]  ------------------------- Batch 134 training: round 3 -------------------------
2023-03-25 16:09:54,962 : [INFO]  ------------------------- Batch round 3, loss: 0.5319 -------------------------
2023-03-25 16:09:54,962 : [INFO]  ------------------------- Batch 134, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:54,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:54,967 : [INFO]  Batch number 134 model fetched from the server
2023-03-25 16:09:54,967 : [INFO]  ################ Batch 134: final global model evalution after 3 rounds ################
2023-03-25 16:09:56,356 : [INFO]  Batch 134: Training set : loss - 0.5296, accuracy - 0.788, recall - 0.9239, AUC - 0.8926, F1 - 0.8134, precision - 0.7265, training time - -9.0 seconds
2023-03-25 16:09:56,356 : [INFO]  Batch 134: Testing set : loss - 0.578, accuracy - 0.6961, recall - 0.902, AUC - 0.8522, F1 - 0.748, precision - 0.6389
2023-03-25 16:09:56,362 : [INFO]  Batch 135 initialized 
2023-03-25 16:09:56,789 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:57,284 : [INFO]  ------------------------- Batch 135 training: round 1 -------------------------
2023-03-25 16:10:01,252 : [INFO]  ------------------------- Batch round 1, loss: 0.5124 -------------------------
2023-03-25 16:10:01,252 : [INFO]  ------------------------- Batch 135, round 1: Sent local model to the server -------------------------
2023-03-25 16:10:01,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:01,257 : [INFO]  ------------------------- Batch 135 training: round 2 -------------------------
2023-03-25 16:10:03,508 : [INFO]  ------------------------- Batch round 2, loss: 0.5131 -------------------------
2023-03-25 16:10:03,508 : [INFO]  ------------------------- Batch 135, round 2: Sent local model to the server -------------------------
2023-03-25 16:10:03,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:03,513 : [INFO]  ------------------------- Batch 135 training: round 3 -------------------------
2023-03-25 16:10:05,729 : [INFO]  ------------------------- Batch round 3, loss: 0.5094 -------------------------
2023-03-25 16:10:05,729 : [INFO]  ------------------------- Batch 135, round 3: Sent local model to the server -------------------------
2023-03-25 16:10:05,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:05,734 : [INFO]  Batch number 135 model fetched from the server
2023-03-25 16:10:05,734 : [INFO]  ################ Batch 135: final global model evalution after 3 rounds ################
2023-03-25 16:10:07,070 : [INFO]  Batch 135: Training set : loss - 0.5066, accuracy - 0.8207, recall - 0.9565, AUC - 0.9454, F1 - 0.8421, precision - 0.7521, training time - -8.0 seconds
2023-03-25 16:10:07,070 : [INFO]  Batch 135: Testing set : loss - 0.5838, accuracy - 0.6912, recall - 0.9412, AUC - 0.8944, F1 - 0.7529, precision - 0.6275
2023-03-25 16:10:07,077 : [INFO]  Batch 136 initialized 
2023-03-25 16:10:07,500 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:10:08,002 : [INFO]  ------------------------- Batch 136 training: round 1 -------------------------
2023-03-25 16:10:11,986 : [INFO]  ------------------------- Batch round 1, loss: 0.5661 -------------------------
2023-03-25 16:10:11,987 : [INFO]  ------------------------- Batch 136, round 1: Sent local model to the server -------------------------
2023-03-25 16:10:11,990 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:11,991 : [INFO]  ------------------------- Batch 136 training: round 2 -------------------------
2023-03-25 16:10:14,159 : [INFO]  ------------------------- Batch round 2, loss: 0.5455 -------------------------
2023-03-25 16:10:14,159 : [INFO]  ------------------------- Batch 136, round 2: Sent local model to the server -------------------------
2023-03-25 16:10:14,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:14,345 : [INFO]  ------------------------- Batch 136 training: round 3 -------------------------
2023-03-25 16:10:16,634 : [INFO]  ------------------------- Batch round 3, loss: 0.5412 -------------------------
2023-03-25 16:10:16,634 : [INFO]  ------------------------- Batch 136, round 3: Sent local model to the server -------------------------
2023-03-25 16:10:16,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:16,640 : [INFO]  Batch number 136 model fetched from the server
2023-03-25 16:10:16,640 : [INFO]  ################ Batch 136: final global model evalution after 3 rounds ################
2023-03-25 16:10:18,123 : [INFO]  Batch 136: Training set : loss - 0.5318, accuracy - 0.7772, recall - 0.9239, AUC - 0.8885, F1 - 0.8057, precision - 0.7143, training time - -9.0 seconds
2023-03-25 16:10:18,123 : [INFO]  Batch 136: Testing set : loss - 0.5836, accuracy - 0.6569, recall - 0.8824, AUC - 0.8476, F1 - 0.72, precision - 0.6081
2023-03-25 16:10:18,132 : [INFO]  Batch 137 initialized 
2023-03-25 16:10:18,745 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:10:19,295 : [INFO]  ------------------------- Batch 137 training: round 1 -------------------------
2023-03-25 16:10:26,555 : [INFO]  ------------------------- Batch round 1, loss: 0.5546 -------------------------
2023-03-25 16:10:26,556 : [INFO]  ------------------------- Batch 137, round 1: Sent local model to the server -------------------------
2023-03-25 16:10:26,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
