2023-03-25 13:26:30,464 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 13:26:30,465 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 1, epochs 6
2023-03-25 13:26:34,016 : [INFO]  Model initialized for training
2023-03-25 13:26:50,812 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:26:50,951 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:26:50,952 : [INFO]  Connected to the server
2023-03-25 13:26:51,038 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:26:51,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:51,047 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:26:51,047 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:27:16,926 : [INFO]  ------------------------- Training round 1, loss: 0.6768 -------------------------
2023-03-25 13:27:16,926 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:27:16,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:27:16,930 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:27:41,869 : [INFO]  ------------------------- Training round 2, loss: 0.6358 -------------------------
2023-03-25 13:27:41,870 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:27:42,129 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:27:42,131 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:28:03,950 : [INFO]  ------------------------- Training round 3, loss: 0.6146 -------------------------
2023-03-25 13:28:03,951 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:28:04,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:28:04,382 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:28:27,044 : [INFO]  ------------------------- Training round 4, loss: 0.606 -------------------------
2023-03-25 13:28:27,045 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:28:27,534 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:28:27,536 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:28:50,772 : [INFO]  ------------------------- Training round 5, loss: 0.6017 -------------------------
2023-03-25 13:28:50,772 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:28:51,130 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:28:51,132 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:29:35,218 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.82, F1 - 0.74, precision - 0.64, training time - -120.0 seconds
2023-03-25 13:29:35,218 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 13:29:35,224 : [INFO]  Batch 1 initialized 
2023-03-25 13:29:35,639 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:29:35,744 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:29:35,744 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:29:39,850 : [INFO]  ------------------------- Batch round 1, loss: 0.61 -------------------------
2023-03-25 13:29:39,850 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:29:40,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:40,698 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:29:43,048 : [INFO]  ------------------------- Batch round 2, loss: 0.5883 -------------------------
2023-03-25 13:29:43,049 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:29:43,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:43,054 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:29:45,344 : [INFO]  ------------------------- Batch round 3, loss: 0.5766 -------------------------
2023-03-25 13:29:45,344 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:29:45,347 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:45,349 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:29:45,349 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:29:46,776 : [INFO]  Batch 1: Training set : loss - 0.582, accuracy - 0.7391, recall - 0.9348, AUC - 0.8347, F1 - 0.7818, precision - 0.6719, training time - -10.0 seconds
2023-03-25 13:29:46,776 : [INFO]  Batch 1: Testing set : loss - 0.5613, accuracy - 0.7598, recall - 0.8725, AUC - 0.86, F1 - 0.7841, precision - 0.712
2023-03-25 13:29:46,783 : [INFO]  Batch 2 initialized 
2023-03-25 13:29:47,293 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:29:47,490 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:29:51,436 : [INFO]  ------------------------- Batch round 1, loss: 0.5619 -------------------------
2023-03-25 13:29:51,436 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:29:51,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:51,474 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:29:53,572 : [INFO]  ------------------------- Batch round 2, loss: 0.5572 -------------------------
2023-03-25 13:29:53,572 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:29:53,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:53,593 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:29:55,697 : [INFO]  ------------------------- Batch round 3, loss: 0.5482 -------------------------
2023-03-25 13:29:55,697 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:29:55,704 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:55,706 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:29:55,706 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:29:57,024 : [INFO]  Batch 2: Training set : loss - 0.5505, accuracy - 0.7826, recall - 0.9565, AUC - 0.8748, F1 - 0.8148, precision - 0.7097, training time - -8.0 seconds
2023-03-25 13:29:57,024 : [INFO]  Batch 2: Testing set : loss - 0.5668, accuracy - 0.7402, recall - 0.8922, AUC - 0.8633, F1 - 0.7745, precision - 0.6842
2023-03-25 13:29:57,031 : [INFO]  Batch 3 initialized 
2023-03-25 13:29:57,458 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:29:57,695 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:30:01,674 : [INFO]  ------------------------- Batch round 1, loss: 0.5394 -------------------------
2023-03-25 13:30:01,674 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:01,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:01,753 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:30:04,028 : [INFO]  ------------------------- Batch round 2, loss: 0.5356 -------------------------
2023-03-25 13:30:04,028 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:04,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:04,119 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:30:06,460 : [INFO]  ------------------------- Batch round 3, loss: 0.5297 -------------------------
2023-03-25 13:30:06,460 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:06,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:06,465 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:30:06,465 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:30:07,725 : [INFO]  Batch 3: Training set : loss - 0.5294, accuracy - 0.7989, recall - 0.8913, AUC - 0.861, F1 - 0.8159, precision - 0.7523, training time - -9.0 seconds
2023-03-25 13:30:07,725 : [INFO]  Batch 3: Testing set : loss - 0.5605, accuracy - 0.7451, recall - 0.951, AUC - 0.856, F1 - 0.7886, precision - 0.6736
2023-03-25 13:30:07,733 : [INFO]  Batch 4 initialized 
2023-03-25 13:30:08,167 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:08,378 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 13:30:12,211 : [INFO]  ------------------------- Batch round 1, loss: 0.5484 -------------------------
2023-03-25 13:30:12,211 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:12,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:12,375 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 13:30:14,341 : [INFO]  ------------------------- Batch round 2, loss: 0.5402 -------------------------
2023-03-25 13:30:14,341 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:14,665 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:14,667 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 13:30:16,633 : [INFO]  ------------------------- Batch round 3, loss: 0.5341 -------------------------
2023-03-25 13:30:16,633 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:16,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:16,645 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 13:30:16,645 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 13:30:17,986 : [INFO]  Batch 4: Training set : loss - 0.5257, accuracy - 0.7717, recall - 0.9457, AUC - 0.9083, F1 - 0.8056, precision - 0.7016, training time - -8.0 seconds
2023-03-25 13:30:17,986 : [INFO]  Batch 4: Testing set : loss - 0.5827, accuracy - 0.6667, recall - 0.9216, AUC - 0.8612, F1 - 0.7344, precision - 0.6104
2023-03-25 13:30:17,991 : [INFO]  Batch 5 initialized 
2023-03-25 13:30:18,443 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:18,672 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 13:30:22,643 : [INFO]  ------------------------- Batch round 1, loss: 0.5455 -------------------------
2023-03-25 13:30:22,643 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:22,646 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:22,648 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 13:30:24,792 : [INFO]  ------------------------- Batch round 2, loss: 0.5357 -------------------------
2023-03-25 13:30:24,792 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:24,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:24,797 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 13:30:26,895 : [INFO]  ------------------------- Batch round 3, loss: 0.5297 -------------------------
2023-03-25 13:30:26,895 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:26,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:26,900 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 13:30:26,900 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 13:30:28,206 : [INFO]  Batch 5: Training set : loss - 0.5252, accuracy - 0.8043, recall - 0.9565, AUC - 0.9266, F1 - 0.8302, precision - 0.7333, training time - -8.0 seconds
2023-03-25 13:30:28,206 : [INFO]  Batch 5: Testing set : loss - 0.5896, accuracy - 0.6667, recall - 0.8333, AUC - 0.8079, F1 - 0.7143, precision - 0.625
2023-03-25 13:30:28,212 : [INFO]  Batch 6 initialized 
2023-03-25 13:30:28,651 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:28,904 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 13:30:32,807 : [INFO]  ------------------------- Batch round 1, loss: 0.5681 -------------------------
2023-03-25 13:30:32,807 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:32,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:32,894 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 13:30:34,933 : [INFO]  ------------------------- Batch round 2, loss: 0.5569 -------------------------
2023-03-25 13:30:34,933 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:34,999 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:35,001 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 13:30:37,110 : [INFO]  ------------------------- Batch round 3, loss: 0.5559 -------------------------
2023-03-25 13:30:37,111 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:37,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:37,164 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 13:30:37,164 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 13:30:38,447 : [INFO]  Batch 6: Training set : loss - 0.5538, accuracy - 0.7772, recall - 0.9565, AUC - 0.8868, F1 - 0.8111, precision - 0.704, training time - -8.0 seconds
2023-03-25 13:30:38,447 : [INFO]  Batch 6: Testing set : loss - 0.561, accuracy - 0.7696, recall - 0.9216, AUC - 0.8798, F1 - 0.8, precision - 0.7068
2023-03-25 13:30:38,452 : [INFO]  Batch 7 initialized 
2023-03-25 13:30:38,882 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:39,124 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 13:30:43,299 : [INFO]  ------------------------- Batch round 1, loss: 0.5732 -------------------------
2023-03-25 13:30:43,299 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:43,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:43,305 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 13:30:45,493 : [INFO]  ------------------------- Batch round 2, loss: 0.5638 -------------------------
2023-03-25 13:30:45,494 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:45,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:45,498 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 13:30:47,571 : [INFO]  ------------------------- Batch round 3, loss: 0.5587 -------------------------
2023-03-25 13:30:47,571 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:47,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:47,631 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 13:30:47,631 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 13:30:48,969 : [INFO]  Batch 7: Training set : loss - 0.5566, accuracy - 0.7717, recall - 0.9239, AUC - 0.8796, F1 - 0.8019, precision - 0.7083, training time - -9.0 seconds
2023-03-25 13:30:48,970 : [INFO]  Batch 7: Testing set : loss - 0.5944, accuracy - 0.6961, recall - 0.8137, AUC - 0.8103, F1 - 0.7281, precision - 0.6587
2023-03-25 13:30:48,976 : [INFO]  Batch 8 initialized 
2023-03-25 13:30:49,431 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:49,687 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 13:30:53,686 : [INFO]  ------------------------- Batch round 1, loss: 0.5905 -------------------------
2023-03-25 13:30:53,687 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:53,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:53,715 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 13:30:55,801 : [INFO]  ------------------------- Batch round 2, loss: 0.572 -------------------------
2023-03-25 13:30:55,801 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:55,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:55,826 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 13:30:57,932 : [INFO]  ------------------------- Batch round 3, loss: 0.5595 -------------------------
2023-03-25 13:30:57,932 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:57,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:57,959 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 13:30:57,959 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 13:30:59,251 : [INFO]  Batch 8: Training set : loss - 0.5655, accuracy - 0.7337, recall - 0.8696, AUC - 0.8443, F1 - 0.7656, precision - 0.6838, training time - -8.0 seconds
2023-03-25 13:30:59,251 : [INFO]  Batch 8: Testing set : loss - 0.5755, accuracy - 0.7108, recall - 0.8824, AUC - 0.8286, F1 - 0.7531, precision - 0.6569
2023-03-25 13:30:59,257 : [INFO]  Batch 9 initialized 
2023-03-25 13:30:59,687 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:59,979 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 13:31:03,932 : [INFO]  ------------------------- Batch round 1, loss: 0.5532 -------------------------
2023-03-25 13:31:03,932 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:04,141 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:04,143 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 13:31:06,939 : [INFO]  ------------------------- Batch round 2, loss: 0.5453 -------------------------
2023-03-25 13:31:06,939 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:07,064 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:07,066 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 13:31:09,216 : [INFO]  ------------------------- Batch round 3, loss: 0.5342 -------------------------
2023-03-25 13:31:09,216 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:09,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:09,394 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 13:31:09,394 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 13:31:10,706 : [INFO]  Batch 9: Training set : loss - 0.5322, accuracy - 0.7772, recall - 0.9348, AUC - 0.911, F1 - 0.8075, precision - 0.7107, training time - -9.0 seconds
2023-03-25 13:31:10,706 : [INFO]  Batch 9: Testing set : loss - 0.5524, accuracy - 0.6961, recall - 0.8627, AUC - 0.8718, F1 - 0.7395, precision - 0.6471
2023-03-25 13:31:10,712 : [INFO]  Batch 10 initialized 
2023-03-25 13:31:11,152 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:11,384 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 13:31:16,888 : [INFO]  ------------------------- Batch round 1, loss: 0.5559 -------------------------
2023-03-25 13:31:16,888 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:17,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:17,027 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 13:31:19,190 : [INFO]  ------------------------- Batch round 2, loss: 0.5417 -------------------------
2023-03-25 13:31:19,190 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:19,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:19,304 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 13:31:21,407 : [INFO]  ------------------------- Batch round 3, loss: 0.5433 -------------------------
2023-03-25 13:31:21,407 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:21,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:21,557 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 13:31:21,557 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 13:31:23,156 : [INFO]  Batch 10: Training set : loss - 0.5418, accuracy - 0.7609, recall - 0.9783, AUC - 0.9036, F1 - 0.8036, precision - 0.6818, training time - -10.0 seconds
2023-03-25 13:31:23,156 : [INFO]  Batch 10: Testing set : loss - 0.5449, accuracy - 0.7451, recall - 0.9216, AUC - 0.8978, F1 - 0.7833, precision - 0.6812
2023-03-25 13:31:23,162 : [INFO]  Batch 11 initialized 
2023-03-25 13:31:23,590 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:23,831 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 13:31:27,631 : [INFO]  ------------------------- Batch round 1, loss: 0.5722 -------------------------
2023-03-25 13:31:27,631 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:27,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:27,715 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 13:31:30,769 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-25 13:31:30,769 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:30,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:30,774 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 13:31:32,918 : [INFO]  ------------------------- Batch round 3, loss: 0.562 -------------------------
2023-03-25 13:31:32,918 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:32,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:32,957 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 13:31:32,958 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 13:31:34,379 : [INFO]  Batch 11: Training set : loss - 0.5646, accuracy - 0.75, recall - 0.9239, AUC - 0.869, F1 - 0.787, precision - 0.6855, training time - -9.0 seconds
2023-03-25 13:31:34,379 : [INFO]  Batch 11: Testing set : loss - 0.5561, accuracy - 0.7206, recall - 0.9118, AUC - 0.8946, F1 - 0.7654, precision - 0.6596
2023-03-25 13:31:34,387 : [INFO]  Batch 12 initialized 
2023-03-25 13:31:34,824 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:35,095 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 13:31:39,227 : [INFO]  ------------------------- Batch round 1, loss: 0.5666 -------------------------
2023-03-25 13:31:39,227 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:39,230 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:39,232 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 13:31:41,434 : [INFO]  ------------------------- Batch round 2, loss: 0.5615 -------------------------
2023-03-25 13:31:41,434 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:41,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:41,647 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 13:31:44,010 : [INFO]  ------------------------- Batch round 3, loss: 0.5554 -------------------------
2023-03-25 13:31:44,010 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:44,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:44,017 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 13:31:44,017 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 13:31:45,428 : [INFO]  Batch 12: Training set : loss - 0.5517, accuracy - 0.7446, recall - 0.8913, AUC - 0.8849, F1 - 0.7773, precision - 0.6891, training time - -9.0 seconds
2023-03-25 13:31:45,429 : [INFO]  Batch 12: Testing set : loss - 0.6076, accuracy - 0.6814, recall - 0.8235, AUC - 0.7894, F1 - 0.721, precision - 0.6412
2023-03-25 13:31:45,437 : [INFO]  Batch 13 initialized 
2023-03-25 13:31:45,882 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:46,146 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 13:31:50,645 : [INFO]  ------------------------- Batch round 1, loss: 0.6044 -------------------------
2023-03-25 13:31:50,645 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:50,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:50,817 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 13:31:53,040 : [INFO]  ------------------------- Batch round 2, loss: 0.5903 -------------------------
2023-03-25 13:31:53,040 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:53,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:53,067 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 13:31:55,256 : [INFO]  ------------------------- Batch round 3, loss: 0.5866 -------------------------
2023-03-25 13:31:55,256 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:55,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:55,270 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 13:31:55,270 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 13:31:56,591 : [INFO]  Batch 13: Training set : loss - 0.5825, accuracy - 0.7228, recall - 0.8696, AUC - 0.8238, F1 - 0.7583, precision - 0.6723, training time - -9.0 seconds
2023-03-25 13:31:56,591 : [INFO]  Batch 13: Testing set : loss - 0.5968, accuracy - 0.6569, recall - 0.8039, AUC - 0.8102, F1 - 0.7009, precision - 0.6212
2023-03-25 13:31:56,597 : [INFO]  Batch 14 initialized 
2023-03-25 13:31:57,052 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:57,316 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 13:32:02,378 : [INFO]  ------------------------- Batch round 1, loss: 0.5526 -------------------------
2023-03-25 13:32:02,378 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:02,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:02,384 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 13:32:04,681 : [INFO]  ------------------------- Batch round 2, loss: 0.539 -------------------------
2023-03-25 13:32:04,681 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:04,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:04,686 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 13:32:06,754 : [INFO]  ------------------------- Batch round 3, loss: 0.5343 -------------------------
2023-03-25 13:32:06,754 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:06,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:06,759 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 13:32:06,759 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 13:32:08,077 : [INFO]  Batch 14: Training set : loss - 0.532, accuracy - 0.8043, recall - 0.9239, AUC - 0.884, F1 - 0.8252, precision - 0.7456, training time - -9.0 seconds
2023-03-25 13:32:08,077 : [INFO]  Batch 14: Testing set : loss - 0.5643, accuracy - 0.7059, recall - 0.8824, AUC - 0.8662, F1 - 0.75, precision - 0.6522
2023-03-25 13:32:08,090 : [INFO]  Batch 15 initialized 
2023-03-25 13:32:08,554 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:08,845 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 13:32:13,228 : [INFO]  ------------------------- Batch round 1, loss: 0.5685 -------------------------
2023-03-25 13:32:13,228 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:13,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:13,233 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 13:32:15,392 : [INFO]  ------------------------- Batch round 2, loss: 0.5561 -------------------------
2023-03-25 13:32:15,393 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:15,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:15,398 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 13:32:17,739 : [INFO]  ------------------------- Batch round 3, loss: 0.5478 -------------------------
2023-03-25 13:32:17,739 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:17,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:17,748 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 13:32:17,748 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 13:32:19,837 : [INFO]  Batch 15: Training set : loss - 0.5428, accuracy - 0.7717, recall - 0.9348, AUC - 0.8922, F1 - 0.8037, precision - 0.7049, training time - -9.0 seconds
2023-03-25 13:32:19,838 : [INFO]  Batch 15: Testing set : loss - 0.5838, accuracy - 0.6667, recall - 0.8137, AUC - 0.8395, F1 - 0.7094, precision - 0.6288
2023-03-25 13:32:19,849 : [INFO]  Batch 16 initialized 
2023-03-25 13:32:20,294 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:20,562 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 13:32:24,542 : [INFO]  ------------------------- Batch round 1, loss: 0.5585 -------------------------
2023-03-25 13:32:24,542 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:24,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:24,632 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 13:32:26,670 : [INFO]  ------------------------- Batch round 2, loss: 0.5483 -------------------------
2023-03-25 13:32:26,670 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:26,791 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:26,793 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 13:32:28,799 : [INFO]  ------------------------- Batch round 3, loss: 0.5404 -------------------------
2023-03-25 13:32:28,800 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:28,912 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:28,913 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 13:32:28,913 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 13:32:30,241 : [INFO]  Batch 16: Training set : loss - 0.5377, accuracy - 0.7609, recall - 0.9239, AUC - 0.9025, F1 - 0.7944, precision - 0.6967, training time - -8.0 seconds
2023-03-25 13:32:30,241 : [INFO]  Batch 16: Testing set : loss - 0.5391, accuracy - 0.7549, recall - 0.9412, AUC - 0.8988, F1 - 0.7934, precision - 0.6857
2023-03-25 13:32:30,253 : [INFO]  Batch 17 initialized 
2023-03-25 13:32:30,704 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:30,993 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 13:32:35,053 : [INFO]  ------------------------- Batch round 1, loss: 0.5559 -------------------------
2023-03-25 13:32:35,053 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:35,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:35,159 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 13:32:37,697 : [INFO]  ------------------------- Batch round 2, loss: 0.5491 -------------------------
2023-03-25 13:32:37,697 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:37,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:37,702 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 13:32:39,834 : [INFO]  ------------------------- Batch round 3, loss: 0.5416 -------------------------
2023-03-25 13:32:39,834 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:39,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:39,879 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 13:32:39,879 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 13:32:41,344 : [INFO]  Batch 17: Training set : loss - 0.5363, accuracy - 0.7772, recall - 0.9239, AUC - 0.8948, F1 - 0.8057, precision - 0.7143, training time - -9.0 seconds
2023-03-25 13:32:41,345 : [INFO]  Batch 17: Testing set : loss - 0.5823, accuracy - 0.701, recall - 0.8725, AUC - 0.8569, F1 - 0.7448, precision - 0.6496
2023-03-25 13:32:41,355 : [INFO]  Batch 18 initialized 
2023-03-25 13:32:41,840 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:42,111 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 13:32:47,041 : [INFO]  ------------------------- Batch round 1, loss: 0.5662 -------------------------
2023-03-25 13:32:47,041 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:47,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:47,247 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 13:32:49,491 : [INFO]  ------------------------- Batch round 2, loss: 0.5558 -------------------------
2023-03-25 13:32:49,492 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:49,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:49,723 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 13:32:51,722 : [INFO]  ------------------------- Batch round 3, loss: 0.5464 -------------------------
2023-03-25 13:32:51,722 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:51,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:51,921 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 13:32:51,921 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 13:32:53,304 : [INFO]  Batch 18: Training set : loss - 0.5554, accuracy - 0.7609, recall - 0.9457, AUC - 0.858, F1 - 0.7982, precision - 0.6905, training time - -10.0 seconds
2023-03-25 13:32:53,304 : [INFO]  Batch 18: Testing set : loss - 0.5837, accuracy - 0.6814, recall - 0.9314, AUC - 0.8441, F1 - 0.7451, precision - 0.6209
2023-03-25 13:32:53,316 : [INFO]  Batch 19 initialized 
2023-03-25 13:32:53,816 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:54,103 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 13:32:58,325 : [INFO]  ------------------------- Batch round 1, loss: 0.5705 -------------------------
2023-03-25 13:32:58,325 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:58,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:58,330 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 13:33:00,612 : [INFO]  ------------------------- Batch round 2, loss: 0.5645 -------------------------
2023-03-25 13:33:00,612 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:00,727 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:00,729 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 13:33:02,804 : [INFO]  ------------------------- Batch round 3, loss: 0.5536 -------------------------
2023-03-25 13:33:02,804 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:02,865 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:02,867 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 13:33:02,867 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 13:33:04,244 : [INFO]  Batch 19: Training set : loss - 0.5599, accuracy - 0.7446, recall - 0.8587, AUC - 0.8303, F1 - 0.7707, precision - 0.6991, training time - -9.0 seconds
2023-03-25 13:33:04,245 : [INFO]  Batch 19: Testing set : loss - 0.604, accuracy - 0.6667, recall - 0.8235, AUC - 0.803, F1 - 0.7119, precision - 0.6269
2023-03-25 13:33:04,253 : [INFO]  Batch 20 initialized 
2023-03-25 13:33:04,713 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:05,016 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 13:33:09,062 : [INFO]  ------------------------- Batch round 1, loss: 0.5526 -------------------------
2023-03-25 13:33:09,062 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:09,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:09,160 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 13:33:11,229 : [INFO]  ------------------------- Batch round 2, loss: 0.5407 -------------------------
2023-03-25 13:33:11,229 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:11,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:11,376 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 13:33:14,772 : [INFO]  ------------------------- Batch round 3, loss: 0.5371 -------------------------
2023-03-25 13:33:14,772 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:14,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:14,874 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 13:33:14,874 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 13:33:16,214 : [INFO]  Batch 20: Training set : loss - 0.5373, accuracy - 0.7554, recall - 0.9891, AUC - 0.9341, F1 - 0.8018, precision - 0.6741, training time - -10.0 seconds
2023-03-25 13:33:16,214 : [INFO]  Batch 20: Testing set : loss - 0.5657, accuracy - 0.7304, recall - 0.9216, AUC - 0.8738, F1 - 0.7737, precision - 0.6667
2023-03-25 13:33:16,225 : [INFO]  Batch 21 initialized 
2023-03-25 13:33:16,637 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:16,915 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 13:33:21,012 : [INFO]  ------------------------- Batch round 1, loss: 0.5817 -------------------------
2023-03-25 13:33:21,012 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:21,171 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:21,173 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 13:33:23,233 : [INFO]  ------------------------- Batch round 2, loss: 0.569 -------------------------
2023-03-25 13:33:23,233 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:23,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:23,298 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 13:33:25,637 : [INFO]  ------------------------- Batch round 3, loss: 0.5625 -------------------------
2023-03-25 13:33:25,638 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:25,708 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:25,710 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 13:33:25,710 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 13:33:26,985 : [INFO]  Batch 21: Training set : loss - 0.5693, accuracy - 0.7554, recall - 0.9239, AUC - 0.8052, F1 - 0.7907, precision - 0.6911, training time - -9.0 seconds
2023-03-25 13:33:26,985 : [INFO]  Batch 21: Testing set : loss - 0.556, accuracy - 0.7451, recall - 0.8922, AUC - 0.8481, F1 - 0.7778, precision - 0.6894
2023-03-25 13:33:26,995 : [INFO]  Batch 22 initialized 
2023-03-25 13:33:27,455 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:27,750 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 13:33:32,001 : [INFO]  ------------------------- Batch round 1, loss: 0.6051 -------------------------
2023-03-25 13:33:32,001 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:32,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:32,017 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 13:33:34,402 : [INFO]  ------------------------- Batch round 2, loss: 0.5862 -------------------------
2023-03-25 13:33:34,402 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:34,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:34,408 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 13:33:37,388 : [INFO]  ------------------------- Batch round 3, loss: 0.5861 -------------------------
2023-03-25 13:33:37,388 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:37,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:37,743 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 13:33:37,743 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 13:33:39,034 : [INFO]  Batch 22: Training set : loss - 0.5747, accuracy - 0.7554, recall - 0.913, AUC - 0.8493, F1 - 0.7887, precision - 0.6942, training time - -10.0 seconds
2023-03-25 13:33:39,034 : [INFO]  Batch 22: Testing set : loss - 0.6608, accuracy - 0.5833, recall - 0.7647, AUC - 0.716, F1 - 0.6473, precision - 0.5612
2023-03-25 13:33:39,047 : [INFO]  Batch 23 initialized 
2023-03-25 13:33:39,468 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:39,752 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 13:33:44,307 : [INFO]  ------------------------- Batch round 1, loss: 0.5541 -------------------------
2023-03-25 13:33:44,307 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:44,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:44,311 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 13:33:46,534 : [INFO]  ------------------------- Batch round 2, loss: 0.5484 -------------------------
2023-03-25 13:33:46,535 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:46,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:46,578 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 13:33:49,078 : [INFO]  ------------------------- Batch round 3, loss: 0.5382 -------------------------
2023-03-25 13:33:49,078 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:49,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:49,084 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 13:33:49,084 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 13:33:50,490 : [INFO]  Batch 23: Training set : loss - 0.5308, accuracy - 0.8098, recall - 0.9239, AUC - 0.8983, F1 - 0.8293, precision - 0.7522, training time - -9.0 seconds
2023-03-25 13:33:50,491 : [INFO]  Batch 23: Testing set : loss - 0.5701, accuracy - 0.7059, recall - 0.9118, AUC - 0.8654, F1 - 0.7561, precision - 0.6458
2023-03-25 13:33:50,504 : [INFO]  Batch 24 initialized 
2023-03-25 13:33:50,939 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:51,211 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 13:33:56,547 : [INFO]  ------------------------- Batch round 1, loss: 0.5946 -------------------------
2023-03-25 13:33:56,547 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:56,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:56,554 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 13:33:59,044 : [INFO]  ------------------------- Batch round 2, loss: 0.5783 -------------------------
2023-03-25 13:33:59,045 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:59,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:59,050 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 13:34:01,302 : [INFO]  ------------------------- Batch round 3, loss: 0.5721 -------------------------
2023-03-25 13:34:01,303 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:01,355 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:01,358 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 13:34:01,358 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 13:34:02,973 : [INFO]  Batch 24: Training set : loss - 0.5668, accuracy - 0.7391, recall - 0.8913, AUC - 0.8352, F1 - 0.7736, precision - 0.6833, training time - -10.0 seconds
2023-03-25 13:34:02,973 : [INFO]  Batch 24: Testing set : loss - 0.575, accuracy - 0.7353, recall - 0.8627, AUC - 0.8382, F1 - 0.7652, precision - 0.6875
2023-03-25 13:34:02,985 : [INFO]  Batch 25 initialized 
2023-03-25 13:34:03,397 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:03,671 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 13:34:07,706 : [INFO]  ------------------------- Batch round 1, loss: 0.5687 -------------------------
2023-03-25 13:34:07,706 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:07,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:07,714 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 13:34:11,223 : [INFO]  ------------------------- Batch round 2, loss: 0.5528 -------------------------
2023-03-25 13:34:11,223 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:11,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:11,228 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 13:34:13,327 : [INFO]  ------------------------- Batch round 3, loss: 0.5502 -------------------------
2023-03-25 13:34:13,328 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:13,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:13,625 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 13:34:13,625 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 13:34:14,941 : [INFO]  Batch 25: Training set : loss - 0.5425, accuracy - 0.788, recall - 0.9348, AUC - 0.8987, F1 - 0.8152, precision - 0.7227, training time - -10.0 seconds
2023-03-25 13:34:14,941 : [INFO]  Batch 25: Testing set : loss - 0.5692, accuracy - 0.7157, recall - 0.902, AUC - 0.8745, F1 - 0.7603, precision - 0.6571
2023-03-25 13:34:14,950 : [INFO]  Batch 26 initialized 
2023-03-25 13:34:15,367 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:15,649 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 13:34:19,616 : [INFO]  ------------------------- Batch round 1, loss: 0.5996 -------------------------
2023-03-25 13:34:19,617 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:19,620 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:19,622 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 13:34:21,893 : [INFO]  ------------------------- Batch round 2, loss: 0.5809 -------------------------
2023-03-25 13:34:21,893 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:21,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:21,900 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 13:34:24,025 : [INFO]  ------------------------- Batch round 3, loss: 0.5706 -------------------------
2023-03-25 13:34:24,025 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:24,028 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:24,030 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 13:34:24,030 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 13:34:25,421 : [INFO]  Batch 26: Training set : loss - 0.5709, accuracy - 0.7446, recall - 0.8913, AUC - 0.8319, F1 - 0.7773, precision - 0.6891, training time - -8.0 seconds
2023-03-25 13:34:25,421 : [INFO]  Batch 26: Testing set : loss - 0.5834, accuracy - 0.701, recall - 0.9216, AUC - 0.8332, F1 - 0.755, precision - 0.6395
2023-03-25 13:34:25,430 : [INFO]  Batch 27 initialized 
2023-03-25 13:34:25,881 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:26,214 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 13:34:30,107 : [INFO]  ------------------------- Batch round 1, loss: 0.6016 -------------------------
2023-03-25 13:34:30,107 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:30,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:30,209 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 13:34:32,451 : [INFO]  ------------------------- Batch round 2, loss: 0.5849 -------------------------
2023-03-25 13:34:32,451 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:32,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:32,563 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 13:34:35,009 : [INFO]  ------------------------- Batch round 3, loss: 0.5849 -------------------------
2023-03-25 13:34:35,009 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:35,012 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:35,014 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 13:34:35,014 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 13:34:36,345 : [INFO]  Batch 27: Training set : loss - 0.5815, accuracy - 0.7011, recall - 0.8913, AUC - 0.8202, F1 - 0.7489, precision - 0.6457, training time - -9.0 seconds
2023-03-25 13:34:36,345 : [INFO]  Batch 27: Testing set : loss - 0.5836, accuracy - 0.7059, recall - 0.9314, AUC - 0.8431, F1 - 0.76, precision - 0.6419
2023-03-25 13:34:36,358 : [INFO]  Batch 28 initialized 
2023-03-25 13:34:36,775 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:37,093 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 13:34:41,523 : [INFO]  ------------------------- Batch round 1, loss: 0.5749 -------------------------
2023-03-25 13:34:41,523 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:41,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:41,574 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 13:34:44,960 : [INFO]  ------------------------- Batch round 2, loss: 0.5643 -------------------------
2023-03-25 13:34:44,961 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:44,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:44,968 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 13:34:47,296 : [INFO]  ------------------------- Batch round 3, loss: 0.5504 -------------------------
2023-03-25 13:34:47,296 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:47,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:47,358 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 13:34:47,359 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 13:34:48,774 : [INFO]  Batch 28: Training set : loss - 0.5506, accuracy - 0.7446, recall - 0.8804, AUC - 0.8619, F1 - 0.7751, precision - 0.6923, training time - -10.0 seconds
2023-03-25 13:34:48,775 : [INFO]  Batch 28: Testing set : loss - 0.5666, accuracy - 0.75, recall - 0.8922, AUC - 0.8451, F1 - 0.7811, precision - 0.6947
2023-03-25 13:34:48,788 : [INFO]  Batch 29 initialized 
2023-03-25 13:34:49,236 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:49,517 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 13:34:53,913 : [INFO]  ------------------------- Batch round 1, loss: 0.5543 -------------------------
2023-03-25 13:34:53,914 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:54,205 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:54,207 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 13:34:56,276 : [INFO]  ------------------------- Batch round 2, loss: 0.5471 -------------------------
2023-03-25 13:34:56,276 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:56,540 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:56,541 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 13:34:59,038 : [INFO]  ------------------------- Batch round 3, loss: 0.5422 -------------------------
2023-03-25 13:34:59,038 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:59,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:59,500 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 13:34:59,500 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 13:35:00,980 : [INFO]  Batch 29: Training set : loss - 0.5415, accuracy - 0.7663, recall - 0.9565, AUC - 0.8876, F1 - 0.8037, precision - 0.6929, training time - -10.0 seconds
2023-03-25 13:35:00,980 : [INFO]  Batch 29: Testing set : loss - 0.5668, accuracy - 0.7059, recall - 0.8824, AUC - 0.8369, F1 - 0.75, precision - 0.6522
2023-03-25 13:35:00,993 : [INFO]  Batch 30 initialized 
2023-03-25 13:35:01,541 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:01,789 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 13:35:06,758 : [INFO]  ------------------------- Batch round 1, loss: 0.5713 -------------------------
2023-03-25 13:35:06,758 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:06,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:06,998 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 13:35:09,422 : [INFO]  ------------------------- Batch round 2, loss: 0.5559 -------------------------
2023-03-25 13:35:09,423 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:09,708 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:09,709 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 13:35:11,910 : [INFO]  ------------------------- Batch round 3, loss: 0.5488 -------------------------
2023-03-25 13:35:11,910 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:11,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:11,952 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 13:35:11,952 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 13:35:13,819 : [INFO]  Batch 30: Training set : loss - 0.5447, accuracy - 0.8098, recall - 0.9457, AUC - 0.8806, F1 - 0.8325, precision - 0.7436, training time - -10.0 seconds
2023-03-25 13:35:13,819 : [INFO]  Batch 30: Testing set : loss - 0.5311, accuracy - 0.8088, recall - 0.9804, AUC - 0.9422, F1 - 0.8368, precision - 0.7299
2023-03-25 13:35:13,832 : [INFO]  Batch 31 initialized 
2023-03-25 13:35:14,441 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:14,785 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 13:35:19,874 : [INFO]  ------------------------- Batch round 1, loss: 0.5939 -------------------------
2023-03-25 13:35:19,874 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:20,274 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:20,277 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 13:35:22,483 : [INFO]  ------------------------- Batch round 2, loss: 0.5794 -------------------------
2023-03-25 13:35:22,483 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:22,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:22,490 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 13:35:25,724 : [INFO]  ------------------------- Batch round 3, loss: 0.575 -------------------------
2023-03-25 13:35:25,724 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:25,727 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:25,729 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 13:35:25,729 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 13:35:27,097 : [INFO]  Batch 31: Training set : loss - 0.5594, accuracy - 0.7554, recall - 0.8152, AUC - 0.8362, F1 - 0.7692, precision - 0.7282, training time - -11.0 seconds
2023-03-25 13:35:27,097 : [INFO]  Batch 31: Testing set : loss - 0.5814, accuracy - 0.7059, recall - 0.8235, AUC - 0.8473, F1 - 0.7368, precision - 0.6667
2023-03-25 13:35:27,103 : [INFO]  Batch 32 initialized 
2023-03-25 13:35:27,557 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:27,882 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 13:35:32,457 : [INFO]  ------------------------- Batch round 1, loss: 0.5958 -------------------------
2023-03-25 13:35:32,457 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:32,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:32,461 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 13:35:34,717 : [INFO]  ------------------------- Batch round 2, loss: 0.5833 -------------------------
2023-03-25 13:35:34,717 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:34,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:34,722 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 13:35:36,977 : [INFO]  ------------------------- Batch round 3, loss: 0.5796 -------------------------
2023-03-25 13:35:36,977 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:36,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:36,984 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 13:35:36,984 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 13:35:38,439 : [INFO]  Batch 32: Training set : loss - 0.5766, accuracy - 0.712, recall - 0.8804, AUC - 0.8436, F1 - 0.7535, precision - 0.6585, training time - -9.0 seconds
2023-03-25 13:35:38,439 : [INFO]  Batch 32: Testing set : loss - 0.5713, accuracy - 0.7059, recall - 0.8824, AUC - 0.844, F1 - 0.75, precision - 0.6522
2023-03-25 13:35:38,449 : [INFO]  Batch 33 initialized 
2023-03-25 13:35:38,952 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:39,394 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 13:35:44,037 : [INFO]  ------------------------- Batch round 1, loss: 0.5954 -------------------------
2023-03-25 13:35:44,037 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:44,040 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:44,042 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 13:35:46,091 : [INFO]  ------------------------- Batch round 2, loss: 0.5793 -------------------------
2023-03-25 13:35:46,092 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:46,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:46,096 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 13:35:48,135 : [INFO]  ------------------------- Batch round 3, loss: 0.575 -------------------------
2023-03-25 13:35:48,135 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:48,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:48,141 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 13:35:48,142 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 13:35:49,455 : [INFO]  Batch 33: Training set : loss - 0.5863, accuracy - 0.7011, recall - 0.913, AUC - 0.7638, F1 - 0.7534, precision - 0.6412, training time - -9.0 seconds
2023-03-25 13:35:49,455 : [INFO]  Batch 33: Testing set : loss - 0.583, accuracy - 0.6912, recall - 0.9118, AUC - 0.7979, F1 - 0.747, precision - 0.6327
2023-03-25 13:35:49,462 : [INFO]  Batch 34 initialized 
2023-03-25 13:35:49,880 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:50,181 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 13:35:53,981 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 13:35:53,981 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:54,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:54,110 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 13:35:56,147 : [INFO]  ------------------------- Batch round 2, loss: 0.5629 -------------------------
2023-03-25 13:35:56,147 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:56,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:56,236 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 13:35:58,259 : [INFO]  ------------------------- Batch round 3, loss: 0.5504 -------------------------
2023-03-25 13:35:58,260 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:58,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:58,356 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 13:35:58,356 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 13:35:59,601 : [INFO]  Batch 34: Training set : loss - 0.5488, accuracy - 0.7446, recall - 0.913, AUC - 0.8847, F1 - 0.7814, precision - 0.6829, training time - -8.0 seconds
2023-03-25 13:35:59,601 : [INFO]  Batch 34: Testing set : loss - 0.5545, accuracy - 0.7206, recall - 0.9412, AUC - 0.9169, F1 - 0.7711, precision - 0.6531
2023-03-25 13:35:59,611 : [INFO]  Batch 35 initialized 
2023-03-25 13:36:00,035 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:36:00,336 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 13:36:04,384 : [INFO]  ------------------------- Batch round 1, loss: 0.5619 -------------------------
2023-03-25 13:36:04,385 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 13:36:04,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:04,453 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 13:36:06,631 : [INFO]  ------------------------- Batch round 2, loss: 0.5548 -------------------------
2023-03-25 13:36:06,632 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 13:36:06,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:06,700 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 13:36:08,937 : [INFO]  ------------------------- Batch round 3, loss: 0.5457 -------------------------
2023-03-25 13:36:08,937 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 13:36:08,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:08,942 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 13:36:08,943 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 13:36:10,440 : [INFO]  Batch 35: Training set : loss - 0.5475, accuracy - 0.75, recall - 0.8696, AUC - 0.8823, F1 - 0.7767, precision - 0.7018, training time - -9.0 seconds
2023-03-25 13:36:10,440 : [INFO]  Batch 35: Testing set : loss - 0.5799, accuracy - 0.7059, recall - 0.7941, AUC - 0.8135, F1 - 0.7297, precision - 0.675
2023-03-25 13:36:10,454 : [INFO]  Batch 36 initialized 
2023-03-25 13:36:10,901 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:36:11,224 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 13:36:16,369 : [INFO]  ------------------------- Batch round 1, loss: 0.5517 -------------------------
2023-03-25 13:36:16,369 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 13:36:16,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
