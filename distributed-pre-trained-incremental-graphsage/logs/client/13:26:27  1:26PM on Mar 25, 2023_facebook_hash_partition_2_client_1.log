2023-03-25 13:26:27,559 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 13:26:27,559 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 1, epochs 6
2023-03-25 13:26:30,875 : [INFO]  Model initialized for training
2023-03-25 13:26:47,791 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:26:48,232 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:26:48,233 : [INFO]  Connected to the server
2023-03-25 13:26:48,372 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:26:48,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:48,387 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:26:48,388 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:27:15,563 : [INFO]  ------------------------- Training round 1, loss: 0.6788 -------------------------
2023-03-25 13:27:15,564 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:27:16,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:27:16,930 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:27:42,126 : [INFO]  ------------------------- Training round 2, loss: 0.6383 -------------------------
2023-03-25 13:27:42,126 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:27:42,129 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:27:42,130 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:28:04,377 : [INFO]  ------------------------- Training round 3, loss: 0.615 -------------------------
2023-03-25 13:28:04,378 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:28:04,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:28:04,382 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:28:27,531 : [INFO]  ------------------------- Training round 4, loss: 0.6044 -------------------------
2023-03-25 13:28:27,531 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:28:27,534 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:28:27,535 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:28:51,127 : [INFO]  ------------------------- Training round 5, loss: 0.6014 -------------------------
2023-03-25 13:28:51,127 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:28:51,130 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:28:51,132 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:29:36,148 : [INFO]  Initially trained model: Training set : loss - 0.6, accuracy - 0.69, recall - 0.87, AUC - 0.82, F1 - 0.74, precision - 0.64, training time - -123.0 seconds
2023-03-25 13:29:36,148 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 13:29:36,154 : [INFO]  Batch 1 initialized 
2023-03-25 13:29:36,579 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:29:36,690 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:29:36,690 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:29:40,693 : [INFO]  ------------------------- Batch round 1, loss: 0.5885 -------------------------
2023-03-25 13:29:40,693 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:29:40,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:40,697 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:29:42,924 : [INFO]  ------------------------- Batch round 2, loss: 0.5786 -------------------------
2023-03-25 13:29:42,924 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:29:43,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:43,054 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:29:45,261 : [INFO]  ------------------------- Batch round 3, loss: 0.569 -------------------------
2023-03-25 13:29:45,261 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:29:45,347 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:45,349 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:29:45,350 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:29:46,741 : [INFO]  Batch 1: Training set : loss - 0.5636, accuracy - 0.75, recall - 0.913, AUC - 0.8609, F1 - 0.785, precision - 0.6885, training time - -9.0 seconds
2023-03-25 13:29:46,742 : [INFO]  Batch 1: Testing set : loss - 0.5554, accuracy - 0.7451, recall - 0.902, AUC - 0.8897, F1 - 0.7797, precision - 0.6866
2023-03-25 13:29:46,748 : [INFO]  Batch 2 initialized 
2023-03-25 13:29:47,278 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:29:47,479 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:29:51,468 : [INFO]  ------------------------- Batch round 1, loss: 0.5552 -------------------------
2023-03-25 13:29:51,468 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:29:51,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:51,473 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:29:53,586 : [INFO]  ------------------------- Batch round 2, loss: 0.5497 -------------------------
2023-03-25 13:29:53,587 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:29:53,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:53,592 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:29:55,701 : [INFO]  ------------------------- Batch round 3, loss: 0.5434 -------------------------
2023-03-25 13:29:55,701 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:29:55,704 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:29:55,706 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:29:55,706 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:29:57,018 : [INFO]  Batch 2: Training set : loss - 0.5378, accuracy - 0.8043, recall - 0.9457, AUC - 0.9059, F1 - 0.8286, precision - 0.7373, training time - -8.0 seconds
2023-03-25 13:29:57,018 : [INFO]  Batch 2: Testing set : loss - 0.5407, accuracy - 0.7696, recall - 0.9216, AUC - 0.911, F1 - 0.8, precision - 0.7068
2023-03-25 13:29:57,025 : [INFO]  Batch 3 initialized 
2023-03-25 13:29:57,448 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:29:57,682 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:30:01,748 : [INFO]  ------------------------- Batch round 1, loss: 0.5435 -------------------------
2023-03-25 13:30:01,748 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:01,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:01,753 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:30:04,114 : [INFO]  ------------------------- Batch round 2, loss: 0.5388 -------------------------
2023-03-25 13:30:04,114 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:04,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:04,119 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:30:06,255 : [INFO]  ------------------------- Batch round 3, loss: 0.5249 -------------------------
2023-03-25 13:30:06,256 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:06,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:06,465 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:30:06,465 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:30:07,779 : [INFO]  Batch 3: Training set : loss - 0.5244, accuracy - 0.8152, recall - 0.9239, AUC - 0.9169, F1 - 0.8333, precision - 0.7589, training time - -9.0 seconds
2023-03-25 13:30:07,779 : [INFO]  Batch 3: Testing set : loss - 0.5617, accuracy - 0.7206, recall - 0.902, AUC - 0.899, F1 - 0.7635, precision - 0.6619
2023-03-25 13:30:07,784 : [INFO]  Batch 4 initialized 
2023-03-25 13:30:08,226 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:08,468 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 13:30:12,369 : [INFO]  ------------------------- Batch round 1, loss: 0.5623 -------------------------
2023-03-25 13:30:12,369 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:12,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:12,375 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 13:30:14,662 : [INFO]  ------------------------- Batch round 2, loss: 0.5466 -------------------------
2023-03-25 13:30:14,662 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:14,665 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:14,667 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 13:30:16,639 : [INFO]  ------------------------- Batch round 3, loss: 0.5533 -------------------------
2023-03-25 13:30:16,639 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:16,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:16,645 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 13:30:16,645 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 13:30:18,013 : [INFO]  Batch 4: Training set : loss - 0.5434, accuracy - 0.7935, recall - 0.913, AUC - 0.8829, F1 - 0.8155, precision - 0.7368, training time - -8.0 seconds
2023-03-25 13:30:18,013 : [INFO]  Batch 4: Testing set : loss - 0.5519, accuracy - 0.7353, recall - 0.9412, AUC - 0.9296, F1 - 0.7805, precision - 0.6667
2023-03-25 13:30:18,023 : [INFO]  Batch 5 initialized 
2023-03-25 13:30:18,460 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:18,691 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 13:30:22,578 : [INFO]  ------------------------- Batch round 1, loss: 0.5409 -------------------------
2023-03-25 13:30:22,578 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:22,646 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:22,648 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 13:30:24,769 : [INFO]  ------------------------- Batch round 2, loss: 0.5393 -------------------------
2023-03-25 13:30:24,769 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:24,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:24,797 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 13:30:26,862 : [INFO]  ------------------------- Batch round 3, loss: 0.5348 -------------------------
2023-03-25 13:30:26,862 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:26,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:26,900 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 13:30:26,900 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 13:30:28,208 : [INFO]  Batch 5: Training set : loss - 0.534, accuracy - 0.8043, recall - 0.9348, AUC - 0.9065, F1 - 0.8269, precision - 0.7414, training time - -8.0 seconds
2023-03-25 13:30:28,208 : [INFO]  Batch 5: Testing set : loss - 0.5252, accuracy - 0.7843, recall - 0.9118, AUC - 0.9161, F1 - 0.8087, precision - 0.7266
2023-03-25 13:30:28,223 : [INFO]  Batch 6 initialized 
2023-03-25 13:30:28,664 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:28,921 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 13:30:32,888 : [INFO]  ------------------------- Batch round 1, loss: 0.5478 -------------------------
2023-03-25 13:30:32,889 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:32,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:32,893 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 13:30:34,995 : [INFO]  ------------------------- Batch round 2, loss: 0.5406 -------------------------
2023-03-25 13:30:34,995 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:34,999 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:35,001 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 13:30:37,159 : [INFO]  ------------------------- Batch round 3, loss: 0.5333 -------------------------
2023-03-25 13:30:37,159 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:37,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:37,163 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 13:30:37,164 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 13:30:38,444 : [INFO]  Batch 6: Training set : loss - 0.5226, accuracy - 0.8043, recall - 0.9457, AUC - 0.9126, F1 - 0.8286, precision - 0.7373, training time - -8.0 seconds
2023-03-25 13:30:38,444 : [INFO]  Batch 6: Testing set : loss - 0.5589, accuracy - 0.701, recall - 0.9118, AUC - 0.8896, F1 - 0.753, precision - 0.6414
2023-03-25 13:30:38,450 : [INFO]  Batch 7 initialized 
2023-03-25 13:30:38,876 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:39,118 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 13:30:42,988 : [INFO]  ------------------------- Batch round 1, loss: 0.5476 -------------------------
2023-03-25 13:30:42,988 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:43,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:43,305 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 13:30:45,440 : [INFO]  ------------------------- Batch round 2, loss: 0.5398 -------------------------
2023-03-25 13:30:45,440 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:45,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:45,499 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 13:30:47,625 : [INFO]  ------------------------- Batch round 3, loss: 0.531 -------------------------
2023-03-25 13:30:47,626 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:47,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:47,631 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 13:30:47,631 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 13:30:48,959 : [INFO]  Batch 7: Training set : loss - 0.5258, accuracy - 0.788, recall - 0.9239, AUC - 0.9078, F1 - 0.8134, precision - 0.7265, training time - -9.0 seconds
2023-03-25 13:30:48,959 : [INFO]  Batch 7: Testing set : loss - 0.5824, accuracy - 0.7059, recall - 0.8725, AUC - 0.8515, F1 - 0.7479, precision - 0.6544
2023-03-25 13:30:48,972 : [INFO]  Batch 8 initialized 
2023-03-25 13:30:49,431 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:49,686 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 13:30:53,709 : [INFO]  ------------------------- Batch round 1, loss: 0.5663 -------------------------
2023-03-25 13:30:53,709 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 13:30:53,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:53,715 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 13:30:55,821 : [INFO]  ------------------------- Batch round 2, loss: 0.56 -------------------------
2023-03-25 13:30:55,821 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 13:30:55,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:55,826 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 13:30:57,954 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-25 13:30:57,954 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 13:30:57,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:30:57,959 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 13:30:57,959 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 13:30:59,257 : [INFO]  Batch 8: Training set : loss - 0.558, accuracy - 0.75, recall - 0.9565, AUC - 0.8934, F1 - 0.7928, precision - 0.6769, training time - -8.0 seconds
2023-03-25 13:30:59,258 : [INFO]  Batch 8: Testing set : loss - 0.5833, accuracy - 0.6961, recall - 0.9118, AUC - 0.8614, F1 - 0.75, precision - 0.637
2023-03-25 13:30:59,263 : [INFO]  Batch 9 initialized 
2023-03-25 13:30:59,690 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:30:59,979 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 13:31:04,138 : [INFO]  ------------------------- Batch round 1, loss: 0.5792 -------------------------
2023-03-25 13:31:04,138 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:04,141 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:04,143 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 13:31:07,061 : [INFO]  ------------------------- Batch round 2, loss: 0.5741 -------------------------
2023-03-25 13:31:07,061 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:07,064 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:07,066 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 13:31:09,389 : [INFO]  ------------------------- Batch round 3, loss: 0.5645 -------------------------
2023-03-25 13:31:09,389 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:09,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:09,393 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 13:31:09,394 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 13:31:10,750 : [INFO]  Batch 9: Training set : loss - 0.5666, accuracy - 0.7174, recall - 0.8152, AUC - 0.853, F1 - 0.7426, precision - 0.6818, training time - -9.0 seconds
2023-03-25 13:31:10,750 : [INFO]  Batch 9: Testing set : loss - 0.6083, accuracy - 0.6667, recall - 0.8137, AUC - 0.7869, F1 - 0.7094, precision - 0.6288
2023-03-25 13:31:10,762 : [INFO]  Batch 10 initialized 
2023-03-25 13:31:11,215 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:11,451 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 13:31:17,022 : [INFO]  ------------------------- Batch round 1, loss: 0.552 -------------------------
2023-03-25 13:31:17,022 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:17,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:17,027 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 13:31:19,298 : [INFO]  ------------------------- Batch round 2, loss: 0.5521 -------------------------
2023-03-25 13:31:19,298 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:19,301 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:19,303 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 13:31:21,551 : [INFO]  ------------------------- Batch round 3, loss: 0.5416 -------------------------
2023-03-25 13:31:21,551 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:21,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:21,556 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 13:31:21,556 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 13:31:23,181 : [INFO]  Batch 10: Training set : loss - 0.5329, accuracy - 0.788, recall - 0.9457, AUC - 0.8839, F1 - 0.8169, precision - 0.719, training time - -10.0 seconds
2023-03-25 13:31:23,181 : [INFO]  Batch 10: Testing set : loss - 0.5616, accuracy - 0.7108, recall - 0.8824, AUC - 0.8728, F1 - 0.7531, precision - 0.6569
2023-03-25 13:31:23,187 : [INFO]  Batch 11 initialized 
2023-03-25 13:31:23,611 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:23,858 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 13:31:27,710 : [INFO]  ------------------------- Batch round 1, loss: 0.571 -------------------------
2023-03-25 13:31:27,710 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:27,713 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:27,715 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 13:31:30,652 : [INFO]  ------------------------- Batch round 2, loss: 0.5663 -------------------------
2023-03-25 13:31:30,652 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:30,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:30,774 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 13:31:32,951 : [INFO]  ------------------------- Batch round 3, loss: 0.5599 -------------------------
2023-03-25 13:31:32,951 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:32,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:32,957 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 13:31:32,957 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 13:31:34,389 : [INFO]  Batch 11: Training set : loss - 0.5623, accuracy - 0.7391, recall - 0.913, AUC - 0.8674, F1 - 0.7778, precision - 0.6774, training time - -9.0 seconds
2023-03-25 13:31:34,389 : [INFO]  Batch 11: Testing set : loss - 0.5667, accuracy - 0.7402, recall - 0.9216, AUC - 0.882, F1 - 0.7801, precision - 0.6763
2023-03-25 13:31:34,402 : [INFO]  Batch 12 initialized 
2023-03-25 13:31:34,843 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:35,122 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 13:31:39,117 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-25 13:31:39,118 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:39,230 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:39,232 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 13:31:41,642 : [INFO]  ------------------------- Batch round 2, loss: 0.5558 -------------------------
2023-03-25 13:31:41,642 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:41,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:41,646 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 13:31:43,888 : [INFO]  ------------------------- Batch round 3, loss: 0.5574 -------------------------
2023-03-25 13:31:43,889 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:44,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:44,017 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 13:31:44,017 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 13:31:45,401 : [INFO]  Batch 12: Training set : loss - 0.5546, accuracy - 0.7717, recall - 0.8804, AUC - 0.8624, F1 - 0.7941, precision - 0.7232, training time - -9.0 seconds
2023-03-25 13:31:45,401 : [INFO]  Batch 12: Testing set : loss - 0.5813, accuracy - 0.7157, recall - 0.8431, AUC - 0.832, F1 - 0.7478, precision - 0.6719
2023-03-25 13:31:45,413 : [INFO]  Batch 13 initialized 
2023-03-25 13:31:45,861 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:46,122 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 13:31:50,812 : [INFO]  ------------------------- Batch round 1, loss: 0.5522 -------------------------
2023-03-25 13:31:50,812 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 13:31:50,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:50,817 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 13:31:53,062 : [INFO]  ------------------------- Batch round 2, loss: 0.5323 -------------------------
2023-03-25 13:31:53,062 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 13:31:53,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:53,067 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 13:31:55,265 : [INFO]  ------------------------- Batch round 3, loss: 0.5333 -------------------------
2023-03-25 13:31:55,265 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 13:31:55,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:31:55,270 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 13:31:55,270 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 13:31:56,602 : [INFO]  Batch 13: Training set : loss - 0.5314, accuracy - 0.7989, recall - 0.9348, AUC - 0.91, F1 - 0.823, precision - 0.735, training time - -9.0 seconds
2023-03-25 13:31:56,602 : [INFO]  Batch 13: Testing set : loss - 0.558, accuracy - 0.7108, recall - 0.8922, AUC - 0.8891, F1 - 0.7552, precision - 0.6547
2023-03-25 13:31:56,608 : [INFO]  Batch 14 initialized 
2023-03-25 13:31:57,052 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:31:57,324 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 13:32:02,370 : [INFO]  ------------------------- Batch round 1, loss: 0.5427 -------------------------
2023-03-25 13:32:02,370 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:02,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:02,384 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 13:32:04,629 : [INFO]  ------------------------- Batch round 2, loss: 0.5305 -------------------------
2023-03-25 13:32:04,629 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:04,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:04,686 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 13:32:06,749 : [INFO]  ------------------------- Batch round 3, loss: 0.5269 -------------------------
2023-03-25 13:32:06,749 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:06,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:06,759 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 13:32:06,759 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 13:32:08,084 : [INFO]  Batch 14: Training set : loss - 0.5237, accuracy - 0.7772, recall - 0.9565, AUC - 0.9048, F1 - 0.8111, precision - 0.704, training time - -9.0 seconds
2023-03-25 13:32:08,084 : [INFO]  Batch 14: Testing set : loss - 0.5678, accuracy - 0.7206, recall - 0.8824, AUC - 0.8634, F1 - 0.7595, precision - 0.6667
2023-03-25 13:32:08,094 : [INFO]  Batch 15 initialized 
2023-03-25 13:32:08,541 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:08,835 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 13:32:13,144 : [INFO]  ------------------------- Batch round 1, loss: 0.5883 -------------------------
2023-03-25 13:32:13,144 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:13,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:13,233 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 13:32:15,338 : [INFO]  ------------------------- Batch round 2, loss: 0.5833 -------------------------
2023-03-25 13:32:15,338 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:15,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:15,398 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 13:32:17,666 : [INFO]  ------------------------- Batch round 3, loss: 0.5705 -------------------------
2023-03-25 13:32:17,667 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:17,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:17,747 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 13:32:17,747 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 13:32:19,837 : [INFO]  Batch 15: Training set : loss - 0.5735, accuracy - 0.7283, recall - 0.9565, AUC - 0.8526, F1 - 0.7788, precision - 0.6567, training time - -9.0 seconds
2023-03-25 13:32:19,837 : [INFO]  Batch 15: Testing set : loss - 0.5574, accuracy - 0.7206, recall - 0.9412, AUC - 0.8978, F1 - 0.7711, precision - 0.6531
2023-03-25 13:32:19,850 : [INFO]  Batch 16 initialized 
2023-03-25 13:32:20,300 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:20,569 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 13:32:24,626 : [INFO]  ------------------------- Batch round 1, loss: 0.5797 -------------------------
2023-03-25 13:32:24,627 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:24,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:24,631 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 13:32:26,787 : [INFO]  ------------------------- Batch round 2, loss: 0.5681 -------------------------
2023-03-25 13:32:26,788 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:26,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:26,792 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 13:32:28,908 : [INFO]  ------------------------- Batch round 3, loss: 0.562 -------------------------
2023-03-25 13:32:28,908 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:28,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:28,913 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 13:32:28,913 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 13:32:30,293 : [INFO]  Batch 16: Training set : loss - 0.5605, accuracy - 0.7663, recall - 0.8913, AUC - 0.8403, F1 - 0.7923, precision - 0.713, training time - -8.0 seconds
2023-03-25 13:32:30,294 : [INFO]  Batch 16: Testing set : loss - 0.545, accuracy - 0.7549, recall - 0.8824, AUC - 0.8897, F1 - 0.7826, precision - 0.7031
2023-03-25 13:32:30,300 : [INFO]  Batch 17 initialized 
2023-03-25 13:32:30,756 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:31,051 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 13:32:35,154 : [INFO]  ------------------------- Batch round 1, loss: 0.5389 -------------------------
2023-03-25 13:32:35,154 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:35,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:35,159 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 13:32:37,635 : [INFO]  ------------------------- Batch round 2, loss: 0.5305 -------------------------
2023-03-25 13:32:37,635 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:37,700 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:37,702 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 13:32:39,872 : [INFO]  ------------------------- Batch round 3, loss: 0.5229 -------------------------
2023-03-25 13:32:39,872 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:39,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:39,878 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 13:32:39,879 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 13:32:41,305 : [INFO]  Batch 17: Training set : loss - 0.5219, accuracy - 0.7717, recall - 0.9565, AUC - 0.9159, F1 - 0.8073, precision - 0.6984, training time - -9.0 seconds
2023-03-25 13:32:41,306 : [INFO]  Batch 17: Testing set : loss - 0.5578, accuracy - 0.7451, recall - 0.9902, AUC - 0.9121, F1 - 0.7953, precision - 0.6645
2023-03-25 13:32:41,318 : [INFO]  Batch 18 initialized 
2023-03-25 13:32:41,798 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:42,065 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 13:32:47,240 : [INFO]  ------------------------- Batch round 1, loss: 0.5891 -------------------------
2023-03-25 13:32:47,240 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:47,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:47,246 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 13:32:49,718 : [INFO]  ------------------------- Batch round 2, loss: 0.5741 -------------------------
2023-03-25 13:32:49,718 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 13:32:49,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:49,722 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 13:32:51,916 : [INFO]  ------------------------- Batch round 3, loss: 0.5652 -------------------------
2023-03-25 13:32:51,916 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 13:32:51,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:51,920 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 13:32:51,920 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 13:32:53,362 : [INFO]  Batch 18: Training set : loss - 0.5681, accuracy - 0.7337, recall - 0.9022, AUC - 0.8553, F1 - 0.7721, precision - 0.6748, training time - -10.0 seconds
2023-03-25 13:32:53,362 : [INFO]  Batch 18: Testing set : loss - 0.6168, accuracy - 0.6912, recall - 0.7941, AUC - 0.7604, F1 - 0.72, precision - 0.6585
2023-03-25 13:32:53,367 : [INFO]  Batch 19 initialized 
2023-03-25 13:32:53,850 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:32:54,130 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 13:32:58,069 : [INFO]  ------------------------- Batch round 1, loss: 0.571 -------------------------
2023-03-25 13:32:58,069 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 13:32:58,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:32:58,330 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 13:33:00,724 : [INFO]  ------------------------- Batch round 2, loss: 0.5541 -------------------------
2023-03-25 13:33:00,724 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:00,727 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:00,728 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 13:33:02,862 : [INFO]  ------------------------- Batch round 3, loss: 0.5507 -------------------------
2023-03-25 13:33:02,862 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:02,865 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:02,867 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 13:33:02,867 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 13:33:04,275 : [INFO]  Batch 19: Training set : loss - 0.5496, accuracy - 0.7772, recall - 0.9457, AUC - 0.8699, F1 - 0.8093, precision - 0.7073, training time - -9.0 seconds
2023-03-25 13:33:04,275 : [INFO]  Batch 19: Testing set : loss - 0.6017, accuracy - 0.652, recall - 0.8627, AUC - 0.8278, F1 - 0.7126, precision - 0.6069
2023-03-25 13:33:04,281 : [INFO]  Batch 20 initialized 
2023-03-25 13:33:04,770 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:05,064 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 13:33:09,155 : [INFO]  ------------------------- Batch round 1, loss: 0.5898 -------------------------
2023-03-25 13:33:09,155 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:09,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:09,160 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 13:33:11,371 : [INFO]  ------------------------- Batch round 2, loss: 0.5815 -------------------------
2023-03-25 13:33:11,371 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:11,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:11,376 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 13:33:14,868 : [INFO]  ------------------------- Batch round 3, loss: 0.5725 -------------------------
2023-03-25 13:33:14,868 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:14,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:14,873 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 13:33:14,874 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 13:33:16,251 : [INFO]  Batch 20: Training set : loss - 0.5654, accuracy - 0.7391, recall - 0.8913, AUC - 0.8488, F1 - 0.7736, precision - 0.6833, training time - -10.0 seconds
2023-03-25 13:33:16,251 : [INFO]  Batch 20: Testing set : loss - 0.586, accuracy - 0.6863, recall - 0.8922, AUC - 0.8411, F1 - 0.7398, precision - 0.6319
2023-03-25 13:33:16,256 : [INFO]  Batch 21 initialized 
2023-03-25 13:33:16,671 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:16,969 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 13:33:21,168 : [INFO]  ------------------------- Batch round 1, loss: 0.598 -------------------------
2023-03-25 13:33:21,168 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:21,171 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:21,173 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 13:33:23,292 : [INFO]  ------------------------- Batch round 2, loss: 0.5971 -------------------------
2023-03-25 13:33:23,292 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:23,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:23,297 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 13:33:25,704 : [INFO]  ------------------------- Batch round 3, loss: 0.5896 -------------------------
2023-03-25 13:33:25,704 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:25,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:25,709 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 13:33:25,709 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 13:33:27,044 : [INFO]  Batch 21: Training set : loss - 0.587, accuracy - 0.712, recall - 0.8913, AUC - 0.8358, F1 - 0.7558, precision - 0.656, training time - -9.0 seconds
2023-03-25 13:33:27,044 : [INFO]  Batch 21: Testing set : loss - 0.5622, accuracy - 0.7304, recall - 0.9608, AUC - 0.8957, F1 - 0.7809, precision - 0.6577
2023-03-25 13:33:27,054 : [INFO]  Batch 22 initialized 
2023-03-25 13:33:27,515 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:27,805 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 13:33:32,012 : [INFO]  ------------------------- Batch round 1, loss: 0.6029 -------------------------
2023-03-25 13:33:32,012 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:32,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:32,017 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 13:33:34,345 : [INFO]  ------------------------- Batch round 2, loss: 0.5918 -------------------------
2023-03-25 13:33:34,345 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:34,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:34,408 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 13:33:37,738 : [INFO]  ------------------------- Batch round 3, loss: 0.5811 -------------------------
2023-03-25 13:33:37,738 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:37,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:37,742 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 13:33:37,742 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 13:33:39,034 : [INFO]  Batch 22: Training set : loss - 0.5881, accuracy - 0.7011, recall - 0.8478, AUC - 0.8361, F1 - 0.7393, precision - 0.6555, training time - -10.0 seconds
2023-03-25 13:33:39,034 : [INFO]  Batch 22: Testing set : loss - 0.5833, accuracy - 0.6961, recall - 0.8529, AUC - 0.8351, F1 - 0.7373, precision - 0.6493
2023-03-25 13:33:39,049 : [INFO]  Batch 23 initialized 
2023-03-25 13:33:39,472 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:39,763 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 13:33:44,060 : [INFO]  ------------------------- Batch round 1, loss: 0.5848 -------------------------
2023-03-25 13:33:44,060 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:44,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:44,312 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 13:33:46,572 : [INFO]  ------------------------- Batch round 2, loss: 0.5679 -------------------------
2023-03-25 13:33:46,572 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:46,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:46,577 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 13:33:48,981 : [INFO]  ------------------------- Batch round 3, loss: 0.5633 -------------------------
2023-03-25 13:33:48,982 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 13:33:49,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:49,084 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 13:33:49,084 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 13:33:50,522 : [INFO]  Batch 23: Training set : loss - 0.553, accuracy - 0.7228, recall - 0.8587, AUC - 0.8576, F1 - 0.756, precision - 0.6752, training time - -9.0 seconds
2023-03-25 13:33:50,522 : [INFO]  Batch 23: Testing set : loss - 0.6031, accuracy - 0.6569, recall - 0.8235, AUC - 0.7768, F1 - 0.7059, precision - 0.6176
2023-03-25 13:33:50,534 : [INFO]  Batch 24 initialized 
2023-03-25 13:33:50,993 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:33:51,268 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 13:33:56,542 : [INFO]  ------------------------- Batch round 1, loss: 0.5938 -------------------------
2023-03-25 13:33:56,542 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 13:33:56,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:56,554 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 13:33:59,025 : [INFO]  ------------------------- Batch round 2, loss: 0.5828 -------------------------
2023-03-25 13:33:59,025 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 13:33:59,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:33:59,050 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 13:34:01,352 : [INFO]  ------------------------- Batch round 3, loss: 0.5752 -------------------------
2023-03-25 13:34:01,352 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:01,355 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:01,357 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 13:34:01,357 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 13:34:02,986 : [INFO]  Batch 24: Training set : loss - 0.5711, accuracy - 0.7228, recall - 0.8696, AUC - 0.8328, F1 - 0.7583, precision - 0.6723, training time - -10.0 seconds
2023-03-25 13:34:02,986 : [INFO]  Batch 24: Testing set : loss - 0.578, accuracy - 0.7353, recall - 0.8529, AUC - 0.8239, F1 - 0.7632, precision - 0.6905
2023-03-25 13:34:02,996 : [INFO]  Batch 25 initialized 
2023-03-25 13:34:03,415 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:03,695 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 13:34:07,698 : [INFO]  ------------------------- Batch round 1, loss: 0.6227 -------------------------
2023-03-25 13:34:07,698 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:07,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:07,714 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 13:34:10,614 : [INFO]  ------------------------- Batch round 2, loss: 0.5901 -------------------------
2023-03-25 13:34:10,614 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:11,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:11,228 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 13:34:13,619 : [INFO]  ------------------------- Batch round 3, loss: 0.5712 -------------------------
2023-03-25 13:34:13,619 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:13,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:13,624 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 13:34:13,625 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 13:34:14,910 : [INFO]  Batch 25: Training set : loss - 0.5878, accuracy - 0.7011, recall - 0.8804, AUC - 0.8249, F1 - 0.7465, precision - 0.648, training time - -10.0 seconds
2023-03-25 13:34:14,911 : [INFO]  Batch 25: Testing set : loss - 0.6138, accuracy - 0.6618, recall - 0.8039, AUC - 0.7933, F1 - 0.7039, precision - 0.626
2023-03-25 13:34:14,920 : [INFO]  Batch 26 initialized 
2023-03-25 13:34:15,343 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:15,618 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 13:34:19,501 : [INFO]  ------------------------- Batch round 1, loss: 0.5582 -------------------------
2023-03-25 13:34:19,501 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:19,620 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:19,622 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 13:34:21,789 : [INFO]  ------------------------- Batch round 2, loss: 0.5515 -------------------------
2023-03-25 13:34:21,789 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:21,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:21,900 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 13:34:23,983 : [INFO]  ------------------------- Batch round 3, loss: 0.5461 -------------------------
2023-03-25 13:34:23,983 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:24,028 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:24,030 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 13:34:24,030 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 13:34:25,409 : [INFO]  Batch 26: Training set : loss - 0.5478, accuracy - 0.7554, recall - 0.8804, AUC - 0.8744, F1 - 0.7826, precision - 0.7043, training time - -8.0 seconds
2023-03-25 13:34:25,409 : [INFO]  Batch 26: Testing set : loss - 0.539, accuracy - 0.7941, recall - 0.951, AUC - 0.91, F1 - 0.822, precision - 0.7239
2023-03-25 13:34:25,422 : [INFO]  Batch 27 initialized 
2023-03-25 13:34:25,876 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:26,224 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 13:34:30,204 : [INFO]  ------------------------- Batch round 1, loss: 0.5871 -------------------------
2023-03-25 13:34:30,204 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:30,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:30,209 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 13:34:32,558 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-25 13:34:32,558 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:32,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:32,562 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 13:34:34,785 : [INFO]  ------------------------- Batch round 3, loss: 0.5486 -------------------------
2023-03-25 13:34:34,785 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:35,012 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:35,014 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 13:34:35,014 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 13:34:36,347 : [INFO]  Batch 27: Training set : loss - 0.5489, accuracy - 0.7663, recall - 0.9457, AUC - 0.8694, F1 - 0.8018, precision - 0.696, training time - -9.0 seconds
2023-03-25 13:34:36,347 : [INFO]  Batch 27: Testing set : loss - 0.6013, accuracy - 0.6912, recall - 0.8039, AUC - 0.8042, F1 - 0.7225, precision - 0.656
2023-03-25 13:34:36,357 : [INFO]  Batch 28 initialized 
2023-03-25 13:34:36,778 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:37,102 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 13:34:41,568 : [INFO]  ------------------------- Batch round 1, loss: 0.5777 -------------------------
2023-03-25 13:34:41,568 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:41,571 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:41,573 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 13:34:44,950 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-25 13:34:44,950 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:44,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:44,967 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 13:34:47,353 : [INFO]  ------------------------- Batch round 3, loss: 0.5527 -------------------------
2023-03-25 13:34:47,353 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:47,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:47,358 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 13:34:47,358 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 13:34:48,841 : [INFO]  Batch 28: Training set : loss - 0.5537, accuracy - 0.7663, recall - 0.8913, AUC - 0.8574, F1 - 0.7923, precision - 0.713, training time - -10.0 seconds
2023-03-25 13:34:48,842 : [INFO]  Batch 28: Testing set : loss - 0.5973, accuracy - 0.6961, recall - 0.8627, AUC - 0.8211, F1 - 0.7395, precision - 0.6471
2023-03-25 13:34:48,849 : [INFO]  Batch 29 initialized 
2023-03-25 13:34:49,289 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:34:49,580 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 13:34:54,202 : [INFO]  ------------------------- Batch round 1, loss: 0.576 -------------------------
2023-03-25 13:34:54,202 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 13:34:54,205 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:54,207 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 13:34:56,530 : [INFO]  ------------------------- Batch round 2, loss: 0.5619 -------------------------
2023-03-25 13:34:56,531 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 13:34:56,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:56,541 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 13:34:59,491 : [INFO]  ------------------------- Batch round 3, loss: 0.5599 -------------------------
2023-03-25 13:34:59,492 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 13:34:59,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:34:59,500 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 13:34:59,500 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 13:35:01,210 : [INFO]  Batch 29: Training set : loss - 0.5573, accuracy - 0.7554, recall - 0.9239, AUC - 0.8904, F1 - 0.7907, precision - 0.6911, training time - -10.0 seconds
2023-03-25 13:35:01,210 : [INFO]  Batch 29: Testing set : loss - 0.5662, accuracy - 0.7255, recall - 0.902, AUC - 0.8663, F1 - 0.7667, precision - 0.6667
2023-03-25 13:35:01,217 : [INFO]  Batch 30 initialized 
2023-03-25 13:35:01,714 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:01,979 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 13:35:06,992 : [INFO]  ------------------------- Batch round 1, loss: 0.5825 -------------------------
2023-03-25 13:35:06,992 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:06,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:06,999 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 13:35:09,704 : [INFO]  ------------------------- Batch round 2, loss: 0.5742 -------------------------
2023-03-25 13:35:09,704 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:09,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:09,709 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 13:35:11,934 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-25 13:35:11,934 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:11,941 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:11,944 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 13:35:11,945 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 13:35:13,791 : [INFO]  Batch 30: Training set : loss - 0.5633, accuracy - 0.7717, recall - 0.8587, AUC - 0.8163, F1 - 0.79, precision - 0.7315, training time - -10.0 seconds
2023-03-25 13:35:13,791 : [INFO]  Batch 30: Testing set : loss - 0.5786, accuracy - 0.7059, recall - 0.8627, AUC - 0.8364, F1 - 0.7458, precision - 0.6567
2023-03-25 13:35:13,811 : [INFO]  Batch 31 initialized 
2023-03-25 13:35:14,453 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:14,802 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 13:35:20,271 : [INFO]  ------------------------- Batch round 1, loss: 0.5651 -------------------------
2023-03-25 13:35:20,272 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:20,274 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:20,277 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 13:35:22,451 : [INFO]  ------------------------- Batch round 2, loss: 0.555 -------------------------
2023-03-25 13:35:22,451 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:22,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:22,490 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 13:35:25,518 : [INFO]  ------------------------- Batch round 3, loss: 0.5498 -------------------------
2023-03-25 13:35:25,519 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:25,727 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:25,729 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 13:35:25,730 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 13:35:27,079 : [INFO]  Batch 31: Training set : loss - 0.5336, accuracy - 0.788, recall - 0.8913, AUC - 0.9002, F1 - 0.8079, precision - 0.7387, training time - -11.0 seconds
2023-03-25 13:35:27,079 : [INFO]  Batch 31: Testing set : loss - 0.5729, accuracy - 0.7304, recall - 0.8824, AUC - 0.8479, F1 - 0.766, precision - 0.6767
2023-03-25 13:35:27,092 : [INFO]  Batch 32 initialized 
2023-03-25 13:35:27,548 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:27,864 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 13:35:32,319 : [INFO]  ------------------------- Batch round 1, loss: 0.5769 -------------------------
2023-03-25 13:35:32,319 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:32,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:32,462 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 13:35:34,623 : [INFO]  ------------------------- Batch round 2, loss: 0.5631 -------------------------
2023-03-25 13:35:34,623 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:34,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:34,722 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 13:35:36,851 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 13:35:36,851 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:36,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:36,984 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 13:35:36,984 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 13:35:38,352 : [INFO]  Batch 32: Training set : loss - 0.5527, accuracy - 0.788, recall - 0.9348, AUC - 0.8636, F1 - 0.8152, precision - 0.7227, training time - -9.0 seconds
2023-03-25 13:35:38,352 : [INFO]  Batch 32: Testing set : loss - 0.5676, accuracy - 0.7353, recall - 0.9216, AUC - 0.8841, F1 - 0.7769, precision - 0.6714
2023-03-25 13:35:38,366 : [INFO]  Batch 33 initialized 
2023-03-25 13:35:38,850 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:39,281 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 13:35:43,880 : [INFO]  ------------------------- Batch round 1, loss: 0.5652 -------------------------
2023-03-25 13:35:43,880 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:44,040 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:44,042 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 13:35:45,999 : [INFO]  ------------------------- Batch round 2, loss: 0.5542 -------------------------
2023-03-25 13:35:45,999 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:46,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:46,096 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 13:35:48,071 : [INFO]  ------------------------- Batch round 3, loss: 0.553 -------------------------
2023-03-25 13:35:48,071 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:48,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:48,141 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 13:35:48,142 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 13:35:49,442 : [INFO]  Batch 33: Training set : loss - 0.5658, accuracy - 0.7283, recall - 0.9891, AUC - 0.9057, F1 - 0.7845, precision - 0.65, training time - -9.0 seconds
2023-03-25 13:35:49,442 : [INFO]  Batch 33: Testing set : loss - 0.5824, accuracy - 0.6961, recall - 0.9706, AUC - 0.8971, F1 - 0.7615, precision - 0.6266
2023-03-25 13:35:49,452 : [INFO]  Batch 34 initialized 
2023-03-25 13:35:49,872 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:35:50,178 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 13:35:54,105 : [INFO]  ------------------------- Batch round 1, loss: 0.5624 -------------------------
2023-03-25 13:35:54,105 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 13:35:54,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:54,110 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 13:35:56,230 : [INFO]  ------------------------- Batch round 2, loss: 0.5524 -------------------------
2023-03-25 13:35:56,230 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 13:35:56,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:56,236 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 13:35:58,350 : [INFO]  ------------------------- Batch round 3, loss: 0.5488 -------------------------
2023-03-25 13:35:58,351 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 13:35:58,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:35:58,355 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 13:35:58,355 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 13:35:59,662 : [INFO]  Batch 34: Training set : loss - 0.5408, accuracy - 0.7826, recall - 0.9348, AUC - 0.9002, F1 - 0.8113, precision - 0.7167, training time - -8.0 seconds
2023-03-25 13:35:59,662 : [INFO]  Batch 34: Testing set : loss - 0.5536, accuracy - 0.7451, recall - 0.9412, AUC - 0.8857, F1 - 0.7869, precision - 0.6761
2023-03-25 13:35:59,667 : [INFO]  Batch 35 initialized 
2023-03-25 13:36:00,090 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:36:00,411 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 13:36:04,448 : [INFO]  ------------------------- Batch round 1, loss: 0.5517 -------------------------
2023-03-25 13:36:04,448 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 13:36:04,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:04,453 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 13:36:06,694 : [INFO]  ------------------------- Batch round 2, loss: 0.5477 -------------------------
2023-03-25 13:36:06,694 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 13:36:06,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:06,699 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 13:36:08,932 : [INFO]  ------------------------- Batch round 3, loss: 0.5422 -------------------------
2023-03-25 13:36:08,932 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 13:36:08,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:08,942 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 13:36:08,942 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 13:36:10,455 : [INFO]  Batch 35: Training set : loss - 0.5417, accuracy - 0.7772, recall - 0.913, AUC - 0.8872, F1 - 0.8038, precision - 0.7179, training time - -9.0 seconds
2023-03-25 13:36:10,456 : [INFO]  Batch 35: Testing set : loss - 0.5706, accuracy - 0.7206, recall - 0.9412, AUC - 0.8708, F1 - 0.7711, precision - 0.6531
2023-03-25 13:36:10,463 : [INFO]  Batch 36 initialized 
2023-03-25 13:36:10,902 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:36:11,226 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
