2023-03-25 17:12:47,348 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 17:12:47,348 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 2, epochs 6
2023-03-25 17:12:50,742 : [INFO]  Model initialized for training
2023-03-25 17:13:11,187 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:13:11,454 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 17:13:11,454 : [INFO]  Connected to the server
2023-03-25 17:13:11,611 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 17:13:11,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:13:11,625 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 17:13:11,625 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 17:14:33,199 : [INFO]  ------------------------- Training round 1, loss: 0.6573 -------------------------
2023-03-25 17:14:33,200 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 17:14:33,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:14:33,210 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 17:15:21,889 : [INFO]  ------------------------- Training round 2, loss: 0.6092 -------------------------
2023-03-25 17:15:21,889 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 17:15:21,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:15:21,894 : [INFO]  ################ Initial trained model: Final global model evalution after 2 rounds ################
2023-03-25 17:16:13,770 : [INFO]  Initially trained model: Training set : loss - 0.61, accuracy - 0.68, recall - 0.88, AUC - 0.8, F1 - 0.73, precision - 0.63, training time - -130.0 seconds
2023-03-25 17:16:13,770 : [INFO]  Initially trained model: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.88, AUC - 0.81, F1 - 0.73, precision - 0.62
2023-03-25 17:16:13,785 : [INFO]  Batch 1 initialized 
2023-03-25 17:16:14,309 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:14,455 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 17:16:14,455 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 17:16:19,763 : [INFO]  ------------------------- Batch round 1, loss: 0.6041 -------------------------
2023-03-25 17:16:19,763 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:20,010 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:20,012 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 17:16:22,357 : [INFO]  ------------------------- Batch round 2, loss: 0.6011 -------------------------
2023-03-25 17:16:22,357 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:22,483 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:22,486 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 17:16:22,486 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-25 17:16:24,290 : [INFO]  Batch 1: Training set : loss - 0.6163, accuracy - 0.7065, recall - 0.913, AUC - 0.7798, F1 - 0.7568, precision - 0.6462, training time - -8.0 seconds
2023-03-25 17:16:24,290 : [INFO]  Batch 1: Testing set : loss - 0.5894, accuracy - 0.7059, recall - 0.9216, AUC - 0.8652, F1 - 0.7581, precision - 0.6438
2023-03-25 17:16:24,299 : [INFO]  Batch 2 initialized 
2023-03-25 17:16:24,947 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:25,251 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 17:16:31,382 : [INFO]  ------------------------- Batch round 1, loss: 0.5912 -------------------------
2023-03-25 17:16:31,382 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:31,390 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:31,392 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 17:16:34,261 : [INFO]  ------------------------- Batch round 2, loss: 0.5936 -------------------------
2023-03-25 17:16:34,261 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:34,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:34,305 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 17:16:34,305 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-25 17:16:35,956 : [INFO]  Batch 2: Training set : loss - 0.6075, accuracy - 0.7065, recall - 0.9457, AUC - 0.7946, F1 - 0.7632, precision - 0.6397, training time - -9.0 seconds
2023-03-25 17:16:35,956 : [INFO]  Batch 2: Testing set : loss - 0.5914, accuracy - 0.7402, recall - 0.9608, AUC - 0.8646, F1 - 0.7871, precision - 0.6667
2023-03-25 17:16:35,969 : [INFO]  Batch 3 initialized 
2023-03-25 17:16:36,542 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:36,905 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 17:16:42,290 : [INFO]  ------------------------- Batch round 1, loss: 0.574 -------------------------
2023-03-25 17:16:42,304 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:42,387 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:42,389 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 17:16:44,894 : [INFO]  ------------------------- Batch round 2, loss: 0.5753 -------------------------
2023-03-25 17:16:44,894 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:44,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:44,902 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 17:16:44,902 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-25 17:16:46,585 : [INFO]  Batch 3: Training set : loss - 0.5982, accuracy - 0.7065, recall - 0.8478, AUC - 0.828, F1 - 0.7429, precision - 0.661, training time - -8.0 seconds
2023-03-25 17:16:46,585 : [INFO]  Batch 3: Testing set : loss - 0.6096, accuracy - 0.6716, recall - 0.8529, AUC - 0.7982, F1 - 0.722, precision - 0.6259
2023-03-25 17:16:46,594 : [INFO]  Batch 4 initialized 
2023-03-25 17:16:47,123 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:47,407 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 17:16:52,996 : [INFO]  ------------------------- Batch round 1, loss: 0.5782 -------------------------
2023-03-25 17:16:52,996 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:53,030 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:53,033 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 17:16:55,421 : [INFO]  ------------------------- Batch round 2, loss: 0.5841 -------------------------
2023-03-25 17:16:55,421 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:55,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:55,676 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 17:16:55,677 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-25 17:16:57,418 : [INFO]  Batch 4: Training set : loss - 0.6028, accuracy - 0.6902, recall - 0.9674, AUC - 0.816, F1 - 0.7574, precision - 0.6224, training time - -8.0 seconds
2023-03-25 17:16:57,419 : [INFO]  Batch 4: Testing set : loss - 0.5749, accuracy - 0.7255, recall - 0.9608, AUC - 0.8896, F1 - 0.7778, precision - 0.6533
2023-03-25 17:16:57,428 : [INFO]  Batch 5 initialized 
2023-03-25 17:16:58,319 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:58,656 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 17:17:03,410 : [INFO]  ------------------------- Batch round 1, loss: 0.562 -------------------------
2023-03-25 17:17:03,410 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:03,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:03,483 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 17:17:05,672 : [INFO]  ------------------------- Batch round 2, loss: 0.5617 -------------------------
2023-03-25 17:17:05,672 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:05,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:05,735 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 17:17:05,735 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-25 17:17:07,292 : [INFO]  Batch 5: Training set : loss - 0.5661, accuracy - 0.7609, recall - 0.9565, AUC - 0.8922, F1 - 0.8, precision - 0.6875, training time - -7.0 seconds
2023-03-25 17:17:07,292 : [INFO]  Batch 5: Testing set : loss - 0.5602, accuracy - 0.7647, recall - 0.9412, AUC - 0.8953, F1 - 0.8, precision - 0.6957
2023-03-25 17:17:07,307 : [INFO]  Batch 6 initialized 
2023-03-25 17:17:07,767 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:08,036 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 17:17:12,313 : [INFO]  ------------------------- Batch round 1, loss: 0.5639 -------------------------
2023-03-25 17:17:12,313 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:12,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:12,405 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 17:17:14,546 : [INFO]  ------------------------- Batch round 2, loss: 0.5632 -------------------------
2023-03-25 17:17:14,546 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:14,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:14,555 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 17:17:14,555 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-25 17:17:15,979 : [INFO]  Batch 6: Training set : loss - 0.5693, accuracy - 0.7446, recall - 0.9565, AUC - 0.8874, F1 - 0.7892, precision - 0.6718, training time - -7.0 seconds
2023-03-25 17:17:15,980 : [INFO]  Batch 6: Testing set : loss - 0.6137, accuracy - 0.6618, recall - 0.902, AUC - 0.8093, F1 - 0.7273, precision - 0.6093
2023-03-25 17:17:15,989 : [INFO]  Batch 7 initialized 
2023-03-25 17:17:16,789 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:17,210 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 17:17:21,737 : [INFO]  ------------------------- Batch round 1, loss: 0.5846 -------------------------
2023-03-25 17:17:21,737 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:21,821 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:21,823 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 17:17:24,373 : [INFO]  ------------------------- Batch round 2, loss: 0.5845 -------------------------
2023-03-25 17:17:24,373 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:24,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:24,637 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 17:17:24,638 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-25 17:17:26,545 : [INFO]  Batch 7: Training set : loss - 0.599, accuracy - 0.6902, recall - 0.8913, AUC - 0.8242, F1 - 0.7421, precision - 0.6357, training time - -7.0 seconds
2023-03-25 17:17:26,545 : [INFO]  Batch 7: Testing set : loss - 0.6319, accuracy - 0.5882, recall - 0.8529, AUC - 0.7827, F1 - 0.6744, precision - 0.5577
2023-03-25 17:17:26,558 : [INFO]  Batch 8 initialized 
2023-03-25 17:17:27,111 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:27,479 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 17:17:32,944 : [INFO]  ------------------------- Batch round 1, loss: 0.5884 -------------------------
2023-03-25 17:17:32,945 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:33,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:33,005 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 17:17:35,597 : [INFO]  ------------------------- Batch round 2, loss: 0.5986 -------------------------
2023-03-25 17:17:35,597 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:35,644 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:35,646 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 17:17:35,647 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-25 17:17:37,260 : [INFO]  Batch 8: Training set : loss - 0.6047, accuracy - 0.663, recall - 0.9022, AUC - 0.8341, F1 - 0.7281, precision - 0.6103, training time - -8.0 seconds
2023-03-25 17:17:37,260 : [INFO]  Batch 8: Testing set : loss - 0.6192, accuracy - 0.6863, recall - 0.9118, AUC - 0.783, F1 - 0.744, precision - 0.6284
2023-03-25 17:17:37,273 : [INFO]  Batch 9 initialized 
2023-03-25 17:17:37,806 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:38,123 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 17:17:43,119 : [INFO]  ------------------------- Batch round 1, loss: 0.6015 -------------------------
2023-03-25 17:17:43,119 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:43,123 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:43,125 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 17:17:45,720 : [INFO]  ------------------------- Batch round 2, loss: 0.6023 -------------------------
2023-03-25 17:17:45,720 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:45,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:45,727 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 17:17:45,727 : [INFO]  ################ Batch 9: final global model evalution after 2 rounds ################
2023-03-25 17:17:47,532 : [INFO]  Batch 9: Training set : loss - 0.6177, accuracy - 0.6522, recall - 0.7935, AUC - 0.7495, F1 - 0.6952, precision - 0.6186, training time - -8.0 seconds
2023-03-25 17:17:47,532 : [INFO]  Batch 9: Testing set : loss - 0.6257, accuracy - 0.6814, recall - 0.8333, AUC - 0.7335, F1 - 0.7234, precision - 0.6391
2023-03-25 17:17:47,546 : [INFO]  Batch 10 initialized 
2023-03-25 17:17:48,145 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:48,451 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 17:17:53,907 : [INFO]  ------------------------- Batch round 1, loss: 0.5819 -------------------------
2023-03-25 17:17:53,907 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:54,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:54,089 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 17:17:56,701 : [INFO]  ------------------------- Batch round 2, loss: 0.5844 -------------------------
2023-03-25 17:17:56,701 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:56,705 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:56,708 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 17:17:56,708 : [INFO]  ################ Batch 10: final global model evalution after 2 rounds ################
2023-03-25 17:17:58,324 : [INFO]  Batch 10: Training set : loss - 0.5977, accuracy - 0.7391, recall - 0.9457, AUC - 0.8149, F1 - 0.7838, precision - 0.6692, training time - -8.0 seconds
2023-03-25 17:17:58,324 : [INFO]  Batch 10: Testing set : loss - 0.5736, accuracy - 0.7255, recall - 0.9412, AUC - 0.8799, F1 - 0.7742, precision - 0.6575
2023-03-25 17:17:58,333 : [INFO]  Batch 11 initialized 
2023-03-25 17:17:58,846 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:59,150 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 17:18:03,668 : [INFO]  ------------------------- Batch round 1, loss: 0.6099 -------------------------
2023-03-25 17:18:03,668 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:03,677 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:03,680 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 17:18:06,099 : [INFO]  ------------------------- Batch round 2, loss: 0.603 -------------------------
2023-03-25 17:18:06,099 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:06,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:06,138 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 17:18:06,138 : [INFO]  ################ Batch 11: final global model evalution after 2 rounds ################
2023-03-25 17:18:08,146 : [INFO]  Batch 11: Training set : loss - 0.6198, accuracy - 0.6902, recall - 0.8587, AUC - 0.7723, F1 - 0.7349, precision - 0.6423, training time - -7.0 seconds
2023-03-25 17:18:08,146 : [INFO]  Batch 11: Testing set : loss - 0.6012, accuracy - 0.7157, recall - 0.902, AUC - 0.813, F1 - 0.7603, precision - 0.6571
2023-03-25 17:18:08,158 : [INFO]  Batch 12 initialized 
2023-03-25 17:18:08,740 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:09,066 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 17:18:15,833 : [INFO]  ------------------------- Batch round 1, loss: 0.6138 -------------------------
2023-03-25 17:18:15,833 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:16,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:16,267 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 17:18:19,229 : [INFO]  ------------------------- Batch round 2, loss: 0.6177 -------------------------
2023-03-25 17:18:19,229 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:19,472 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:19,476 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 17:18:19,476 : [INFO]  ################ Batch 12: final global model evalution after 2 rounds ################
2023-03-25 17:18:21,678 : [INFO]  Batch 12: Training set : loss - 0.6352, accuracy - 0.6522, recall - 0.8804, AUC - 0.7407, F1 - 0.7168, precision - 0.6045, training time - -10.0 seconds
2023-03-25 17:18:21,678 : [INFO]  Batch 12: Testing set : loss - 0.6291, accuracy - 0.6324, recall - 0.8529, AUC - 0.7476, F1 - 0.6988, precision - 0.5918
2023-03-25 17:18:21,695 : [INFO]  Batch 13 initialized 
2023-03-25 17:18:22,538 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:22,887 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 17:18:29,348 : [INFO]  ------------------------- Batch round 1, loss: 0.5753 -------------------------
2023-03-25 17:18:29,349 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:29,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:29,356 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 17:18:32,792 : [INFO]  ------------------------- Batch round 2, loss: 0.579 -------------------------
2023-03-25 17:18:32,792 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:32,863 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:32,867 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 17:18:32,867 : [INFO]  ################ Batch 13: final global model evalution after 2 rounds ################
2023-03-25 17:18:34,954 : [INFO]  Batch 13: Training set : loss - 0.5932, accuracy - 0.7174, recall - 0.913, AUC - 0.8253, F1 - 0.7636, precision - 0.6562, training time - -10.0 seconds
2023-03-25 17:18:34,954 : [INFO]  Batch 13: Testing set : loss - 0.5899, accuracy - 0.7353, recall - 0.902, AUC - 0.8571, F1 - 0.7731, precision - 0.6765
2023-03-25 17:18:34,972 : [INFO]  Batch 14 initialized 
2023-03-25 17:18:35,955 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:36,353 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 17:18:42,811 : [INFO]  ------------------------- Batch round 1, loss: 0.591 -------------------------
2023-03-25 17:18:42,811 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:43,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:43,172 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 17:18:45,641 : [INFO]  ------------------------- Batch round 2, loss: 0.5963 -------------------------
2023-03-25 17:18:45,641 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:45,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:45,655 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 17:18:45,655 : [INFO]  ################ Batch 14: final global model evalution after 2 rounds ################
2023-03-25 17:18:47,313 : [INFO]  Batch 14: Training set : loss - 0.6125, accuracy - 0.6957, recall - 0.9565, AUC - 0.8074, F1 - 0.7586, precision - 0.6286, training time - -9.0 seconds
2023-03-25 17:18:47,313 : [INFO]  Batch 14: Testing set : loss - 0.5961, accuracy - 0.7206, recall - 0.9216, AUC - 0.8242, F1 - 0.7673, precision - 0.6573
2023-03-25 17:18:47,325 : [INFO]  Batch 15 initialized 
2023-03-25 17:18:47,884 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:48,162 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 17:18:53,484 : [INFO]  ------------------------- Batch round 1, loss: 0.6095 -------------------------
2023-03-25 17:18:53,484 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:53,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:53,546 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 17:18:57,264 : [INFO]  ------------------------- Batch round 2, loss: 0.6083 -------------------------
2023-03-25 17:18:57,265 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:57,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:57,386 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 17:18:57,386 : [INFO]  ################ Batch 15: final global model evalution after 2 rounds ################
2023-03-25 17:19:00,037 : [INFO]  Batch 15: Training set : loss - 0.6185, accuracy - 0.6576, recall - 0.913, AUC - 0.7792, F1 - 0.7273, precision - 0.6043, training time - -9.0 seconds
2023-03-25 17:19:00,038 : [INFO]  Batch 15: Testing set : loss - 0.5886, accuracy - 0.7108, recall - 0.9412, AUC - 0.8474, F1 - 0.7649, precision - 0.6443
2023-03-25 17:19:00,052 : [INFO]  Batch 16 initialized 
2023-03-25 17:19:00,900 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:01,402 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 17:19:07,345 : [INFO]  ------------------------- Batch round 1, loss: 0.5951 -------------------------
2023-03-25 17:19:07,345 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:07,349 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:07,352 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 17:19:10,682 : [INFO]  ------------------------- Batch round 2, loss: 0.5963 -------------------------
2023-03-25 17:19:10,682 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 17:19:10,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:10,688 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 17:19:10,688 : [INFO]  ################ Batch 16: final global model evalution after 2 rounds ################
2023-03-25 17:19:12,788 : [INFO]  Batch 16: Training set : loss - 0.6009, accuracy - 0.7174, recall - 0.9565, AUC - 0.804, F1 - 0.7719, precision - 0.6471, training time - -9.0 seconds
2023-03-25 17:19:12,789 : [INFO]  Batch 16: Testing set : loss - 0.5777, accuracy - 0.7108, recall - 0.8824, AUC - 0.8662, F1 - 0.7531, precision - 0.6569
2023-03-25 17:19:12,801 : [INFO]  Batch 17 initialized 
2023-03-25 17:19:13,679 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:14,189 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 17:19:20,516 : [INFO]  ------------------------- Batch round 1, loss: 0.586 -------------------------
2023-03-25 17:19:20,516 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:20,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:20,523 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 17:19:23,055 : [INFO]  ------------------------- Batch round 2, loss: 0.5955 -------------------------
2023-03-25 17:19:23,056 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 17:19:23,111 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:23,114 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 17:19:23,114 : [INFO]  ################ Batch 17: final global model evalution after 2 rounds ################
2023-03-25 17:19:25,371 : [INFO]  Batch 17: Training set : loss - 0.6238, accuracy - 0.6685, recall - 0.9348, AUC - 0.7665, F1 - 0.7382, precision - 0.6099, training time - -9.0 seconds
2023-03-25 17:19:25,371 : [INFO]  Batch 17: Testing set : loss - 0.6217, accuracy - 0.6765, recall - 0.9804, AUC - 0.7992, F1 - 0.7519, precision - 0.6098
2023-03-25 17:19:25,386 : [INFO]  Batch 18 initialized 
2023-03-25 17:19:25,985 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:26,254 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 17:19:30,421 : [INFO]  ------------------------- Batch round 1, loss: 0.6229 -------------------------
2023-03-25 17:19:30,421 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:30,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:30,427 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 17:19:32,692 : [INFO]  ------------------------- Batch round 2, loss: 0.6238 -------------------------
2023-03-25 17:19:32,692 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 17:19:32,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:32,697 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 17:19:32,697 : [INFO]  ################ Batch 18: final global model evalution after 2 rounds ################
2023-03-25 17:19:34,065 : [INFO]  Batch 18: Training set : loss - 0.655, accuracy - 0.6304, recall - 0.913, AUC - 0.689, F1 - 0.7119, precision - 0.5833, training time - -6.0 seconds
2023-03-25 17:19:34,065 : [INFO]  Batch 18: Testing set : loss - 0.6746, accuracy - 0.6078, recall - 0.8333, AUC - 0.6324, F1 - 0.68, precision - 0.5743
2023-03-25 17:19:34,071 : [INFO]  Batch 19 initialized 
2023-03-25 17:19:34,526 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:34,781 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 17:19:38,910 : [INFO]  ------------------------- Batch round 1, loss: 0.6047 -------------------------
2023-03-25 17:19:38,910 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:38,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:38,915 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
