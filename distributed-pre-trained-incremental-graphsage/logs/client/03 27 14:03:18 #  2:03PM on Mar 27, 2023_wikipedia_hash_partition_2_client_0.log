2023-03-27 14:03:18,050 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-27 14:03:18,051 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 6, epochs 6
2023-03-27 14:03:20,665 : [INFO]  Model initialized for training
2023-03-27 14:03:23,283 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:03:23,319 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-27 14:03:23,320 : [INFO]  Connected to the server
2023-03-27 14:03:23,440 : [INFO]  Distributed training for streaming graphs started!
2023-03-27 14:03:23,441 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:03:23,452 : [INFO]  ################################## Initial model training started ##################################
2023-03-27 14:03:23,452 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-27 14:03:49,200 : [INFO]  ------------------------- Training round 1, loss: 0.6634 -------------------------
2023-03-27 14:03:49,200 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-27 14:03:52,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:03:52,358 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-27 14:04:16,384 : [INFO]  ------------------------- Training round 2, loss: 0.5968 -------------------------
2023-03-27 14:04:16,384 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-27 14:04:16,388 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:04:16,390 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-27 14:04:37,581 : [INFO]  ------------------------- Training round 3, loss: 0.5797 -------------------------
2023-03-27 14:04:37,581 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-27 14:04:37,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:04:37,586 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-27 14:04:57,104 : [INFO]  ------------------------- Training round 4, loss: 0.572 -------------------------
2023-03-27 14:04:57,104 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-27 14:04:57,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:04:57,108 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-27 14:05:16,655 : [INFO]  ------------------------- Training round 5, loss: 0.5687 -------------------------
2023-03-27 14:05:16,655 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-27 14:05:16,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:16,660 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-27 14:05:36,688 : [INFO]  ------------------------- Training round 6, loss: 0.5673 -------------------------
2023-03-27 14:05:36,688 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-27 14:05:36,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:36,693 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-27 14:05:44,018 : [INFO]  Initially trained model: Training set : loss - 0.56, accuracy - 0.74, recall - 0.92, AUC - 0.88, F1 - 0.78, precision - 0.67, training time - -133.0 seconds
2023-03-27 14:05:44,018 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.74, recall - 0.92, AUC - 0.87, F1 - 0.78, precision - 0.68
2023-03-27 14:05:44,022 : [INFO]  Batch 1 initialized 
2023-03-27 14:05:44,447 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:05:44,555 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-27 14:05:44,555 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-27 14:05:48,573 : [INFO]  ------------------------- Batch round 1, loss: 0.5664 -------------------------
2023-03-27 14:05:48,573 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-27 14:05:48,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:48,577 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-27 14:05:50,874 : [INFO]  ------------------------- Batch round 2, loss: 0.5513 -------------------------
2023-03-27 14:05:50,874 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-27 14:05:50,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:50,879 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-27 14:05:53,094 : [INFO]  ------------------------- Batch round 3, loss: 0.5499 -------------------------
2023-03-27 14:05:53,094 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-27 14:05:53,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:53,099 : [INFO]  Batch number 1 model fetched from the server
2023-03-27 14:05:53,099 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-27 14:05:54,776 : [INFO]  Batch 1: Training set : loss - 0.5499, accuracy - 0.788, recall - 0.913, AUC - 0.865, F1 - 0.8116, precision - 0.7304, training time - -9.0 seconds
2023-03-27 14:05:54,776 : [INFO]  Batch 1: Testing set : loss - 0.5679, accuracy - 0.7647, recall - 0.9412, AUC - 0.8519, F1 - 0.8, precision - 0.6957
2023-03-27 14:05:54,781 : [INFO]  Batch 2 initialized 
2023-03-27 14:05:55,242 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:05:55,405 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-27 14:05:59,389 : [INFO]  ------------------------- Batch round 1, loss: 0.5843 -------------------------
2023-03-27 14:05:59,389 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-27 14:05:59,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:59,393 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-27 14:06:01,583 : [INFO]  ------------------------- Batch round 2, loss: 0.5747 -------------------------
2023-03-27 14:06:01,583 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:01,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:01,703 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-27 14:06:03,861 : [INFO]  ------------------------- Batch round 3, loss: 0.5704 -------------------------
2023-03-27 14:06:03,861 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:03,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:03,928 : [INFO]  Batch number 2 model fetched from the server
2023-03-27 14:06:03,928 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-27 14:06:05,302 : [INFO]  Batch 2: Training set : loss - 0.5663, accuracy - 0.7609, recall - 0.8913, AUC - 0.8456, F1 - 0.7885, precision - 0.7069, training time - -9.0 seconds
2023-03-27 14:06:05,302 : [INFO]  Batch 2: Testing set : loss - 0.5817, accuracy - 0.7206, recall - 0.9216, AUC - 0.8295, F1 - 0.7673, precision - 0.6573
2023-03-27 14:06:05,314 : [INFO]  Batch 3 initialized 
2023-03-27 14:06:05,762 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:06,003 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-27 14:06:10,588 : [INFO]  ------------------------- Batch round 1, loss: 0.597 -------------------------
2023-03-27 14:06:10,588 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:10,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:10,593 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-27 14:06:13,848 : [INFO]  ------------------------- Batch round 2, loss: 0.5883 -------------------------
2023-03-27 14:06:13,848 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:14,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:14,120 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-27 14:06:16,339 : [INFO]  ------------------------- Batch round 3, loss: 0.5837 -------------------------
2023-03-27 14:06:16,339 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:16,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:16,343 : [INFO]  Batch number 3 model fetched from the server
2023-03-27 14:06:16,343 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-27 14:06:17,780 : [INFO]  Batch 3: Training set : loss - 0.5802, accuracy - 0.7283, recall - 0.9239, AUC - 0.8358, F1 - 0.7727, precision - 0.6641, training time - -10.0 seconds
2023-03-27 14:06:17,780 : [INFO]  Batch 3: Testing set : loss - 0.5689, accuracy - 0.7549, recall - 0.9314, AUC - 0.8554, F1 - 0.7917, precision - 0.6884
2023-03-27 14:06:17,786 : [INFO]  Batch 4 initialized 
2023-03-27 14:06:18,433 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:18,691 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-27 14:06:22,754 : [INFO]  ------------------------- Batch round 1, loss: 0.5451 -------------------------
2023-03-27 14:06:22,754 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:22,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:22,759 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-27 14:06:25,097 : [INFO]  ------------------------- Batch round 2, loss: 0.5394 -------------------------
2023-03-27 14:06:25,097 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:25,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:25,141 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-27 14:06:27,375 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-27 14:06:27,375 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:27,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:27,436 : [INFO]  Batch number 4 model fetched from the server
2023-03-27 14:06:27,436 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-27 14:06:28,817 : [INFO]  Batch 4: Training set : loss - 0.5311, accuracy - 0.7663, recall - 0.9674, AUC - 0.94, F1 - 0.8054, precision - 0.6899, training time - -9.0 seconds
2023-03-27 14:06:28,817 : [INFO]  Batch 4: Testing set : loss - 0.5405, accuracy - 0.7696, recall - 0.9314, AUC - 0.9006, F1 - 0.8017, precision - 0.7037
2023-03-27 14:06:28,823 : [INFO]  Batch 5 initialized 
2023-03-27 14:06:29,250 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:29,480 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-27 14:06:33,410 : [INFO]  ------------------------- Batch round 1, loss: 0.5649 -------------------------
2023-03-27 14:06:33,410 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:33,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:33,647 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-27 14:06:35,777 : [INFO]  ------------------------- Batch round 2, loss: 0.5585 -------------------------
2023-03-27 14:06:35,777 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:35,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:35,865 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-27 14:06:37,999 : [INFO]  ------------------------- Batch round 3, loss: 0.5555 -------------------------
2023-03-27 14:06:38,000 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:38,073 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:38,075 : [INFO]  Batch number 5 model fetched from the server
2023-03-27 14:06:38,075 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-27 14:06:39,452 : [INFO]  Batch 5: Training set : loss - 0.5525, accuracy - 0.7609, recall - 0.9457, AUC - 0.8899, F1 - 0.7982, precision - 0.6905, training time - -9.0 seconds
2023-03-27 14:06:39,452 : [INFO]  Batch 5: Testing set : loss - 0.5583, accuracy - 0.7941, recall - 0.951, AUC - 0.8862, F1 - 0.822, precision - 0.7239
2023-03-27 14:06:39,456 : [INFO]  Batch 6 initialized 
2023-03-27 14:06:39,861 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:40,101 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-27 14:06:44,253 : [INFO]  ------------------------- Batch round 1, loss: 0.5626 -------------------------
2023-03-27 14:06:44,253 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:44,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:44,258 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-27 14:06:46,556 : [INFO]  ------------------------- Batch round 2, loss: 0.5553 -------------------------
2023-03-27 14:06:46,556 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:46,559 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:46,561 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-27 14:06:49,035 : [INFO]  ------------------------- Batch round 3, loss: 0.5545 -------------------------
2023-03-27 14:06:49,036 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:49,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:49,040 : [INFO]  Batch number 6 model fetched from the server
2023-03-27 14:06:49,040 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-27 14:06:50,486 : [INFO]  Batch 6: Training set : loss - 0.5546, accuracy - 0.7717, recall - 0.9674, AUC - 0.8566, F1 - 0.8091, precision - 0.6953, training time - -9.0 seconds
2023-03-27 14:06:50,486 : [INFO]  Batch 6: Testing set : loss - 0.581, accuracy - 0.7206, recall - 0.9314, AUC - 0.8341, F1 - 0.7692, precision - 0.6552
2023-03-27 14:06:50,493 : [INFO]  Batch 7 initialized 
2023-03-27 14:06:50,956 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:51,194 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-27 14:06:55,553 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-27 14:06:55,553 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:55,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:55,559 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-27 14:06:58,219 : [INFO]  ------------------------- Batch round 2, loss: 0.5614 -------------------------
2023-03-27 14:06:58,219 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:58,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:58,224 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-27 14:07:00,540 : [INFO]  ------------------------- Batch round 3, loss: 0.5578 -------------------------
2023-03-27 14:07:00,540 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:00,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:00,546 : [INFO]  Batch number 7 model fetched from the server
2023-03-27 14:07:00,546 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-27 14:07:02,240 : [INFO]  Batch 7: Training set : loss - 0.5546, accuracy - 0.7772, recall - 0.9457, AUC - 0.87, F1 - 0.8093, precision - 0.7073, training time - -9.0 seconds
2023-03-27 14:07:02,241 : [INFO]  Batch 7: Testing set : loss - 0.5519, accuracy - 0.7696, recall - 0.9216, AUC - 0.8701, F1 - 0.8, precision - 0.7068
2023-03-27 14:07:02,251 : [INFO]  Batch 8 initialized 
2023-03-27 14:07:02,698 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:02,921 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-27 14:07:07,289 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-27 14:07:07,289 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:07,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:07,527 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-27 14:07:09,850 : [INFO]  ------------------------- Batch round 2, loss: 0.5561 -------------------------
2023-03-27 14:07:09,851 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:09,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:09,900 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-27 14:07:12,451 : [INFO]  ------------------------- Batch round 3, loss: 0.5556 -------------------------
2023-03-27 14:07:12,452 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:12,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:12,469 : [INFO]  Batch number 8 model fetched from the server
2023-03-27 14:07:12,469 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-27 14:07:13,889 : [INFO]  Batch 8: Training set : loss - 0.5511, accuracy - 0.7826, recall - 0.9457, AUC - 0.8649, F1 - 0.8131, precision - 0.7131, training time - -10.0 seconds
2023-03-27 14:07:13,889 : [INFO]  Batch 8: Testing set : loss - 0.5987, accuracy - 0.6765, recall - 0.8824, AUC - 0.8147, F1 - 0.7317, precision - 0.625
2023-03-27 14:07:13,893 : [INFO]  Batch 9 initialized 
2023-03-27 14:07:14,308 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:14,569 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-27 14:07:18,561 : [INFO]  ------------------------- Batch round 1, loss: 0.5589 -------------------------
2023-03-27 14:07:18,561 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:18,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:18,566 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-27 14:07:20,954 : [INFO]  ------------------------- Batch round 2, loss: 0.5473 -------------------------
2023-03-27 14:07:20,954 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:20,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:20,961 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-27 14:07:23,367 : [INFO]  ------------------------- Batch round 3, loss: 0.5454 -------------------------
2023-03-27 14:07:23,367 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:23,370 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:23,372 : [INFO]  Batch number 9 model fetched from the server
2023-03-27 14:07:23,372 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-27 14:07:24,753 : [INFO]  Batch 9: Training set : loss - 0.5469, accuracy - 0.7554, recall - 0.9565, AUC - 0.8881, F1 - 0.7964, precision - 0.6822, training time - -9.0 seconds
2023-03-27 14:07:24,753 : [INFO]  Batch 9: Testing set : loss - 0.5436, accuracy - 0.7647, recall - 0.9216, AUC - 0.8755, F1 - 0.7966, precision - 0.7015
2023-03-27 14:07:24,759 : [INFO]  Batch 10 initialized 
2023-03-27 14:07:25,176 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:25,414 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-27 14:07:29,752 : [INFO]  ------------------------- Batch round 1, loss: 0.5539 -------------------------
2023-03-27 14:07:29,752 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:29,756 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:29,759 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-27 14:07:32,382 : [INFO]  ------------------------- Batch round 2, loss: 0.5483 -------------------------
2023-03-27 14:07:32,382 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:32,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:32,386 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-27 14:07:34,859 : [INFO]  ------------------------- Batch round 3, loss: 0.5454 -------------------------
2023-03-27 14:07:34,859 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:34,862 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:34,865 : [INFO]  Batch number 10 model fetched from the server
2023-03-27 14:07:34,865 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-27 14:07:36,443 : [INFO]  Batch 10: Training set : loss - 0.5477, accuracy - 0.7826, recall - 0.9239, AUC - 0.878, F1 - 0.8095, precision - 0.7203, training time - -9.0 seconds
2023-03-27 14:07:36,443 : [INFO]  Batch 10: Testing set : loss - 0.5729, accuracy - 0.7402, recall - 0.8824, AUC - 0.8655, F1 - 0.7725, precision - 0.687
2023-03-27 14:07:36,456 : [INFO]  Batch 11 initialized 
2023-03-27 14:07:36,910 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:37,159 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-27 14:07:41,237 : [INFO]  ------------------------- Batch round 1, loss: 0.5404 -------------------------
2023-03-27 14:07:41,237 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:41,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:41,242 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-27 14:07:43,395 : [INFO]  ------------------------- Batch round 2, loss: 0.5318 -------------------------
2023-03-27 14:07:43,395 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:43,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:43,400 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-27 14:07:45,547 : [INFO]  ------------------------- Batch round 3, loss: 0.526 -------------------------
2023-03-27 14:07:45,548 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:45,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:45,570 : [INFO]  Batch number 11 model fetched from the server
2023-03-27 14:07:45,570 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-27 14:07:47,163 : [INFO]  Batch 11: Training set : loss - 0.5229, accuracy - 0.8098, recall - 0.9783, AUC - 0.9366, F1 - 0.8372, precision - 0.7317, training time - -8.0 seconds
2023-03-27 14:07:47,164 : [INFO]  Batch 11: Testing set : loss - 0.5486, accuracy - 0.7647, recall - 0.9412, AUC - 0.9153, F1 - 0.8, precision - 0.6957
2023-03-27 14:07:47,168 : [INFO]  Batch 12 initialized 
2023-03-27 14:07:47,698 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:48,011 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-27 14:07:52,317 : [INFO]  ------------------------- Batch round 1, loss: 0.5177 -------------------------
2023-03-27 14:07:52,317 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:52,320 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:52,321 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-27 14:07:54,869 : [INFO]  ------------------------- Batch round 2, loss: 0.5141 -------------------------
2023-03-27 14:07:54,870 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:54,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:54,875 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-27 14:07:57,308 : [INFO]  ------------------------- Batch round 3, loss: 0.5107 -------------------------
2023-03-27 14:07:57,308 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:57,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:57,313 : [INFO]  Batch number 12 model fetched from the server
2023-03-27 14:07:57,313 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-27 14:07:58,746 : [INFO]  Batch 12: Training set : loss - 0.5127, accuracy - 0.8424, recall - 0.9891, AUC - 0.92, F1 - 0.8626, precision - 0.7647, training time - -9.0 seconds
2023-03-27 14:07:58,746 : [INFO]  Batch 12: Testing set : loss - 0.5634, accuracy - 0.7402, recall - 0.9412, AUC - 0.8854, F1 - 0.7837, precision - 0.6713
2023-03-27 14:07:58,750 : [INFO]  Batch 13 initialized 
2023-03-27 14:07:59,249 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:59,556 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-27 14:08:03,905 : [INFO]  ------------------------- Batch round 1, loss: 0.5397 -------------------------
2023-03-27 14:08:03,905 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:03,908 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:03,910 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-27 14:08:06,357 : [INFO]  ------------------------- Batch round 2, loss: 0.5345 -------------------------
2023-03-27 14:08:06,357 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:06,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:06,386 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-27 14:08:08,964 : [INFO]  ------------------------- Batch round 3, loss: 0.5308 -------------------------
2023-03-27 14:08:08,964 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:08,987 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:08,989 : [INFO]  Batch number 13 model fetched from the server
2023-03-27 14:08:08,989 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-27 14:08:10,873 : [INFO]  Batch 13: Training set : loss - 0.533, accuracy - 0.7935, recall - 0.9783, AUC - 0.9324, F1 - 0.8257, precision - 0.7143, training time - -9.0 seconds
2023-03-27 14:08:10,873 : [INFO]  Batch 13: Testing set : loss - 0.5654, accuracy - 0.7696, recall - 0.9804, AUC - 0.8515, F1 - 0.8097, precision - 0.6897
2023-03-27 14:08:10,880 : [INFO]  Batch 14 initialized 
2023-03-27 14:08:11,329 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:11,567 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-27 14:08:15,510 : [INFO]  ------------------------- Batch round 1, loss: 0.5516 -------------------------
2023-03-27 14:08:15,510 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:15,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:15,515 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-27 14:08:17,748 : [INFO]  ------------------------- Batch round 2, loss: 0.5458 -------------------------
2023-03-27 14:08:17,748 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:17,808 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:17,810 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-27 14:08:20,036 : [INFO]  ------------------------- Batch round 3, loss: 0.5434 -------------------------
2023-03-27 14:08:20,036 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:20,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:20,040 : [INFO]  Batch number 14 model fetched from the server
2023-03-27 14:08:20,040 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-27 14:08:21,447 : [INFO]  Batch 14: Training set : loss - 0.5403, accuracy - 0.7663, recall - 0.9348, AUC - 0.9222, F1 - 0.8, precision - 0.6992, training time - -8.0 seconds
2023-03-27 14:08:21,447 : [INFO]  Batch 14: Testing set : loss - 0.568, accuracy - 0.75, recall - 0.9216, AUC - 0.871, F1 - 0.7866, precision - 0.6861
2023-03-27 14:08:21,451 : [INFO]  Batch 15 initialized 
2023-03-27 14:08:21,866 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:22,121 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-27 14:08:26,151 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-27 14:08:26,151 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:26,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:26,157 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-27 14:08:28,353 : [INFO]  ------------------------- Batch round 2, loss: 0.5517 -------------------------
2023-03-27 14:08:28,353 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:28,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:28,357 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-27 14:08:30,550 : [INFO]  ------------------------- Batch round 3, loss: 0.545 -------------------------
2023-03-27 14:08:30,550 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:30,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:30,617 : [INFO]  Batch number 15 model fetched from the server
2023-03-27 14:08:30,617 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-27 14:08:31,993 : [INFO]  Batch 15: Training set : loss - 0.5492, accuracy - 0.7663, recall - 0.913, AUC - 0.8703, F1 - 0.7962, precision - 0.7059, training time - -8.0 seconds
2023-03-27 14:08:31,993 : [INFO]  Batch 15: Testing set : loss - 0.5444, accuracy - 0.7794, recall - 0.9216, AUC - 0.8854, F1 - 0.8069, precision - 0.7176
2023-03-27 14:08:31,999 : [INFO]  Batch 16 initialized 
2023-03-27 14:08:32,410 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:32,672 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-27 14:08:36,575 : [INFO]  ------------------------- Batch round 1, loss: 0.552 -------------------------
2023-03-27 14:08:36,575 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:36,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:36,580 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-27 14:08:38,830 : [INFO]  ------------------------- Batch round 2, loss: 0.5489 -------------------------
2023-03-27 14:08:38,830 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:38,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:38,835 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-27 14:08:41,278 : [INFO]  ------------------------- Batch round 3, loss: 0.5456 -------------------------
2023-03-27 14:08:41,278 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:41,280 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:41,282 : [INFO]  Batch number 16 model fetched from the server
2023-03-27 14:08:41,282 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-27 14:08:42,777 : [INFO]  Batch 16: Training set : loss - 0.5434, accuracy - 0.7717, recall - 0.9457, AUC - 0.8905, F1 - 0.8056, precision - 0.7016, training time - -9.0 seconds
2023-03-27 14:08:42,778 : [INFO]  Batch 16: Testing set : loss - 0.5464, accuracy - 0.7402, recall - 0.9118, AUC - 0.8986, F1 - 0.7782, precision - 0.6788
2023-03-27 14:08:42,790 : [INFO]  Batch 17 initialized 
2023-03-27 14:08:43,257 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:43,511 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-27 14:08:47,713 : [INFO]  ------------------------- Batch round 1, loss: 0.5238 -------------------------
2023-03-27 14:08:47,713 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:48,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:48,058 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-27 14:08:50,406 : [INFO]  ------------------------- Batch round 2, loss: 0.5202 -------------------------
2023-03-27 14:08:50,406 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:50,409 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:50,411 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-27 14:08:53,221 : [INFO]  ------------------------- Batch round 3, loss: 0.5158 -------------------------
2023-03-27 14:08:53,221 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:53,224 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:53,226 : [INFO]  Batch number 17 model fetched from the server
2023-03-27 14:08:53,226 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-27 14:08:54,898 : [INFO]  Batch 17: Training set : loss - 0.5136, accuracy - 0.8207, recall - 0.9457, AUC - 0.9314, F1 - 0.8406, precision - 0.7565, training time - -10.0 seconds
2023-03-27 14:08:54,898 : [INFO]  Batch 17: Testing set : loss - 0.5504, accuracy - 0.7647, recall - 0.9902, AUC - 0.9208, F1 - 0.808, precision - 0.6824
2023-03-27 14:08:54,902 : [INFO]  Batch 18 initialized 
2023-03-27 14:08:55,314 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:55,573 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-27 14:09:00,038 : [INFO]  ------------------------- Batch round 1, loss: 0.5538 -------------------------
2023-03-27 14:09:00,038 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:00,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:00,043 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-27 14:09:02,424 : [INFO]  ------------------------- Batch round 2, loss: 0.5462 -------------------------
2023-03-27 14:09:02,424 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:02,428 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:02,429 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-27 14:09:04,844 : [INFO]  ------------------------- Batch round 3, loss: 0.5449 -------------------------
2023-03-27 14:09:04,844 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:04,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:04,855 : [INFO]  Batch number 18 model fetched from the server
2023-03-27 14:09:04,855 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-27 14:09:06,518 : [INFO]  Batch 18: Training set : loss - 0.5492, accuracy - 0.7554, recall - 0.9348, AUC - 0.8963, F1 - 0.7926, precision - 0.688, training time - -9.0 seconds
2023-03-27 14:09:06,518 : [INFO]  Batch 18: Testing set : loss - 0.5466, accuracy - 0.7402, recall - 0.9216, AUC - 0.8898, F1 - 0.7801, precision - 0.6763
2023-03-27 14:09:06,524 : [INFO]  Batch 19 initialized 
2023-03-27 14:09:06,959 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:07,321 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-27 14:09:11,979 : [INFO]  ------------------------- Batch round 1, loss: 0.5422 -------------------------
2023-03-27 14:09:11,980 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:11,983 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:11,984 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-27 14:09:14,454 : [INFO]  ------------------------- Batch round 2, loss: 0.534 -------------------------
2023-03-27 14:09:14,454 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:14,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:14,460 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-27 14:09:17,075 : [INFO]  ------------------------- Batch round 3, loss: 0.5286 -------------------------
2023-03-27 14:09:17,075 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:17,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:17,080 : [INFO]  Batch number 19 model fetched from the server
2023-03-27 14:09:17,080 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-27 14:09:18,723 : [INFO]  Batch 19: Training set : loss - 0.5331, accuracy - 0.7717, recall - 0.913, AUC - 0.8965, F1 - 0.8, precision - 0.7119, training time - -10.0 seconds
2023-03-27 14:09:18,723 : [INFO]  Batch 19: Testing set : loss - 0.5589, accuracy - 0.7402, recall - 0.9412, AUC - 0.9021, F1 - 0.7837, precision - 0.6713
2023-03-27 14:09:18,727 : [INFO]  Batch 20 initialized 
2023-03-27 14:09:19,139 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:19,410 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-27 14:09:23,821 : [INFO]  ------------------------- Batch round 1, loss: 0.5662 -------------------------
2023-03-27 14:09:23,821 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:23,837 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:23,839 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-27 14:09:26,085 : [INFO]  ------------------------- Batch round 2, loss: 0.5621 -------------------------
2023-03-27 14:09:26,086 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:26,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:26,094 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-27 14:09:28,301 : [INFO]  ------------------------- Batch round 3, loss: 0.5598 -------------------------
2023-03-27 14:09:28,302 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:28,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:28,327 : [INFO]  Batch number 20 model fetched from the server
2023-03-27 14:09:28,328 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-27 14:09:29,782 : [INFO]  Batch 20: Training set : loss - 0.5562, accuracy - 0.7446, recall - 0.9022, AUC - 0.8834, F1 - 0.7793, precision - 0.686, training time - -9.0 seconds
2023-03-27 14:09:29,782 : [INFO]  Batch 20: Testing set : loss - 0.5767, accuracy - 0.7353, recall - 0.951, AUC - 0.8635, F1 - 0.7823, precision - 0.6644
2023-03-27 14:09:29,792 : [INFO]  Batch 21 initialized 
2023-03-27 14:09:30,218 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:30,505 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-27 14:09:35,049 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-27 14:09:35,050 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:35,055 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:35,058 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-27 14:09:37,586 : [INFO]  ------------------------- Batch round 2, loss: 0.5702 -------------------------
2023-03-27 14:09:37,587 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:37,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:37,631 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-27 14:09:40,029 : [INFO]  ------------------------- Batch round 3, loss: 0.5691 -------------------------
2023-03-27 14:09:40,030 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:40,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:40,082 : [INFO]  Batch number 21 model fetched from the server
2023-03-27 14:09:40,082 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-27 14:09:41,461 : [INFO]  Batch 21: Training set : loss - 0.5677, accuracy - 0.7663, recall - 0.9674, AUC - 0.85, F1 - 0.8054, precision - 0.6899, training time - -10.0 seconds
2023-03-27 14:09:41,461 : [INFO]  Batch 21: Testing set : loss - 0.5656, accuracy - 0.7206, recall - 0.8725, AUC - 0.8711, F1 - 0.7574, precision - 0.6692
2023-03-27 14:09:41,471 : [INFO]  Batch 22 initialized 
2023-03-27 14:09:41,964 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:42,279 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-27 14:09:46,998 : [INFO]  ------------------------- Batch round 1, loss: 0.5416 -------------------------
2023-03-27 14:09:46,998 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:47,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:47,003 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-27 14:09:49,359 : [INFO]  ------------------------- Batch round 2, loss: 0.5376 -------------------------
2023-03-27 14:09:49,359 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:49,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:49,391 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-27 14:09:51,817 : [INFO]  ------------------------- Batch round 3, loss: 0.5335 -------------------------
2023-03-27 14:09:51,817 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:51,820 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:51,821 : [INFO]  Batch number 22 model fetched from the server
2023-03-27 14:09:51,822 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-27 14:09:53,302 : [INFO]  Batch 22: Training set : loss - 0.5323, accuracy - 0.7826, recall - 0.913, AUC - 0.9002, F1 - 0.8077, precision - 0.7241, training time - -10.0 seconds
2023-03-27 14:09:53,302 : [INFO]  Batch 22: Testing set : loss - 0.5671, accuracy - 0.7402, recall - 0.8725, AUC - 0.8539, F1 - 0.7706, precision - 0.6899
2023-03-27 14:09:53,306 : [INFO]  Batch 23 initialized 
2023-03-27 14:09:53,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:54,043 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-27 14:09:58,703 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-27 14:09:58,704 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:58,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:58,713 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-27 14:10:01,315 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-27 14:10:01,315 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:01,318 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:01,320 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-27 14:10:03,715 : [INFO]  ------------------------- Batch round 3, loss: 0.5602 -------------------------
2023-03-27 14:10:03,715 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:03,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:03,724 : [INFO]  Batch number 23 model fetched from the server
2023-03-27 14:10:03,724 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-27 14:10:05,397 : [INFO]  Batch 23: Training set : loss - 0.5624, accuracy - 0.7228, recall - 0.9457, AUC - 0.8869, F1 - 0.7733, precision - 0.6541, training time - -10.0 seconds
2023-03-27 14:10:05,397 : [INFO]  Batch 23: Testing set : loss - 0.5558, accuracy - 0.7745, recall - 0.9412, AUC - 0.8723, F1 - 0.8067, precision - 0.7059
2023-03-27 14:10:05,403 : [INFO]  Batch 24 initialized 
2023-03-27 14:10:05,930 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:06,216 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-27 14:10:10,221 : [INFO]  ------------------------- Batch round 1, loss: 0.5671 -------------------------
2023-03-27 14:10:10,221 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:10,224 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:10,226 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-27 14:10:12,432 : [INFO]  ------------------------- Batch round 2, loss: 0.5604 -------------------------
2023-03-27 14:10:12,432 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:12,435 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:12,437 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-27 14:10:14,644 : [INFO]  ------------------------- Batch round 3, loss: 0.5567 -------------------------
2023-03-27 14:10:14,644 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:14,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:14,649 : [INFO]  Batch number 24 model fetched from the server
2023-03-27 14:10:14,649 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-27 14:10:16,147 : [INFO]  Batch 24: Training set : loss - 0.555, accuracy - 0.7554, recall - 0.9348, AUC - 0.8934, F1 - 0.7926, precision - 0.688, training time - -8.0 seconds
2023-03-27 14:10:16,147 : [INFO]  Batch 24: Testing set : loss - 0.5552, accuracy - 0.7451, recall - 0.9608, AUC - 0.8903, F1 - 0.7903, precision - 0.6712
2023-03-27 14:10:16,154 : [INFO]  Batch 25 initialized 
2023-03-27 14:10:16,600 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:16,899 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-27 14:10:21,497 : [INFO]  ------------------------- Batch round 1, loss: 0.5473 -------------------------
2023-03-27 14:10:21,497 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:21,502 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:21,504 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-27 14:10:23,828 : [INFO]  ------------------------- Batch round 2, loss: 0.5467 -------------------------
2023-03-27 14:10:23,828 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:23,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:23,859 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-27 14:10:26,128 : [INFO]  ------------------------- Batch round 3, loss: 0.5452 -------------------------
2023-03-27 14:10:26,128 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:26,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:26,215 : [INFO]  Batch number 25 model fetched from the server
2023-03-27 14:10:26,215 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-27 14:10:27,669 : [INFO]  Batch 25: Training set : loss - 0.5439, accuracy - 0.7663, recall - 0.9891, AUC - 0.9229, F1 - 0.8089, precision - 0.6842, training time - -9.0 seconds
2023-03-27 14:10:27,669 : [INFO]  Batch 25: Testing set : loss - 0.5449, accuracy - 0.7598, recall - 0.9412, AUC - 0.8846, F1 - 0.7967, precision - 0.6906
2023-03-27 14:10:27,673 : [INFO]  Batch 26 initialized 
2023-03-27 14:10:28,075 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:28,363 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-27 14:10:32,430 : [INFO]  ------------------------- Batch round 1, loss: 0.5303 -------------------------
2023-03-27 14:10:32,430 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:32,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:32,435 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-27 14:10:34,659 : [INFO]  ------------------------- Batch round 2, loss: 0.522 -------------------------
2023-03-27 14:10:34,659 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:34,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:34,664 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-27 14:10:36,974 : [INFO]  ------------------------- Batch round 3, loss: 0.5204 -------------------------
2023-03-27 14:10:36,974 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:36,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:36,979 : [INFO]  Batch number 26 model fetched from the server
2023-03-27 14:10:36,979 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-27 14:10:38,345 : [INFO]  Batch 26: Training set : loss - 0.5209, accuracy - 0.8043, recall - 0.9891, AUC - 0.9363, F1 - 0.8349, precision - 0.7222, training time - -9.0 seconds
2023-03-27 14:10:38,345 : [INFO]  Batch 26: Testing set : loss - 0.5649, accuracy - 0.7304, recall - 0.902, AUC - 0.8706, F1 - 0.7699, precision - 0.6715
2023-03-27 14:10:38,351 : [INFO]  Batch 27 initialized 
2023-03-27 14:10:38,759 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:39,041 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-27 14:10:43,041 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-27 14:10:43,042 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:43,111 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:43,113 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-27 14:10:45,316 : [INFO]  ------------------------- Batch round 2, loss: 0.5612 -------------------------
2023-03-27 14:10:45,316 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:45,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:45,367 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-27 14:10:48,374 : [INFO]  ------------------------- Batch round 3, loss: 0.557 -------------------------
2023-03-27 14:10:48,374 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:48,395 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:48,397 : [INFO]  Batch number 27 model fetched from the server
2023-03-27 14:10:48,397 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-27 14:10:49,838 : [INFO]  Batch 27: Training set : loss - 0.5581, accuracy - 0.7554, recall - 0.8913, AUC - 0.8757, F1 - 0.7847, precision - 0.7009, training time - -9.0 seconds
2023-03-27 14:10:49,838 : [INFO]  Batch 27: Testing set : loss - 0.5805, accuracy - 0.7304, recall - 0.9118, AUC - 0.8507, F1 - 0.7718, precision - 0.6691
2023-03-27 14:10:49,842 : [INFO]  Batch 28 initialized 
2023-03-27 14:10:50,265 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:50,577 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-27 14:10:54,567 : [INFO]  ------------------------- Batch round 1, loss: 0.5847 -------------------------
2023-03-27 14:10:54,568 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:54,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:54,789 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-27 14:10:57,039 : [INFO]  ------------------------- Batch round 2, loss: 0.5811 -------------------------
2023-03-27 14:10:57,040 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:57,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:57,044 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-27 14:10:59,974 : [INFO]  ------------------------- Batch round 3, loss: 0.5764 -------------------------
2023-03-27 14:10:59,974 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:59,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:59,979 : [INFO]  Batch number 28 model fetched from the server
2023-03-27 14:10:59,979 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-27 14:11:02,169 : [INFO]  Batch 28: Training set : loss - 0.5717, accuracy - 0.7174, recall - 0.913, AUC - 0.8448, F1 - 0.7636, precision - 0.6562, training time - -9.0 seconds
2023-03-27 14:11:02,169 : [INFO]  Batch 28: Testing set : loss - 0.5584, accuracy - 0.75, recall - 0.9412, AUC - 0.9087, F1 - 0.7901, precision - 0.6809
2023-03-27 14:11:02,190 : [INFO]  Batch 29 initialized 
2023-03-27 14:11:02,828 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:03,157 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-27 14:11:07,243 : [INFO]  ------------------------- Batch round 1, loss: 0.5588 -------------------------
2023-03-27 14:11:07,243 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:07,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:07,248 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-27 14:11:09,921 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-27 14:11:09,922 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:09,973 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:09,975 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-27 14:11:12,332 : [INFO]  ------------------------- Batch round 3, loss: 0.5529 -------------------------
2023-03-27 14:11:12,332 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:12,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:12,400 : [INFO]  Batch number 29 model fetched from the server
2023-03-27 14:11:12,400 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-27 14:11:13,847 : [INFO]  Batch 29: Training set : loss - 0.5559, accuracy - 0.7554, recall - 0.9457, AUC - 0.8858, F1 - 0.7945, precision - 0.685, training time - -9.0 seconds
2023-03-27 14:11:13,848 : [INFO]  Batch 29: Testing set : loss - 0.5623, accuracy - 0.7451, recall - 0.9706, AUC - 0.8712, F1 - 0.792, precision - 0.6689
2023-03-27 14:11:13,858 : [INFO]  Batch 30 initialized 
2023-03-27 14:11:14,263 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:14,593 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-27 14:11:18,700 : [INFO]  ------------------------- Batch round 1, loss: 0.5707 -------------------------
2023-03-27 14:11:18,700 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:18,708 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:18,710 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-27 14:11:21,476 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-27 14:11:21,476 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:21,514 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:21,517 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-27 14:11:23,894 : [INFO]  ------------------------- Batch round 3, loss: 0.5642 -------------------------
2023-03-27 14:11:23,894 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:23,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:23,899 : [INFO]  Batch number 30 model fetched from the server
2023-03-27 14:11:23,899 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-27 14:11:25,302 : [INFO]  Batch 30: Training set : loss - 0.5642, accuracy - 0.7554, recall - 0.9022, AUC - 0.8642, F1 - 0.7867, precision - 0.6975, training time - -9.0 seconds
2023-03-27 14:11:25,302 : [INFO]  Batch 30: Testing set : loss - 0.5346, accuracy - 0.7843, recall - 0.9608, AUC - 0.9041, F1 - 0.8167, precision - 0.7101
2023-03-27 14:11:25,306 : [INFO]  Batch 31 initialized 
2023-03-27 14:11:25,964 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:26,449 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-27 14:11:31,399 : [INFO]  ------------------------- Batch round 1, loss: 0.5453 -------------------------
2023-03-27 14:11:31,399 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:31,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:31,404 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-27 14:11:34,253 : [INFO]  ------------------------- Batch round 2, loss: 0.5332 -------------------------
2023-03-27 14:11:34,253 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:34,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:34,258 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-27 14:11:36,477 : [INFO]  ------------------------- Batch round 3, loss: 0.5302 -------------------------
2023-03-27 14:11:36,478 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:36,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:36,483 : [INFO]  Batch number 31 model fetched from the server
2023-03-27 14:11:36,484 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-27 14:11:38,031 : [INFO]  Batch 31: Training set : loss - 0.5305, accuracy - 0.7772, recall - 0.913, AUC - 0.9029, F1 - 0.8038, precision - 0.7179, training time - -10.0 seconds
2023-03-27 14:11:38,031 : [INFO]  Batch 31: Testing set : loss - 0.5391, accuracy - 0.7696, recall - 0.8922, AUC - 0.8911, F1 - 0.7948, precision - 0.7165
2023-03-27 14:11:38,038 : [INFO]  Batch 32 initialized 
2023-03-27 14:11:38,670 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:38,977 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-27 14:11:44,013 : [INFO]  ------------------------- Batch round 1, loss: 0.5499 -------------------------
2023-03-27 14:11:44,013 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:44,133 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:44,135 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-27 14:11:46,367 : [INFO]  ------------------------- Batch round 2, loss: 0.5485 -------------------------
2023-03-27 14:11:46,368 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:46,370 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:46,373 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-27 14:11:48,557 : [INFO]  ------------------------- Batch round 3, loss: 0.5444 -------------------------
2023-03-27 14:11:48,558 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:48,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:48,622 : [INFO]  Batch number 32 model fetched from the server
2023-03-27 14:11:48,622 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-27 14:11:50,034 : [INFO]  Batch 32: Training set : loss - 0.5408, accuracy - 0.7826, recall - 0.9348, AUC - 0.8945, F1 - 0.8113, precision - 0.7167, training time - -10.0 seconds
2023-03-27 14:11:50,035 : [INFO]  Batch 32: Testing set : loss - 0.5659, accuracy - 0.7353, recall - 0.8922, AUC - 0.8631, F1 - 0.7712, precision - 0.6791
2023-03-27 14:11:50,038 : [INFO]  Batch 33 initialized 
2023-03-27 14:11:50,454 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:50,761 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-27 14:11:55,071 : [INFO]  ------------------------- Batch round 1, loss: 0.5284 -------------------------
2023-03-27 14:11:55,072 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:55,075 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:55,077 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-27 14:11:57,904 : [INFO]  ------------------------- Batch round 2, loss: 0.5217 -------------------------
2023-03-27 14:11:57,904 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:57,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:57,948 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-27 14:12:00,592 : [INFO]  ------------------------- Batch round 3, loss: 0.5179 -------------------------
2023-03-27 14:12:00,592 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:00,642 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:00,644 : [INFO]  Batch number 33 model fetched from the server
2023-03-27 14:12:00,644 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-27 14:12:02,199 : [INFO]  Batch 33: Training set : loss - 0.5189, accuracy - 0.8207, recall - 0.9457, AUC - 0.9209, F1 - 0.8406, precision - 0.7565, training time - -10.0 seconds
2023-03-27 14:12:02,199 : [INFO]  Batch 33: Testing set : loss - 0.5481, accuracy - 0.7696, recall - 0.9608, AUC - 0.9069, F1 - 0.8066, precision - 0.695
2023-03-27 14:12:02,229 : [INFO]  Batch 34 initialized 
2023-03-27 14:12:02,694 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:02,989 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-27 14:12:07,267 : [INFO]  ------------------------- Batch round 1, loss: 0.5845 -------------------------
2023-03-27 14:12:07,268 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:07,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:07,272 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-27 14:12:09,580 : [INFO]  ------------------------- Batch round 2, loss: 0.576 -------------------------
2023-03-27 14:12:09,581 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:09,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:09,624 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-27 14:12:12,253 : [INFO]  ------------------------- Batch round 3, loss: 0.5711 -------------------------
2023-03-27 14:12:12,253 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:12,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:12,258 : [INFO]  Batch number 34 model fetched from the server
2023-03-27 14:12:12,258 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-27 14:12:13,824 : [INFO]  Batch 34: Training set : loss - 0.5699, accuracy - 0.7446, recall - 0.913, AUC - 0.8687, F1 - 0.7814, precision - 0.6829, training time - -9.0 seconds
2023-03-27 14:12:13,824 : [INFO]  Batch 34: Testing set : loss - 0.5349, accuracy - 0.7745, recall - 0.9608, AUC - 0.9184, F1 - 0.8099, precision - 0.7
2023-03-27 14:12:13,833 : [INFO]  Batch 35 initialized 
2023-03-27 14:12:14,262 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:14,561 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-27 14:12:18,444 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-27 14:12:18,444 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:18,447 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:18,449 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-27 14:12:20,581 : [INFO]  ------------------------- Batch round 2, loss: 0.5654 -------------------------
2023-03-27 14:12:20,581 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:20,589 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:20,591 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-27 14:12:22,765 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-27 14:12:22,765 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:22,768 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:22,770 : [INFO]  Batch number 35 model fetched from the server
2023-03-27 14:12:22,770 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-27 14:12:24,142 : [INFO]  Batch 35: Training set : loss - 0.558, accuracy - 0.7283, recall - 0.913, AUC - 0.8726, F1 - 0.7706, precision - 0.6667, training time - -8.0 seconds
2023-03-27 14:12:24,142 : [INFO]  Batch 35: Testing set : loss - 0.5562, accuracy - 0.7598, recall - 0.951, AUC - 0.8755, F1 - 0.7984, precision - 0.6879
2023-03-27 14:12:24,148 : [INFO]  Batch 36 initialized 
2023-03-27 14:12:24,585 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:24,894 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-27 14:12:28,956 : [INFO]  ------------------------- Batch round 1, loss: 0.5712 -------------------------
2023-03-27 14:12:28,957 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:28,960 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:28,962 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-27 14:12:31,565 : [INFO]  ------------------------- Batch round 2, loss: 0.5654 -------------------------
2023-03-27 14:12:31,565 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:31,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:31,570 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-27 14:12:33,982 : [INFO]  ------------------------- Batch round 3, loss: 0.5637 -------------------------
2023-03-27 14:12:33,982 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:33,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:33,987 : [INFO]  Batch number 36 model fetched from the server
2023-03-27 14:12:33,987 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-27 14:12:35,344 : [INFO]  Batch 36: Training set : loss - 0.5638, accuracy - 0.7174, recall - 0.9348, AUC - 0.9005, F1 - 0.7679, precision - 0.6515, training time - -9.0 seconds
2023-03-27 14:12:35,344 : [INFO]  Batch 36: Testing set : loss - 0.5844, accuracy - 0.6912, recall - 0.9216, AUC - 0.8444, F1 - 0.749, precision - 0.6309
2023-03-27 14:12:35,348 : [INFO]  Batch 37 initialized 
2023-03-27 14:12:35,758 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:36,048 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-27 14:12:40,589 : [INFO]  ------------------------- Batch round 1, loss: 0.5393 -------------------------
2023-03-27 14:12:40,589 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:40,592 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:40,594 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-27 14:12:42,811 : [INFO]  ------------------------- Batch round 2, loss: 0.5336 -------------------------
2023-03-27 14:12:42,811 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:42,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:42,816 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-27 14:12:45,076 : [INFO]  ------------------------- Batch round 3, loss: 0.5338 -------------------------
2023-03-27 14:12:45,076 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:45,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:45,081 : [INFO]  Batch number 37 model fetched from the server
2023-03-27 14:12:45,081 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-27 14:12:46,495 : [INFO]  Batch 37: Training set : loss - 0.5359, accuracy - 0.7935, recall - 0.9674, AUC - 0.9132, F1 - 0.8241, precision - 0.7177, training time - -9.0 seconds
2023-03-27 14:12:46,495 : [INFO]  Batch 37: Testing set : loss - 0.5615, accuracy - 0.7402, recall - 0.9216, AUC - 0.8776, F1 - 0.7801, precision - 0.6763
2023-03-27 14:12:46,500 : [INFO]  Batch 38 initialized 
2023-03-27 14:12:46,921 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:47,220 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-27 14:12:51,206 : [INFO]  ------------------------- Batch round 1, loss: 0.5608 -------------------------
2023-03-27 14:12:51,207 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:51,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:51,211 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-27 14:12:53,453 : [INFO]  ------------------------- Batch round 2, loss: 0.5541 -------------------------
2023-03-27 14:12:53,453 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:53,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:53,457 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-27 14:12:55,719 : [INFO]  ------------------------- Batch round 3, loss: 0.549 -------------------------
2023-03-27 14:12:55,719 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:55,722 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:55,724 : [INFO]  Batch number 38 model fetched from the server
2023-03-27 14:12:55,724 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-27 14:12:57,113 : [INFO]  Batch 38: Training set : loss - 0.5489, accuracy - 0.7717, recall - 0.9348, AUC - 0.8882, F1 - 0.8037, precision - 0.7049, training time - -9.0 seconds
2023-03-27 14:12:57,113 : [INFO]  Batch 38: Testing set : loss - 0.5687, accuracy - 0.7157, recall - 0.9412, AUC - 0.8769, F1 - 0.768, precision - 0.6486
2023-03-27 14:12:57,130 : [INFO]  Batch 39 initialized 
2023-03-27 14:12:57,554 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:57,861 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-27 14:13:01,775 : [INFO]  ------------------------- Batch round 1, loss: 0.5501 -------------------------
2023-03-27 14:13:01,775 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:01,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:01,780 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-27 14:13:03,928 : [INFO]  ------------------------- Batch round 2, loss: 0.542 -------------------------
2023-03-27 14:13:03,928 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:03,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:03,938 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-27 14:13:06,169 : [INFO]  ------------------------- Batch round 3, loss: 0.5391 -------------------------
2023-03-27 14:13:06,169 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:06,172 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:06,174 : [INFO]  Batch number 39 model fetched from the server
2023-03-27 14:13:06,174 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-27 14:13:07,620 : [INFO]  Batch 39: Training set : loss - 0.5406, accuracy - 0.8152, recall - 0.9783, AUC - 0.9039, F1 - 0.8411, precision - 0.7377, training time - -8.0 seconds
2023-03-27 14:13:07,620 : [INFO]  Batch 39: Testing set : loss - 0.5598, accuracy - 0.7549, recall - 0.902, AUC - 0.8775, F1 - 0.7863, precision - 0.697
2023-03-27 14:13:07,624 : [INFO]  Batch 40 initialized 
2023-03-27 14:13:08,060 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:08,374 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-27 14:13:12,303 : [INFO]  ------------------------- Batch round 1, loss: 0.5511 -------------------------
2023-03-27 14:13:12,304 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:12,358 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:12,360 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-27 14:13:14,503 : [INFO]  ------------------------- Batch round 2, loss: 0.5438 -------------------------
2023-03-27 14:13:14,504 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:14,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:14,572 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-27 14:13:16,780 : [INFO]  ------------------------- Batch round 3, loss: 0.5415 -------------------------
2023-03-27 14:13:16,780 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:16,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:16,800 : [INFO]  Batch number 40 model fetched from the server
2023-03-27 14:13:16,800 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-27 14:13:18,201 : [INFO]  Batch 40: Training set : loss - 0.5456, accuracy - 0.8043, recall - 0.913, AUC - 0.8894, F1 - 0.8235, precision - 0.75, training time - -8.0 seconds
2023-03-27 14:13:18,201 : [INFO]  Batch 40: Testing set : loss - 0.5506, accuracy - 0.7451, recall - 0.902, AUC - 0.8813, F1 - 0.7797, precision - 0.6866
2023-03-27 14:13:18,205 : [INFO]  Batch 41 initialized 
2023-03-27 14:13:18,617 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:18,924 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-27 14:13:22,845 : [INFO]  ------------------------- Batch round 1, loss: 0.5509 -------------------------
2023-03-27 14:13:22,846 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:22,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:22,850 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-27 14:13:25,073 : [INFO]  ------------------------- Batch round 2, loss: 0.548 -------------------------
2023-03-27 14:13:25,073 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:25,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:25,078 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-27 14:13:27,317 : [INFO]  ------------------------- Batch round 3, loss: 0.5431 -------------------------
2023-03-27 14:13:27,317 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:27,320 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:27,322 : [INFO]  Batch number 41 model fetched from the server
2023-03-27 14:13:27,322 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-27 14:13:28,818 : [INFO]  Batch 41: Training set : loss - 0.5402, accuracy - 0.7554, recall - 0.9783, AUC - 0.8937, F1 - 0.8, precision - 0.6767, training time - -8.0 seconds
2023-03-27 14:13:28,819 : [INFO]  Batch 41: Testing set : loss - 0.5633, accuracy - 0.7255, recall - 0.9412, AUC - 0.8642, F1 - 0.7742, precision - 0.6575
2023-03-27 14:13:28,824 : [INFO]  Batch 42 initialized 
2023-03-27 14:13:29,254 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:29,574 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-27 14:13:33,569 : [INFO]  ------------------------- Batch round 1, loss: 0.5718 -------------------------
2023-03-27 14:13:33,569 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:33,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:33,574 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-27 14:13:35,835 : [INFO]  ------------------------- Batch round 2, loss: 0.5661 -------------------------
2023-03-27 14:13:35,835 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:35,838 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:35,840 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-27 14:13:38,080 : [INFO]  ------------------------- Batch round 3, loss: 0.5624 -------------------------
2023-03-27 14:13:38,080 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:38,083 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:38,085 : [INFO]  Batch number 42 model fetched from the server
2023-03-27 14:13:38,085 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-27 14:13:39,435 : [INFO]  Batch 42: Training set : loss - 0.5608, accuracy - 0.7391, recall - 0.913, AUC - 0.875, F1 - 0.7778, precision - 0.6774, training time - -9.0 seconds
2023-03-27 14:13:39,435 : [INFO]  Batch 42: Testing set : loss - 0.5781, accuracy - 0.701, recall - 0.951, AUC - 0.8803, F1 - 0.7608, precision - 0.634
2023-03-27 14:13:39,439 : [INFO]  Batch 43 initialized 
2023-03-27 14:13:39,963 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:40,321 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-27 14:13:45,091 : [INFO]  ------------------------- Batch round 1, loss: 0.5222 -------------------------
2023-03-27 14:13:45,092 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:45,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:45,096 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-27 14:13:47,490 : [INFO]  ------------------------- Batch round 2, loss: 0.5221 -------------------------
2023-03-27 14:13:47,490 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:47,559 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:47,561 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-27 14:13:49,747 : [INFO]  ------------------------- Batch round 3, loss: 0.5194 -------------------------
2023-03-27 14:13:49,747 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:49,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:49,752 : [INFO]  Batch number 43 model fetched from the server
2023-03-27 14:13:49,752 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-27 14:13:51,171 : [INFO]  Batch 43: Training set : loss - 0.5203, accuracy - 0.8315, recall - 0.9783, AUC - 0.9278, F1 - 0.8531, precision - 0.7563, training time - -9.0 seconds
2023-03-27 14:13:51,172 : [INFO]  Batch 43: Testing set : loss - 0.5706, accuracy - 0.7108, recall - 0.8922, AUC - 0.8608, F1 - 0.7552, precision - 0.6547
2023-03-27 14:13:51,176 : [INFO]  Batch 44 initialized 
2023-03-27 14:13:51,581 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:51,949 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-27 14:13:56,811 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-27 14:13:56,812 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:56,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:56,817 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-27 14:13:59,248 : [INFO]  ------------------------- Batch round 2, loss: 0.5598 -------------------------
2023-03-27 14:13:59,248 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:59,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:59,253 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-27 14:14:01,821 : [INFO]  ------------------------- Batch round 3, loss: 0.5591 -------------------------
2023-03-27 14:14:01,821 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:01,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:01,829 : [INFO]  Batch number 44 model fetched from the server
2023-03-27 14:14:01,829 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-27 14:14:03,344 : [INFO]  Batch 44: Training set : loss - 0.5559, accuracy - 0.7663, recall - 0.9239, AUC - 0.8798, F1 - 0.7981, precision - 0.7025, training time - -10.0 seconds
2023-03-27 14:14:03,344 : [INFO]  Batch 44: Testing set : loss - 0.5736, accuracy - 0.7255, recall - 0.902, AUC - 0.8532, F1 - 0.7667, precision - 0.6667
2023-03-27 14:14:03,348 : [INFO]  Batch 45 initialized 
2023-03-27 14:14:03,804 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:04,157 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-27 14:14:08,353 : [INFO]  ------------------------- Batch round 1, loss: 0.5573 -------------------------
2023-03-27 14:14:08,354 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:08,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:08,359 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-27 14:14:11,001 : [INFO]  ------------------------- Batch round 2, loss: 0.5514 -------------------------
2023-03-27 14:14:11,001 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:11,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:11,104 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-27 14:14:13,409 : [INFO]  ------------------------- Batch round 3, loss: 0.5486 -------------------------
2023-03-27 14:14:13,409 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:13,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:13,434 : [INFO]  Batch number 45 model fetched from the server
2023-03-27 14:14:13,434 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-27 14:14:14,808 : [INFO]  Batch 45: Training set : loss - 0.5512, accuracy - 0.7772, recall - 0.9565, AUC - 0.8813, F1 - 0.8111, precision - 0.704, training time - -9.0 seconds
2023-03-27 14:14:14,808 : [INFO]  Batch 45: Testing set : loss - 0.5598, accuracy - 0.7451, recall - 0.9314, AUC - 0.8693, F1 - 0.7851, precision - 0.6786
2023-03-27 14:14:14,817 : [INFO]  Batch 46 initialized 
2023-03-27 14:14:15,224 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:15,548 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-27 14:14:19,449 : [INFO]  ------------------------- Batch round 1, loss: 0.6069 -------------------------
2023-03-27 14:14:19,449 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:19,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:19,525 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-27 14:14:21,693 : [INFO]  ------------------------- Batch round 2, loss: 0.597 -------------------------
2023-03-27 14:14:21,694 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:21,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:21,735 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-27 14:14:24,079 : [INFO]  ------------------------- Batch round 3, loss: 0.5918 -------------------------
2023-03-27 14:14:24,079 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:24,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:24,168 : [INFO]  Batch number 46 model fetched from the server
2023-03-27 14:14:24,168 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-27 14:14:25,720 : [INFO]  Batch 46: Training set : loss - 0.5918, accuracy - 0.7011, recall - 0.8696, AUC - 0.822, F1 - 0.7442, precision - 0.6504, training time - -9.0 seconds
2023-03-27 14:14:25,720 : [INFO]  Batch 46: Testing set : loss - 0.5843, accuracy - 0.7157, recall - 0.9216, AUC - 0.8364, F1 - 0.7642, precision - 0.6528
2023-03-27 14:14:25,730 : [INFO]  Batch 47 initialized 
2023-03-27 14:14:26,167 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:26,503 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-27 14:14:30,467 : [INFO]  ------------------------- Batch round 1, loss: 0.5565 -------------------------
2023-03-27 14:14:30,467 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:30,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:30,530 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-27 14:14:32,916 : [INFO]  ------------------------- Batch round 2, loss: 0.5483 -------------------------
2023-03-27 14:14:32,916 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:32,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:32,970 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-27 14:14:35,419 : [INFO]  ------------------------- Batch round 3, loss: 0.5474 -------------------------
2023-03-27 14:14:35,420 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:35,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:35,519 : [INFO]  Batch number 47 model fetched from the server
2023-03-27 14:14:35,519 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-27 14:14:36,925 : [INFO]  Batch 47: Training set : loss - 0.5478, accuracy - 0.7663, recall - 0.9022, AUC - 0.8716, F1 - 0.7943, precision - 0.7094, training time - -9.0 seconds
2023-03-27 14:14:36,925 : [INFO]  Batch 47: Testing set : loss - 0.5826, accuracy - 0.7206, recall - 0.9216, AUC - 0.8523, F1 - 0.7673, precision - 0.6573
2023-03-27 14:14:36,936 : [INFO]  Batch 48 initialized 
2023-03-27 14:14:37,372 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:37,720 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-27 14:14:41,744 : [INFO]  ------------------------- Batch round 1, loss: 0.5567 -------------------------
2023-03-27 14:14:41,744 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:41,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:41,820 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-27 14:14:43,985 : [INFO]  ------------------------- Batch round 2, loss: 0.5502 -------------------------
2023-03-27 14:14:43,985 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:44,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:44,099 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-27 14:14:46,245 : [INFO]  ------------------------- Batch round 3, loss: 0.5466 -------------------------
2023-03-27 14:14:46,245 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:46,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:46,408 : [INFO]  Batch number 48 model fetched from the server
2023-03-27 14:14:46,408 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-27 14:14:47,865 : [INFO]  Batch 48: Training set : loss - 0.5527, accuracy - 0.7391, recall - 0.913, AUC - 0.9028, F1 - 0.7778, precision - 0.6774, training time - -9.0 seconds
2023-03-27 14:14:47,866 : [INFO]  Batch 48: Testing set : loss - 0.5703, accuracy - 0.7206, recall - 0.951, AUC - 0.8959, F1 - 0.7729, precision - 0.651
2023-03-27 14:14:47,873 : [INFO]  Batch 49 initialized 
2023-03-27 14:14:48,515 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:48,900 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-27 14:14:53,659 : [INFO]  ------------------------- Batch round 1, loss: 0.54 -------------------------
2023-03-27 14:14:53,659 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:53,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:53,666 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-27 14:14:56,190 : [INFO]  ------------------------- Batch round 2, loss: 0.5344 -------------------------
2023-03-27 14:14:56,190 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:56,194 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:56,195 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-27 14:14:58,555 : [INFO]  ------------------------- Batch round 3, loss: 0.533 -------------------------
2023-03-27 14:14:58,555 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:58,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:58,560 : [INFO]  Batch number 49 model fetched from the server
2023-03-27 14:14:58,560 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-27 14:14:59,976 : [INFO]  Batch 49: Training set : loss - 0.5338, accuracy - 0.7935, recall - 0.9891, AUC - 0.9204, F1 - 0.8273, precision - 0.7109, training time - -10.0 seconds
2023-03-27 14:14:59,976 : [INFO]  Batch 49: Testing set : loss - 0.5865, accuracy - 0.7059, recall - 0.9412, AUC - 0.8595, F1 - 0.7619, precision - 0.64
2023-03-27 14:14:59,981 : [INFO]  Batch 50 initialized 
2023-03-27 14:15:00,416 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:00,753 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-27 14:15:04,846 : [INFO]  ------------------------- Batch round 1, loss: 0.545 -------------------------
2023-03-27 14:15:04,846 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:04,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:04,850 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-27 14:15:07,048 : [INFO]  ------------------------- Batch round 2, loss: 0.5333 -------------------------
2023-03-27 14:15:07,048 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:07,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:07,080 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-27 14:15:09,714 : [INFO]  ------------------------- Batch round 3, loss: 0.5333 -------------------------
2023-03-27 14:15:09,714 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:09,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:09,745 : [INFO]  Batch number 50 model fetched from the server
2023-03-27 14:15:09,745 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-27 14:15:11,204 : [INFO]  Batch 50: Training set : loss - 0.5248, accuracy - 0.7826, recall - 0.913, AUC - 0.922, F1 - 0.8077, precision - 0.7241, training time - -9.0 seconds
2023-03-27 14:15:11,204 : [INFO]  Batch 50: Testing set : loss - 0.5209, accuracy - 0.7843, recall - 0.951, AUC - 0.9289, F1 - 0.8151, precision - 0.7132
2023-03-27 14:15:11,210 : [INFO]  Batch 51 initialized 
2023-03-27 14:15:11,661 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:11,990 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-27 14:15:16,041 : [INFO]  ------------------------- Batch round 1, loss: 0.5198 -------------------------
2023-03-27 14:15:16,041 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:16,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:16,046 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-27 14:15:18,509 : [INFO]  ------------------------- Batch round 2, loss: 0.5144 -------------------------
2023-03-27 14:15:18,509 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:18,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:18,514 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-27 14:15:21,109 : [INFO]  ------------------------- Batch round 3, loss: 0.5126 -------------------------
2023-03-27 14:15:21,109 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:21,112 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:21,114 : [INFO]  Batch number 51 model fetched from the server
2023-03-27 14:15:21,114 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-27 14:15:22,539 : [INFO]  Batch 51: Training set : loss - 0.5136, accuracy - 0.7717, recall - 0.9565, AUC - 0.9516, F1 - 0.8073, precision - 0.6984, training time - -9.0 seconds
2023-03-27 14:15:22,539 : [INFO]  Batch 51: Testing set : loss - 0.5357, accuracy - 0.7745, recall - 0.9608, AUC - 0.9157, F1 - 0.8099, precision - 0.7
2023-03-27 14:15:22,543 : [INFO]  Batch 52 initialized 
2023-03-27 14:15:22,984 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:23,309 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-27 14:15:27,587 : [INFO]  ------------------------- Batch round 1, loss: 0.5514 -------------------------
2023-03-27 14:15:27,588 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:27,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:27,592 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-27 14:15:30,031 : [INFO]  ------------------------- Batch round 2, loss: 0.5478 -------------------------
2023-03-27 14:15:30,031 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:30,034 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:30,035 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-27 14:15:32,244 : [INFO]  ------------------------- Batch round 3, loss: 0.5441 -------------------------
2023-03-27 14:15:32,244 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:32,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:32,250 : [INFO]  Batch number 52 model fetched from the server
2023-03-27 14:15:32,250 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-27 14:15:33,644 : [INFO]  Batch 52: Training set : loss - 0.5407, accuracy - 0.7446, recall - 0.9565, AUC - 0.924, F1 - 0.7892, precision - 0.6718, training time - -9.0 seconds
2023-03-27 14:15:33,645 : [INFO]  Batch 52: Testing set : loss - 0.5748, accuracy - 0.7059, recall - 0.9314, AUC - 0.8776, F1 - 0.76, precision - 0.6419
2023-03-27 14:15:33,653 : [INFO]  Batch 53 initialized 
2023-03-27 14:15:34,101 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:34,484 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-27 14:15:40,119 : [INFO]  ------------------------- Batch round 1, loss: 0.5697 -------------------------
2023-03-27 14:15:40,120 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:40,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:40,130 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-27 14:15:42,685 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-27 14:15:42,685 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:42,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:42,772 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-27 14:15:44,980 : [INFO]  ------------------------- Batch round 3, loss: 0.5616 -------------------------
2023-03-27 14:15:44,980 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:44,998 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:45,000 : [INFO]  Batch number 53 model fetched from the server
2023-03-27 14:15:45,000 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-27 14:15:46,391 : [INFO]  Batch 53: Training set : loss - 0.5632, accuracy - 0.7337, recall - 0.9565, AUC - 0.9188, F1 - 0.7822, precision - 0.6617, training time - -11.0 seconds
2023-03-27 14:15:46,392 : [INFO]  Batch 53: Testing set : loss - 0.5448, accuracy - 0.7647, recall - 0.902, AUC - 0.895, F1 - 0.7931, precision - 0.7077
2023-03-27 14:15:46,395 : [INFO]  Batch 54 initialized 
2023-03-27 14:15:46,808 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:47,173 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-27 14:15:51,377 : [INFO]  ------------------------- Batch round 1, loss: 0.5407 -------------------------
2023-03-27 14:15:51,378 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:51,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:51,382 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-27 14:15:53,595 : [INFO]  ------------------------- Batch round 2, loss: 0.5347 -------------------------
2023-03-27 14:15:53,595 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:53,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:53,600 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-27 14:15:55,961 : [INFO]  ------------------------- Batch round 3, loss: 0.5308 -------------------------
2023-03-27 14:15:55,961 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:56,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:56,105 : [INFO]  Batch number 54 model fetched from the server
2023-03-27 14:15:56,105 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-27 14:15:57,657 : [INFO]  Batch 54: Training set : loss - 0.5301, accuracy - 0.7772, recall - 0.9783, AUC - 0.9343, F1 - 0.8145, precision - 0.6977, training time - -9.0 seconds
2023-03-27 14:15:57,657 : [INFO]  Batch 54: Testing set : loss - 0.5582, accuracy - 0.7304, recall - 0.951, AUC - 0.8922, F1 - 0.7791, precision - 0.6599
2023-03-27 14:15:57,661 : [INFO]  Batch 55 initialized 
2023-03-27 14:15:58,083 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:58,426 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-27 14:16:02,483 : [INFO]  ------------------------- Batch round 1, loss: 0.539 -------------------------
2023-03-27 14:16:02,483 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:02,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:02,488 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-27 14:16:05,910 : [INFO]  ------------------------- Batch round 2, loss: 0.5312 -------------------------
2023-03-27 14:16:05,911 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:05,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:05,916 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-27 14:16:08,458 : [INFO]  ------------------------- Batch round 3, loss: 0.5304 -------------------------
2023-03-27 14:16:08,459 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:08,462 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:08,463 : [INFO]  Batch number 55 model fetched from the server
2023-03-27 14:16:08,463 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-27 14:16:10,225 : [INFO]  Batch 55: Training set : loss - 0.5329, accuracy - 0.7772, recall - 0.9783, AUC - 0.9352, F1 - 0.8145, precision - 0.6977, training time - -10.0 seconds
2023-03-27 14:16:10,225 : [INFO]  Batch 55: Testing set : loss - 0.5502, accuracy - 0.7549, recall - 0.9804, AUC - 0.9322, F1 - 0.8, precision - 0.6757
2023-03-27 14:16:10,232 : [INFO]  Batch 56 initialized 
2023-03-27 14:16:10,739 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:11,079 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-27 14:16:16,037 : [INFO]  ------------------------- Batch round 1, loss: 0.5212 -------------------------
2023-03-27 14:16:16,038 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:16,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:16,042 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-27 14:16:18,553 : [INFO]  ------------------------- Batch round 2, loss: 0.5149 -------------------------
2023-03-27 14:16:18,554 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:18,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:18,560 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-27 14:16:20,938 : [INFO]  ------------------------- Batch round 3, loss: 0.5118 -------------------------
2023-03-27 14:16:20,938 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:20,942 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:20,945 : [INFO]  Batch number 56 model fetched from the server
2023-03-27 14:16:20,945 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-27 14:16:22,486 : [INFO]  Batch 56: Training set : loss - 0.5103, accuracy - 0.8098, recall - 0.9565, AUC - 0.9369, F1 - 0.8341, precision - 0.7395, training time - -10.0 seconds
2023-03-27 14:16:22,486 : [INFO]  Batch 56: Testing set : loss - 0.5497, accuracy - 0.7696, recall - 0.902, AUC - 0.8903, F1 - 0.7965, precision - 0.7132
2023-03-27 14:16:22,490 : [INFO]  Batch 57 initialized 
2023-03-27 14:16:23,035 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:23,446 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-27 14:16:28,933 : [INFO]  ------------------------- Batch round 1, loss: 0.5444 -------------------------
2023-03-27 14:16:28,933 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:28,937 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:28,939 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-27 14:16:31,758 : [INFO]  ------------------------- Batch round 2, loss: 0.5392 -------------------------
2023-03-27 14:16:31,759 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:31,792 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:31,794 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-27 14:16:34,643 : [INFO]  ------------------------- Batch round 3, loss: 0.5369 -------------------------
2023-03-27 14:16:34,643 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:34,646 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:34,649 : [INFO]  Batch number 57 model fetched from the server
2023-03-27 14:16:34,649 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-27 14:16:36,348 : [INFO]  Batch 57: Training set : loss - 0.5404, accuracy - 0.7446, recall - 0.9022, AUC - 0.9087, F1 - 0.7793, precision - 0.686, training time - -11.0 seconds
2023-03-27 14:16:36,348 : [INFO]  Batch 57: Testing set : loss - 0.5592, accuracy - 0.7353, recall - 0.9804, AUC - 0.9128, F1 - 0.7874, precision - 0.6579
2023-03-27 14:16:36,358 : [INFO]  Batch 58 initialized 
2023-03-27 14:16:36,787 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:37,184 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-27 14:16:42,845 : [INFO]  ------------------------- Batch round 1, loss: 0.532 -------------------------
2023-03-27 14:16:42,845 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:42,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:42,849 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-27 14:16:44,960 : [INFO]  ------------------------- Batch round 2, loss: 0.5282 -------------------------
2023-03-27 14:16:44,961 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:44,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:44,968 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-27 14:16:47,152 : [INFO]  ------------------------- Batch round 3, loss: 0.5249 -------------------------
2023-03-27 14:16:47,152 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:47,155 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:47,157 : [INFO]  Batch number 58 model fetched from the server
2023-03-27 14:16:47,157 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-27 14:16:48,529 : [INFO]  Batch 58: Training set : loss - 0.5244, accuracy - 0.8098, recall - 0.9565, AUC - 0.9216, F1 - 0.8341, precision - 0.7395, training time - -10.0 seconds
2023-03-27 14:16:48,529 : [INFO]  Batch 58: Testing set : loss - 0.5745, accuracy - 0.7255, recall - 0.9118, AUC - 0.8713, F1 - 0.7686, precision - 0.6643
2023-03-27 14:16:48,533 : [INFO]  Batch 59 initialized 
2023-03-27 14:16:48,944 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:49,291 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-27 14:16:53,970 : [INFO]  ------------------------- Batch round 1, loss: 0.5369 -------------------------
2023-03-27 14:16:53,970 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:53,973 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:53,975 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-27 14:16:56,268 : [INFO]  ------------------------- Batch round 2, loss: 0.5351 -------------------------
2023-03-27 14:16:56,268 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:56,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:56,273 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-27 14:16:58,732 : [INFO]  ------------------------- Batch round 3, loss: 0.5304 -------------------------
2023-03-27 14:16:58,733 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:58,736 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:58,738 : [INFO]  Batch number 59 model fetched from the server
2023-03-27 14:16:58,738 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-27 14:17:00,237 : [INFO]  Batch 59: Training set : loss - 0.5317, accuracy - 0.7663, recall - 0.9783, AUC - 0.9543, F1 - 0.8072, precision - 0.687, training time - -9.0 seconds
2023-03-27 14:17:00,238 : [INFO]  Batch 59: Testing set : loss - 0.5464, accuracy - 0.75, recall - 0.951, AUC - 0.9188, F1 - 0.7918, precision - 0.6783
2023-03-27 14:17:00,242 : [INFO]  Batch 60 initialized 
2023-03-27 14:17:00,675 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:01,025 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-27 14:17:05,157 : [INFO]  ------------------------- Batch round 1, loss: 0.5558 -------------------------
2023-03-27 14:17:05,157 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:05,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:05,162 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-27 14:17:07,492 : [INFO]  ------------------------- Batch round 2, loss: 0.554 -------------------------
2023-03-27 14:17:07,493 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:07,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:07,498 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-27 14:17:09,767 : [INFO]  ------------------------- Batch round 3, loss: 0.5506 -------------------------
2023-03-27 14:17:09,767 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:09,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:09,773 : [INFO]  Batch number 60 model fetched from the server
2023-03-27 14:17:09,773 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-27 14:17:11,165 : [INFO]  Batch 60: Training set : loss - 0.5543, accuracy - 0.7554, recall - 0.8804, AUC - 0.8596, F1 - 0.7826, precision - 0.7043, training time - -9.0 seconds
2023-03-27 14:17:11,165 : [INFO]  Batch 60: Testing set : loss - 0.5325, accuracy - 0.7598, recall - 0.9412, AUC - 0.9183, F1 - 0.7967, precision - 0.6906
2023-03-27 14:17:11,174 : [INFO]  Batch 61 initialized 
2023-03-27 14:17:11,595 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:11,984 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-27 14:17:16,397 : [INFO]  ------------------------- Batch round 1, loss: 0.5448 -------------------------
2023-03-27 14:17:16,397 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:16,400 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:16,402 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-27 14:17:18,624 : [INFO]  ------------------------- Batch round 2, loss: 0.5398 -------------------------
2023-03-27 14:17:18,624 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:18,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:18,629 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-27 14:17:20,799 : [INFO]  ------------------------- Batch round 3, loss: 0.5367 -------------------------
2023-03-27 14:17:20,799 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:20,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:20,804 : [INFO]  Batch number 61 model fetched from the server
2023-03-27 14:17:20,804 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-27 14:17:22,207 : [INFO]  Batch 61: Training set : loss - 0.5396, accuracy - 0.75, recall - 0.9565, AUC - 0.9205, F1 - 0.7928, precision - 0.6769, training time - -9.0 seconds
2023-03-27 14:17:22,207 : [INFO]  Batch 61: Testing set : loss - 0.5354, accuracy - 0.7549, recall - 0.951, AUC - 0.9295, F1 - 0.7951, precision - 0.6831
2023-03-27 14:17:22,211 : [INFO]  Batch 62 initialized 
2023-03-27 14:17:22,655 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:23,027 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-27 14:17:27,769 : [INFO]  ------------------------- Batch round 1, loss: 0.5501 -------------------------
2023-03-27 14:17:27,769 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:27,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:27,776 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-27 14:17:30,380 : [INFO]  ------------------------- Batch round 2, loss: 0.5391 -------------------------
2023-03-27 14:17:30,380 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:30,384 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:30,386 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-27 14:17:32,744 : [INFO]  ------------------------- Batch round 3, loss: 0.5346 -------------------------
2023-03-27 14:17:32,744 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:32,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:32,749 : [INFO]  Batch number 62 model fetched from the server
2023-03-27 14:17:32,749 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-27 14:17:34,114 : [INFO]  Batch 62: Training set : loss - 0.5276, accuracy - 0.7772, recall - 0.9457, AUC - 0.929, F1 - 0.8093, precision - 0.7073, training time - -10.0 seconds
2023-03-27 14:17:34,114 : [INFO]  Batch 62: Testing set : loss - 0.5501, accuracy - 0.7647, recall - 0.9902, AUC - 0.9319, F1 - 0.808, precision - 0.6824
2023-03-27 14:17:34,118 : [INFO]  Batch 63 initialized 
2023-03-27 14:17:34,530 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:34,891 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-27 14:17:40,334 : [INFO]  ------------------------- Batch round 1, loss: 0.5696 -------------------------
2023-03-27 14:17:40,334 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:40,341 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:40,347 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-27 14:17:43,358 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-27 14:17:43,358 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:43,363 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:43,365 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-27 14:17:46,192 : [INFO]  ------------------------- Batch round 3, loss: 0.56 -------------------------
2023-03-27 14:17:46,192 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:46,196 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:46,200 : [INFO]  Batch number 63 model fetched from the server
2023-03-27 14:17:46,200 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-27 14:17:48,111 : [INFO]  Batch 63: Training set : loss - 0.5639, accuracy - 0.7391, recall - 0.913, AUC - 0.8781, F1 - 0.7778, precision - 0.6774, training time - -11.0 seconds
2023-03-27 14:17:48,111 : [INFO]  Batch 63: Testing set : loss - 0.5415, accuracy - 0.75, recall - 0.9608, AUC - 0.9293, F1 - 0.7935, precision - 0.6759
2023-03-27 14:17:48,117 : [INFO]  Batch 64 initialized 
2023-03-27 14:17:48,752 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:49,335 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-27 14:17:55,094 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-27 14:17:55,095 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:55,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:55,143 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-27 14:17:59,275 : [INFO]  ------------------------- Batch round 2, loss: 0.5646 -------------------------
2023-03-27 14:17:59,276 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:59,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:59,300 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-27 14:18:03,302 : [INFO]  ------------------------- Batch round 3, loss: 0.5575 -------------------------
2023-03-27 14:18:03,302 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:03,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:03,588 : [INFO]  Batch number 64 model fetched from the server
2023-03-27 14:18:03,588 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-27 14:18:07,066 : [INFO]  Batch 64: Training set : loss - 0.5553, accuracy - 0.7663, recall - 0.9022, AUC - 0.8884, F1 - 0.7943, precision - 0.7094, training time - -14.0 seconds
2023-03-27 14:18:07,066 : [INFO]  Batch 64: Testing set : loss - 0.5155, accuracy - 0.8088, recall - 0.9608, AUC - 0.9307, F1 - 0.834, precision - 0.7368
2023-03-27 14:18:07,071 : [INFO]  Batch 65 initialized 
2023-03-27 14:18:07,885 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:08,271 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-27 14:18:13,071 : [INFO]  ------------------------- Batch round 1, loss: 0.5463 -------------------------
2023-03-27 14:18:13,071 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:13,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:13,076 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-27 14:18:15,332 : [INFO]  ------------------------- Batch round 2, loss: 0.5422 -------------------------
2023-03-27 14:18:15,332 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:15,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:15,337 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-27 14:18:17,618 : [INFO]  ------------------------- Batch round 3, loss: 0.5374 -------------------------
2023-03-27 14:18:17,619 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:17,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:17,623 : [INFO]  Batch number 65 model fetched from the server
2023-03-27 14:18:17,624 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-27 14:18:18,991 : [INFO]  Batch 65: Training set : loss - 0.5383, accuracy - 0.788, recall - 0.9674, AUC - 0.9124, F1 - 0.8203, precision - 0.712, training time - -9.0 seconds
2023-03-27 14:18:18,992 : [INFO]  Batch 65: Testing set : loss - 0.5795, accuracy - 0.7255, recall - 0.9216, AUC - 0.853, F1 - 0.7705, precision - 0.662
2023-03-27 14:18:18,995 : [INFO]  Batch 66 initialized 
2023-03-27 14:18:19,484 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:19,860 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-27 14:18:24,899 : [INFO]  ------------------------- Batch round 1, loss: 0.536 -------------------------
2023-03-27 14:18:24,899 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:24,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:24,969 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-27 14:18:27,635 : [INFO]  ------------------------- Batch round 2, loss: 0.5338 -------------------------
2023-03-27 14:18:27,635 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:27,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:27,669 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-27 14:18:30,313 : [INFO]  ------------------------- Batch round 3, loss: 0.5295 -------------------------
2023-03-27 14:18:30,313 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:30,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:30,428 : [INFO]  Batch number 66 model fetched from the server
2023-03-27 14:18:30,428 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-27 14:18:32,307 : [INFO]  Batch 66: Training set : loss - 0.5314, accuracy - 0.788, recall - 0.9783, AUC - 0.9343, F1 - 0.8219, precision - 0.7087, training time - -11.0 seconds
2023-03-27 14:18:32,307 : [INFO]  Batch 66: Testing set : loss - 0.521, accuracy - 0.7745, recall - 0.951, AUC - 0.9319, F1 - 0.8083, precision - 0.7029
2023-03-27 14:18:32,328 : [INFO]  Batch 67 initialized 
2023-03-27 14:18:32,997 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:33,435 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-27 14:18:38,321 : [INFO]  ------------------------- Batch round 1, loss: 0.5404 -------------------------
2023-03-27 14:18:38,321 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:38,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:38,326 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-27 14:18:41,181 : [INFO]  ------------------------- Batch round 2, loss: 0.5367 -------------------------
2023-03-27 14:18:41,183 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:41,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:41,192 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-27 14:18:44,947 : [INFO]  ------------------------- Batch round 3, loss: 0.5327 -------------------------
2023-03-27 14:18:44,947 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:45,719 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:45,723 : [INFO]  Batch number 67 model fetched from the server
2023-03-27 14:18:45,723 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-27 14:18:48,653 : [INFO]  Batch 67: Training set : loss - 0.533, accuracy - 0.7826, recall - 0.9348, AUC - 0.9034, F1 - 0.8113, precision - 0.7167, training time - -12.0 seconds
2023-03-27 14:18:48,653 : [INFO]  Batch 67: Testing set : loss - 0.5499, accuracy - 0.75, recall - 0.9216, AUC - 0.8996, F1 - 0.7866, precision - 0.6861
2023-03-27 14:18:48,660 : [INFO]  Batch 68 initialized 
2023-03-27 14:18:49,642 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:50,325 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-27 14:18:56,733 : [INFO]  ------------------------- Batch round 1, loss: 0.5523 -------------------------
2023-03-27 14:18:56,733 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:56,736 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:56,738 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-27 14:18:59,608 : [INFO]  ------------------------- Batch round 2, loss: 0.5477 -------------------------
2023-03-27 14:18:59,608 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:59,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:59,618 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-27 14:19:03,030 : [INFO]  ------------------------- Batch round 3, loss: 0.5419 -------------------------
2023-03-27 14:19:03,031 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:03,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:03,122 : [INFO]  Batch number 68 model fetched from the server
2023-03-27 14:19:03,123 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-27 14:19:04,734 : [INFO]  Batch 68: Training set : loss - 0.544, accuracy - 0.7554, recall - 0.913, AUC - 0.9062, F1 - 0.7887, precision - 0.6942, training time - -13.0 seconds
2023-03-27 14:19:04,734 : [INFO]  Batch 68: Testing set : loss - 0.5733, accuracy - 0.7206, recall - 0.902, AUC - 0.8725, F1 - 0.7635, precision - 0.6619
2023-03-27 14:19:04,739 : [INFO]  Batch 69 initialized 
2023-03-27 14:19:05,202 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:05,646 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-27 14:19:11,818 : [INFO]  ------------------------- Batch round 1, loss: 0.5405 -------------------------
2023-03-27 14:19:11,818 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-27 14:19:11,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:11,826 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-27 14:19:14,826 : [INFO]  ------------------------- Batch round 2, loss: 0.5353 -------------------------
2023-03-27 14:19:14,827 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-27 14:19:14,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:14,834 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-27 14:19:17,682 : [INFO]  ------------------------- Batch round 3, loss: 0.5318 -------------------------
2023-03-27 14:19:17,683 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:17,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:17,688 : [INFO]  Batch number 69 model fetched from the server
2023-03-27 14:19:17,688 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-27 14:19:19,245 : [INFO]  Batch 69: Training set : loss - 0.5375, accuracy - 0.7826, recall - 0.9783, AUC - 0.9238, F1 - 0.8182, precision - 0.7031, training time - -12.0 seconds
2023-03-27 14:19:19,245 : [INFO]  Batch 69: Testing set : loss - 0.5674, accuracy - 0.7304, recall - 0.9216, AUC - 0.8874, F1 - 0.7737, precision - 0.6667
2023-03-27 14:19:19,252 : [INFO]  Batch 70 initialized 
2023-03-27 14:19:19,708 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:20,135 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-27 14:19:26,232 : [INFO]  ------------------------- Batch round 1, loss: 0.5266 -------------------------
2023-03-27 14:19:26,233 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-27 14:19:26,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:26,241 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-27 14:19:29,354 : [INFO]  ------------------------- Batch round 2, loss: 0.5241 -------------------------
2023-03-27 14:19:29,354 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-27 14:19:29,358 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:29,362 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-27 14:19:32,633 : [INFO]  ------------------------- Batch round 3, loss: 0.5183 -------------------------
2023-03-27 14:19:32,633 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:32,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:32,645 : [INFO]  Batch number 70 model fetched from the server
2023-03-27 14:19:32,645 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-27 14:19:35,450 : [INFO]  Batch 70: Training set : loss - 0.5194, accuracy - 0.7772, recall - 1.0, AUC - 0.9514, F1 - 0.8178, precision - 0.6917, training time - -13.0 seconds
2023-03-27 14:19:35,451 : [INFO]  Batch 70: Testing set : loss - 0.5423, accuracy - 0.7647, recall - 0.951, AUC - 0.9089, F1 - 0.8017, precision - 0.6929
2023-03-27 14:19:35,459 : [INFO]  Batch 71 initialized 
2023-03-27 14:19:36,605 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:37,446 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-27 14:19:43,613 : [INFO]  ------------------------- Batch round 1, loss: 0.5329 -------------------------
2023-03-27 14:19:43,614 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-27 14:19:43,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:43,619 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-27 14:19:47,211 : [INFO]  ------------------------- Batch round 2, loss: 0.5292 -------------------------
2023-03-27 14:19:47,212 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-27 14:19:47,283 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:47,290 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-27 14:19:50,958 : [INFO]  ------------------------- Batch round 3, loss: 0.528 -------------------------
2023-03-27 14:19:50,959 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:50,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:50,970 : [INFO]  Batch number 71 model fetched from the server
2023-03-27 14:19:50,970 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-27 14:19:53,572 : [INFO]  Batch 71: Training set : loss - 0.531, accuracy - 0.7935, recall - 0.9783, AUC - 0.9346, F1 - 0.8257, precision - 0.7143, training time - -14.0 seconds
2023-03-27 14:19:53,572 : [INFO]  Batch 71: Testing set : loss - 0.5629, accuracy - 0.7157, recall - 0.9118, AUC - 0.8777, F1 - 0.7623, precision - 0.6549
2023-03-27 14:19:53,601 : [INFO]  Batch 72 initialized 
2023-03-27 14:19:54,489 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:55,380 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-27 14:20:01,183 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-27 14:20:01,184 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:01,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:01,192 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-27 14:20:04,476 : [INFO]  ------------------------- Batch round 2, loss: 0.5479 -------------------------
2023-03-27 14:20:04,476 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:04,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:04,481 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-27 14:20:06,849 : [INFO]  ------------------------- Batch round 3, loss: 0.5405 -------------------------
2023-03-27 14:20:06,850 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:06,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:06,863 : [INFO]  Batch number 72 model fetched from the server
2023-03-27 14:20:06,863 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-27 14:20:08,480 : [INFO]  Batch 72: Training set : loss - 0.5384, accuracy - 0.7609, recall - 0.9783, AUC - 0.928, F1 - 0.8036, precision - 0.6818, training time - -11.0 seconds
2023-03-27 14:20:08,481 : [INFO]  Batch 72: Testing set : loss - 0.5522, accuracy - 0.7451, recall - 0.9706, AUC - 0.9072, F1 - 0.792, precision - 0.6689
2023-03-27 14:20:08,486 : [INFO]  Batch 73 initialized 
2023-03-27 14:20:09,365 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:09,860 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-27 14:20:15,867 : [INFO]  ------------------------- Batch round 1, loss: 0.5454 -------------------------
2023-03-27 14:20:15,867 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:15,979 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:15,981 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-27 14:20:20,146 : [INFO]  ------------------------- Batch round 2, loss: 0.5379 -------------------------
2023-03-27 14:20:20,147 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:20,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:20,155 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-27 14:20:22,999 : [INFO]  ------------------------- Batch round 3, loss: 0.5339 -------------------------
2023-03-27 14:20:22,999 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:23,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:23,008 : [INFO]  Batch number 73 model fetched from the server
2023-03-27 14:20:23,008 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-27 14:20:25,256 : [INFO]  Batch 73: Training set : loss - 0.5314, accuracy - 0.7717, recall - 0.9348, AUC - 0.905, F1 - 0.8037, precision - 0.7049, training time - -13.0 seconds
2023-03-27 14:20:25,257 : [INFO]  Batch 73: Testing set : loss - 0.5681, accuracy - 0.7255, recall - 0.9216, AUC - 0.8892, F1 - 0.7705, precision - 0.662
2023-03-27 14:20:25,266 : [INFO]  Batch 74 initialized 
2023-03-27 14:20:26,039 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:26,585 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-27 14:20:32,193 : [INFO]  ------------------------- Batch round 1, loss: 0.5699 -------------------------
2023-03-27 14:20:32,194 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:32,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:32,199 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-27 14:20:34,706 : [INFO]  ------------------------- Batch round 2, loss: 0.5596 -------------------------
2023-03-27 14:20:34,707 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:34,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:34,712 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-27 14:20:38,408 : [INFO]  ------------------------- Batch round 3, loss: 0.5529 -------------------------
2023-03-27 14:20:38,408 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:38,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:38,413 : [INFO]  Batch number 74 model fetched from the server
2023-03-27 14:20:38,413 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-27 14:20:40,382 : [INFO]  Batch 74: Training set : loss - 0.5502, accuracy - 0.7609, recall - 1.0, AUC - 0.922, F1 - 0.807, precision - 0.6765, training time - -12.0 seconds
2023-03-27 14:20:40,383 : [INFO]  Batch 74: Testing set : loss - 0.545, accuracy - 0.7892, recall - 0.9608, AUC - 0.896, F1 - 0.8201, precision - 0.7153
2023-03-27 14:20:40,387 : [INFO]  Batch 75 initialized 
2023-03-27 14:20:40,984 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:41,514 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-27 14:20:48,515 : [INFO]  ------------------------- Batch round 1, loss: 0.5238 -------------------------
2023-03-27 14:20:48,515 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:48,518 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:48,520 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-27 14:20:51,130 : [INFO]  ------------------------- Batch round 2, loss: 0.5206 -------------------------
2023-03-27 14:20:51,130 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:51,133 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:51,136 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-27 14:20:53,971 : [INFO]  ------------------------- Batch round 3, loss: 0.518 -------------------------
2023-03-27 14:20:53,971 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:53,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:53,978 : [INFO]  Batch number 75 model fetched from the server
2023-03-27 14:20:53,978 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-27 14:20:55,755 : [INFO]  Batch 75: Training set : loss - 0.5172, accuracy - 0.8098, recall - 0.9783, AUC - 0.9568, F1 - 0.8372, precision - 0.7317, training time - -12.0 seconds
2023-03-27 14:20:55,755 : [INFO]  Batch 75: Testing set : loss - 0.531, accuracy - 0.7745, recall - 0.9314, AUC - 0.9097, F1 - 0.8051, precision - 0.709
2023-03-27 14:20:55,760 : [INFO]  Batch 76 initialized 
2023-03-27 14:20:56,313 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:56,846 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-27 14:21:02,020 : [INFO]  ------------------------- Batch round 1, loss: 0.5643 -------------------------
2023-03-27 14:21:02,020 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:02,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:02,025 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-27 14:21:04,766 : [INFO]  ------------------------- Batch round 2, loss: 0.5571 -------------------------
2023-03-27 14:21:04,766 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:04,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:04,771 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-27 14:21:07,476 : [INFO]  ------------------------- Batch round 3, loss: 0.5546 -------------------------
2023-03-27 14:21:07,476 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:07,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:07,481 : [INFO]  Batch number 76 model fetched from the server
2023-03-27 14:21:07,482 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-27 14:21:09,269 : [INFO]  Batch 76: Training set : loss - 0.5487, accuracy - 0.7663, recall - 0.9457, AUC - 0.9054, F1 - 0.8018, precision - 0.696, training time - -11.0 seconds
2023-03-27 14:21:09,269 : [INFO]  Batch 76: Testing set : loss - 0.562, accuracy - 0.7549, recall - 0.951, AUC - 0.8994, F1 - 0.7951, precision - 0.6831
2023-03-27 14:21:09,274 : [INFO]  Batch 77 initialized 
2023-03-27 14:21:09,871 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:10,348 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-27 14:21:15,240 : [INFO]  ------------------------- Batch round 1, loss: 0.5444 -------------------------
2023-03-27 14:21:15,240 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:15,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:15,246 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-27 14:21:17,884 : [INFO]  ------------------------- Batch round 2, loss: 0.5353 -------------------------
2023-03-27 14:21:17,884 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:17,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:17,902 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-27 14:21:20,565 : [INFO]  ------------------------- Batch round 3, loss: 0.5333 -------------------------
2023-03-27 14:21:20,566 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:20,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:20,579 : [INFO]  Batch number 77 model fetched from the server
2023-03-27 14:21:20,579 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-27 14:21:22,212 : [INFO]  Batch 77: Training set : loss - 0.5332, accuracy - 0.75, recall - 0.9239, AUC - 0.9092, F1 - 0.787, precision - 0.6855, training time - -10.0 seconds
2023-03-27 14:21:22,213 : [INFO]  Batch 77: Testing set : loss - 0.5822, accuracy - 0.7059, recall - 0.902, AUC - 0.8506, F1 - 0.7541, precision - 0.6479
2023-03-27 14:21:22,224 : [INFO]  Batch 78 initialized 
2023-03-27 14:21:22,738 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:23,222 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-27 14:21:28,268 : [INFO]  ------------------------- Batch round 1, loss: 0.5374 -------------------------
2023-03-27 14:21:28,268 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:28,273 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:28,275 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-27 14:21:30,942 : [INFO]  ------------------------- Batch round 2, loss: 0.5333 -------------------------
2023-03-27 14:21:30,942 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:30,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:30,947 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-27 14:21:33,624 : [INFO]  ------------------------- Batch round 3, loss: 0.5296 -------------------------
2023-03-27 14:21:33,624 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:33,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:33,631 : [INFO]  Batch number 78 model fetched from the server
2023-03-27 14:21:33,631 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-27 14:21:35,443 : [INFO]  Batch 78: Training set : loss - 0.5355, accuracy - 0.7717, recall - 0.9457, AUC - 0.9057, F1 - 0.8056, precision - 0.7016, training time - -10.0 seconds
2023-03-27 14:21:35,444 : [INFO]  Batch 78: Testing set : loss - 0.5562, accuracy - 0.75, recall - 0.9608, AUC - 0.8924, F1 - 0.7935, precision - 0.6759
2023-03-27 14:21:35,450 : [INFO]  Batch 79 initialized 
2023-03-27 14:21:35,993 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:36,470 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-27 14:21:41,570 : [INFO]  ------------------------- Batch round 1, loss: 0.547 -------------------------
2023-03-27 14:21:41,570 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:41,574 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:41,576 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-27 14:21:44,246 : [INFO]  ------------------------- Batch round 2, loss: 0.5386 -------------------------
2023-03-27 14:21:44,246 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:44,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:44,252 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-27 14:21:46,911 : [INFO]  ------------------------- Batch round 3, loss: 0.5359 -------------------------
2023-03-27 14:21:46,911 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:47,121 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:47,123 : [INFO]  Batch number 79 model fetched from the server
2023-03-27 14:21:47,123 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-27 14:21:48,835 : [INFO]  Batch 79: Training set : loss - 0.5399, accuracy - 0.7663, recall - 0.9891, AUC - 0.9164, F1 - 0.8089, precision - 0.6842, training time - -11.0 seconds
2023-03-27 14:21:48,835 : [INFO]  Batch 79: Testing set : loss - 0.5468, accuracy - 0.7843, recall - 0.9804, AUC - 0.9107, F1 - 0.8197, precision - 0.7042
2023-03-27 14:21:48,841 : [INFO]  Batch 80 initialized 
2023-03-27 14:21:49,368 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:49,843 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-27 14:21:55,072 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-27 14:21:55,072 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:55,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:55,078 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-27 14:21:57,665 : [INFO]  ------------------------- Batch round 2, loss: 0.5434 -------------------------
2023-03-27 14:21:57,666 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:57,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:57,904 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-27 14:22:00,442 : [INFO]  ------------------------- Batch round 3, loss: 0.5396 -------------------------
2023-03-27 14:22:00,442 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:00,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:00,467 : [INFO]  Batch number 80 model fetched from the server
2023-03-27 14:22:00,467 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-27 14:22:02,162 : [INFO]  Batch 80: Training set : loss - 0.541, accuracy - 0.7772, recall - 0.9674, AUC - 0.9254, F1 - 0.8128, precision - 0.7008, training time - -11.0 seconds
2023-03-27 14:22:02,162 : [INFO]  Batch 80: Testing set : loss - 0.5435, accuracy - 0.7451, recall - 0.9608, AUC - 0.9194, F1 - 0.7903, precision - 0.6712
2023-03-27 14:22:02,168 : [INFO]  Batch 81 initialized 
2023-03-27 14:22:02,658 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:03,133 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-27 14:22:08,104 : [INFO]  ------------------------- Batch round 1, loss: 0.5554 -------------------------
2023-03-27 14:22:08,105 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:08,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:08,112 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-27 14:22:10,754 : [INFO]  ------------------------- Batch round 2, loss: 0.5503 -------------------------
2023-03-27 14:22:10,755 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:10,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:10,760 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-27 14:22:13,335 : [INFO]  ------------------------- Batch round 3, loss: 0.5414 -------------------------
2023-03-27 14:22:13,335 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:13,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:13,342 : [INFO]  Batch number 81 model fetched from the server
2023-03-27 14:22:13,342 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-27 14:22:15,039 : [INFO]  Batch 81: Training set : loss - 0.5428, accuracy - 0.7717, recall - 0.9783, AUC - 0.9185, F1 - 0.8108, precision - 0.6923, training time - -10.0 seconds
2023-03-27 14:22:15,039 : [INFO]  Batch 81: Testing set : loss - 0.5459, accuracy - 0.7549, recall - 0.9412, AUC - 0.9138, F1 - 0.7934, precision - 0.6857
2023-03-27 14:22:15,044 : [INFO]  Batch 82 initialized 
2023-03-27 14:22:15,539 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:16,002 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-27 14:22:20,946 : [INFO]  ------------------------- Batch round 1, loss: 0.5492 -------------------------
2023-03-27 14:22:20,947 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:20,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:20,953 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-27 14:22:23,811 : [INFO]  ------------------------- Batch round 2, loss: 0.5468 -------------------------
2023-03-27 14:22:23,811 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:23,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:23,816 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-27 14:22:26,498 : [INFO]  ------------------------- Batch round 3, loss: 0.5413 -------------------------
2023-03-27 14:22:26,498 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:26,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:26,582 : [INFO]  Batch number 82 model fetched from the server
2023-03-27 14:22:26,582 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-27 14:22:28,254 : [INFO]  Batch 82: Training set : loss - 0.5376, accuracy - 0.7772, recall - 0.9565, AUC - 0.8917, F1 - 0.8111, precision - 0.704, training time - -11.0 seconds
2023-03-27 14:22:28,254 : [INFO]  Batch 82: Testing set : loss - 0.5392, accuracy - 0.7696, recall - 0.9706, AUC - 0.9285, F1 - 0.8082, precision - 0.6923
2023-03-27 14:22:28,261 : [INFO]  Batch 83 initialized 
2023-03-27 14:22:28,774 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:29,244 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-27 14:22:35,339 : [INFO]  ------------------------- Batch round 1, loss: 0.5716 -------------------------
2023-03-27 14:22:35,340 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:35,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:35,346 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-27 14:22:38,835 : [INFO]  ------------------------- Batch round 2, loss: 0.5661 -------------------------
2023-03-27 14:22:38,835 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:38,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:38,971 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-27 14:22:42,184 : [INFO]  ------------------------- Batch round 3, loss: 0.5626 -------------------------
2023-03-27 14:22:42,184 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:42,187 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:42,189 : [INFO]  Batch number 83 model fetched from the server
2023-03-27 14:22:42,189 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-27 14:22:44,327 : [INFO]  Batch 83: Training set : loss - 0.5615, accuracy - 0.7446, recall - 0.9457, AUC - 0.8893, F1 - 0.7873, precision - 0.6744, training time - -13.0 seconds
2023-03-27 14:22:44,328 : [INFO]  Batch 83: Testing set : loss - 0.5695, accuracy - 0.7304, recall - 0.9412, AUC - 0.8794, F1 - 0.7773, precision - 0.6621
2023-03-27 14:22:44,339 : [INFO]  Batch 84 initialized 
2023-03-27 14:22:45,332 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:46,133 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-27 14:22:54,241 : [INFO]  ------------------------- Batch round 1, loss: 0.5456 -------------------------
2023-03-27 14:22:54,241 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:54,246 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:54,251 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-27 14:22:57,612 : [INFO]  ------------------------- Batch round 2, loss: 0.54 -------------------------
2023-03-27 14:22:57,612 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:57,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:57,620 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-27 14:23:00,590 : [INFO]  ------------------------- Batch round 3, loss: 0.5372 -------------------------
2023-03-27 14:23:00,590 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:00,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:00,595 : [INFO]  Batch number 84 model fetched from the server
2023-03-27 14:23:00,595 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-27 14:23:02,147 : [INFO]  Batch 84: Training set : loss - 0.5356, accuracy - 0.7772, recall - 0.9565, AUC - 0.9153, F1 - 0.8111, precision - 0.704, training time - -14.0 seconds
2023-03-27 14:23:02,147 : [INFO]  Batch 84: Testing set : loss - 0.5902, accuracy - 0.6961, recall - 0.9118, AUC - 0.8268, F1 - 0.75, precision - 0.637
2023-03-27 14:23:02,154 : [INFO]  Batch 85 initialized 
2023-03-27 14:23:02,660 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:03,145 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-27 14:23:08,082 : [INFO]  ------------------------- Batch round 1, loss: 0.5708 -------------------------
2023-03-27 14:23:08,082 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:08,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:08,087 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-27 14:23:11,257 : [INFO]  ------------------------- Batch round 2, loss: 0.5688 -------------------------
2023-03-27 14:23:11,257 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:11,262 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:11,266 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-27 14:23:14,647 : [INFO]  ------------------------- Batch round 3, loss: 0.5683 -------------------------
2023-03-27 14:23:14,647 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:14,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:14,690 : [INFO]  Batch number 85 model fetched from the server
2023-03-27 14:23:14,690 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-27 14:23:16,885 : [INFO]  Batch 85: Training set : loss - 0.5685, accuracy - 0.712, recall - 0.8913, AUC - 0.8692, F1 - 0.7558, precision - 0.656, training time - -12.0 seconds
2023-03-27 14:23:16,886 : [INFO]  Batch 85: Testing set : loss - 0.564, accuracy - 0.7402, recall - 0.9216, AUC - 0.8578, F1 - 0.7801, precision - 0.6763
2023-03-27 14:23:16,897 : [INFO]  Batch 86 initialized 
2023-03-27 14:23:17,538 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:17,948 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-27 14:23:22,860 : [INFO]  ------------------------- Batch round 1, loss: 0.591 -------------------------
2023-03-27 14:23:22,861 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:22,981 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:22,985 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-27 14:23:26,564 : [INFO]  ------------------------- Batch round 2, loss: 0.5789 -------------------------
2023-03-27 14:23:26,564 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:26,603 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:26,607 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-27 14:23:29,825 : [INFO]  ------------------------- Batch round 3, loss: 0.5768 -------------------------
2023-03-27 14:23:29,837 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:30,002 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:30,020 : [INFO]  Batch number 86 model fetched from the server
2023-03-27 14:23:30,020 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-27 14:23:32,016 : [INFO]  Batch 86: Training set : loss - 0.5735, accuracy - 0.7228, recall - 0.9457, AUC - 0.8823, F1 - 0.7733, precision - 0.6541, training time - -12.0 seconds
2023-03-27 14:23:32,016 : [INFO]  Batch 86: Testing set : loss - 0.5501, accuracy - 0.7696, recall - 0.9608, AUC - 0.895, F1 - 0.8066, precision - 0.695
2023-03-27 14:23:32,027 : [INFO]  Batch 87 initialized 
2023-03-27 14:23:32,754 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:33,267 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-27 14:23:39,912 : [INFO]  ------------------------- Batch round 1, loss: 0.5534 -------------------------
2023-03-27 14:23:39,913 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:39,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:39,918 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-27 14:23:42,753 : [INFO]  ------------------------- Batch round 2, loss: 0.5498 -------------------------
2023-03-27 14:23:42,753 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:42,759 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:42,763 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-27 14:23:45,643 : [INFO]  ------------------------- Batch round 3, loss: 0.5453 -------------------------
2023-03-27 14:23:45,643 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:45,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:45,650 : [INFO]  Batch number 87 model fetched from the server
2023-03-27 14:23:45,650 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-27 14:23:47,572 : [INFO]  Batch 87: Training set : loss - 0.5491, accuracy - 0.7554, recall - 0.9783, AUC - 0.8903, F1 - 0.8, precision - 0.6767, training time - -12.0 seconds
2023-03-27 14:23:47,573 : [INFO]  Batch 87: Testing set : loss - 0.5319, accuracy - 0.7941, recall - 0.951, AUC - 0.9052, F1 - 0.822, precision - 0.7239
2023-03-27 14:23:47,582 : [INFO]  Batch 88 initialized 
2023-03-27 14:23:48,148 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:48,712 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-27 14:23:54,158 : [INFO]  ------------------------- Batch round 1, loss: 0.5297 -------------------------
2023-03-27 14:23:54,158 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:54,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:54,163 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-27 14:23:57,144 : [INFO]  ------------------------- Batch round 2, loss: 0.5255 -------------------------
2023-03-27 14:23:57,145 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:57,150 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:57,153 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-27 14:24:00,381 : [INFO]  ------------------------- Batch round 3, loss: 0.5212 -------------------------
2023-03-27 14:24:00,382 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:00,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:00,387 : [INFO]  Batch number 88 model fetched from the server
2023-03-27 14:24:00,387 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-27 14:24:02,272 : [INFO]  Batch 88: Training set : loss - 0.5301, accuracy - 0.7826, recall - 0.9674, AUC - 0.9269, F1 - 0.8165, precision - 0.7063, training time - -12.0 seconds
2023-03-27 14:24:02,272 : [INFO]  Batch 88: Testing set : loss - 0.5655, accuracy - 0.701, recall - 0.9314, AUC - 0.8954, F1 - 0.757, precision - 0.6376
2023-03-27 14:24:02,276 : [INFO]  Batch 89 initialized 
2023-03-27 14:24:02,859 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:03,399 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-27 14:24:09,563 : [INFO]  ------------------------- Batch round 1, loss: 0.5382 -------------------------
2023-03-27 14:24:09,564 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:09,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:09,570 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-27 14:24:12,663 : [INFO]  ------------------------- Batch round 2, loss: 0.5265 -------------------------
2023-03-27 14:24:12,664 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:12,708 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:12,711 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-27 14:24:15,641 : [INFO]  ------------------------- Batch round 3, loss: 0.5213 -------------------------
2023-03-27 14:24:15,641 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:15,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:15,797 : [INFO]  Batch number 89 model fetched from the server
2023-03-27 14:24:15,797 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-27 14:24:17,722 : [INFO]  Batch 89: Training set : loss - 0.5202, accuracy - 0.8207, recall - 0.9565, AUC - 0.9153, F1 - 0.8421, precision - 0.7521, training time - -12.0 seconds
2023-03-27 14:24:17,723 : [INFO]  Batch 89: Testing set : loss - 0.557, accuracy - 0.7255, recall - 0.9216, AUC - 0.9074, F1 - 0.7705, precision - 0.662
2023-03-27 14:24:17,730 : [INFO]  Batch 90 initialized 
2023-03-27 14:24:18,332 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:18,925 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-27 14:24:24,526 : [INFO]  ------------------------- Batch round 1, loss: 0.5577 -------------------------
2023-03-27 14:24:24,526 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:24,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:24,531 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-27 14:24:27,503 : [INFO]  ------------------------- Batch round 2, loss: 0.539 -------------------------
2023-03-27 14:24:27,503 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:27,506 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:27,508 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-27 14:24:30,375 : [INFO]  ------------------------- Batch round 3, loss: 0.532 -------------------------
2023-03-27 14:24:30,375 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:30,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:30,387 : [INFO]  Batch number 90 model fetched from the server
2023-03-27 14:24:30,387 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-27 14:24:32,256 : [INFO]  Batch 90: Training set : loss - 0.5317, accuracy - 0.7772, recall - 0.9457, AUC - 0.9088, F1 - 0.8093, precision - 0.7073, training time - -11.0 seconds
2023-03-27 14:24:32,256 : [INFO]  Batch 90: Testing set : loss - 0.5577, accuracy - 0.7696, recall - 0.951, AUC - 0.897, F1 - 0.805, precision - 0.6978
2023-03-27 14:24:32,263 : [INFO]  Batch 91 initialized 
2023-03-27 14:24:32,787 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:33,436 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-27 14:24:39,049 : [INFO]  ------------------------- Batch round 1, loss: 0.5468 -------------------------
2023-03-27 14:24:39,050 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:39,054 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:39,060 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-27 14:24:41,844 : [INFO]  ------------------------- Batch round 2, loss: 0.5432 -------------------------
2023-03-27 14:24:41,845 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:41,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:41,892 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-27 14:24:44,722 : [INFO]  ------------------------- Batch round 3, loss: 0.5384 -------------------------
2023-03-27 14:24:44,722 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:44,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:44,826 : [INFO]  Batch number 91 model fetched from the server
2023-03-27 14:24:44,826 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-27 14:24:46,886 : [INFO]  Batch 91: Training set : loss - 0.5417, accuracy - 0.7663, recall - 0.9674, AUC - 0.9134, F1 - 0.8054, precision - 0.6899, training time - -11.0 seconds
2023-03-27 14:24:46,886 : [INFO]  Batch 91: Testing set : loss - 0.5672, accuracy - 0.7451, recall - 0.9608, AUC - 0.9034, F1 - 0.7903, precision - 0.6712
2023-03-27 14:24:46,893 : [INFO]  Batch 92 initialized 
2023-03-27 14:24:47,996 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:48,977 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-27 14:24:54,621 : [INFO]  ------------------------- Batch round 1, loss: 0.5483 -------------------------
2023-03-27 14:24:54,622 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:54,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:54,627 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-27 14:24:57,333 : [INFO]  ------------------------- Batch round 2, loss: 0.5425 -------------------------
2023-03-27 14:24:57,333 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:57,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:57,399 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-27 14:25:00,106 : [INFO]  ------------------------- Batch round 3, loss: 0.5381 -------------------------
2023-03-27 14:25:00,106 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-27 14:25:00,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:00,365 : [INFO]  Batch number 92 model fetched from the server
2023-03-27 14:25:00,365 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-27 14:25:02,169 : [INFO]  Batch 92: Training set : loss - 0.5356, accuracy - 0.7609, recall - 0.913, AUC - 0.9012, F1 - 0.7925, precision - 0.7, training time - -11.0 seconds
2023-03-27 14:25:02,169 : [INFO]  Batch 92: Testing set : loss - 0.5663, accuracy - 0.7549, recall - 0.951, AUC - 0.8935, F1 - 0.7951, precision - 0.6831
2023-03-27 14:25:02,173 : [INFO]  Batch 93 initialized 
2023-03-27 14:25:02,705 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:25:03,246 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-27 14:25:08,562 : [INFO]  ------------------------- Batch round 1, loss: 0.5209 -------------------------
2023-03-27 14:25:08,563 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-27 14:25:08,776 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:08,778 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-27 14:25:11,657 : [INFO]  ------------------------- Batch round 2, loss: 0.5145 -------------------------
2023-03-27 14:25:11,658 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-27 14:25:11,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:11,663 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-27 14:25:14,446 : [INFO]  ------------------------- Batch round 3, loss: 0.5112 -------------------------
2023-03-27 14:25:14,446 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-27 14:25:14,453 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:14,455 : [INFO]  Batch number 93 model fetched from the server
2023-03-27 14:25:14,455 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-27 14:25:16,397 : [INFO]  Batch 93: Training set : loss - 0.5108, accuracy - 0.8207, recall - 0.9565, AUC - 0.922, F1 - 0.8421, precision - 0.7521, training time - -11.0 seconds
2023-03-27 14:25:16,397 : [INFO]  Batch 93: Testing set : loss - 0.5663, accuracy - 0.7353, recall - 0.8922, AUC - 0.8644, F1 - 0.7712, precision - 0.6791
2023-03-27 14:25:16,404 : [INFO]  Result report : Accuracy - 0.746 (0.0254), Recall - 0.9351 (0.0265), AUC - 0.8858 (0.0268), F1 - 0.7865 (0.0195), Precision - 0.6792 (0.0228)
2023-03-27 14:25:16,405 : [INFO]  Result report : Accuracy - 0.746 (0.0254), Recall - 0.9351 (0.0265), AUC - 0.8858 (0.0268), F1 - 0.7865 (0.0195), Precision - 0.6792 (0.0228), Mean time for a batch - 10.04 (1.47) seconds
2023-03-27 14:25:16,405 : [INFO]  Distributed training done!
2023-03-27 14:25:16,405 : [INFO]  Training report : Total elapsed time 1312.964155370999 seconds, graph name wikipedia, graph ID 1, partition ID 0, training epochs 6, epochs 6
