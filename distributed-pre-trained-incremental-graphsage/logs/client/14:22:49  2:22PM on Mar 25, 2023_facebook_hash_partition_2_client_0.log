2023-03-25 14:22:49,661 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 14:22:49,661 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 10, epochs 10
2023-03-25 14:22:54,478 : [INFO]  Model initialized for training
2023-03-25 14:23:14,836 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:23:15,119 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 14:23:15,121 : [INFO]  Connected to the server
2023-03-25 14:23:15,277 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 14:23:15,277 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:23:15,294 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 14:23:15,294 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 14:29:00,854 : [INFO]  ------------------------- Training round 1, loss: 0.6116 -------------------------
2023-03-25 14:29:00,859 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 14:29:00,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:29:00,867 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 14:33:48,273 : [INFO]  ------------------------- Training round 2, loss: 0.5917 -------------------------
2023-03-25 14:33:48,274 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 14:33:48,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:33:48,282 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 14:38:40,038 : [INFO]  ------------------------- Training round 3, loss: 0.5889 -------------------------
2023-03-25 14:38:40,040 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 14:38:40,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:38:40,051 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 14:43:28,769 : [INFO]  ------------------------- Training round 4, loss: 0.5876 -------------------------
2023-03-25 14:43:28,769 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 14:43:28,775 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:43:28,777 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 14:49:07,840 : [INFO]  ------------------------- Training round 5, loss: 0.5865 -------------------------
2023-03-25 14:49:07,841 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 14:49:07,844 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:49:07,846 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 14:50:08,058 : [INFO]  Initially trained model: Training set : loss - 0.58, accuracy - 0.71, recall - 0.87, AUC - 0.83, F1 - 0.75, precision - 0.65, training time - -1553.0 seconds
2023-03-25 14:50:08,058 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 14:50:08,168 : [INFO]  Batch 1 initialized 
2023-03-25 14:50:08,854 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:50:11,389 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 14:50:11,389 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 14:50:17,624 : [INFO]  ------------------------- Batch round 1, loss: 0.5893 -------------------------
2023-03-25 14:50:17,624 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 14:50:17,636 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:17,639 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 14:50:22,138 : [INFO]  ------------------------- Batch round 2, loss: 0.5747 -------------------------
2023-03-25 14:50:22,139 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 14:50:22,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:22,177 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 14:50:26,416 : [INFO]  ------------------------- Batch round 3, loss: 0.5584 -------------------------
2023-03-25 14:50:26,416 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 14:50:26,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:26,426 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 14:50:26,426 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 14:50:28,105 : [INFO]  Batch 1: Training set : loss - 0.5626, accuracy - 0.7609, recall - 0.9239, AUC - 0.8775, F1 - 0.7944, precision - 0.6967, training time - -15.0 seconds
2023-03-25 14:50:28,105 : [INFO]  Batch 1: Testing set : loss - 0.5662, accuracy - 0.7157, recall - 0.8627, AUC - 0.8697, F1 - 0.7521, precision - 0.6667
2023-03-25 14:50:28,113 : [INFO]  Batch 2 initialized 
2023-03-25 14:50:28,672 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:50:28,838 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 14:50:34,897 : [INFO]  ------------------------- Batch round 1, loss: 0.5572 -------------------------
2023-03-25 14:50:34,897 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 14:50:34,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:34,902 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 14:50:38,795 : [INFO]  ------------------------- Batch round 2, loss: 0.5426 -------------------------
2023-03-25 14:50:38,795 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 14:50:38,819 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:38,824 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 14:50:42,726 : [INFO]  ------------------------- Batch round 3, loss: 0.5376 -------------------------
2023-03-25 14:50:42,726 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 14:50:42,729 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:42,731 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 14:50:42,731 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 14:50:44,269 : [INFO]  Batch 2: Training set : loss - 0.5414, accuracy - 0.788, recall - 0.9565, AUC - 0.9001, F1 - 0.8186, precision - 0.7154, training time - -14.0 seconds
2023-03-25 14:50:44,270 : [INFO]  Batch 2: Testing set : loss - 0.5601, accuracy - 0.7206, recall - 0.951, AUC - 0.8909, F1 - 0.7729, precision - 0.651
2023-03-25 14:50:44,277 : [INFO]  Batch 3 initialized 
2023-03-25 14:50:44,968 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:50:45,190 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 14:50:51,604 : [INFO]  ------------------------- Batch round 1, loss: 0.5332 -------------------------
2023-03-25 14:50:51,604 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 14:50:51,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:51,618 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 14:50:55,812 : [INFO]  ------------------------- Batch round 2, loss: 0.525 -------------------------
2023-03-25 14:50:55,812 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 14:50:55,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:50:55,970 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 14:51:00,251 : [INFO]  ------------------------- Batch round 3, loss: 0.5211 -------------------------
2023-03-25 14:51:00,251 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 14:51:00,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:00,257 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 14:51:00,257 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 14:51:01,841 : [INFO]  Batch 3: Training set : loss - 0.5259, accuracy - 0.7663, recall - 0.8913, AUC - 0.8941, F1 - 0.7923, precision - 0.713, training time - -15.0 seconds
2023-03-25 14:51:01,841 : [INFO]  Batch 3: Testing set : loss - 0.5701, accuracy - 0.701, recall - 0.951, AUC - 0.8558, F1 - 0.7608, precision - 0.634
2023-03-25 14:51:01,848 : [INFO]  Batch 4 initialized 
2023-03-25 14:51:02,353 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:51:02,618 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 14:51:08,881 : [INFO]  ------------------------- Batch round 1, loss: 0.5544 -------------------------
2023-03-25 14:51:08,881 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 14:51:08,884 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:08,886 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 14:51:12,998 : [INFO]  ------------------------- Batch round 2, loss: 0.5401 -------------------------
2023-03-25 14:51:12,998 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 14:51:13,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:13,004 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 14:51:16,765 : [INFO]  ------------------------- Batch round 3, loss: 0.5285 -------------------------
2023-03-25 14:51:16,765 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 14:51:16,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:16,874 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 14:51:16,874 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 14:51:18,352 : [INFO]  Batch 4: Training set : loss - 0.5264, accuracy - 0.788, recall - 0.9674, AUC - 0.9187, F1 - 0.8203, precision - 0.712, training time - -14.0 seconds
2023-03-25 14:51:18,352 : [INFO]  Batch 4: Testing set : loss - 0.5639, accuracy - 0.75, recall - 0.9608, AUC - 0.8973, F1 - 0.7935, precision - 0.6759
2023-03-25 14:51:18,358 : [INFO]  Batch 5 initialized 
2023-03-25 14:51:18,855 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:51:19,136 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 14:51:25,307 : [INFO]  ------------------------- Batch round 1, loss: 0.5412 -------------------------
2023-03-25 14:51:25,307 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 14:51:25,312 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:25,315 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 14:51:29,409 : [INFO]  ------------------------- Batch round 2, loss: 0.5237 -------------------------
2023-03-25 14:51:29,409 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 14:51:29,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:29,414 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 14:51:33,534 : [INFO]  ------------------------- Batch round 3, loss: 0.5147 -------------------------
2023-03-25 14:51:33,534 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 14:51:33,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:33,546 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 14:51:33,546 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 14:51:35,077 : [INFO]  Batch 5: Training set : loss - 0.5042, accuracy - 0.8315, recall - 0.9783, AUC - 0.9482, F1 - 0.8531, precision - 0.7563, training time - -14.0 seconds
2023-03-25 14:51:35,077 : [INFO]  Batch 5: Testing set : loss - 0.5728, accuracy - 0.7157, recall - 0.8627, AUC - 0.8404, F1 - 0.7521, precision - 0.6667
2023-03-25 14:51:35,084 : [INFO]  Batch 6 initialized 
2023-03-25 14:51:35,619 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:51:35,877 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 14:51:42,030 : [INFO]  ------------------------- Batch round 1, loss: 0.5694 -------------------------
2023-03-25 14:51:42,030 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 14:51:42,033 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:42,035 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 14:51:45,955 : [INFO]  ------------------------- Batch round 2, loss: 0.5548 -------------------------
2023-03-25 14:51:45,956 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 14:51:45,973 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:45,975 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 14:51:50,064 : [INFO]  ------------------------- Batch round 3, loss: 0.5461 -------------------------
2023-03-25 14:51:50,064 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 14:51:50,070 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:50,072 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 14:51:50,072 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 14:51:51,604 : [INFO]  Batch 6: Training set : loss - 0.5501, accuracy - 0.7446, recall - 0.9457, AUC - 0.8824, F1 - 0.7873, precision - 0.6744, training time - -14.0 seconds
2023-03-25 14:51:51,604 : [INFO]  Batch 6: Testing set : loss - 0.563, accuracy - 0.7157, recall - 0.902, AUC - 0.8908, F1 - 0.7603, precision - 0.6571
2023-03-25 14:51:51,613 : [INFO]  Batch 7 initialized 
2023-03-25 14:51:52,154 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:51:52,434 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 14:51:59,477 : [INFO]  ------------------------- Batch round 1, loss: 0.5597 -------------------------
2023-03-25 14:51:59,477 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 14:51:59,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:51:59,483 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 14:52:03,668 : [INFO]  ------------------------- Batch round 2, loss: 0.5548 -------------------------
2023-03-25 14:52:03,668 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 14:52:03,671 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:03,674 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 14:52:07,866 : [INFO]  ------------------------- Batch round 3, loss: 0.5468 -------------------------
2023-03-25 14:52:07,866 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 14:52:07,869 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:07,871 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 14:52:07,871 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 14:52:09,541 : [INFO]  Batch 7: Training set : loss - 0.5449, accuracy - 0.75, recall - 0.9565, AUC - 0.8799, F1 - 0.7928, precision - 0.6769, training time - -15.0 seconds
2023-03-25 14:52:09,541 : [INFO]  Batch 7: Testing set : loss - 0.5669, accuracy - 0.7157, recall - 0.8725, AUC - 0.8452, F1 - 0.7542, precision - 0.6642
2023-03-25 14:52:09,551 : [INFO]  Batch 8 initialized 
2023-03-25 14:52:10,097 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:52:10,381 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 14:52:17,561 : [INFO]  ------------------------- Batch round 1, loss: 0.5697 -------------------------
2023-03-25 14:52:17,561 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 14:52:17,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:17,567 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 14:52:22,140 : [INFO]  ------------------------- Batch round 2, loss: 0.5528 -------------------------
2023-03-25 14:52:22,140 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 14:52:22,143 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:22,146 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 14:52:26,690 : [INFO]  ------------------------- Batch round 3, loss: 0.5416 -------------------------
2023-03-25 14:52:26,690 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 14:52:26,694 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:26,697 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 14:52:26,697 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 14:52:28,305 : [INFO]  Batch 8: Training set : loss - 0.5441, accuracy - 0.7663, recall - 0.9239, AUC - 0.8849, F1 - 0.7981, precision - 0.7025, training time - -16.0 seconds
2023-03-25 14:52:28,305 : [INFO]  Batch 8: Testing set : loss - 0.5706, accuracy - 0.7059, recall - 0.8333, AUC - 0.8535, F1 - 0.7391, precision - 0.6641
2023-03-25 14:52:28,312 : [INFO]  Batch 9 initialized 
2023-03-25 14:52:28,813 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:52:29,113 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 14:52:35,386 : [INFO]  ------------------------- Batch round 1, loss: 0.5427 -------------------------
2023-03-25 14:52:35,386 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 14:52:35,390 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:35,392 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 14:52:39,561 : [INFO]  ------------------------- Batch round 2, loss: 0.5246 -------------------------
2023-03-25 14:52:39,561 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 14:52:39,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:39,566 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 14:52:43,468 : [INFO]  ------------------------- Batch round 3, loss: 0.514 -------------------------
2023-03-25 14:52:43,468 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 14:52:43,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:43,506 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 14:52:43,506 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 14:52:45,007 : [INFO]  Batch 9: Training set : loss - 0.5122, accuracy - 0.8043, recall - 0.9674, AUC - 0.9454, F1 - 0.8318, precision - 0.7295, training time - -14.0 seconds
2023-03-25 14:52:45,007 : [INFO]  Batch 9: Testing set : loss - 0.5473, accuracy - 0.7451, recall - 0.902, AUC - 0.8907, F1 - 0.7797, precision - 0.6866
2023-03-25 14:52:45,016 : [INFO]  Batch 10 initialized 
2023-03-25 14:52:45,564 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:52:45,847 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 14:52:51,798 : [INFO]  ------------------------- Batch round 1, loss: 0.5504 -------------------------
2023-03-25 14:52:51,798 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 14:52:51,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:51,803 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 14:52:55,645 : [INFO]  ------------------------- Batch round 2, loss: 0.5377 -------------------------
2023-03-25 14:52:55,646 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 14:52:55,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:55,653 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 14:52:59,617 : [INFO]  ------------------------- Batch round 3, loss: 0.526 -------------------------
2023-03-25 14:52:59,617 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 14:52:59,641 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:52:59,643 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 14:52:59,644 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 14:53:01,479 : [INFO]  Batch 10: Training set : loss - 0.5222, accuracy - 0.7826, recall - 0.9783, AUC - 0.9236, F1 - 0.8182, precision - 0.7031, training time - -14.0 seconds
2023-03-25 14:53:01,479 : [INFO]  Batch 10: Testing set : loss - 0.5454, accuracy - 0.75, recall - 0.9118, AUC - 0.8848, F1 - 0.7848, precision - 0.6889
2023-03-25 14:53:01,486 : [INFO]  Batch 11 initialized 
2023-03-25 14:53:02,133 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:53:02,472 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 14:53:09,060 : [INFO]  ------------------------- Batch round 1, loss: 0.573 -------------------------
2023-03-25 14:53:09,060 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 14:53:09,063 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:09,065 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 14:53:13,613 : [INFO]  ------------------------- Batch round 2, loss: 0.5515 -------------------------
2023-03-25 14:53:13,614 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 14:53:13,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:13,619 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 14:53:18,255 : [INFO]  ------------------------- Batch round 3, loss: 0.5479 -------------------------
2023-03-25 14:53:18,256 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 14:53:18,260 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:18,263 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 14:53:18,263 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 14:53:19,877 : [INFO]  Batch 11: Training set : loss - 0.5477, accuracy - 0.7337, recall - 0.9457, AUC - 0.8961, F1 - 0.7803, precision - 0.6641, training time - -16.0 seconds
2023-03-25 14:53:19,877 : [INFO]  Batch 11: Testing set : loss - 0.5491, accuracy - 0.7451, recall - 0.9118, AUC - 0.9028, F1 - 0.7815, precision - 0.6838
2023-03-25 14:53:19,889 : [INFO]  Batch 12 initialized 
2023-03-25 14:53:20,598 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:53:20,896 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 14:53:27,332 : [INFO]  ------------------------- Batch round 1, loss: 0.5514 -------------------------
2023-03-25 14:53:27,332 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 14:53:27,336 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:27,339 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 14:53:32,369 : [INFO]  ------------------------- Batch round 2, loss: 0.5452 -------------------------
2023-03-25 14:53:32,370 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 14:53:32,373 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:32,376 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 14:53:37,701 : [INFO]  ------------------------- Batch round 3, loss: 0.5426 -------------------------
2023-03-25 14:53:37,701 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 14:53:37,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:37,708 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 14:53:37,708 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 14:53:39,551 : [INFO]  Batch 12: Training set : loss - 0.5356, accuracy - 0.7772, recall - 0.8261, AUC - 0.8666, F1 - 0.7876, precision - 0.7525, training time - -17.0 seconds
2023-03-25 14:53:39,551 : [INFO]  Batch 12: Testing set : loss - 0.5879, accuracy - 0.6765, recall - 0.8529, AUC - 0.8366, F1 - 0.725, precision - 0.6304
2023-03-25 14:53:39,561 : [INFO]  Batch 13 initialized 
2023-03-25 14:53:40,215 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:53:40,475 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 14:53:49,213 : [INFO]  ------------------------- Batch round 1, loss: 0.5895 -------------------------
2023-03-25 14:53:49,213 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 14:53:49,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:49,220 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 14:53:53,558 : [INFO]  ------------------------- Batch round 2, loss: 0.5731 -------------------------
2023-03-25 14:53:53,558 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 14:53:53,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:53,704 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 14:53:57,950 : [INFO]  ------------------------- Batch round 3, loss: 0.5679 -------------------------
2023-03-25 14:53:57,950 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 14:53:58,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:53:58,052 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 14:53:58,053 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 14:54:00,002 : [INFO]  Batch 13: Training set : loss - 0.5623, accuracy - 0.7337, recall - 0.9022, AUC - 0.8426, F1 - 0.7721, precision - 0.6748, training time - -18.0 seconds
2023-03-25 14:54:00,002 : [INFO]  Batch 13: Testing set : loss - 0.5724, accuracy - 0.7157, recall - 0.8137, AUC - 0.8205, F1 - 0.7411, precision - 0.6803
2023-03-25 14:54:00,020 : [INFO]  Batch 14 initialized 
2023-03-25 14:54:00,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:54:00,877 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 14:54:08,505 : [INFO]  ------------------------- Batch round 1, loss: 0.5531 -------------------------
2023-03-25 14:54:08,506 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 14:54:08,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:08,514 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 14:54:14,935 : [INFO]  ------------------------- Batch round 2, loss: 0.5373 -------------------------
2023-03-25 14:54:14,935 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 14:54:14,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:14,941 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 14:54:19,253 : [INFO]  ------------------------- Batch round 3, loss: 0.5293 -------------------------
2023-03-25 14:54:19,253 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 14:54:19,257 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:19,260 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 14:54:19,260 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 14:54:20,884 : [INFO]  Batch 14: Training set : loss - 0.5247, accuracy - 0.8152, recall - 0.913, AUC - 0.8852, F1 - 0.8317, precision - 0.7636, training time - -18.0 seconds
2023-03-25 14:54:20,884 : [INFO]  Batch 14: Testing set : loss - 0.5706, accuracy - 0.6961, recall - 0.8824, AUC - 0.871, F1 - 0.7438, precision - 0.6429
2023-03-25 14:54:20,893 : [INFO]  Batch 15 initialized 
2023-03-25 14:54:21,515 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:54:21,754 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 14:54:28,474 : [INFO]  ------------------------- Batch round 1, loss: 0.5728 -------------------------
2023-03-25 14:54:28,475 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 14:54:28,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:28,483 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 14:54:32,823 : [INFO]  ------------------------- Batch round 2, loss: 0.558 -------------------------
2023-03-25 14:54:32,823 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 14:54:32,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:32,829 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 14:54:36,657 : [INFO]  ------------------------- Batch round 3, loss: 0.5451 -------------------------
2023-03-25 14:54:36,657 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 14:54:36,660 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:36,661 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 14:54:36,661 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 14:54:38,065 : [INFO]  Batch 15: Training set : loss - 0.5437, accuracy - 0.7717, recall - 0.9457, AUC - 0.8783, F1 - 0.8056, precision - 0.7016, training time - -15.0 seconds
2023-03-25 14:54:38,065 : [INFO]  Batch 15: Testing set : loss - 0.5854, accuracy - 0.6667, recall - 0.8529, AUC - 0.8378, F1 - 0.719, precision - 0.6214
2023-03-25 14:54:38,075 : [INFO]  Batch 16 initialized 
2023-03-25 14:54:38,682 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:54:38,960 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 14:54:44,721 : [INFO]  ------------------------- Batch round 1, loss: 0.5508 -------------------------
2023-03-25 14:54:44,721 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 14:54:44,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:44,727 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 14:54:48,364 : [INFO]  ------------------------- Batch round 2, loss: 0.5376 -------------------------
2023-03-25 14:54:48,364 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 14:54:48,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:48,392 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 14:54:52,620 : [INFO]  ------------------------- Batch round 3, loss: 0.5256 -------------------------
2023-03-25 14:54:52,620 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 14:54:52,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:54:52,626 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 14:54:52,626 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 14:54:54,022 : [INFO]  Batch 16: Training set : loss - 0.5279, accuracy - 0.7717, recall - 0.9565, AUC - 0.9144, F1 - 0.8073, precision - 0.6984, training time - -14.0 seconds
2023-03-25 14:54:54,023 : [INFO]  Batch 16: Testing set : loss - 0.5358, accuracy - 0.7402, recall - 0.951, AUC - 0.9251, F1 - 0.7854, precision - 0.669
2023-03-25 14:54:54,035 : [INFO]  Batch 17 initialized 
2023-03-25 14:54:54,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:54:54,994 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 14:55:01,227 : [INFO]  ------------------------- Batch round 1, loss: 0.5519 -------------------------
2023-03-25 14:55:01,227 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 14:55:01,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:01,352 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 14:55:05,519 : [INFO]  ------------------------- Batch round 2, loss: 0.5323 -------------------------
2023-03-25 14:55:05,519 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 14:55:05,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:05,525 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 14:55:09,261 : [INFO]  ------------------------- Batch round 3, loss: 0.5162 -------------------------
2023-03-25 14:55:09,262 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 14:55:09,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:09,268 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 14:55:09,268 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 14:55:10,824 : [INFO]  Batch 17: Training set : loss - 0.5178, accuracy - 0.8098, recall - 0.9239, AUC - 0.9045, F1 - 0.8293, precision - 0.7522, training time - -14.0 seconds
2023-03-25 14:55:10,824 : [INFO]  Batch 17: Testing set : loss - 0.577, accuracy - 0.6961, recall - 0.8824, AUC - 0.8573, F1 - 0.7438, precision - 0.6429
2023-03-25 14:55:10,837 : [INFO]  Batch 18 initialized 
2023-03-25 14:55:11,352 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:55:11,651 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 14:55:17,834 : [INFO]  ------------------------- Batch round 1, loss: 0.5738 -------------------------
2023-03-25 14:55:17,834 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 14:55:17,837 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:17,839 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 14:55:21,616 : [INFO]  ------------------------- Batch round 2, loss: 0.5579 -------------------------
2023-03-25 14:55:21,616 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 14:55:21,619 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:21,622 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 14:55:25,214 : [INFO]  ------------------------- Batch round 3, loss: 0.5518 -------------------------
2023-03-25 14:55:25,215 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 14:55:25,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:25,415 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 14:55:25,415 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 14:55:26,968 : [INFO]  Batch 18: Training set : loss - 0.5501, accuracy - 0.7446, recall - 0.9565, AUC - 0.8634, F1 - 0.7892, precision - 0.6718, training time - -14.0 seconds
2023-03-25 14:55:26,968 : [INFO]  Batch 18: Testing set : loss - 0.612, accuracy - 0.6373, recall - 0.8725, AUC - 0.8137, F1 - 0.7063, precision - 0.5933
2023-03-25 14:55:26,981 : [INFO]  Batch 19 initialized 
2023-03-25 14:55:27,573 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:55:27,839 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 14:55:34,228 : [INFO]  ------------------------- Batch round 1, loss: 0.5835 -------------------------
2023-03-25 14:55:34,228 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 14:55:34,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:34,233 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 14:55:38,243 : [INFO]  ------------------------- Batch round 2, loss: 0.5714 -------------------------
2023-03-25 14:55:38,243 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 14:55:38,246 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:38,249 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 14:55:41,928 : [INFO]  ------------------------- Batch round 3, loss: 0.5617 -------------------------
2023-03-25 14:55:41,928 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 14:55:41,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:41,997 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 14:55:41,997 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 14:55:43,429 : [INFO]  Batch 19: Training set : loss - 0.565, accuracy - 0.7337, recall - 0.8913, AUC - 0.8385, F1 - 0.77, precision - 0.6777, training time - -14.0 seconds
2023-03-25 14:55:43,430 : [INFO]  Batch 19: Testing set : loss - 0.5963, accuracy - 0.6814, recall - 0.8824, AUC - 0.8344, F1 - 0.7347, precision - 0.6294
2023-03-25 14:55:43,449 : [INFO]  Batch 20 initialized 
2023-03-25 14:55:44,031 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:55:44,322 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 14:55:50,019 : [INFO]  ------------------------- Batch round 1, loss: 0.5485 -------------------------
2023-03-25 14:55:50,019 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 14:55:50,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:50,026 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 14:55:53,854 : [INFO]  ------------------------- Batch round 2, loss: 0.5413 -------------------------
2023-03-25 14:55:53,854 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 14:55:53,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:53,878 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 14:55:58,035 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 14:55:58,035 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 14:55:58,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:55:58,040 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 14:55:58,040 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 14:55:59,479 : [INFO]  Batch 20: Training set : loss - 0.5334, accuracy - 0.7663, recall - 0.9783, AUC - 0.8978, F1 - 0.8072, precision - 0.687, training time - -14.0 seconds
2023-03-25 14:55:59,479 : [INFO]  Batch 20: Testing set : loss - 0.5795, accuracy - 0.6863, recall - 0.9118, AUC - 0.8515, F1 - 0.744, precision - 0.6284
2023-03-25 14:55:59,493 : [INFO]  Batch 21 initialized 
2023-03-25 14:55:59,988 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:56:00,295 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 14:56:06,294 : [INFO]  ------------------------- Batch round 1, loss: 0.5961 -------------------------
2023-03-25 14:56:06,294 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 14:56:06,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:06,299 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 14:56:10,351 : [INFO]  ------------------------- Batch round 2, loss: 0.5832 -------------------------
2023-03-25 14:56:10,351 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 14:56:10,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:10,356 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 14:56:14,263 : [INFO]  ------------------------- Batch round 3, loss: 0.5829 -------------------------
2023-03-25 14:56:14,263 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 14:56:14,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:14,269 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 14:56:14,269 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 14:56:15,885 : [INFO]  Batch 21: Training set : loss - 0.5797, accuracy - 0.7283, recall - 0.9239, AUC - 0.8032, F1 - 0.7727, precision - 0.6641, training time - -14.0 seconds
2023-03-25 14:56:15,885 : [INFO]  Batch 21: Testing set : loss - 0.5563, accuracy - 0.7108, recall - 0.9314, AUC - 0.8578, F1 - 0.7631, precision - 0.6463
2023-03-25 14:56:15,891 : [INFO]  Batch 22 initialized 
2023-03-25 14:56:16,421 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:56:16,718 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 14:56:23,105 : [INFO]  ------------------------- Batch round 1, loss: 0.6022 -------------------------
2023-03-25 14:56:23,105 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 14:56:23,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:23,113 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 14:56:27,751 : [INFO]  ------------------------- Batch round 2, loss: 0.5872 -------------------------
2023-03-25 14:56:27,751 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 14:56:27,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:27,756 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 14:56:32,599 : [INFO]  ------------------------- Batch round 3, loss: 0.5809 -------------------------
2023-03-25 14:56:32,599 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 14:56:32,603 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:32,606 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 14:56:32,606 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 14:56:34,527 : [INFO]  Batch 22: Training set : loss - 0.5796, accuracy - 0.7174, recall - 0.8478, AUC - 0.7934, F1 - 0.75, precision - 0.6724, training time - -16.0 seconds
2023-03-25 14:56:34,527 : [INFO]  Batch 22: Testing set : loss - 0.6441, accuracy - 0.6127, recall - 0.8333, AUC - 0.7469, F1 - 0.6827, precision - 0.5782
2023-03-25 14:56:34,533 : [INFO]  Batch 23 initialized 
2023-03-25 14:56:35,082 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:56:35,410 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 14:56:42,324 : [INFO]  ------------------------- Batch round 1, loss: 0.5666 -------------------------
2023-03-25 14:56:42,324 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 14:56:42,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:42,330 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 14:56:46,442 : [INFO]  ------------------------- Batch round 2, loss: 0.5522 -------------------------
2023-03-25 14:56:46,443 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 14:56:46,446 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:46,447 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 14:56:50,770 : [INFO]  ------------------------- Batch round 3, loss: 0.5308 -------------------------
2023-03-25 14:56:50,770 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 14:56:50,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:50,776 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 14:56:50,776 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 14:56:52,411 : [INFO]  Batch 23: Training set : loss - 0.5244, accuracy - 0.7772, recall - 0.8913, AUC - 0.9118, F1 - 0.8, precision - 0.7257, training time - -15.0 seconds
2023-03-25 14:56:52,411 : [INFO]  Batch 23: Testing set : loss - 0.5717, accuracy - 0.7157, recall - 0.8922, AUC - 0.8753, F1 - 0.7583, precision - 0.6594
2023-03-25 14:56:52,421 : [INFO]  Batch 24 initialized 
2023-03-25 14:56:52,998 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:56:53,318 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 14:56:59,553 : [INFO]  ------------------------- Batch round 1, loss: 0.585 -------------------------
2023-03-25 14:56:59,553 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 14:56:59,556 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:56:59,558 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 14:57:03,805 : [INFO]  ------------------------- Batch round 2, loss: 0.573 -------------------------
2023-03-25 14:57:03,805 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 14:57:03,808 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:03,811 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 14:57:08,778 : [INFO]  ------------------------- Batch round 3, loss: 0.564 -------------------------
2023-03-25 14:57:08,778 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 14:57:08,784 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:08,788 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 14:57:08,788 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 14:57:10,620 : [INFO]  Batch 24: Training set : loss - 0.5655, accuracy - 0.7609, recall - 0.9348, AUC - 0.8403, F1 - 0.7963, precision - 0.6935, training time - -15.0 seconds
2023-03-25 14:57:10,620 : [INFO]  Batch 24: Testing set : loss - 0.6161, accuracy - 0.6471, recall - 0.8431, AUC - 0.8059, F1 - 0.7049, precision - 0.6056
2023-03-25 14:57:10,626 : [INFO]  Batch 25 initialized 
2023-03-25 14:57:11,458 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:57:11,981 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 14:57:19,994 : [INFO]  ------------------------- Batch round 1, loss: 0.5998 -------------------------
2023-03-25 14:57:19,994 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 14:57:19,999 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:20,003 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 14:57:26,838 : [INFO]  ------------------------- Batch round 2, loss: 0.5746 -------------------------
2023-03-25 14:57:26,838 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 14:57:26,844 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:26,846 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 14:57:32,520 : [INFO]  ------------------------- Batch round 3, loss: 0.5613 -------------------------
2023-03-25 14:57:32,520 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 14:57:32,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:32,532 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 14:57:32,532 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 14:57:34,902 : [INFO]  Batch 25: Training set : loss - 0.5519, accuracy - 0.7446, recall - 0.9022, AUC - 0.8777, F1 - 0.7793, precision - 0.686, training time - -21.0 seconds
2023-03-25 14:57:34,903 : [INFO]  Batch 25: Testing set : loss - 0.5715, accuracy - 0.7206, recall - 0.9314, AUC - 0.8653, F1 - 0.7692, precision - 0.6552
2023-03-25 14:57:34,932 : [INFO]  Batch 26 initialized 
2023-03-25 14:57:36,380 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:57:37,114 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 14:57:47,820 : [INFO]  ------------------------- Batch round 1, loss: 0.5818 -------------------------
2023-03-25 14:57:47,820 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 14:57:47,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:47,830 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 14:57:52,838 : [INFO]  ------------------------- Batch round 2, loss: 0.5529 -------------------------
2023-03-25 14:57:52,838 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 14:57:52,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:52,852 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 14:57:58,802 : [INFO]  ------------------------- Batch round 3, loss: 0.5387 -------------------------
2023-03-25 14:57:58,802 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 14:57:58,808 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:57:58,814 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 14:57:58,814 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 14:58:01,159 : [INFO]  Batch 26: Training set : loss - 0.5416, accuracy - 0.7554, recall - 0.8587, AUC - 0.87, F1 - 0.7783, precision - 0.7117, training time - -22.0 seconds
2023-03-25 14:58:01,160 : [INFO]  Batch 26: Testing set : loss - 0.5962, accuracy - 0.6912, recall - 0.8922, AUC - 0.8173, F1 - 0.7429, precision - 0.6364
2023-03-25 14:58:01,168 : [INFO]  Batch 27 initialized 
2023-03-25 14:58:01,969 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:58:02,641 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 14:58:11,133 : [INFO]  ------------------------- Batch round 1, loss: 0.597 -------------------------
2023-03-25 14:58:11,133 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 14:58:11,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:11,143 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 14:58:17,017 : [INFO]  ------------------------- Batch round 2, loss: 0.5759 -------------------------
2023-03-25 14:58:17,017 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 14:58:17,021 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:17,023 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 14:58:22,684 : [INFO]  ------------------------- Batch round 3, loss: 0.5604 -------------------------
2023-03-25 14:58:22,684 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 14:58:22,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:22,689 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 14:58:22,689 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 14:58:24,800 : [INFO]  Batch 27: Training set : loss - 0.5639, accuracy - 0.7554, recall - 0.9348, AUC - 0.8629, F1 - 0.7926, precision - 0.688, training time - -20.0 seconds
2023-03-25 14:58:24,800 : [INFO]  Batch 27: Testing set : loss - 0.6017, accuracy - 0.6667, recall - 0.8627, AUC - 0.822, F1 - 0.7213, precision - 0.6197
2023-03-25 14:58:24,808 : [INFO]  Batch 28 initialized 
2023-03-25 14:58:25,481 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:58:25,878 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 14:58:33,288 : [INFO]  ------------------------- Batch round 1, loss: 0.5596 -------------------------
2023-03-25 14:58:33,296 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 14:58:33,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:33,307 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 14:58:38,269 : [INFO]  ------------------------- Batch round 2, loss: 0.5391 -------------------------
2023-03-25 14:58:38,270 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 14:58:38,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:38,458 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 14:58:44,375 : [INFO]  ------------------------- Batch round 3, loss: 0.5275 -------------------------
2023-03-25 14:58:44,375 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 14:58:44,378 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:44,382 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 14:58:44,382 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 14:58:45,938 : [INFO]  Batch 28: Training set : loss - 0.5217, accuracy - 0.7717, recall - 0.8913, AUC - 0.8763, F1 - 0.7961, precision - 0.7193, training time - -19.0 seconds
2023-03-25 14:58:45,938 : [INFO]  Batch 28: Testing set : loss - 0.5832, accuracy - 0.6863, recall - 0.8529, AUC - 0.8243, F1 - 0.7311, precision - 0.6397
2023-03-25 14:58:45,948 : [INFO]  Batch 29 initialized 
2023-03-25 14:58:46,955 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:58:47,464 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 14:58:54,892 : [INFO]  ------------------------- Batch round 1, loss: 0.5377 -------------------------
2023-03-25 14:58:54,892 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 14:58:55,112 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:55,115 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 14:58:59,145 : [INFO]  ------------------------- Batch round 2, loss: 0.5221 -------------------------
2023-03-25 14:58:59,146 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 14:58:59,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:58:59,460 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 14:59:04,347 : [INFO]  ------------------------- Batch round 3, loss: 0.519 -------------------------
2023-03-25 14:59:04,347 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 14:59:04,642 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:04,644 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 14:59:04,644 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 14:59:06,819 : [INFO]  Batch 29: Training set : loss - 0.5149, accuracy - 0.8152, recall - 1.0, AUC - 0.9414, F1 - 0.844, precision - 0.7302, training time - -17.0 seconds
2023-03-25 14:59:06,820 : [INFO]  Batch 29: Testing set : loss - 0.5684, accuracy - 0.6961, recall - 0.8824, AUC - 0.8507, F1 - 0.7438, precision - 0.6429
2023-03-25 14:59:06,833 : [INFO]  Batch 30 initialized 
2023-03-25 14:59:07,603 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:59:07,981 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 14:59:15,200 : [INFO]  ------------------------- Batch round 1, loss: 0.5748 -------------------------
2023-03-25 14:59:15,200 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 14:59:15,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:15,851 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 14:59:19,758 : [INFO]  ------------------------- Batch round 2, loss: 0.5454 -------------------------
2023-03-25 14:59:19,758 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 14:59:19,762 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:19,764 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 14:59:23,398 : [INFO]  ------------------------- Batch round 3, loss: 0.5346 -------------------------
2023-03-25 14:59:23,398 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 14:59:23,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:23,403 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 14:59:23,403 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 14:59:24,832 : [INFO]  Batch 30: Training set : loss - 0.5322, accuracy - 0.788, recall - 0.9457, AUC - 0.9031, F1 - 0.8169, precision - 0.719, training time - -15.0 seconds
2023-03-25 14:59:24,832 : [INFO]  Batch 30: Testing set : loss - 0.5548, accuracy - 0.7157, recall - 0.9608, AUC - 0.9199, F1 - 0.7717, precision - 0.6447
2023-03-25 14:59:24,842 : [INFO]  Batch 31 initialized 
2023-03-25 14:59:25,524 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:59:25,876 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 14:59:32,017 : [INFO]  ------------------------- Batch round 1, loss: 0.6142 -------------------------
2023-03-25 14:59:32,018 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 14:59:32,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:32,024 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 14:59:36,224 : [INFO]  ------------------------- Batch round 2, loss: 0.5865 -------------------------
2023-03-25 14:59:36,225 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 14:59:36,229 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:36,231 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 14:59:40,245 : [INFO]  ------------------------- Batch round 3, loss: 0.5685 -------------------------
2023-03-25 14:59:40,245 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 14:59:40,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:40,250 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 14:59:40,250 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 14:59:41,671 : [INFO]  Batch 31: Training set : loss - 0.5694, accuracy - 0.7174, recall - 0.8152, AUC - 0.8334, F1 - 0.7426, precision - 0.6818, training time - -14.0 seconds
2023-03-25 14:59:41,671 : [INFO]  Batch 31: Testing set : loss - 0.5826, accuracy - 0.6961, recall - 0.8529, AUC - 0.8325, F1 - 0.7373, precision - 0.6493
2023-03-25 14:59:41,680 : [INFO]  Batch 32 initialized 
2023-03-25 14:59:42,304 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:59:42,631 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 14:59:48,947 : [INFO]  ------------------------- Batch round 1, loss: 0.5886 -------------------------
2023-03-25 14:59:48,947 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 14:59:48,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:48,952 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 14:59:53,420 : [INFO]  ------------------------- Batch round 2, loss: 0.5737 -------------------------
2023-03-25 14:59:53,420 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 14:59:53,425 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:53,427 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 14:59:58,527 : [INFO]  ------------------------- Batch round 3, loss: 0.5539 -------------------------
2023-03-25 14:59:58,528 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 14:59:58,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:59:58,545 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 14:59:58,546 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 15:00:00,462 : [INFO]  Batch 32: Training set : loss - 0.5489, accuracy - 0.7717, recall - 0.8804, AUC - 0.8785, F1 - 0.7941, precision - 0.7232, training time - -16.0 seconds
2023-03-25 15:00:00,462 : [INFO]  Batch 32: Testing set : loss - 0.5675, accuracy - 0.7255, recall - 0.8824, AUC - 0.8438, F1 - 0.7627, precision - 0.6716
2023-03-25 15:00:00,475 : [INFO]  Batch 33 initialized 
2023-03-25 15:00:01,255 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:00:01,574 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 15:00:07,975 : [INFO]  ------------------------- Batch round 1, loss: 0.5853 -------------------------
2023-03-25 15:00:07,975 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 15:00:07,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:07,980 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 15:00:13,034 : [INFO]  ------------------------- Batch round 2, loss: 0.5704 -------------------------
2023-03-25 15:00:13,034 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 15:00:13,037 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:13,039 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 15:00:17,571 : [INFO]  ------------------------- Batch round 3, loss: 0.5615 -------------------------
2023-03-25 15:00:17,571 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 15:00:17,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:17,578 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 15:00:17,578 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 15:00:19,546 : [INFO]  Batch 33: Training set : loss - 0.5759, accuracy - 0.7446, recall - 0.8913, AUC - 0.8126, F1 - 0.7773, precision - 0.6891, training time - -16.0 seconds
2023-03-25 15:00:19,546 : [INFO]  Batch 33: Testing set : loss - 0.5966, accuracy - 0.6863, recall - 0.8627, AUC - 0.7941, F1 - 0.7333, precision - 0.6377
2023-03-25 15:00:19,557 : [INFO]  Batch 34 initialized 
2023-03-25 15:00:20,300 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:00:20,807 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 15:00:28,828 : [INFO]  ------------------------- Batch round 1, loss: 0.5667 -------------------------
2023-03-25 15:00:28,828 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 15:00:28,842 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:28,849 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 15:00:33,468 : [INFO]  ------------------------- Batch round 2, loss: 0.5548 -------------------------
2023-03-25 15:00:33,468 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 15:00:33,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:33,473 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 15:00:37,697 : [INFO]  ------------------------- Batch round 3, loss: 0.5456 -------------------------
2023-03-25 15:00:37,697 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 15:00:37,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:37,804 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 15:00:37,804 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 15:00:39,517 : [INFO]  Batch 34: Training set : loss - 0.5456, accuracy - 0.75, recall - 0.9457, AUC - 0.9094, F1 - 0.7909, precision - 0.6797, training time - -17.0 seconds
2023-03-25 15:00:39,517 : [INFO]  Batch 34: Testing set : loss - 0.5383, accuracy - 0.7451, recall - 0.9608, AUC - 0.9243, F1 - 0.7903, precision - 0.6712
2023-03-25 15:00:39,530 : [INFO]  Batch 35 initialized 
2023-03-25 15:00:40,114 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:00:40,424 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 15:00:45,994 : [INFO]  ------------------------- Batch round 1, loss: 0.5547 -------------------------
2023-03-25 15:00:45,994 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 15:00:46,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:46,004 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 15:00:50,915 : [INFO]  ------------------------- Batch round 2, loss: 0.5404 -------------------------
2023-03-25 15:00:50,915 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 15:00:50,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:50,922 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 15:00:55,140 : [INFO]  ------------------------- Batch round 3, loss: 0.5394 -------------------------
2023-03-25 15:00:55,140 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 15:00:55,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:00:55,146 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 15:00:55,146 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 15:00:57,032 : [INFO]  Batch 35: Training set : loss - 0.5365, accuracy - 0.7609, recall - 0.9022, AUC - 0.8862, F1 - 0.7905, precision - 0.7034, training time - -15.0 seconds
2023-03-25 15:00:57,032 : [INFO]  Batch 35: Testing set : loss - 0.5797, accuracy - 0.6961, recall - 0.8235, AUC - 0.8048, F1 - 0.7304, precision - 0.6562
2023-03-25 15:00:57,042 : [INFO]  Batch 36 initialized 
2023-03-25 15:00:57,802 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:00:58,252 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 15:01:04,874 : [INFO]  ------------------------- Batch round 1, loss: 0.5528 -------------------------
2023-03-25 15:01:04,874 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 15:01:04,878 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:04,881 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 15:01:09,395 : [INFO]  ------------------------- Batch round 2, loss: 0.544 -------------------------
2023-03-25 15:01:09,395 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 15:01:09,400 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:09,402 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 15:01:13,370 : [INFO]  ------------------------- Batch round 3, loss: 0.5348 -------------------------
2023-03-25 15:01:13,371 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 15:01:13,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:13,379 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 15:01:13,379 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-25 15:01:15,094 : [INFO]  Batch 36: Training set : loss - 0.532, accuracy - 0.7663, recall - 0.9239, AUC - 0.8897, F1 - 0.7981, precision - 0.7025, training time - -15.0 seconds
2023-03-25 15:01:15,094 : [INFO]  Batch 36: Testing set : loss - 0.5588, accuracy - 0.7402, recall - 0.9118, AUC - 0.857, F1 - 0.7782, precision - 0.6788
2023-03-25 15:01:15,107 : [INFO]  Batch 37 initialized 
2023-03-25 15:01:15,771 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:01:16,263 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 15:01:22,985 : [INFO]  ------------------------- Batch round 1, loss: 0.5674 -------------------------
2023-03-25 15:01:22,985 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 15:01:22,989 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:22,991 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 15:01:27,187 : [INFO]  ------------------------- Batch round 2, loss: 0.5415 -------------------------
2023-03-25 15:01:27,187 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 15:01:27,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:27,193 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 15:01:31,205 : [INFO]  ------------------------- Batch round 3, loss: 0.5303 -------------------------
2023-03-25 15:01:31,205 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 15:01:31,208 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:31,210 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 15:01:31,210 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-25 15:01:32,729 : [INFO]  Batch 37: Training set : loss - 0.5321, accuracy - 0.7663, recall - 0.9348, AUC - 0.9187, F1 - 0.8, precision - 0.6992, training time - -15.0 seconds
2023-03-25 15:01:32,729 : [INFO]  Batch 37: Testing set : loss - 0.5933, accuracy - 0.701, recall - 0.8922, AUC - 0.8576, F1 - 0.749, precision - 0.6454
2023-03-25 15:01:32,735 : [INFO]  Batch 38 initialized 
2023-03-25 15:01:33,424 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:01:33,833 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 15:01:42,393 : [INFO]  ------------------------- Batch round 1, loss: 0.6038 -------------------------
2023-03-25 15:01:42,393 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 15:01:42,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:42,398 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 15:01:47,466 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-25 15:01:47,466 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 15:01:47,469 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:47,471 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 15:01:51,817 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-25 15:01:51,817 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 15:01:51,821 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:01:51,823 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 15:01:51,823 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-25 15:01:53,490 : [INFO]  Batch 38: Training set : loss - 0.5658, accuracy - 0.7337, recall - 0.913, AUC - 0.8545, F1 - 0.7742, precision - 0.672, training time - -18.0 seconds
2023-03-25 15:01:53,490 : [INFO]  Batch 38: Testing set : loss - 0.5765, accuracy - 0.6961, recall - 0.902, AUC - 0.8547, F1 - 0.748, precision - 0.6389
2023-03-25 15:01:53,497 : [INFO]  Batch 39 initialized 
2023-03-25 15:01:54,122 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:01:54,588 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 15:02:04,252 : [INFO]  ------------------------- Batch round 1, loss: 0.5542 -------------------------
2023-03-25 15:02:04,253 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 15:02:04,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
