2023-03-25 13:36:32,613 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 13:36:32,613 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 1, epochs 8
2023-03-25 13:36:35,404 : [INFO]  Model initialized for training
2023-03-25 13:36:49,660 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:36:49,778 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:36:49,778 : [INFO]  Connected to the server
2023-03-25 13:36:49,853 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:36:49,853 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:49,860 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:36:49,860 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:37:13,773 : [INFO]  ------------------------- Training round 1, loss: 0.6788 -------------------------
2023-03-25 13:37:13,773 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:37:16,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:37:16,577 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:37:38,878 : [INFO]  ------------------------- Training round 2, loss: 0.6383 -------------------------
2023-03-25 13:37:38,878 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:37:39,034 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:37:39,037 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:38:01,297 : [INFO]  ------------------------- Training round 3, loss: 0.615 -------------------------
2023-03-25 13:38:01,298 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:38:01,540 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:38:01,541 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:38:25,408 : [INFO]  ------------------------- Training round 4, loss: 0.6044 -------------------------
2023-03-25 13:38:25,408 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:38:25,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:38:25,620 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:38:51,074 : [INFO]  ------------------------- Training round 5, loss: 0.6014 -------------------------
2023-03-25 13:38:51,074 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:38:51,362 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:38:51,364 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:39:37,390 : [INFO]  Initially trained model: Training set : loss - 0.6, accuracy - 0.69, recall - 0.87, AUC - 0.82, F1 - 0.74, precision - 0.64, training time - -122.0 seconds
2023-03-25 13:39:37,390 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 13:39:37,405 : [INFO]  Batch 1 initialized 
2023-03-25 13:39:37,984 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:39:38,151 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:39:38,151 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:39:42,645 : [INFO]  ------------------------- Batch round 1, loss: 0.5872 -------------------------
2023-03-25 13:39:42,645 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:39:43,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:43,792 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:39:46,400 : [INFO]  ------------------------- Batch round 2, loss: 0.5721 -------------------------
2023-03-25 13:39:46,401 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:39:46,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:46,584 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:39:49,562 : [INFO]  ------------------------- Batch round 3, loss: 0.5616 -------------------------
2023-03-25 13:39:49,562 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:39:49,797 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:49,799 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:39:49,799 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:39:51,169 : [INFO]  Batch 1: Training set : loss - 0.5591, accuracy - 0.7717, recall - 0.9022, AUC - 0.8657, F1 - 0.7981, precision - 0.7155, training time - -12.0 seconds
2023-03-25 13:39:51,169 : [INFO]  Batch 1: Testing set : loss - 0.5547, accuracy - 0.7549, recall - 0.9118, AUC - 0.8948, F1 - 0.7881, precision - 0.694
2023-03-25 13:39:51,182 : [INFO]  Batch 2 initialized 
2023-03-25 13:39:51,821 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:39:51,991 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:39:58,209 : [INFO]  ------------------------- Batch round 1, loss: 0.5512 -------------------------
2023-03-25 13:39:58,209 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:39:58,212 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:58,215 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:40:02,722 : [INFO]  ------------------------- Batch round 2, loss: 0.5491 -------------------------
2023-03-25 13:40:02,722 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:02,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:02,726 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:40:05,921 : [INFO]  ------------------------- Batch round 3, loss: 0.5398 -------------------------
2023-03-25 13:40:05,921 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:05,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:05,959 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:40:05,959 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:40:07,341 : [INFO]  Batch 2: Training set : loss - 0.534, accuracy - 0.8098, recall - 0.9565, AUC - 0.9064, F1 - 0.8341, precision - 0.7395, training time - -14.0 seconds
2023-03-25 13:40:07,341 : [INFO]  Batch 2: Testing set : loss - 0.5386, accuracy - 0.7598, recall - 0.9314, AUC - 0.9112, F1 - 0.795, precision - 0.6934
2023-03-25 13:40:07,354 : [INFO]  Batch 3 initialized 
2023-03-25 13:40:07,790 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:08,025 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:40:12,947 : [INFO]  ------------------------- Batch round 1, loss: 0.5423 -------------------------
2023-03-25 13:40:12,947 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:12,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:12,952 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:40:16,172 : [INFO]  ------------------------- Batch round 2, loss: 0.5365 -------------------------
2023-03-25 13:40:16,172 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:16,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:16,177 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:40:19,331 : [INFO]  ------------------------- Batch round 3, loss: 0.5315 -------------------------
2023-03-25 13:40:19,332 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:19,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:19,482 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:40:19,482 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:40:20,867 : [INFO]  Batch 3: Training set : loss - 0.5294, accuracy - 0.788, recall - 0.9457, AUC - 0.9201, F1 - 0.8169, precision - 0.719, training time - -11.0 seconds
2023-03-25 13:40:20,867 : [INFO]  Batch 3: Testing set : loss - 0.5574, accuracy - 0.7402, recall - 0.9314, AUC - 0.9158, F1 - 0.7819, precision - 0.6738
2023-03-25 13:40:20,876 : [INFO]  Batch 4 initialized 
2023-03-25 13:40:21,366 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:21,656 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 13:40:26,616 : [INFO]  ------------------------- Batch round 1, loss: 0.5527 -------------------------
2023-03-25 13:40:26,616 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:26,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:26,640 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 13:40:29,524 : [INFO]  ------------------------- Batch round 2, loss: 0.5497 -------------------------
2023-03-25 13:40:29,525 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:29,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:29,603 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 13:40:32,366 : [INFO]  ------------------------- Batch round 3, loss: 0.5381 -------------------------
2023-03-25 13:40:32,366 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:32,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:32,455 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 13:40:32,455 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 13:40:34,049 : [INFO]  Batch 4: Training set : loss - 0.5367, accuracy - 0.7826, recall - 0.913, AUC - 0.9021, F1 - 0.8077, precision - 0.7241, training time - -11.0 seconds
2023-03-25 13:40:34,050 : [INFO]  Batch 4: Testing set : loss - 0.5502, accuracy - 0.7353, recall - 0.9412, AUC - 0.9284, F1 - 0.7805, precision - 0.6667
2023-03-25 13:40:34,063 : [INFO]  Batch 5 initialized 
2023-03-25 13:40:34,558 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:34,803 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 13:40:39,560 : [INFO]  ------------------------- Batch round 1, loss: 0.5406 -------------------------
2023-03-25 13:40:39,560 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:39,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:39,657 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 13:40:42,728 : [INFO]  ------------------------- Batch round 2, loss: 0.5349 -------------------------
2023-03-25 13:40:42,728 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:42,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:42,804 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 13:40:45,569 : [INFO]  ------------------------- Batch round 3, loss: 0.525 -------------------------
2023-03-25 13:40:45,569 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:45,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:45,685 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 13:40:45,685 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 13:40:47,045 : [INFO]  Batch 5: Training set : loss - 0.5303, accuracy - 0.837, recall - 0.9457, AUC - 0.9002, F1 - 0.8529, precision - 0.7768, training time - -11.0 seconds
2023-03-25 13:40:47,046 : [INFO]  Batch 5: Testing set : loss - 0.5272, accuracy - 0.7745, recall - 0.9314, AUC - 0.9099, F1 - 0.8051, precision - 0.709
2023-03-25 13:40:47,056 : [INFO]  Batch 6 initialized 
2023-03-25 13:40:47,507 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:47,758 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 13:40:52,349 : [INFO]  ------------------------- Batch round 1, loss: 0.5419 -------------------------
2023-03-25 13:40:52,349 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:52,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:52,406 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 13:40:55,131 : [INFO]  ------------------------- Batch round 2, loss: 0.5266 -------------------------
2023-03-25 13:40:55,131 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:55,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:55,136 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 13:40:57,910 : [INFO]  ------------------------- Batch round 3, loss: 0.5251 -------------------------
2023-03-25 13:40:57,910 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:57,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:57,915 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 13:40:57,915 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 13:40:59,296 : [INFO]  Batch 6: Training set : loss - 0.5161, accuracy - 0.8207, recall - 0.9565, AUC - 0.9144, F1 - 0.8421, precision - 0.7521, training time - -10.0 seconds
2023-03-25 13:40:59,296 : [INFO]  Batch 6: Testing set : loss - 0.5621, accuracy - 0.6961, recall - 0.902, AUC - 0.8865, F1 - 0.748, precision - 0.6389
2023-03-25 13:40:59,306 : [INFO]  Batch 7 initialized 
2023-03-25 13:40:59,770 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:00,026 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 13:41:04,607 : [INFO]  ------------------------- Batch round 1, loss: 0.5418 -------------------------
2023-03-25 13:41:04,607 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:04,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:04,938 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 13:41:07,700 : [INFO]  ------------------------- Batch round 2, loss: 0.5336 -------------------------
2023-03-25 13:41:07,701 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:07,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:07,760 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 13:41:10,542 : [INFO]  ------------------------- Batch round 3, loss: 0.5295 -------------------------
2023-03-25 13:41:10,542 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:10,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:10,584 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 13:41:10,584 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 13:41:11,894 : [INFO]  Batch 7: Training set : loss - 0.5243, accuracy - 0.8152, recall - 0.9348, AUC - 0.9018, F1 - 0.835, precision - 0.7544, training time - -11.0 seconds
2023-03-25 13:41:11,894 : [INFO]  Batch 7: Testing set : loss - 0.5812, accuracy - 0.7059, recall - 0.8922, AUC - 0.8433, F1 - 0.7521, precision - 0.65
2023-03-25 13:41:11,901 : [INFO]  Batch 8 initialized 
2023-03-25 13:41:12,357 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:12,591 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 13:41:17,097 : [INFO]  ------------------------- Batch round 1, loss: 0.5656 -------------------------
2023-03-25 13:41:17,097 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:17,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:17,163 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 13:41:19,955 : [INFO]  ------------------------- Batch round 2, loss: 0.5573 -------------------------
2023-03-25 13:41:19,955 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:19,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:19,966 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 13:41:22,762 : [INFO]  ------------------------- Batch round 3, loss: 0.5516 -------------------------
2023-03-25 13:41:22,762 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:22,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:22,785 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 13:41:22,785 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 13:41:24,133 : [INFO]  Batch 8: Training set : loss - 0.5506, accuracy - 0.7391, recall - 0.9565, AUC - 0.9019, F1 - 0.7857, precision - 0.6667, training time - -10.0 seconds
2023-03-25 13:41:24,133 : [INFO]  Batch 8: Testing set : loss - 0.5783, accuracy - 0.7108, recall - 0.9118, AUC - 0.8577, F1 - 0.7592, precision - 0.6503
2023-03-25 13:41:24,146 : [INFO]  Batch 9 initialized 
2023-03-25 13:41:24,565 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:24,813 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 13:41:29,490 : [INFO]  ------------------------- Batch round 1, loss: 0.5851 -------------------------
2023-03-25 13:41:29,490 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:29,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:29,494 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 13:41:32,357 : [INFO]  ------------------------- Batch round 2, loss: 0.5735 -------------------------
2023-03-25 13:41:32,357 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:32,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:32,362 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 13:41:35,319 : [INFO]  ------------------------- Batch round 3, loss: 0.5557 -------------------------
2023-03-25 13:41:35,319 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:35,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:35,324 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 13:41:35,324 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 13:41:36,659 : [INFO]  Batch 9: Training set : loss - 0.5653, accuracy - 0.7446, recall - 0.9022, AUC - 0.8674, F1 - 0.7793, precision - 0.686, training time - -11.0 seconds
2023-03-25 13:41:36,660 : [INFO]  Batch 9: Testing set : loss - 0.6117, accuracy - 0.6765, recall - 0.8333, AUC - 0.802, F1 - 0.7203, precision - 0.6343
2023-03-25 13:41:36,666 : [INFO]  Batch 10 initialized 
2023-03-25 13:41:37,101 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:37,356 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 13:41:41,899 : [INFO]  ------------------------- Batch round 1, loss: 0.5592 -------------------------
2023-03-25 13:41:41,899 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:41,903 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:41,905 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 13:41:44,766 : [INFO]  ------------------------- Batch round 2, loss: 0.5422 -------------------------
2023-03-25 13:41:44,767 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:44,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:44,771 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 13:41:47,598 : [INFO]  ------------------------- Batch round 3, loss: 0.5344 -------------------------
2023-03-25 13:41:47,598 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:47,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:47,603 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 13:41:47,603 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 13:41:48,913 : [INFO]  Batch 10: Training set : loss - 0.5282, accuracy - 0.7935, recall - 0.9348, AUC - 0.8762, F1 - 0.819, precision - 0.7288, training time - -10.0 seconds
2023-03-25 13:41:48,913 : [INFO]  Batch 10: Testing set : loss - 0.5694, accuracy - 0.7255, recall - 0.8922, AUC - 0.8649, F1 - 0.7647, precision - 0.6691
2023-03-25 13:41:48,924 : [INFO]  Batch 11 initialized 
2023-03-25 13:41:49,358 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:49,615 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 13:41:54,217 : [INFO]  ------------------------- Batch round 1, loss: 0.5754 -------------------------
2023-03-25 13:41:54,217 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:54,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:54,233 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 13:41:56,989 : [INFO]  ------------------------- Batch round 2, loss: 0.5603 -------------------------
2023-03-25 13:41:56,989 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:57,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:57,087 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 13:41:59,820 : [INFO]  ------------------------- Batch round 3, loss: 0.5649 -------------------------
2023-03-25 13:41:59,820 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:59,866 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:59,869 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 13:41:59,869 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 13:42:01,167 : [INFO]  Batch 11: Training set : loss - 0.5574, accuracy - 0.7446, recall - 0.913, AUC - 0.8718, F1 - 0.7814, precision - 0.6829, training time - -10.0 seconds
2023-03-25 13:42:01,167 : [INFO]  Batch 11: Testing set : loss - 0.5739, accuracy - 0.7304, recall - 0.9314, AUC - 0.8665, F1 - 0.7755, precision - 0.6643
2023-03-25 13:42:01,180 : [INFO]  Batch 12 initialized 
2023-03-25 13:42:01,618 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:01,877 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 13:42:06,866 : [INFO]  ------------------------- Batch round 1, loss: 0.5633 -------------------------
2023-03-25 13:42:06,866 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:07,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:07,046 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 13:42:09,893 : [INFO]  ------------------------- Batch round 2, loss: 0.5492 -------------------------
2023-03-25 13:42:09,893 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:10,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:10,366 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 13:42:13,077 : [INFO]  ------------------------- Batch round 3, loss: 0.5426 -------------------------
2023-03-25 13:42:13,078 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:13,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:13,258 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 13:42:13,258 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 13:42:14,580 : [INFO]  Batch 12: Training set : loss - 0.5502, accuracy - 0.7609, recall - 0.8804, AUC - 0.868, F1 - 0.7864, precision - 0.7105, training time - -11.0 seconds
2023-03-25 13:42:14,580 : [INFO]  Batch 12: Testing set : loss - 0.577, accuracy - 0.6961, recall - 0.8627, AUC - 0.8442, F1 - 0.7395, precision - 0.6471
2023-03-25 13:42:14,593 : [INFO]  Batch 13 initialized 
2023-03-25 13:42:15,069 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:15,319 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 13:42:19,988 : [INFO]  ------------------------- Batch round 1, loss: 0.544 -------------------------
2023-03-25 13:42:19,988 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:20,000 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:20,003 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 13:42:23,098 : [INFO]  ------------------------- Batch round 2, loss: 0.5326 -------------------------
2023-03-25 13:42:23,098 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:23,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:23,105 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 13:42:25,914 : [INFO]  ------------------------- Batch round 3, loss: 0.5282 -------------------------
2023-03-25 13:42:25,914 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:26,002 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:26,004 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 13:42:26,004 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 13:42:27,392 : [INFO]  Batch 13: Training set : loss - 0.5225, accuracy - 0.8207, recall - 0.9457, AUC - 0.921, F1 - 0.8406, precision - 0.7565, training time - -11.0 seconds
2023-03-25 13:42:27,392 : [INFO]  Batch 13: Testing set : loss - 0.5635, accuracy - 0.6912, recall - 0.8824, AUC - 0.8903, F1 - 0.7407, precision - 0.6383
2023-03-25 13:42:27,404 : [INFO]  Batch 14 initialized 
2023-03-25 13:42:27,908 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:28,192 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 13:42:32,890 : [INFO]  ------------------------- Batch round 1, loss: 0.5277 -------------------------
2023-03-25 13:42:32,890 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:32,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:32,942 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 13:42:35,747 : [INFO]  ------------------------- Batch round 2, loss: 0.5264 -------------------------
2023-03-25 13:42:35,747 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:35,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:35,833 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 13:42:38,784 : [INFO]  ------------------------- Batch round 3, loss: 0.5204 -------------------------
2023-03-25 13:42:38,784 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:38,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:38,792 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 13:42:38,792 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 13:42:40,231 : [INFO]  Batch 14: Training set : loss - 0.5189, accuracy - 0.7717, recall - 0.9457, AUC - 0.9041, F1 - 0.8056, precision - 0.7016, training time - -11.0 seconds
2023-03-25 13:42:40,232 : [INFO]  Batch 14: Testing set : loss - 0.5595, accuracy - 0.7255, recall - 0.902, AUC - 0.8639, F1 - 0.7667, precision - 0.6667
2023-03-25 13:42:40,245 : [INFO]  Batch 15 initialized 
2023-03-25 13:42:40,732 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:40,986 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 13:42:46,121 : [INFO]  ------------------------- Batch round 1, loss: 0.5851 -------------------------
2023-03-25 13:42:46,121 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:46,125 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:46,127 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 13:42:49,620 : [INFO]  ------------------------- Batch round 2, loss: 0.5741 -------------------------
2023-03-25 13:42:49,620 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:49,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:49,625 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 13:42:52,686 : [INFO]  ------------------------- Batch round 3, loss: 0.5704 -------------------------
2023-03-25 13:42:52,686 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:52,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:52,916 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 13:42:52,916 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 13:42:54,408 : [INFO]  Batch 15: Training set : loss - 0.5662, accuracy - 0.7337, recall - 0.9239, AUC - 0.8601, F1 - 0.7763, precision - 0.6693, training time - -12.0 seconds
2023-03-25 13:42:54,408 : [INFO]  Batch 15: Testing set : loss - 0.5646, accuracy - 0.7304, recall - 0.9412, AUC - 0.8897, F1 - 0.7773, precision - 0.6621
2023-03-25 13:42:54,422 : [INFO]  Batch 16 initialized 
2023-03-25 13:42:54,859 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:55,134 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 13:43:00,294 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 13:43:00,294 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:00,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:00,298 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 13:43:03,225 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-25 13:43:03,225 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:03,229 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:03,232 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 13:43:06,057 : [INFO]  ------------------------- Batch round 3, loss: 0.5578 -------------------------
2023-03-25 13:43:06,058 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:06,061 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:06,062 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 13:43:06,062 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 13:43:07,371 : [INFO]  Batch 16: Training set : loss - 0.5548, accuracy - 0.7663, recall - 0.8913, AUC - 0.8383, F1 - 0.7923, precision - 0.713, training time - -11.0 seconds
2023-03-25 13:43:07,371 : [INFO]  Batch 16: Testing set : loss - 0.5541, accuracy - 0.7157, recall - 0.8529, AUC - 0.8721, F1 - 0.75, precision - 0.6692
2023-03-25 13:43:07,382 : [INFO]  Batch 17 initialized 
2023-03-25 13:43:07,833 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:08,116 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 13:43:12,626 : [INFO]  ------------------------- Batch round 1, loss: 0.5412 -------------------------
2023-03-25 13:43:12,626 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:12,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:12,888 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 13:43:15,660 : [INFO]  ------------------------- Batch round 2, loss: 0.5273 -------------------------
2023-03-25 13:43:15,660 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:15,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:15,666 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 13:43:18,433 : [INFO]  ------------------------- Batch round 3, loss: 0.5139 -------------------------
2023-03-25 13:43:18,433 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:18,436 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:18,437 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 13:43:18,438 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 13:43:19,754 : [INFO]  Batch 17: Training set : loss - 0.521, accuracy - 0.7772, recall - 0.9457, AUC - 0.9193, F1 - 0.8093, precision - 0.7073, training time - -10.0 seconds
2023-03-25 13:43:19,754 : [INFO]  Batch 17: Testing set : loss - 0.5681, accuracy - 0.7304, recall - 0.9706, AUC - 0.9204, F1 - 0.7826, precision - 0.6556
2023-03-25 13:43:19,759 : [INFO]  Batch 18 initialized 
2023-03-25 13:43:20,203 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:20,480 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 13:43:25,293 : [INFO]  ------------------------- Batch round 1, loss: 0.5662 -------------------------
2023-03-25 13:43:25,293 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:25,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:25,297 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 13:43:28,228 : [INFO]  ------------------------- Batch round 2, loss: 0.5588 -------------------------
2023-03-25 13:43:28,228 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:28,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:28,233 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 13:43:31,128 : [INFO]  ------------------------- Batch round 3, loss: 0.5466 -------------------------
2023-03-25 13:43:31,129 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:31,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:31,133 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 13:43:31,133 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 13:43:32,483 : [INFO]  Batch 18: Training set : loss - 0.5486, accuracy - 0.7717, recall - 0.9022, AUC - 0.8622, F1 - 0.7981, precision - 0.7155, training time - -11.0 seconds
2023-03-25 13:43:32,483 : [INFO]  Batch 18: Testing set : loss - 0.6133, accuracy - 0.6765, recall - 0.7451, AUC - 0.7593, F1 - 0.6972, precision - 0.6552
2023-03-25 13:43:32,488 : [INFO]  Batch 19 initialized 
2023-03-25 13:43:32,919 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:33,191 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 13:43:38,128 : [INFO]  ------------------------- Batch round 1, loss: 0.577 -------------------------
2023-03-25 13:43:38,128 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:38,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:38,133 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 13:43:41,001 : [INFO]  ------------------------- Batch round 2, loss: 0.5614 -------------------------
2023-03-25 13:43:41,001 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:41,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:41,006 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 13:43:43,798 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 13:43:43,798 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:43,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:43,804 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 13:43:43,804 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 13:43:45,125 : [INFO]  Batch 19: Training set : loss - 0.5483, accuracy - 0.7772, recall - 0.9457, AUC - 0.8784, F1 - 0.8093, precision - 0.7073, training time - -11.0 seconds
2023-03-25 13:43:45,125 : [INFO]  Batch 19: Testing set : loss - 0.6114, accuracy - 0.652, recall - 0.8725, AUC - 0.8324, F1 - 0.7149, precision - 0.6054
2023-03-25 13:43:45,134 : [INFO]  Batch 20 initialized 
2023-03-25 13:43:45,561 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:45,847 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 13:43:50,547 : [INFO]  ------------------------- Batch round 1, loss: 0.5778 -------------------------
2023-03-25 13:43:50,547 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:50,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:50,552 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 13:43:53,451 : [INFO]  ------------------------- Batch round 2, loss: 0.5624 -------------------------
2023-03-25 13:43:53,451 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:53,454 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:53,456 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 13:43:56,391 : [INFO]  ------------------------- Batch round 3, loss: 0.5624 -------------------------
2023-03-25 13:43:56,391 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:56,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:56,396 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 13:43:56,396 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 13:43:57,771 : [INFO]  Batch 20: Training set : loss - 0.5567, accuracy - 0.7446, recall - 0.8913, AUC - 0.8612, F1 - 0.7773, precision - 0.6891, training time - -11.0 seconds
2023-03-25 13:43:57,772 : [INFO]  Batch 20: Testing set : loss - 0.5865, accuracy - 0.6912, recall - 0.9314, AUC - 0.8631, F1 - 0.751, precision - 0.6291
2023-03-25 13:43:57,795 : [INFO]  Batch 21 initialized 
2023-03-25 13:43:58,236 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:58,519 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 13:44:04,394 : [INFO]  ------------------------- Batch round 1, loss: 0.6014 -------------------------
2023-03-25 13:44:04,394 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:04,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:04,510 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 13:44:07,500 : [INFO]  ------------------------- Batch round 2, loss: 0.591 -------------------------
2023-03-25 13:44:07,500 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:07,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:07,505 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 13:44:10,450 : [INFO]  ------------------------- Batch round 3, loss: 0.5881 -------------------------
2023-03-25 13:44:10,450 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:10,454 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:10,456 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 13:44:10,456 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 13:44:11,988 : [INFO]  Batch 21: Training set : loss - 0.5921, accuracy - 0.7065, recall - 0.9022, AUC - 0.8313, F1 - 0.7545, precision - 0.6484, training time - -12.0 seconds
2023-03-25 13:44:11,988 : [INFO]  Batch 21: Testing set : loss - 0.5615, accuracy - 0.7304, recall - 0.951, AUC - 0.8994, F1 - 0.7791, precision - 0.6599
2023-03-25 13:44:11,994 : [INFO]  Batch 22 initialized 
2023-03-25 13:44:12,462 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:12,727 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 13:44:17,415 : [INFO]  ------------------------- Batch round 1, loss: 0.6076 -------------------------
2023-03-25 13:44:17,415 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:17,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:17,424 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 13:44:21,655 : [INFO]  ------------------------- Batch round 2, loss: 0.5913 -------------------------
2023-03-25 13:44:21,656 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:21,711 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:21,713 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 13:44:24,700 : [INFO]  ------------------------- Batch round 3, loss: 0.5812 -------------------------
2023-03-25 13:44:24,700 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:24,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:24,911 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 13:44:24,911 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 13:44:26,335 : [INFO]  Batch 22: Training set : loss - 0.5801, accuracy - 0.7174, recall - 0.8587, AUC - 0.8425, F1 - 0.7524, precision - 0.6695, training time - -12.0 seconds
2023-03-25 13:44:26,335 : [INFO]  Batch 22: Testing set : loss - 0.5829, accuracy - 0.6863, recall - 0.8333, AUC - 0.8289, F1 - 0.7265, precision - 0.6439
2023-03-25 13:44:26,346 : [INFO]  Batch 23 initialized 
2023-03-25 13:44:26,775 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:27,050 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 13:44:32,424 : [INFO]  ------------------------- Batch round 1, loss: 0.6008 -------------------------
2023-03-25 13:44:32,424 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:32,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:32,429 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 13:44:35,378 : [INFO]  ------------------------- Batch round 2, loss: 0.5839 -------------------------
2023-03-25 13:44:35,378 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:35,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:35,525 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 13:44:39,722 : [INFO]  ------------------------- Batch round 3, loss: 0.5702 -------------------------
2023-03-25 13:44:39,722 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:39,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:39,726 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 13:44:39,726 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 13:44:41,080 : [INFO]  Batch 23: Training set : loss - 0.5672, accuracy - 0.7228, recall - 0.837, AUC - 0.829, F1 - 0.7512, precision - 0.6814, training time - -13.0 seconds
2023-03-25 13:44:41,080 : [INFO]  Batch 23: Testing set : loss - 0.6151, accuracy - 0.6618, recall - 0.8039, AUC - 0.7745, F1 - 0.7039, precision - 0.626
2023-03-25 13:44:41,092 : [INFO]  Batch 24 initialized 
2023-03-25 13:44:41,526 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:41,807 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 13:44:47,033 : [INFO]  ------------------------- Batch round 1, loss: 0.5795 -------------------------
2023-03-25 13:44:47,033 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:47,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:47,061 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 13:44:50,021 : [INFO]  ------------------------- Batch round 2, loss: 0.5698 -------------------------
2023-03-25 13:44:50,021 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:50,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:50,103 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 13:44:54,239 : [INFO]  ------------------------- Batch round 3, loss: 0.5595 -------------------------
2023-03-25 13:44:54,239 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:54,242 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:54,244 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 13:44:54,244 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 13:44:56,001 : [INFO]  Batch 24: Training set : loss - 0.5574, accuracy - 0.7337, recall - 0.8696, AUC - 0.8476, F1 - 0.7656, precision - 0.6838, training time - -12.0 seconds
2023-03-25 13:44:56,001 : [INFO]  Batch 24: Testing set : loss - 0.572, accuracy - 0.7451, recall - 0.8725, AUC - 0.8333, F1 - 0.7739, precision - 0.6953
2023-03-25 13:44:56,012 : [INFO]  Batch 25 initialized 
2023-03-25 13:44:56,919 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:57,243 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 13:45:01,909 : [INFO]  ------------------------- Batch round 1, loss: 0.6068 -------------------------
2023-03-25 13:45:01,909 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:02,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:02,383 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 13:45:05,236 : [INFO]  ------------------------- Batch round 2, loss: 0.5799 -------------------------
2023-03-25 13:45:05,236 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:05,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:05,421 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 13:45:08,536 : [INFO]  ------------------------- Batch round 3, loss: 0.5707 -------------------------
2023-03-25 13:45:08,536 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:08,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:08,711 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 13:45:08,711 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 13:45:10,019 : [INFO]  Batch 25: Training set : loss - 0.5732, accuracy - 0.7065, recall - 0.8913, AUC - 0.8571, F1 - 0.7523, precision - 0.6508, training time - -11.0 seconds
2023-03-25 13:45:10,020 : [INFO]  Batch 25: Testing set : loss - 0.6203, accuracy - 0.6225, recall - 0.8235, AUC - 0.8011, F1 - 0.6857, precision - 0.5874
2023-03-25 13:45:10,034 : [INFO]  Batch 26 initialized 
2023-03-25 13:45:10,478 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:10,776 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 13:45:16,499 : [INFO]  ------------------------- Batch round 1, loss: 0.5511 -------------------------
2023-03-25 13:45:16,499 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:16,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:16,759 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 13:45:19,653 : [INFO]  ------------------------- Batch round 2, loss: 0.5449 -------------------------
2023-03-25 13:45:19,653 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:19,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:19,830 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 13:45:22,563 : [INFO]  ------------------------- Batch round 3, loss: 0.5425 -------------------------
2023-03-25 13:45:22,564 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:22,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:22,705 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 13:45:22,705 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 13:45:24,145 : [INFO]  Batch 26: Training set : loss - 0.544, accuracy - 0.7391, recall - 0.913, AUC - 0.8857, F1 - 0.7778, precision - 0.6774, training time - -12.0 seconds
2023-03-25 13:45:24,146 : [INFO]  Batch 26: Testing set : loss - 0.5372, accuracy - 0.7451, recall - 0.9412, AUC - 0.921, F1 - 0.7869, precision - 0.6761
2023-03-25 13:45:24,163 : [INFO]  Batch 27 initialized 
2023-03-25 13:45:24,677 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:25,051 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 13:45:30,176 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-25 13:45:30,176 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:30,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:30,218 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 13:45:34,010 : [INFO]  ------------------------- Batch round 2, loss: 0.5448 -------------------------
2023-03-25 13:45:34,010 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:34,063 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:34,066 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 13:45:37,532 : [INFO]  ------------------------- Batch round 3, loss: 0.5357 -------------------------
2023-03-25 13:45:37,532 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:37,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:37,698 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 13:45:37,699 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 13:45:39,072 : [INFO]  Batch 27: Training set : loss - 0.5231, accuracy - 0.788, recall - 0.9674, AUC - 0.8965, F1 - 0.8203, precision - 0.712, training time - -13.0 seconds
2023-03-25 13:45:39,072 : [INFO]  Batch 27: Testing set : loss - 0.6148, accuracy - 0.6569, recall - 0.8137, AUC - 0.7873, F1 - 0.7034, precision - 0.6194
2023-03-25 13:45:39,081 : [INFO]  Batch 28 initialized 
2023-03-25 13:45:39,517 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:39,826 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 13:45:45,688 : [INFO]  ------------------------- Batch round 1, loss: 0.5917 -------------------------
2023-03-25 13:45:45,688 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:45,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:45,693 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 13:45:48,963 : [INFO]  ------------------------- Batch round 2, loss: 0.5683 -------------------------
2023-03-25 13:45:48,963 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:48,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:48,969 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 13:45:52,198 : [INFO]  ------------------------- Batch round 3, loss: 0.565 -------------------------
2023-03-25 13:45:52,198 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:52,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:52,289 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 13:45:52,289 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 13:45:53,758 : [INFO]  Batch 28: Training set : loss - 0.552, accuracy - 0.7717, recall - 0.8913, AUC - 0.8526, F1 - 0.7961, precision - 0.7193, training time - -12.0 seconds
2023-03-25 13:45:53,758 : [INFO]  Batch 28: Testing set : loss - 0.6162, accuracy - 0.6618, recall - 0.8529, AUC - 0.8027, F1 - 0.716, precision - 0.617
2023-03-25 13:45:53,769 : [INFO]  Batch 29 initialized 
2023-03-25 13:45:54,625 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:55,057 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 13:46:01,089 : [INFO]  ------------------------- Batch round 1, loss: 0.5751 -------------------------
2023-03-25 13:46:01,090 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:01,093 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:01,095 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 13:46:04,285 : [INFO]  ------------------------- Batch round 2, loss: 0.5618 -------------------------
2023-03-25 13:46:04,285 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:04,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:04,290 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 13:46:07,574 : [INFO]  ------------------------- Batch round 3, loss: 0.5522 -------------------------
2023-03-25 13:46:07,574 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:07,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:07,581 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 13:46:07,581 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 13:46:09,177 : [INFO]  Batch 29: Training set : loss - 0.5518, accuracy - 0.7446, recall - 0.913, AUC - 0.8905, F1 - 0.7814, precision - 0.6829, training time - -13.0 seconds
2023-03-25 13:46:09,177 : [INFO]  Batch 29: Testing set : loss - 0.5605, accuracy - 0.7549, recall - 0.9118, AUC - 0.8715, F1 - 0.7881, precision - 0.694
2023-03-25 13:46:09,183 : [INFO]  Batch 30 initialized 
2023-03-25 13:46:09,625 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:09,902 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 13:46:14,879 : [INFO]  ------------------------- Batch round 1, loss: 0.5841 -------------------------
2023-03-25 13:46:14,880 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:14,883 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:14,885 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 13:46:17,748 : [INFO]  ------------------------- Batch round 2, loss: 0.5727 -------------------------
2023-03-25 13:46:17,748 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:18,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:18,088 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 13:46:20,991 : [INFO]  ------------------------- Batch round 3, loss: 0.5723 -------------------------
2023-03-25 13:46:20,991 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:20,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:20,997 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 13:46:20,997 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 13:46:22,682 : [INFO]  Batch 30: Training set : loss - 0.5715, accuracy - 0.7228, recall - 0.8587, AUC - 0.8062, F1 - 0.756, precision - 0.6752, training time - -11.0 seconds
2023-03-25 13:46:22,683 : [INFO]  Batch 30: Testing set : loss - 0.6011, accuracy - 0.6716, recall - 0.8725, AUC - 0.8242, F1 - 0.7265, precision - 0.6224
2023-03-25 13:46:22,695 : [INFO]  Batch 31 initialized 
2023-03-25 13:46:23,154 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:23,508 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 13:46:28,307 : [INFO]  ------------------------- Batch round 1, loss: 0.5647 -------------------------
2023-03-25 13:46:28,307 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:28,453 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:28,457 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 13:46:31,935 : [INFO]  ------------------------- Batch round 2, loss: 0.5466 -------------------------
2023-03-25 13:46:31,935 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:32,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:32,080 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 13:46:35,099 : [INFO]  ------------------------- Batch round 3, loss: 0.5392 -------------------------
2023-03-25 13:46:35,099 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:35,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:35,104 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 13:46:35,104 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 13:46:36,418 : [INFO]  Batch 31: Training set : loss - 0.5266, accuracy - 0.8152, recall - 0.9022, AUC - 0.9091, F1 - 0.83, precision - 0.7685, training time - -12.0 seconds
2023-03-25 13:46:36,418 : [INFO]  Batch 31: Testing set : loss - 0.5873, accuracy - 0.701, recall - 0.8529, AUC - 0.8063, F1 - 0.7404, precision - 0.6541
2023-03-25 13:46:36,430 : [INFO]  Batch 32 initialized 
2023-03-25 13:46:36,878 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:37,188 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 13:46:42,659 : [INFO]  ------------------------- Batch round 1, loss: 0.5822 -------------------------
2023-03-25 13:46:42,659 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:42,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:42,957 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 13:46:46,421 : [INFO]  ------------------------- Batch round 2, loss: 0.5612 -------------------------
2023-03-25 13:46:46,421 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:46,492 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:46,496 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 13:46:49,608 : [INFO]  ------------------------- Batch round 3, loss: 0.5484 -------------------------
2023-03-25 13:46:49,608 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:50,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:50,005 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 13:46:50,005 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 13:46:51,248 : [INFO]  Batch 32: Training set : loss - 0.5475, accuracy - 0.788, recall - 0.9348, AUC - 0.8497, F1 - 0.8152, precision - 0.7227, training time - -13.0 seconds
2023-03-25 13:46:51,249 : [INFO]  Batch 32: Testing set : loss - 0.5702, accuracy - 0.6814, recall - 0.8922, AUC - 0.8735, F1 - 0.7368, precision - 0.6276
2023-03-25 13:46:51,254 : [INFO]  Batch 33 initialized 
2023-03-25 13:46:51,688 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:51,985 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 13:46:56,471 : [INFO]  ------------------------- Batch round 1, loss: 0.5592 -------------------------
2023-03-25 13:46:56,471 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:56,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:56,676 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 13:46:59,293 : [INFO]  ------------------------- Batch round 2, loss: 0.5575 -------------------------
2023-03-25 13:46:59,293 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:59,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:59,514 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 13:47:02,102 : [INFO]  ------------------------- Batch round 3, loss: 0.5489 -------------------------
2023-03-25 13:47:02,103 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:02,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:02,256 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 13:47:02,256 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 13:47:03,595 : [INFO]  Batch 33: Training set : loss - 0.5633, accuracy - 0.7337, recall - 0.9891, AUC - 0.9103, F1 - 0.7879, precision - 0.6547, training time - -10.0 seconds
2023-03-25 13:47:03,595 : [INFO]  Batch 33: Testing set : loss - 0.5781, accuracy - 0.7206, recall - 0.9804, AUC - 0.9022, F1 - 0.7782, precision - 0.6452
2023-03-25 13:47:03,607 : [INFO]  Batch 34 initialized 
2023-03-25 13:47:04,030 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:04,333 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 13:47:08,881 : [INFO]  ------------------------- Batch round 1, loss: 0.5558 -------------------------
2023-03-25 13:47:08,881 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:08,884 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:08,886 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 13:47:11,680 : [INFO]  ------------------------- Batch round 2, loss: 0.5528 -------------------------
2023-03-25 13:47:11,680 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:11,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:11,685 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 13:47:14,457 : [INFO]  ------------------------- Batch round 3, loss: 0.5517 -------------------------
2023-03-25 13:47:14,457 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:14,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:14,462 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 13:47:14,462 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 13:47:15,779 : [INFO]  Batch 34: Training set : loss - 0.545, accuracy - 0.7717, recall - 0.9457, AUC - 0.8807, F1 - 0.8056, precision - 0.7016, training time - -10.0 seconds
2023-03-25 13:47:15,780 : [INFO]  Batch 34: Testing set : loss - 0.5526, accuracy - 0.7598, recall - 0.9216, AUC - 0.8882, F1 - 0.7932, precision - 0.6963
2023-03-25 13:47:15,788 : [INFO]  Batch 35 initialized 
2023-03-25 13:47:16,224 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:16,526 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 13:47:21,031 : [INFO]  ------------------------- Batch round 1, loss: 0.5509 -------------------------
2023-03-25 13:47:21,031 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:21,089 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:21,092 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 13:47:24,438 : [INFO]  ------------------------- Batch round 2, loss: 0.5493 -------------------------
2023-03-25 13:47:24,438 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:24,506 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:24,508 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 13:47:27,464 : [INFO]  ------------------------- Batch round 3, loss: 0.5425 -------------------------
2023-03-25 13:47:27,464 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:27,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:27,519 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 13:47:27,519 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 13:47:28,849 : [INFO]  Batch 35: Training set : loss - 0.5358, accuracy - 0.7826, recall - 0.9022, AUC - 0.8941, F1 - 0.8058, precision - 0.7281, training time - -11.0 seconds
2023-03-25 13:47:28,849 : [INFO]  Batch 35: Testing set : loss - 0.5636, accuracy - 0.7451, recall - 0.9412, AUC - 0.8922, F1 - 0.7869, precision - 0.6761
2023-03-25 13:47:28,858 : [INFO]  Batch 36 initialized 
2023-03-25 13:47:29,293 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:29,608 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 13:47:34,166 : [INFO]  ------------------------- Batch round 1, loss: 0.5656 -------------------------
2023-03-25 13:47:34,166 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:34,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:34,172 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 13:47:36,994 : [INFO]  ------------------------- Batch round 2, loss: 0.5632 -------------------------
2023-03-25 13:47:36,994 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:37,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:37,017 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 13:47:40,017 : [INFO]  ------------------------- Batch round 3, loss: 0.5591 -------------------------
2023-03-25 13:47:40,017 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:40,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:40,022 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 13:47:40,022 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-25 13:47:41,319 : [INFO]  Batch 36: Training set : loss - 0.5681, accuracy - 0.7446, recall - 0.9348, AUC - 0.8897, F1 - 0.7854, precision - 0.6772, training time - -10.0 seconds
2023-03-25 13:47:41,319 : [INFO]  Batch 36: Testing set : loss - 0.564, accuracy - 0.7255, recall - 0.9608, AUC - 0.9158, F1 - 0.7778, precision - 0.6533
2023-03-25 13:47:41,325 : [INFO]  Batch 37 initialized 
2023-03-25 13:47:41,755 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:42,072 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 13:47:46,617 : [INFO]  ------------------------- Batch round 1, loss: 0.575 -------------------------
2023-03-25 13:47:46,617 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:46,620 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:46,622 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 13:47:49,487 : [INFO]  ------------------------- Batch round 2, loss: 0.5672 -------------------------
2023-03-25 13:47:49,487 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:49,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:49,494 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 13:47:52,269 : [INFO]  ------------------------- Batch round 3, loss: 0.5643 -------------------------
2023-03-25 13:47:52,269 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:52,305 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:52,307 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 13:47:52,308 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-25 13:47:53,609 : [INFO]  Batch 37: Training set : loss - 0.5659, accuracy - 0.7391, recall - 0.9348, AUC - 0.8495, F1 - 0.7818, precision - 0.6719, training time - -10.0 seconds
2023-03-25 13:47:53,609 : [INFO]  Batch 37: Testing set : loss - 0.5597, accuracy - 0.7549, recall - 0.8922, AUC - 0.8557, F1 - 0.7845, precision - 0.7
2023-03-25 13:47:53,616 : [INFO]  Batch 38 initialized 
2023-03-25 13:47:54,048 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:54,368 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 13:47:59,151 : [INFO]  ------------------------- Batch round 1, loss: 0.5766 -------------------------
2023-03-25 13:47:59,151 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:59,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:59,156 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 13:48:01,943 : [INFO]  ------------------------- Batch round 2, loss: 0.5631 -------------------------
2023-03-25 13:48:01,943 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:02,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:02,053 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 13:48:04,829 : [INFO]  ------------------------- Batch round 3, loss: 0.557 -------------------------
2023-03-25 13:48:04,829 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:04,904 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:04,906 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 13:48:04,906 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-25 13:48:06,223 : [INFO]  Batch 38: Training set : loss - 0.551, accuracy - 0.7609, recall - 0.9022, AUC - 0.8812, F1 - 0.7905, precision - 0.7034, training time - -11.0 seconds
2023-03-25 13:48:06,223 : [INFO]  Batch 38: Testing set : loss - 0.5753, accuracy - 0.7108, recall - 0.9216, AUC - 0.9025, F1 - 0.7611, precision - 0.6483
2023-03-25 13:48:06,236 : [INFO]  Batch 39 initialized 
2023-03-25 13:48:06,667 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:06,974 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 13:48:11,431 : [INFO]  ------------------------- Batch round 1, loss: 0.5605 -------------------------
2023-03-25 13:48:11,431 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:11,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:11,544 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 13:48:14,212 : [INFO]  ------------------------- Batch round 2, loss: 0.5496 -------------------------
2023-03-25 13:48:14,212 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:14,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:14,280 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 13:48:16,950 : [INFO]  ------------------------- Batch round 3, loss: 0.5505 -------------------------
2023-03-25 13:48:16,951 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:16,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:16,977 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 13:48:16,977 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-25 13:48:18,265 : [INFO]  Batch 39: Training set : loss - 0.5488, accuracy - 0.7826, recall - 0.9565, AUC - 0.8763, F1 - 0.8148, precision - 0.7097, training time - -10.0 seconds
2023-03-25 13:48:18,265 : [INFO]  Batch 39: Testing set : loss - 0.5247, accuracy - 0.8088, recall - 0.9804, AUC - 0.9235, F1 - 0.8368, precision - 0.7299
2023-03-25 13:48:18,277 : [INFO]  Batch 40 initialized 
2023-03-25 13:48:18,701 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:19,018 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 13:48:23,566 : [INFO]  ------------------------- Batch round 1, loss: 0.5574 -------------------------
2023-03-25 13:48:23,567 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:23,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:23,997 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 13:48:26,758 : [INFO]  ------------------------- Batch round 2, loss: 0.5477 -------------------------
2023-03-25 13:48:26,758 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:26,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:26,909 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 13:48:29,962 : [INFO]  ------------------------- Batch round 3, loss: 0.532 -------------------------
2023-03-25 13:48:29,963 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:29,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:29,967 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 13:48:29,967 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-25 13:48:31,257 : [INFO]  Batch 40: Training set : loss - 0.5302, accuracy - 0.7935, recall - 0.9348, AUC - 0.9094, F1 - 0.819, precision - 0.7288, training time - -11.0 seconds
2023-03-25 13:48:31,257 : [INFO]  Batch 40: Testing set : loss - 0.5935, accuracy - 0.6422, recall - 0.8627, AUC - 0.831, F1 - 0.7068, precision - 0.5986
2023-03-25 13:48:31,270 : [INFO]  Batch 41 initialized 
2023-03-25 13:48:31,714 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:32,026 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 13:48:36,618 : [INFO]  ------------------------- Batch round 1, loss: 0.5508 -------------------------
2023-03-25 13:48:36,618 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:36,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:36,637 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 13:48:39,431 : [INFO]  ------------------------- Batch round 2, loss: 0.545 -------------------------
2023-03-25 13:48:39,431 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:39,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:39,489 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 13:48:42,324 : [INFO]  ------------------------- Batch round 3, loss: 0.5416 -------------------------
2023-03-25 13:48:42,324 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:42,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:42,334 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 13:48:42,334 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-25 13:48:43,655 : [INFO]  Batch 41: Training set : loss - 0.5388, accuracy - 0.75, recall - 0.9239, AUC - 0.8968, F1 - 0.787, precision - 0.6855, training time - -10.0 seconds
2023-03-25 13:48:43,655 : [INFO]  Batch 41: Testing set : loss - 0.5728, accuracy - 0.701, recall - 0.9216, AUC - 0.8521, F1 - 0.755, precision - 0.6395
2023-03-25 13:48:43,668 : [INFO]  Batch 42 initialized 
2023-03-25 13:48:44,103 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:44,426 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 13:48:48,853 : [INFO]  ------------------------- Batch round 1, loss: 0.5417 -------------------------
2023-03-25 13:48:48,854 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:49,016 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:49,018 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 13:48:51,642 : [INFO]  ------------------------- Batch round 2, loss: 0.5365 -------------------------
2023-03-25 13:48:51,642 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:51,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:51,796 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 13:48:54,469 : [INFO]  ------------------------- Batch round 3, loss: 0.5332 -------------------------
2023-03-25 13:48:54,469 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:54,606 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:54,608 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 13:48:54,608 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-25 13:48:55,889 : [INFO]  Batch 42: Training set : loss - 0.5218, accuracy - 0.7989, recall - 0.913, AUC - 0.8888, F1 - 0.8195, precision - 0.7434, training time - -10.0 seconds
2023-03-25 13:48:55,889 : [INFO]  Batch 42: Testing set : loss - 0.5444, accuracy - 0.7598, recall - 0.9216, AUC - 0.8829, F1 - 0.7932, precision - 0.6963
2023-03-25 13:48:55,902 : [INFO]  Batch 43 initialized 
2023-03-25 13:48:56,348 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:56,665 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 13:49:01,152 : [INFO]  ------------------------- Batch round 1, loss: 0.581 -------------------------
2023-03-25 13:49:01,152 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:01,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:01,235 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 13:49:03,955 : [INFO]  ------------------------- Batch round 2, loss: 0.5708 -------------------------
2023-03-25 13:49:03,955 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:04,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:04,109 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 13:49:06,771 : [INFO]  ------------------------- Batch round 3, loss: 0.5637 -------------------------
2023-03-25 13:49:06,771 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:06,845 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:06,847 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 13:49:06,847 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-25 13:49:08,104 : [INFO]  Batch 43: Training set : loss - 0.5535, accuracy - 0.788, recall - 0.8804, AUC - 0.843, F1 - 0.806, precision - 0.7431, training time - -10.0 seconds
2023-03-25 13:49:08,104 : [INFO]  Batch 43: Testing set : loss - 0.5461, accuracy - 0.7598, recall - 0.9314, AUC - 0.8859, F1 - 0.795, precision - 0.6934
2023-03-25 13:49:08,148 : [INFO]  Batch 44 initialized 
2023-03-25 13:49:08,577 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:08,903 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 13:49:13,689 : [INFO]  ------------------------- Batch round 1, loss: 0.5294 -------------------------
2023-03-25 13:49:13,689 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:13,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:13,693 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 13:49:16,426 : [INFO]  ------------------------- Batch round 2, loss: 0.5209 -------------------------
2023-03-25 13:49:16,426 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:16,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:16,496 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 13:49:19,402 : [INFO]  ------------------------- Batch round 3, loss: 0.5207 -------------------------
2023-03-25 13:49:19,402 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:19,405 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:19,406 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 13:49:19,406 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-25 13:49:20,695 : [INFO]  Batch 44: Training set : loss - 0.5143, accuracy - 0.788, recall - 0.9239, AUC - 0.8993, F1 - 0.8134, precision - 0.7265, training time - -11.0 seconds
2023-03-25 13:49:20,695 : [INFO]  Batch 44: Testing set : loss - 0.5607, accuracy - 0.6912, recall - 0.9118, AUC - 0.8866, F1 - 0.747, precision - 0.6327
2023-03-25 13:49:20,706 : [INFO]  Batch 45 initialized 
2023-03-25 13:49:21,139 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:21,472 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 13:49:26,004 : [INFO]  ------------------------- Batch round 1, loss: 0.5359 -------------------------
2023-03-25 13:49:26,004 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:26,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:26,197 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 13:49:29,142 : [INFO]  ------------------------- Batch round 2, loss: 0.5266 -------------------------
2023-03-25 13:49:29,142 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:29,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:29,374 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 13:49:31,927 : [INFO]  ------------------------- Batch round 3, loss: 0.5123 -------------------------
2023-03-25 13:49:31,928 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:32,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:32,344 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 13:49:32,344 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-25 13:49:33,601 : [INFO]  Batch 45: Training set : loss - 0.5165, accuracy - 0.8043, recall - 0.9674, AUC - 0.9334, F1 - 0.8318, precision - 0.7295, training time - -11.0 seconds
2023-03-25 13:49:33,601 : [INFO]  Batch 45: Testing set : loss - 0.5498, accuracy - 0.7402, recall - 0.9412, AUC - 0.9148, F1 - 0.7837, precision - 0.6713
2023-03-25 13:49:33,614 : [INFO]  Batch 46 initialized 
2023-03-25 13:49:34,048 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:34,373 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 13:49:38,914 : [INFO]  ------------------------- Batch round 1, loss: 0.5613 -------------------------
2023-03-25 13:49:38,914 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:38,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:38,995 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 13:49:41,825 : [INFO]  ------------------------- Batch round 2, loss: 0.5514 -------------------------
2023-03-25 13:49:41,825 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:41,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:41,834 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 13:49:44,672 : [INFO]  ------------------------- Batch round 3, loss: 0.5437 -------------------------
2023-03-25 13:49:44,672 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:44,711 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:44,713 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 13:49:44,714 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-25 13:49:46,009 : [INFO]  Batch 46: Training set : loss - 0.55, accuracy - 0.75, recall - 0.8587, AUC - 0.8522, F1 - 0.7745, precision - 0.7054, training time - -10.0 seconds
2023-03-25 13:49:46,009 : [INFO]  Batch 46: Testing set : loss - 0.6014, accuracy - 0.6569, recall - 0.8431, AUC - 0.8403, F1 - 0.7107, precision - 0.6143
2023-03-25 13:49:46,021 : [INFO]  Batch 47 initialized 
2023-03-25 13:49:46,502 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:46,824 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 13:49:51,611 : [INFO]  ------------------------- Batch round 1, loss: 0.5701 -------------------------
2023-03-25 13:49:51,611 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:51,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:51,630 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 13:49:54,378 : [INFO]  ------------------------- Batch round 2, loss: 0.5718 -------------------------
2023-03-25 13:49:54,378 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:54,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:54,396 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 13:49:57,182 : [INFO]  ------------------------- Batch round 3, loss: 0.5673 -------------------------
2023-03-25 13:49:57,183 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:57,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:57,233 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 13:49:57,233 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-25 13:49:58,551 : [INFO]  Batch 47: Training set : loss - 0.5746, accuracy - 0.7065, recall - 0.9348, AUC - 0.8289, F1 - 0.7611, precision - 0.6418, training time - -10.0 seconds
2023-03-25 13:49:58,551 : [INFO]  Batch 47: Testing set : loss - 0.5839, accuracy - 0.7157, recall - 0.8725, AUC - 0.8061, F1 - 0.7542, precision - 0.6642
2023-03-25 13:49:58,560 : [INFO]  Batch 48 initialized 
2023-03-25 13:49:58,988 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:59,336 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 13:50:03,965 : [INFO]  ------------------------- Batch round 1, loss: 0.5622 -------------------------
2023-03-25 13:50:03,965 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:03,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:03,969 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 13:50:06,847 : [INFO]  ------------------------- Batch round 2, loss: 0.5414 -------------------------
2023-03-25 13:50:06,847 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:06,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:06,852 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 13:50:09,649 : [INFO]  ------------------------- Batch round 3, loss: 0.5306 -------------------------
2023-03-25 13:50:09,649 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:09,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:09,654 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 13:50:09,654 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-25 13:50:10,963 : [INFO]  Batch 48: Training set : loss - 0.5218, accuracy - 0.788, recall - 0.9674, AUC - 0.895, F1 - 0.8203, precision - 0.712, training time - -10.0 seconds
2023-03-25 13:50:10,963 : [INFO]  Batch 48: Testing set : loss - 0.5527, accuracy - 0.7206, recall - 0.9216, AUC - 0.8959, F1 - 0.7673, precision - 0.6573
2023-03-25 13:50:10,969 : [INFO]  Batch 49 initialized 
2023-03-25 13:50:11,393 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:11,732 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 13:50:18,302 : [INFO]  ------------------------- Batch round 1, loss: 0.5947 -------------------------
2023-03-25 13:50:18,302 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:18,305 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:18,307 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 13:50:23,179 : [INFO]  ------------------------- Batch round 2, loss: 0.5799 -------------------------
2023-03-25 13:50:23,179 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:23,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:23,298 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 13:50:27,878 : [INFO]  ------------------------- Batch round 3, loss: 0.5684 -------------------------
2023-03-25 13:50:27,879 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:27,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:27,890 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 13:50:27,890 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-25 13:50:30,412 : [INFO]  Batch 49: Training set : loss - 0.5739, accuracy - 0.7228, recall - 0.8913, AUC - 0.8591, F1 - 0.7628, precision - 0.6667, training time - -16.0 seconds
2023-03-25 13:50:30,412 : [INFO]  Batch 49: Testing set : loss - 0.6091, accuracy - 0.6765, recall - 0.8431, AUC - 0.7956, F1 - 0.7227, precision - 0.6324
2023-03-25 13:50:30,422 : [INFO]  Batch 50 initialized 
2023-03-25 13:50:31,380 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:31,800 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 13:50:37,667 : [INFO]  ------------------------- Batch round 1, loss: 0.5497 -------------------------
2023-03-25 13:50:37,667 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:37,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:37,672 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 13:50:40,511 : [INFO]  ------------------------- Batch round 2, loss: 0.5392 -------------------------
2023-03-25 13:50:40,511 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:40,514 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:40,516 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 13:50:43,363 : [INFO]  ------------------------- Batch round 3, loss: 0.5392 -------------------------
2023-03-25 13:50:43,363 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:43,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:43,368 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 13:50:43,368 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-25 13:50:44,747 : [INFO]  Batch 50: Training set : loss - 0.5322, accuracy - 0.8098, recall - 0.9348, AUC - 0.8853, F1 - 0.8309, precision - 0.7478, training time - -12.0 seconds
2023-03-25 13:50:44,747 : [INFO]  Batch 50: Testing set : loss - 0.5603, accuracy - 0.7353, recall - 0.9216, AUC - 0.8793, F1 - 0.7769, precision - 0.6714
2023-03-25 13:50:44,755 : [INFO]  Batch 51 initialized 
2023-03-25 13:50:45,221 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:45,575 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 13:50:50,296 : [INFO]  ------------------------- Batch round 1, loss: 0.5591 -------------------------
2023-03-25 13:50:50,296 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:50,313 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:50,315 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 13:50:53,179 : [INFO]  ------------------------- Batch round 2, loss: 0.5453 -------------------------
2023-03-25 13:50:53,179 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:53,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:53,207 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 13:50:56,465 : [INFO]  ------------------------- Batch round 3, loss: 0.5382 -------------------------
2023-03-25 13:50:56,466 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:56,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:56,486 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 13:50:56,486 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-25 13:50:57,692 : [INFO]  Batch 51: Training set : loss - 0.5371, accuracy - 0.75, recall - 0.9348, AUC - 0.9044, F1 - 0.789, precision - 0.6825, training time - -11.0 seconds
2023-03-25 13:50:57,692 : [INFO]  Batch 51: Testing set : loss - 0.572, accuracy - 0.7059, recall - 0.8922, AUC - 0.8795, F1 - 0.7521, precision - 0.65
2023-03-25 13:50:57,704 : [INFO]  Batch 52 initialized 
2023-03-25 13:50:58,190 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:58,534 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 13:51:03,367 : [INFO]  ------------------------- Batch round 1, loss: 0.5741 -------------------------
2023-03-25 13:51:03,367 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:03,370 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:03,372 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 13:51:06,325 : [INFO]  ------------------------- Batch round 2, loss: 0.5638 -------------------------
2023-03-25 13:51:06,325 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:06,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:06,591 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 13:51:09,809 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 13:51:09,810 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:09,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:09,820 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 13:51:09,820 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-25 13:51:11,224 : [INFO]  Batch 52: Training set : loss - 0.5537, accuracy - 0.7391, recall - 0.837, AUC - 0.8426, F1 - 0.7624, precision - 0.7, training time - -11.0 seconds
2023-03-25 13:51:11,224 : [INFO]  Batch 52: Testing set : loss - 0.5847, accuracy - 0.6961, recall - 0.9118, AUC - 0.8453, F1 - 0.75, precision - 0.637
2023-03-25 13:51:11,233 : [INFO]  Batch 53 initialized 
2023-03-25 13:51:11,718 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:12,067 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 13:51:16,714 : [INFO]  ------------------------- Batch round 1, loss: 0.5581 -------------------------
2023-03-25 13:51:16,714 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:16,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:16,767 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 13:51:19,663 : [INFO]  ------------------------- Batch round 2, loss: 0.5482 -------------------------
2023-03-25 13:51:19,663 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:19,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:19,729 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 13:51:22,502 : [INFO]  ------------------------- Batch round 3, loss: 0.5386 -------------------------
2023-03-25 13:51:22,502 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:22,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:22,596 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 13:51:22,596 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-25 13:51:23,909 : [INFO]  Batch 53: Training set : loss - 0.5441, accuracy - 0.7717, recall - 0.9457, AUC - 0.8987, F1 - 0.8056, precision - 0.7016, training time - -11.0 seconds
2023-03-25 13:51:23,909 : [INFO]  Batch 53: Testing set : loss - 0.5595, accuracy - 0.7157, recall - 0.902, AUC - 0.8707, F1 - 0.7603, precision - 0.6571
2023-03-25 13:51:23,921 : [INFO]  Batch 54 initialized 
2023-03-25 13:51:24,377 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:24,734 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 13:51:29,345 : [INFO]  ------------------------- Batch round 1, loss: 0.5263 -------------------------
2023-03-25 13:51:29,345 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:29,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:29,493 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 13:51:32,189 : [INFO]  ------------------------- Batch round 2, loss: 0.5187 -------------------------
2023-03-25 13:51:32,189 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:32,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:32,355 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 13:51:35,357 : [INFO]  ------------------------- Batch round 3, loss: 0.5107 -------------------------
2023-03-25 13:51:35,357 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:35,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:35,362 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 13:51:35,362 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-25 13:51:36,632 : [INFO]  Batch 54: Training set : loss - 0.5108, accuracy - 0.8152, recall - 0.9783, AUC - 0.932, F1 - 0.8411, precision - 0.7377, training time - -11.0 seconds
2023-03-25 13:51:36,633 : [INFO]  Batch 54: Testing set : loss - 0.5658, accuracy - 0.7108, recall - 0.9412, AUC - 0.9034, F1 - 0.7649, precision - 0.6443
2023-03-25 13:51:36,646 : [INFO]  Batch 55 initialized 
2023-03-25 13:51:37,109 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:37,456 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 13:51:42,024 : [INFO]  ------------------------- Batch round 1, loss: 0.5886 -------------------------
2023-03-25 13:51:42,024 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:42,146 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:42,148 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 13:51:45,142 : [INFO]  ------------------------- Batch round 2, loss: 0.5675 -------------------------
2023-03-25 13:51:45,142 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:45,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:45,147 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 13:51:47,825 : [INFO]  ------------------------- Batch round 3, loss: 0.5497 -------------------------
2023-03-25 13:51:47,825 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:47,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:47,952 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 13:51:47,952 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-25 13:51:49,244 : [INFO]  Batch 55: Training set : loss - 0.5577, accuracy - 0.7337, recall - 0.9022, AUC - 0.8694, F1 - 0.7721, precision - 0.6748, training time - -10.0 seconds
2023-03-25 13:51:49,244 : [INFO]  Batch 55: Testing set : loss - 0.573, accuracy - 0.7108, recall - 0.9412, AUC - 0.8812, F1 - 0.7649, precision - 0.6443
2023-03-25 13:51:49,256 : [INFO]  Batch 56 initialized 
2023-03-25 13:51:49,691 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:50,043 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 13:51:54,622 : [INFO]  ------------------------- Batch round 1, loss: 0.5821 -------------------------
2023-03-25 13:51:54,622 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:54,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:54,627 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 13:51:57,556 : [INFO]  ------------------------- Batch round 2, loss: 0.575 -------------------------
2023-03-25 13:51:57,556 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:57,559 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:57,561 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 13:52:00,377 : [INFO]  ------------------------- Batch round 3, loss: 0.5666 -------------------------
2023-03-25 13:52:00,378 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:00,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:00,382 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 13:52:00,382 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-25 13:52:01,733 : [INFO]  Batch 56: Training set : loss - 0.5566, accuracy - 0.7174, recall - 0.8478, AUC - 0.8556, F1 - 0.75, precision - 0.6724, training time - -10.0 seconds
2023-03-25 13:52:01,733 : [INFO]  Batch 56: Testing set : loss - 0.5845, accuracy - 0.6716, recall - 0.8333, AUC - 0.823, F1 - 0.7173, precision - 0.6296
2023-03-25 13:52:01,739 : [INFO]  Batch 57 initialized 
2023-03-25 13:52:02,165 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:02,529 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 13:52:08,164 : [INFO]  ------------------------- Batch round 1, loss: 0.5892 -------------------------
2023-03-25 13:52:08,164 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:08,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:08,174 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 13:52:12,411 : [INFO]  ------------------------- Batch round 2, loss: 0.5786 -------------------------
2023-03-25 13:52:12,411 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:12,417 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:12,419 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 13:52:16,381 : [INFO]  ------------------------- Batch round 3, loss: 0.568 -------------------------
2023-03-25 13:52:16,381 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:16,386 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:16,388 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 13:52:16,388 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-25 13:52:18,084 : [INFO]  Batch 57: Training set : loss - 0.5638, accuracy - 0.75, recall - 0.9022, AUC - 0.846, F1 - 0.783, precision - 0.6917, training time - -14.0 seconds
2023-03-25 13:52:18,084 : [INFO]  Batch 57: Testing set : loss - 0.5941, accuracy - 0.701, recall - 0.8627, AUC - 0.8285, F1 - 0.7426, precision - 0.6519
2023-03-25 13:52:18,091 : [INFO]  Batch 58 initialized 
2023-03-25 13:52:18,563 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:19,136 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 13:52:25,318 : [INFO]  ------------------------- Batch round 1, loss: 0.5607 -------------------------
2023-03-25 13:52:25,318 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:25,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:25,330 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 13:52:28,952 : [INFO]  ------------------------- Batch round 2, loss: 0.5472 -------------------------
2023-03-25 13:52:28,952 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:28,956 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:28,960 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 13:52:32,524 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-25 13:52:32,524 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:32,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:32,530 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 13:52:32,530 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-25 13:52:34,065 : [INFO]  Batch 58: Training set : loss - 0.537, accuracy - 0.7935, recall - 0.9457, AUC - 0.8865, F1 - 0.8208, precision - 0.725, training time - -13.0 seconds
2023-03-25 13:52:34,065 : [INFO]  Batch 58: Testing set : loss - 0.5894, accuracy - 0.6814, recall - 0.8627, AUC - 0.8203, F1 - 0.7303, precision - 0.6331
2023-03-25 13:52:34,071 : [INFO]  Batch 59 initialized 
2023-03-25 13:52:34,506 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:34,875 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 13:52:39,626 : [INFO]  ------------------------- Batch round 1, loss: 0.5355 -------------------------
2023-03-25 13:52:39,627 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:39,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:39,631 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 13:52:43,125 : [INFO]  ------------------------- Batch round 2, loss: 0.5268 -------------------------
2023-03-25 13:52:43,125 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:43,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:43,138 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 13:52:46,477 : [INFO]  ------------------------- Batch round 3, loss: 0.5145 -------------------------
2023-03-25 13:52:46,477 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:46,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:46,482 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 13:52:46,482 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-25 13:52:48,113 : [INFO]  Batch 59: Training set : loss - 0.5122, accuracy - 0.8207, recall - 0.9457, AUC - 0.9079, F1 - 0.8406, precision - 0.7565, training time - -12.0 seconds
2023-03-25 13:52:48,113 : [INFO]  Batch 59: Testing set : loss - 0.5591, accuracy - 0.7108, recall - 0.8824, AUC - 0.8775, F1 - 0.7531, precision - 0.6569
2023-03-25 13:52:48,128 : [INFO]  Batch 60 initialized 
2023-03-25 13:52:48,625 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:49,018 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 13:52:54,842 : [INFO]  ------------------------- Batch round 1, loss: 0.5349 -------------------------
2023-03-25 13:52:54,842 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:54,952 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:54,954 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 13:52:58,116 : [INFO]  ------------------------- Batch round 2, loss: 0.516 -------------------------
2023-03-25 13:52:58,116 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:58,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:58,139 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 13:53:01,193 : [INFO]  ------------------------- Batch round 3, loss: 0.5142 -------------------------
2023-03-25 13:53:01,194 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:01,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:01,199 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 13:53:01,199 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-25 13:53:02,646 : [INFO]  Batch 60: Training set : loss - 0.5169, accuracy - 0.788, recall - 0.9565, AUC - 0.8843, F1 - 0.8186, precision - 0.7154, training time - -12.0 seconds
2023-03-25 13:53:02,646 : [INFO]  Batch 60: Testing set : loss - 0.5766, accuracy - 0.6961, recall - 0.9412, AUC - 0.8677, F1 - 0.7559, precision - 0.6316
2023-03-25 13:53:02,655 : [INFO]  Batch 61 initialized 
2023-03-25 13:53:03,227 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:03,593 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 13:53:09,414 : [INFO]  ------------------------- Batch round 1, loss: 0.5301 -------------------------
2023-03-25 13:53:09,414 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:09,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:09,590 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 13:53:12,732 : [INFO]  ------------------------- Batch round 2, loss: 0.5149 -------------------------
2023-03-25 13:53:12,732 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:12,860 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:12,863 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 13:53:15,771 : [INFO]  ------------------------- Batch round 3, loss: 0.5051 -------------------------
2023-03-25 13:53:15,771 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:15,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:15,916 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 13:53:15,916 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-25 13:53:17,365 : [INFO]  Batch 61: Training set : loss - 0.5014, accuracy - 0.8098, recall - 1.0, AUC - 0.9328, F1 - 0.8402, precision - 0.7244, training time - -12.0 seconds
2023-03-25 13:53:17,365 : [INFO]  Batch 61: Testing set : loss - 0.5962, accuracy - 0.6863, recall - 0.9118, AUC - 0.838, F1 - 0.744, precision - 0.6284
2023-03-25 13:53:17,378 : [INFO]  Batch 62 initialized 
2023-03-25 13:53:17,921 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:18,354 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 13:53:23,293 : [INFO]  ------------------------- Batch round 1, loss: 0.5747 -------------------------
2023-03-25 13:53:23,293 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:23,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:23,590 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 13:53:26,709 : [INFO]  ------------------------- Batch round 2, loss: 0.5662 -------------------------
2023-03-25 13:53:26,709 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:26,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:26,839 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 13:53:29,935 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 13:53:29,935 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:30,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:30,102 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 13:53:30,102 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-25 13:53:31,399 : [INFO]  Batch 62: Training set : loss - 0.5721, accuracy - 0.712, recall - 0.9348, AUC - 0.8663, F1 - 0.7644, precision - 0.6466, training time - -12.0 seconds
2023-03-25 13:53:31,399 : [INFO]  Batch 62: Testing set : loss - 0.5643, accuracy - 0.7304, recall - 0.9314, AUC - 0.8997, F1 - 0.7755, precision - 0.6643
2023-03-25 13:53:31,405 : [INFO]  Batch 63 initialized 
2023-03-25 13:53:31,848 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:32,188 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 13:53:36,700 : [INFO]  ------------------------- Batch round 1, loss: 0.5297 -------------------------
2023-03-25 13:53:36,701 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:37,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:37,069 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 13:53:40,024 : [INFO]  ------------------------- Batch round 2, loss: 0.5258 -------------------------
2023-03-25 13:53:40,024 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:40,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:40,094 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 13:53:42,863 : [INFO]  ------------------------- Batch round 3, loss: 0.5164 -------------------------
2023-03-25 13:53:42,863 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:43,202 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:43,204 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 13:53:43,204 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-25 13:53:44,492 : [INFO]  Batch 63: Training set : loss - 0.5217, accuracy - 0.75, recall - 0.9348, AUC - 0.9024, F1 - 0.789, precision - 0.6825, training time - -11.0 seconds
2023-03-25 13:53:44,492 : [INFO]  Batch 63: Testing set : loss - 0.5364, accuracy - 0.7745, recall - 0.9314, AUC - 0.903, F1 - 0.8051, precision - 0.709
2023-03-25 13:53:44,506 : [INFO]  Batch 64 initialized 
2023-03-25 13:53:44,967 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:45,351 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 13:53:50,437 : [INFO]  ------------------------- Batch round 1, loss: 0.5449 -------------------------
2023-03-25 13:53:50,438 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:50,441 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:50,443 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 13:53:53,830 : [INFO]  ------------------------- Batch round 2, loss: 0.5391 -------------------------
2023-03-25 13:53:53,830 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:53,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:53,835 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 13:53:56,799 : [INFO]  ------------------------- Batch round 3, loss: 0.5347 -------------------------
2023-03-25 13:53:56,799 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:56,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:56,804 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 13:53:56,805 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-25 13:53:58,405 : [INFO]  Batch 64: Training set : loss - 0.5473, accuracy - 0.7391, recall - 0.8913, AUC - 0.8901, F1 - 0.7736, precision - 0.6833, training time - -11.0 seconds
2023-03-25 13:53:58,405 : [INFO]  Batch 64: Testing set : loss - 0.5576, accuracy - 0.7255, recall - 0.9314, AUC - 0.8888, F1 - 0.7724, precision - 0.6597
2023-03-25 13:53:58,416 : [INFO]  Batch 65 initialized 
2023-03-25 13:53:58,884 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:59,279 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 13:54:03,865 : [INFO]  ------------------------- Batch round 1, loss: 0.5583 -------------------------
2023-03-25 13:54:03,865 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:03,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:03,967 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 13:54:06,653 : [INFO]  ------------------------- Batch round 2, loss: 0.5463 -------------------------
2023-03-25 13:54:06,653 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:06,767 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:06,769 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 13:54:09,650 : [INFO]  ------------------------- Batch round 3, loss: 0.5421 -------------------------
2023-03-25 13:54:09,651 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:09,822 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:09,824 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 13:54:09,824 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-25 13:54:11,484 : [INFO]  Batch 65: Training set : loss - 0.5312, accuracy - 0.788, recall - 0.9348, AUC - 0.8683, F1 - 0.8152, precision - 0.7227, training time - -11.0 seconds
2023-03-25 13:54:11,484 : [INFO]  Batch 65: Testing set : loss - 0.593, accuracy - 0.6814, recall - 0.8922, AUC - 0.8485, F1 - 0.7368, precision - 0.6276
2023-03-25 13:54:11,499 : [INFO]  Batch 66 initialized 
2023-03-25 13:54:11,951 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:12,302 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 13:54:17,313 : [INFO]  ------------------------- Batch round 1, loss: 0.572 -------------------------
2023-03-25 13:54:17,314 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:17,317 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:17,320 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 13:54:20,663 : [INFO]  ------------------------- Batch round 2, loss: 0.5521 -------------------------
2023-03-25 13:54:20,663 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:20,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:20,806 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 13:54:23,925 : [INFO]  ------------------------- Batch round 3, loss: 0.5402 -------------------------
2023-03-25 13:54:23,925 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:23,928 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:23,932 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 13:54:23,932 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-25 13:54:25,580 : [INFO]  Batch 66: Training set : loss - 0.5485, accuracy - 0.7391, recall - 0.9565, AUC - 0.8737, F1 - 0.7857, precision - 0.6667, training time - -12.0 seconds
2023-03-25 13:54:25,580 : [INFO]  Batch 66: Testing set : loss - 0.6034, accuracy - 0.6716, recall - 0.8824, AUC - 0.8014, F1 - 0.7287, precision - 0.6207
2023-03-25 13:54:25,589 : [INFO]  Batch 67 initialized 
2023-03-25 13:54:26,077 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:26,477 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 13:54:31,270 : [INFO]  ------------------------- Batch round 1, loss: 0.5563 -------------------------
2023-03-25 13:54:31,270 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:31,273 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:31,275 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 13:54:34,157 : [INFO]  ------------------------- Batch round 2, loss: 0.5406 -------------------------
2023-03-25 13:54:34,157 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:34,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:34,162 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 13:54:37,117 : [INFO]  ------------------------- Batch round 3, loss: 0.5345 -------------------------
2023-03-25 13:54:37,117 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:37,121 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:37,122 : [INFO]  Batch number 67 model fetched from the server
2023-03-25 13:54:37,123 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-25 13:54:38,499 : [INFO]  Batch 67: Training set : loss - 0.5336, accuracy - 0.7663, recall - 0.9239, AUC - 0.8937, F1 - 0.7981, precision - 0.7025, training time - -11.0 seconds
2023-03-25 13:54:38,500 : [INFO]  Batch 67: Testing set : loss - 0.5987, accuracy - 0.6814, recall - 0.8529, AUC - 0.808, F1 - 0.728, precision - 0.635
2023-03-25 13:54:38,505 : [INFO]  Batch 68 initialized 
2023-03-25 13:54:38,973 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:39,352 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-25 13:54:44,031 : [INFO]  ------------------------- Batch round 1, loss: 0.5455 -------------------------
2023-03-25 13:54:44,032 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:44,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:44,071 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-25 13:54:47,113 : [INFO]  ------------------------- Batch round 2, loss: 0.5401 -------------------------
2023-03-25 13:54:47,113 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:47,178 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:47,180 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-25 13:54:50,322 : [INFO]  ------------------------- Batch round 3, loss: 0.5311 -------------------------
2023-03-25 13:54:50,323 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:50,326 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:50,328 : [INFO]  Batch number 68 model fetched from the server
2023-03-25 13:54:50,328 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-25 13:54:51,713 : [INFO]  Batch 68: Training set : loss - 0.5295, accuracy - 0.7772, recall - 0.9457, AUC - 0.9266, F1 - 0.8093, precision - 0.7073, training time - -11.0 seconds
2023-03-25 13:54:51,713 : [INFO]  Batch 68: Testing set : loss - 0.5794, accuracy - 0.6814, recall - 0.9314, AUC - 0.8833, F1 - 0.7451, precision - 0.6209
2023-03-25 13:54:51,725 : [INFO]  Batch 69 initialized 
2023-03-25 13:54:52,153 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:52,538 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-25 13:54:57,055 : [INFO]  ------------------------- Batch round 1, loss: 0.551 -------------------------
2023-03-25 13:54:57,055 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:57,373 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:57,375 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-25 13:55:00,212 : [INFO]  ------------------------- Batch round 2, loss: 0.5409 -------------------------
2023-03-25 13:55:00,213 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:00,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:00,217 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-25 13:55:03,097 : [INFO]  ------------------------- Batch round 3, loss: 0.5372 -------------------------
2023-03-25 13:55:03,098 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:03,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:03,102 : [INFO]  Batch number 69 model fetched from the server
2023-03-25 13:55:03,103 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-25 13:55:04,412 : [INFO]  Batch 69: Training set : loss - 0.5413, accuracy - 0.7717, recall - 0.9022, AUC - 0.8602, F1 - 0.7981, precision - 0.7155, training time - -11.0 seconds
2023-03-25 13:55:04,412 : [INFO]  Batch 69: Testing set : loss - 0.5617, accuracy - 0.7255, recall - 0.9216, AUC - 0.8845, F1 - 0.7705, precision - 0.662
2023-03-25 13:55:04,421 : [INFO]  Batch 70 initialized 
2023-03-25 13:55:04,840 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:05,139 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-25 13:55:10,055 : [INFO]  ------------------------- Batch round 1, loss: 0.5462 -------------------------
2023-03-25 13:55:10,055 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:10,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:10,383 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-25 13:55:13,297 : [INFO]  ------------------------- Batch round 2, loss: 0.5395 -------------------------
2023-03-25 13:55:13,297 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:13,300 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:13,303 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-25 13:55:16,161 : [INFO]  ------------------------- Batch round 3, loss: 0.5319 -------------------------
2023-03-25 13:55:16,161 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:16,164 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:16,166 : [INFO]  Batch number 70 model fetched from the server
2023-03-25 13:55:16,166 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-25 13:55:17,515 : [INFO]  Batch 70: Training set : loss - 0.5308, accuracy - 0.7772, recall - 0.9565, AUC - 0.8905, F1 - 0.8111, precision - 0.704, training time - -11.0 seconds
2023-03-25 13:55:17,515 : [INFO]  Batch 70: Testing set : loss - 0.582, accuracy - 0.6863, recall - 0.8725, AUC - 0.8342, F1 - 0.7355, precision - 0.6357
2023-03-25 13:55:17,525 : [INFO]  Batch 71 initialized 
2023-03-25 13:55:17,984 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:18,385 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-25 13:55:22,986 : [INFO]  ------------------------- Batch round 1, loss: 0.5674 -------------------------
2023-03-25 13:55:22,986 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:23,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:23,028 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-25 13:55:25,755 : [INFO]  ------------------------- Batch round 2, loss: 0.5467 -------------------------
2023-03-25 13:55:25,755 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:25,811 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:25,813 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-25 13:55:28,614 : [INFO]  ------------------------- Batch round 3, loss: 0.535 -------------------------
2023-03-25 13:55:28,614 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:28,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:28,712 : [INFO]  Batch number 71 model fetched from the server
2023-03-25 13:55:28,713 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-25 13:55:30,315 : [INFO]  Batch 71: Training set : loss - 0.5346, accuracy - 0.7717, recall - 0.913, AUC - 0.8781, F1 - 0.8, precision - 0.7119, training time - -10.0 seconds
2023-03-25 13:55:30,316 : [INFO]  Batch 71: Testing set : loss - 0.5636, accuracy - 0.7255, recall - 0.8627, AUC - 0.8591, F1 - 0.7586, precision - 0.6769
2023-03-25 13:55:30,330 : [INFO]  Batch 72 initialized 
2023-03-25 13:55:30,812 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:31,194 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-25 13:55:36,375 : [INFO]  ------------------------- Batch round 1, loss: 0.5609 -------------------------
2023-03-25 13:55:36,375 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:36,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:36,566 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-25 13:55:39,367 : [INFO]  ------------------------- Batch round 2, loss: 0.5478 -------------------------
2023-03-25 13:55:39,367 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:39,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:39,580 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-25 13:55:42,447 : [INFO]  ------------------------- Batch round 3, loss: 0.5388 -------------------------
2023-03-25 13:55:42,447 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:42,708 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:42,710 : [INFO]  Batch number 72 model fetched from the server
2023-03-25 13:55:42,710 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-25 13:55:43,986 : [INFO]  Batch 72: Training set : loss - 0.5497, accuracy - 0.7554, recall - 0.9457, AUC - 0.9003, F1 - 0.7945, precision - 0.685, training time - -12.0 seconds
2023-03-25 13:55:43,986 : [INFO]  Batch 72: Testing set : loss - 0.5738, accuracy - 0.7108, recall - 0.902, AUC - 0.8771, F1 - 0.7572, precision - 0.6525
2023-03-25 13:55:43,999 : [INFO]  Batch 73 initialized 
2023-03-25 13:55:44,447 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:44,825 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-25 13:55:49,883 : [INFO]  ------------------------- Batch round 1, loss: 0.5521 -------------------------
2023-03-25 13:55:49,883 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:49,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:49,969 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-25 13:55:53,263 : [INFO]  ------------------------- Batch round 2, loss: 0.5366 -------------------------
2023-03-25 13:55:53,263 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:53,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:53,269 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-25 13:55:56,428 : [INFO]  ------------------------- Batch round 3, loss: 0.532 -------------------------
2023-03-25 13:55:56,428 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:56,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:56,433 : [INFO]  Batch number 73 model fetched from the server
2023-03-25 13:55:56,433 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-25 13:55:57,740 : [INFO]  Batch 73: Training set : loss - 0.5297, accuracy - 0.788, recall - 0.9348, AUC - 0.9003, F1 - 0.8152, precision - 0.7227, training time - -12.0 seconds
2023-03-25 13:55:57,740 : [INFO]  Batch 73: Testing set : loss - 0.6022, accuracy - 0.6863, recall - 0.902, AUC - 0.8346, F1 - 0.7419, precision - 0.6301
2023-03-25 13:55:57,776 : [INFO]  Batch 74 initialized 
2023-03-25 13:55:58,204 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:58,588 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-25 13:56:03,329 : [INFO]  ------------------------- Batch round 1, loss: 0.5495 -------------------------
2023-03-25 13:56:03,329 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:03,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:03,334 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-25 13:56:06,169 : [INFO]  ------------------------- Batch round 2, loss: 0.5216 -------------------------
2023-03-25 13:56:06,169 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:06,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:06,190 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-25 13:56:09,056 : [INFO]  ------------------------- Batch round 3, loss: 0.5132 -------------------------
2023-03-25 13:56:09,056 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:09,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:09,103 : [INFO]  Batch number 74 model fetched from the server
2023-03-25 13:56:09,103 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-25 13:56:10,580 : [INFO]  Batch 74: Training set : loss - 0.5031, accuracy - 0.8315, recall - 0.9565, AUC - 0.9253, F1 - 0.8502, precision - 0.7652, training time - -11.0 seconds
2023-03-25 13:56:10,580 : [INFO]  Batch 74: Testing set : loss - 0.5563, accuracy - 0.7451, recall - 0.9118, AUC - 0.8992, F1 - 0.7815, precision - 0.6838
2023-03-25 13:56:10,591 : [INFO]  Batch 75 initialized 
2023-03-25 13:56:11,062 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:11,478 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-25 13:56:16,554 : [INFO]  ------------------------- Batch round 1, loss: 0.5859 -------------------------
2023-03-25 13:56:16,554 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:16,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:16,559 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-25 13:56:19,634 : [INFO]  ------------------------- Batch round 2, loss: 0.5705 -------------------------
2023-03-25 13:56:19,634 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:19,639 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:19,641 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-25 13:56:22,650 : [INFO]  ------------------------- Batch round 3, loss: 0.5649 -------------------------
2023-03-25 13:56:22,650 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:22,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:22,656 : [INFO]  Batch number 75 model fetched from the server
2023-03-25 13:56:22,656 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-25 13:56:24,107 : [INFO]  Batch 75: Training set : loss - 0.5639, accuracy - 0.7554, recall - 0.8913, AUC - 0.8494, F1 - 0.7847, precision - 0.7009, training time - -11.0 seconds
2023-03-25 13:56:24,107 : [INFO]  Batch 75: Testing set : loss - 0.6029, accuracy - 0.6961, recall - 0.8627, AUC - 0.8213, F1 - 0.7395, precision - 0.6471
2023-03-25 13:56:24,119 : [INFO]  Batch 76 initialized 
2023-03-25 13:56:24,635 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:25,051 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-25 13:56:30,001 : [INFO]  ------------------------- Batch round 1, loss: 0.6031 -------------------------
2023-03-25 13:56:30,001 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:30,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:30,006 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-25 13:56:32,972 : [INFO]  ------------------------- Batch round 2, loss: 0.5746 -------------------------
2023-03-25 13:56:32,972 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:32,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:32,977 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-25 13:56:35,943 : [INFO]  ------------------------- Batch round 3, loss: 0.5614 -------------------------
2023-03-25 13:56:35,943 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:35,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:35,948 : [INFO]  Batch number 76 model fetched from the server
2023-03-25 13:56:35,948 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-25 13:56:37,337 : [INFO]  Batch 76: Training set : loss - 0.561, accuracy - 0.7554, recall - 0.8913, AUC - 0.8304, F1 - 0.7847, precision - 0.7009, training time - -11.0 seconds
2023-03-25 13:56:37,337 : [INFO]  Batch 76: Testing set : loss - 0.5545, accuracy - 0.7255, recall - 0.902, AUC - 0.8893, F1 - 0.7667, precision - 0.6667
2023-03-25 13:56:37,345 : [INFO]  Batch 77 initialized 
2023-03-25 13:56:37,857 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:38,357 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-25 13:56:43,157 : [INFO]  ------------------------- Batch round 1, loss: 0.5692 -------------------------
2023-03-25 13:56:43,158 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:43,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:43,163 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-25 13:56:46,116 : [INFO]  ------------------------- Batch round 2, loss: 0.5505 -------------------------
2023-03-25 13:56:46,116 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:46,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:46,121 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-25 13:56:49,221 : [INFO]  ------------------------- Batch round 3, loss: 0.5402 -------------------------
2023-03-25 13:56:49,222 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:49,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:49,385 : [INFO]  Batch number 77 model fetched from the server
2023-03-25 13:56:49,386 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-25 13:56:50,973 : [INFO]  Batch 77: Training set : loss - 0.5464, accuracy - 0.7609, recall - 0.913, AUC - 0.8731, F1 - 0.7925, precision - 0.7, training time - -11.0 seconds
2023-03-25 13:56:50,973 : [INFO]  Batch 77: Testing set : loss - 0.5753, accuracy - 0.7157, recall - 0.8039, AUC - 0.8301, F1 - 0.7387, precision - 0.6833
2023-03-25 13:56:50,985 : [INFO]  Batch 78 initialized 
2023-03-25 13:56:51,568 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:52,015 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-25 13:56:56,624 : [INFO]  ------------------------- Batch round 1, loss: 0.5454 -------------------------
2023-03-25 13:56:56,624 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:56,666 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:56,668 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-25 13:56:59,365 : [INFO]  ------------------------- Batch round 2, loss: 0.5367 -------------------------
2023-03-25 13:56:59,365 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:59,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:59,460 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-25 13:57:02,109 : [INFO]  ------------------------- Batch round 3, loss: 0.5314 -------------------------
2023-03-25 13:57:02,109 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:02,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:02,235 : [INFO]  Batch number 78 model fetched from the server
2023-03-25 13:57:02,235 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-25 13:57:03,505 : [INFO]  Batch 78: Training set : loss - 0.5229, accuracy - 0.7663, recall - 0.9348, AUC - 0.8877, F1 - 0.8, precision - 0.6992, training time - -10.0 seconds
2023-03-25 13:57:03,505 : [INFO]  Batch 78: Testing set : loss - 0.5645, accuracy - 0.701, recall - 0.902, AUC - 0.8909, F1 - 0.751, precision - 0.6434
2023-03-25 13:57:03,514 : [INFO]  Batch 79 initialized 
2023-03-25 13:57:03,934 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:04,306 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-25 13:57:08,971 : [INFO]  ------------------------- Batch round 1, loss: 0.5887 -------------------------
2023-03-25 13:57:08,972 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:08,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:08,976 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-25 13:57:12,084 : [INFO]  ------------------------- Batch round 2, loss: 0.5877 -------------------------
2023-03-25 13:57:12,084 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:12,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:12,087 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-25 13:57:14,910 : [INFO]  ------------------------- Batch round 3, loss: 0.5694 -------------------------
2023-03-25 13:57:14,910 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:14,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:14,915 : [INFO]  Batch number 79 model fetched from the server
2023-03-25 13:57:14,915 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-25 13:57:16,353 : [INFO]  Batch 79: Training set : loss - 0.561, accuracy - 0.7228, recall - 0.8696, AUC - 0.8453, F1 - 0.7583, precision - 0.6723, training time - -11.0 seconds
2023-03-25 13:57:16,354 : [INFO]  Batch 79: Testing set : loss - 0.6075, accuracy - 0.6765, recall - 0.8627, AUC - 0.7973, F1 - 0.7273, precision - 0.6286
2023-03-25 13:57:16,363 : [INFO]  Batch 80 initialized 
2023-03-25 13:57:16,809 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:17,198 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-25 13:57:21,667 : [INFO]  ------------------------- Batch round 1, loss: 0.5829 -------------------------
2023-03-25 13:57:21,667 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:21,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:21,798 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-25 13:57:24,581 : [INFO]  ------------------------- Batch round 2, loss: 0.5748 -------------------------
2023-03-25 13:57:24,581 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:24,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:24,661 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-25 13:57:27,481 : [INFO]  ------------------------- Batch round 3, loss: 0.5608 -------------------------
2023-03-25 13:57:27,481 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:27,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:27,582 : [INFO]  Batch number 80 model fetched from the server
2023-03-25 13:57:27,582 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-25 13:57:28,879 : [INFO]  Batch 80: Training set : loss - 0.5721, accuracy - 0.7283, recall - 0.9239, AUC - 0.8316, F1 - 0.7727, precision - 0.6641, training time - -10.0 seconds
2023-03-25 13:57:28,879 : [INFO]  Batch 80: Testing set : loss - 0.5746, accuracy - 0.7255, recall - 0.8725, AUC - 0.8293, F1 - 0.7607, precision - 0.6742
2023-03-25 13:57:28,891 : [INFO]  Batch 81 initialized 
2023-03-25 13:57:29,331 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:29,727 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-25 13:57:34,300 : [INFO]  ------------------------- Batch round 1, loss: 0.5581 -------------------------
2023-03-25 13:57:34,300 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:34,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:34,387 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-25 13:57:37,117 : [INFO]  ------------------------- Batch round 2, loss: 0.5398 -------------------------
2023-03-25 13:57:37,117 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:37,199 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:37,201 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-25 13:57:39,974 : [INFO]  ------------------------- Batch round 3, loss: 0.5355 -------------------------
2023-03-25 13:57:39,974 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:40,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:40,025 : [INFO]  Batch number 81 model fetched from the server
2023-03-25 13:57:40,025 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-25 13:57:41,351 : [INFO]  Batch 81: Training set : loss - 0.5386, accuracy - 0.8098, recall - 0.9457, AUC - 0.8567, F1 - 0.8325, precision - 0.7436, training time - -10.0 seconds
2023-03-25 13:57:41,351 : [INFO]  Batch 81: Testing set : loss - 0.581, accuracy - 0.7059, recall - 0.9608, AUC - 0.885, F1 - 0.7656, precision - 0.6364
2023-03-25 13:57:41,357 : [INFO]  Batch 82 initialized 
2023-03-25 13:57:41,787 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:42,190 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-25 13:57:46,741 : [INFO]  ------------------------- Batch round 1, loss: 0.5549 -------------------------
2023-03-25 13:57:46,741 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:46,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:46,746 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-25 13:57:49,476 : [INFO]  ------------------------- Batch round 2, loss: 0.5522 -------------------------
2023-03-25 13:57:49,477 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:49,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:49,482 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-25 13:57:52,219 : [INFO]  ------------------------- Batch round 3, loss: 0.5389 -------------------------
2023-03-25 13:57:52,219 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:52,257 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:52,259 : [INFO]  Batch number 82 model fetched from the server
2023-03-25 13:57:52,260 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-25 13:57:53,549 : [INFO]  Batch 82: Training set : loss - 0.5352, accuracy - 0.7826, recall - 0.9239, AUC - 0.9018, F1 - 0.8095, precision - 0.7203, training time - -10.0 seconds
2023-03-25 13:57:53,549 : [INFO]  Batch 82: Testing set : loss - 0.5786, accuracy - 0.6961, recall - 0.8725, AUC - 0.852, F1 - 0.7417, precision - 0.6449
2023-03-25 13:57:53,562 : [INFO]  Batch 83 initialized 
2023-03-25 13:57:54,001 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:54,403 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-25 13:57:58,923 : [INFO]  ------------------------- Batch round 1, loss: 0.5411 -------------------------
2023-03-25 13:57:58,923 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:58,969 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:58,971 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-25 13:58:01,738 : [INFO]  ------------------------- Batch round 2, loss: 0.5366 -------------------------
2023-03-25 13:58:01,738 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:01,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:01,743 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-25 13:58:04,508 : [INFO]  ------------------------- Batch round 3, loss: 0.5292 -------------------------
2023-03-25 13:58:04,508 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:04,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:04,585 : [INFO]  Batch number 83 model fetched from the server
2023-03-25 13:58:04,585 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-25 13:58:05,905 : [INFO]  Batch 83: Training set : loss - 0.534, accuracy - 0.7826, recall - 0.913, AUC - 0.8959, F1 - 0.8077, precision - 0.7241, training time - -10.0 seconds
2023-03-25 13:58:05,905 : [INFO]  Batch 83: Testing set : loss - 0.5621, accuracy - 0.7353, recall - 0.9216, AUC - 0.8811, F1 - 0.7769, precision - 0.6714
2023-03-25 13:58:05,915 : [INFO]  Batch 84 initialized 
2023-03-25 13:58:06,346 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:06,750 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-25 13:58:11,162 : [INFO]  ------------------------- Batch round 1, loss: 0.5385 -------------------------
2023-03-25 13:58:11,162 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:11,331 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:11,332 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-25 13:58:13,955 : [INFO]  ------------------------- Batch round 2, loss: 0.5283 -------------------------
2023-03-25 13:58:13,955 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:14,136 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:14,138 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-25 13:58:16,760 : [INFO]  ------------------------- Batch round 3, loss: 0.5248 -------------------------
2023-03-25 13:58:16,760 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:16,899 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:16,901 : [INFO]  Batch number 84 model fetched from the server
2023-03-25 13:58:16,901 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-25 13:58:18,181 : [INFO]  Batch 84: Training set : loss - 0.5338, accuracy - 0.788, recall - 0.9565, AUC - 0.9118, F1 - 0.8186, precision - 0.7154, training time - -10.0 seconds
2023-03-25 13:58:18,182 : [INFO]  Batch 84: Testing set : loss - 0.5738, accuracy - 0.7157, recall - 0.8824, AUC - 0.8558, F1 - 0.7563, precision - 0.6618
2023-03-25 13:58:18,190 : [INFO]  Batch 85 initialized 
2023-03-25 13:58:18,628 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:19,031 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-25 13:58:23,731 : [INFO]  ------------------------- Batch round 1, loss: 0.586 -------------------------
2023-03-25 13:58:23,731 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:23,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:23,736 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-25 13:58:26,396 : [INFO]  ------------------------- Batch round 2, loss: 0.5594 -------------------------
2023-03-25 13:58:26,396 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:26,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:26,401 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-25 13:58:29,131 : [INFO]  ------------------------- Batch round 3, loss: 0.5578 -------------------------
2023-03-25 13:58:29,132 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:29,135 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:29,137 : [INFO]  Batch number 85 model fetched from the server
2023-03-25 13:58:29,137 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-25 13:58:30,418 : [INFO]  Batch 85: Training set : loss - 0.5529, accuracy - 0.7826, recall - 0.8804, AUC - 0.8362, F1 - 0.802, precision - 0.7364, training time - -10.0 seconds
2023-03-25 13:58:30,418 : [INFO]  Batch 85: Testing set : loss - 0.595, accuracy - 0.7206, recall - 0.8137, AUC - 0.8058, F1 - 0.7444, precision - 0.686
2023-03-25 13:58:30,429 : [INFO]  Batch 86 initialized 
2023-03-25 13:58:30,856 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:31,269 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-25 13:58:35,898 : [INFO]  ------------------------- Batch round 1, loss: 0.5867 -------------------------
2023-03-25 13:58:35,898 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:35,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:35,903 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-25 13:58:38,753 : [INFO]  ------------------------- Batch round 2, loss: 0.5785 -------------------------
2023-03-25 13:58:38,753 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:38,756 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:38,759 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-25 13:58:41,565 : [INFO]  ------------------------- Batch round 3, loss: 0.57 -------------------------
2023-03-25 13:58:41,565 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:41,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:41,570 : [INFO]  Batch number 86 model fetched from the server
2023-03-25 13:58:41,570 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-25 13:58:42,887 : [INFO]  Batch 86: Training set : loss - 0.5825, accuracy - 0.7174, recall - 0.8804, AUC - 0.7889, F1 - 0.757, precision - 0.6639, training time - -10.0 seconds
2023-03-25 13:58:42,887 : [INFO]  Batch 86: Testing set : loss - 0.6079, accuracy - 0.6814, recall - 0.9216, AUC - 0.797, F1 - 0.7431, precision - 0.6225
2023-03-25 13:58:42,894 : [INFO]  Batch 87 initialized 
2023-03-25 13:58:43,325 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:43,740 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-25 13:58:48,182 : [INFO]  ------------------------- Batch round 1, loss: 0.5772 -------------------------
2023-03-25 13:58:48,182 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:48,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:48,198 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-25 13:58:50,918 : [INFO]  ------------------------- Batch round 2, loss: 0.5607 -------------------------
2023-03-25 13:58:50,919 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:50,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:50,923 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-25 13:58:53,601 : [INFO]  ------------------------- Batch round 3, loss: 0.5561 -------------------------
2023-03-25 13:58:53,601 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:53,604 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:53,606 : [INFO]  Batch number 87 model fetched from the server
2023-03-25 13:58:53,606 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-25 13:58:54,894 : [INFO]  Batch 87: Training set : loss - 0.5511, accuracy - 0.7446, recall - 0.9022, AUC - 0.8549, F1 - 0.7793, precision - 0.686, training time - -10.0 seconds
2023-03-25 13:58:54,894 : [INFO]  Batch 87: Testing set : loss - 0.568, accuracy - 0.6667, recall - 0.8627, AUC - 0.8614, F1 - 0.7213, precision - 0.6197
2023-03-25 13:58:54,901 : [INFO]  Batch 88 initialized 
2023-03-25 13:58:55,336 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:55,752 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-25 13:59:00,266 : [INFO]  ------------------------- Batch round 1, loss: 0.5515 -------------------------
2023-03-25 13:59:00,266 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:00,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:00,312 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-25 13:59:03,055 : [INFO]  ------------------------- Batch round 2, loss: 0.5405 -------------------------
2023-03-25 13:59:03,055 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:03,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:03,168 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-25 13:59:05,816 : [INFO]  ------------------------- Batch round 3, loss: 0.5222 -------------------------
2023-03-25 13:59:05,816 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:05,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:05,998 : [INFO]  Batch number 88 model fetched from the server
2023-03-25 13:59:05,998 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-25 13:59:07,254 : [INFO]  Batch 88: Training set : loss - 0.5199, accuracy - 0.8207, recall - 0.9239, AUC - 0.8999, F1 - 0.8374, precision - 0.7658, training time - -10.0 seconds
2023-03-25 13:59:07,254 : [INFO]  Batch 88: Testing set : loss - 0.5592, accuracy - 0.7696, recall - 0.9314, AUC - 0.88, F1 - 0.8017, precision - 0.7037
2023-03-25 13:59:07,269 : [INFO]  Batch 89 initialized 
2023-03-25 13:59:07,707 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:08,190 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-25 13:59:14,054 : [INFO]  ------------------------- Batch round 1, loss: 0.5754 -------------------------
2023-03-25 13:59:14,054 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:14,058 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:14,061 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-25 13:59:17,756 : [INFO]  ------------------------- Batch round 2, loss: 0.5647 -------------------------
2023-03-25 13:59:17,759 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:17,777 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:17,779 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-25 13:59:20,598 : [INFO]  ------------------------- Batch round 3, loss: 0.5566 -------------------------
2023-03-25 13:59:20,598 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:20,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:20,603 : [INFO]  Batch number 89 model fetched from the server
2023-03-25 13:59:20,603 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-25 13:59:22,037 : [INFO]  Batch 89: Training set : loss - 0.557, accuracy - 0.7446, recall - 0.9565, AUC - 0.8839, F1 - 0.7892, precision - 0.6718, training time - -12.0 seconds
2023-03-25 13:59:22,037 : [INFO]  Batch 89: Testing set : loss - 0.5245, accuracy - 0.7794, recall - 0.951, AUC - 0.9161, F1 - 0.8117, precision - 0.708
2023-03-25 13:59:22,112 : [INFO]  Batch 90 initialized 
2023-03-25 13:59:22,565 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:23,164 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-25 13:59:27,691 : [INFO]  ------------------------- Batch round 1, loss: 0.5459 -------------------------
2023-03-25 13:59:27,691 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:27,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:27,697 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-25 13:59:30,554 : [INFO]  ------------------------- Batch round 2, loss: 0.544 -------------------------
2023-03-25 13:59:30,554 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:30,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:30,559 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-25 13:59:33,389 : [INFO]  ------------------------- Batch round 3, loss: 0.5414 -------------------------
2023-03-25 13:59:33,389 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:33,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:33,413 : [INFO]  Batch number 90 model fetched from the server
2023-03-25 13:59:33,413 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-25 13:59:34,704 : [INFO]  Batch 90: Training set : loss - 0.5421, accuracy - 0.75, recall - 0.8913, AUC - 0.8921, F1 - 0.781, precision - 0.6949, training time - -10.0 seconds
2023-03-25 13:59:34,704 : [INFO]  Batch 90: Testing set : loss - 0.5756, accuracy - 0.7059, recall - 0.9216, AUC - 0.8691, F1 - 0.7581, precision - 0.6438
2023-03-25 13:59:34,716 : [INFO]  Batch 91 initialized 
2023-03-25 13:59:35,154 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:35,583 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-25 13:59:40,188 : [INFO]  ------------------------- Batch round 1, loss: 0.5461 -------------------------
2023-03-25 13:59:40,188 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:40,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:40,287 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-25 13:59:43,680 : [INFO]  ------------------------- Batch round 2, loss: 0.5371 -------------------------
2023-03-25 13:59:43,680 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:43,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:43,742 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-25 13:59:47,088 : [INFO]  ------------------------- Batch round 3, loss: 0.5372 -------------------------
2023-03-25 13:59:47,088 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:47,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:47,094 : [INFO]  Batch number 91 model fetched from the server
2023-03-25 13:59:47,094 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-25 13:59:48,730 : [INFO]  Batch 91: Training set : loss - 0.538, accuracy - 0.75, recall - 0.9022, AUC - 0.8748, F1 - 0.783, precision - 0.6917, training time - -12.0 seconds
2023-03-25 13:59:48,730 : [INFO]  Batch 91: Testing set : loss - 0.6412, accuracy - 0.6176, recall - 0.8725, AUC - 0.7777, F1 - 0.6953, precision - 0.5779
2023-03-25 13:59:48,746 : [INFO]  Batch 92 initialized 
2023-03-25 13:59:49,264 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:49,691 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-25 13:59:55,433 : [INFO]  ------------------------- Batch round 1, loss: 0.5476 -------------------------
2023-03-25 13:59:55,433 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:55,436 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:55,439 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-25 13:59:59,095 : [INFO]  ------------------------- Batch round 2, loss: 0.5402 -------------------------
2023-03-25 13:59:59,095 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:59,098 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:59,100 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-25 14:00:03,207 : [INFO]  ------------------------- Batch round 3, loss: 0.5304 -------------------------
2023-03-25 14:00:03,207 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-25 14:00:03,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:00:03,211 : [INFO]  Batch number 92 model fetched from the server
2023-03-25 14:00:03,211 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-25 14:00:04,622 : [INFO]  Batch 92: Training set : loss - 0.5298, accuracy - 0.7989, recall - 0.913, AUC - 0.8986, F1 - 0.8195, precision - 0.7434, training time - -14.0 seconds
2023-03-25 14:00:04,622 : [INFO]  Batch 92: Testing set : loss - 0.5788, accuracy - 0.7304, recall - 0.902, AUC - 0.8301, F1 - 0.7699, precision - 0.6715
2023-03-25 14:00:04,628 : [INFO]  Batch 93 initialized 
2023-03-25 14:00:05,080 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:00:05,497 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-25 14:00:10,359 : [INFO]  ------------------------- Batch round 1, loss: 0.5438 -------------------------
2023-03-25 14:00:10,360 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-25 14:00:10,363 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:00:10,365 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
