2023-03-25 15:33:06,785 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 15:33:06,785 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 6, epochs 6
2023-03-25 15:33:09,998 : [INFO]  Model initialized for training
2023-03-25 15:33:27,208 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:33:27,330 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 15:33:27,331 : [INFO]  Connected to the server
2023-03-25 15:33:27,407 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 15:33:27,407 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:33:27,415 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 15:33:27,415 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 15:35:46,650 : [INFO]  ------------------------- Training round 1, loss: 0.6208 -------------------------
2023-03-25 15:35:46,650 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 15:35:57,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:35:57,054 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 15:38:09,565 : [INFO]  ------------------------- Training round 2, loss: 0.5945 -------------------------
2023-03-25 15:38:09,566 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 15:38:17,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:38:17,492 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 15:40:30,201 : [INFO]  ------------------------- Training round 3, loss: 0.5912 -------------------------
2023-03-25 15:40:30,201 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 15:40:37,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:40:37,923 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 15:42:50,210 : [INFO]  ------------------------- Training round 4, loss: 0.589 -------------------------
2023-03-25 15:42:50,210 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 15:42:57,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:42:57,947 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 15:45:10,074 : [INFO]  ------------------------- Training round 5, loss: 0.5887 -------------------------
2023-03-25 15:45:10,074 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 15:45:18,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:45:18,160 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 15:46:02,504 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.7, recall - 0.87, AUC - 0.83, F1 - 0.75, precision - 0.65, training time - -711.0 seconds
2023-03-25 15:46:02,504 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.65
2023-03-25 15:46:02,512 : [INFO]  Batch 1 initialized 
2023-03-25 15:46:02,967 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:03,071 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 15:46:03,071 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 15:46:06,800 : [INFO]  ------------------------- Batch round 1, loss: 0.5873 -------------------------
2023-03-25 15:46:06,800 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:09,910 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:09,912 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 15:46:11,889 : [INFO]  ------------------------- Batch round 2, loss: 0.5719 -------------------------
2023-03-25 15:46:11,889 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:12,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:12,182 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 15:46:14,208 : [INFO]  ------------------------- Batch round 3, loss: 0.5701 -------------------------
2023-03-25 15:46:14,208 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:14,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:14,473 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 15:46:14,473 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 15:46:15,738 : [INFO]  Batch 1: Training set : loss - 0.5657, accuracy - 0.7826, recall - 0.9022, AUC - 0.868, F1 - 0.8058, precision - 0.7281, training time - -11.0 seconds
2023-03-25 15:46:15,738 : [INFO]  Batch 1: Testing set : loss - 0.5577, accuracy - 0.7353, recall - 0.9118, AUC - 0.8829, F1 - 0.775, precision - 0.6739
2023-03-25 15:46:15,743 : [INFO]  Batch 2 initialized 
2023-03-25 15:46:16,172 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:16,299 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 15:46:20,223 : [INFO]  ------------------------- Batch round 1, loss: 0.5505 -------------------------
2023-03-25 15:46:20,223 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:20,699 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:20,700 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 15:46:22,651 : [INFO]  ------------------------- Batch round 2, loss: 0.5397 -------------------------
2023-03-25 15:46:22,652 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:22,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:22,746 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 15:46:24,696 : [INFO]  ------------------------- Batch round 3, loss: 0.5336 -------------------------
2023-03-25 15:46:24,696 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:25,067 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:25,068 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 15:46:25,069 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 15:46:26,340 : [INFO]  Batch 2: Training set : loss - 0.529, accuracy - 0.8152, recall - 0.9565, AUC - 0.8987, F1 - 0.8381, precision - 0.7458, training time - -9.0 seconds
2023-03-25 15:46:26,340 : [INFO]  Batch 2: Testing set : loss - 0.5445, accuracy - 0.7745, recall - 0.9412, AUC - 0.9116, F1 - 0.8067, precision - 0.7059
2023-03-25 15:46:26,347 : [INFO]  Batch 3 initialized 
2023-03-25 15:46:26,772 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:26,993 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 15:46:31,139 : [INFO]  ------------------------- Batch round 1, loss: 0.5472 -------------------------
2023-03-25 15:46:31,139 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:31,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:31,159 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 15:46:33,439 : [INFO]  ------------------------- Batch round 2, loss: 0.5503 -------------------------
2023-03-25 15:46:33,439 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:33,442 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:33,444 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 15:46:35,548 : [INFO]  ------------------------- Batch round 3, loss: 0.5414 -------------------------
2023-03-25 15:46:35,548 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:35,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:35,590 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 15:46:35,590 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 15:46:36,897 : [INFO]  Batch 3: Training set : loss - 0.5452, accuracy - 0.7717, recall - 0.9565, AUC - 0.9199, F1 - 0.8073, precision - 0.6984, training time - -9.0 seconds
2023-03-25 15:46:36,897 : [INFO]  Batch 3: Testing set : loss - 0.5661, accuracy - 0.6961, recall - 0.902, AUC - 0.8986, F1 - 0.748, precision - 0.6389
2023-03-25 15:46:36,906 : [INFO]  Batch 4 initialized 
2023-03-25 15:46:37,335 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:37,548 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 15:46:41,364 : [INFO]  ------------------------- Batch round 1, loss: 0.5648 -------------------------
2023-03-25 15:46:41,364 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:41,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:41,510 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 15:46:43,478 : [INFO]  ------------------------- Batch round 2, loss: 0.5456 -------------------------
2023-03-25 15:46:43,478 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:43,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:43,672 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 15:46:45,686 : [INFO]  ------------------------- Batch round 3, loss: 0.544 -------------------------
2023-03-25 15:46:45,686 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:45,863 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:45,866 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 15:46:45,866 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 15:46:47,141 : [INFO]  Batch 4: Training set : loss - 0.5439, accuracy - 0.7717, recall - 0.9239, AUC - 0.8938, F1 - 0.8019, precision - 0.7083, training time - -8.0 seconds
2023-03-25 15:46:47,141 : [INFO]  Batch 4: Testing set : loss - 0.5548, accuracy - 0.7206, recall - 0.9608, AUC - 0.9177, F1 - 0.7747, precision - 0.649
2023-03-25 15:46:47,149 : [INFO]  Batch 5 initialized 
2023-03-25 15:46:47,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:47,790 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 15:46:51,606 : [INFO]  ------------------------- Batch round 1, loss: 0.5517 -------------------------
2023-03-25 15:46:51,606 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 15:46:51,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:51,752 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 15:46:53,844 : [INFO]  ------------------------- Batch round 2, loss: 0.5459 -------------------------
2023-03-25 15:46:53,845 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 15:46:54,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:54,003 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 15:46:56,042 : [INFO]  ------------------------- Batch round 3, loss: 0.5385 -------------------------
2023-03-25 15:46:56,042 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 15:46:56,192 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:46:56,194 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 15:46:56,194 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 15:46:57,465 : [INFO]  Batch 5: Training set : loss - 0.5345, accuracy - 0.7717, recall - 0.9348, AUC - 0.905, F1 - 0.8037, precision - 0.7049, training time - -8.0 seconds
2023-03-25 15:46:57,465 : [INFO]  Batch 5: Testing set : loss - 0.543, accuracy - 0.7549, recall - 0.8824, AUC - 0.8917, F1 - 0.7826, precision - 0.7031
2023-03-25 15:46:57,470 : [INFO]  Batch 6 initialized 
2023-03-25 15:46:57,896 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:46:58,096 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 15:47:01,860 : [INFO]  ------------------------- Batch round 1, loss: 0.5467 -------------------------
2023-03-25 15:47:01,860 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:02,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:02,108 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 15:47:04,258 : [INFO]  ------------------------- Batch round 2, loss: 0.5397 -------------------------
2023-03-25 15:47:04,258 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:04,395 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:04,397 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 15:47:06,420 : [INFO]  ------------------------- Batch round 3, loss: 0.5242 -------------------------
2023-03-25 15:47:06,420 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:06,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:06,519 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 15:47:06,519 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 15:47:07,799 : [INFO]  Batch 6: Training set : loss - 0.5274, accuracy - 0.7826, recall - 0.9348, AUC - 0.9051, F1 - 0.8113, precision - 0.7167, training time - -8.0 seconds
2023-03-25 15:47:07,799 : [INFO]  Batch 6: Testing set : loss - 0.55, accuracy - 0.7255, recall - 0.9216, AUC - 0.8983, F1 - 0.7705, precision - 0.662
2023-03-25 15:47:07,808 : [INFO]  Batch 7 initialized 
2023-03-25 15:47:08,276 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:08,511 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 15:47:12,297 : [INFO]  ------------------------- Batch round 1, loss: 0.5461 -------------------------
2023-03-25 15:47:12,297 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:12,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:12,711 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 15:47:14,902 : [INFO]  ------------------------- Batch round 2, loss: 0.5334 -------------------------
2023-03-25 15:47:14,902 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:15,006 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:15,008 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 15:47:17,126 : [INFO]  ------------------------- Batch round 3, loss: 0.5235 -------------------------
2023-03-25 15:47:17,126 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:17,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:17,273 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 15:47:17,273 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 15:47:18,561 : [INFO]  Batch 7: Training set : loss - 0.5218, accuracy - 0.8098, recall - 0.9239, AUC - 0.9032, F1 - 0.8293, precision - 0.7522, training time - -9.0 seconds
2023-03-25 15:47:18,562 : [INFO]  Batch 7: Testing set : loss - 0.583, accuracy - 0.7157, recall - 0.9216, AUC - 0.8693, F1 - 0.7642, precision - 0.6528
2023-03-25 15:47:18,567 : [INFO]  Batch 8 initialized 
2023-03-25 15:47:19,000 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:19,219 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 15:47:23,081 : [INFO]  ------------------------- Batch round 1, loss: 0.5533 -------------------------
2023-03-25 15:47:23,081 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:23,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:23,313 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 15:47:25,357 : [INFO]  ------------------------- Batch round 2, loss: 0.5542 -------------------------
2023-03-25 15:47:25,357 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:25,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:25,528 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 15:47:27,601 : [INFO]  ------------------------- Batch round 3, loss: 0.5517 -------------------------
2023-03-25 15:47:27,601 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:27,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:27,743 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 15:47:27,743 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 15:47:29,017 : [INFO]  Batch 8: Training set : loss - 0.5435, accuracy - 0.8098, recall - 0.9239, AUC - 0.8993, F1 - 0.8293, precision - 0.7522, training time - -9.0 seconds
2023-03-25 15:47:29,017 : [INFO]  Batch 8: Testing set : loss - 0.584, accuracy - 0.7157, recall - 0.8922, AUC - 0.8454, F1 - 0.7583, precision - 0.6594
2023-03-25 15:47:29,022 : [INFO]  Batch 9 initialized 
2023-03-25 15:47:29,438 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:29,666 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 15:47:33,886 : [INFO]  ------------------------- Batch round 1, loss: 0.5859 -------------------------
2023-03-25 15:47:33,886 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:33,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:33,891 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 15:47:36,115 : [INFO]  ------------------------- Batch round 2, loss: 0.5759 -------------------------
2023-03-25 15:47:36,115 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:36,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:36,161 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 15:47:38,599 : [INFO]  ------------------------- Batch round 3, loss: 0.5663 -------------------------
2023-03-25 15:47:38,599 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:38,602 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:38,604 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 15:47:38,604 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 15:47:39,916 : [INFO]  Batch 9: Training set : loss - 0.559, accuracy - 0.75, recall - 0.8804, AUC - 0.8675, F1 - 0.7788, precision - 0.6983, training time - -9.0 seconds
2023-03-25 15:47:39,916 : [INFO]  Batch 9: Testing set : loss - 0.6163, accuracy - 0.6422, recall - 0.8235, AUC - 0.7986, F1 - 0.6971, precision - 0.6043
2023-03-25 15:47:39,922 : [INFO]  Batch 10 initialized 
2023-03-25 15:47:40,364 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:40,598 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 15:47:44,483 : [INFO]  ------------------------- Batch round 1, loss: 0.5615 -------------------------
2023-03-25 15:47:44,483 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:44,556 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:44,558 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 15:47:46,728 : [INFO]  ------------------------- Batch round 2, loss: 0.5413 -------------------------
2023-03-25 15:47:46,728 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:46,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:46,781 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 15:47:49,170 : [INFO]  ------------------------- Batch round 3, loss: 0.5335 -------------------------
2023-03-25 15:47:49,170 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:49,173 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:49,175 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 15:47:49,175 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 15:47:50,479 : [INFO]  Batch 10: Training set : loss - 0.5341, accuracy - 0.7826, recall - 0.9457, AUC - 0.8852, F1 - 0.8131, precision - 0.7131, training time - -9.0 seconds
2023-03-25 15:47:50,479 : [INFO]  Batch 10: Testing set : loss - 0.5648, accuracy - 0.7108, recall - 0.8725, AUC - 0.8707, F1 - 0.7511, precision - 0.6593
2023-03-25 15:47:50,484 : [INFO]  Batch 11 initialized 
2023-03-25 15:47:50,912 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:47:51,159 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 15:47:55,257 : [INFO]  ------------------------- Batch round 1, loss: 0.5641 -------------------------
2023-03-25 15:47:55,257 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 15:47:55,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:55,274 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 15:47:57,308 : [INFO]  ------------------------- Batch round 2, loss: 0.562 -------------------------
2023-03-25 15:47:57,308 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 15:47:57,435 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:57,437 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 15:47:59,512 : [INFO]  ------------------------- Batch round 3, loss: 0.5529 -------------------------
2023-03-25 15:47:59,512 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 15:47:59,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:47:59,636 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 15:47:59,636 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 15:48:00,948 : [INFO]  Batch 11: Training set : loss - 0.5523, accuracy - 0.7554, recall - 0.8913, AUC - 0.8637, F1 - 0.7847, precision - 0.7009, training time - -8.0 seconds
2023-03-25 15:48:00,948 : [INFO]  Batch 11: Testing set : loss - 0.5765, accuracy - 0.701, recall - 0.9216, AUC - 0.8837, F1 - 0.755, precision - 0.6395
2023-03-25 15:48:00,953 : [INFO]  Batch 12 initialized 
2023-03-25 15:48:01,390 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:01,630 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 15:48:05,463 : [INFO]  ------------------------- Batch round 1, loss: 0.5518 -------------------------
2023-03-25 15:48:05,463 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:05,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:05,715 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 15:48:07,807 : [INFO]  ------------------------- Batch round 2, loss: 0.5453 -------------------------
2023-03-25 15:48:07,807 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:08,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:08,052 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 15:48:10,097 : [INFO]  ------------------------- Batch round 3, loss: 0.5453 -------------------------
2023-03-25 15:48:10,098 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:10,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:10,373 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 15:48:10,373 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 15:48:11,639 : [INFO]  Batch 12: Training set : loss - 0.5391, accuracy - 0.7826, recall - 0.8913, AUC - 0.8844, F1 - 0.8039, precision - 0.7321, training time - -9.0 seconds
2023-03-25 15:48:11,639 : [INFO]  Batch 12: Testing set : loss - 0.5758, accuracy - 0.7206, recall - 0.8725, AUC - 0.8534, F1 - 0.7574, precision - 0.6692
2023-03-25 15:48:11,644 : [INFO]  Batch 13 initialized 
2023-03-25 15:48:12,075 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:12,292 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 15:48:16,188 : [INFO]  ------------------------- Batch round 1, loss: 0.5415 -------------------------
2023-03-25 15:48:16,188 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:16,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:16,401 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 15:48:18,510 : [INFO]  ------------------------- Batch round 2, loss: 0.5334 -------------------------
2023-03-25 15:48:18,510 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:18,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:18,617 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 15:48:20,698 : [INFO]  ------------------------- Batch round 3, loss: 0.5222 -------------------------
2023-03-25 15:48:20,698 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:20,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:20,804 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 15:48:20,804 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 15:48:22,107 : [INFO]  Batch 13: Training set : loss - 0.5245, accuracy - 0.8098, recall - 0.9348, AUC - 0.906, F1 - 0.8309, precision - 0.7478, training time - -9.0 seconds
2023-03-25 15:48:22,107 : [INFO]  Batch 13: Testing set : loss - 0.5547, accuracy - 0.6765, recall - 0.8824, AUC - 0.8897, F1 - 0.7317, precision - 0.625
2023-03-25 15:48:22,119 : [INFO]  Batch 14 initialized 
2023-03-25 15:48:22,550 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:22,790 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 15:48:26,625 : [INFO]  ------------------------- Batch round 1, loss: 0.5548 -------------------------
2023-03-25 15:48:26,626 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:26,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:26,819 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 15:48:28,784 : [INFO]  ------------------------- Batch round 2, loss: 0.541 -------------------------
2023-03-25 15:48:28,784 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:28,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:28,973 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 15:48:31,019 : [INFO]  ------------------------- Batch round 3, loss: 0.5353 -------------------------
2023-03-25 15:48:31,019 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:31,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:31,118 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 15:48:31,118 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 15:48:32,439 : [INFO]  Batch 14: Training set : loss - 0.5361, accuracy - 0.7772, recall - 0.9565, AUC - 0.8928, F1 - 0.8111, precision - 0.704, training time - -8.0 seconds
2023-03-25 15:48:32,439 : [INFO]  Batch 14: Testing set : loss - 0.5655, accuracy - 0.7108, recall - 0.902, AUC - 0.8966, F1 - 0.7572, precision - 0.6525
2023-03-25 15:48:32,454 : [INFO]  Batch 15 initialized 
2023-03-25 15:48:32,887 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:33,112 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 15:48:36,889 : [INFO]  ------------------------- Batch round 1, loss: 0.5822 -------------------------
2023-03-25 15:48:36,889 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:37,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:37,251 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 15:48:39,261 : [INFO]  ------------------------- Batch round 2, loss: 0.5832 -------------------------
2023-03-25 15:48:39,261 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:39,510 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:39,512 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 15:48:41,602 : [INFO]  ------------------------- Batch round 3, loss: 0.5734 -------------------------
2023-03-25 15:48:41,602 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:41,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:41,828 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 15:48:41,828 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 15:48:43,093 : [INFO]  Batch 15: Training set : loss - 0.5705, accuracy - 0.75, recall - 0.9674, AUC - 0.8501, F1 - 0.7946, precision - 0.6742, training time - -9.0 seconds
2023-03-25 15:48:43,094 : [INFO]  Batch 15: Testing set : loss - 0.5594, accuracy - 0.7157, recall - 0.9412, AUC - 0.8988, F1 - 0.768, precision - 0.6486
2023-03-25 15:48:43,108 : [INFO]  Batch 16 initialized 
2023-03-25 15:48:43,539 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:43,774 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 15:48:47,936 : [INFO]  ------------------------- Batch round 1, loss: 0.5738 -------------------------
2023-03-25 15:48:47,936 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:47,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:47,953 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 15:48:49,986 : [INFO]  ------------------------- Batch round 2, loss: 0.5713 -------------------------
2023-03-25 15:48:49,986 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 15:48:50,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:50,043 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 15:48:52,153 : [INFO]  ------------------------- Batch round 3, loss: 0.5681 -------------------------
2023-03-25 15:48:52,153 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 15:48:52,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:52,199 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 15:48:52,199 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 15:48:53,529 : [INFO]  Batch 16: Training set : loss - 0.5576, accuracy - 0.7554, recall - 0.8804, AUC - 0.8424, F1 - 0.7826, precision - 0.7043, training time - -8.0 seconds
2023-03-25 15:48:53,529 : [INFO]  Batch 16: Testing set : loss - 0.5685, accuracy - 0.6912, recall - 0.8627, AUC - 0.8811, F1 - 0.7364, precision - 0.6423
2023-03-25 15:48:53,539 : [INFO]  Batch 17 initialized 
2023-03-25 15:48:53,961 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:48:54,229 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 15:48:58,047 : [INFO]  ------------------------- Batch round 1, loss: 0.543 -------------------------
2023-03-25 15:48:58,047 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 15:48:58,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:48:58,150 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 15:49:00,259 : [INFO]  ------------------------- Batch round 2, loss: 0.5304 -------------------------
2023-03-25 15:49:00,259 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:00,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:00,300 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 15:49:02,416 : [INFO]  ------------------------- Batch round 3, loss: 0.5193 -------------------------
2023-03-25 15:49:02,416 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:02,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:02,484 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 15:49:02,484 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 15:49:03,770 : [INFO]  Batch 17: Training set : loss - 0.5145, accuracy - 0.8098, recall - 0.9674, AUC - 0.9196, F1 - 0.8357, precision - 0.7355, training time - -8.0 seconds
2023-03-25 15:49:03,770 : [INFO]  Batch 17: Testing set : loss - 0.5542, accuracy - 0.7255, recall - 0.9706, AUC - 0.9176, F1 - 0.7795, precision - 0.6513
2023-03-25 15:49:03,780 : [INFO]  Batch 18 initialized 
2023-03-25 15:49:04,198 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:04,468 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 15:49:08,373 : [INFO]  ------------------------- Batch round 1, loss: 0.5975 -------------------------
2023-03-25 15:49:08,373 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:08,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:08,379 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 15:49:10,643 : [INFO]  ------------------------- Batch round 2, loss: 0.5768 -------------------------
2023-03-25 15:49:10,644 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:10,646 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:10,648 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 15:49:12,838 : [INFO]  ------------------------- Batch round 3, loss: 0.5756 -------------------------
2023-03-25 15:49:12,838 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:12,841 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:12,843 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 15:49:12,843 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 15:49:14,177 : [INFO]  Batch 18: Training set : loss - 0.5858, accuracy - 0.7065, recall - 0.8913, AUC - 0.8396, F1 - 0.7523, precision - 0.6508, training time - -8.0 seconds
2023-03-25 15:49:14,177 : [INFO]  Batch 18: Testing set : loss - 0.6067, accuracy - 0.6716, recall - 0.8235, AUC - 0.7898, F1 - 0.7149, precision - 0.6316
2023-03-25 15:49:14,215 : [INFO]  Batch 19 initialized 
2023-03-25 15:49:14,650 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:14,911 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 15:49:18,896 : [INFO]  ------------------------- Batch round 1, loss: 0.5648 -------------------------
2023-03-25 15:49:18,896 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:18,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:18,918 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 15:49:21,117 : [INFO]  ------------------------- Batch round 2, loss: 0.5522 -------------------------
2023-03-25 15:49:21,117 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:21,130 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:21,132 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 15:49:23,347 : [INFO]  ------------------------- Batch round 3, loss: 0.5443 -------------------------
2023-03-25 15:49:23,347 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:23,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:23,366 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 15:49:23,366 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 15:49:24,699 : [INFO]  Batch 19: Training set : loss - 0.5361, accuracy - 0.8043, recall - 0.9565, AUC - 0.8797, F1 - 0.8302, precision - 0.7333, training time - -8.0 seconds
2023-03-25 15:49:24,700 : [INFO]  Batch 19: Testing set : loss - 0.595, accuracy - 0.6716, recall - 0.8922, AUC - 0.8339, F1 - 0.7309, precision - 0.619
2023-03-25 15:49:24,711 : [INFO]  Batch 20 initialized 
2023-03-25 15:49:25,130 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:25,378 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 15:49:29,613 : [INFO]  ------------------------- Batch round 1, loss: 0.5848 -------------------------
2023-03-25 15:49:29,613 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:29,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:29,630 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 15:49:31,800 : [INFO]  ------------------------- Batch round 2, loss: 0.5711 -------------------------
2023-03-25 15:49:31,800 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:31,835 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:31,837 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 15:49:34,009 : [INFO]  ------------------------- Batch round 3, loss: 0.565 -------------------------
2023-03-25 15:49:34,009 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:34,363 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:34,367 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 15:49:34,367 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 15:49:35,737 : [INFO]  Batch 20: Training set : loss - 0.5586, accuracy - 0.7391, recall - 0.9348, AUC - 0.8791, F1 - 0.7818, precision - 0.6719, training time - -9.0 seconds
2023-03-25 15:49:35,737 : [INFO]  Batch 20: Testing set : loss - 0.5752, accuracy - 0.7108, recall - 0.902, AUC - 0.8725, F1 - 0.7572, precision - 0.6525
2023-03-25 15:49:35,748 : [INFO]  Batch 21 initialized 
2023-03-25 15:49:36,166 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:36,452 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 15:49:40,356 : [INFO]  ------------------------- Batch round 1, loss: 0.5914 -------------------------
2023-03-25 15:49:40,356 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:40,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:40,459 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 15:49:42,615 : [INFO]  ------------------------- Batch round 2, loss: 0.5937 -------------------------
2023-03-25 15:49:42,615 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:42,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:42,711 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 15:49:44,896 : [INFO]  ------------------------- Batch round 3, loss: 0.593 -------------------------
2023-03-25 15:49:44,896 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:45,007 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:45,009 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 15:49:45,009 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 15:49:46,301 : [INFO]  Batch 21: Training set : loss - 0.5883, accuracy - 0.7337, recall - 0.9348, AUC - 0.8415, F1 - 0.7783, precision - 0.6667, training time - -9.0 seconds
2023-03-25 15:49:46,301 : [INFO]  Batch 21: Testing set : loss - 0.5607, accuracy - 0.6961, recall - 0.9608, AUC - 0.9354, F1 - 0.7597, precision - 0.6282
2023-03-25 15:49:46,336 : [INFO]  Batch 22 initialized 
2023-03-25 15:49:46,765 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:47,031 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 15:49:50,943 : [INFO]  ------------------------- Batch round 1, loss: 0.6052 -------------------------
2023-03-25 15:49:50,943 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 15:49:51,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:51,130 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 15:49:53,320 : [INFO]  ------------------------- Batch round 2, loss: 0.5946 -------------------------
2023-03-25 15:49:53,321 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 15:49:53,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:53,528 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 15:49:55,868 : [INFO]  ------------------------- Batch round 3, loss: 0.5941 -------------------------
2023-03-25 15:49:55,868 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 15:49:55,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:49:55,874 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 15:49:55,874 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 15:49:57,232 : [INFO]  Batch 22: Training set : loss - 0.5958, accuracy - 0.6848, recall - 0.8913, AUC - 0.8374, F1 - 0.7387, precision - 0.6308, training time - -9.0 seconds
2023-03-25 15:49:57,232 : [INFO]  Batch 22: Testing set : loss - 0.6105, accuracy - 0.6716, recall - 0.8333, AUC - 0.8151, F1 - 0.7173, precision - 0.6296
2023-03-25 15:49:57,239 : [INFO]  Batch 23 initialized 
2023-03-25 15:49:57,652 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:49:57,901 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 15:50:01,898 : [INFO]  ------------------------- Batch round 1, loss: 0.5952 -------------------------
2023-03-25 15:50:01,898 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:02,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:02,172 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 15:50:04,569 : [INFO]  ------------------------- Batch round 2, loss: 0.5844 -------------------------
2023-03-25 15:50:04,569 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:04,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:04,574 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 15:50:06,672 : [INFO]  ------------------------- Batch round 3, loss: 0.5768 -------------------------
2023-03-25 15:50:06,673 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:06,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:06,900 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 15:50:06,900 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 15:50:08,220 : [INFO]  Batch 23: Training set : loss - 0.5668, accuracy - 0.7228, recall - 0.8696, AUC - 0.8527, F1 - 0.7583, precision - 0.6723, training time - -9.0 seconds
2023-03-25 15:50:08,220 : [INFO]  Batch 23: Testing set : loss - 0.5992, accuracy - 0.6618, recall - 0.8333, AUC - 0.815, F1 - 0.7113, precision - 0.6204
2023-03-25 15:50:08,231 : [INFO]  Batch 24 initialized 
2023-03-25 15:50:08,670 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:08,932 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 15:50:12,872 : [INFO]  ------------------------- Batch round 1, loss: 0.587 -------------------------
2023-03-25 15:50:12,872 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:13,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:13,109 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 15:50:15,443 : [INFO]  ------------------------- Batch round 2, loss: 0.5742 -------------------------
2023-03-25 15:50:15,444 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:15,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:15,452 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 15:50:17,651 : [INFO]  ------------------------- Batch round 3, loss: 0.5739 -------------------------
2023-03-25 15:50:17,651 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:17,822 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:17,824 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 15:50:17,824 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 15:50:19,111 : [INFO]  Batch 24: Training set : loss - 0.5731, accuracy - 0.7554, recall - 0.8696, AUC - 0.8149, F1 - 0.7805, precision - 0.708, training time - -9.0 seconds
2023-03-25 15:50:19,111 : [INFO]  Batch 24: Testing set : loss - 0.5806, accuracy - 0.6961, recall - 0.8725, AUC - 0.8317, F1 - 0.7417, precision - 0.6449
2023-03-25 15:50:19,125 : [INFO]  Batch 25 initialized 
2023-03-25 15:50:19,559 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:19,829 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 15:50:23,731 : [INFO]  ------------------------- Batch round 1, loss: 0.6137 -------------------------
2023-03-25 15:50:23,732 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:24,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:24,230 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 15:50:26,300 : [INFO]  ------------------------- Batch round 2, loss: 0.5912 -------------------------
2023-03-25 15:50:26,300 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:26,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:26,529 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 15:50:28,627 : [INFO]  ------------------------- Batch round 3, loss: 0.5867 -------------------------
2023-03-25 15:50:28,627 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:28,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:28,875 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 15:50:28,875 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 15:50:30,177 : [INFO]  Batch 25: Training set : loss - 0.5861, accuracy - 0.6957, recall - 0.8913, AUC - 0.8224, F1 - 0.7455, precision - 0.6406, training time - -9.0 seconds
2023-03-25 15:50:30,177 : [INFO]  Batch 25: Testing set : loss - 0.6124, accuracy - 0.6618, recall - 0.8431, AUC - 0.7977, F1 - 0.7137, precision - 0.6187
2023-03-25 15:50:30,190 : [INFO]  Batch 26 initialized 
2023-03-25 15:50:30,626 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:30,896 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 15:50:34,816 : [INFO]  ------------------------- Batch round 1, loss: 0.5792 -------------------------
2023-03-25 15:50:34,816 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:35,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:35,093 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 15:50:37,740 : [INFO]  ------------------------- Batch round 2, loss: 0.559 -------------------------
2023-03-25 15:50:37,741 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:37,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:37,744 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 15:50:39,777 : [INFO]  ------------------------- Batch round 3, loss: 0.55 -------------------------
2023-03-25 15:50:39,777 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:40,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:40,018 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 15:50:40,018 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 15:50:41,337 : [INFO]  Batch 26: Training set : loss - 0.5547, accuracy - 0.7446, recall - 0.8804, AUC - 0.857, F1 - 0.7751, precision - 0.6923, training time - -9.0 seconds
2023-03-25 15:50:41,337 : [INFO]  Batch 26: Testing set : loss - 0.5508, accuracy - 0.7451, recall - 0.9412, AUC - 0.9169, F1 - 0.7869, precision - 0.6761
2023-03-25 15:50:41,349 : [INFO]  Batch 27 initialized 
2023-03-25 15:50:41,781 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:42,048 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 15:50:45,873 : [INFO]  ------------------------- Batch round 1, loss: 0.5765 -------------------------
2023-03-25 15:50:45,873 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:46,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:46,333 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 15:50:48,418 : [INFO]  ------------------------- Batch round 2, loss: 0.5664 -------------------------
2023-03-25 15:50:48,418 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:48,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:48,554 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 15:50:50,647 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 15:50:50,647 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 15:50:50,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:50,791 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 15:50:50,791 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 15:50:52,079 : [INFO]  Batch 27: Training set : loss - 0.5597, accuracy - 0.7609, recall - 0.9457, AUC - 0.8697, F1 - 0.7982, precision - 0.6905, training time - -9.0 seconds
2023-03-25 15:50:52,079 : [INFO]  Batch 27: Testing set : loss - 0.5947, accuracy - 0.6814, recall - 0.8235, AUC - 0.8184, F1 - 0.721, precision - 0.6412
2023-03-25 15:50:52,090 : [INFO]  Batch 28 initialized 
2023-03-25 15:50:52,512 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:50:52,788 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 15:50:56,761 : [INFO]  ------------------------- Batch round 1, loss: 0.5846 -------------------------
2023-03-25 15:50:56,761 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 15:50:56,883 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:56,884 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 15:50:59,057 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-25 15:50:59,058 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 15:50:59,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:50:59,159 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 15:51:01,302 : [INFO]  ------------------------- Batch round 3, loss: 0.5512 -------------------------
2023-03-25 15:51:01,303 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:01,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:01,412 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 15:51:01,412 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 15:51:02,784 : [INFO]  Batch 28: Training set : loss - 0.5439, accuracy - 0.7663, recall - 0.8804, AUC - 0.8668, F1 - 0.7902, precision - 0.7168, training time - -9.0 seconds
2023-03-25 15:51:02,784 : [INFO]  Batch 28: Testing set : loss - 0.5821, accuracy - 0.6961, recall - 0.8627, AUC - 0.8423, F1 - 0.7395, precision - 0.6471
2023-03-25 15:51:02,795 : [INFO]  Batch 29 initialized 
2023-03-25 15:51:03,216 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:03,489 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 15:51:07,425 : [INFO]  ------------------------- Batch round 1, loss: 0.575 -------------------------
2023-03-25 15:51:07,426 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:07,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:07,431 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 15:51:09,731 : [INFO]  ------------------------- Batch round 2, loss: 0.5611 -------------------------
2023-03-25 15:51:09,731 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:09,904 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:09,906 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 15:51:12,079 : [INFO]  ------------------------- Batch round 3, loss: 0.5624 -------------------------
2023-03-25 15:51:12,079 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:12,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:12,084 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 15:51:12,084 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 15:51:13,436 : [INFO]  Batch 29: Training set : loss - 0.5584, accuracy - 0.7554, recall - 0.8804, AUC - 0.8795, F1 - 0.7826, precision - 0.7043, training time - -9.0 seconds
2023-03-25 15:51:13,436 : [INFO]  Batch 29: Testing set : loss - 0.5701, accuracy - 0.7353, recall - 0.8725, AUC - 0.8709, F1 - 0.7672, precision - 0.6846
2023-03-25 15:51:13,447 : [INFO]  Batch 30 initialized 
2023-03-25 15:51:13,889 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:14,173 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 15:51:18,088 : [INFO]  ------------------------- Batch round 1, loss: 0.6007 -------------------------
2023-03-25 15:51:18,088 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:18,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:18,150 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 15:51:20,265 : [INFO]  ------------------------- Batch round 2, loss: 0.58 -------------------------
2023-03-25 15:51:20,266 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:20,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:20,374 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 15:51:22,517 : [INFO]  ------------------------- Batch round 3, loss: 0.5777 -------------------------
2023-03-25 15:51:22,517 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:22,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:22,628 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 15:51:22,628 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 15:51:24,029 : [INFO]  Batch 30: Training set : loss - 0.5792, accuracy - 0.7228, recall - 0.8152, AUC - 0.7993, F1 - 0.7463, precision - 0.6881, training time - -8.0 seconds
2023-03-25 15:51:24,029 : [INFO]  Batch 30: Testing set : loss - 0.5785, accuracy - 0.701, recall - 0.8333, AUC - 0.8375, F1 - 0.7359, precision - 0.6589
2023-03-25 15:51:24,042 : [INFO]  Batch 31 initialized 
2023-03-25 15:51:24,495 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:24,793 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 15:51:28,662 : [INFO]  ------------------------- Batch round 1, loss: 0.5574 -------------------------
2023-03-25 15:51:28,662 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:28,928 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:28,929 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 15:51:31,023 : [INFO]  ------------------------- Batch round 2, loss: 0.5433 -------------------------
2023-03-25 15:51:31,023 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:31,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:31,242 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 15:51:33,368 : [INFO]  ------------------------- Batch round 3, loss: 0.5334 -------------------------
2023-03-25 15:51:33,368 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:33,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:33,600 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 15:51:33,600 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 15:51:34,909 : [INFO]  Batch 31: Training set : loss - 0.524, accuracy - 0.837, recall - 0.9348, AUC - 0.9058, F1 - 0.8515, precision - 0.7818, training time - -9.0 seconds
2023-03-25 15:51:34,909 : [INFO]  Batch 31: Testing set : loss - 0.5676, accuracy - 0.7206, recall - 0.8824, AUC - 0.8426, F1 - 0.7595, precision - 0.6667
2023-03-25 15:51:34,918 : [INFO]  Batch 32 initialized 
2023-03-25 15:51:35,356 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:35,628 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 15:51:39,465 : [INFO]  ------------------------- Batch round 1, loss: 0.5798 -------------------------
2023-03-25 15:51:39,465 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:39,845 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:39,847 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 15:51:41,785 : [INFO]  ------------------------- Batch round 2, loss: 0.5659 -------------------------
2023-03-25 15:51:41,785 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:42,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:42,107 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 15:51:44,126 : [INFO]  ------------------------- Batch round 3, loss: 0.5652 -------------------------
2023-03-25 15:51:44,126 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:44,428 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:44,430 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 15:51:44,431 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 15:51:45,694 : [INFO]  Batch 32: Training set : loss - 0.5573, accuracy - 0.7772, recall - 0.9022, AUC - 0.855, F1 - 0.8019, precision - 0.7217, training time - -9.0 seconds
2023-03-25 15:51:45,694 : [INFO]  Batch 32: Testing set : loss - 0.5606, accuracy - 0.7255, recall - 0.9608, AUC - 0.9078, F1 - 0.7778, precision - 0.6533
2023-03-25 15:51:45,704 : [INFO]  Batch 33 initialized 
2023-03-25 15:51:46,139 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:46,407 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 15:51:50,233 : [INFO]  ------------------------- Batch round 1, loss: 0.574 -------------------------
2023-03-25 15:51:50,233 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 15:51:50,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:50,574 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 15:51:52,571 : [INFO]  ------------------------- Batch round 2, loss: 0.566 -------------------------
2023-03-25 15:51:52,571 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 15:51:52,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:52,833 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 15:51:54,813 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 15:51:54,813 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 15:51:55,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:51:55,061 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 15:51:55,061 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 15:51:56,325 : [INFO]  Batch 33: Training set : loss - 0.5677, accuracy - 0.7391, recall - 0.9674, AUC - 0.8871, F1 - 0.7876, precision - 0.6642, training time - -9.0 seconds
2023-03-25 15:51:56,326 : [INFO]  Batch 33: Testing set : loss - 0.5703, accuracy - 0.7304, recall - 0.9706, AUC - 0.8784, F1 - 0.7826, precision - 0.6556
2023-03-25 15:51:56,338 : [INFO]  Batch 34 initialized 
2023-03-25 15:51:56,755 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:51:57,009 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 15:52:00,952 : [INFO]  ------------------------- Batch round 1, loss: 0.5718 -------------------------
2023-03-25 15:52:00,952 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:01,208 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:01,209 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 15:52:03,351 : [INFO]  ------------------------- Batch round 2, loss: 0.5572 -------------------------
2023-03-25 15:52:03,351 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:03,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:03,374 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 15:52:05,478 : [INFO]  ------------------------- Batch round 3, loss: 0.5473 -------------------------
2023-03-25 15:52:05,478 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:05,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:05,819 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 15:52:05,819 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 15:52:07,115 : [INFO]  Batch 34: Training set : loss - 0.5446, accuracy - 0.7989, recall - 0.9457, AUC - 0.8942, F1 - 0.8246, precision - 0.7311, training time - -9.0 seconds
2023-03-25 15:52:07,116 : [INFO]  Batch 34: Testing set : loss - 0.5495, accuracy - 0.7549, recall - 0.9216, AUC - 0.9068, F1 - 0.7899, precision - 0.6912
2023-03-25 15:52:07,128 : [INFO]  Batch 35 initialized 
2023-03-25 15:52:07,551 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:07,863 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 15:52:12,055 : [INFO]  ------------------------- Batch round 1, loss: 0.5551 -------------------------
2023-03-25 15:52:12,055 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:12,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:12,072 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 15:52:14,122 : [INFO]  ------------------------- Batch round 2, loss: 0.5502 -------------------------
2023-03-25 15:52:14,122 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:14,238 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:14,240 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 15:52:16,336 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-25 15:52:16,337 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:16,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:16,463 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 15:52:16,463 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 15:52:17,762 : [INFO]  Batch 35: Training set : loss - 0.5405, accuracy - 0.7609, recall - 0.9239, AUC - 0.8888, F1 - 0.7944, precision - 0.6967, training time - -9.0 seconds
2023-03-25 15:52:17,763 : [INFO]  Batch 35: Testing set : loss - 0.5667, accuracy - 0.7206, recall - 0.9412, AUC - 0.9035, F1 - 0.7711, precision - 0.6531
2023-03-25 15:52:17,776 : [INFO]  Batch 36 initialized 
2023-03-25 15:52:18,213 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:18,504 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 15:52:22,420 : [INFO]  ------------------------- Batch round 1, loss: 0.5603 -------------------------
2023-03-25 15:52:22,420 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:22,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:22,595 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 15:52:24,745 : [INFO]  ------------------------- Batch round 2, loss: 0.5429 -------------------------
2023-03-25 15:52:24,745 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:24,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:24,850 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 15:52:26,921 : [INFO]  ------------------------- Batch round 3, loss: 0.5446 -------------------------
2023-03-25 15:52:26,921 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:27,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:27,028 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 15:52:27,028 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-25 15:52:28,340 : [INFO]  Batch 36: Training set : loss - 0.5329, accuracy - 0.7772, recall - 0.9239, AUC - 0.9085, F1 - 0.8057, precision - 0.7143, training time - -9.0 seconds
2023-03-25 15:52:28,341 : [INFO]  Batch 36: Testing set : loss - 0.5368, accuracy - 0.7353, recall - 0.951, AUC - 0.9429, F1 - 0.7823, precision - 0.6644
2023-03-25 15:52:28,352 : [INFO]  Batch 37 initialized 
2023-03-25 15:52:28,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:29,071 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 15:52:32,974 : [INFO]  ------------------------- Batch round 1, loss: 0.5935 -------------------------
2023-03-25 15:52:32,974 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:33,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:33,083 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 15:52:35,200 : [INFO]  ------------------------- Batch round 2, loss: 0.5845 -------------------------
2023-03-25 15:52:35,200 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:35,312 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:35,313 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 15:52:37,472 : [INFO]  ------------------------- Batch round 3, loss: 0.582 -------------------------
2023-03-25 15:52:37,472 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:37,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:37,515 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 15:52:37,515 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-25 15:52:38,865 : [INFO]  Batch 37: Training set : loss - 0.5833, accuracy - 0.7174, recall - 0.8913, AUC - 0.8386, F1 - 0.7593, precision - 0.6613, training time - -8.0 seconds
2023-03-25 15:52:38,866 : [INFO]  Batch 37: Testing set : loss - 0.5553, accuracy - 0.7402, recall - 0.8137, AUC - 0.862, F1 - 0.758, precision - 0.7094
2023-03-25 15:52:38,880 : [INFO]  Batch 38 initialized 
2023-03-25 15:52:39,335 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:39,637 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 15:52:43,558 : [INFO]  ------------------------- Batch round 1, loss: 0.576 -------------------------
2023-03-25 15:52:43,558 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:43,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:43,751 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 15:52:45,770 : [INFO]  ------------------------- Batch round 2, loss: 0.5685 -------------------------
2023-03-25 15:52:45,770 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:46,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:46,179 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 15:52:48,234 : [INFO]  ------------------------- Batch round 3, loss: 0.5596 -------------------------
2023-03-25 15:52:48,234 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:48,444 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:48,445 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 15:52:48,445 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-25 15:52:49,711 : [INFO]  Batch 38: Training set : loss - 0.5574, accuracy - 0.7391, recall - 0.9239, AUC - 0.8869, F1 - 0.7798, precision - 0.6746, training time - -9.0 seconds
2023-03-25 15:52:49,711 : [INFO]  Batch 38: Testing set : loss - 0.5692, accuracy - 0.7206, recall - 0.902, AUC - 0.8795, F1 - 0.7635, precision - 0.6619
2023-03-25 15:52:49,725 : [INFO]  Batch 39 initialized 
2023-03-25 15:52:50,155 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:52:50,430 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 15:52:54,254 : [INFO]  ------------------------- Batch round 1, loss: 0.5637 -------------------------
2023-03-25 15:52:54,254 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 15:52:54,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:54,543 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 15:52:56,537 : [INFO]  ------------------------- Batch round 2, loss: 0.5583 -------------------------
2023-03-25 15:52:56,537 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 15:52:56,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:56,651 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 15:52:58,673 : [INFO]  ------------------------- Batch round 3, loss: 0.5476 -------------------------
2023-03-25 15:52:58,673 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 15:52:58,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:52:58,833 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 15:52:58,833 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-25 15:53:00,087 : [INFO]  Batch 39: Training set : loss - 0.5501, accuracy - 0.75, recall - 0.9674, AUC - 0.8931, F1 - 0.7946, precision - 0.6742, training time - -8.0 seconds
2023-03-25 15:53:00,087 : [INFO]  Batch 39: Testing set : loss - 0.5371, accuracy - 0.7745, recall - 0.9804, AUC - 0.9212, F1 - 0.813, precision - 0.6944
2023-03-25 15:53:00,099 : [INFO]  Batch 40 initialized 
2023-03-25 15:53:00,522 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:00,815 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 15:53:04,824 : [INFO]  ------------------------- Batch round 1, loss: 0.5644 -------------------------
2023-03-25 15:53:04,825 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:05,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:05,055 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 15:53:07,468 : [INFO]  ------------------------- Batch round 2, loss: 0.5585 -------------------------
2023-03-25 15:53:07,468 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:07,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:07,473 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 15:53:09,566 : [INFO]  ------------------------- Batch round 3, loss: 0.5477 -------------------------
2023-03-25 15:53:09,567 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:09,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:09,795 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 15:53:09,795 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-25 15:53:11,089 : [INFO]  Batch 40: Training set : loss - 0.5432, accuracy - 0.7826, recall - 0.8696, AUC - 0.8695, F1 - 0.8, precision - 0.7407, training time - -9.0 seconds
2023-03-25 15:53:11,089 : [INFO]  Batch 40: Testing set : loss - 0.5689, accuracy - 0.7353, recall - 0.8725, AUC - 0.8724, F1 - 0.7672, precision - 0.6846
2023-03-25 15:53:11,102 : [INFO]  Batch 41 initialized 
2023-03-25 15:53:11,533 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:11,831 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 15:53:15,745 : [INFO]  ------------------------- Batch round 1, loss: 0.5426 -------------------------
2023-03-25 15:53:15,745 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:15,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:15,917 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 15:53:18,060 : [INFO]  ------------------------- Batch round 2, loss: 0.5379 -------------------------
2023-03-25 15:53:18,060 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:18,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:18,169 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 15:53:20,285 : [INFO]  ------------------------- Batch round 3, loss: 0.5232 -------------------------
2023-03-25 15:53:20,285 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:20,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:20,380 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 15:53:20,380 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-25 15:53:21,723 : [INFO]  Batch 41: Training set : loss - 0.5328, accuracy - 0.7663, recall - 0.9674, AUC - 0.9249, F1 - 0.8054, precision - 0.6899, training time - -9.0 seconds
2023-03-25 15:53:21,723 : [INFO]  Batch 41: Testing set : loss - 0.5741, accuracy - 0.7059, recall - 0.8922, AUC - 0.8616, F1 - 0.7521, precision - 0.65
2023-03-25 15:53:21,736 : [INFO]  Batch 42 initialized 
2023-03-25 15:53:22,178 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:22,485 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 15:53:26,334 : [INFO]  ------------------------- Batch round 1, loss: 0.5324 -------------------------
2023-03-25 15:53:26,334 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:26,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:26,592 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 15:53:28,621 : [INFO]  ------------------------- Batch round 2, loss: 0.5257 -------------------------
2023-03-25 15:53:28,621 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:28,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:28,799 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 15:53:30,735 : [INFO]  ------------------------- Batch round 3, loss: 0.5232 -------------------------
2023-03-25 15:53:30,735 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:31,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:31,206 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 15:53:31,206 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-25 15:53:32,477 : [INFO]  Batch 42: Training set : loss - 0.5094, accuracy - 0.8424, recall - 0.9565, AUC - 0.9226, F1 - 0.8585, precision - 0.7788, training time - -9.0 seconds
2023-03-25 15:53:32,477 : [INFO]  Batch 42: Testing set : loss - 0.5515, accuracy - 0.7451, recall - 0.9216, AUC - 0.8907, F1 - 0.7833, precision - 0.6812
2023-03-25 15:53:32,490 : [INFO]  Batch 43 initialized 
2023-03-25 15:53:32,922 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:33,242 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 15:53:37,028 : [INFO]  ------------------------- Batch round 1, loss: 0.5955 -------------------------
2023-03-25 15:53:37,028 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:37,234 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:37,237 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 15:53:39,242 : [INFO]  ------------------------- Batch round 2, loss: 0.5883 -------------------------
2023-03-25 15:53:39,242 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:39,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:39,420 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 15:53:41,444 : [INFO]  ------------------------- Batch round 3, loss: 0.5725 -------------------------
2023-03-25 15:53:41,444 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:41,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:41,613 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 15:53:41,613 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-25 15:53:42,896 : [INFO]  Batch 43: Training set : loss - 0.5751, accuracy - 0.7337, recall - 0.9022, AUC - 0.8366, F1 - 0.7721, precision - 0.6748, training time - -8.0 seconds
2023-03-25 15:53:42,896 : [INFO]  Batch 43: Testing set : loss - 0.5378, accuracy - 0.7696, recall - 0.9314, AUC - 0.8915, F1 - 0.8017, precision - 0.7037
2023-03-25 15:53:42,909 : [INFO]  Batch 44 initialized 
2023-03-25 15:53:43,338 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:43,646 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 15:53:47,407 : [INFO]  ------------------------- Batch round 1, loss: 0.5441 -------------------------
2023-03-25 15:53:47,407 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:47,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:47,851 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 15:53:49,852 : [INFO]  ------------------------- Batch round 2, loss: 0.5317 -------------------------
2023-03-25 15:53:49,852 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 15:53:50,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:50,024 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 15:53:52,302 : [INFO]  ------------------------- Batch round 3, loss: 0.5248 -------------------------
2023-03-25 15:53:52,303 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 15:53:52,305 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:52,307 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 15:53:52,307 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-25 15:53:53,597 : [INFO]  Batch 44: Training set : loss - 0.5309, accuracy - 0.7609, recall - 0.9239, AUC - 0.9086, F1 - 0.7944, precision - 0.6967, training time - -9.0 seconds
2023-03-25 15:53:53,597 : [INFO]  Batch 44: Testing set : loss - 0.5784, accuracy - 0.6912, recall - 0.8824, AUC - 0.8613, F1 - 0.7407, precision - 0.6383
2023-03-25 15:53:53,631 : [INFO]  Batch 45 initialized 
2023-03-25 15:53:54,060 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:53:54,376 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 15:53:58,223 : [INFO]  ------------------------- Batch round 1, loss: 0.5521 -------------------------
2023-03-25 15:53:58,223 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 15:53:58,501 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:53:58,502 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 15:54:00,549 : [INFO]  ------------------------- Batch round 2, loss: 0.5433 -------------------------
2023-03-25 15:54:00,549 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:00,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:00,803 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 15:54:03,134 : [INFO]  ------------------------- Batch round 3, loss: 0.5443 -------------------------
2023-03-25 15:54:03,134 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:03,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:03,141 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 15:54:03,141 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-25 15:54:04,429 : [INFO]  Batch 45: Training set : loss - 0.539, accuracy - 0.8043, recall - 0.9457, AUC - 0.9202, F1 - 0.8286, precision - 0.7373, training time - -9.0 seconds
2023-03-25 15:54:04,430 : [INFO]  Batch 45: Testing set : loss - 0.5577, accuracy - 0.7353, recall - 0.9314, AUC - 0.9035, F1 - 0.7787, precision - 0.669
2023-03-25 15:54:04,442 : [INFO]  Batch 46 initialized 
2023-03-25 15:54:04,864 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:05,183 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 15:54:09,124 : [INFO]  ------------------------- Batch round 1, loss: 0.5622 -------------------------
2023-03-25 15:54:09,124 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:09,260 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:09,262 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 15:54:11,321 : [INFO]  ------------------------- Batch round 2, loss: 0.5539 -------------------------
2023-03-25 15:54:11,321 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:11,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:11,469 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 15:54:13,603 : [INFO]  ------------------------- Batch round 3, loss: 0.5513 -------------------------
2023-03-25 15:54:13,603 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:13,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:13,766 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 15:54:13,766 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-25 15:54:15,087 : [INFO]  Batch 46: Training set : loss - 0.5512, accuracy - 0.75, recall - 0.8804, AUC - 0.8648, F1 - 0.7788, precision - 0.6983, training time - -9.0 seconds
2023-03-25 15:54:15,087 : [INFO]  Batch 46: Testing set : loss - 0.5864, accuracy - 0.6667, recall - 0.8529, AUC - 0.849, F1 - 0.719, precision - 0.6214
2023-03-25 15:54:15,107 : [INFO]  Batch 47 initialized 
2023-03-25 15:54:15,535 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:15,843 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 15:54:19,711 : [INFO]  ------------------------- Batch round 1, loss: 0.5921 -------------------------
2023-03-25 15:54:19,712 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:19,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:19,852 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 15:54:21,921 : [INFO]  ------------------------- Batch round 2, loss: 0.582 -------------------------
2023-03-25 15:54:21,921 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:22,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:22,028 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 15:54:24,152 : [INFO]  ------------------------- Batch round 3, loss: 0.5764 -------------------------
2023-03-25 15:54:24,152 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:24,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:24,257 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 15:54:24,258 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-25 15:54:25,592 : [INFO]  Batch 47: Training set : loss - 0.5866, accuracy - 0.7011, recall - 0.8913, AUC - 0.8046, F1 - 0.7489, precision - 0.6457, training time - -8.0 seconds
2023-03-25 15:54:25,592 : [INFO]  Batch 47: Testing set : loss - 0.5826, accuracy - 0.7206, recall - 0.8627, AUC - 0.8178, F1 - 0.7554, precision - 0.6718
2023-03-25 15:54:25,606 : [INFO]  Batch 48 initialized 
2023-03-25 15:54:26,026 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:26,350 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 15:54:30,255 : [INFO]  ------------------------- Batch round 1, loss: 0.5795 -------------------------
2023-03-25 15:54:30,255 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:30,336 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:30,338 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 15:54:32,548 : [INFO]  ------------------------- Batch round 2, loss: 0.5592 -------------------------
2023-03-25 15:54:32,548 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:32,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:32,583 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 15:54:34,685 : [INFO]  ------------------------- Batch round 3, loss: 0.5502 -------------------------
2023-03-25 15:54:34,685 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:34,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:34,760 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 15:54:34,760 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-25 15:54:36,093 : [INFO]  Batch 48: Training set : loss - 0.5532, accuracy - 0.7663, recall - 0.9783, AUC - 0.894, F1 - 0.8072, precision - 0.687, training time - -8.0 seconds
2023-03-25 15:54:36,093 : [INFO]  Batch 48: Testing set : loss - 0.5576, accuracy - 0.7304, recall - 0.9216, AUC - 0.9015, F1 - 0.7737, precision - 0.6667
2023-03-25 15:54:36,101 : [INFO]  Batch 49 initialized 
2023-03-25 15:54:36,521 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:36,843 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 15:54:40,851 : [INFO]  ------------------------- Batch round 1, loss: 0.593 -------------------------
2023-03-25 15:54:40,851 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:40,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:40,908 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 15:54:43,121 : [INFO]  ------------------------- Batch round 2, loss: 0.5846 -------------------------
2023-03-25 15:54:43,121 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:43,146 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:43,148 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 15:54:45,348 : [INFO]  ------------------------- Batch round 3, loss: 0.5671 -------------------------
2023-03-25 15:54:45,348 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:45,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:45,382 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 15:54:45,382 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-25 15:54:46,726 : [INFO]  Batch 49: Training set : loss - 0.5747, accuracy - 0.7228, recall - 0.8696, AUC - 0.8631, F1 - 0.7583, precision - 0.6723, training time - -9.0 seconds
2023-03-25 15:54:46,726 : [INFO]  Batch 49: Testing set : loss - 0.5987, accuracy - 0.6618, recall - 0.8529, AUC - 0.8051, F1 - 0.716, precision - 0.617
2023-03-25 15:54:46,741 : [INFO]  Batch 50 initialized 
2023-03-25 15:54:47,167 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:47,507 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 15:54:51,363 : [INFO]  ------------------------- Batch round 1, loss: 0.5388 -------------------------
2023-03-25 15:54:51,363 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 15:54:51,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:51,487 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 15:54:53,594 : [INFO]  ------------------------- Batch round 2, loss: 0.5346 -------------------------
2023-03-25 15:54:53,594 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 15:54:53,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:53,716 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 15:54:55,785 : [INFO]  ------------------------- Batch round 3, loss: 0.5271 -------------------------
2023-03-25 15:54:55,785 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 15:54:55,868 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:54:55,870 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 15:54:55,870 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-25 15:54:57,157 : [INFO]  Batch 50: Training set : loss - 0.5273, accuracy - 0.8152, recall - 0.9239, AUC - 0.8943, F1 - 0.8333, precision - 0.7589, training time - -8.0 seconds
2023-03-25 15:54:57,157 : [INFO]  Batch 50: Testing set : loss - 0.5746, accuracy - 0.7108, recall - 0.8333, AUC - 0.8647, F1 - 0.7424, precision - 0.6693
2023-03-25 15:54:57,172 : [INFO]  Batch 51 initialized 
2023-03-25 15:54:57,613 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:54:57,941 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 15:55:01,780 : [INFO]  ------------------------- Batch round 1, loss: 0.5701 -------------------------
2023-03-25 15:55:01,780 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:01,934 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:01,936 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 15:55:04,020 : [INFO]  ------------------------- Batch round 2, loss: 0.5526 -------------------------
2023-03-25 15:55:04,020 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:04,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:04,133 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 15:55:06,291 : [INFO]  ------------------------- Batch round 3, loss: 0.551 -------------------------
2023-03-25 15:55:06,291 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:06,379 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:06,381 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 15:55:06,381 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-25 15:55:07,672 : [INFO]  Batch 51: Training set : loss - 0.5551, accuracy - 0.7717, recall - 0.9457, AUC - 0.8945, F1 - 0.8056, precision - 0.7016, training time - -8.0 seconds
2023-03-25 15:55:07,673 : [INFO]  Batch 51: Testing set : loss - 0.5634, accuracy - 0.7255, recall - 0.8824, AUC - 0.8918, F1 - 0.7627, precision - 0.6716
2023-03-25 15:55:07,684 : [INFO]  Batch 52 initialized 
2023-03-25 15:55:08,106 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:08,443 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 15:55:12,380 : [INFO]  ------------------------- Batch round 1, loss: 0.5777 -------------------------
2023-03-25 15:55:12,380 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:12,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:12,483 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 15:55:14,602 : [INFO]  ------------------------- Batch round 2, loss: 0.5696 -------------------------
2023-03-25 15:55:14,602 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:14,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:14,657 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 15:55:16,743 : [INFO]  ------------------------- Batch round 3, loss: 0.5669 -------------------------
2023-03-25 15:55:16,743 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:16,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:16,783 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 15:55:16,783 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-25 15:55:18,083 : [INFO]  Batch 52: Training set : loss - 0.5659, accuracy - 0.7283, recall - 0.8478, AUC - 0.8463, F1 - 0.7573, precision - 0.6842, training time - -8.0 seconds
2023-03-25 15:55:18,083 : [INFO]  Batch 52: Testing set : loss - 0.5813, accuracy - 0.6912, recall - 0.8725, AUC - 0.8515, F1 - 0.7386, precision - 0.6403
2023-03-25 15:55:18,096 : [INFO]  Batch 53 initialized 
2023-03-25 15:55:18,538 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:18,877 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 15:55:22,731 : [INFO]  ------------------------- Batch round 1, loss: 0.5629 -------------------------
2023-03-25 15:55:22,731 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:22,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:22,960 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 15:55:24,976 : [INFO]  ------------------------- Batch round 2, loss: 0.5511 -------------------------
2023-03-25 15:55:24,976 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:25,168 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:25,170 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 15:55:27,222 : [INFO]  ------------------------- Batch round 3, loss: 0.5478 -------------------------
2023-03-25 15:55:27,222 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:27,417 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:27,419 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 15:55:27,419 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-25 15:55:28,736 : [INFO]  Batch 53: Training set : loss - 0.5494, accuracy - 0.7663, recall - 0.9457, AUC - 0.8888, F1 - 0.8018, precision - 0.696, training time - -9.0 seconds
2023-03-25 15:55:28,736 : [INFO]  Batch 53: Testing set : loss - 0.5642, accuracy - 0.7598, recall - 0.9216, AUC - 0.8818, F1 - 0.7932, precision - 0.6963
2023-03-25 15:55:28,748 : [INFO]  Batch 54 initialized 
2023-03-25 15:55:29,174 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:29,507 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 15:55:33,322 : [INFO]  ------------------------- Batch round 1, loss: 0.5425 -------------------------
2023-03-25 15:55:33,322 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:33,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:33,584 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 15:55:35,625 : [INFO]  ------------------------- Batch round 2, loss: 0.5326 -------------------------
2023-03-25 15:55:35,625 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:36,031 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:36,033 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 15:55:38,043 : [INFO]  ------------------------- Batch round 3, loss: 0.5192 -------------------------
2023-03-25 15:55:38,043 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:38,257 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:38,259 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 15:55:38,259 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-25 15:55:39,512 : [INFO]  Batch 54: Training set : loss - 0.5172, accuracy - 0.8043, recall - 0.9565, AUC - 0.9325, F1 - 0.8302, precision - 0.7333, training time - -9.0 seconds
2023-03-25 15:55:39,512 : [INFO]  Batch 54: Testing set : loss - 0.5518, accuracy - 0.7549, recall - 0.9608, AUC - 0.9144, F1 - 0.7967, precision - 0.6806
2023-03-25 15:55:39,524 : [INFO]  Batch 55 initialized 
2023-03-25 15:55:39,960 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:40,252 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 15:55:44,314 : [INFO]  ------------------------- Batch round 1, loss: 0.5838 -------------------------
2023-03-25 15:55:44,314 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:44,675 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:44,677 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 15:55:46,668 : [INFO]  ------------------------- Batch round 2, loss: 0.5776 -------------------------
2023-03-25 15:55:46,669 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:47,159 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:47,161 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 15:55:49,147 : [INFO]  ------------------------- Batch round 3, loss: 0.5638 -------------------------
2023-03-25 15:55:49,147 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:49,289 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:49,292 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 15:55:49,292 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-25 15:55:50,584 : [INFO]  Batch 55: Training set : loss - 0.5735, accuracy - 0.7065, recall - 0.8913, AUC - 0.8429, F1 - 0.7523, precision - 0.6508, training time - -9.0 seconds
2023-03-25 15:55:50,584 : [INFO]  Batch 55: Testing set : loss - 0.5593, accuracy - 0.7353, recall - 0.9608, AUC - 0.8888, F1 - 0.784, precision - 0.6622
2023-03-25 15:55:50,596 : [INFO]  Batch 56 initialized 
2023-03-25 15:55:51,019 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:55:51,343 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 15:55:55,257 : [INFO]  ------------------------- Batch round 1, loss: 0.5778 -------------------------
2023-03-25 15:55:55,257 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 15:55:55,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:55,354 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 15:55:57,498 : [INFO]  ------------------------- Batch round 2, loss: 0.574 -------------------------
2023-03-25 15:55:57,498 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 15:55:57,546 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:57,548 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 15:55:59,650 : [INFO]  ------------------------- Batch round 3, loss: 0.5632 -------------------------
2023-03-25 15:55:59,650 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 15:55:59,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:55:59,709 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 15:55:59,709 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-25 15:56:01,042 : [INFO]  Batch 56: Training set : loss - 0.5631, accuracy - 0.7011, recall - 0.8913, AUC - 0.8784, F1 - 0.7489, precision - 0.6457, training time - -8.0 seconds
2023-03-25 15:56:01,043 : [INFO]  Batch 56: Testing set : loss - 0.5816, accuracy - 0.6912, recall - 0.8922, AUC - 0.8584, F1 - 0.7429, precision - 0.6364
2023-03-25 15:56:01,054 : [INFO]  Batch 57 initialized 
2023-03-25 15:56:01,476 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:01,827 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 15:56:05,775 : [INFO]  ------------------------- Batch round 1, loss: 0.5903 -------------------------
2023-03-25 15:56:05,775 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:05,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:05,780 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 15:56:07,936 : [INFO]  ------------------------- Batch round 2, loss: 0.5778 -------------------------
2023-03-25 15:56:07,936 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:07,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:07,941 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 15:56:10,188 : [INFO]  ------------------------- Batch round 3, loss: 0.561 -------------------------
2023-03-25 15:56:10,188 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:10,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:10,192 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 15:56:10,192 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-25 15:56:11,534 : [INFO]  Batch 57: Training set : loss - 0.5568, accuracy - 0.7609, recall - 0.9457, AUC - 0.8728, F1 - 0.7982, precision - 0.6905, training time - -8.0 seconds
2023-03-25 15:56:11,534 : [INFO]  Batch 57: Testing set : loss - 0.5719, accuracy - 0.701, recall - 0.8922, AUC - 0.8591, F1 - 0.749, precision - 0.6454
2023-03-25 15:56:11,544 : [INFO]  Batch 58 initialized 
2023-03-25 15:56:11,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:12,309 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 15:56:16,184 : [INFO]  ------------------------- Batch round 1, loss: 0.5547 -------------------------
2023-03-25 15:56:16,184 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:16,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:16,312 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 15:56:18,388 : [INFO]  ------------------------- Batch round 2, loss: 0.556 -------------------------
2023-03-25 15:56:18,388 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:18,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:18,434 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 15:56:20,530 : [INFO]  ------------------------- Batch round 3, loss: 0.5454 -------------------------
2023-03-25 15:56:20,530 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:20,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:20,563 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 15:56:20,563 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-25 15:56:21,843 : [INFO]  Batch 58: Training set : loss - 0.5395, accuracy - 0.7935, recall - 0.913, AUC - 0.8904, F1 - 0.8155, precision - 0.7368, training time - -8.0 seconds
2023-03-25 15:56:21,843 : [INFO]  Batch 58: Testing set : loss - 0.573, accuracy - 0.6912, recall - 0.8529, AUC - 0.8504, F1 - 0.7342, precision - 0.6444
2023-03-25 15:56:21,857 : [INFO]  Batch 59 initialized 
2023-03-25 15:56:22,285 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:22,625 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 15:56:26,458 : [INFO]  ------------------------- Batch round 1, loss: 0.539 -------------------------
2023-03-25 15:56:26,458 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:26,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:26,665 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 15:56:28,712 : [INFO]  ------------------------- Batch round 2, loss: 0.5369 -------------------------
2023-03-25 15:56:28,712 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:28,806 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:28,808 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 15:56:30,827 : [INFO]  ------------------------- Batch round 3, loss: 0.5282 -------------------------
2023-03-25 15:56:30,827 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:30,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:30,941 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 15:56:30,942 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-25 15:56:32,235 : [INFO]  Batch 59: Training set : loss - 0.5223, accuracy - 0.8098, recall - 0.9348, AUC - 0.9044, F1 - 0.8309, precision - 0.7478, training time - -8.0 seconds
2023-03-25 15:56:32,235 : [INFO]  Batch 59: Testing set : loss - 0.5545, accuracy - 0.7402, recall - 0.8725, AUC - 0.8723, F1 - 0.7706, precision - 0.6899
2023-03-25 15:56:32,243 : [INFO]  Batch 60 initialized 
2023-03-25 15:56:32,680 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:33,008 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 15:56:36,900 : [INFO]  ------------------------- Batch round 1, loss: 0.5372 -------------------------
2023-03-25 15:56:36,900 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:37,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:37,078 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 15:56:39,189 : [INFO]  ------------------------- Batch round 2, loss: 0.526 -------------------------
2023-03-25 15:56:39,190 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:39,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:39,292 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 15:56:41,360 : [INFO]  ------------------------- Batch round 3, loss: 0.5165 -------------------------
2023-03-25 15:56:41,360 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:41,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:41,474 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 15:56:41,474 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-25 15:56:42,784 : [INFO]  Batch 60: Training set : loss - 0.5142, accuracy - 0.8207, recall - 0.9674, AUC - 0.8979, F1 - 0.8436, precision - 0.7479, training time - -8.0 seconds
2023-03-25 15:56:42,784 : [INFO]  Batch 60: Testing set : loss - 0.5799, accuracy - 0.6863, recall - 0.951, AUC - 0.8728, F1 - 0.7519, precision - 0.6218
2023-03-25 15:56:42,797 : [INFO]  Batch 61 initialized 
2023-03-25 15:56:43,231 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:43,577 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 15:56:47,379 : [INFO]  ------------------------- Batch round 1, loss: 0.5291 -------------------------
2023-03-25 15:56:47,379 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:47,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:47,621 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 15:56:49,703 : [INFO]  ------------------------- Batch round 2, loss: 0.5243 -------------------------
2023-03-25 15:56:49,703 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 15:56:49,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:49,887 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 15:56:51,910 : [INFO]  ------------------------- Batch round 3, loss: 0.5147 -------------------------
2023-03-25 15:56:51,911 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 15:56:52,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:52,119 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 15:56:52,119 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-25 15:56:53,450 : [INFO]  Batch 61: Training set : loss - 0.5114, accuracy - 0.8098, recall - 0.9891, AUC - 0.9425, F1 - 0.8387, precision - 0.728, training time - -9.0 seconds
2023-03-25 15:56:53,451 : [INFO]  Batch 61: Testing set : loss - 0.5665, accuracy - 0.7402, recall - 0.9216, AUC - 0.8766, F1 - 0.7801, precision - 0.6763
2023-03-25 15:56:53,465 : [INFO]  Batch 62 initialized 
2023-03-25 15:56:53,898 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:56:54,239 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 15:56:58,187 : [INFO]  ------------------------- Batch round 1, loss: 0.5796 -------------------------
2023-03-25 15:56:58,187 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 15:56:58,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:56:58,401 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 15:57:00,493 : [INFO]  ------------------------- Batch round 2, loss: 0.5676 -------------------------
2023-03-25 15:57:00,493 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:00,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:00,650 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 15:57:02,777 : [INFO]  ------------------------- Batch round 3, loss: 0.5625 -------------------------
2023-03-25 15:57:02,777 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:02,931 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:02,933 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 15:57:02,933 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-25 15:57:04,224 : [INFO]  Batch 62: Training set : loss - 0.5673, accuracy - 0.7609, recall - 0.9457, AUC - 0.8566, F1 - 0.7982, precision - 0.6905, training time - -9.0 seconds
2023-03-25 15:57:04,224 : [INFO]  Batch 62: Testing set : loss - 0.5606, accuracy - 0.7206, recall - 0.9412, AUC - 0.9128, F1 - 0.7711, precision - 0.6531
2023-03-25 15:57:04,232 : [INFO]  Batch 63 initialized 
2023-03-25 15:57:04,671 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:05,014 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 15:57:08,806 : [INFO]  ------------------------- Batch round 1, loss: 0.5425 -------------------------
2023-03-25 15:57:08,806 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:09,075 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:09,077 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 15:57:11,111 : [INFO]  ------------------------- Batch round 2, loss: 0.5255 -------------------------
2023-03-25 15:57:11,112 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:11,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:11,297 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 15:57:13,315 : [INFO]  ------------------------- Batch round 3, loss: 0.5258 -------------------------
2023-03-25 15:57:13,315 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:13,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:13,469 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 15:57:13,469 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-25 15:57:14,798 : [INFO]  Batch 63: Training set : loss - 0.5172, accuracy - 0.7554, recall - 0.9348, AUC - 0.9185, F1 - 0.7926, precision - 0.688, training time - -8.0 seconds
2023-03-25 15:57:14,798 : [INFO]  Batch 63: Testing set : loss - 0.5335, accuracy - 0.7451, recall - 0.9216, AUC - 0.8966, F1 - 0.7833, precision - 0.6812
2023-03-25 15:57:14,805 : [INFO]  Batch 64 initialized 
2023-03-25 15:57:15,245 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:15,587 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 15:57:19,534 : [INFO]  ------------------------- Batch round 1, loss: 0.5509 -------------------------
2023-03-25 15:57:19,534 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:19,619 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:19,621 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 15:57:21,733 : [INFO]  ------------------------- Batch round 2, loss: 0.5493 -------------------------
2023-03-25 15:57:21,733 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:21,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:21,781 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 15:57:23,861 : [INFO]  ------------------------- Batch round 3, loss: 0.5421 -------------------------
2023-03-25 15:57:23,861 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:23,961 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:23,963 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 15:57:23,963 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-25 15:57:25,313 : [INFO]  Batch 64: Training set : loss - 0.5368, accuracy - 0.7391, recall - 0.8913, AUC - 0.8982, F1 - 0.7736, precision - 0.6833, training time - -8.0 seconds
2023-03-25 15:57:25,313 : [INFO]  Batch 64: Testing set : loss - 0.5649, accuracy - 0.6814, recall - 0.9216, AUC - 0.8856, F1 - 0.7431, precision - 0.6225
2023-03-25 15:57:25,320 : [INFO]  Batch 65 initialized 
2023-03-25 15:57:25,757 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:26,120 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 15:57:29,946 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 15:57:29,946 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:30,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:30,136 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 15:57:32,171 : [INFO]  ------------------------- Batch round 2, loss: 0.5632 -------------------------
2023-03-25 15:57:32,172 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:32,368 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:32,370 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 15:57:34,384 : [INFO]  ------------------------- Batch round 3, loss: 0.5481 -------------------------
2023-03-25 15:57:34,384 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:34,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:34,572 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 15:57:34,572 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-25 15:57:35,843 : [INFO]  Batch 65: Training set : loss - 0.5476, accuracy - 0.7663, recall - 0.9239, AUC - 0.8751, F1 - 0.7981, precision - 0.7025, training time - -8.0 seconds
2023-03-25 15:57:35,843 : [INFO]  Batch 65: Testing set : loss - 0.585, accuracy - 0.6716, recall - 0.8922, AUC - 0.857, F1 - 0.7309, precision - 0.619
2023-03-25 15:57:35,855 : [INFO]  Batch 66 initialized 
2023-03-25 15:57:36,285 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:36,622 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 15:57:40,553 : [INFO]  ------------------------- Batch round 1, loss: 0.5754 -------------------------
2023-03-25 15:57:40,553 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:40,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:40,664 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 15:57:42,746 : [INFO]  ------------------------- Batch round 2, loss: 0.5652 -------------------------
2023-03-25 15:57:42,746 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:42,822 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:42,824 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 15:57:44,949 : [INFO]  ------------------------- Batch round 3, loss: 0.5559 -------------------------
2023-03-25 15:57:44,949 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:44,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:44,961 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 15:57:44,961 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-25 15:57:46,255 : [INFO]  Batch 66: Training set : loss - 0.555, accuracy - 0.75, recall - 0.9239, AUC - 0.8788, F1 - 0.787, precision - 0.6855, training time - -8.0 seconds
2023-03-25 15:57:46,255 : [INFO]  Batch 66: Testing set : loss - 0.5941, accuracy - 0.6618, recall - 0.8824, AUC - 0.8344, F1 - 0.7229, precision - 0.6122
2023-03-25 15:57:46,267 : [INFO]  Batch 67 initialized 
2023-03-25 15:57:46,683 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:47,045 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 15:57:51,095 : [INFO]  ------------------------- Batch round 1, loss: 0.5373 -------------------------
2023-03-25 15:57:51,095 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 15:57:51,098 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:51,100 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 15:57:53,332 : [INFO]  ------------------------- Batch round 2, loss: 0.524 -------------------------
2023-03-25 15:57:53,332 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 15:57:53,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:53,337 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 15:57:55,552 : [INFO]  ------------------------- Batch round 3, loss: 0.525 -------------------------
2023-03-25 15:57:55,552 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 15:57:55,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:57:55,557 : [INFO]  Batch number 67 model fetched from the server
2023-03-25 15:57:55,557 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-25 15:57:56,931 : [INFO]  Batch 67: Training set : loss - 0.5206, accuracy - 0.7717, recall - 0.9348, AUC - 0.9099, F1 - 0.8037, precision - 0.7049, training time - -9.0 seconds
2023-03-25 15:57:56,931 : [INFO]  Batch 67: Testing set : loss - 0.5748, accuracy - 0.7157, recall - 0.8824, AUC - 0.8385, F1 - 0.7563, precision - 0.6618
2023-03-25 15:57:56,939 : [INFO]  Batch 68 initialized 
2023-03-25 15:57:57,367 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:57:57,731 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-25 15:58:01,862 : [INFO]  ------------------------- Batch round 1, loss: 0.5403 -------------------------
2023-03-25 15:58:01,862 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:01,865 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:01,867 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-25 15:58:03,944 : [INFO]  ------------------------- Batch round 2, loss: 0.5451 -------------------------
2023-03-25 15:58:03,944 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:04,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:04,099 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-25 15:58:06,184 : [INFO]  ------------------------- Batch round 3, loss: 0.5318 -------------------------
2023-03-25 15:58:06,184 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:06,300 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:06,302 : [INFO]  Batch number 68 model fetched from the server
2023-03-25 15:58:06,302 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-25 15:58:07,616 : [INFO]  Batch 68: Training set : loss - 0.5268, accuracy - 0.7826, recall - 0.913, AUC - 0.9068, F1 - 0.8077, precision - 0.7241, training time - -9.0 seconds
2023-03-25 15:58:07,616 : [INFO]  Batch 68: Testing set : loss - 0.5563, accuracy - 0.7745, recall - 0.9216, AUC - 0.8661, F1 - 0.8034, precision - 0.7121
2023-03-25 15:58:07,628 : [INFO]  Batch 69 initialized 
2023-03-25 15:58:08,061 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:08,403 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-25 15:58:12,344 : [INFO]  ------------------------- Batch round 1, loss: 0.555 -------------------------
2023-03-25 15:58:12,344 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:12,490 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:12,492 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-25 15:58:14,599 : [INFO]  ------------------------- Batch round 2, loss: 0.542 -------------------------
2023-03-25 15:58:14,600 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:14,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:14,662 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-25 15:58:16,821 : [INFO]  ------------------------- Batch round 3, loss: 0.5403 -------------------------
2023-03-25 15:58:16,821 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:16,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:16,883 : [INFO]  Batch number 69 model fetched from the server
2023-03-25 15:58:16,883 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-25 15:58:18,196 : [INFO]  Batch 69: Training set : loss - 0.5368, accuracy - 0.7717, recall - 0.8913, AUC - 0.8762, F1 - 0.7961, precision - 0.7193, training time - -8.0 seconds
2023-03-25 15:58:18,196 : [INFO]  Batch 69: Testing set : loss - 0.5648, accuracy - 0.701, recall - 0.9118, AUC - 0.8748, F1 - 0.753, precision - 0.6414
2023-03-25 15:58:18,210 : [INFO]  Batch 70 initialized 
2023-03-25 15:58:18,634 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:18,986 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-25 15:58:22,883 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 15:58:22,883 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:23,000 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:23,002 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-25 15:58:25,118 : [INFO]  ------------------------- Batch round 2, loss: 0.5556 -------------------------
2023-03-25 15:58:25,118 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:25,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:25,197 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-25 15:58:27,561 : [INFO]  ------------------------- Batch round 3, loss: 0.5457 -------------------------
2023-03-25 15:58:27,561 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:27,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:27,565 : [INFO]  Batch number 70 model fetched from the server
2023-03-25 15:58:27,565 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-25 15:58:28,862 : [INFO]  Batch 70: Training set : loss - 0.5452, accuracy - 0.7554, recall - 0.9348, AUC - 0.8778, F1 - 0.7926, precision - 0.688, training time - -9.0 seconds
2023-03-25 15:58:28,862 : [INFO]  Batch 70: Testing set : loss - 0.5571, accuracy - 0.7598, recall - 0.8725, AUC - 0.8506, F1 - 0.7841, precision - 0.712
2023-03-25 15:58:28,874 : [INFO]  Batch 71 initialized 
2023-03-25 15:58:29,321 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:29,681 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-25 15:58:33,500 : [INFO]  ------------------------- Batch round 1, loss: 0.5461 -------------------------
2023-03-25 15:58:33,500 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:33,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:33,693 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-25 15:58:35,956 : [INFO]  ------------------------- Batch round 2, loss: 0.536 -------------------------
2023-03-25 15:58:35,957 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:35,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:35,961 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-25 15:58:37,979 : [INFO]  ------------------------- Batch round 3, loss: 0.527 -------------------------
2023-03-25 15:58:37,979 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:38,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:38,164 : [INFO]  Batch number 71 model fetched from the server
2023-03-25 15:58:38,164 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-25 15:58:39,438 : [INFO]  Batch 71: Training set : loss - 0.5266, accuracy - 0.7772, recall - 0.9348, AUC - 0.9081, F1 - 0.8075, precision - 0.7107, training time - -8.0 seconds
2023-03-25 15:58:39,438 : [INFO]  Batch 71: Testing set : loss - 0.5749, accuracy - 0.6961, recall - 0.8529, AUC - 0.848, F1 - 0.7373, precision - 0.6493
2023-03-25 15:58:39,450 : [INFO]  Batch 72 initialized 
2023-03-25 15:58:39,883 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:40,245 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-25 15:58:44,083 : [INFO]  ------------------------- Batch round 1, loss: 0.5592 -------------------------
2023-03-25 15:58:44,083 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:44,391 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:44,393 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-25 15:58:46,388 : [INFO]  ------------------------- Batch round 2, loss: 0.5562 -------------------------
2023-03-25 15:58:46,388 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:46,633 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:46,634 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-25 15:58:48,568 : [INFO]  ------------------------- Batch round 3, loss: 0.5509 -------------------------
2023-03-25 15:58:48,568 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:48,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:48,853 : [INFO]  Batch number 72 model fetched from the server
2023-03-25 15:58:48,853 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-25 15:58:50,079 : [INFO]  Batch 72: Training set : loss - 0.558, accuracy - 0.712, recall - 0.9348, AUC - 0.8955, F1 - 0.7644, precision - 0.6466, training time - -9.0 seconds
2023-03-25 15:58:50,079 : [INFO]  Batch 72: Testing set : loss - 0.5708, accuracy - 0.7304, recall - 0.9412, AUC - 0.8867, F1 - 0.7773, precision - 0.6621
2023-03-25 15:58:50,091 : [INFO]  Batch 73 initialized 
2023-03-25 15:58:50,524 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:58:50,859 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-25 15:58:54,744 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-25 15:58:54,744 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-25 15:58:54,979 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:54,981 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-25 15:58:57,060 : [INFO]  ------------------------- Batch round 2, loss: 0.5421 -------------------------
2023-03-25 15:58:57,060 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-25 15:58:57,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:57,220 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-25 15:58:59,279 : [INFO]  ------------------------- Batch round 3, loss: 0.5393 -------------------------
2023-03-25 15:58:59,279 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-25 15:58:59,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:58:59,424 : [INFO]  Batch number 73 model fetched from the server
2023-03-25 15:58:59,424 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-25 15:59:00,691 : [INFO]  Batch 73: Training set : loss - 0.534, accuracy - 0.7772, recall - 0.9348, AUC - 0.9013, F1 - 0.8075, precision - 0.7107, training time - -9.0 seconds
2023-03-25 15:59:00,691 : [INFO]  Batch 73: Testing set : loss - 0.5694, accuracy - 0.7108, recall - 0.9412, AUC - 0.8733, F1 - 0.7649, precision - 0.6443
2023-03-25 15:59:00,702 : [INFO]  Batch 74 initialized 
2023-03-25 15:59:01,156 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:01,515 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-25 15:59:05,332 : [INFO]  ------------------------- Batch round 1, loss: 0.5511 -------------------------
2023-03-25 15:59:05,333 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:05,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:05,481 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-25 15:59:07,502 : [INFO]  ------------------------- Batch round 2, loss: 0.5284 -------------------------
2023-03-25 15:59:07,502 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:07,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:07,664 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-25 15:59:09,696 : [INFO]  ------------------------- Batch round 3, loss: 0.5152 -------------------------
2023-03-25 15:59:09,696 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:09,829 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:09,830 : [INFO]  Batch number 74 model fetched from the server
2023-03-25 15:59:09,831 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-25 15:59:11,144 : [INFO]  Batch 74: Training set : loss - 0.5137, accuracy - 0.8152, recall - 0.9565, AUC - 0.9266, F1 - 0.8381, precision - 0.7458, training time - -8.0 seconds
2023-03-25 15:59:11,144 : [INFO]  Batch 74: Testing set : loss - 0.5617, accuracy - 0.7059, recall - 0.9118, AUC - 0.8889, F1 - 0.7561, precision - 0.6458
2023-03-25 15:59:11,156 : [INFO]  Batch 75 initialized 
2023-03-25 15:59:11,583 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:11,946 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-25 15:59:15,927 : [INFO]  ------------------------- Batch round 1, loss: 0.6015 -------------------------
2023-03-25 15:59:15,927 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:15,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:15,970 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-25 15:59:18,182 : [INFO]  ------------------------- Batch round 2, loss: 0.5855 -------------------------
2023-03-25 15:59:18,182 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:18,185 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:18,187 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-25 15:59:20,636 : [INFO]  ------------------------- Batch round 3, loss: 0.576 -------------------------
2023-03-25 15:59:20,636 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:20,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:20,655 : [INFO]  Batch number 75 model fetched from the server
2023-03-25 15:59:20,656 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-25 15:59:21,926 : [INFO]  Batch 75: Training set : loss - 0.5801, accuracy - 0.7283, recall - 0.8696, AUC - 0.8407, F1 - 0.7619, precision - 0.678, training time - -9.0 seconds
2023-03-25 15:59:21,926 : [INFO]  Batch 75: Testing set : loss - 0.5985, accuracy - 0.6765, recall - 0.8627, AUC - 0.8292, F1 - 0.7273, precision - 0.6286
2023-03-25 15:59:21,938 : [INFO]  Batch 76 initialized 
2023-03-25 15:59:22,373 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:22,750 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-25 15:59:26,772 : [INFO]  ------------------------- Batch round 1, loss: 0.6051 -------------------------
2023-03-25 15:59:26,772 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:26,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:26,805 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-25 15:59:29,017 : [INFO]  ------------------------- Batch round 2, loss: 0.5707 -------------------------
2023-03-25 15:59:29,017 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:29,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:29,029 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-25 15:59:31,175 : [INFO]  ------------------------- Batch round 3, loss: 0.5561 -------------------------
2023-03-25 15:59:31,176 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:31,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:31,232 : [INFO]  Batch number 76 model fetched from the server
2023-03-25 15:59:31,233 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-25 15:59:32,556 : [INFO]  Batch 76: Training set : loss - 0.5579, accuracy - 0.7772, recall - 0.9022, AUC - 0.8512, F1 - 0.8019, precision - 0.7217, training time - -8.0 seconds
2023-03-25 15:59:32,556 : [INFO]  Batch 76: Testing set : loss - 0.5784, accuracy - 0.701, recall - 0.902, AUC - 0.866, F1 - 0.751, precision - 0.6434
2023-03-25 15:59:32,567 : [INFO]  Batch 77 initialized 
2023-03-25 15:59:32,988 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:33,371 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-25 15:59:37,296 : [INFO]  ------------------------- Batch round 1, loss: 0.5817 -------------------------
2023-03-25 15:59:37,296 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:37,393 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:37,396 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-25 15:59:39,457 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 15:59:39,458 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:39,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:39,517 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-25 15:59:41,855 : [INFO]  ------------------------- Batch round 3, loss: 0.5572 -------------------------
2023-03-25 15:59:41,855 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:41,858 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:41,859 : [INFO]  Batch number 77 model fetched from the server
2023-03-25 15:59:41,859 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-25 15:59:43,160 : [INFO]  Batch 77: Training set : loss - 0.5604, accuracy - 0.75, recall - 0.9022, AUC - 0.8761, F1 - 0.783, precision - 0.6917, training time - -8.0 seconds
2023-03-25 15:59:43,160 : [INFO]  Batch 77: Testing set : loss - 0.5913, accuracy - 0.652, recall - 0.7843, AUC - 0.8151, F1 - 0.6926, precision - 0.6202
2023-03-25 15:59:43,173 : [INFO]  Batch 78 initialized 
2023-03-25 15:59:43,607 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:43,987 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-25 15:59:47,857 : [INFO]  ------------------------- Batch round 1, loss: 0.548 -------------------------
2023-03-25 15:59:47,857 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:48,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:48,026 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-25 15:59:50,023 : [INFO]  ------------------------- Batch round 2, loss: 0.5377 -------------------------
2023-03-25 15:59:50,023 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-25 15:59:50,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:50,181 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-25 15:59:52,206 : [INFO]  ------------------------- Batch round 3, loss: 0.5261 -------------------------
2023-03-25 15:59:52,206 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-25 15:59:52,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:52,336 : [INFO]  Batch number 78 model fetched from the server
2023-03-25 15:59:52,336 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-25 15:59:53,640 : [INFO]  Batch 78: Training set : loss - 0.5243, accuracy - 0.7989, recall - 0.9565, AUC - 0.9083, F1 - 0.8263, precision - 0.7273, training time - -8.0 seconds
2023-03-25 15:59:53,640 : [INFO]  Batch 78: Testing set : loss - 0.57, accuracy - 0.701, recall - 0.9118, AUC - 0.8912, F1 - 0.753, precision - 0.6414
2023-03-25 15:59:53,648 : [INFO]  Batch 79 initialized 
2023-03-25 15:59:54,075 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 15:59:54,471 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-25 15:59:58,461 : [INFO]  ------------------------- Batch round 1, loss: 0.5929 -------------------------
2023-03-25 15:59:58,461 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-25 15:59:58,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 15:59:58,466 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-25 16:00:00,630 : [INFO]  ------------------------- Batch round 2, loss: 0.5754 -------------------------
2023-03-25 16:00:00,630 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:00,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:00,872 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-25 16:00:03,066 : [INFO]  ------------------------- Batch round 3, loss: 0.5665 -------------------------
2023-03-25 16:00:03,066 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:03,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:03,072 : [INFO]  Batch number 79 model fetched from the server
2023-03-25 16:00:03,072 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-25 16:00:04,475 : [INFO]  Batch 79: Training set : loss - 0.5657, accuracy - 0.7446, recall - 0.8478, AUC - 0.8136, F1 - 0.7685, precision - 0.7027, training time - -9.0 seconds
2023-03-25 16:00:04,475 : [INFO]  Batch 79: Testing set : loss - 0.6142, accuracy - 0.652, recall - 0.7451, AUC - 0.7636, F1 - 0.6816, precision - 0.6281
2023-03-25 16:00:04,481 : [INFO]  Batch 80 initialized 
2023-03-25 16:00:04,900 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:05,287 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-25 16:00:09,315 : [INFO]  ------------------------- Batch round 1, loss: 0.6065 -------------------------
2023-03-25 16:00:09,315 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:09,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:09,514 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-25 16:00:11,570 : [INFO]  ------------------------- Batch round 2, loss: 0.5966 -------------------------
2023-03-25 16:00:11,570 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:11,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:11,811 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-25 16:00:14,102 : [INFO]  ------------------------- Batch round 3, loss: 0.5742 -------------------------
2023-03-25 16:00:14,102 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:14,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:14,107 : [INFO]  Batch number 80 model fetched from the server
2023-03-25 16:00:14,107 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-25 16:00:15,429 : [INFO]  Batch 80: Training set : loss - 0.5771, accuracy - 0.75, recall - 0.8478, AUC - 0.8072, F1 - 0.7723, precision - 0.7091, training time - -9.0 seconds
2023-03-25 16:00:15,429 : [INFO]  Batch 80: Testing set : loss - 0.5884, accuracy - 0.7059, recall - 0.8725, AUC - 0.851, F1 - 0.7479, precision - 0.6544
2023-03-25 16:00:15,440 : [INFO]  Batch 81 initialized 
2023-03-25 16:00:15,866 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:16,231 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-25 16:00:20,161 : [INFO]  ------------------------- Batch round 1, loss: 0.5748 -------------------------
2023-03-25 16:00:20,161 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:20,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:20,358 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-25 16:00:22,957 : [INFO]  ------------------------- Batch round 2, loss: 0.5613 -------------------------
2023-03-25 16:00:22,957 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:22,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:22,960 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-25 16:00:25,086 : [INFO]  ------------------------- Batch round 3, loss: 0.5544 -------------------------
2023-03-25 16:00:25,086 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:25,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:25,209 : [INFO]  Batch number 81 model fetched from the server
2023-03-25 16:00:25,209 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-25 16:00:26,498 : [INFO]  Batch 81: Training set : loss - 0.5517, accuracy - 0.7609, recall - 0.9457, AUC - 0.8534, F1 - 0.7982, precision - 0.6905, training time - -9.0 seconds
2023-03-25 16:00:26,498 : [INFO]  Batch 81: Testing set : loss - 0.5784, accuracy - 0.6765, recall - 0.9216, AUC - 0.8837, F1 - 0.7402, precision - 0.6184
2023-03-25 16:00:26,509 : [INFO]  Batch 82 initialized 
2023-03-25 16:00:26,936 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:27,318 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-25 16:00:31,194 : [INFO]  ------------------------- Batch round 1, loss: 0.5418 -------------------------
2023-03-25 16:00:31,195 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:31,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:31,675 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-25 16:00:33,667 : [INFO]  ------------------------- Batch round 2, loss: 0.544 -------------------------
2023-03-25 16:00:33,667 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:33,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:33,765 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-25 16:00:35,875 : [INFO]  ------------------------- Batch round 3, loss: 0.5521 -------------------------
2023-03-25 16:00:35,875 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:35,997 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:35,999 : [INFO]  Batch number 82 model fetched from the server
2023-03-25 16:00:35,999 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-25 16:00:37,301 : [INFO]  Batch 82: Training set : loss - 0.5403, accuracy - 0.788, recall - 0.913, AUC - 0.8764, F1 - 0.8116, precision - 0.7304, training time - -9.0 seconds
2023-03-25 16:00:37,301 : [INFO]  Batch 82: Testing set : loss - 0.5387, accuracy - 0.7941, recall - 0.9216, AUC - 0.901, F1 - 0.8174, precision - 0.7344
2023-03-25 16:00:37,315 : [INFO]  Batch 83 initialized 
2023-03-25 16:00:37,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:38,142 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-25 16:00:42,066 : [INFO]  ------------------------- Batch round 1, loss: 0.5492 -------------------------
2023-03-25 16:00:42,066 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:42,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:42,191 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-25 16:00:44,516 : [INFO]  ------------------------- Batch round 2, loss: 0.5525 -------------------------
2023-03-25 16:00:44,516 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:44,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:44,521 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-25 16:00:46,613 : [INFO]  ------------------------- Batch round 3, loss: 0.5435 -------------------------
2023-03-25 16:00:46,613 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:46,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:46,766 : [INFO]  Batch number 83 model fetched from the server
2023-03-25 16:00:46,766 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-25 16:00:48,044 : [INFO]  Batch 83: Training set : loss - 0.5366, accuracy - 0.7663, recall - 0.9348, AUC - 0.9039, F1 - 0.8, precision - 0.6992, training time - -9.0 seconds
2023-03-25 16:00:48,044 : [INFO]  Batch 83: Testing set : loss - 0.5469, accuracy - 0.7598, recall - 0.9314, AUC - 0.8733, F1 - 0.795, precision - 0.6934
2023-03-25 16:00:48,056 : [INFO]  Batch 84 initialized 
2023-03-25 16:00:48,503 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:48,885 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-25 16:00:52,716 : [INFO]  ------------------------- Batch round 1, loss: 0.5267 -------------------------
2023-03-25 16:00:52,716 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-25 16:00:53,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:53,003 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-25 16:00:55,027 : [INFO]  ------------------------- Batch round 2, loss: 0.521 -------------------------
2023-03-25 16:00:55,027 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-25 16:00:55,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:55,252 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-25 16:00:57,246 : [INFO]  ------------------------- Batch round 3, loss: 0.5163 -------------------------
2023-03-25 16:00:57,247 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-25 16:00:57,490 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:00:57,492 : [INFO]  Batch number 84 model fetched from the server
2023-03-25 16:00:57,492 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-25 16:00:58,777 : [INFO]  Batch 84: Training set : loss - 0.5173, accuracy - 0.8043, recall - 0.9891, AUC - 0.9501, F1 - 0.8349, precision - 0.7222, training time - -9.0 seconds
2023-03-25 16:00:58,777 : [INFO]  Batch 84: Testing set : loss - 0.5605, accuracy - 0.75, recall - 0.902, AUC - 0.8668, F1 - 0.783, precision - 0.6917
2023-03-25 16:00:58,790 : [INFO]  Batch 85 initialized 
2023-03-25 16:00:59,217 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:00:59,589 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-25 16:01:03,426 : [INFO]  ------------------------- Batch round 1, loss: 0.5958 -------------------------
2023-03-25 16:01:03,426 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:03,606 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:03,608 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-25 16:01:05,681 : [INFO]  ------------------------- Batch round 2, loss: 0.5925 -------------------------
2023-03-25 16:01:05,681 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:05,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:05,765 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-25 16:01:07,790 : [INFO]  ------------------------- Batch round 3, loss: 0.5865 -------------------------
2023-03-25 16:01:07,790 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:07,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:07,935 : [INFO]  Batch number 85 model fetched from the server
2023-03-25 16:01:07,935 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-25 16:01:09,213 : [INFO]  Batch 85: Training set : loss - 0.5805, accuracy - 0.7391, recall - 0.8804, AUC - 0.8321, F1 - 0.7714, precision - 0.6864, training time - -8.0 seconds
2023-03-25 16:01:09,213 : [INFO]  Batch 85: Testing set : loss - 0.5919, accuracy - 0.701, recall - 0.8529, AUC - 0.8245, F1 - 0.7404, precision - 0.6541
2023-03-25 16:01:09,225 : [INFO]  Batch 86 initialized 
2023-03-25 16:01:09,646 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:10,045 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-25 16:01:14,011 : [INFO]  ------------------------- Batch round 1, loss: 0.6035 -------------------------
2023-03-25 16:01:14,011 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:14,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:14,101 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-25 16:01:16,338 : [INFO]  ------------------------- Batch round 2, loss: 0.5796 -------------------------
2023-03-25 16:01:16,338 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:16,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:16,421 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-25 16:01:18,789 : [INFO]  ------------------------- Batch round 3, loss: 0.5762 -------------------------
2023-03-25 16:01:18,789 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:18,792 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:18,793 : [INFO]  Batch number 86 model fetched from the server
2023-03-25 16:01:18,794 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-25 16:01:20,097 : [INFO]  Batch 86: Training set : loss - 0.5794, accuracy - 0.7337, recall - 0.8913, AUC - 0.7849, F1 - 0.77, precision - 0.6777, training time - -9.0 seconds
2023-03-25 16:01:20,097 : [INFO]  Batch 86: Testing set : loss - 0.6051, accuracy - 0.6716, recall - 0.951, AUC - 0.7932, F1 - 0.7433, precision - 0.6101
2023-03-25 16:01:20,110 : [INFO]  Batch 87 initialized 
2023-03-25 16:01:20,539 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:20,928 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-25 16:01:24,747 : [INFO]  ------------------------- Batch round 1, loss: 0.5504 -------------------------
2023-03-25 16:01:24,747 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:24,878 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:24,880 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-25 16:01:26,912 : [INFO]  ------------------------- Batch round 2, loss: 0.5372 -------------------------
2023-03-25 16:01:26,912 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:27,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:27,029 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-25 16:01:29,102 : [INFO]  ------------------------- Batch round 3, loss: 0.5363 -------------------------
2023-03-25 16:01:29,103 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:29,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:29,215 : [INFO]  Batch number 87 model fetched from the server
2023-03-25 16:01:29,215 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-25 16:01:30,517 : [INFO]  Batch 87: Training set : loss - 0.5292, accuracy - 0.7609, recall - 0.9239, AUC - 0.9099, F1 - 0.7944, precision - 0.6967, training time - -8.0 seconds
2023-03-25 16:01:30,517 : [INFO]  Batch 87: Testing set : loss - 0.5847, accuracy - 0.6667, recall - 0.8235, AUC - 0.8413, F1 - 0.7119, precision - 0.6269
2023-03-25 16:01:30,523 : [INFO]  Batch 88 initialized 
2023-03-25 16:01:30,965 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:31,369 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-25 16:01:35,153 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 16:01:35,153 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:35,446 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:35,447 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-25 16:01:37,412 : [INFO]  ------------------------- Batch round 2, loss: 0.5466 -------------------------
2023-03-25 16:01:37,412 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:37,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:37,639 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-25 16:01:39,637 : [INFO]  ------------------------- Batch round 3, loss: 0.5305 -------------------------
2023-03-25 16:01:39,637 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:39,859 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:39,861 : [INFO]  Batch number 88 model fetched from the server
2023-03-25 16:01:39,861 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-25 16:01:41,121 : [INFO]  Batch 88: Training set : loss - 0.5268, accuracy - 0.7717, recall - 0.9239, AUC - 0.9177, F1 - 0.8019, precision - 0.7083, training time - -8.0 seconds
2023-03-25 16:01:41,121 : [INFO]  Batch 88: Testing set : loss - 0.5504, accuracy - 0.75, recall - 0.9216, AUC - 0.884, F1 - 0.7866, precision - 0.6861
2023-03-25 16:01:41,132 : [INFO]  Batch 89 initialized 
2023-03-25 16:01:41,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:41,953 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-25 16:01:45,821 : [INFO]  ------------------------- Batch round 1, loss: 0.56 -------------------------
2023-03-25 16:01:45,821 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:45,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:45,965 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-25 16:01:48,028 : [INFO]  ------------------------- Batch round 2, loss: 0.556 -------------------------
2023-03-25 16:01:48,028 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:48,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:48,083 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-25 16:01:50,119 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 16:01:50,119 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-25 16:01:50,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:50,170 : [INFO]  Batch number 89 model fetched from the server
2023-03-25 16:01:50,171 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-25 16:01:51,482 : [INFO]  Batch 89: Training set : loss - 0.5428, accuracy - 0.7446, recall - 0.9565, AUC - 0.9079, F1 - 0.7892, precision - 0.6718, training time - -8.0 seconds
2023-03-25 16:01:51,482 : [INFO]  Batch 89: Testing set : loss - 0.5201, accuracy - 0.7843, recall - 0.9608, AUC - 0.9381, F1 - 0.8167, precision - 0.7101
2023-03-25 16:01:51,494 : [INFO]  Batch 90 initialized 
2023-03-25 16:01:51,923 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:01:52,326 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-25 16:01:56,197 : [INFO]  ------------------------- Batch round 1, loss: 0.533 -------------------------
2023-03-25 16:01:56,197 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-25 16:01:56,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:56,525 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-25 16:01:58,598 : [INFO]  ------------------------- Batch round 2, loss: 0.5217 -------------------------
2023-03-25 16:01:58,598 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-25 16:01:58,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:01:58,692 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-25 16:02:00,793 : [INFO]  ------------------------- Batch round 3, loss: 0.518 -------------------------
2023-03-25 16:02:00,793 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:00,887 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:00,889 : [INFO]  Batch number 90 model fetched from the server
2023-03-25 16:02:00,890 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-25 16:02:02,185 : [INFO]  Batch 90: Training set : loss - 0.5164, accuracy - 0.8315, recall - 0.913, AUC - 0.9038, F1 - 0.8442, precision - 0.785, training time - -9.0 seconds
2023-03-25 16:02:02,185 : [INFO]  Batch 90: Testing set : loss - 0.5744, accuracy - 0.7304, recall - 0.9314, AUC - 0.8664, F1 - 0.7755, precision - 0.6643
2023-03-25 16:02:02,198 : [INFO]  Batch 91 initialized 
2023-03-25 16:02:02,630 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:03,027 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-25 16:02:06,854 : [INFO]  ------------------------- Batch round 1, loss: 0.5432 -------------------------
2023-03-25 16:02:06,854 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:07,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:07,120 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-25 16:02:09,221 : [INFO]  ------------------------- Batch round 2, loss: 0.5329 -------------------------
2023-03-25 16:02:09,221 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:09,391 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:09,393 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-25 16:02:11,456 : [INFO]  ------------------------- Batch round 3, loss: 0.5333 -------------------------
2023-03-25 16:02:11,456 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:11,634 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:11,636 : [INFO]  Batch number 91 model fetched from the server
2023-03-25 16:02:11,636 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-25 16:02:12,950 : [INFO]  Batch 91: Training set : loss - 0.5358, accuracy - 0.7772, recall - 0.8913, AUC - 0.8572, F1 - 0.8, precision - 0.7257, training time - -9.0 seconds
2023-03-25 16:02:12,950 : [INFO]  Batch 91: Testing set : loss - 0.6388, accuracy - 0.6078, recall - 0.8627, AUC - 0.7315, F1 - 0.6875, precision - 0.5714
2023-03-25 16:02:12,959 : [INFO]  Batch 92 initialized 
2023-03-25 16:02:13,381 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:13,784 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-25 16:02:17,855 : [INFO]  ------------------------- Batch round 1, loss: 0.5649 -------------------------
2023-03-25 16:02:17,855 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:17,858 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:17,860 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-25 16:02:20,146 : [INFO]  ------------------------- Batch round 2, loss: 0.5446 -------------------------
2023-03-25 16:02:20,146 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:20,149 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:20,150 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-25 16:02:22,366 : [INFO]  ------------------------- Batch round 3, loss: 0.5286 -------------------------
2023-03-25 16:02:22,366 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:22,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:22,370 : [INFO]  Batch number 92 model fetched from the server
2023-03-25 16:02:22,370 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-25 16:02:23,749 : [INFO]  Batch 92: Training set : loss - 0.5309, accuracy - 0.7935, recall - 0.913, AUC - 0.917, F1 - 0.8155, precision - 0.7368, training time - -9.0 seconds
2023-03-25 16:02:23,749 : [INFO]  Batch 92: Testing set : loss - 0.5773, accuracy - 0.7157, recall - 0.9216, AUC - 0.8658, F1 - 0.7642, precision - 0.6528
2023-03-25 16:02:23,755 : [INFO]  Batch 93 initialized 
2023-03-25 16:02:24,189 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:24,612 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-25 16:02:28,439 : [INFO]  ------------------------- Batch round 1, loss: 0.5494 -------------------------
2023-03-25 16:02:28,439 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:28,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:28,529 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-25 16:02:30,954 : [INFO]  ------------------------- Batch round 2, loss: 0.5381 -------------------------
2023-03-25 16:02:30,954 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:30,956 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:30,958 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-25 16:02:33,026 : [INFO]  ------------------------- Batch round 3, loss: 0.5421 -------------------------
2023-03-25 16:02:33,026 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:33,150 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:33,152 : [INFO]  Batch number 93 model fetched from the server
2023-03-25 16:02:33,153 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-25 16:02:34,467 : [INFO]  Batch 93: Training set : loss - 0.5326, accuracy - 0.7717, recall - 0.9239, AUC - 0.861, F1 - 0.8019, precision - 0.7083, training time - -9.0 seconds
2023-03-25 16:02:34,467 : [INFO]  Batch 93: Testing set : loss - 0.564, accuracy - 0.7353, recall - 0.8824, AUC - 0.8447, F1 - 0.7692, precision - 0.6818
2023-03-25 16:02:34,479 : [INFO]  Batch 94 initialized 
2023-03-25 16:02:34,913 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:35,304 : [INFO]  ------------------------- Batch 94 training: round 1 -------------------------
2023-03-25 16:02:39,442 : [INFO]  ------------------------- Batch round 1, loss: 0.5921 -------------------------
2023-03-25 16:02:39,442 : [INFO]  ------------------------- Batch 94, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:39,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:39,447 : [INFO]  ------------------------- Batch 94 training: round 2 -------------------------
2023-03-25 16:02:41,535 : [INFO]  ------------------------- Batch round 2, loss: 0.5852 -------------------------
2023-03-25 16:02:41,535 : [INFO]  ------------------------- Batch 94, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:41,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:41,693 : [INFO]  ------------------------- Batch 94 training: round 3 -------------------------
2023-03-25 16:02:43,763 : [INFO]  ------------------------- Batch round 3, loss: 0.5742 -------------------------
2023-03-25 16:02:43,763 : [INFO]  ------------------------- Batch 94, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:43,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:43,921 : [INFO]  Batch number 94 model fetched from the server
2023-03-25 16:02:43,922 : [INFO]  ################ Batch 94: final global model evalution after 3 rounds ################
2023-03-25 16:02:45,173 : [INFO]  Batch 94: Training set : loss - 0.5745, accuracy - 0.6957, recall - 0.9239, AUC - 0.8526, F1 - 0.7522, precision - 0.6343, training time - -9.0 seconds
2023-03-25 16:02:45,173 : [INFO]  Batch 94: Testing set : loss - 0.5795, accuracy - 0.6667, recall - 0.9608, AUC - 0.9112, F1 - 0.7424, precision - 0.6049
2023-03-25 16:02:45,187 : [INFO]  Batch 95 initialized 
2023-03-25 16:02:45,645 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:46,046 : [INFO]  ------------------------- Batch 95 training: round 1 -------------------------
2023-03-25 16:02:49,854 : [INFO]  ------------------------- Batch round 1, loss: 0.5263 -------------------------
2023-03-25 16:02:49,854 : [INFO]  ------------------------- Batch 95, round 1: Sent local model to the server -------------------------
2023-03-25 16:02:50,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:50,130 : [INFO]  ------------------------- Batch 95 training: round 2 -------------------------
2023-03-25 16:02:52,191 : [INFO]  ------------------------- Batch round 2, loss: 0.5119 -------------------------
2023-03-25 16:02:52,191 : [INFO]  ------------------------- Batch 95, round 2: Sent local model to the server -------------------------
2023-03-25 16:02:52,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:52,433 : [INFO]  ------------------------- Batch 95 training: round 3 -------------------------
2023-03-25 16:02:54,463 : [INFO]  ------------------------- Batch round 3, loss: 0.51 -------------------------
2023-03-25 16:02:54,463 : [INFO]  ------------------------- Batch 95, round 3: Sent local model to the server -------------------------
2023-03-25 16:02:54,739 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:02:54,740 : [INFO]  Batch number 95 model fetched from the server
2023-03-25 16:02:54,740 : [INFO]  ################ Batch 95: final global model evalution after 3 rounds ################
2023-03-25 16:02:55,996 : [INFO]  Batch 95: Training set : loss - 0.5139, accuracy - 0.8152, recall - 0.9783, AUC - 0.9269, F1 - 0.8411, precision - 0.7377, training time - -9.0 seconds
2023-03-25 16:02:55,996 : [INFO]  Batch 95: Testing set : loss - 0.519, accuracy - 0.8088, recall - 0.9902, AUC - 0.9485, F1 - 0.8382, precision - 0.7266
2023-03-25 16:02:56,007 : [INFO]  Batch 96 initialized 
2023-03-25 16:02:56,431 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:02:56,827 : [INFO]  ------------------------- Batch 96 training: round 1 -------------------------
2023-03-25 16:03:00,824 : [INFO]  ------------------------- Batch round 1, loss: 0.5899 -------------------------
2023-03-25 16:03:00,824 : [INFO]  ------------------------- Batch 96, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:00,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:00,995 : [INFO]  ------------------------- Batch 96 training: round 2 -------------------------
2023-03-25 16:03:03,154 : [INFO]  ------------------------- Batch round 2, loss: 0.5734 -------------------------
2023-03-25 16:03:03,154 : [INFO]  ------------------------- Batch 96, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:03,293 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:03,295 : [INFO]  ------------------------- Batch 96 training: round 3 -------------------------
2023-03-25 16:03:05,392 : [INFO]  ------------------------- Batch round 3, loss: 0.5749 -------------------------
2023-03-25 16:03:05,392 : [INFO]  ------------------------- Batch 96, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:05,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:05,567 : [INFO]  Batch number 96 model fetched from the server
2023-03-25 16:03:05,567 : [INFO]  ################ Batch 96: final global model evalution after 3 rounds ################
2023-03-25 16:03:06,888 : [INFO]  Batch 96: Training set : loss - 0.5661, accuracy - 0.7174, recall - 0.8913, AUC - 0.8583, F1 - 0.7593, precision - 0.6613, training time - -9.0 seconds
2023-03-25 16:03:06,888 : [INFO]  Batch 96: Testing set : loss - 0.5699, accuracy - 0.6912, recall - 0.8824, AUC - 0.8416, F1 - 0.7407, precision - 0.6383
2023-03-25 16:03:06,901 : [INFO]  Batch 97 initialized 
2023-03-25 16:03:07,327 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:07,737 : [INFO]  ------------------------- Batch 97 training: round 1 -------------------------
2023-03-25 16:03:11,525 : [INFO]  ------------------------- Batch round 1, loss: 0.5466 -------------------------
2023-03-25 16:03:11,525 : [INFO]  ------------------------- Batch 97, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:11,722 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:11,724 : [INFO]  ------------------------- Batch 97 training: round 2 -------------------------
2023-03-25 16:03:13,784 : [INFO]  ------------------------- Batch round 2, loss: 0.531 -------------------------
2023-03-25 16:03:13,784 : [INFO]  ------------------------- Batch 97, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:13,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:13,950 : [INFO]  ------------------------- Batch 97 training: round 3 -------------------------
2023-03-25 16:03:15,987 : [INFO]  ------------------------- Batch round 3, loss: 0.5198 -------------------------
2023-03-25 16:03:15,987 : [INFO]  ------------------------- Batch 97, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:16,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:16,118 : [INFO]  Batch number 97 model fetched from the server
2023-03-25 16:03:16,118 : [INFO]  ################ Batch 97: final global model evalution after 3 rounds ################
2023-03-25 16:03:17,379 : [INFO]  Batch 97: Training set : loss - 0.5225, accuracy - 0.7772, recall - 0.9783, AUC - 0.9381, F1 - 0.8145, precision - 0.6977, training time - -8.0 seconds
2023-03-25 16:03:17,379 : [INFO]  Batch 97: Testing set : loss - 0.5802, accuracy - 0.6961, recall - 0.9216, AUC - 0.8594, F1 - 0.752, precision - 0.6351
2023-03-25 16:03:17,391 : [INFO]  Batch 98 initialized 
2023-03-25 16:03:17,820 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:18,214 : [INFO]  ------------------------- Batch 98 training: round 1 -------------------------
2023-03-25 16:03:22,061 : [INFO]  ------------------------- Batch round 1, loss: 0.5632 -------------------------
2023-03-25 16:03:22,062 : [INFO]  ------------------------- Batch 98, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:22,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:22,353 : [INFO]  ------------------------- Batch 98 training: round 2 -------------------------
2023-03-25 16:03:24,431 : [INFO]  ------------------------- Batch round 2, loss: 0.5414 -------------------------
2023-03-25 16:03:24,431 : [INFO]  ------------------------- Batch 98, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:24,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:24,619 : [INFO]  ------------------------- Batch 98 training: round 3 -------------------------
2023-03-25 16:03:26,714 : [INFO]  ------------------------- Batch round 3, loss: 0.5248 -------------------------
2023-03-25 16:03:26,714 : [INFO]  ------------------------- Batch 98, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:26,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:26,899 : [INFO]  Batch number 98 model fetched from the server
2023-03-25 16:03:26,899 : [INFO]  ################ Batch 98: final global model evalution after 3 rounds ################
2023-03-25 16:03:28,183 : [INFO]  Batch 98: Training set : loss - 0.52, accuracy - 0.8152, recall - 0.9239, AUC - 0.9041, F1 - 0.8333, precision - 0.7589, training time - -9.0 seconds
2023-03-25 16:03:28,183 : [INFO]  Batch 98: Testing set : loss - 0.5816, accuracy - 0.6814, recall - 0.8725, AUC - 0.8553, F1 - 0.7325, precision - 0.6312
2023-03-25 16:03:28,192 : [INFO]  Batch 99 initialized 
2023-03-25 16:03:28,620 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:29,023 : [INFO]  ------------------------- Batch 99 training: round 1 -------------------------
2023-03-25 16:03:32,910 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 16:03:32,910 : [INFO]  ------------------------- Batch 99, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:33,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:33,088 : [INFO]  ------------------------- Batch 99 training: round 2 -------------------------
2023-03-25 16:03:35,210 : [INFO]  ------------------------- Batch round 2, loss: 0.5506 -------------------------
2023-03-25 16:03:35,210 : [INFO]  ------------------------- Batch 99, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:35,281 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:35,283 : [INFO]  ------------------------- Batch 99 training: round 3 -------------------------
2023-03-25 16:03:37,381 : [INFO]  ------------------------- Batch round 3, loss: 0.5424 -------------------------
2023-03-25 16:03:37,381 : [INFO]  ------------------------- Batch 99, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:37,446 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:37,448 : [INFO]  Batch number 99 model fetched from the server
2023-03-25 16:03:37,448 : [INFO]  ################ Batch 99: final global model evalution after 3 rounds ################
2023-03-25 16:03:38,757 : [INFO]  Batch 99: Training set : loss - 0.553, accuracy - 0.7663, recall - 0.9783, AUC - 0.8796, F1 - 0.8072, precision - 0.687, training time - -8.0 seconds
2023-03-25 16:03:38,757 : [INFO]  Batch 99: Testing set : loss - 0.5591, accuracy - 0.7696, recall - 0.951, AUC - 0.8871, F1 - 0.805, precision - 0.6978
2023-03-25 16:03:38,769 : [INFO]  Batch 100 initialized 
2023-03-25 16:03:39,200 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:39,622 : [INFO]  ------------------------- Batch 100 training: round 1 -------------------------
2023-03-25 16:03:43,442 : [INFO]  ------------------------- Batch round 1, loss: 0.5539 -------------------------
2023-03-25 16:03:43,442 : [INFO]  ------------------------- Batch 100, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:43,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:43,664 : [INFO]  ------------------------- Batch 100 training: round 2 -------------------------
2023-03-25 16:03:45,710 : [INFO]  ------------------------- Batch round 2, loss: 0.5514 -------------------------
2023-03-25 16:03:45,710 : [INFO]  ------------------------- Batch 100, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:45,868 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:45,870 : [INFO]  ------------------------- Batch 100 training: round 3 -------------------------
2023-03-25 16:03:47,937 : [INFO]  ------------------------- Batch round 3, loss: 0.5489 -------------------------
2023-03-25 16:03:47,937 : [INFO]  ------------------------- Batch 100, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:48,114 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:48,116 : [INFO]  Batch number 100 model fetched from the server
2023-03-25 16:03:48,116 : [INFO]  ################ Batch 100: final global model evalution after 3 rounds ################
2023-03-25 16:03:49,413 : [INFO]  Batch 100: Training set : loss - 0.5486, accuracy - 0.7391, recall - 0.8696, AUC - 0.8616, F1 - 0.7692, precision - 0.6897, training time - -8.0 seconds
2023-03-25 16:03:49,413 : [INFO]  Batch 100: Testing set : loss - 0.5793, accuracy - 0.6863, recall - 0.9118, AUC - 0.8574, F1 - 0.744, precision - 0.6284
2023-03-25 16:03:49,423 : [INFO]  Batch 101 initialized 
2023-03-25 16:03:49,862 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:03:50,267 : [INFO]  ------------------------- Batch 101 training: round 1 -------------------------
2023-03-25 16:03:54,085 : [INFO]  ------------------------- Batch round 1, loss: 0.5324 -------------------------
2023-03-25 16:03:54,085 : [INFO]  ------------------------- Batch 101, round 1: Sent local model to the server -------------------------
2023-03-25 16:03:54,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:54,262 : [INFO]  ------------------------- Batch 101 training: round 2 -------------------------
2023-03-25 16:03:56,280 : [INFO]  ------------------------- Batch round 2, loss: 0.5254 -------------------------
2023-03-25 16:03:56,280 : [INFO]  ------------------------- Batch 101, round 2: Sent local model to the server -------------------------
2023-03-25 16:03:56,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:56,395 : [INFO]  ------------------------- Batch 101 training: round 3 -------------------------
2023-03-25 16:03:58,415 : [INFO]  ------------------------- Batch round 3, loss: 0.527 -------------------------
2023-03-25 16:03:58,415 : [INFO]  ------------------------- Batch 101, round 3: Sent local model to the server -------------------------
2023-03-25 16:03:58,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:03:58,521 : [INFO]  Batch number 101 model fetched from the server
2023-03-25 16:03:58,521 : [INFO]  ################ Batch 101: final global model evalution after 3 rounds ################
2023-03-25 16:03:59,971 : [INFO]  Batch 101: Training set : loss - 0.5202, accuracy - 0.7772, recall - 0.9565, AUC - 0.9227, F1 - 0.8111, precision - 0.704, training time - -8.0 seconds
2023-03-25 16:03:59,971 : [INFO]  Batch 101: Testing set : loss - 0.5784, accuracy - 0.6814, recall - 0.8824, AUC - 0.8557, F1 - 0.7347, precision - 0.6294
2023-03-25 16:03:59,985 : [INFO]  Batch 102 initialized 
2023-03-25 16:04:00,441 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:00,854 : [INFO]  ------------------------- Batch 102 training: round 1 -------------------------
2023-03-25 16:04:04,812 : [INFO]  ------------------------- Batch round 1, loss: 0.5955 -------------------------
2023-03-25 16:04:04,812 : [INFO]  ------------------------- Batch 102, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:04,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:04,937 : [INFO]  ------------------------- Batch 102 training: round 2 -------------------------
2023-03-25 16:04:07,163 : [INFO]  ------------------------- Batch round 2, loss: 0.5893 -------------------------
2023-03-25 16:04:07,163 : [INFO]  ------------------------- Batch 102, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:07,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:07,176 : [INFO]  ------------------------- Batch 102 training: round 3 -------------------------
2023-03-25 16:04:09,325 : [INFO]  ------------------------- Batch round 3, loss: 0.5684 -------------------------
2023-03-25 16:04:09,325 : [INFO]  ------------------------- Batch 102, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:09,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:09,403 : [INFO]  Batch number 102 model fetched from the server
2023-03-25 16:04:09,403 : [INFO]  ################ Batch 102: final global model evalution after 3 rounds ################
2023-03-25 16:04:10,792 : [INFO]  Batch 102: Training set : loss - 0.5685, accuracy - 0.7228, recall - 0.8587, AUC - 0.8347, F1 - 0.756, precision - 0.6752, training time - -9.0 seconds
2023-03-25 16:04:10,792 : [INFO]  Batch 102: Testing set : loss - 0.602, accuracy - 0.6765, recall - 0.8333, AUC - 0.8051, F1 - 0.7203, precision - 0.6343
2023-03-25 16:04:10,804 : [INFO]  Batch 103 initialized 
2023-03-25 16:04:11,246 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:11,664 : [INFO]  ------------------------- Batch 103 training: round 1 -------------------------
2023-03-25 16:04:15,532 : [INFO]  ------------------------- Batch round 1, loss: 0.5693 -------------------------
2023-03-25 16:04:15,532 : [INFO]  ------------------------- Batch 103, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:15,762 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:15,764 : [INFO]  ------------------------- Batch 103 training: round 2 -------------------------
2023-03-25 16:04:17,775 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 16:04:17,775 : [INFO]  ------------------------- Batch 103, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:17,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:17,969 : [INFO]  ------------------------- Batch 103 training: round 3 -------------------------
2023-03-25 16:04:20,051 : [INFO]  ------------------------- Batch round 3, loss: 0.5589 -------------------------
2023-03-25 16:04:20,051 : [INFO]  ------------------------- Batch 103, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:20,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:20,193 : [INFO]  Batch number 103 model fetched from the server
2023-03-25 16:04:20,193 : [INFO]  ################ Batch 103: final global model evalution after 3 rounds ################
2023-03-25 16:04:21,457 : [INFO]  Batch 103: Training set : loss - 0.5566, accuracy - 0.7391, recall - 0.8913, AUC - 0.8615, F1 - 0.7736, precision - 0.6833, training time - -9.0 seconds
2023-03-25 16:04:21,458 : [INFO]  Batch 103: Testing set : loss - 0.5673, accuracy - 0.7157, recall - 0.8627, AUC - 0.8386, F1 - 0.7521, precision - 0.6667
2023-03-25 16:04:21,469 : [INFO]  Batch 104 initialized 
2023-03-25 16:04:21,895 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:22,317 : [INFO]  ------------------------- Batch 104 training: round 1 -------------------------
2023-03-25 16:04:26,280 : [INFO]  ------------------------- Batch round 1, loss: 0.5897 -------------------------
2023-03-25 16:04:26,280 : [INFO]  ------------------------- Batch 104, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:26,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:26,358 : [INFO]  ------------------------- Batch 104 training: round 2 -------------------------
2023-03-25 16:04:28,475 : [INFO]  ------------------------- Batch round 2, loss: 0.5708 -------------------------
2023-03-25 16:04:28,475 : [INFO]  ------------------------- Batch 104, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:28,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:28,560 : [INFO]  ------------------------- Batch 104 training: round 3 -------------------------
2023-03-25 16:04:30,712 : [INFO]  ------------------------- Batch round 3, loss: 0.5647 -------------------------
2023-03-25 16:04:30,712 : [INFO]  ------------------------- Batch 104, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:30,767 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:30,769 : [INFO]  Batch number 104 model fetched from the server
2023-03-25 16:04:30,769 : [INFO]  ################ Batch 104: final global model evalution after 3 rounds ################
2023-03-25 16:04:32,093 : [INFO]  Batch 104: Training set : loss - 0.5638, accuracy - 0.7391, recall - 0.9022, AUC - 0.8427, F1 - 0.7757, precision - 0.6803, training time - -8.0 seconds
2023-03-25 16:04:32,093 : [INFO]  Batch 104: Testing set : loss - 0.5913, accuracy - 0.6765, recall - 0.8725, AUC - 0.8524, F1 - 0.7295, precision - 0.6268
2023-03-25 16:04:32,105 : [INFO]  Batch 105 initialized 
2023-03-25 16:04:32,540 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:32,990 : [INFO]  ------------------------- Batch 105 training: round 1 -------------------------
2023-03-25 16:04:36,951 : [INFO]  ------------------------- Batch round 1, loss: 0.6156 -------------------------
2023-03-25 16:04:36,951 : [INFO]  ------------------------- Batch 105, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:36,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:36,956 : [INFO]  ------------------------- Batch 105 training: round 2 -------------------------
2023-03-25 16:04:39,179 : [INFO]  ------------------------- Batch round 2, loss: 0.5948 -------------------------
2023-03-25 16:04:39,180 : [INFO]  ------------------------- Batch 105, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:39,183 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:39,184 : [INFO]  ------------------------- Batch 105 training: round 3 -------------------------
2023-03-25 16:04:41,352 : [INFO]  ------------------------- Batch round 3, loss: 0.5776 -------------------------
2023-03-25 16:04:41,352 : [INFO]  ------------------------- Batch 105, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:41,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:41,377 : [INFO]  Batch number 105 model fetched from the server
2023-03-25 16:04:41,377 : [INFO]  ################ Batch 105: final global model evalution after 3 rounds ################
2023-03-25 16:04:42,716 : [INFO]  Batch 105: Training set : loss - 0.5883, accuracy - 0.6793, recall - 0.837, AUC - 0.8045, F1 - 0.723, precision - 0.6364, training time - -8.0 seconds
2023-03-25 16:04:42,716 : [INFO]  Batch 105: Testing set : loss - 0.5966, accuracy - 0.7059, recall - 0.8529, AUC - 0.8058, F1 - 0.7436, precision - 0.6591
2023-03-25 16:04:42,728 : [INFO]  Batch 106 initialized 
2023-03-25 16:04:43,154 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:43,578 : [INFO]  ------------------------- Batch 106 training: round 1 -------------------------
2023-03-25 16:04:47,430 : [INFO]  ------------------------- Batch round 1, loss: 0.5631 -------------------------
2023-03-25 16:04:47,431 : [INFO]  ------------------------- Batch 106, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:47,631 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:47,632 : [INFO]  ------------------------- Batch 106 training: round 2 -------------------------
2023-03-25 16:04:49,693 : [INFO]  ------------------------- Batch round 2, loss: 0.5564 -------------------------
2023-03-25 16:04:49,693 : [INFO]  ------------------------- Batch 106, round 2: Sent local model to the server -------------------------
2023-03-25 16:04:49,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:49,835 : [INFO]  ------------------------- Batch 106 training: round 3 -------------------------
2023-03-25 16:04:51,925 : [INFO]  ------------------------- Batch round 3, loss: 0.5468 -------------------------
2023-03-25 16:04:51,925 : [INFO]  ------------------------- Batch 106, round 3: Sent local model to the server -------------------------
2023-03-25 16:04:52,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:52,079 : [INFO]  Batch number 106 model fetched from the server
2023-03-25 16:04:52,079 : [INFO]  ################ Batch 106: final global model evalution after 3 rounds ################
2023-03-25 16:04:53,389 : [INFO]  Batch 106: Training set : loss - 0.5416, accuracy - 0.7717, recall - 0.8696, AUC - 0.8389, F1 - 0.7921, precision - 0.7273, training time - -9.0 seconds
2023-03-25 16:04:53,390 : [INFO]  Batch 106: Testing set : loss - 0.5577, accuracy - 0.7206, recall - 0.8922, AUC - 0.8686, F1 - 0.7615, precision - 0.6642
2023-03-25 16:04:53,396 : [INFO]  Batch 107 initialized 
2023-03-25 16:04:53,818 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:04:54,243 : [INFO]  ------------------------- Batch 107 training: round 1 -------------------------
2023-03-25 16:04:58,079 : [INFO]  ------------------------- Batch round 1, loss: 0.5858 -------------------------
2023-03-25 16:04:58,080 : [INFO]  ------------------------- Batch 107, round 1: Sent local model to the server -------------------------
2023-03-25 16:04:58,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:04:58,335 : [INFO]  ------------------------- Batch 107 training: round 2 -------------------------
2023-03-25 16:05:00,389 : [INFO]  ------------------------- Batch round 2, loss: 0.5701 -------------------------
2023-03-25 16:05:00,389 : [INFO]  ------------------------- Batch 107, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:00,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:00,590 : [INFO]  ------------------------- Batch 107 training: round 3 -------------------------
2023-03-25 16:05:02,627 : [INFO]  ------------------------- Batch round 3, loss: 0.5611 -------------------------
2023-03-25 16:05:02,627 : [INFO]  ------------------------- Batch 107, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:02,857 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:02,858 : [INFO]  Batch number 107 model fetched from the server
2023-03-25 16:05:02,859 : [INFO]  ################ Batch 107: final global model evalution after 3 rounds ################
2023-03-25 16:05:04,191 : [INFO]  Batch 107: Training set : loss - 0.5558, accuracy - 0.7391, recall - 0.9239, AUC - 0.8726, F1 - 0.7798, precision - 0.6746, training time - -9.0 seconds
2023-03-25 16:05:04,191 : [INFO]  Batch 107: Testing set : loss - 0.5898, accuracy - 0.6863, recall - 0.8922, AUC - 0.8146, F1 - 0.7398, precision - 0.6319
2023-03-25 16:05:04,204 : [INFO]  Batch 108 initialized 
2023-03-25 16:05:04,628 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:05,045 : [INFO]  ------------------------- Batch 108 training: round 1 -------------------------
2023-03-25 16:05:08,850 : [INFO]  ------------------------- Batch round 1, loss: 0.5373 -------------------------
2023-03-25 16:05:08,851 : [INFO]  ------------------------- Batch 108, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:09,126 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:09,129 : [INFO]  ------------------------- Batch 108 training: round 2 -------------------------
2023-03-25 16:05:11,131 : [INFO]  ------------------------- Batch round 2, loss: 0.5346 -------------------------
2023-03-25 16:05:11,131 : [INFO]  ------------------------- Batch 108, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:11,336 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:11,338 : [INFO]  ------------------------- Batch 108 training: round 3 -------------------------
2023-03-25 16:05:13,370 : [INFO]  ------------------------- Batch round 3, loss: 0.536 -------------------------
2023-03-25 16:05:13,371 : [INFO]  ------------------------- Batch 108, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:13,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:13,551 : [INFO]  Batch number 108 model fetched from the server
2023-03-25 16:05:13,551 : [INFO]  ################ Batch 108: final global model evalution after 3 rounds ################
2023-03-25 16:05:14,815 : [INFO]  Batch 108: Training set : loss - 0.5239, accuracy - 0.788, recall - 0.9565, AUC - 0.9266, F1 - 0.8186, precision - 0.7154, training time - -9.0 seconds
2023-03-25 16:05:14,815 : [INFO]  Batch 108: Testing set : loss - 0.5219, accuracy - 0.799, recall - 0.9706, AUC - 0.9364, F1 - 0.8285, precision - 0.7226
2023-03-25 16:05:14,822 : [INFO]  Batch 109 initialized 
2023-03-25 16:05:15,260 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:15,671 : [INFO]  ------------------------- Batch 109 training: round 1 -------------------------
2023-03-25 16:05:19,659 : [INFO]  ------------------------- Batch round 1, loss: 0.5725 -------------------------
2023-03-25 16:05:19,659 : [INFO]  ------------------------- Batch 109, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:19,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:19,806 : [INFO]  ------------------------- Batch 109 training: round 2 -------------------------
2023-03-25 16:05:21,936 : [INFO]  ------------------------- Batch round 2, loss: 0.5641 -------------------------
2023-03-25 16:05:21,936 : [INFO]  ------------------------- Batch 109, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:21,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:21,996 : [INFO]  ------------------------- Batch 109 training: round 3 -------------------------
2023-03-25 16:05:24,048 : [INFO]  ------------------------- Batch round 3, loss: 0.5575 -------------------------
2023-03-25 16:05:24,048 : [INFO]  ------------------------- Batch 109, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:24,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:24,423 : [INFO]  Batch number 109 model fetched from the server
2023-03-25 16:05:24,423 : [INFO]  ################ Batch 109: final global model evalution after 3 rounds ################
2023-03-25 16:05:25,694 : [INFO]  Batch 109: Training set : loss - 0.5643, accuracy - 0.7554, recall - 0.9022, AUC - 0.868, F1 - 0.7867, precision - 0.6975, training time - -9.0 seconds
2023-03-25 16:05:25,694 : [INFO]  Batch 109: Testing set : loss - 0.609, accuracy - 0.6618, recall - 0.8235, AUC - 0.8196, F1 - 0.7089, precision - 0.6222
2023-03-25 16:05:25,707 : [INFO]  Batch 110 initialized 
2023-03-25 16:05:26,135 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:26,589 : [INFO]  ------------------------- Batch 110 training: round 1 -------------------------
2023-03-25 16:05:30,451 : [INFO]  ------------------------- Batch round 1, loss: 0.5628 -------------------------
2023-03-25 16:05:30,451 : [INFO]  ------------------------- Batch 110, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:30,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:30,649 : [INFO]  ------------------------- Batch 110 training: round 2 -------------------------
2023-03-25 16:05:32,717 : [INFO]  ------------------------- Batch round 2, loss: 0.5438 -------------------------
2023-03-25 16:05:32,717 : [INFO]  ------------------------- Batch 110, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:32,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:32,917 : [INFO]  ------------------------- Batch 110 training: round 3 -------------------------
2023-03-25 16:05:34,978 : [INFO]  ------------------------- Batch round 3, loss: 0.5352 -------------------------
2023-03-25 16:05:34,979 : [INFO]  ------------------------- Batch 110, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:35,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:35,141 : [INFO]  Batch number 110 model fetched from the server
2023-03-25 16:05:35,141 : [INFO]  ################ Batch 110: final global model evalution after 3 rounds ################
2023-03-25 16:05:36,403 : [INFO]  Batch 110: Training set : loss - 0.5422, accuracy - 0.7826, recall - 0.9565, AUC - 0.8953, F1 - 0.8148, precision - 0.7097, training time - -9.0 seconds
2023-03-25 16:05:36,403 : [INFO]  Batch 110: Testing set : loss - 0.5677, accuracy - 0.7255, recall - 0.9608, AUC - 0.8501, F1 - 0.7778, precision - 0.6533
2023-03-25 16:05:36,415 : [INFO]  Batch 111 initialized 
2023-03-25 16:05:36,835 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:37,265 : [INFO]  ------------------------- Batch 111 training: round 1 -------------------------
2023-03-25 16:05:41,207 : [INFO]  ------------------------- Batch round 1, loss: 0.5796 -------------------------
2023-03-25 16:05:41,207 : [INFO]  ------------------------- Batch 111, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:41,326 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:41,327 : [INFO]  ------------------------- Batch 111 training: round 2 -------------------------
2023-03-25 16:05:43,476 : [INFO]  ------------------------- Batch round 2, loss: 0.5704 -------------------------
2023-03-25 16:05:43,476 : [INFO]  ------------------------- Batch 111, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:43,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:43,529 : [INFO]  ------------------------- Batch 111 training: round 3 -------------------------
2023-03-25 16:05:45,657 : [INFO]  ------------------------- Batch round 3, loss: 0.5569 -------------------------
2023-03-25 16:05:45,657 : [INFO]  ------------------------- Batch 111, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:45,705 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:45,708 : [INFO]  Batch number 111 model fetched from the server
2023-03-25 16:05:45,708 : [INFO]  ################ Batch 111: final global model evalution after 3 rounds ################
2023-03-25 16:05:47,025 : [INFO]  Batch 111: Training set : loss - 0.5624, accuracy - 0.7174, recall - 0.8913, AUC - 0.8546, F1 - 0.7593, precision - 0.6613, training time - -8.0 seconds
2023-03-25 16:05:47,025 : [INFO]  Batch 111: Testing set : loss - 0.5985, accuracy - 0.6324, recall - 0.8529, AUC - 0.8052, F1 - 0.6988, precision - 0.5918
2023-03-25 16:05:47,053 : [INFO]  Batch 112 initialized 
2023-03-25 16:05:47,485 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:47,921 : [INFO]  ------------------------- Batch 112 training: round 1 -------------------------
2023-03-25 16:05:51,792 : [INFO]  ------------------------- Batch round 1, loss: 0.5599 -------------------------
2023-03-25 16:05:51,792 : [INFO]  ------------------------- Batch 112, round 1: Sent local model to the server -------------------------
2023-03-25 16:05:51,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:51,928 : [INFO]  ------------------------- Batch 112 training: round 2 -------------------------
2023-03-25 16:05:53,952 : [INFO]  ------------------------- Batch round 2, loss: 0.5488 -------------------------
2023-03-25 16:05:53,952 : [INFO]  ------------------------- Batch 112, round 2: Sent local model to the server -------------------------
2023-03-25 16:05:54,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:54,092 : [INFO]  ------------------------- Batch 112 training: round 3 -------------------------
2023-03-25 16:05:56,141 : [INFO]  ------------------------- Batch round 3, loss: 0.5344 -------------------------
2023-03-25 16:05:56,141 : [INFO]  ------------------------- Batch 112, round 3: Sent local model to the server -------------------------
2023-03-25 16:05:56,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:05:56,270 : [INFO]  Batch number 112 model fetched from the server
2023-03-25 16:05:56,270 : [INFO]  ################ Batch 112: final global model evalution after 3 rounds ################
2023-03-25 16:05:57,929 : [INFO]  Batch 112: Training set : loss - 0.5411, accuracy - 0.7772, recall - 0.913, AUC - 0.8715, F1 - 0.8038, precision - 0.7179, training time - -8.0 seconds
2023-03-25 16:05:57,929 : [INFO]  Batch 112: Testing set : loss - 0.5984, accuracy - 0.6716, recall - 0.8529, AUC - 0.8204, F1 - 0.722, precision - 0.6259
2023-03-25 16:05:57,935 : [INFO]  Batch 113 initialized 
2023-03-25 16:05:58,459 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:05:58,832 : [INFO]  ------------------------- Batch 113 training: round 1 -------------------------
2023-03-25 16:06:02,717 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-25 16:06:02,717 : [INFO]  ------------------------- Batch 113, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:02,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:02,722 : [INFO]  ------------------------- Batch 113 training: round 2 -------------------------
2023-03-25 16:06:05,039 : [INFO]  ------------------------- Batch round 2, loss: 0.5454 -------------------------
2023-03-25 16:06:05,039 : [INFO]  ------------------------- Batch 113, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:05,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:05,044 : [INFO]  ------------------------- Batch 113 training: round 3 -------------------------
2023-03-25 16:06:07,444 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 16:06:07,445 : [INFO]  ------------------------- Batch 113, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:07,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:07,466 : [INFO]  Batch number 113 model fetched from the server
2023-03-25 16:06:07,466 : [INFO]  ################ Batch 113: final global model evalution after 3 rounds ################
2023-03-25 16:06:08,698 : [INFO]  Batch 113: Training set : loss - 0.541, accuracy - 0.7609, recall - 0.913, AUC - 0.8869, F1 - 0.7925, precision - 0.7, training time - -9.0 seconds
2023-03-25 16:06:08,698 : [INFO]  Batch 113: Testing set : loss - 0.5696, accuracy - 0.701, recall - 0.9118, AUC - 0.8772, F1 - 0.753, precision - 0.6414
2023-03-25 16:06:08,711 : [INFO]  Batch 114 initialized 
2023-03-25 16:06:09,142 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:09,581 : [INFO]  ------------------------- Batch 114 training: round 1 -------------------------
2023-03-25 16:06:13,462 : [INFO]  ------------------------- Batch round 1, loss: 0.5634 -------------------------
2023-03-25 16:06:13,462 : [INFO]  ------------------------- Batch 114, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:13,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:13,694 : [INFO]  ------------------------- Batch 114 training: round 2 -------------------------
2023-03-25 16:06:15,776 : [INFO]  ------------------------- Batch round 2, loss: 0.5533 -------------------------
2023-03-25 16:06:15,776 : [INFO]  ------------------------- Batch 114, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:15,887 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:15,889 : [INFO]  ------------------------- Batch 114 training: round 3 -------------------------
2023-03-25 16:06:18,211 : [INFO]  ------------------------- Batch round 3, loss: 0.5543 -------------------------
2023-03-25 16:06:18,211 : [INFO]  ------------------------- Batch 114, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:18,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:18,216 : [INFO]  Batch number 114 model fetched from the server
2023-03-25 16:06:18,216 : [INFO]  ################ Batch 114: final global model evalution after 3 rounds ################
2023-03-25 16:06:19,491 : [INFO]  Batch 114: Training set : loss - 0.5628, accuracy - 0.7228, recall - 0.913, AUC - 0.8605, F1 - 0.7671, precision - 0.6614, training time - -9.0 seconds
2023-03-25 16:06:19,491 : [INFO]  Batch 114: Testing set : loss - 0.5858, accuracy - 0.6814, recall - 0.9216, AUC - 0.883, F1 - 0.7431, precision - 0.6225
2023-03-25 16:06:19,503 : [INFO]  Batch 115 initialized 
2023-03-25 16:06:19,933 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:20,376 : [INFO]  ------------------------- Batch 115 training: round 1 -------------------------
2023-03-25 16:06:24,186 : [INFO]  ------------------------- Batch round 1, loss: 0.5684 -------------------------
2023-03-25 16:06:24,186 : [INFO]  ------------------------- Batch 115, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:24,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:24,483 : [INFO]  ------------------------- Batch 115 training: round 2 -------------------------
2023-03-25 16:06:26,822 : [INFO]  ------------------------- Batch round 2, loss: 0.5558 -------------------------
2023-03-25 16:06:26,822 : [INFO]  ------------------------- Batch 115, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:26,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:26,826 : [INFO]  ------------------------- Batch 115 training: round 3 -------------------------
2023-03-25 16:06:28,870 : [INFO]  ------------------------- Batch round 3, loss: 0.5531 -------------------------
2023-03-25 16:06:28,871 : [INFO]  ------------------------- Batch 115, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:29,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:29,080 : [INFO]  Batch number 115 model fetched from the server
2023-03-25 16:06:29,080 : [INFO]  ################ Batch 115: final global model evalution after 3 rounds ################
2023-03-25 16:06:30,348 : [INFO]  Batch 115: Training set : loss - 0.5564, accuracy - 0.7446, recall - 0.9457, AUC - 0.8837, F1 - 0.7873, precision - 0.6744, training time - -9.0 seconds
2023-03-25 16:06:30,349 : [INFO]  Batch 115: Testing set : loss - 0.6005, accuracy - 0.6667, recall - 0.9314, AUC - 0.8624, F1 - 0.7364, precision - 0.609
2023-03-25 16:06:30,365 : [INFO]  Batch 116 initialized 
2023-03-25 16:06:30,820 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:31,260 : [INFO]  ------------------------- Batch 116 training: round 1 -------------------------
2023-03-25 16:06:35,099 : [INFO]  ------------------------- Batch round 1, loss: 0.5322 -------------------------
2023-03-25 16:06:35,099 : [INFO]  ------------------------- Batch 116, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:35,330 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:35,332 : [INFO]  ------------------------- Batch 116 training: round 2 -------------------------
2023-03-25 16:06:37,463 : [INFO]  ------------------------- Batch round 2, loss: 0.5194 -------------------------
2023-03-25 16:06:37,463 : [INFO]  ------------------------- Batch 116, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:37,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:37,581 : [INFO]  ------------------------- Batch 116 training: round 3 -------------------------
2023-03-25 16:06:39,612 : [INFO]  ------------------------- Batch round 3, loss: 0.5035 -------------------------
2023-03-25 16:06:39,612 : [INFO]  ------------------------- Batch 116, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:39,786 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:39,788 : [INFO]  Batch number 116 model fetched from the server
2023-03-25 16:06:39,788 : [INFO]  ################ Batch 116: final global model evalution after 3 rounds ################
2023-03-25 16:06:41,068 : [INFO]  Batch 116: Training set : loss - 0.5069, accuracy - 0.7989, recall - 0.9457, AUC - 0.9442, F1 - 0.8246, precision - 0.7311, training time - -9.0 seconds
2023-03-25 16:06:41,068 : [INFO]  Batch 116: Testing set : loss - 0.5597, accuracy - 0.7206, recall - 0.9216, AUC - 0.8978, F1 - 0.7673, precision - 0.6573
2023-03-25 16:06:41,082 : [INFO]  Batch 117 initialized 
2023-03-25 16:06:41,520 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:41,956 : [INFO]  ------------------------- Batch 117 training: round 1 -------------------------
2023-03-25 16:06:45,867 : [INFO]  ------------------------- Batch round 1, loss: 0.568 -------------------------
2023-03-25 16:06:45,868 : [INFO]  ------------------------- Batch 117, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:46,049 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:46,051 : [INFO]  ------------------------- Batch 117 training: round 2 -------------------------
2023-03-25 16:06:48,098 : [INFO]  ------------------------- Batch round 2, loss: 0.569 -------------------------
2023-03-25 16:06:48,098 : [INFO]  ------------------------- Batch 117, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:48,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:48,269 : [INFO]  ------------------------- Batch 117 training: round 3 -------------------------
2023-03-25 16:06:50,328 : [INFO]  ------------------------- Batch round 3, loss: 0.5535 -------------------------
2023-03-25 16:06:50,328 : [INFO]  ------------------------- Batch 117, round 3: Sent local model to the server -------------------------
2023-03-25 16:06:50,476 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:50,478 : [INFO]  Batch number 117 model fetched from the server
2023-03-25 16:06:50,478 : [INFO]  ################ Batch 117: final global model evalution after 3 rounds ################
2023-03-25 16:06:51,777 : [INFO]  Batch 117: Training set : loss - 0.563, accuracy - 0.75, recall - 0.8913, AUC - 0.8414, F1 - 0.781, precision - 0.6949, training time - -9.0 seconds
2023-03-25 16:06:51,778 : [INFO]  Batch 117: Testing set : loss - 0.5652, accuracy - 0.7157, recall - 0.8725, AUC - 0.8586, F1 - 0.7542, precision - 0.6642
2023-03-25 16:06:51,791 : [INFO]  Batch 118 initialized 
2023-03-25 16:06:52,211 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:06:52,675 : [INFO]  ------------------------- Batch 118 training: round 1 -------------------------
2023-03-25 16:06:56,543 : [INFO]  ------------------------- Batch round 1, loss: 0.5551 -------------------------
2023-03-25 16:06:56,543 : [INFO]  ------------------------- Batch 118, round 1: Sent local model to the server -------------------------
2023-03-25 16:06:56,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:56,714 : [INFO]  ------------------------- Batch 118 training: round 2 -------------------------
2023-03-25 16:06:58,858 : [INFO]  ------------------------- Batch round 2, loss: 0.552 -------------------------
2023-03-25 16:06:58,858 : [INFO]  ------------------------- Batch 118, round 2: Sent local model to the server -------------------------
2023-03-25 16:06:58,925 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:06:58,927 : [INFO]  ------------------------- Batch 118 training: round 3 -------------------------
2023-03-25 16:07:01,025 : [INFO]  ------------------------- Batch round 3, loss: 0.547 -------------------------
2023-03-25 16:07:01,025 : [INFO]  ------------------------- Batch 118, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:01,149 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:01,151 : [INFO]  Batch number 118 model fetched from the server
2023-03-25 16:07:01,151 : [INFO]  ################ Batch 118: final global model evalution after 3 rounds ################
2023-03-25 16:07:02,503 : [INFO]  Batch 118: Training set : loss - 0.539, accuracy - 0.7717, recall - 0.9348, AUC - 0.8829, F1 - 0.8037, precision - 0.7049, training time - -8.0 seconds
2023-03-25 16:07:02,503 : [INFO]  Batch 118: Testing set : loss - 0.5721, accuracy - 0.7206, recall - 0.8922, AUC - 0.8566, F1 - 0.7615, precision - 0.6642
2023-03-25 16:07:02,515 : [INFO]  Batch 119 initialized 
2023-03-25 16:07:02,951 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:03,388 : [INFO]  ------------------------- Batch 119 training: round 1 -------------------------
2023-03-25 16:07:07,343 : [INFO]  ------------------------- Batch round 1, loss: 0.5775 -------------------------
2023-03-25 16:07:07,343 : [INFO]  ------------------------- Batch 119, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:07,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:07,401 : [INFO]  ------------------------- Batch 119 training: round 2 -------------------------
2023-03-25 16:07:09,599 : [INFO]  ------------------------- Batch round 2, loss: 0.571 -------------------------
2023-03-25 16:07:09,599 : [INFO]  ------------------------- Batch 119, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:09,602 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:09,605 : [INFO]  ------------------------- Batch 119 training: round 3 -------------------------
2023-03-25 16:07:11,815 : [INFO]  ------------------------- Batch round 3, loss: 0.5556 -------------------------
2023-03-25 16:07:11,815 : [INFO]  ------------------------- Batch 119, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:11,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:11,820 : [INFO]  Batch number 119 model fetched from the server
2023-03-25 16:07:11,820 : [INFO]  ################ Batch 119: final global model evalution after 3 rounds ################
2023-03-25 16:07:13,172 : [INFO]  Batch 119: Training set : loss - 0.5584, accuracy - 0.7609, recall - 0.913, AUC - 0.8814, F1 - 0.7925, precision - 0.7, training time - -8.0 seconds
2023-03-25 16:07:13,172 : [INFO]  Batch 119: Testing set : loss - 0.5698, accuracy - 0.7255, recall - 0.9216, AUC - 0.878, F1 - 0.7705, precision - 0.662
2023-03-25 16:07:13,182 : [INFO]  Batch 120 initialized 
2023-03-25 16:07:13,626 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:14,107 : [INFO]  ------------------------- Batch 120 training: round 1 -------------------------
2023-03-25 16:07:18,023 : [INFO]  ------------------------- Batch round 1, loss: 0.5507 -------------------------
2023-03-25 16:07:18,023 : [INFO]  ------------------------- Batch 120, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:18,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:18,166 : [INFO]  ------------------------- Batch 120 training: round 2 -------------------------
2023-03-25 16:07:20,331 : [INFO]  ------------------------- Batch round 2, loss: 0.5426 -------------------------
2023-03-25 16:07:20,331 : [INFO]  ------------------------- Batch 120, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:20,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:20,434 : [INFO]  ------------------------- Batch 120 training: round 3 -------------------------
2023-03-25 16:07:22,543 : [INFO]  ------------------------- Batch round 3, loss: 0.5428 -------------------------
2023-03-25 16:07:22,543 : [INFO]  ------------------------- Batch 120, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:22,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:22,949 : [INFO]  Batch number 120 model fetched from the server
2023-03-25 16:07:22,949 : [INFO]  ################ Batch 120: final global model evalution after 3 rounds ################
2023-03-25 16:07:24,245 : [INFO]  Batch 120: Training set : loss - 0.5451, accuracy - 0.7663, recall - 0.9457, AUC - 0.8843, F1 - 0.8018, precision - 0.696, training time - -9.0 seconds
2023-03-25 16:07:24,245 : [INFO]  Batch 120: Testing set : loss - 0.6069, accuracy - 0.6863, recall - 0.8137, AUC - 0.788, F1 - 0.7217, precision - 0.6484
2023-03-25 16:07:24,272 : [INFO]  Batch 121 initialized 
2023-03-25 16:07:24,693 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:25,143 : [INFO]  ------------------------- Batch 121 training: round 1 -------------------------
2023-03-25 16:07:29,352 : [INFO]  ------------------------- Batch round 1, loss: 0.5871 -------------------------
2023-03-25 16:07:29,353 : [INFO]  ------------------------- Batch 121, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:29,355 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:29,357 : [INFO]  ------------------------- Batch 121 training: round 2 -------------------------
2023-03-25 16:07:31,539 : [INFO]  ------------------------- Batch round 2, loss: 0.5777 -------------------------
2023-03-25 16:07:31,539 : [INFO]  ------------------------- Batch 121, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:31,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:31,544 : [INFO]  ------------------------- Batch 121 training: round 3 -------------------------
2023-03-25 16:07:33,752 : [INFO]  ------------------------- Batch round 3, loss: 0.5636 -------------------------
2023-03-25 16:07:33,752 : [INFO]  ------------------------- Batch 121, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:33,755 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:33,756 : [INFO]  Batch number 121 model fetched from the server
2023-03-25 16:07:33,757 : [INFO]  ################ Batch 121: final global model evalution after 3 rounds ################
2023-03-25 16:07:35,082 : [INFO]  Batch 121: Training set : loss - 0.5656, accuracy - 0.7337, recall - 0.8478, AUC - 0.8182, F1 - 0.761, precision - 0.6903, training time - -9.0 seconds
2023-03-25 16:07:35,082 : [INFO]  Batch 121: Testing set : loss - 0.5814, accuracy - 0.6912, recall - 0.8431, AUC - 0.8263, F1 - 0.7319, precision - 0.6466
2023-03-25 16:07:35,091 : [INFO]  Batch 122 initialized 
2023-03-25 16:07:35,514 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:36,021 : [INFO]  ------------------------- Batch 122 training: round 1 -------------------------
2023-03-25 16:07:39,956 : [INFO]  ------------------------- Batch round 1, loss: 0.5746 -------------------------
2023-03-25 16:07:39,956 : [INFO]  ------------------------- Batch 122, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:40,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:40,101 : [INFO]  ------------------------- Batch 122 training: round 2 -------------------------
2023-03-25 16:07:42,245 : [INFO]  ------------------------- Batch round 2, loss: 0.5567 -------------------------
2023-03-25 16:07:42,245 : [INFO]  ------------------------- Batch 122, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:42,409 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:42,411 : [INFO]  ------------------------- Batch 122 training: round 3 -------------------------
2023-03-25 16:07:44,568 : [INFO]  ------------------------- Batch round 3, loss: 0.5514 -------------------------
2023-03-25 16:07:44,568 : [INFO]  ------------------------- Batch 122, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:44,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:44,699 : [INFO]  Batch number 122 model fetched from the server
2023-03-25 16:07:44,699 : [INFO]  ################ Batch 122: final global model evalution after 3 rounds ################
2023-03-25 16:07:46,008 : [INFO]  Batch 122: Training set : loss - 0.5532, accuracy - 0.7391, recall - 0.8804, AUC - 0.8404, F1 - 0.7714, precision - 0.6864, training time - -9.0 seconds
2023-03-25 16:07:46,008 : [INFO]  Batch 122: Testing set : loss - 0.6456, accuracy - 0.6127, recall - 0.8431, AUC - 0.7099, F1 - 0.6853, precision - 0.5772
2023-03-25 16:07:46,022 : [INFO]  Batch 123 initialized 
2023-03-25 16:07:46,457 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:46,936 : [INFO]  ------------------------- Batch 123 training: round 1 -------------------------
2023-03-25 16:07:50,856 : [INFO]  ------------------------- Batch round 1, loss: 0.5489 -------------------------
2023-03-25 16:07:50,856 : [INFO]  ------------------------- Batch 123, round 1: Sent local model to the server -------------------------
2023-03-25 16:07:50,951 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:50,953 : [INFO]  ------------------------- Batch 123 training: round 2 -------------------------
2023-03-25 16:07:53,103 : [INFO]  ------------------------- Batch round 2, loss: 0.5372 -------------------------
2023-03-25 16:07:53,103 : [INFO]  ------------------------- Batch 123, round 2: Sent local model to the server -------------------------
2023-03-25 16:07:53,211 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:53,214 : [INFO]  ------------------------- Batch 123 training: round 3 -------------------------
2023-03-25 16:07:55,344 : [INFO]  ------------------------- Batch round 3, loss: 0.5279 -------------------------
2023-03-25 16:07:55,344 : [INFO]  ------------------------- Batch 123, round 3: Sent local model to the server -------------------------
2023-03-25 16:07:55,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:07:55,495 : [INFO]  Batch number 123 model fetched from the server
2023-03-25 16:07:55,495 : [INFO]  ################ Batch 123: final global model evalution after 3 rounds ################
2023-03-25 16:07:56,761 : [INFO]  Batch 123: Training set : loss - 0.5305, accuracy - 0.7717, recall - 0.913, AUC - 0.899, F1 - 0.8, precision - 0.7119, training time - -9.0 seconds
2023-03-25 16:07:56,761 : [INFO]  Batch 123: Testing set : loss - 0.5579, accuracy - 0.7206, recall - 0.9314, AUC - 0.8659, F1 - 0.7692, precision - 0.6552
2023-03-25 16:07:56,773 : [INFO]  Batch 124 initialized 
2023-03-25 16:07:57,200 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:07:57,649 : [INFO]  ------------------------- Batch 124 training: round 1 -------------------------
2023-03-25 16:08:01,598 : [INFO]  ------------------------- Batch round 1, loss: 0.6078 -------------------------
2023-03-25 16:08:01,598 : [INFO]  ------------------------- Batch 124, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:01,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:01,882 : [INFO]  ------------------------- Batch 124 training: round 2 -------------------------
2023-03-25 16:08:04,054 : [INFO]  ------------------------- Batch round 2, loss: 0.5866 -------------------------
2023-03-25 16:08:04,054 : [INFO]  ------------------------- Batch 124, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:04,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:04,219 : [INFO]  ------------------------- Batch 124 training: round 3 -------------------------
2023-03-25 16:08:06,395 : [INFO]  ------------------------- Batch round 3, loss: 0.5709 -------------------------
2023-03-25 16:08:06,395 : [INFO]  ------------------------- Batch 124, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:06,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:06,537 : [INFO]  Batch number 124 model fetched from the server
2023-03-25 16:08:06,537 : [INFO]  ################ Batch 124: final global model evalution after 3 rounds ################
2023-03-25 16:08:07,867 : [INFO]  Batch 124: Training set : loss - 0.5654, accuracy - 0.7283, recall - 0.9022, AUC - 0.857, F1 - 0.7685, precision - 0.6694, training time - -9.0 seconds
2023-03-25 16:08:07,868 : [INFO]  Batch 124: Testing set : loss - 0.5897, accuracy - 0.6716, recall - 0.9118, AUC - 0.865, F1 - 0.7352, precision - 0.6159
2023-03-25 16:08:07,880 : [INFO]  Batch 125 initialized 
2023-03-25 16:08:08,308 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:08,768 : [INFO]  ------------------------- Batch 125 training: round 1 -------------------------
2023-03-25 16:08:12,662 : [INFO]  ------------------------- Batch round 1, loss: 0.536 -------------------------
2023-03-25 16:08:12,662 : [INFO]  ------------------------- Batch 125, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:12,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:12,941 : [INFO]  ------------------------- Batch 125 training: round 2 -------------------------
2023-03-25 16:08:14,981 : [INFO]  ------------------------- Batch round 2, loss: 0.5276 -------------------------
2023-03-25 16:08:14,981 : [INFO]  ------------------------- Batch 125, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:15,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:15,287 : [INFO]  ------------------------- Batch 125 training: round 3 -------------------------
2023-03-25 16:08:17,334 : [INFO]  ------------------------- Batch round 3, loss: 0.5201 -------------------------
2023-03-25 16:08:17,334 : [INFO]  ------------------------- Batch 125, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:17,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:17,628 : [INFO]  Batch number 125 model fetched from the server
2023-03-25 16:08:17,628 : [INFO]  ################ Batch 125: final global model evalution after 3 rounds ################
2023-03-25 16:08:18,946 : [INFO]  Batch 125: Training set : loss - 0.521, accuracy - 0.7989, recall - 0.9565, AUC - 0.8961, F1 - 0.8263, precision - 0.7273, training time - -9.0 seconds
2023-03-25 16:08:18,946 : [INFO]  Batch 125: Testing set : loss - 0.5862, accuracy - 0.6814, recall - 0.8725, AUC - 0.8322, F1 - 0.7325, precision - 0.6312
2023-03-25 16:08:18,958 : [INFO]  Batch 126 initialized 
2023-03-25 16:08:19,388 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:19,855 : [INFO]  ------------------------- Batch 126 training: round 1 -------------------------
2023-03-25 16:08:23,722 : [INFO]  ------------------------- Batch round 1, loss: 0.5639 -------------------------
2023-03-25 16:08:23,722 : [INFO]  ------------------------- Batch 126, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:24,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:24,093 : [INFO]  ------------------------- Batch 126 training: round 2 -------------------------
2023-03-25 16:08:26,130 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-25 16:08:26,130 : [INFO]  ------------------------- Batch 126, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:26,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:26,381 : [INFO]  ------------------------- Batch 126 training: round 3 -------------------------
2023-03-25 16:08:28,344 : [INFO]  ------------------------- Batch round 3, loss: 0.5352 -------------------------
2023-03-25 16:08:28,344 : [INFO]  ------------------------- Batch 126, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:28,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:28,624 : [INFO]  Batch number 126 model fetched from the server
2023-03-25 16:08:28,624 : [INFO]  ################ Batch 126: final global model evalution after 3 rounds ################
2023-03-25 16:08:29,903 : [INFO]  Batch 126: Training set : loss - 0.5363, accuracy - 0.8043, recall - 0.9891, AUC - 0.9048, F1 - 0.8349, precision - 0.7222, training time - -9.0 seconds
2023-03-25 16:08:29,904 : [INFO]  Batch 126: Testing set : loss - 0.5659, accuracy - 0.7304, recall - 0.9314, AUC - 0.8819, F1 - 0.7755, precision - 0.6643
2023-03-25 16:08:29,916 : [INFO]  Batch 127 initialized 
2023-03-25 16:08:30,346 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:30,800 : [INFO]  ------------------------- Batch 127 training: round 1 -------------------------
2023-03-25 16:08:34,695 : [INFO]  ------------------------- Batch round 1, loss: 0.5471 -------------------------
2023-03-25 16:08:34,695 : [INFO]  ------------------------- Batch 127, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:34,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:34,965 : [INFO]  ------------------------- Batch 127 training: round 2 -------------------------
2023-03-25 16:08:36,976 : [INFO]  ------------------------- Batch round 2, loss: 0.5383 -------------------------
2023-03-25 16:08:36,977 : [INFO]  ------------------------- Batch 127, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:37,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:37,181 : [INFO]  ------------------------- Batch 127 training: round 3 -------------------------
2023-03-25 16:08:39,213 : [INFO]  ------------------------- Batch round 3, loss: 0.5292 -------------------------
2023-03-25 16:08:39,213 : [INFO]  ------------------------- Batch 127, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:39,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:39,413 : [INFO]  Batch number 127 model fetched from the server
2023-03-25 16:08:39,413 : [INFO]  ################ Batch 127: final global model evalution after 3 rounds ################
2023-03-25 16:08:40,701 : [INFO]  Batch 127: Training set : loss - 0.5401, accuracy - 0.7391, recall - 0.9674, AUC - 0.9509, F1 - 0.7876, precision - 0.6642, training time - -9.0 seconds
2023-03-25 16:08:40,701 : [INFO]  Batch 127: Testing set : loss - 0.5812, accuracy - 0.6765, recall - 0.9608, AUC - 0.8774, F1 - 0.7481, precision - 0.6125
2023-03-25 16:08:40,714 : [INFO]  Batch 128 initialized 
2023-03-25 16:08:41,152 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:41,607 : [INFO]  ------------------------- Batch 128 training: round 1 -------------------------
2023-03-25 16:08:45,371 : [INFO]  ------------------------- Batch round 1, loss: 0.5344 -------------------------
2023-03-25 16:08:45,371 : [INFO]  ------------------------- Batch 128, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:45,619 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:45,621 : [INFO]  ------------------------- Batch 128 training: round 2 -------------------------
2023-03-25 16:08:47,586 : [INFO]  ------------------------- Batch round 2, loss: 0.5274 -------------------------
2023-03-25 16:08:47,586 : [INFO]  ------------------------- Batch 128, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:47,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:47,780 : [INFO]  ------------------------- Batch 128 training: round 3 -------------------------
2023-03-25 16:08:49,716 : [INFO]  ------------------------- Batch round 3, loss: 0.5205 -------------------------
2023-03-25 16:08:49,716 : [INFO]  ------------------------- Batch 128, round 3: Sent local model to the server -------------------------
2023-03-25 16:08:50,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:50,158 : [INFO]  Batch number 128 model fetched from the server
2023-03-25 16:08:50,159 : [INFO]  ################ Batch 128: final global model evalution after 3 rounds ################
2023-03-25 16:08:51,355 : [INFO]  Batch 128: Training set : loss - 0.5171, accuracy - 0.7989, recall - 0.9348, AUC - 0.9192, F1 - 0.823, precision - 0.735, training time - -9.0 seconds
2023-03-25 16:08:51,356 : [INFO]  Batch 128: Testing set : loss - 0.5392, accuracy - 0.7549, recall - 0.8824, AUC - 0.8966, F1 - 0.7826, precision - 0.7031
2023-03-25 16:08:51,369 : [INFO]  Batch 129 initialized 
2023-03-25 16:08:51,812 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:08:52,284 : [INFO]  ------------------------- Batch 129 training: round 1 -------------------------
2023-03-25 16:08:56,158 : [INFO]  ------------------------- Batch round 1, loss: 0.6094 -------------------------
2023-03-25 16:08:56,159 : [INFO]  ------------------------- Batch 129, round 1: Sent local model to the server -------------------------
2023-03-25 16:08:56,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:56,355 : [INFO]  ------------------------- Batch 129 training: round 2 -------------------------
2023-03-25 16:08:58,456 : [INFO]  ------------------------- Batch round 2, loss: 0.6027 -------------------------
2023-03-25 16:08:58,456 : [INFO]  ------------------------- Batch 129, round 2: Sent local model to the server -------------------------
2023-03-25 16:08:58,586 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:08:58,588 : [INFO]  ------------------------- Batch 129 training: round 3 -------------------------
2023-03-25 16:09:00,725 : [INFO]  ------------------------- Batch round 3, loss: 0.5951 -------------------------
2023-03-25 16:09:00,725 : [INFO]  ------------------------- Batch 129, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:00,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:00,840 : [INFO]  Batch number 129 model fetched from the server
2023-03-25 16:09:00,841 : [INFO]  ################ Batch 129: final global model evalution after 3 rounds ################
2023-03-25 16:09:02,139 : [INFO]  Batch 129: Training set : loss - 0.603, accuracy - 0.663, recall - 0.837, AUC - 0.7469, F1 - 0.713, precision - 0.621, training time - -9.0 seconds
2023-03-25 16:09:02,139 : [INFO]  Batch 129: Testing set : loss - 0.5774, accuracy - 0.7353, recall - 0.8431, AUC - 0.8221, F1 - 0.7611, precision - 0.6935
2023-03-25 16:09:02,151 : [INFO]  Batch 130 initialized 
2023-03-25 16:09:02,576 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:03,047 : [INFO]  ------------------------- Batch 130 training: round 1 -------------------------
2023-03-25 16:09:06,868 : [INFO]  ------------------------- Batch round 1, loss: 0.5728 -------------------------
2023-03-25 16:09:06,868 : [INFO]  ------------------------- Batch 130, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:07,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:07,139 : [INFO]  ------------------------- Batch 130 training: round 2 -------------------------
2023-03-25 16:09:09,098 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 16:09:09,098 : [INFO]  ------------------------- Batch 130, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:09,547 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:09,549 : [INFO]  ------------------------- Batch 130 training: round 3 -------------------------
2023-03-25 16:09:11,538 : [INFO]  ------------------------- Batch round 3, loss: 0.551 -------------------------
2023-03-25 16:09:11,538 : [INFO]  ------------------------- Batch 130, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:11,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:11,726 : [INFO]  Batch number 130 model fetched from the server
2023-03-25 16:09:11,726 : [INFO]  ################ Batch 130: final global model evalution after 3 rounds ################
2023-03-25 16:09:12,999 : [INFO]  Batch 130: Training set : loss - 0.5565, accuracy - 0.7609, recall - 0.9348, AUC - 0.8814, F1 - 0.7963, precision - 0.6935, training time - -9.0 seconds
2023-03-25 16:09:13,000 : [INFO]  Batch 130: Testing set : loss - 0.5396, accuracy - 0.7402, recall - 0.9608, AUC - 0.9298, F1 - 0.7871, precision - 0.6667
2023-03-25 16:09:13,015 : [INFO]  Batch 131 initialized 
2023-03-25 16:09:13,472 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:13,943 : [INFO]  ------------------------- Batch 131 training: round 1 -------------------------
2023-03-25 16:09:17,793 : [INFO]  ------------------------- Batch round 1, loss: 0.5159 -------------------------
2023-03-25 16:09:17,793 : [INFO]  ------------------------- Batch 131, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:18,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:18,055 : [INFO]  ------------------------- Batch 131 training: round 2 -------------------------
2023-03-25 16:09:20,152 : [INFO]  ------------------------- Batch round 2, loss: 0.517 -------------------------
2023-03-25 16:09:20,152 : [INFO]  ------------------------- Batch 131, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:20,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:20,294 : [INFO]  ------------------------- Batch 131 training: round 3 -------------------------
2023-03-25 16:09:22,382 : [INFO]  ------------------------- Batch round 3, loss: 0.5029 -------------------------
2023-03-25 16:09:22,382 : [INFO]  ------------------------- Batch 131, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:22,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:22,552 : [INFO]  Batch number 131 model fetched from the server
2023-03-25 16:09:22,552 : [INFO]  ################ Batch 131: final global model evalution after 3 rounds ################
2023-03-25 16:09:23,816 : [INFO]  Batch 131: Training set : loss - 0.5076, accuracy - 0.8207, recall - 0.9783, AUC - 0.9588, F1 - 0.8451, precision - 0.7438, training time - -9.0 seconds
2023-03-25 16:09:23,816 : [INFO]  Batch 131: Testing set : loss - 0.5348, accuracy - 0.7745, recall - 0.9608, AUC - 0.9317, F1 - 0.8099, precision - 0.7
2023-03-25 16:09:23,823 : [INFO]  Batch 132 initialized 
2023-03-25 16:09:24,279 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:24,731 : [INFO]  ------------------------- Batch 132 training: round 1 -------------------------
2023-03-25 16:09:28,731 : [INFO]  ------------------------- Batch round 1, loss: 0.5507 -------------------------
2023-03-25 16:09:28,731 : [INFO]  ------------------------- Batch 132, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:28,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:28,904 : [INFO]  ------------------------- Batch 132 training: round 2 -------------------------
2023-03-25 16:09:31,304 : [INFO]  ------------------------- Batch round 2, loss: 0.5468 -------------------------
2023-03-25 16:09:31,305 : [INFO]  ------------------------- Batch 132, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:31,315 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:31,325 : [INFO]  ------------------------- Batch 132 training: round 3 -------------------------
2023-03-25 16:09:33,450 : [INFO]  ------------------------- Batch round 3, loss: 0.5356 -------------------------
2023-03-25 16:09:33,450 : [INFO]  ------------------------- Batch 132, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:33,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:33,564 : [INFO]  Batch number 132 model fetched from the server
2023-03-25 16:09:33,564 : [INFO]  ################ Batch 132: final global model evalution after 3 rounds ################
2023-03-25 16:09:34,878 : [INFO]  Batch 132: Training set : loss - 0.5272, accuracy - 0.7554, recall - 0.913, AUC - 0.896, F1 - 0.7887, precision - 0.6942, training time - -9.0 seconds
2023-03-25 16:09:34,878 : [INFO]  Batch 132: Testing set : loss - 0.563, accuracy - 0.7304, recall - 0.8725, AUC - 0.8427, F1 - 0.7639, precision - 0.6794
2023-03-25 16:09:34,894 : [INFO]  Batch 133 initialized 
2023-03-25 16:09:35,329 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:35,792 : [INFO]  ------------------------- Batch 133 training: round 1 -------------------------
2023-03-25 16:09:39,656 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-25 16:09:39,656 : [INFO]  ------------------------- Batch 133, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:39,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:39,782 : [INFO]  ------------------------- Batch 133 training: round 2 -------------------------
2023-03-25 16:09:41,860 : [INFO]  ------------------------- Batch round 2, loss: 0.5475 -------------------------
2023-03-25 16:09:41,860 : [INFO]  ------------------------- Batch 133, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:41,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:41,940 : [INFO]  ------------------------- Batch 133 training: round 3 -------------------------
2023-03-25 16:09:44,061 : [INFO]  ------------------------- Batch round 3, loss: 0.5416 -------------------------
2023-03-25 16:09:44,061 : [INFO]  ------------------------- Batch 133, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:44,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:44,096 : [INFO]  Batch number 133 model fetched from the server
2023-03-25 16:09:44,096 : [INFO]  ################ Batch 133: final global model evalution after 3 rounds ################
2023-03-25 16:09:45,395 : [INFO]  Batch 133: Training set : loss - 0.5344, accuracy - 0.7717, recall - 0.9348, AUC - 0.8964, F1 - 0.8037, precision - 0.7049, training time - -8.0 seconds
2023-03-25 16:09:45,395 : [INFO]  Batch 133: Testing set : loss - 0.5665, accuracy - 0.7402, recall - 0.951, AUC - 0.8517, F1 - 0.7854, precision - 0.669
2023-03-25 16:09:45,407 : [INFO]  Batch 134 initialized 
2023-03-25 16:09:45,834 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:46,328 : [INFO]  ------------------------- Batch 134 training: round 1 -------------------------
2023-03-25 16:09:50,496 : [INFO]  ------------------------- Batch round 1, loss: 0.564 -------------------------
2023-03-25 16:09:50,496 : [INFO]  ------------------------- Batch 134, round 1: Sent local model to the server -------------------------
2023-03-25 16:09:50,499 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:50,500 : [INFO]  ------------------------- Batch 134 training: round 2 -------------------------
2023-03-25 16:09:52,695 : [INFO]  ------------------------- Batch round 2, loss: 0.5421 -------------------------
2023-03-25 16:09:52,695 : [INFO]  ------------------------- Batch 134, round 2: Sent local model to the server -------------------------
2023-03-25 16:09:52,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:52,726 : [INFO]  ------------------------- Batch 134 training: round 3 -------------------------
2023-03-25 16:09:54,886 : [INFO]  ------------------------- Batch round 3, loss: 0.5387 -------------------------
2023-03-25 16:09:54,886 : [INFO]  ------------------------- Batch 134, round 3: Sent local model to the server -------------------------
2023-03-25 16:09:54,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:09:54,967 : [INFO]  Batch number 134 model fetched from the server
2023-03-25 16:09:54,967 : [INFO]  ################ Batch 134: final global model evalution after 3 rounds ################
2023-03-25 16:09:56,347 : [INFO]  Batch 134: Training set : loss - 0.5342, accuracy - 0.788, recall - 0.9239, AUC - 0.9011, F1 - 0.8134, precision - 0.7265, training time - -9.0 seconds
2023-03-25 16:09:56,347 : [INFO]  Batch 134: Testing set : loss - 0.5855, accuracy - 0.7108, recall - 0.8529, AUC - 0.8283, F1 - 0.7468, precision - 0.6641
2023-03-25 16:09:56,358 : [INFO]  Batch 135 initialized 
2023-03-25 16:09:56,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:09:57,266 : [INFO]  ------------------------- Batch 135 training: round 1 -------------------------
2023-03-25 16:10:01,203 : [INFO]  ------------------------- Batch round 1, loss: 0.5857 -------------------------
2023-03-25 16:10:01,203 : [INFO]  ------------------------- Batch 135, round 1: Sent local model to the server -------------------------
2023-03-25 16:10:01,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:01,257 : [INFO]  ------------------------- Batch 135 training: round 2 -------------------------
2023-03-25 16:10:03,451 : [INFO]  ------------------------- Batch round 2, loss: 0.5784 -------------------------
2023-03-25 16:10:03,451 : [INFO]  ------------------------- Batch 135, round 2: Sent local model to the server -------------------------
2023-03-25 16:10:03,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:03,513 : [INFO]  ------------------------- Batch 135 training: round 3 -------------------------
2023-03-25 16:10:05,683 : [INFO]  ------------------------- Batch round 3, loss: 0.5701 -------------------------
2023-03-25 16:10:05,684 : [INFO]  ------------------------- Batch 135, round 3: Sent local model to the server -------------------------
2023-03-25 16:10:05,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:05,734 : [INFO]  Batch number 135 model fetched from the server
2023-03-25 16:10:05,734 : [INFO]  ################ Batch 135: final global model evalution after 3 rounds ################
2023-03-25 16:10:07,042 : [INFO]  Batch 135: Training set : loss - 0.5696, accuracy - 0.712, recall - 0.8587, AUC - 0.8376, F1 - 0.7488, precision - 0.6639, training time - -8.0 seconds
2023-03-25 16:10:07,042 : [INFO]  Batch 135: Testing set : loss - 0.6274, accuracy - 0.652, recall - 0.8824, AUC - 0.7805, F1 - 0.7171, precision - 0.604
2023-03-25 16:10:07,056 : [INFO]  Batch 136 initialized 
2023-03-25 16:10:07,478 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:10:07,967 : [INFO]  ------------------------- Batch 136 training: round 1 -------------------------
2023-03-25 16:10:11,883 : [INFO]  ------------------------- Batch round 1, loss: 0.5775 -------------------------
2023-03-25 16:10:11,883 : [INFO]  ------------------------- Batch 136, round 1: Sent local model to the server -------------------------
2023-03-25 16:10:11,990 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:11,991 : [INFO]  ------------------------- Batch 136 training: round 2 -------------------------
2023-03-25 16:10:14,340 : [INFO]  ------------------------- Batch round 2, loss: 0.5594 -------------------------
2023-03-25 16:10:14,340 : [INFO]  ------------------------- Batch 136, round 2: Sent local model to the server -------------------------
2023-03-25 16:10:14,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:14,345 : [INFO]  ------------------------- Batch 136 training: round 3 -------------------------
2023-03-25 16:10:16,565 : [INFO]  ------------------------- Batch round 3, loss: 0.5542 -------------------------
2023-03-25 16:10:16,565 : [INFO]  ------------------------- Batch 136, round 3: Sent local model to the server -------------------------
2023-03-25 16:10:16,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 16:10:16,640 : [INFO]  Batch number 136 model fetched from the server
2023-03-25 16:10:16,640 : [INFO]  ################ Batch 136: final global model evalution after 3 rounds ################
2023-03-25 16:10:18,098 : [INFO]  Batch 136: Training set : loss - 0.5429, accuracy - 0.7826, recall - 0.9022, AUC - 0.836, F1 - 0.8058, precision - 0.7281, training time - -9.0 seconds
2023-03-25 16:10:18,098 : [INFO]  Batch 136: Testing set : loss - 0.5962, accuracy - 0.6863, recall - 0.8529, AUC - 0.7982, F1 - 0.7311, precision - 0.6397
2023-03-25 16:10:18,107 : [INFO]  Batch 137 initialized 
2023-03-25 16:10:18,775 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 16:10:19,327 : [INFO]  ------------------------- Batch 137 training: round 1 -------------------------
