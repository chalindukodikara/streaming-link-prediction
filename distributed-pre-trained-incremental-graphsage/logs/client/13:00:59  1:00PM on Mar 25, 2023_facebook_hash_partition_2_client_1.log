2023-03-25 13:00:59,708 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 13:00:59,708 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 1, epochs 6
2023-03-25 13:01:02,354 : [INFO]  Model initialized for training
2023-03-25 13:01:12,616 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:01:12,745 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:01:12,746 : [INFO]  Connected to the server
2023-03-25 13:01:12,842 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:01:12,843 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:01:12,852 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:01:12,852 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:01:30,748 : [INFO]  ------------------------- Training round 1, loss: 0.6558 -------------------------
2023-03-25 13:01:30,748 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:01:30,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:01:30,753 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:01:56,089 : [INFO]  ------------------------- Training round 2, loss: 0.613 -------------------------
2023-03-25 13:01:56,089 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:01:56,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:01:56,094 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:02:18,546 : [INFO]  ------------------------- Training round 3, loss: 0.601 -------------------------
2023-03-25 13:02:18,546 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:02:18,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:02:18,553 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:02:41,434 : [INFO]  ------------------------- Training round 4, loss: 0.5961 -------------------------
2023-03-25 13:02:41,434 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:02:41,438 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:02:41,440 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:03:04,082 : [INFO]  ------------------------- Training round 5, loss: 0.594 -------------------------
2023-03-25 13:03:04,082 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:03:04,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:03:04,087 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:03:48,777 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.7, recall - 0.89, AUC - 0.84, F1 - 0.75, precision - 0.64, training time - -111.0 seconds
2023-03-25 13:03:48,777 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.89, AUC - 0.84, F1 - 0.74, precision - 0.64
2023-03-25 13:03:48,795 : [INFO]  Batch 1 initialized 
2023-03-25 13:03:49,229 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:03:49,344 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:03:49,344 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:03:53,143 : [INFO]  ------------------------- Batch round 1, loss: 0.5869 -------------------------
2023-03-25 13:03:53,143 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:03:53,146 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:03:53,148 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:03:55,229 : [INFO]  ------------------------- Batch round 2, loss: 0.5751 -------------------------
2023-03-25 13:03:55,229 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:03:55,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:03:55,329 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:03:57,392 : [INFO]  ------------------------- Batch round 3, loss: 0.566 -------------------------
2023-03-25 13:03:57,392 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:03:57,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:03:57,749 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:03:57,749 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:03:59,040 : [INFO]  Batch 1: Training set : loss - 0.5639, accuracy - 0.7283, recall - 0.9348, AUC - 0.8895, F1 - 0.7748, precision - 0.6615, training time - -8.0 seconds
2023-03-25 13:03:59,040 : [INFO]  Batch 1: Testing set : loss - 0.5503, accuracy - 0.7304, recall - 0.9216, AUC - 0.9028, F1 - 0.7737, precision - 0.6667
2023-03-25 13:03:59,063 : [INFO]  Batch 2 initialized 
2023-03-25 13:03:59,772 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:03:59,956 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:04:04,287 : [INFO]  ------------------------- Batch round 1, loss: 0.5723 -------------------------
2023-03-25 13:04:04,287 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:04:04,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:04,293 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:04:06,621 : [INFO]  ------------------------- Batch round 2, loss: 0.5574 -------------------------
2023-03-25 13:04:06,621 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:04:06,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:06,628 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:04:08,962 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 13:04:08,963 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:04:08,966 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:08,968 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:04:08,968 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:04:10,267 : [INFO]  Batch 2: Training set : loss - 0.5448, accuracy - 0.75, recall - 0.9239, AUC - 0.893, F1 - 0.787, precision - 0.6855, training time - -9.0 seconds
2023-03-25 13:04:10,267 : [INFO]  Batch 2: Testing set : loss - 0.5306, accuracy - 0.7647, recall - 0.951, AUC - 0.9189, F1 - 0.8017, precision - 0.6929
2023-03-25 13:04:10,280 : [INFO]  Batch 3 initialized 
2023-03-25 13:04:10,710 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:04:10,952 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:04:14,866 : [INFO]  ------------------------- Batch round 1, loss: 0.5607 -------------------------
2023-03-25 13:04:14,866 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:04:14,869 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:14,872 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:04:17,074 : [INFO]  ------------------------- Batch round 2, loss: 0.5467 -------------------------
2023-03-25 13:04:17,074 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:04:17,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:17,080 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:04:19,270 : [INFO]  ------------------------- Batch round 3, loss: 0.5428 -------------------------
2023-03-25 13:04:19,270 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:04:19,273 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:19,275 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:04:19,275 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:04:20,612 : [INFO]  Batch 3: Training set : loss - 0.5414, accuracy - 0.7663, recall - 0.9565, AUC - 0.9236, F1 - 0.8037, precision - 0.6929, training time - -8.0 seconds
2023-03-25 13:04:20,612 : [INFO]  Batch 3: Testing set : loss - 0.5641, accuracy - 0.6765, recall - 0.9216, AUC - 0.9171, F1 - 0.7402, precision - 0.6184
2023-03-25 13:04:20,621 : [INFO]  Batch 4 initialized 
2023-03-25 13:04:21,049 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:04:21,278 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 13:04:25,112 : [INFO]  ------------------------- Batch round 1, loss: 0.5569 -------------------------
2023-03-25 13:04:25,112 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 13:04:25,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:25,117 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 13:04:27,448 : [INFO]  ------------------------- Batch round 2, loss: 0.538 -------------------------
2023-03-25 13:04:27,448 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 13:04:27,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:27,453 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 13:04:29,508 : [INFO]  ------------------------- Batch round 3, loss: 0.5329 -------------------------
2023-03-25 13:04:29,508 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 13:04:29,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:29,514 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 13:04:29,514 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 13:04:30,843 : [INFO]  Batch 4: Training set : loss - 0.5296, accuracy - 0.7989, recall - 0.9348, AUC - 0.9103, F1 - 0.823, precision - 0.735, training time - -8.0 seconds
2023-03-25 13:04:30,843 : [INFO]  Batch 4: Testing set : loss - 0.544, accuracy - 0.7647, recall - 0.9314, AUC - 0.9144, F1 - 0.7983, precision - 0.6985
2023-03-25 13:04:30,854 : [INFO]  Batch 5 initialized 
2023-03-25 13:04:31,290 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:04:31,528 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 13:04:35,457 : [INFO]  ------------------------- Batch round 1, loss: 0.5338 -------------------------
2023-03-25 13:04:35,457 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 13:04:35,462 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:35,465 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 13:04:37,744 : [INFO]  ------------------------- Batch round 2, loss: 0.5297 -------------------------
2023-03-25 13:04:37,744 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 13:04:37,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:37,749 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 13:04:39,860 : [INFO]  ------------------------- Batch round 3, loss: 0.5278 -------------------------
2023-03-25 13:04:39,860 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 13:04:39,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:39,875 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 13:04:39,876 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 13:04:41,219 : [INFO]  Batch 5: Training set : loss - 0.5266, accuracy - 0.7609, recall - 0.913, AUC - 0.9087, F1 - 0.7925, precision - 0.7, training time - -8.0 seconds
2023-03-25 13:04:41,220 : [INFO]  Batch 5: Testing set : loss - 0.5616, accuracy - 0.6961, recall - 0.8824, AUC - 0.8844, F1 - 0.7438, precision - 0.6429
2023-03-25 13:04:41,230 : [INFO]  Batch 6 initialized 
2023-03-25 13:04:41,676 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:04:41,911 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 13:04:45,746 : [INFO]  ------------------------- Batch round 1, loss: 0.537 -------------------------
2023-03-25 13:04:45,746 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 13:04:45,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:45,751 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 13:04:48,047 : [INFO]  ------------------------- Batch round 2, loss: 0.5242 -------------------------
2023-03-25 13:04:48,047 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 13:04:48,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:48,052 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 13:04:50,152 : [INFO]  ------------------------- Batch round 3, loss: 0.5206 -------------------------
2023-03-25 13:04:50,152 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 13:04:50,155 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:50,157 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 13:04:50,157 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 13:04:51,463 : [INFO]  Batch 6: Training set : loss - 0.5118, accuracy - 0.7989, recall - 0.9457, AUC - 0.9161, F1 - 0.8246, precision - 0.7311, training time - -8.0 seconds
2023-03-25 13:04:51,463 : [INFO]  Batch 6: Testing set : loss - 0.5618, accuracy - 0.701, recall - 0.9412, AUC - 0.8899, F1 - 0.7589, precision - 0.6358
2023-03-25 13:04:51,473 : [INFO]  Batch 7 initialized 
2023-03-25 13:04:51,902 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:04:52,149 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 13:04:56,358 : [INFO]  ------------------------- Batch round 1, loss: 0.5428 -------------------------
2023-03-25 13:04:56,358 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 13:04:56,361 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:56,364 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 13:04:59,143 : [INFO]  ------------------------- Batch round 2, loss: 0.5348 -------------------------
2023-03-25 13:04:59,143 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 13:04:59,150 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:04:59,154 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 13:05:01,484 : [INFO]  ------------------------- Batch round 3, loss: 0.5258 -------------------------
2023-03-25 13:05:01,484 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 13:05:01,525 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:01,527 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 13:05:01,528 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 13:05:02,851 : [INFO]  Batch 7: Training set : loss - 0.5171, accuracy - 0.8152, recall - 0.9348, AUC - 0.9148, F1 - 0.835, precision - 0.7544, training time - -9.0 seconds
2023-03-25 13:05:02,852 : [INFO]  Batch 7: Testing set : loss - 0.5772, accuracy - 0.701, recall - 0.9216, AUC - 0.8772, F1 - 0.755, precision - 0.6395
2023-03-25 13:05:02,864 : [INFO]  Batch 8 initialized 
2023-03-25 13:05:03,323 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:05:03,565 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 13:05:07,772 : [INFO]  ------------------------- Batch round 1, loss: 0.5582 -------------------------
2023-03-25 13:05:07,773 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 13:05:07,776 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:07,778 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 13:05:10,192 : [INFO]  ------------------------- Batch round 2, loss: 0.5526 -------------------------
2023-03-25 13:05:10,192 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 13:05:10,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:10,197 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 13:05:12,381 : [INFO]  ------------------------- Batch round 3, loss: 0.545 -------------------------
2023-03-25 13:05:12,381 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 13:05:12,384 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:12,386 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 13:05:12,386 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 13:05:13,692 : [INFO]  Batch 8: Training set : loss - 0.5468, accuracy - 0.7609, recall - 0.913, AUC - 0.8782, F1 - 0.7925, precision - 0.7, training time - -9.0 seconds
2023-03-25 13:05:13,692 : [INFO]  Batch 8: Testing set : loss - 0.5895, accuracy - 0.6814, recall - 0.8725, AUC - 0.841, F1 - 0.7325, precision - 0.6312
2023-03-25 13:05:13,700 : [INFO]  Batch 9 initialized 
2023-03-25 13:05:14,129 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:05:14,389 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 13:05:18,459 : [INFO]  ------------------------- Batch round 1, loss: 0.5803 -------------------------
2023-03-25 13:05:18,460 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 13:05:18,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:18,465 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 13:05:21,126 : [INFO]  ------------------------- Batch round 2, loss: 0.5622 -------------------------
2023-03-25 13:05:21,126 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 13:05:21,133 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:21,135 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 13:05:23,999 : [INFO]  ------------------------- Batch round 3, loss: 0.5567 -------------------------
2023-03-25 13:05:23,999 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 13:05:24,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:24,006 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 13:05:24,006 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 13:05:25,395 : [INFO]  Batch 9: Training set : loss - 0.5521, accuracy - 0.7609, recall - 0.9239, AUC - 0.8956, F1 - 0.7944, precision - 0.6967, training time - -10.0 seconds
2023-03-25 13:05:25,395 : [INFO]  Batch 9: Testing set : loss - 0.6098, accuracy - 0.6471, recall - 0.8431, AUC - 0.8071, F1 - 0.7049, precision - 0.6056
2023-03-25 13:05:25,400 : [INFO]  Batch 10 initialized 
2023-03-25 13:05:25,835 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:05:26,091 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 13:05:30,098 : [INFO]  ------------------------- Batch round 1, loss: 0.5756 -------------------------
2023-03-25 13:05:30,098 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 13:05:30,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:30,103 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 13:05:33,535 : [INFO]  ------------------------- Batch round 2, loss: 0.5557 -------------------------
2023-03-25 13:05:33,536 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 13:05:33,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:05:33,541 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 13:05:36,080 : [INFO]  ------------------------- Batch round 3, loss: 0.5386 -------------------------
2023-03-25 13:05:36,081 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 13:05:37,574 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
