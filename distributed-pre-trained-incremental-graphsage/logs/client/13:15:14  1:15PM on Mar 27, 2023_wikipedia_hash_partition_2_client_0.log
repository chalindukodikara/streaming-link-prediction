2023-03-27 13:15:14,491 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-27 13:15:14,492 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 0, training epochs 6, epochs 6
2023-03-27 13:15:17,351 : [INFO]  Model initialized for training
2023-03-27 13:15:19,317 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:15:19,357 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-27 13:15:19,358 : [INFO]  Connected to the server
2023-03-27 13:15:19,455 : [INFO]  Distributed training for streaming graphs started!
2023-03-27 13:15:19,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:15:19,465 : [INFO]  ################################## Initial model training started ##################################
2023-03-27 13:15:19,465 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-27 13:15:32,009 : [INFO]  ------------------------- Training round 1, loss: 0.6624 -------------------------
2023-03-27 13:15:32,009 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-27 13:15:51,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:15:51,658 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-27 13:16:06,524 : [INFO]  ------------------------- Training round 2, loss: 0.5981 -------------------------
2023-03-27 13:16:06,524 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-27 13:16:06,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:06,773 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-27 13:16:21,577 : [INFO]  ------------------------- Training round 3, loss: 0.5808 -------------------------
2023-03-27 13:16:21,577 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-27 13:16:21,699 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:21,701 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-27 13:16:36,569 : [INFO]  ------------------------- Training round 4, loss: 0.5726 -------------------------
2023-03-27 13:16:36,569 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-27 13:16:36,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:36,789 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-27 13:16:51,458 : [INFO]  ------------------------- Training round 5, loss: 0.5686 -------------------------
2023-03-27 13:16:51,458 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-27 13:16:51,633 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:51,635 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-27 13:17:06,193 : [INFO]  ------------------------- Training round 6, loss: 0.5666 -------------------------
2023-03-27 13:17:06,193 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-27 13:17:06,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:06,372 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-27 13:17:11,877 : [INFO]  Initially trained model: Training set : loss - 0.56, accuracy - 0.75, recall - 0.92, AUC - 0.88, F1 - 0.78, precision - 0.68, training time - -107.0 seconds
2023-03-27 13:17:11,877 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.75, recall - 0.93, AUC - 0.87, F1 - 0.79, precision - 0.68
2023-03-27 13:17:11,882 : [INFO]  Batch 1 initialized 
2023-03-27 13:17:12,329 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:12,450 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-27 13:17:12,450 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-27 13:17:15,921 : [INFO]  ------------------------- Batch round 1, loss: 0.5661 -------------------------
2023-03-27 13:17:15,921 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:15,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:15,997 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-27 13:17:17,760 : [INFO]  ------------------------- Batch round 2, loss: 0.5543 -------------------------
2023-03-27 13:17:17,760 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:17,768 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:17,770 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-27 13:17:19,517 : [INFO]  ------------------------- Batch round 3, loss: 0.5496 -------------------------
2023-03-27 13:17:19,517 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:19,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:19,523 : [INFO]  Batch number 1 model fetched from the server
2023-03-27 13:17:19,523 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-27 13:17:20,688 : [INFO]  Batch 1: Training set : loss - 0.5444, accuracy - 0.7935, recall - 0.9348, AUC - 0.8659, F1 - 0.819, precision - 0.7288, training time - -7.0 seconds
2023-03-27 13:17:20,688 : [INFO]  Batch 1: Testing set : loss - 0.5649, accuracy - 0.7598, recall - 0.951, AUC - 0.8537, F1 - 0.7984, precision - 0.6879
2023-03-27 13:17:20,699 : [INFO]  Batch 2 initialized 
2023-03-27 13:17:21,126 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:21,270 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-27 13:17:24,785 : [INFO]  ------------------------- Batch round 1, loss: 0.5835 -------------------------
2023-03-27 13:17:24,785 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:24,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:24,880 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-27 13:17:26,580 : [INFO]  ------------------------- Batch round 2, loss: 0.5733 -------------------------
2023-03-27 13:17:26,580 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:26,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:26,658 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-27 13:17:28,482 : [INFO]  ------------------------- Batch round 3, loss: 0.5711 -------------------------
2023-03-27 13:17:28,482 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:28,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:28,543 : [INFO]  Batch number 2 model fetched from the server
2023-03-27 13:17:28,543 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-27 13:17:29,718 : [INFO]  Batch 2: Training set : loss - 0.5701, accuracy - 0.7554, recall - 0.8804, AUC - 0.8307, F1 - 0.7826, precision - 0.7043, training time - -7.0 seconds
2023-03-27 13:17:29,718 : [INFO]  Batch 2: Testing set : loss - 0.5792, accuracy - 0.7206, recall - 0.9216, AUC - 0.8281, F1 - 0.7673, precision - 0.6573
2023-03-27 13:17:29,722 : [INFO]  Batch 3 initialized 
2023-03-27 13:17:30,163 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:30,373 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-27 13:17:33,823 : [INFO]  ------------------------- Batch round 1, loss: 0.5959 -------------------------
2023-03-27 13:17:33,824 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:33,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:33,947 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-27 13:17:35,839 : [INFO]  ------------------------- Batch round 2, loss: 0.5923 -------------------------
2023-03-27 13:17:35,840 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:35,843 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:35,845 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-27 13:17:37,836 : [INFO]  ------------------------- Batch round 3, loss: 0.5878 -------------------------
2023-03-27 13:17:37,837 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:37,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:37,842 : [INFO]  Batch number 3 model fetched from the server
2023-03-27 13:17:37,842 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-27 13:17:39,051 : [INFO]  Batch 3: Training set : loss - 0.586, accuracy - 0.712, recall - 0.913, AUC - 0.8181, F1 - 0.7602, precision - 0.6512, training time - -7.0 seconds
2023-03-27 13:17:39,052 : [INFO]  Batch 3: Testing set : loss - 0.5669, accuracy - 0.7451, recall - 0.9412, AUC - 0.8589, F1 - 0.7869, precision - 0.6761
2023-03-27 13:17:39,056 : [INFO]  Batch 4 initialized 
2023-03-27 13:17:39,477 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:39,695 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-27 13:17:43,115 : [INFO]  ------------------------- Batch round 1, loss: 0.5454 -------------------------
2023-03-27 13:17:43,115 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:43,121 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:43,122 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-27 13:17:44,951 : [INFO]  ------------------------- Batch round 2, loss: 0.5405 -------------------------
2023-03-27 13:17:44,952 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:45,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:45,242 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-27 13:17:46,963 : [INFO]  ------------------------- Batch round 3, loss: 0.538 -------------------------
2023-03-27 13:17:46,963 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:46,966 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:46,968 : [INFO]  Batch number 4 model fetched from the server
2023-03-27 13:17:46,968 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-27 13:17:48,172 : [INFO]  Batch 4: Training set : loss - 0.5306, accuracy - 0.788, recall - 0.9783, AUC - 0.9375, F1 - 0.8219, precision - 0.7087, training time - -7.0 seconds
2023-03-27 13:17:48,172 : [INFO]  Batch 4: Testing set : loss - 0.546, accuracy - 0.7794, recall - 0.9412, AUC - 0.8911, F1 - 0.8101, precision - 0.7111
2023-03-27 13:17:48,180 : [INFO]  Batch 5 initialized 
2023-03-27 13:17:48,600 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:48,818 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-27 13:17:52,178 : [INFO]  ------------------------- Batch round 1, loss: 0.5649 -------------------------
2023-03-27 13:17:52,179 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:52,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:52,299 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-27 13:17:53,909 : [INFO]  ------------------------- Batch round 2, loss: 0.5599 -------------------------
2023-03-27 13:17:53,909 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:54,008 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:54,010 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-27 13:17:55,663 : [INFO]  ------------------------- Batch round 3, loss: 0.5576 -------------------------
2023-03-27 13:17:55,663 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:55,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:55,782 : [INFO]  Batch number 5 model fetched from the server
2023-03-27 13:17:55,782 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-27 13:17:56,936 : [INFO]  Batch 5: Training set : loss - 0.5538, accuracy - 0.75, recall - 0.9348, AUC - 0.8858, F1 - 0.789, precision - 0.6825, training time - -7.0 seconds
2023-03-27 13:17:56,936 : [INFO]  Batch 5: Testing set : loss - 0.5552, accuracy - 0.7941, recall - 0.9314, AUC - 0.8888, F1 - 0.819, precision - 0.7308
2023-03-27 13:17:56,943 : [INFO]  Batch 6 initialized 
2023-03-27 13:17:57,371 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:57,595 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-27 13:18:01,035 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-27 13:18:01,036 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:01,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:01,040 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-27 13:18:02,798 : [INFO]  ------------------------- Batch round 2, loss: 0.5576 -------------------------
2023-03-27 13:18:02,798 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:02,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:02,803 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-27 13:18:04,580 : [INFO]  ------------------------- Batch round 3, loss: 0.5528 -------------------------
2023-03-27 13:18:04,580 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:04,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:04,584 : [INFO]  Batch number 6 model fetched from the server
2023-03-27 13:18:04,584 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-27 13:18:05,769 : [INFO]  Batch 6: Training set : loss - 0.5529, accuracy - 0.7663, recall - 0.9674, AUC - 0.8689, F1 - 0.8054, precision - 0.6899, training time - -7.0 seconds
2023-03-27 13:18:05,769 : [INFO]  Batch 6: Testing set : loss - 0.5863, accuracy - 0.7157, recall - 0.9314, AUC - 0.8267, F1 - 0.7661, precision - 0.6507
2023-03-27 13:18:05,777 : [INFO]  Batch 7 initialized 
2023-03-27 13:18:06,184 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:06,405 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-27 13:18:09,816 : [INFO]  ------------------------- Batch round 1, loss: 0.5709 -------------------------
2023-03-27 13:18:09,816 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:09,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:09,908 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-27 13:18:11,595 : [INFO]  ------------------------- Batch round 2, loss: 0.5624 -------------------------
2023-03-27 13:18:11,595 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:11,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:11,627 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-27 13:18:13,328 : [INFO]  ------------------------- Batch round 3, loss: 0.5576 -------------------------
2023-03-27 13:18:13,328 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:13,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:13,348 : [INFO]  Batch number 7 model fetched from the server
2023-03-27 13:18:13,348 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-27 13:18:14,518 : [INFO]  Batch 7: Training set : loss - 0.5525, accuracy - 0.7826, recall - 0.9457, AUC - 0.8634, F1 - 0.8131, precision - 0.7131, training time - -7.0 seconds
2023-03-27 13:18:14,518 : [INFO]  Batch 7: Testing set : loss - 0.5517, accuracy - 0.7745, recall - 0.9314, AUC - 0.8663, F1 - 0.8051, precision - 0.709
2023-03-27 13:18:14,527 : [INFO]  Batch 8 initialized 
2023-03-27 13:18:14,964 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:15,188 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-27 13:18:18,665 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-27 13:18:18,666 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:18,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:18,735 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-27 13:18:20,442 : [INFO]  ------------------------- Batch round 2, loss: 0.5556 -------------------------
2023-03-27 13:18:20,442 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:20,501 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:20,503 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-27 13:18:22,162 : [INFO]  ------------------------- Batch round 3, loss: 0.5562 -------------------------
2023-03-27 13:18:22,162 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:22,198 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:22,202 : [INFO]  Batch number 8 model fetched from the server
2023-03-27 13:18:22,202 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-27 13:18:23,390 : [INFO]  Batch 8: Training set : loss - 0.5503, accuracy - 0.7935, recall - 0.9565, AUC - 0.877, F1 - 0.8224, precision - 0.7213, training time - -7.0 seconds
2023-03-27 13:18:23,390 : [INFO]  Batch 8: Testing set : loss - 0.5999, accuracy - 0.6863, recall - 0.8824, AUC - 0.809, F1 - 0.7377, precision - 0.6338
2023-03-27 13:18:23,395 : [INFO]  Batch 9 initialized 
2023-03-27 13:18:23,825 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:24,061 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-27 13:18:27,458 : [INFO]  ------------------------- Batch round 1, loss: 0.5564 -------------------------
2023-03-27 13:18:27,458 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:27,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:27,463 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-27 13:18:29,181 : [INFO]  ------------------------- Batch round 2, loss: 0.5505 -------------------------
2023-03-27 13:18:29,181 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:29,192 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:29,193 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-27 13:18:30,961 : [INFO]  ------------------------- Batch round 3, loss: 0.5458 -------------------------
2023-03-27 13:18:30,961 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:30,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:30,967 : [INFO]  Batch number 9 model fetched from the server
2023-03-27 13:18:30,967 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-27 13:18:32,156 : [INFO]  Batch 9: Training set : loss - 0.545, accuracy - 0.75, recall - 0.9565, AUC - 0.8976, F1 - 0.7928, precision - 0.6769, training time - -7.0 seconds
2023-03-27 13:18:32,156 : [INFO]  Batch 9: Testing set : loss - 0.5453, accuracy - 0.7598, recall - 0.9314, AUC - 0.8741, F1 - 0.795, precision - 0.6934
2023-03-27 13:18:32,167 : [INFO]  Batch 10 initialized 
2023-03-27 13:18:32,614 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:32,853 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-27 13:18:36,254 : [INFO]  ------------------------- Batch round 1, loss: 0.5538 -------------------------
2023-03-27 13:18:36,255 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:36,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:36,267 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-27 13:18:37,959 : [INFO]  ------------------------- Batch round 2, loss: 0.5501 -------------------------
2023-03-27 13:18:37,959 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:37,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:37,964 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-27 13:18:39,701 : [INFO]  ------------------------- Batch round 3, loss: 0.5482 -------------------------
2023-03-27 13:18:39,701 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:39,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:39,719 : [INFO]  Batch number 10 model fetched from the server
2023-03-27 13:18:39,719 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-27 13:18:40,898 : [INFO]  Batch 10: Training set : loss - 0.5467, accuracy - 0.7772, recall - 0.9239, AUC - 0.8812, F1 - 0.8057, precision - 0.7143, training time - -7.0 seconds
2023-03-27 13:18:40,899 : [INFO]  Batch 10: Testing set : loss - 0.5748, accuracy - 0.7353, recall - 0.8824, AUC - 0.8568, F1 - 0.7692, precision - 0.6818
2023-03-27 13:18:40,903 : [INFO]  Batch 11 initialized 
2023-03-27 13:18:41,316 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:41,558 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-27 13:18:44,923 : [INFO]  ------------------------- Batch round 1, loss: 0.5414 -------------------------
2023-03-27 13:18:44,924 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:45,002 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:45,004 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-27 13:18:46,665 : [INFO]  ------------------------- Batch round 2, loss: 0.5324 -------------------------
2023-03-27 13:18:46,665 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:46,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:46,726 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-27 13:18:48,415 : [INFO]  ------------------------- Batch round 3, loss: 0.5262 -------------------------
2023-03-27 13:18:48,415 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:48,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:48,479 : [INFO]  Batch number 11 model fetched from the server
2023-03-27 13:18:48,479 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-27 13:18:49,653 : [INFO]  Batch 11: Training set : loss - 0.5194, accuracy - 0.8152, recall - 0.9783, AUC - 0.9431, F1 - 0.8411, precision - 0.7377, training time - -7.0 seconds
2023-03-27 13:18:49,653 : [INFO]  Batch 11: Testing set : loss - 0.5498, accuracy - 0.7696, recall - 0.9412, AUC - 0.9108, F1 - 0.8033, precision - 0.7007
2023-03-27 13:18:49,663 : [INFO]  Batch 12 initialized 
2023-03-27 13:18:50,086 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:50,331 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-27 13:18:53,742 : [INFO]  ------------------------- Batch round 1, loss: 0.5156 -------------------------
2023-03-27 13:18:53,742 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:53,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:53,747 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-27 13:18:55,470 : [INFO]  ------------------------- Batch round 2, loss: 0.5129 -------------------------
2023-03-27 13:18:55,470 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:55,473 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:55,475 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-27 13:18:57,188 : [INFO]  ------------------------- Batch round 3, loss: 0.5115 -------------------------
2023-03-27 13:18:57,188 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:57,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:57,192 : [INFO]  Batch number 12 model fetched from the server
2023-03-27 13:18:57,193 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-27 13:18:58,343 : [INFO]  Batch 12: Training set : loss - 0.5043, accuracy - 0.8533, recall - 0.9783, AUC - 0.9231, F1 - 0.8696, precision - 0.7826, training time - -7.0 seconds
2023-03-27 13:18:58,343 : [INFO]  Batch 12: Testing set : loss - 0.5628, accuracy - 0.7353, recall - 0.9412, AUC - 0.8801, F1 - 0.7805, precision - 0.6667
2023-03-27 13:18:58,388 : [INFO]  Batch 13 initialized 
2023-03-27 13:18:58,803 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:59,047 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-27 13:19:02,422 : [INFO]  ------------------------- Batch round 1, loss: 0.5394 -------------------------
2023-03-27 13:19:02,423 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:02,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:02,457 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-27 13:19:04,087 : [INFO]  ------------------------- Batch round 2, loss: 0.5353 -------------------------
2023-03-27 13:19:04,087 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:04,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:04,092 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-27 13:19:05,769 : [INFO]  ------------------------- Batch round 3, loss: 0.5314 -------------------------
2023-03-27 13:19:05,769 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:05,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:05,774 : [INFO]  Batch number 13 model fetched from the server
2023-03-27 13:19:05,774 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-27 13:19:06,927 : [INFO]  Batch 13: Training set : loss - 0.5322, accuracy - 0.7989, recall - 0.9783, AUC - 0.93, F1 - 0.8295, precision - 0.72, training time - -7.0 seconds
2023-03-27 13:19:06,928 : [INFO]  Batch 13: Testing set : loss - 0.5635, accuracy - 0.7696, recall - 0.9804, AUC - 0.8609, F1 - 0.8097, precision - 0.6897
2023-03-27 13:19:06,932 : [INFO]  Batch 14 initialized 
2023-03-27 13:19:07,347 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:07,591 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-27 13:19:10,954 : [INFO]  ------------------------- Batch round 1, loss: 0.5518 -------------------------
2023-03-27 13:19:10,955 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:10,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:10,978 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-27 13:19:12,629 : [INFO]  ------------------------- Batch round 2, loss: 0.5452 -------------------------
2023-03-27 13:19:12,630 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:12,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:12,689 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-27 13:19:14,378 : [INFO]  ------------------------- Batch round 3, loss: 0.5427 -------------------------
2023-03-27 13:19:14,379 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:14,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:14,426 : [INFO]  Batch number 14 model fetched from the server
2023-03-27 13:19:14,426 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-27 13:19:15,561 : [INFO]  Batch 14: Training set : loss - 0.5468, accuracy - 0.7772, recall - 0.9348, AUC - 0.9096, F1 - 0.8075, precision - 0.7107, training time - -7.0 seconds
2023-03-27 13:19:15,561 : [INFO]  Batch 14: Testing set : loss - 0.5689, accuracy - 0.75, recall - 0.902, AUC - 0.87, F1 - 0.783, precision - 0.6917
2023-03-27 13:19:15,570 : [INFO]  Batch 15 initialized 
2023-03-27 13:19:15,987 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:16,238 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-27 13:19:19,677 : [INFO]  ------------------------- Batch round 1, loss: 0.5601 -------------------------
2023-03-27 13:19:19,677 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:19,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:19,694 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-27 13:19:21,375 : [INFO]  ------------------------- Batch round 2, loss: 0.5527 -------------------------
2023-03-27 13:19:21,376 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:21,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:21,400 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-27 13:19:23,071 : [INFO]  ------------------------- Batch round 3, loss: 0.5465 -------------------------
2023-03-27 13:19:23,071 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:23,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:23,107 : [INFO]  Batch number 15 model fetched from the server
2023-03-27 13:19:23,107 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-27 13:19:24,246 : [INFO]  Batch 15: Training set : loss - 0.5431, accuracy - 0.7935, recall - 0.9457, AUC - 0.883, F1 - 0.8208, precision - 0.725, training time - -7.0 seconds
2023-03-27 13:19:24,246 : [INFO]  Batch 15: Testing set : loss - 0.545, accuracy - 0.7794, recall - 0.9314, AUC - 0.8864, F1 - 0.8085, precision - 0.7143
2023-03-27 13:19:24,251 : [INFO]  Batch 16 initialized 
2023-03-27 13:19:24,677 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:24,927 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-27 13:19:28,348 : [INFO]  ------------------------- Batch round 1, loss: 0.5526 -------------------------
2023-03-27 13:19:28,348 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:28,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:28,353 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-27 13:19:30,003 : [INFO]  ------------------------- Batch round 2, loss: 0.549 -------------------------
2023-03-27 13:19:30,004 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:30,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:30,043 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-27 13:19:31,710 : [INFO]  ------------------------- Batch round 3, loss: 0.5464 -------------------------
2023-03-27 13:19:31,710 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:31,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:31,744 : [INFO]  Batch number 16 model fetched from the server
2023-03-27 13:19:31,744 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-27 13:19:32,895 : [INFO]  Batch 16: Training set : loss - 0.5433, accuracy - 0.7935, recall - 0.9674, AUC - 0.8899, F1 - 0.8241, precision - 0.7177, training time - -7.0 seconds
2023-03-27 13:19:32,895 : [INFO]  Batch 16: Testing set : loss - 0.5391, accuracy - 0.7647, recall - 0.9412, AUC - 0.9146, F1 - 0.8, precision - 0.6957
2023-03-27 13:19:32,899 : [INFO]  Batch 17 initialized 
2023-03-27 13:19:33,305 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:33,565 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-27 13:19:36,944 : [INFO]  ------------------------- Batch round 1, loss: 0.5246 -------------------------
2023-03-27 13:19:36,944 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:36,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:36,956 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-27 13:19:38,649 : [INFO]  ------------------------- Batch round 2, loss: 0.5198 -------------------------
2023-03-27 13:19:38,649 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:38,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:38,659 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-27 13:19:40,371 : [INFO]  ------------------------- Batch round 3, loss: 0.515 -------------------------
2023-03-27 13:19:40,371 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:40,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:40,388 : [INFO]  Batch number 17 model fetched from the server
2023-03-27 13:19:40,388 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-27 13:19:41,556 : [INFO]  Batch 17: Training set : loss - 0.5133, accuracy - 0.8098, recall - 0.9457, AUC - 0.9271, F1 - 0.8325, precision - 0.7436, training time - -7.0 seconds
2023-03-27 13:19:41,556 : [INFO]  Batch 17: Testing set : loss - 0.5549, accuracy - 0.7402, recall - 0.9902, AUC - 0.92, F1 - 0.7922, precision - 0.6601
2023-03-27 13:19:41,561 : [INFO]  Batch 18 initialized 
2023-03-27 13:19:41,966 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:42,228 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-27 13:19:45,575 : [INFO]  ------------------------- Batch round 1, loss: 0.5567 -------------------------
2023-03-27 13:19:45,576 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:45,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:45,583 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-27 13:19:47,234 : [INFO]  ------------------------- Batch round 2, loss: 0.5521 -------------------------
2023-03-27 13:19:47,234 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:47,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:47,264 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-27 13:19:48,920 : [INFO]  ------------------------- Batch round 3, loss: 0.547 -------------------------
2023-03-27 13:19:48,921 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:48,923 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:48,925 : [INFO]  Batch number 18 model fetched from the server
2023-03-27 13:19:48,925 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-27 13:19:50,062 : [INFO]  Batch 18: Training set : loss - 0.5457, accuracy - 0.7609, recall - 0.9239, AUC - 0.8987, F1 - 0.7944, precision - 0.6967, training time - -7.0 seconds
2023-03-27 13:19:50,062 : [INFO]  Batch 18: Testing set : loss - 0.5472, accuracy - 0.7402, recall - 0.9216, AUC - 0.8913, F1 - 0.7801, precision - 0.6763
2023-03-27 13:19:50,070 : [INFO]  Batch 19 initialized 
2023-03-27 13:19:50,504 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:50,764 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-27 13:19:54,134 : [INFO]  ------------------------- Batch round 1, loss: 0.5421 -------------------------
2023-03-27 13:19:54,134 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:54,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:54,140 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-27 13:19:55,829 : [INFO]  ------------------------- Batch round 2, loss: 0.5366 -------------------------
2023-03-27 13:19:55,829 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:55,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:55,833 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-27 13:19:57,509 : [INFO]  ------------------------- Batch round 3, loss: 0.5318 -------------------------
2023-03-27 13:19:57,509 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:57,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:57,515 : [INFO]  Batch number 19 model fetched from the server
2023-03-27 13:19:57,515 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-27 13:19:58,687 : [INFO]  Batch 19: Training set : loss - 0.5302, accuracy - 0.788, recall - 0.9239, AUC - 0.9011, F1 - 0.8134, precision - 0.7265, training time - -7.0 seconds
2023-03-27 13:19:58,688 : [INFO]  Batch 19: Testing set : loss - 0.5561, accuracy - 0.7402, recall - 0.951, AUC - 0.9108, F1 - 0.7854, precision - 0.669
2023-03-27 13:19:58,698 : [INFO]  Batch 20 initialized 
2023-03-27 13:19:59,103 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:59,366 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-27 13:20:02,790 : [INFO]  ------------------------- Batch round 1, loss: 0.567 -------------------------
2023-03-27 13:20:02,790 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:02,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:02,830 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-27 13:20:04,542 : [INFO]  ------------------------- Batch round 2, loss: 0.5613 -------------------------
2023-03-27 13:20:04,543 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:04,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:04,585 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-27 13:20:06,248 : [INFO]  ------------------------- Batch round 3, loss: 0.5595 -------------------------
2023-03-27 13:20:06,248 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:06,293 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:06,295 : [INFO]  Batch number 20 model fetched from the server
2023-03-27 13:20:06,296 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-27 13:20:07,474 : [INFO]  Batch 20: Training set : loss - 0.5596, accuracy - 0.7446, recall - 0.9022, AUC - 0.8793, F1 - 0.7793, precision - 0.686, training time - -7.0 seconds
2023-03-27 13:20:07,475 : [INFO]  Batch 20: Testing set : loss - 0.5776, accuracy - 0.7206, recall - 0.9608, AUC - 0.8654, F1 - 0.7747, precision - 0.649
2023-03-27 13:20:07,484 : [INFO]  Batch 21 initialized 
2023-03-27 13:20:07,917 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:08,175 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-27 13:20:11,597 : [INFO]  ------------------------- Batch round 1, loss: 0.5704 -------------------------
2023-03-27 13:20:11,597 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:11,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:11,616 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-27 13:20:13,305 : [INFO]  ------------------------- Batch round 2, loss: 0.5699 -------------------------
2023-03-27 13:20:13,305 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:13,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:13,326 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-27 13:20:15,032 : [INFO]  ------------------------- Batch round 3, loss: 0.5671 -------------------------
2023-03-27 13:20:15,033 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:15,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:15,084 : [INFO]  Batch number 21 model fetched from the server
2023-03-27 13:20:15,084 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-27 13:20:16,232 : [INFO]  Batch 21: Training set : loss - 0.5722, accuracy - 0.75, recall - 0.9565, AUC - 0.8408, F1 - 0.7928, precision - 0.6769, training time - -7.0 seconds
2023-03-27 13:20:16,235 : [INFO]  Batch 21: Testing set : loss - 0.5615, accuracy - 0.7304, recall - 0.8824, AUC - 0.8828, F1 - 0.766, precision - 0.6767
2023-03-27 13:20:16,241 : [INFO]  Batch 22 initialized 
2023-03-27 13:20:16,647 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:16,911 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-27 13:20:20,258 : [INFO]  ------------------------- Batch round 1, loss: 0.5398 -------------------------
2023-03-27 13:20:20,258 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:20,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:20,362 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-27 13:20:22,150 : [INFO]  ------------------------- Batch round 2, loss: 0.5363 -------------------------
2023-03-27 13:20:22,150 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:22,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:22,239 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-27 13:20:23,874 : [INFO]  ------------------------- Batch round 3, loss: 0.5324 -------------------------
2023-03-27 13:20:23,874 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:23,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:23,931 : [INFO]  Batch number 22 model fetched from the server
2023-03-27 13:20:23,931 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-27 13:20:25,065 : [INFO]  Batch 22: Training set : loss - 0.5327, accuracy - 0.7717, recall - 0.9022, AUC - 0.9005, F1 - 0.7981, precision - 0.7155, training time - -7.0 seconds
2023-03-27 13:20:25,065 : [INFO]  Batch 22: Testing set : loss - 0.5629, accuracy - 0.7451, recall - 0.8824, AUC - 0.8551, F1 - 0.7759, precision - 0.6923
2023-03-27 13:20:25,077 : [INFO]  Batch 23 initialized 
2023-03-27 13:20:25,500 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:25,765 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-27 13:20:29,180 : [INFO]  ------------------------- Batch round 1, loss: 0.5706 -------------------------
2023-03-27 13:20:29,180 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:29,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:29,225 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-27 13:20:30,984 : [INFO]  ------------------------- Batch round 2, loss: 0.5627 -------------------------
2023-03-27 13:20:30,984 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:30,987 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:30,989 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-27 13:20:32,693 : [INFO]  ------------------------- Batch round 3, loss: 0.5613 -------------------------
2023-03-27 13:20:32,693 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:32,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:32,698 : [INFO]  Batch number 23 model fetched from the server
2023-03-27 13:20:32,698 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-27 13:20:33,866 : [INFO]  Batch 23: Training set : loss - 0.557, accuracy - 0.7446, recall - 0.9457, AUC - 0.8946, F1 - 0.7873, precision - 0.6744, training time - -7.0 seconds
2023-03-27 13:20:33,866 : [INFO]  Batch 23: Testing set : loss - 0.5509, accuracy - 0.7794, recall - 0.9412, AUC - 0.8813, F1 - 0.8101, precision - 0.7111
2023-03-27 13:20:33,877 : [INFO]  Batch 24 initialized 
2023-03-27 13:20:34,283 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:34,555 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-27 13:20:37,990 : [INFO]  ------------------------- Batch round 1, loss: 0.5656 -------------------------
2023-03-27 13:20:37,990 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:37,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:37,995 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-27 13:20:39,660 : [INFO]  ------------------------- Batch round 2, loss: 0.5616 -------------------------
2023-03-27 13:20:39,660 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:39,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:39,665 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-27 13:20:41,348 : [INFO]  ------------------------- Batch round 3, loss: 0.5544 -------------------------
2023-03-27 13:20:41,348 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:41,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:41,353 : [INFO]  Batch number 24 model fetched from the server
2023-03-27 13:20:41,353 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-27 13:20:42,502 : [INFO]  Batch 24: Training set : loss - 0.5599, accuracy - 0.75, recall - 0.9348, AUC - 0.8922, F1 - 0.789, precision - 0.6825, training time - -7.0 seconds
2023-03-27 13:20:42,502 : [INFO]  Batch 24: Testing set : loss - 0.5559, accuracy - 0.7549, recall - 0.9608, AUC - 0.8842, F1 - 0.7967, precision - 0.6806
2023-03-27 13:20:42,512 : [INFO]  Batch 25 initialized 
2023-03-27 13:20:42,918 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:43,200 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-27 13:20:46,611 : [INFO]  ------------------------- Batch round 1, loss: 0.5503 -------------------------
2023-03-27 13:20:46,612 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:46,634 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:46,636 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-27 13:20:48,408 : [INFO]  ------------------------- Batch round 2, loss: 0.5455 -------------------------
2023-03-27 13:20:48,409 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:48,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:48,416 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-27 13:20:50,206 : [INFO]  ------------------------- Batch round 3, loss: 0.5438 -------------------------
2023-03-27 13:20:50,206 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:50,225 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:50,227 : [INFO]  Batch number 25 model fetched from the server
2023-03-27 13:20:50,227 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-27 13:20:51,436 : [INFO]  Batch 25: Training set : loss - 0.5445, accuracy - 0.7554, recall - 0.9783, AUC - 0.9273, F1 - 0.8, precision - 0.6767, training time - -7.0 seconds
2023-03-27 13:20:51,436 : [INFO]  Batch 25: Testing set : loss - 0.5453, accuracy - 0.7647, recall - 0.951, AUC - 0.8903, F1 - 0.8017, precision - 0.6929
2023-03-27 13:20:51,445 : [INFO]  Batch 26 initialized 
2023-03-27 13:20:51,863 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:52,140 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-27 13:20:55,597 : [INFO]  ------------------------- Batch round 1, loss: 0.5296 -------------------------
2023-03-27 13:20:55,597 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:55,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:55,657 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-27 13:20:57,403 : [INFO]  ------------------------- Batch round 2, loss: 0.5274 -------------------------
2023-03-27 13:20:57,404 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:57,417 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:57,419 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-27 13:20:59,203 : [INFO]  ------------------------- Batch round 3, loss: 0.5219 -------------------------
2023-03-27 13:20:59,203 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:59,208 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:59,210 : [INFO]  Batch number 26 model fetched from the server
2023-03-27 13:20:59,210 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-27 13:21:00,384 : [INFO]  Batch 26: Training set : loss - 0.5214, accuracy - 0.8098, recall - 0.9891, AUC - 0.9428, F1 - 0.8387, precision - 0.728, training time - -7.0 seconds
2023-03-27 13:21:00,385 : [INFO]  Batch 26: Testing set : loss - 0.5596, accuracy - 0.7451, recall - 0.902, AUC - 0.8792, F1 - 0.7797, precision - 0.6866
2023-03-27 13:21:00,427 : [INFO]  Batch 27 initialized 
2023-03-27 13:21:00,828 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:01,105 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-27 13:21:04,574 : [INFO]  ------------------------- Batch round 1, loss: 0.5674 -------------------------
2023-03-27 13:21:04,574 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:04,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:04,631 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-27 13:21:06,292 : [INFO]  ------------------------- Batch round 2, loss: 0.5604 -------------------------
2023-03-27 13:21:06,292 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:06,336 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:06,339 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-27 13:21:07,981 : [INFO]  ------------------------- Batch round 3, loss: 0.555 -------------------------
2023-03-27 13:21:07,981 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:08,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:08,055 : [INFO]  Batch number 27 model fetched from the server
2023-03-27 13:21:08,055 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-27 13:21:09,206 : [INFO]  Batch 27: Training set : loss - 0.5537, accuracy - 0.7446, recall - 0.9022, AUC - 0.8902, F1 - 0.7793, precision - 0.686, training time - -7.0 seconds
2023-03-27 13:21:09,206 : [INFO]  Batch 27: Testing set : loss - 0.5827, accuracy - 0.7108, recall - 0.9216, AUC - 0.8446, F1 - 0.7611, precision - 0.6483
2023-03-27 13:21:09,217 : [INFO]  Batch 28 initialized 
2023-03-27 13:21:09,625 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:09,906 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-27 13:21:13,269 : [INFO]  ------------------------- Batch round 1, loss: 0.5876 -------------------------
2023-03-27 13:21:13,269 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:13,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:13,301 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-27 13:21:14,958 : [INFO]  ------------------------- Batch round 2, loss: 0.5807 -------------------------
2023-03-27 13:21:14,958 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:14,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:14,964 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-27 13:21:16,680 : [INFO]  ------------------------- Batch round 3, loss: 0.5753 -------------------------
2023-03-27 13:21:16,680 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:16,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:16,689 : [INFO]  Batch number 28 model fetched from the server
2023-03-27 13:21:16,689 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-27 13:21:17,937 : [INFO]  Batch 28: Training set : loss - 0.5716, accuracy - 0.712, recall - 0.913, AUC - 0.8378, F1 - 0.7602, precision - 0.6512, training time - -7.0 seconds
2023-03-27 13:21:17,938 : [INFO]  Batch 28: Testing set : loss - 0.556, accuracy - 0.7549, recall - 0.9412, AUC - 0.9092, F1 - 0.7934, precision - 0.6857
2023-03-27 13:21:17,943 : [INFO]  Batch 29 initialized 
2023-03-27 13:21:18,361 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:18,643 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-27 13:21:22,070 : [INFO]  ------------------------- Batch round 1, loss: 0.5624 -------------------------
2023-03-27 13:21:22,070 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:22,141 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:22,143 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-27 13:21:23,828 : [INFO]  ------------------------- Batch round 2, loss: 0.5579 -------------------------
2023-03-27 13:21:23,828 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:23,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:23,893 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-27 13:21:25,588 : [INFO]  ------------------------- Batch round 3, loss: 0.5542 -------------------------
2023-03-27 13:21:25,588 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:25,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:25,661 : [INFO]  Batch number 29 model fetched from the server
2023-03-27 13:21:25,661 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-27 13:21:26,825 : [INFO]  Batch 29: Training set : loss - 0.5555, accuracy - 0.7717, recall - 0.9457, AUC - 0.886, F1 - 0.8056, precision - 0.7016, training time - -7.0 seconds
2023-03-27 13:21:26,825 : [INFO]  Batch 29: Testing set : loss - 0.5654, accuracy - 0.7451, recall - 0.9706, AUC - 0.8756, F1 - 0.792, precision - 0.6689
2023-03-27 13:21:26,835 : [INFO]  Batch 30 initialized 
2023-03-27 13:21:27,255 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:27,535 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-27 13:21:30,929 : [INFO]  ------------------------- Batch round 1, loss: 0.567 -------------------------
2023-03-27 13:21:30,929 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:30,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:30,950 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-27 13:21:32,598 : [INFO]  ------------------------- Batch round 2, loss: 0.5601 -------------------------
2023-03-27 13:21:32,598 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:32,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:32,617 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-27 13:21:34,294 : [INFO]  ------------------------- Batch round 3, loss: 0.5632 -------------------------
2023-03-27 13:21:34,294 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:34,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:34,352 : [INFO]  Batch number 30 model fetched from the server
2023-03-27 13:21:34,352 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-27 13:21:35,507 : [INFO]  Batch 30: Training set : loss - 0.5623, accuracy - 0.7663, recall - 0.9022, AUC - 0.8631, F1 - 0.7943, precision - 0.7094, training time - -7.0 seconds
2023-03-27 13:21:35,507 : [INFO]  Batch 30: Testing set : loss - 0.5375, accuracy - 0.7745, recall - 0.951, AUC - 0.8936, F1 - 0.8083, precision - 0.7029
2023-03-27 13:21:35,513 : [INFO]  Batch 31 initialized 
2023-03-27 13:21:35,923 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:36,207 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-27 13:21:39,591 : [INFO]  ------------------------- Batch round 1, loss: 0.5467 -------------------------
2023-03-27 13:21:39,591 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:39,631 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:39,634 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-27 13:21:41,297 : [INFO]  ------------------------- Batch round 2, loss: 0.5383 -------------------------
2023-03-27 13:21:41,297 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:41,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:41,304 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-27 13:21:43,030 : [INFO]  ------------------------- Batch round 3, loss: 0.5345 -------------------------
2023-03-27 13:21:43,031 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:43,058 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:43,060 : [INFO]  Batch number 31 model fetched from the server
2023-03-27 13:21:43,060 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-27 13:21:44,200 : [INFO]  Batch 31: Training set : loss - 0.5322, accuracy - 0.7717, recall - 0.9239, AUC - 0.9078, F1 - 0.8019, precision - 0.7083, training time - -7.0 seconds
2023-03-27 13:21:44,201 : [INFO]  Batch 31: Testing set : loss - 0.5399, accuracy - 0.7745, recall - 0.902, AUC - 0.8953, F1 - 0.8, precision - 0.7188
2023-03-27 13:21:44,211 : [INFO]  Batch 32 initialized 
2023-03-27 13:21:44,616 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:44,911 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-27 13:21:48,366 : [INFO]  ------------------------- Batch round 1, loss: 0.5471 -------------------------
2023-03-27 13:21:48,366 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:48,440 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:48,442 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-27 13:21:50,158 : [INFO]  ------------------------- Batch round 2, loss: 0.5467 -------------------------
2023-03-27 13:21:50,158 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:50,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:50,257 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-27 13:21:51,931 : [INFO]  ------------------------- Batch round 3, loss: 0.5421 -------------------------
2023-03-27 13:21:51,931 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:51,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:51,988 : [INFO]  Batch number 32 model fetched from the server
2023-03-27 13:21:51,988 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-27 13:21:53,147 : [INFO]  Batch 32: Training set : loss - 0.5429, accuracy - 0.7663, recall - 0.9239, AUC - 0.897, F1 - 0.7981, precision - 0.7025, training time - -7.0 seconds
2023-03-27 13:21:53,147 : [INFO]  Batch 32: Testing set : loss - 0.5677, accuracy - 0.7108, recall - 0.8922, AUC - 0.8596, F1 - 0.7552, precision - 0.6547
2023-03-27 13:21:53,158 : [INFO]  Batch 33 initialized 
2023-03-27 13:21:53,567 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:53,866 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-27 13:21:57,280 : [INFO]  ------------------------- Batch round 1, loss: 0.5298 -------------------------
2023-03-27 13:21:57,280 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:57,317 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:57,320 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-27 13:21:58,998 : [INFO]  ------------------------- Batch round 2, loss: 0.5233 -------------------------
2023-03-27 13:21:58,998 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:59,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:59,024 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-27 13:22:00,713 : [INFO]  ------------------------- Batch round 3, loss: 0.517 -------------------------
2023-03-27 13:22:00,713 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:00,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:00,718 : [INFO]  Batch number 33 model fetched from the server
2023-03-27 13:22:00,718 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-27 13:22:01,883 : [INFO]  Batch 33: Training set : loss - 0.5174, accuracy - 0.8207, recall - 0.9674, AUC - 0.9262, F1 - 0.8436, precision - 0.7479, training time - -7.0 seconds
2023-03-27 13:22:01,883 : [INFO]  Batch 33: Testing set : loss - 0.5465, accuracy - 0.7549, recall - 0.951, AUC - 0.9228, F1 - 0.7951, precision - 0.6831
2023-03-27 13:22:01,889 : [INFO]  Batch 34 initialized 
2023-03-27 13:22:02,299 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:02,593 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-27 13:22:06,011 : [INFO]  ------------------------- Batch round 1, loss: 0.5836 -------------------------
2023-03-27 13:22:06,011 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:06,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:06,017 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-27 13:22:07,717 : [INFO]  ------------------------- Batch round 2, loss: 0.5757 -------------------------
2023-03-27 13:22:07,717 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:07,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:07,721 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-27 13:22:09,400 : [INFO]  ------------------------- Batch round 3, loss: 0.5719 -------------------------
2023-03-27 13:22:09,401 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:09,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:09,406 : [INFO]  Batch number 34 model fetched from the server
2023-03-27 13:22:09,406 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-27 13:22:10,562 : [INFO]  Batch 34: Training set : loss - 0.5779, accuracy - 0.7283, recall - 0.9022, AUC - 0.8662, F1 - 0.7685, precision - 0.6694, training time - -7.0 seconds
2023-03-27 13:22:10,562 : [INFO]  Batch 34: Testing set : loss - 0.5421, accuracy - 0.75, recall - 0.9608, AUC - 0.9111, F1 - 0.7935, precision - 0.6759
2023-03-27 13:22:10,568 : [INFO]  Batch 35 initialized 
2023-03-27 13:22:10,977 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:11,273 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-27 13:22:14,634 : [INFO]  ------------------------- Batch round 1, loss: 0.5685 -------------------------
2023-03-27 13:22:14,634 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:14,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:14,666 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-27 13:22:16,340 : [INFO]  ------------------------- Batch round 2, loss: 0.5654 -------------------------
2023-03-27 13:22:16,341 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:16,344 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:16,346 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-27 13:22:17,974 : [INFO]  ------------------------- Batch round 3, loss: 0.558 -------------------------
2023-03-27 13:22:17,974 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:18,006 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:18,008 : [INFO]  Batch number 35 model fetched from the server
2023-03-27 13:22:18,008 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-27 13:22:19,158 : [INFO]  Batch 35: Training set : loss - 0.561, accuracy - 0.7337, recall - 0.9022, AUC - 0.8658, F1 - 0.7721, precision - 0.6748, training time - -7.0 seconds
2023-03-27 13:22:19,158 : [INFO]  Batch 35: Testing set : loss - 0.5563, accuracy - 0.7598, recall - 0.9412, AUC - 0.8901, F1 - 0.7967, precision - 0.6906
2023-03-27 13:22:19,169 : [INFO]  Batch 36 initialized 
2023-03-27 13:22:19,584 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:19,880 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-27 13:22:23,325 : [INFO]  ------------------------- Batch round 1, loss: 0.5718 -------------------------
2023-03-27 13:22:23,325 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:23,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:23,331 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-27 13:22:25,038 : [INFO]  ------------------------- Batch round 2, loss: 0.5668 -------------------------
2023-03-27 13:22:25,038 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:25,047 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:25,049 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-27 13:22:26,775 : [INFO]  ------------------------- Batch round 3, loss: 0.5655 -------------------------
2023-03-27 13:22:26,775 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:26,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:26,780 : [INFO]  Batch number 36 model fetched from the server
2023-03-27 13:22:26,780 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-27 13:22:27,921 : [INFO]  Batch 36: Training set : loss - 0.5679, accuracy - 0.7228, recall - 0.9457, AUC - 0.8977, F1 - 0.7733, precision - 0.6541, training time - -7.0 seconds
2023-03-27 13:22:27,922 : [INFO]  Batch 36: Testing set : loss - 0.5861, accuracy - 0.701, recall - 0.9118, AUC - 0.8463, F1 - 0.753, precision - 0.6414
2023-03-27 13:22:27,932 : [INFO]  Batch 37 initialized 
2023-03-27 13:22:28,340 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:28,642 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-27 13:22:32,082 : [INFO]  ------------------------- Batch round 1, loss: 0.536 -------------------------
2023-03-27 13:22:32,082 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:32,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:32,087 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-27 13:22:33,759 : [INFO]  ------------------------- Batch round 2, loss: 0.5322 -------------------------
2023-03-27 13:22:33,759 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:33,762 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:33,764 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-27 13:22:35,515 : [INFO]  ------------------------- Batch round 3, loss: 0.5307 -------------------------
2023-03-27 13:22:35,516 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:35,518 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:35,520 : [INFO]  Batch number 37 model fetched from the server
2023-03-27 13:22:35,520 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-27 13:22:36,659 : [INFO]  Batch 37: Training set : loss - 0.5285, accuracy - 0.788, recall - 0.9674, AUC - 0.9308, F1 - 0.8203, precision - 0.712, training time - -7.0 seconds
2023-03-27 13:22:36,659 : [INFO]  Batch 37: Testing set : loss - 0.5579, accuracy - 0.7598, recall - 0.9118, AUC - 0.8727, F1 - 0.7915, precision - 0.6992
2023-03-27 13:22:36,667 : [INFO]  Batch 38 initialized 
2023-03-27 13:22:37,076 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:37,375 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-27 13:22:40,783 : [INFO]  ------------------------- Batch round 1, loss: 0.5609 -------------------------
2023-03-27 13:22:40,783 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:40,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:40,791 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-27 13:22:42,546 : [INFO]  ------------------------- Batch round 2, loss: 0.556 -------------------------
2023-03-27 13:22:42,546 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:42,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:42,551 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-27 13:22:44,242 : [INFO]  ------------------------- Batch round 3, loss: 0.5514 -------------------------
2023-03-27 13:22:44,242 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:44,245 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:44,247 : [INFO]  Batch number 38 model fetched from the server
2023-03-27 13:22:44,247 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-27 13:22:45,390 : [INFO]  Batch 38: Training set : loss - 0.5542, accuracy - 0.7446, recall - 0.9348, AUC - 0.8881, F1 - 0.7854, precision - 0.6772, training time - -7.0 seconds
2023-03-27 13:22:45,391 : [INFO]  Batch 38: Testing set : loss - 0.5674, accuracy - 0.7353, recall - 0.951, AUC - 0.8863, F1 - 0.7823, precision - 0.6644
2023-03-27 13:22:45,402 : [INFO]  Batch 39 initialized 
2023-03-27 13:22:45,816 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:46,112 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-27 13:22:49,537 : [INFO]  ------------------------- Batch round 1, loss: 0.5515 -------------------------
2023-03-27 13:22:49,537 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:49,546 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:49,548 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-27 13:22:51,230 : [INFO]  ------------------------- Batch round 2, loss: 0.5427 -------------------------
2023-03-27 13:22:51,230 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:51,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:51,246 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-27 13:22:52,950 : [INFO]  ------------------------- Batch round 3, loss: 0.5389 -------------------------
2023-03-27 13:22:52,950 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:52,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:52,955 : [INFO]  Batch number 39 model fetched from the server
2023-03-27 13:22:52,955 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-27 13:22:54,113 : [INFO]  Batch 39: Training set : loss - 0.5443, accuracy - 0.7826, recall - 0.9674, AUC - 0.908, F1 - 0.8165, precision - 0.7063, training time - -7.0 seconds
2023-03-27 13:22:54,114 : [INFO]  Batch 39: Testing set : loss - 0.5558, accuracy - 0.7549, recall - 0.9118, AUC - 0.8879, F1 - 0.7881, precision - 0.694
2023-03-27 13:22:54,124 : [INFO]  Batch 40 initialized 
2023-03-27 13:22:54,536 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:54,836 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-27 13:22:58,191 : [INFO]  ------------------------- Batch round 1, loss: 0.5508 -------------------------
2023-03-27 13:22:58,191 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:58,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:58,279 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-27 13:22:59,904 : [INFO]  ------------------------- Batch round 2, loss: 0.5456 -------------------------
2023-03-27 13:22:59,905 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:59,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:59,970 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-27 13:23:01,603 : [INFO]  ------------------------- Batch round 3, loss: 0.5406 -------------------------
2023-03-27 13:23:01,603 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:01,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:01,659 : [INFO]  Batch number 40 model fetched from the server
2023-03-27 13:23:01,659 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-27 13:23:02,812 : [INFO]  Batch 40: Training set : loss - 0.5447, accuracy - 0.7989, recall - 0.8913, AUC - 0.8638, F1 - 0.8159, precision - 0.7523, training time - -7.0 seconds
2023-03-27 13:23:02,812 : [INFO]  Batch 40: Testing set : loss - 0.5449, accuracy - 0.7696, recall - 0.9216, AUC - 0.8844, F1 - 0.8, precision - 0.7068
2023-03-27 13:23:02,820 : [INFO]  Batch 41 initialized 
2023-03-27 13:23:03,229 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:03,536 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-27 13:23:06,910 : [INFO]  ------------------------- Batch round 1, loss: 0.5486 -------------------------
2023-03-27 13:23:06,911 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:06,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:06,936 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-27 13:23:08,604 : [INFO]  ------------------------- Batch round 2, loss: 0.5452 -------------------------
2023-03-27 13:23:08,605 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:08,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:08,609 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-27 13:23:10,255 : [INFO]  ------------------------- Batch round 3, loss: 0.5398 -------------------------
2023-03-27 13:23:10,255 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:10,258 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:10,260 : [INFO]  Batch number 41 model fetched from the server
2023-03-27 13:23:10,260 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-27 13:23:11,403 : [INFO]  Batch 41: Training set : loss - 0.5364, accuracy - 0.7717, recall - 0.9783, AUC - 0.9004, F1 - 0.8108, precision - 0.6923, training time - -7.0 seconds
2023-03-27 13:23:11,403 : [INFO]  Batch 41: Testing set : loss - 0.5648, accuracy - 0.7255, recall - 0.9412, AUC - 0.8621, F1 - 0.7742, precision - 0.6575
2023-03-27 13:23:11,412 : [INFO]  Batch 42 initialized 
2023-03-27 13:23:11,819 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:12,119 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-27 13:23:15,480 : [INFO]  ------------------------- Batch round 1, loss: 0.5707 -------------------------
2023-03-27 13:23:15,480 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:15,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:15,544 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-27 13:23:17,278 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-27 13:23:17,278 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:17,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:17,290 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-27 13:23:19,059 : [INFO]  ------------------------- Batch round 3, loss: 0.5595 -------------------------
2023-03-27 13:23:19,059 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:19,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:19,097 : [INFO]  Batch number 42 model fetched from the server
2023-03-27 13:23:19,097 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-27 13:23:20,246 : [INFO]  Batch 42: Training set : loss - 0.5613, accuracy - 0.7228, recall - 0.9239, AUC - 0.8866, F1 - 0.7692, precision - 0.6589, training time - -7.0 seconds
2023-03-27 13:23:20,246 : [INFO]  Batch 42: Testing set : loss - 0.5778, accuracy - 0.6912, recall - 0.9314, AUC - 0.879, F1 - 0.751, precision - 0.6291
2023-03-27 13:23:20,255 : [INFO]  Batch 43 initialized 
2023-03-27 13:23:20,662 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:20,973 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-27 13:23:24,379 : [INFO]  ------------------------- Batch round 1, loss: 0.5248 -------------------------
2023-03-27 13:23:24,379 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:24,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:24,435 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-27 13:23:26,101 : [INFO]  ------------------------- Batch round 2, loss: 0.5213 -------------------------
2023-03-27 13:23:26,102 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:26,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:26,118 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-27 13:23:27,798 : [INFO]  ------------------------- Batch round 3, loss: 0.5177 -------------------------
2023-03-27 13:23:27,798 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:27,805 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:27,807 : [INFO]  Batch number 43 model fetched from the server
2023-03-27 13:23:27,807 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-27 13:23:28,968 : [INFO]  Batch 43: Training set : loss - 0.5197, accuracy - 0.8152, recall - 0.9674, AUC - 0.9361, F1 - 0.8396, precision - 0.7417, training time - -7.0 seconds
2023-03-27 13:23:28,968 : [INFO]  Batch 43: Testing set : loss - 0.5644, accuracy - 0.7059, recall - 0.902, AUC - 0.8706, F1 - 0.7541, precision - 0.6479
2023-03-27 13:23:28,975 : [INFO]  Batch 44 initialized 
2023-03-27 13:23:29,396 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:29,708 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-27 13:23:33,131 : [INFO]  ------------------------- Batch round 1, loss: 0.5619 -------------------------
2023-03-27 13:23:33,131 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:33,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:33,136 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-27 13:23:34,815 : [INFO]  ------------------------- Batch round 2, loss: 0.5539 -------------------------
2023-03-27 13:23:34,815 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:34,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:34,820 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-27 13:23:36,525 : [INFO]  ------------------------- Batch round 3, loss: 0.5492 -------------------------
2023-03-27 13:23:36,525 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:36,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:36,560 : [INFO]  Batch number 44 model fetched from the server
2023-03-27 13:23:36,560 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-27 13:23:37,696 : [INFO]  Batch 44: Training set : loss - 0.5479, accuracy - 0.75, recall - 0.913, AUC - 0.8979, F1 - 0.785, precision - 0.6885, training time - -7.0 seconds
2023-03-27 13:23:37,697 : [INFO]  Batch 44: Testing set : loss - 0.5712, accuracy - 0.7206, recall - 0.9118, AUC - 0.8526, F1 - 0.7654, precision - 0.6596
2023-03-27 13:23:37,706 : [INFO]  Batch 45 initialized 
2023-03-27 13:23:38,118 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:38,431 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-27 13:23:41,850 : [INFO]  ------------------------- Batch round 1, loss: 0.557 -------------------------
2023-03-27 13:23:41,850 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:41,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:41,858 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-27 13:23:43,517 : [INFO]  ------------------------- Batch round 2, loss: 0.5518 -------------------------
2023-03-27 13:23:43,518 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:43,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:43,582 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-27 13:23:45,226 : [INFO]  ------------------------- Batch round 3, loss: 0.5496 -------------------------
2023-03-27 13:23:45,226 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:45,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:45,266 : [INFO]  Batch number 45 model fetched from the server
2023-03-27 13:23:45,266 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-27 13:23:46,433 : [INFO]  Batch 45: Training set : loss - 0.5456, accuracy - 0.7826, recall - 0.9565, AUC - 0.8888, F1 - 0.8148, precision - 0.7097, training time - -7.0 seconds
2023-03-27 13:23:46,434 : [INFO]  Batch 45: Testing set : loss - 0.5575, accuracy - 0.7353, recall - 0.9216, AUC - 0.8746, F1 - 0.7769, precision - 0.6714
2023-03-27 13:23:46,442 : [INFO]  Batch 46 initialized 
2023-03-27 13:23:46,853 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:47,165 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-27 13:23:50,620 : [INFO]  ------------------------- Batch round 1, loss: 0.6078 -------------------------
2023-03-27 13:23:50,621 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:50,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:50,760 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-27 13:23:52,397 : [INFO]  ------------------------- Batch round 2, loss: 0.599 -------------------------
2023-03-27 13:23:52,397 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:52,488 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:52,490 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-27 13:23:54,127 : [INFO]  ------------------------- Batch round 3, loss: 0.5961 -------------------------
2023-03-27 13:23:54,128 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:54,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:54,218 : [INFO]  Batch number 46 model fetched from the server
2023-03-27 13:23:54,218 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-27 13:23:55,337 : [INFO]  Batch 46: Training set : loss - 0.5977, accuracy - 0.6902, recall - 0.8587, AUC - 0.8106, F1 - 0.7349, precision - 0.6423, training time - -7.0 seconds
2023-03-27 13:23:55,337 : [INFO]  Batch 46: Testing set : loss - 0.5792, accuracy - 0.7255, recall - 0.9118, AUC - 0.8504, F1 - 0.7686, precision - 0.6643
2023-03-27 13:23:55,347 : [INFO]  Batch 47 initialized 
2023-03-27 13:23:55,764 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:56,078 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-27 13:23:59,492 : [INFO]  ------------------------- Batch round 1, loss: 0.5538 -------------------------
2023-03-27 13:23:59,493 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:59,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:59,580 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-27 13:24:01,250 : [INFO]  ------------------------- Batch round 2, loss: 0.5495 -------------------------
2023-03-27 13:24:01,251 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:01,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:01,281 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-27 13:24:02,885 : [INFO]  ------------------------- Batch round 3, loss: 0.5508 -------------------------
2023-03-27 13:24:02,885 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:02,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:02,955 : [INFO]  Batch number 47 model fetched from the server
2023-03-27 13:24:02,955 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-27 13:24:04,098 : [INFO]  Batch 47: Training set : loss - 0.5473, accuracy - 0.7609, recall - 0.8913, AUC - 0.8794, F1 - 0.7885, precision - 0.7069, training time - -7.0 seconds
2023-03-27 13:24:04,098 : [INFO]  Batch 47: Testing set : loss - 0.585, accuracy - 0.7157, recall - 0.9314, AUC - 0.845, F1 - 0.7661, precision - 0.6507
2023-03-27 13:24:04,108 : [INFO]  Batch 48 initialized 
2023-03-27 13:24:04,525 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:04,834 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-27 13:24:08,170 : [INFO]  ------------------------- Batch round 1, loss: 0.5572 -------------------------
2023-03-27 13:24:08,170 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:08,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:08,314 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-27 13:24:09,943 : [INFO]  ------------------------- Batch round 2, loss: 0.5494 -------------------------
2023-03-27 13:24:09,943 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:10,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:10,044 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-27 13:24:11,636 : [INFO]  ------------------------- Batch round 3, loss: 0.5454 -------------------------
2023-03-27 13:24:11,636 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:11,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:11,742 : [INFO]  Batch number 48 model fetched from the server
2023-03-27 13:24:11,742 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-27 13:24:12,865 : [INFO]  Batch 48: Training set : loss - 0.5488, accuracy - 0.75, recall - 0.9348, AUC - 0.9106, F1 - 0.789, precision - 0.6825, training time - -7.0 seconds
2023-03-27 13:24:12,865 : [INFO]  Batch 48: Testing set : loss - 0.5654, accuracy - 0.7255, recall - 0.951, AUC - 0.8973, F1 - 0.776, precision - 0.6554
2023-03-27 13:24:12,875 : [INFO]  Batch 49 initialized 
2023-03-27 13:24:13,278 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:13,597 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-27 13:24:16,993 : [INFO]  ------------------------- Batch round 1, loss: 0.5427 -------------------------
2023-03-27 13:24:16,993 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:17,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:17,019 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-27 13:24:18,727 : [INFO]  ------------------------- Batch round 2, loss: 0.536 -------------------------
2023-03-27 13:24:18,728 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:18,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:18,732 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-27 13:24:20,407 : [INFO]  ------------------------- Batch round 3, loss: 0.533 -------------------------
2023-03-27 13:24:20,407 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:20,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:20,412 : [INFO]  Batch number 49 model fetched from the server
2023-03-27 13:24:20,412 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-27 13:24:21,570 : [INFO]  Batch 49: Training set : loss - 0.5311, accuracy - 0.7826, recall - 0.9891, AUC - 0.9343, F1 - 0.8198, precision - 0.7, training time - -7.0 seconds
2023-03-27 13:24:21,570 : [INFO]  Batch 49: Testing set : loss - 0.581, accuracy - 0.7206, recall - 0.9608, AUC - 0.8931, F1 - 0.7747, precision - 0.649
2023-03-27 13:24:21,576 : [INFO]  Batch 50 initialized 
2023-03-27 13:24:21,985 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:22,316 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-27 13:24:25,714 : [INFO]  ------------------------- Batch round 1, loss: 0.5468 -------------------------
2023-03-27 13:24:25,714 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:25,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:25,751 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-27 13:24:27,395 : [INFO]  ------------------------- Batch round 2, loss: 0.5405 -------------------------
2023-03-27 13:24:27,395 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:27,436 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:27,438 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-27 13:24:29,111 : [INFO]  ------------------------- Batch round 3, loss: 0.5368 -------------------------
2023-03-27 13:24:29,111 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:29,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:29,133 : [INFO]  Batch number 50 model fetched from the server
2023-03-27 13:24:29,134 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-27 13:24:30,287 : [INFO]  Batch 50: Training set : loss - 0.5318, accuracy - 0.7554, recall - 0.913, AUC - 0.9135, F1 - 0.7887, precision - 0.6942, training time - -7.0 seconds
2023-03-27 13:24:30,287 : [INFO]  Batch 50: Testing set : loss - 0.5292, accuracy - 0.7696, recall - 0.951, AUC - 0.918, F1 - 0.805, precision - 0.6978
2023-03-27 13:24:30,292 : [INFO]  Batch 51 initialized 
2023-03-27 13:24:30,701 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:31,022 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-27 13:24:34,477 : [INFO]  ------------------------- Batch round 1, loss: 0.5209 -------------------------
2023-03-27 13:24:34,477 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:34,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:34,482 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-27 13:24:36,242 : [INFO]  ------------------------- Batch round 2, loss: 0.517 -------------------------
2023-03-27 13:24:36,242 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:36,245 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:36,247 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-27 13:24:37,901 : [INFO]  ------------------------- Batch round 3, loss: 0.5128 -------------------------
2023-03-27 13:24:37,901 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:37,904 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:37,906 : [INFO]  Batch number 51 model fetched from the server
2023-03-27 13:24:37,906 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-27 13:24:39,051 : [INFO]  Batch 51: Training set : loss - 0.5138, accuracy - 0.7826, recall - 0.9783, AUC - 0.9546, F1 - 0.8182, precision - 0.7031, training time - -7.0 seconds
2023-03-27 13:24:39,051 : [INFO]  Batch 51: Testing set : loss - 0.5315, accuracy - 0.7794, recall - 0.9608, AUC - 0.9144, F1 - 0.8133, precision - 0.705
2023-03-27 13:24:39,059 : [INFO]  Batch 52 initialized 
2023-03-27 13:24:39,467 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:39,793 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-27 13:24:43,194 : [INFO]  ------------------------- Batch round 1, loss: 0.5477 -------------------------
2023-03-27 13:24:43,194 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:43,205 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:43,208 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-27 13:24:44,852 : [INFO]  ------------------------- Batch round 2, loss: 0.5471 -------------------------
2023-03-27 13:24:44,853 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:44,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:44,916 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-27 13:24:46,569 : [INFO]  ------------------------- Batch round 3, loss: 0.5437 -------------------------
2023-03-27 13:24:46,569 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:46,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:46,592 : [INFO]  Batch number 52 model fetched from the server
2023-03-27 13:24:46,592 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-27 13:24:47,765 : [INFO]  Batch 52: Training set : loss - 0.5476, accuracy - 0.7554, recall - 0.9565, AUC - 0.9155, F1 - 0.7964, precision - 0.6822, training time - -7.0 seconds
2023-03-27 13:24:47,766 : [INFO]  Batch 52: Testing set : loss - 0.5616, accuracy - 0.7402, recall - 0.9608, AUC - 0.8938, F1 - 0.7871, precision - 0.6667
2023-03-27 13:24:47,777 : [INFO]  Batch 53 initialized 
2023-03-27 13:24:48,180 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:48,515 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-27 13:24:51,891 : [INFO]  ------------------------- Batch round 1, loss: 0.568 -------------------------
2023-03-27 13:24:51,892 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:51,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:51,957 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-27 13:24:53,637 : [INFO]  ------------------------- Batch round 2, loss: 0.5619 -------------------------
2023-03-27 13:24:53,637 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:53,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:53,672 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-27 13:24:55,320 : [INFO]  ------------------------- Batch round 3, loss: 0.559 -------------------------
2023-03-27 13:24:55,320 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:55,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:55,371 : [INFO]  Batch number 53 model fetched from the server
2023-03-27 13:24:55,371 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-27 13:24:56,520 : [INFO]  Batch 53: Training set : loss - 0.559, accuracy - 0.7391, recall - 0.9565, AUC - 0.9192, F1 - 0.7857, precision - 0.6667, training time - -7.0 seconds
2023-03-27 13:24:56,520 : [INFO]  Batch 53: Testing set : loss - 0.5436, accuracy - 0.7647, recall - 0.902, AUC - 0.9012, F1 - 0.7931, precision - 0.7077
2023-03-27 13:24:56,529 : [INFO]  Batch 54 initialized 
2023-03-27 13:24:56,934 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:57,266 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-27 13:25:00,644 : [INFO]  ------------------------- Batch round 1, loss: 0.5433 -------------------------
2023-03-27 13:25:00,644 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:00,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:00,672 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-27 13:25:02,334 : [INFO]  ------------------------- Batch round 2, loss: 0.5371 -------------------------
2023-03-27 13:25:02,334 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:02,337 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:02,340 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-27 13:25:04,025 : [INFO]  ------------------------- Batch round 3, loss: 0.5317 -------------------------
2023-03-27 13:25:04,025 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:04,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:04,030 : [INFO]  Batch number 54 model fetched from the server
2023-03-27 13:25:04,030 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-27 13:25:05,186 : [INFO]  Batch 54: Training set : loss - 0.5322, accuracy - 0.7663, recall - 0.9674, AUC - 0.9308, F1 - 0.8054, precision - 0.6899, training time - -7.0 seconds
2023-03-27 13:25:05,186 : [INFO]  Batch 54: Testing set : loss - 0.5506, accuracy - 0.7402, recall - 0.951, AUC - 0.8967, F1 - 0.7854, precision - 0.669
2023-03-27 13:25:05,191 : [INFO]  Batch 55 initialized 
2023-03-27 13:25:05,604 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:05,941 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-27 13:25:09,386 : [INFO]  ------------------------- Batch round 1, loss: 0.542 -------------------------
2023-03-27 13:25:09,386 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:09,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:09,391 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-27 13:25:11,080 : [INFO]  ------------------------- Batch round 2, loss: 0.5341 -------------------------
2023-03-27 13:25:11,080 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:11,083 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:11,085 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-27 13:25:12,761 : [INFO]  ------------------------- Batch round 3, loss: 0.5306 -------------------------
2023-03-27 13:25:12,762 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:12,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:12,766 : [INFO]  Batch number 55 model fetched from the server
2023-03-27 13:25:12,766 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-27 13:25:13,898 : [INFO]  Batch 55: Training set : loss - 0.5321, accuracy - 0.7717, recall - 0.9783, AUC - 0.9213, F1 - 0.8108, precision - 0.6923, training time - -7.0 seconds
2023-03-27 13:25:13,898 : [INFO]  Batch 55: Testing set : loss - 0.55, accuracy - 0.7549, recall - 0.9902, AUC - 0.9365, F1 - 0.8016, precision - 0.6733
2023-03-27 13:25:13,906 : [INFO]  Batch 56 initialized 
2023-03-27 13:25:14,314 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:14,648 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-27 13:25:18,031 : [INFO]  ------------------------- Batch round 1, loss: 0.5188 -------------------------
2023-03-27 13:25:18,032 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:18,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:18,080 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-27 13:25:19,724 : [INFO]  ------------------------- Batch round 2, loss: 0.5126 -------------------------
2023-03-27 13:25:19,724 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:19,753 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:19,755 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-27 13:25:21,420 : [INFO]  ------------------------- Batch round 3, loss: 0.5077 -------------------------
2023-03-27 13:25:21,421 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:21,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:21,435 : [INFO]  Batch number 56 model fetched from the server
2023-03-27 13:25:21,435 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-27 13:25:22,619 : [INFO]  Batch 56: Training set : loss - 0.5091, accuracy - 0.8043, recall - 0.9565, AUC - 0.9425, F1 - 0.8302, precision - 0.7333, training time - -7.0 seconds
2023-03-27 13:25:22,619 : [INFO]  Batch 56: Testing set : loss - 0.5484, accuracy - 0.7647, recall - 0.902, AUC - 0.8922, F1 - 0.7931, precision - 0.7077
2023-03-27 13:25:22,629 : [INFO]  Batch 57 initialized 
2023-03-27 13:25:23,039 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:23,377 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-27 13:25:26,787 : [INFO]  ------------------------- Batch round 1, loss: 0.542 -------------------------
2023-03-27 13:25:26,787 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:26,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:26,874 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-27 13:25:28,574 : [INFO]  ------------------------- Batch round 2, loss: 0.5384 -------------------------
2023-03-27 13:25:28,574 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:28,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:28,590 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-27 13:25:30,255 : [INFO]  ------------------------- Batch round 3, loss: 0.5338 -------------------------
2023-03-27 13:25:30,256 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:30,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:30,270 : [INFO]  Batch number 57 model fetched from the server
2023-03-27 13:25:30,270 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-27 13:25:31,435 : [INFO]  Batch 57: Training set : loss - 0.5404, accuracy - 0.7446, recall - 0.9022, AUC - 0.9169, F1 - 0.7793, precision - 0.686, training time - -7.0 seconds
2023-03-27 13:25:31,435 : [INFO]  Batch 57: Testing set : loss - 0.5586, accuracy - 0.75, recall - 0.9804, AUC - 0.9205, F1 - 0.7968, precision - 0.6711
2023-03-27 13:25:31,447 : [INFO]  Batch 58 initialized 
2023-03-27 13:25:31,849 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:32,186 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-27 13:25:35,559 : [INFO]  ------------------------- Batch round 1, loss: 0.5318 -------------------------
2023-03-27 13:25:35,559 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:35,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:35,617 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-27 13:25:37,292 : [INFO]  ------------------------- Batch round 2, loss: 0.5274 -------------------------
2023-03-27 13:25:37,292 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:37,312 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:37,314 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-27 13:25:38,917 : [INFO]  ------------------------- Batch round 3, loss: 0.5262 -------------------------
2023-03-27 13:25:38,918 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:38,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:38,935 : [INFO]  Batch number 58 model fetched from the server
2023-03-27 13:25:38,935 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-27 13:25:40,084 : [INFO]  Batch 58: Training set : loss - 0.5269, accuracy - 0.8043, recall - 0.9565, AUC - 0.9273, F1 - 0.8302, precision - 0.7333, training time - -7.0 seconds
2023-03-27 13:25:40,084 : [INFO]  Batch 58: Testing set : loss - 0.5786, accuracy - 0.7157, recall - 0.9216, AUC - 0.8668, F1 - 0.7642, precision - 0.6528
2023-03-27 13:25:40,093 : [INFO]  Batch 59 initialized 
2023-03-27 13:25:40,491 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:40,824 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-27 13:25:44,236 : [INFO]  ------------------------- Batch round 1, loss: 0.5369 -------------------------
2023-03-27 13:25:44,237 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:44,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:44,273 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-27 13:25:45,918 : [INFO]  ------------------------- Batch round 2, loss: 0.5337 -------------------------
2023-03-27 13:25:45,918 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:45,923 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:45,924 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-27 13:25:47,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5302 -------------------------
2023-03-27 13:25:47,580 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:47,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:47,584 : [INFO]  Batch number 59 model fetched from the server
2023-03-27 13:25:47,584 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-27 13:25:48,748 : [INFO]  Batch 59: Training set : loss - 0.53, accuracy - 0.7772, recall - 0.9783, AUC - 0.9574, F1 - 0.8145, precision - 0.6977, training time - -7.0 seconds
2023-03-27 13:25:48,748 : [INFO]  Batch 59: Testing set : loss - 0.5506, accuracy - 0.7451, recall - 0.951, AUC - 0.9072, F1 - 0.7886, precision - 0.6736
2023-03-27 13:25:48,753 : [INFO]  Batch 60 initialized 
2023-03-27 13:25:49,159 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:49,502 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-27 13:25:52,920 : [INFO]  ------------------------- Batch round 1, loss: 0.5538 -------------------------
2023-03-27 13:25:52,920 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:52,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:52,942 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-27 13:25:54,622 : [INFO]  ------------------------- Batch round 2, loss: 0.5554 -------------------------
2023-03-27 13:25:54,622 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:54,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:54,656 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-27 13:25:56,297 : [INFO]  ------------------------- Batch round 3, loss: 0.5485 -------------------------
2023-03-27 13:25:56,297 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:56,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:56,341 : [INFO]  Batch number 60 model fetched from the server
2023-03-27 13:25:56,341 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-27 13:25:57,487 : [INFO]  Batch 60: Training set : loss - 0.5502, accuracy - 0.7663, recall - 0.8587, AUC - 0.8679, F1 - 0.7861, precision - 0.7248, training time - -7.0 seconds
2023-03-27 13:25:57,487 : [INFO]  Batch 60: Testing set : loss - 0.5378, accuracy - 0.7647, recall - 0.9314, AUC - 0.9148, F1 - 0.7983, precision - 0.6985
2023-03-27 13:25:57,496 : [INFO]  Batch 61 initialized 
2023-03-27 13:25:57,900 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:58,249 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-27 13:26:01,649 : [INFO]  ------------------------- Batch round 1, loss: 0.5444 -------------------------
2023-03-27 13:26:01,650 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:01,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:01,654 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-27 13:26:03,330 : [INFO]  ------------------------- Batch round 2, loss: 0.5375 -------------------------
2023-03-27 13:26:03,330 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:03,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:03,335 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-27 13:26:05,043 : [INFO]  ------------------------- Batch round 3, loss: 0.5379 -------------------------
2023-03-27 13:26:05,043 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:05,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:05,048 : [INFO]  Batch number 61 model fetched from the server
2023-03-27 13:26:05,048 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-27 13:26:06,272 : [INFO]  Batch 61: Training set : loss - 0.5379, accuracy - 0.7609, recall - 0.9674, AUC - 0.9396, F1 - 0.8018, precision - 0.6846, training time - -7.0 seconds
2023-03-27 13:26:06,272 : [INFO]  Batch 61: Testing set : loss - 0.5318, accuracy - 0.7892, recall - 0.9706, AUC - 0.9375, F1 - 0.8216, precision - 0.7122
2023-03-27 13:26:06,279 : [INFO]  Batch 62 initialized 
2023-03-27 13:26:06,689 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:07,032 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-27 13:26:10,428 : [INFO]  ------------------------- Batch round 1, loss: 0.5485 -------------------------
2023-03-27 13:26:10,428 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:10,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:10,432 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-27 13:26:12,109 : [INFO]  ------------------------- Batch round 2, loss: 0.5376 -------------------------
2023-03-27 13:26:12,109 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:12,112 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:12,114 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-27 13:26:13,793 : [INFO]  ------------------------- Batch round 3, loss: 0.5306 -------------------------
2023-03-27 13:26:13,793 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:13,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:13,797 : [INFO]  Batch number 62 model fetched from the server
2023-03-27 13:26:13,798 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-27 13:26:14,957 : [INFO]  Batch 62: Training set : loss - 0.5261, accuracy - 0.7826, recall - 0.9348, AUC - 0.9317, F1 - 0.8113, precision - 0.7167, training time - -7.0 seconds
2023-03-27 13:26:14,957 : [INFO]  Batch 62: Testing set : loss - 0.5552, accuracy - 0.7402, recall - 0.9804, AUC - 0.9296, F1 - 0.7905, precision - 0.6623
2023-03-27 13:26:14,962 : [INFO]  Batch 63 initialized 
2023-03-27 13:26:15,374 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:15,726 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-27 13:26:19,152 : [INFO]  ------------------------- Batch round 1, loss: 0.5683 -------------------------
2023-03-27 13:26:19,152 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:19,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:19,158 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-27 13:26:20,806 : [INFO]  ------------------------- Batch round 2, loss: 0.565 -------------------------
2023-03-27 13:26:20,806 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:20,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:20,814 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-27 13:26:22,517 : [INFO]  ------------------------- Batch round 3, loss: 0.5603 -------------------------
2023-03-27 13:26:22,517 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:22,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:22,522 : [INFO]  Batch number 63 model fetched from the server
2023-03-27 13:26:22,522 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-27 13:26:23,663 : [INFO]  Batch 63: Training set : loss - 0.5619, accuracy - 0.7446, recall - 0.9239, AUC - 0.8771, F1 - 0.7834, precision - 0.68, training time - -7.0 seconds
2023-03-27 13:26:23,663 : [INFO]  Batch 63: Testing set : loss - 0.5315, accuracy - 0.7549, recall - 0.9608, AUC - 0.9356, F1 - 0.7967, precision - 0.6806
2023-03-27 13:26:23,672 : [INFO]  Batch 64 initialized 
2023-03-27 13:26:24,086 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:24,439 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-27 13:26:27,803 : [INFO]  ------------------------- Batch round 1, loss: 0.5742 -------------------------
2023-03-27 13:26:27,804 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:27,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:27,900 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-27 13:26:29,534 : [INFO]  ------------------------- Batch round 2, loss: 0.5683 -------------------------
2023-03-27 13:26:29,534 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:29,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:29,623 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-27 13:26:31,275 : [INFO]  ------------------------- Batch round 3, loss: 0.5661 -------------------------
2023-03-27 13:26:31,275 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:31,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:31,335 : [INFO]  Batch number 64 model fetched from the server
2023-03-27 13:26:31,335 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-27 13:26:32,486 : [INFO]  Batch 64: Training set : loss - 0.5638, accuracy - 0.7391, recall - 0.8804, AUC - 0.8773, F1 - 0.7714, precision - 0.6864, training time - -7.0 seconds
2023-03-27 13:26:32,487 : [INFO]  Batch 64: Testing set : loss - 0.5164, accuracy - 0.8088, recall - 0.9608, AUC - 0.938, F1 - 0.834, precision - 0.7368
2023-03-27 13:26:32,492 : [INFO]  Batch 65 initialized 
2023-03-27 13:26:32,899 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:33,261 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-27 13:26:36,661 : [INFO]  ------------------------- Batch round 1, loss: 0.5443 -------------------------
2023-03-27 13:26:36,661 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:36,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:36,712 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-27 13:26:38,402 : [INFO]  ------------------------- Batch round 2, loss: 0.5391 -------------------------
2023-03-27 13:26:38,402 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:38,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:38,433 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-27 13:26:40,113 : [INFO]  ------------------------- Batch round 3, loss: 0.5372 -------------------------
2023-03-27 13:26:40,113 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:40,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:40,118 : [INFO]  Batch number 65 model fetched from the server
2023-03-27 13:26:40,118 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-27 13:26:41,281 : [INFO]  Batch 65: Training set : loss - 0.5406, accuracy - 0.7772, recall - 0.9565, AUC - 0.9037, F1 - 0.8111, precision - 0.704, training time - -7.0 seconds
2023-03-27 13:26:41,281 : [INFO]  Batch 65: Testing set : loss - 0.5767, accuracy - 0.7304, recall - 0.9314, AUC - 0.8586, F1 - 0.7755, precision - 0.6643
2023-03-27 13:26:41,288 : [INFO]  Batch 66 initialized 
2023-03-27 13:26:41,692 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:42,047 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-27 13:26:45,436 : [INFO]  ------------------------- Batch round 1, loss: 0.5378 -------------------------
2023-03-27 13:26:45,436 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:45,465 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:45,468 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-27 13:26:47,125 : [INFO]  ------------------------- Batch round 2, loss: 0.5346 -------------------------
2023-03-27 13:26:47,125 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:47,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:47,172 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-27 13:26:48,821 : [INFO]  ------------------------- Batch round 3, loss: 0.5315 -------------------------
2023-03-27 13:26:48,822 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:48,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:48,829 : [INFO]  Batch number 66 model fetched from the server
2023-03-27 13:26:48,830 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-27 13:26:49,963 : [INFO]  Batch 66: Training set : loss - 0.5357, accuracy - 0.7772, recall - 0.9674, AUC - 0.9308, F1 - 0.8128, precision - 0.7008, training time - -7.0 seconds
2023-03-27 13:26:49,963 : [INFO]  Batch 66: Testing set : loss - 0.5187, accuracy - 0.7843, recall - 0.951, AUC - 0.9361, F1 - 0.8151, precision - 0.7132
2023-03-27 13:26:49,971 : [INFO]  Batch 67 initialized 
2023-03-27 13:26:50,392 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:50,751 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-27 13:26:54,148 : [INFO]  ------------------------- Batch round 1, loss: 0.5409 -------------------------
2023-03-27 13:26:54,148 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:54,184 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:54,186 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-27 13:26:55,850 : [INFO]  ------------------------- Batch round 2, loss: 0.5364 -------------------------
2023-03-27 13:26:55,850 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:55,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:55,874 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-27 13:26:57,511 : [INFO]  ------------------------- Batch round 3, loss: 0.5338 -------------------------
2023-03-27 13:26:57,511 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:57,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:57,556 : [INFO]  Batch number 67 model fetched from the server
2023-03-27 13:26:57,556 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-27 13:26:58,749 : [INFO]  Batch 67: Training set : loss - 0.5332, accuracy - 0.7826, recall - 0.9348, AUC - 0.9078, F1 - 0.8113, precision - 0.7167, training time - -7.0 seconds
2023-03-27 13:26:58,749 : [INFO]  Batch 67: Testing set : loss - 0.5552, accuracy - 0.75, recall - 0.9216, AUC - 0.8791, F1 - 0.7866, precision - 0.6861
2023-03-27 13:26:58,758 : [INFO]  Batch 68 initialized 
2023-03-27 13:26:59,168 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:59,529 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-27 13:27:02,874 : [INFO]  ------------------------- Batch round 1, loss: 0.5558 -------------------------
2023-03-27 13:27:02,875 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:02,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:02,972 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-27 13:27:04,605 : [INFO]  ------------------------- Batch round 2, loss: 0.5464 -------------------------
2023-03-27 13:27:04,605 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:04,680 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:04,683 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-27 13:27:06,382 : [INFO]  ------------------------- Batch round 3, loss: 0.5445 -------------------------
2023-03-27 13:27:06,382 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:06,430 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:06,432 : [INFO]  Batch number 68 model fetched from the server
2023-03-27 13:27:06,432 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-27 13:27:07,587 : [INFO]  Batch 68: Training set : loss - 0.545, accuracy - 0.7554, recall - 0.913, AUC - 0.894, F1 - 0.7887, precision - 0.6942, training time - -7.0 seconds
2023-03-27 13:27:07,587 : [INFO]  Batch 68: Testing set : loss - 0.5704, accuracy - 0.7353, recall - 0.9216, AUC - 0.8755, F1 - 0.7769, precision - 0.6714
2023-03-27 13:27:07,594 : [INFO]  Batch 69 initialized 
2023-03-27 13:27:08,005 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:08,366 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-27 13:27:11,780 : [INFO]  ------------------------- Batch round 1, loss: 0.5411 -------------------------
2023-03-27 13:27:11,780 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:11,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:11,785 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-27 13:27:13,399 : [INFO]  ------------------------- Batch round 2, loss: 0.5372 -------------------------
2023-03-27 13:27:13,399 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:13,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:13,405 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-27 13:27:15,070 : [INFO]  ------------------------- Batch round 3, loss: 0.5321 -------------------------
2023-03-27 13:27:15,071 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:15,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:15,076 : [INFO]  Batch number 69 model fetched from the server
2023-03-27 13:27:15,076 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-27 13:27:16,209 : [INFO]  Batch 69: Training set : loss - 0.5344, accuracy - 0.7826, recall - 0.9783, AUC - 0.9349, F1 - 0.8182, precision - 0.7031, training time - -7.0 seconds
2023-03-27 13:27:16,209 : [INFO]  Batch 69: Testing set : loss - 0.5605, accuracy - 0.75, recall - 0.9412, AUC - 0.8981, F1 - 0.7901, precision - 0.6809
2023-03-27 13:27:16,219 : [INFO]  Batch 70 initialized 
2023-03-27 13:27:16,624 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:16,982 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-27 13:27:20,351 : [INFO]  ------------------------- Batch round 1, loss: 0.5306 -------------------------
2023-03-27 13:27:20,351 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:20,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:20,400 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-27 13:27:22,074 : [INFO]  ------------------------- Batch round 2, loss: 0.5267 -------------------------
2023-03-27 13:27:22,074 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:22,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:22,079 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-27 13:27:23,743 : [INFO]  ------------------------- Batch round 3, loss: 0.5221 -------------------------
2023-03-27 13:27:23,744 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:23,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:23,750 : [INFO]  Batch number 70 model fetched from the server
2023-03-27 13:27:23,751 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-27 13:27:24,926 : [INFO]  Batch 70: Training set : loss - 0.5222, accuracy - 0.7989, recall - 1.0, AUC - 0.939, F1 - 0.8326, precision - 0.7132, training time - -7.0 seconds
2023-03-27 13:27:24,926 : [INFO]  Batch 70: Testing set : loss - 0.5423, accuracy - 0.7402, recall - 0.9314, AUC - 0.9128, F1 - 0.7819, precision - 0.6738
2023-03-27 13:27:24,932 : [INFO]  Batch 71 initialized 
2023-03-27 13:27:25,340 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:25,704 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-27 13:27:29,104 : [INFO]  ------------------------- Batch round 1, loss: 0.5359 -------------------------
2023-03-27 13:27:29,105 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:29,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:29,124 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-27 13:27:30,768 : [INFO]  ------------------------- Batch round 2, loss: 0.5311 -------------------------
2023-03-27 13:27:30,768 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:30,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:30,792 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-27 13:27:32,444 : [INFO]  ------------------------- Batch round 3, loss: 0.5306 -------------------------
2023-03-27 13:27:32,445 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:32,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:32,465 : [INFO]  Batch number 71 model fetched from the server
2023-03-27 13:27:32,465 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-27 13:27:33,615 : [INFO]  Batch 71: Training set : loss - 0.5338, accuracy - 0.7717, recall - 0.9891, AUC - 0.927, F1 - 0.8125, precision - 0.6894, training time - -7.0 seconds
2023-03-27 13:27:33,615 : [INFO]  Batch 71: Testing set : loss - 0.5654, accuracy - 0.75, recall - 0.9216, AUC - 0.8737, F1 - 0.7866, precision - 0.6861
2023-03-27 13:27:33,626 : [INFO]  Batch 72 initialized 
2023-03-27 13:27:34,038 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:34,404 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-27 13:27:37,796 : [INFO]  ------------------------- Batch round 1, loss: 0.5576 -------------------------
2023-03-27 13:27:37,796 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:37,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:37,836 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-27 13:27:39,536 : [INFO]  ------------------------- Batch round 2, loss: 0.552 -------------------------
2023-03-27 13:27:39,537 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:39,549 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:39,552 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-27 13:27:41,232 : [INFO]  ------------------------- Batch round 3, loss: 0.5469 -------------------------
2023-03-27 13:27:41,233 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:41,236 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:41,237 : [INFO]  Batch number 72 model fetched from the server
2023-03-27 13:27:41,237 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-27 13:27:42,391 : [INFO]  Batch 72: Training set : loss - 0.543, accuracy - 0.75, recall - 0.9674, AUC - 0.9224, F1 - 0.7946, precision - 0.6742, training time - -7.0 seconds
2023-03-27 13:27:42,391 : [INFO]  Batch 72: Testing set : loss - 0.5582, accuracy - 0.7402, recall - 0.9706, AUC - 0.9012, F1 - 0.7888, precision - 0.6644
2023-03-27 13:27:42,401 : [INFO]  Batch 73 initialized 
2023-03-27 13:27:42,806 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:43,182 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-27 13:27:46,561 : [INFO]  ------------------------- Batch round 1, loss: 0.554 -------------------------
2023-03-27 13:27:46,561 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:46,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:46,609 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-27 13:27:48,299 : [INFO]  ------------------------- Batch round 2, loss: 0.5411 -------------------------
2023-03-27 13:27:48,299 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:48,349 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:48,351 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-27 13:27:50,030 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-27 13:27:50,031 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:50,061 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:50,063 : [INFO]  Batch number 73 model fetched from the server
2023-03-27 13:27:50,063 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-27 13:27:51,228 : [INFO]  Batch 73: Training set : loss - 0.5317, accuracy - 0.7772, recall - 0.9348, AUC - 0.9159, F1 - 0.8075, precision - 0.7107, training time - -7.0 seconds
2023-03-27 13:27:51,228 : [INFO]  Batch 73: Testing set : loss - 0.5707, accuracy - 0.7255, recall - 0.9314, AUC - 0.8946, F1 - 0.7724, precision - 0.6597
2023-03-27 13:27:51,234 : [INFO]  Batch 74 initialized 
2023-03-27 13:27:51,644 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:52,012 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-27 13:27:55,391 : [INFO]  ------------------------- Batch round 1, loss: 0.568 -------------------------
2023-03-27 13:27:55,391 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:55,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:55,396 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-27 13:27:57,057 : [INFO]  ------------------------- Batch round 2, loss: 0.5519 -------------------------
2023-03-27 13:27:57,058 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:57,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:57,070 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-27 13:27:58,733 : [INFO]  ------------------------- Batch round 3, loss: 0.5447 -------------------------
2023-03-27 13:27:58,734 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:58,739 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:58,742 : [INFO]  Batch number 74 model fetched from the server
2023-03-27 13:27:58,742 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-27 13:27:59,907 : [INFO]  Batch 74: Training set : loss - 0.544, accuracy - 0.75, recall - 1.0, AUC - 0.9342, F1 - 0.8, precision - 0.6667, training time - -7.0 seconds
2023-03-27 13:27:59,908 : [INFO]  Batch 74: Testing set : loss - 0.5345, accuracy - 0.8088, recall - 0.9804, AUC - 0.9103, F1 - 0.8368, precision - 0.7299
2023-03-27 13:27:59,918 : [INFO]  Batch 75 initialized 
2023-03-27 13:28:00,321 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:00,690 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-27 13:28:04,056 : [INFO]  ------------------------- Batch round 1, loss: 0.5235 -------------------------
2023-03-27 13:28:04,056 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:04,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:04,102 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-27 13:28:05,755 : [INFO]  ------------------------- Batch round 2, loss: 0.5189 -------------------------
2023-03-27 13:28:05,755 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:05,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:05,775 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-27 13:28:07,439 : [INFO]  ------------------------- Batch round 3, loss: 0.5189 -------------------------
2023-03-27 13:28:07,439 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:07,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:07,476 : [INFO]  Batch number 75 model fetched from the server
2023-03-27 13:28:07,476 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-27 13:28:08,614 : [INFO]  Batch 75: Training set : loss - 0.5129, accuracy - 0.8261, recall - 0.9783, AUC - 0.9513, F1 - 0.8491, precision - 0.75, training time - -7.0 seconds
2023-03-27 13:28:08,614 : [INFO]  Batch 75: Testing set : loss - 0.5436, accuracy - 0.7647, recall - 0.9216, AUC - 0.8891, F1 - 0.7966, precision - 0.7015
2023-03-27 13:28:08,625 : [INFO]  Batch 76 initialized 
2023-03-27 13:28:09,029 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:09,408 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-27 13:28:12,803 : [INFO]  ------------------------- Batch round 1, loss: 0.5624 -------------------------
2023-03-27 13:28:12,803 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:12,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:12,835 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-27 13:28:14,528 : [INFO]  ------------------------- Batch round 2, loss: 0.5537 -------------------------
2023-03-27 13:28:14,528 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:14,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:14,559 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-27 13:28:16,286 : [INFO]  ------------------------- Batch round 3, loss: 0.5454 -------------------------
2023-03-27 13:28:16,287 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:16,290 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:16,292 : [INFO]  Batch number 76 model fetched from the server
2023-03-27 13:28:16,292 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-27 13:28:17,437 : [INFO]  Batch 76: Training set : loss - 0.5489, accuracy - 0.7609, recall - 0.913, AUC - 0.8922, F1 - 0.7925, precision - 0.7, training time - -7.0 seconds
2023-03-27 13:28:17,437 : [INFO]  Batch 76: Testing set : loss - 0.5637, accuracy - 0.7549, recall - 0.9608, AUC - 0.8936, F1 - 0.7967, precision - 0.6806
2023-03-27 13:28:17,462 : [INFO]  Batch 77 initialized 
2023-03-27 13:28:17,868 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:18,250 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-27 13:28:21,656 : [INFO]  ------------------------- Batch round 1, loss: 0.5354 -------------------------
2023-03-27 13:28:21,656 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:21,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:21,676 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-27 13:28:23,327 : [INFO]  ------------------------- Batch round 2, loss: 0.5306 -------------------------
2023-03-27 13:28:23,327 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:23,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:23,355 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-27 13:28:24,997 : [INFO]  ------------------------- Batch round 3, loss: 0.527 -------------------------
2023-03-27 13:28:24,997 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:25,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:25,019 : [INFO]  Batch number 77 model fetched from the server
2023-03-27 13:28:25,019 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-27 13:28:26,162 : [INFO]  Batch 77: Training set : loss - 0.5295, accuracy - 0.7717, recall - 0.9239, AUC - 0.9109, F1 - 0.8019, precision - 0.7083, training time - -7.0 seconds
2023-03-27 13:28:26,162 : [INFO]  Batch 77: Testing set : loss - 0.5782, accuracy - 0.701, recall - 0.9118, AUC - 0.8586, F1 - 0.753, precision - 0.6414
2023-03-27 13:28:26,174 : [INFO]  Batch 78 initialized 
2023-03-27 13:28:26,595 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:26,972 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-27 13:28:30,407 : [INFO]  ------------------------- Batch round 1, loss: 0.5426 -------------------------
2023-03-27 13:28:30,407 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:30,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:30,413 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-27 13:28:32,104 : [INFO]  ------------------------- Batch round 2, loss: 0.5369 -------------------------
2023-03-27 13:28:32,104 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:32,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:32,108 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-27 13:28:33,776 : [INFO]  ------------------------- Batch round 3, loss: 0.5318 -------------------------
2023-03-27 13:28:33,777 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:33,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:33,782 : [INFO]  Batch number 78 model fetched from the server
2023-03-27 13:28:33,782 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-27 13:28:34,963 : [INFO]  Batch 78: Training set : loss - 0.5299, accuracy - 0.7772, recall - 0.9565, AUC - 0.9158, F1 - 0.8111, precision - 0.704, training time - -7.0 seconds
2023-03-27 13:28:34,964 : [INFO]  Batch 78: Testing set : loss - 0.5626, accuracy - 0.7353, recall - 0.9608, AUC - 0.8898, F1 - 0.784, precision - 0.6622
2023-03-27 13:28:34,973 : [INFO]  Batch 79 initialized 
2023-03-27 13:28:35,407 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:35,790 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-27 13:28:39,182 : [INFO]  ------------------------- Batch round 1, loss: 0.5451 -------------------------
2023-03-27 13:28:39,183 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:39,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:39,209 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-27 13:28:40,907 : [INFO]  ------------------------- Batch round 2, loss: 0.5327 -------------------------
2023-03-27 13:28:40,907 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:40,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:40,946 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-27 13:28:42,677 : [INFO]  ------------------------- Batch round 3, loss: 0.5308 -------------------------
2023-03-27 13:28:42,678 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:42,680 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:42,682 : [INFO]  Batch number 79 model fetched from the server
2023-03-27 13:28:42,682 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-27 13:28:43,820 : [INFO]  Batch 79: Training set : loss - 0.5375, accuracy - 0.7717, recall - 0.9783, AUC - 0.9204, F1 - 0.8108, precision - 0.6923, training time - -7.0 seconds
2023-03-27 13:28:43,820 : [INFO]  Batch 79: Testing set : loss - 0.5457, accuracy - 0.7549, recall - 0.9706, AUC - 0.9201, F1 - 0.7984, precision - 0.6781
2023-03-27 13:28:43,830 : [INFO]  Batch 80 initialized 
2023-03-27 13:28:44,244 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:44,629 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-27 13:28:48,086 : [INFO]  ------------------------- Batch round 1, loss: 0.5517 -------------------------
2023-03-27 13:28:48,086 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:48,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:48,096 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-27 13:28:49,765 : [INFO]  ------------------------- Batch round 2, loss: 0.5342 -------------------------
2023-03-27 13:28:49,765 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:49,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:49,807 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-27 13:28:51,478 : [INFO]  ------------------------- Batch round 3, loss: 0.5322 -------------------------
2023-03-27 13:28:51,478 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:51,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:51,520 : [INFO]  Batch number 80 model fetched from the server
2023-03-27 13:28:51,520 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-27 13:28:52,674 : [INFO]  Batch 80: Training set : loss - 0.5337, accuracy - 0.7717, recall - 0.9565, AUC - 0.9296, F1 - 0.8073, precision - 0.6984, training time - -7.0 seconds
2023-03-27 13:28:52,674 : [INFO]  Batch 80: Testing set : loss - 0.5476, accuracy - 0.75, recall - 0.951, AUC - 0.9128, F1 - 0.7918, precision - 0.6783
2023-03-27 13:28:52,685 : [INFO]  Batch 81 initialized 
2023-03-27 13:28:53,098 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:53,489 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-27 13:28:56,931 : [INFO]  ------------------------- Batch round 1, loss: 0.5569 -------------------------
2023-03-27 13:28:56,932 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:56,935 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:56,936 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-27 13:28:58,597 : [INFO]  ------------------------- Batch round 2, loss: 0.5497 -------------------------
2023-03-27 13:28:58,597 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:58,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:58,603 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-27 13:29:00,301 : [INFO]  ------------------------- Batch round 3, loss: 0.5442 -------------------------
2023-03-27 13:29:00,302 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:00,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:00,325 : [INFO]  Batch number 81 model fetched from the server
2023-03-27 13:29:00,325 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-27 13:29:01,480 : [INFO]  Batch 81: Training set : loss - 0.5437, accuracy - 0.7663, recall - 0.9674, AUC - 0.9155, F1 - 0.8054, precision - 0.6899, training time - -7.0 seconds
2023-03-27 13:29:01,480 : [INFO]  Batch 81: Testing set : loss - 0.5492, accuracy - 0.7402, recall - 0.9412, AUC - 0.914, F1 - 0.7837, precision - 0.6713
2023-03-27 13:29:01,491 : [INFO]  Batch 82 initialized 
2023-03-27 13:29:01,905 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:02,296 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-27 13:29:05,709 : [INFO]  ------------------------- Batch round 1, loss: 0.5425 -------------------------
2023-03-27 13:29:05,709 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:05,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:05,746 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-27 13:29:07,441 : [INFO]  ------------------------- Batch round 2, loss: 0.5402 -------------------------
2023-03-27 13:29:07,441 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:07,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:07,458 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-27 13:29:09,168 : [INFO]  ------------------------- Batch round 3, loss: 0.5375 -------------------------
2023-03-27 13:29:09,169 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:09,173 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:09,176 : [INFO]  Batch number 82 model fetched from the server
2023-03-27 13:29:09,176 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-27 13:29:10,332 : [INFO]  Batch 82: Training set : loss - 0.5376, accuracy - 0.7826, recall - 0.9348, AUC - 0.8911, F1 - 0.8113, precision - 0.7167, training time - -7.0 seconds
2023-03-27 13:29:10,332 : [INFO]  Batch 82: Testing set : loss - 0.5439, accuracy - 0.7647, recall - 0.9706, AUC - 0.9315, F1 - 0.8049, precision - 0.6875
2023-03-27 13:29:10,336 : [INFO]  Batch 83 initialized 
2023-03-27 13:29:10,746 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:11,130 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-27 13:29:14,524 : [INFO]  ------------------------- Batch round 1, loss: 0.5669 -------------------------
2023-03-27 13:29:14,524 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:14,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:14,529 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-27 13:29:16,174 : [INFO]  ------------------------- Batch round 2, loss: 0.5653 -------------------------
2023-03-27 13:29:16,174 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:16,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:16,179 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-27 13:29:17,853 : [INFO]  ------------------------- Batch round 3, loss: 0.5591 -------------------------
2023-03-27 13:29:17,854 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:17,875 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:17,877 : [INFO]  Batch number 83 model fetched from the server
2023-03-27 13:29:17,877 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-27 13:29:19,020 : [INFO]  Batch 83: Training set : loss - 0.5597, accuracy - 0.7337, recall - 0.9565, AUC - 0.9063, F1 - 0.7822, precision - 0.6617, training time - -7.0 seconds
2023-03-27 13:29:19,020 : [INFO]  Batch 83: Testing set : loss - 0.5724, accuracy - 0.7157, recall - 0.9412, AUC - 0.8817, F1 - 0.768, precision - 0.6486
2023-03-27 13:29:19,024 : [INFO]  Batch 84 initialized 
2023-03-27 13:29:19,431 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:19,826 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-27 13:29:23,283 : [INFO]  ------------------------- Batch round 1, loss: 0.5503 -------------------------
2023-03-27 13:29:23,284 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:23,294 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:23,296 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-27 13:29:24,956 : [INFO]  ------------------------- Batch round 2, loss: 0.5448 -------------------------
2023-03-27 13:29:24,956 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:24,969 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:24,971 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-27 13:29:26,665 : [INFO]  ------------------------- Batch round 3, loss: 0.5417 -------------------------
2023-03-27 13:29:26,665 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:26,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:26,670 : [INFO]  Batch number 84 model fetched from the server
2023-03-27 13:29:26,670 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-27 13:29:27,819 : [INFO]  Batch 84: Training set : loss - 0.5411, accuracy - 0.7609, recall - 0.9674, AUC - 0.9169, F1 - 0.8018, precision - 0.6846, training time - -7.0 seconds
2023-03-27 13:29:27,819 : [INFO]  Batch 84: Testing set : loss - 0.5901, accuracy - 0.6814, recall - 0.9216, AUC - 0.8387, F1 - 0.7431, precision - 0.6225
2023-03-27 13:29:27,829 : [INFO]  Batch 85 initialized 
2023-03-27 13:29:28,239 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:28,632 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-27 13:29:32,023 : [INFO]  ------------------------- Batch round 1, loss: 0.5636 -------------------------
2023-03-27 13:29:32,023 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:32,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:32,028 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-27 13:29:33,708 : [INFO]  ------------------------- Batch round 2, loss: 0.5627 -------------------------
2023-03-27 13:29:33,708 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:33,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:33,714 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-27 13:29:35,399 : [INFO]  ------------------------- Batch round 3, loss: 0.5619 -------------------------
2023-03-27 13:29:35,399 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:35,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:35,405 : [INFO]  Batch number 85 model fetched from the server
2023-03-27 13:29:35,405 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-27 13:29:36,579 : [INFO]  Batch 85: Training set : loss - 0.5629, accuracy - 0.7337, recall - 0.8913, AUC - 0.87, F1 - 0.77, precision - 0.6777, training time - -7.0 seconds
2023-03-27 13:29:36,579 : [INFO]  Batch 85: Testing set : loss - 0.5609, accuracy - 0.7549, recall - 0.9314, AUC - 0.8688, F1 - 0.7917, precision - 0.6884
2023-03-27 13:29:36,585 : [INFO]  Batch 86 initialized 
2023-03-27 13:29:36,997 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:37,384 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-27 13:29:40,722 : [INFO]  ------------------------- Batch round 1, loss: 0.5837 -------------------------
2023-03-27 13:29:40,722 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:40,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:40,792 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-27 13:29:42,381 : [INFO]  ------------------------- Batch round 2, loss: 0.5722 -------------------------
2023-03-27 13:29:42,381 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:42,436 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:42,439 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-27 13:29:44,066 : [INFO]  ------------------------- Batch round 3, loss: 0.5696 -------------------------
2023-03-27 13:29:44,066 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:44,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:44,129 : [INFO]  Batch number 86 model fetched from the server
2023-03-27 13:29:44,129 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-27 13:29:45,279 : [INFO]  Batch 86: Training set : loss - 0.5687, accuracy - 0.7174, recall - 0.9022, AUC - 0.8876, F1 - 0.7615, precision - 0.6587, training time - -7.0 seconds
2023-03-27 13:29:45,279 : [INFO]  Batch 86: Testing set : loss - 0.5521, accuracy - 0.75, recall - 0.951, AUC - 0.8875, F1 - 0.7918, precision - 0.6783
2023-03-27 13:29:45,290 : [INFO]  Batch 87 initialized 
2023-03-27 13:29:45,698 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:46,095 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-27 13:29:49,552 : [INFO]  ------------------------- Batch round 1, loss: 0.5583 -------------------------
2023-03-27 13:29:49,553 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:49,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:49,610 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-27 13:29:51,316 : [INFO]  ------------------------- Batch round 2, loss: 0.552 -------------------------
2023-03-27 13:29:51,316 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:51,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:51,321 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-27 13:29:53,016 : [INFO]  ------------------------- Batch round 3, loss: 0.5495 -------------------------
2023-03-27 13:29:53,016 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:53,028 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:53,029 : [INFO]  Batch number 87 model fetched from the server
2023-03-27 13:29:53,030 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-27 13:29:54,202 : [INFO]  Batch 87: Training set : loss - 0.5549, accuracy - 0.7446, recall - 0.9674, AUC - 0.8898, F1 - 0.7911, precision - 0.6692, training time - -7.0 seconds
2023-03-27 13:29:54,202 : [INFO]  Batch 87: Testing set : loss - 0.5399, accuracy - 0.7745, recall - 0.9412, AUC - 0.8875, F1 - 0.8067, precision - 0.7059
2023-03-27 13:29:54,207 : [INFO]  Batch 88 initialized 
2023-03-27 13:29:54,615 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:55,008 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-27 13:29:58,360 : [INFO]  ------------------------- Batch round 1, loss: 0.5297 -------------------------
2023-03-27 13:29:58,360 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:58,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:58,414 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-27 13:30:00,070 : [INFO]  ------------------------- Batch round 2, loss: 0.5258 -------------------------
2023-03-27 13:30:00,071 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:00,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:00,087 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-27 13:30:01,749 : [INFO]  ------------------------- Batch round 3, loss: 0.5223 -------------------------
2023-03-27 13:30:01,749 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:01,753 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:01,754 : [INFO]  Batch number 88 model fetched from the server
2023-03-27 13:30:01,754 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-27 13:30:02,897 : [INFO]  Batch 88: Training set : loss - 0.5291, accuracy - 0.8261, recall - 0.9783, AUC - 0.9251, F1 - 0.8491, precision - 0.75, training time - -7.0 seconds
2023-03-27 13:30:02,897 : [INFO]  Batch 88: Testing set : loss - 0.5715, accuracy - 0.7108, recall - 0.9314, AUC - 0.8869, F1 - 0.7631, precision - 0.6463
2023-03-27 13:30:02,904 : [INFO]  Batch 89 initialized 
2023-03-27 13:30:03,312 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:03,716 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-27 13:30:07,087 : [INFO]  ------------------------- Batch round 1, loss: 0.539 -------------------------
2023-03-27 13:30:07,087 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:07,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:07,097 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-27 13:30:08,778 : [INFO]  ------------------------- Batch round 2, loss: 0.5291 -------------------------
2023-03-27 13:30:08,779 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:08,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:08,783 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-27 13:30:10,409 : [INFO]  ------------------------- Batch round 3, loss: 0.5248 -------------------------
2023-03-27 13:30:10,409 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:10,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:10,417 : [INFO]  Batch number 89 model fetched from the server
2023-03-27 13:30:10,417 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-27 13:30:11,563 : [INFO]  Batch 89: Training set : loss - 0.5252, accuracy - 0.788, recall - 0.9348, AUC - 0.8995, F1 - 0.8152, precision - 0.7227, training time - -7.0 seconds
2023-03-27 13:30:11,563 : [INFO]  Batch 89: Testing set : loss - 0.5518, accuracy - 0.7206, recall - 0.902, AUC - 0.9143, F1 - 0.7635, precision - 0.6619
2023-03-27 13:30:11,572 : [INFO]  Batch 90 initialized 
2023-03-27 13:30:11,979 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:12,378 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-27 13:30:15,751 : [INFO]  ------------------------- Batch round 1, loss: 0.5433 -------------------------
2023-03-27 13:30:15,751 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:15,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:15,806 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-27 13:30:17,451 : [INFO]  ------------------------- Batch round 2, loss: 0.5297 -------------------------
2023-03-27 13:30:17,452 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:17,472 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:17,474 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-27 13:30:19,109 : [INFO]  ------------------------- Batch round 3, loss: 0.5193 -------------------------
2023-03-27 13:30:19,110 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:19,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:19,120 : [INFO]  Batch number 90 model fetched from the server
2023-03-27 13:30:19,120 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-27 13:30:20,267 : [INFO]  Batch 90: Training set : loss - 0.5173, accuracy - 0.7935, recall - 0.9457, AUC - 0.9164, F1 - 0.8208, precision - 0.725, training time - -7.0 seconds
2023-03-27 13:30:20,268 : [INFO]  Batch 90: Testing set : loss - 0.5566, accuracy - 0.7108, recall - 0.9216, AUC - 0.9084, F1 - 0.7611, precision - 0.6483
2023-03-27 13:30:20,276 : [INFO]  Batch 91 initialized 
2023-03-27 13:30:20,680 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:21,077 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-27 13:30:24,422 : [INFO]  ------------------------- Batch round 1, loss: 0.5556 -------------------------
2023-03-27 13:30:24,422 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:24,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:24,462 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-27 13:30:26,074 : [INFO]  ------------------------- Batch round 2, loss: 0.5483 -------------------------
2023-03-27 13:30:26,074 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:26,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:26,119 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-27 13:30:27,786 : [INFO]  ------------------------- Batch round 3, loss: 0.5462 -------------------------
2023-03-27 13:30:27,786 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:27,844 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:27,845 : [INFO]  Batch number 91 model fetched from the server
2023-03-27 13:30:27,846 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-27 13:30:29,045 : [INFO]  Batch 91: Training set : loss - 0.5473, accuracy - 0.7391, recall - 0.9565, AUC - 0.9047, F1 - 0.7857, precision - 0.6667, training time - -7.0 seconds
2023-03-27 13:30:29,045 : [INFO]  Batch 91: Testing set : loss - 0.5629, accuracy - 0.7255, recall - 0.9608, AUC - 0.9085, F1 - 0.7778, precision - 0.6533
2023-03-27 13:30:29,052 : [INFO]  Batch 92 initialized 
2023-03-27 13:30:29,453 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:29,854 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-27 13:30:33,232 : [INFO]  ------------------------- Batch round 1, loss: 0.564 -------------------------
2023-03-27 13:30:33,233 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:33,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:33,288 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-27 13:30:34,909 : [INFO]  ------------------------- Batch round 2, loss: 0.5556 -------------------------
2023-03-27 13:30:34,910 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:34,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:34,967 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-27 13:30:36,573 : [INFO]  ------------------------- Batch round 3, loss: 0.5526 -------------------------
2023-03-27 13:30:36,573 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:36,644 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:36,646 : [INFO]  Batch number 92 model fetched from the server
2023-03-27 13:30:36,646 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-27 13:30:37,776 : [INFO]  Batch 92: Training set : loss - 0.5511, accuracy - 0.7174, recall - 0.913, AUC - 0.8885, F1 - 0.7636, precision - 0.6562, training time - -7.0 seconds
2023-03-27 13:30:37,776 : [INFO]  Batch 92: Testing set : loss - 0.5566, accuracy - 0.7696, recall - 0.951, AUC - 0.9035, F1 - 0.805, precision - 0.6978
2023-03-27 13:30:37,785 : [INFO]  Batch 93 initialized 
2023-03-27 13:30:38,189 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:38,592 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-27 13:30:42,031 : [INFO]  ------------------------- Batch round 1, loss: 0.5231 -------------------------
2023-03-27 13:30:42,031 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:42,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:42,072 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-27 13:30:43,764 : [INFO]  ------------------------- Batch round 2, loss: 0.5171 -------------------------
2023-03-27 13:30:43,764 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:43,768 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:43,770 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-27 13:30:45,592 : [INFO]  ------------------------- Batch round 3, loss: 0.5136 -------------------------
2023-03-27 13:30:45,592 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:45,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:45,630 : [INFO]  Batch number 93 model fetched from the server
2023-03-27 13:30:45,630 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-27 13:30:47,103 : [INFO]  Batch 93: Training set : loss - 0.5189, accuracy - 0.8152, recall - 0.9674, AUC - 0.9094, F1 - 0.8396, precision - 0.7417, training time - -7.0 seconds
2023-03-27 13:30:47,103 : [INFO]  Batch 93: Testing set : loss - 0.5465, accuracy - 0.7696, recall - 0.951, AUC - 0.8894, F1 - 0.805, precision - 0.6978
2023-03-27 13:30:47,104 : [INFO]  Result report : Accuracy - 0.7459 (0.0255), Recall - 0.9376 (0.0249), AUC - 0.8878 (0.0267), F1 - 0.7869 (0.0189), Precision - 0.6785 (0.0236)
2023-03-27 13:30:47,104 : [INFO]  Result report : Accuracy - 0.7459 (0.0255), Recall - 0.9376 (0.0249), AUC - 0.8878 (0.0267), F1 - 0.7869 (0.0189), Precision - 0.6785 (0.0236), Mean time for a batch - 6.87 (0.13) seconds
2023-03-27 13:30:47,104 : [INFO]  Distributed training done!
2023-03-27 13:30:47,104 : [INFO]  Training report : Total elapsed time 927.6488977620002 seconds, graph name wikipedia, graph ID 1, partition ID 0, training epochs 6, epochs 6
