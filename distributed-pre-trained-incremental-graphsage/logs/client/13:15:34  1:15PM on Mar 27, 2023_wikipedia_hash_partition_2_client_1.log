2023-03-27 13:15:34,607 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-27 13:15:34,607 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 1, training epochs 6, epochs 6
2023-03-27 13:15:36,966 : [INFO]  Model initialized for training
2023-03-27 13:15:38,908 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:15:38,928 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-27 13:15:38,929 : [INFO]  Connected to the server
2023-03-27 13:15:39,017 : [INFO]  Distributed training for streaming graphs started!
2023-03-27 13:15:39,018 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:15:39,027 : [INFO]  ################################## Initial model training started ##################################
2023-03-27 13:15:39,027 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-27 13:15:51,648 : [INFO]  ------------------------- Training round 1, loss: 0.6608 -------------------------
2023-03-27 13:15:51,653 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-27 13:15:51,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:15:51,658 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-27 13:16:06,766 : [INFO]  ------------------------- Training round 2, loss: 0.5981 -------------------------
2023-03-27 13:16:06,766 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-27 13:16:06,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:06,773 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-27 13:16:21,696 : [INFO]  ------------------------- Training round 3, loss: 0.5862 -------------------------
2023-03-27 13:16:21,696 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-27 13:16:21,699 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:21,701 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-27 13:16:36,784 : [INFO]  ------------------------- Training round 4, loss: 0.578 -------------------------
2023-03-27 13:16:36,784 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-27 13:16:36,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:36,789 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-27 13:16:51,630 : [INFO]  ------------------------- Training round 5, loss: 0.5732 -------------------------
2023-03-27 13:16:51,630 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-27 13:16:51,633 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:16:51,635 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-27 13:17:06,367 : [INFO]  ------------------------- Training round 6, loss: 0.5717 -------------------------
2023-03-27 13:17:06,368 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-27 13:17:06,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:06,372 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-27 13:17:11,929 : [INFO]  Initially trained model: Training set : loss - 0.56, accuracy - 0.74, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.68, training time - -87.0 seconds
2023-03-27 13:17:11,929 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.67
2023-03-27 13:17:11,933 : [INFO]  Batch 1 initialized 
2023-03-27 13:17:12,372 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:12,500 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-27 13:17:12,500 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-27 13:17:15,992 : [INFO]  ------------------------- Batch round 1, loss: 0.5528 -------------------------
2023-03-27 13:17:15,992 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:15,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:15,997 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-27 13:17:17,765 : [INFO]  ------------------------- Batch round 2, loss: 0.5461 -------------------------
2023-03-27 13:17:17,765 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:17,768 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:17,770 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-27 13:17:19,485 : [INFO]  ------------------------- Batch round 3, loss: 0.5418 -------------------------
2023-03-27 13:17:19,485 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:19,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:19,523 : [INFO]  Batch number 1 model fetched from the server
2023-03-27 13:17:19,523 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-27 13:17:20,699 : [INFO]  Batch 1: Training set : loss - 0.5358, accuracy - 0.788, recall - 0.9783, AUC - 0.8902, F1 - 0.8219, precision - 0.7087, training time - -7.0 seconds
2023-03-27 13:17:20,699 : [INFO]  Batch 1: Testing set : loss - 0.5496, accuracy - 0.7696, recall - 0.9706, AUC - 0.8887, F1 - 0.8082, precision - 0.6923
2023-03-27 13:17:20,704 : [INFO]  Batch 2 initialized 
2023-03-27 13:17:21,140 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:21,285 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-27 13:17:24,874 : [INFO]  ------------------------- Batch round 1, loss: 0.5876 -------------------------
2023-03-27 13:17:24,874 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:24,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:24,880 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-27 13:17:26,649 : [INFO]  ------------------------- Batch round 2, loss: 0.5849 -------------------------
2023-03-27 13:17:26,649 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:26,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:26,658 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-27 13:17:28,538 : [INFO]  ------------------------- Batch round 3, loss: 0.5786 -------------------------
2023-03-27 13:17:28,538 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:28,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:28,543 : [INFO]  Batch number 2 model fetched from the server
2023-03-27 13:17:28,543 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-27 13:17:29,769 : [INFO]  Batch 2: Training set : loss - 0.5797, accuracy - 0.7391, recall - 0.9674, AUC - 0.8125, F1 - 0.7876, precision - 0.6642, training time - -7.0 seconds
2023-03-27 13:17:29,769 : [INFO]  Batch 2: Testing set : loss - 0.5723, accuracy - 0.7549, recall - 0.9314, AUC - 0.8457, F1 - 0.7917, precision - 0.6884
2023-03-27 13:17:29,784 : [INFO]  Batch 3 initialized 
2023-03-27 13:17:30,244 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:30,454 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-27 13:17:33,942 : [INFO]  ------------------------- Batch round 1, loss: 0.557 -------------------------
2023-03-27 13:17:33,942 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:33,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:33,947 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-27 13:17:35,839 : [INFO]  ------------------------- Batch round 2, loss: 0.5512 -------------------------
2023-03-27 13:17:35,839 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:35,843 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:35,845 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-27 13:17:37,811 : [INFO]  ------------------------- Batch round 3, loss: 0.5474 -------------------------
2023-03-27 13:17:37,812 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:37,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:37,842 : [INFO]  Batch number 3 model fetched from the server
2023-03-27 13:17:37,842 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-27 13:17:39,042 : [INFO]  Batch 3: Training set : loss - 0.545, accuracy - 0.7772, recall - 0.9674, AUC - 0.8676, F1 - 0.8128, precision - 0.7008, training time - -7.0 seconds
2023-03-27 13:17:39,042 : [INFO]  Batch 3: Testing set : loss - 0.5805, accuracy - 0.7353, recall - 0.9314, AUC - 0.8313, F1 - 0.7787, precision - 0.669
2023-03-27 13:17:39,053 : [INFO]  Batch 4 initialized 
2023-03-27 13:17:39,477 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:39,697 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-27 13:17:43,118 : [INFO]  ------------------------- Batch round 1, loss: 0.5549 -------------------------
2023-03-27 13:17:43,118 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:43,121 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:43,123 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-27 13:17:45,068 : [INFO]  ------------------------- Batch round 2, loss: 0.5536 -------------------------
2023-03-27 13:17:45,069 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:45,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:45,242 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-27 13:17:46,960 : [INFO]  ------------------------- Batch round 3, loss: 0.5485 -------------------------
2023-03-27 13:17:46,960 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:46,966 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:46,968 : [INFO]  Batch number 4 model fetched from the server
2023-03-27 13:17:46,968 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-27 13:17:48,169 : [INFO]  Batch 4: Training set : loss - 0.5452, accuracy - 0.7554, recall - 0.9457, AUC - 0.9058, F1 - 0.7945, precision - 0.685, training time - -7.0 seconds
2023-03-27 13:17:48,169 : [INFO]  Batch 4: Testing set : loss - 0.5368, accuracy - 0.7941, recall - 0.9706, AUC - 0.9024, F1 - 0.825, precision - 0.7174
2023-03-27 13:17:48,178 : [INFO]  Batch 5 initialized 
2023-03-27 13:17:48,618 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:48,839 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-27 13:17:52,293 : [INFO]  ------------------------- Batch round 1, loss: 0.5651 -------------------------
2023-03-27 13:17:52,294 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-27 13:17:52,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:52,299 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-27 13:17:54,005 : [INFO]  ------------------------- Batch round 2, loss: 0.5601 -------------------------
2023-03-27 13:17:54,005 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-27 13:17:54,008 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:54,010 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-27 13:17:55,777 : [INFO]  ------------------------- Batch round 3, loss: 0.5579 -------------------------
2023-03-27 13:17:55,777 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-27 13:17:55,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:17:55,781 : [INFO]  Batch number 5 model fetched from the server
2023-03-27 13:17:55,782 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-27 13:17:56,934 : [INFO]  Batch 5: Training set : loss - 0.5592, accuracy - 0.7446, recall - 0.9348, AUC - 0.8846, F1 - 0.7854, precision - 0.6772, training time - -7.0 seconds
2023-03-27 13:17:56,934 : [INFO]  Batch 5: Testing set : loss - 0.5878, accuracy - 0.7157, recall - 0.8922, AUC - 0.8362, F1 - 0.7583, precision - 0.6594
2023-03-27 13:17:56,944 : [INFO]  Batch 6 initialized 
2023-03-27 13:17:57,363 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:17:57,585 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-27 13:18:01,029 : [INFO]  ------------------------- Batch round 1, loss: 0.567 -------------------------
2023-03-27 13:18:01,029 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:01,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:01,041 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-27 13:18:02,776 : [INFO]  ------------------------- Batch round 2, loss: 0.5609 -------------------------
2023-03-27 13:18:02,776 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:02,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:02,803 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-27 13:18:04,577 : [INFO]  ------------------------- Batch round 3, loss: 0.5582 -------------------------
2023-03-27 13:18:04,577 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:04,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:04,585 : [INFO]  Batch number 6 model fetched from the server
2023-03-27 13:18:04,585 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-27 13:18:05,809 : [INFO]  Batch 6: Training set : loss - 0.5605, accuracy - 0.75, recall - 0.9457, AUC - 0.8776, F1 - 0.7909, precision - 0.6797, training time - -7.0 seconds
2023-03-27 13:18:05,810 : [INFO]  Batch 6: Testing set : loss - 0.5477, accuracy - 0.7647, recall - 0.951, AUC - 0.8995, F1 - 0.8017, precision - 0.6929
2023-03-27 13:18:05,814 : [INFO]  Batch 7 initialized 
2023-03-27 13:18:06,255 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:06,477 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-27 13:18:09,903 : [INFO]  ------------------------- Batch round 1, loss: 0.5362 -------------------------
2023-03-27 13:18:09,904 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:09,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:09,908 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-27 13:18:11,621 : [INFO]  ------------------------- Batch round 2, loss: 0.5282 -------------------------
2023-03-27 13:18:11,621 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:11,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:11,627 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-27 13:18:13,342 : [INFO]  ------------------------- Batch round 3, loss: 0.5237 -------------------------
2023-03-27 13:18:13,342 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:13,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:13,348 : [INFO]  Batch number 7 model fetched from the server
2023-03-27 13:18:13,348 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-27 13:18:14,550 : [INFO]  Batch 7: Training set : loss - 0.5176, accuracy - 0.8587, recall - 0.9348, AUC - 0.9091, F1 - 0.8687, precision - 0.8113, training time - -7.0 seconds
2023-03-27 13:18:14,550 : [INFO]  Batch 7: Testing set : loss - 0.5579, accuracy - 0.7647, recall - 0.9314, AUC - 0.8504, F1 - 0.7983, precision - 0.6985
2023-03-27 13:18:14,556 : [INFO]  Batch 8 initialized 
2023-03-27 13:18:15,000 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:15,224 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-27 13:18:18,729 : [INFO]  ------------------------- Batch round 1, loss: 0.5604 -------------------------
2023-03-27 13:18:18,729 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:18,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:18,735 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-27 13:18:20,497 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-27 13:18:20,498 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:20,501 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:20,503 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-27 13:18:22,195 : [INFO]  ------------------------- Batch round 3, loss: 0.5514 -------------------------
2023-03-27 13:18:22,195 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:22,198 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:22,202 : [INFO]  Batch number 8 model fetched from the server
2023-03-27 13:18:22,202 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-27 13:18:23,387 : [INFO]  Batch 8: Training set : loss - 0.5521, accuracy - 0.7609, recall - 0.9348, AUC - 0.8933, F1 - 0.7963, precision - 0.6935, training time - -7.0 seconds
2023-03-27 13:18:23,387 : [INFO]  Batch 8: Testing set : loss - 0.599, accuracy - 0.7108, recall - 0.8824, AUC - 0.827, F1 - 0.7531, precision - 0.6569
2023-03-27 13:18:23,398 : [INFO]  Batch 9 initialized 
2023-03-27 13:18:23,809 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:24,038 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-27 13:18:27,454 : [INFO]  ------------------------- Batch round 1, loss: 0.541 -------------------------
2023-03-27 13:18:27,454 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:27,462 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:27,464 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-27 13:18:29,188 : [INFO]  ------------------------- Batch round 2, loss: 0.5354 -------------------------
2023-03-27 13:18:29,188 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:29,192 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:29,193 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-27 13:18:30,939 : [INFO]  ------------------------- Batch round 3, loss: 0.5335 -------------------------
2023-03-27 13:18:30,939 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:30,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:30,968 : [INFO]  Batch number 9 model fetched from the server
2023-03-27 13:18:30,968 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-27 13:18:32,167 : [INFO]  Batch 9: Training set : loss - 0.5355, accuracy - 0.788, recall - 0.9565, AUC - 0.9312, F1 - 0.8186, precision - 0.7154, training time - -7.0 seconds
2023-03-27 13:18:32,168 : [INFO]  Batch 9: Testing set : loss - 0.55, accuracy - 0.7598, recall - 0.9314, AUC - 0.8583, F1 - 0.795, precision - 0.6934
2023-03-27 13:18:32,176 : [INFO]  Batch 10 initialized 
2023-03-27 13:18:32,623 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:32,863 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-27 13:18:36,262 : [INFO]  ------------------------- Batch round 1, loss: 0.5638 -------------------------
2023-03-27 13:18:36,262 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:36,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:36,267 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-27 13:18:37,954 : [INFO]  ------------------------- Batch round 2, loss: 0.5618 -------------------------
2023-03-27 13:18:37,954 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:37,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:37,964 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-27 13:18:39,712 : [INFO]  ------------------------- Batch round 3, loss: 0.56 -------------------------
2023-03-27 13:18:39,713 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:39,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:39,719 : [INFO]  Batch number 10 model fetched from the server
2023-03-27 13:18:39,719 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-27 13:18:40,893 : [INFO]  Batch 10: Training set : loss - 0.5575, accuracy - 0.7826, recall - 0.9674, AUC - 0.9051, F1 - 0.8165, precision - 0.7063, training time - -7.0 seconds
2023-03-27 13:18:40,893 : [INFO]  Batch 10: Testing set : loss - 0.5477, accuracy - 0.7647, recall - 0.9706, AUC - 0.932, F1 - 0.8049, precision - 0.6875
2023-03-27 13:18:40,901 : [INFO]  Batch 11 initialized 
2023-03-27 13:18:41,321 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:41,564 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-27 13:18:44,999 : [INFO]  ------------------------- Batch round 1, loss: 0.5643 -------------------------
2023-03-27 13:18:44,999 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:45,002 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:45,004 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-27 13:18:46,721 : [INFO]  ------------------------- Batch round 2, loss: 0.5618 -------------------------
2023-03-27 13:18:46,721 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:46,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:46,726 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-27 13:18:48,474 : [INFO]  ------------------------- Batch round 3, loss: 0.5573 -------------------------
2023-03-27 13:18:48,474 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:48,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:48,479 : [INFO]  Batch number 11 model fetched from the server
2023-03-27 13:18:48,479 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-27 13:18:49,655 : [INFO]  Batch 11: Training set : loss - 0.5575, accuracy - 0.7391, recall - 0.913, AUC - 0.8745, F1 - 0.7778, precision - 0.6774, training time - -7.0 seconds
2023-03-27 13:18:49,655 : [INFO]  Batch 11: Testing set : loss - 0.5696, accuracy - 0.7451, recall - 0.8922, AUC - 0.8446, F1 - 0.7778, precision - 0.6894
2023-03-27 13:18:49,662 : [INFO]  Batch 12 initialized 
2023-03-27 13:18:50,095 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:50,335 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-27 13:18:53,736 : [INFO]  ------------------------- Batch round 1, loss: 0.5848 -------------------------
2023-03-27 13:18:53,736 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-27 13:18:53,746 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:53,747 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-27 13:18:55,459 : [INFO]  ------------------------- Batch round 2, loss: 0.5789 -------------------------
2023-03-27 13:18:55,459 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-27 13:18:55,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:55,476 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-27 13:18:57,160 : [INFO]  ------------------------- Batch round 3, loss: 0.5747 -------------------------
2023-03-27 13:18:57,160 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-27 13:18:57,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:18:57,193 : [INFO]  Batch number 12 model fetched from the server
2023-03-27 13:18:57,193 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-27 13:18:58,348 : [INFO]  Batch 12: Training set : loss - 0.5734, accuracy - 0.75, recall - 0.8804, AUC - 0.8456, F1 - 0.7788, precision - 0.6983, training time - -7.0 seconds
2023-03-27 13:18:58,348 : [INFO]  Batch 12: Testing set : loss - 0.5306, accuracy - 0.8137, recall - 0.9216, AUC - 0.903, F1 - 0.8319, precision - 0.7581
2023-03-27 13:18:58,388 : [INFO]  Batch 13 initialized 
2023-03-27 13:18:58,811 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:18:59,055 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-27 13:19:02,452 : [INFO]  ------------------------- Batch round 1, loss: 0.5416 -------------------------
2023-03-27 13:19:02,452 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:02,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:02,457 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-27 13:19:04,080 : [INFO]  ------------------------- Batch round 2, loss: 0.5373 -------------------------
2023-03-27 13:19:04,080 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:04,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:04,092 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-27 13:19:05,720 : [INFO]  ------------------------- Batch round 3, loss: 0.5361 -------------------------
2023-03-27 13:19:05,721 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:05,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:05,774 : [INFO]  Batch number 13 model fetched from the server
2023-03-27 13:19:05,774 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-27 13:19:06,911 : [INFO]  Batch 13: Training set : loss - 0.5352, accuracy - 0.788, recall - 0.9565, AUC - 0.9045, F1 - 0.8186, precision - 0.7154, training time - -7.0 seconds
2023-03-27 13:19:06,912 : [INFO]  Batch 13: Testing set : loss - 0.5635, accuracy - 0.75, recall - 0.9412, AUC - 0.8703, F1 - 0.7901, precision - 0.6809
2023-03-27 13:19:06,921 : [INFO]  Batch 14 initialized 
2023-03-27 13:19:07,348 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:07,594 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-27 13:19:10,973 : [INFO]  ------------------------- Batch round 1, loss: 0.5205 -------------------------
2023-03-27 13:19:10,973 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:10,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:10,978 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-27 13:19:12,683 : [INFO]  ------------------------- Batch round 2, loss: 0.5158 -------------------------
2023-03-27 13:19:12,684 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:12,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:12,688 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-27 13:19:14,421 : [INFO]  ------------------------- Batch round 3, loss: 0.5141 -------------------------
2023-03-27 13:19:14,421 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:14,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:14,426 : [INFO]  Batch number 14 model fetched from the server
2023-03-27 13:19:14,426 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-27 13:19:15,564 : [INFO]  Batch 14: Training set : loss - 0.5122, accuracy - 0.8207, recall - 0.9783, AUC - 0.9235, F1 - 0.8451, precision - 0.7438, training time - -7.0 seconds
2023-03-27 13:19:15,564 : [INFO]  Batch 14: Testing set : loss - 0.5345, accuracy - 0.8088, recall - 0.9412, AUC - 0.9012, F1 - 0.8312, precision - 0.7442
2023-03-27 13:19:15,574 : [INFO]  Batch 15 initialized 
2023-03-27 13:19:15,986 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:16,233 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-27 13:19:19,689 : [INFO]  ------------------------- Batch round 1, loss: 0.5401 -------------------------
2023-03-27 13:19:19,689 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:19,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:19,694 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-27 13:19:21,393 : [INFO]  ------------------------- Batch round 2, loss: 0.5334 -------------------------
2023-03-27 13:19:21,394 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:21,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:21,400 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-27 13:19:23,102 : [INFO]  ------------------------- Batch round 3, loss: 0.5294 -------------------------
2023-03-27 13:19:23,102 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:23,105 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:23,107 : [INFO]  Batch number 15 model fetched from the server
2023-03-27 13:19:23,107 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-27 13:19:24,242 : [INFO]  Batch 15: Training set : loss - 0.5304, accuracy - 0.8098, recall - 0.9674, AUC - 0.9399, F1 - 0.8357, precision - 0.7355, training time - -7.0 seconds
2023-03-27 13:19:24,242 : [INFO]  Batch 15: Testing set : loss - 0.5731, accuracy - 0.7598, recall - 0.951, AUC - 0.8565, F1 - 0.7984, precision - 0.6879
2023-03-27 13:19:24,248 : [INFO]  Batch 16 initialized 
2023-03-27 13:19:24,659 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:24,903 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-27 13:19:28,348 : [INFO]  ------------------------- Batch round 1, loss: 0.5962 -------------------------
2023-03-27 13:19:28,348 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:28,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:28,353 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-27 13:19:30,038 : [INFO]  ------------------------- Batch round 2, loss: 0.5892 -------------------------
2023-03-27 13:19:30,038 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:30,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:30,043 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-27 13:19:31,738 : [INFO]  ------------------------- Batch round 3, loss: 0.585 -------------------------
2023-03-27 13:19:31,738 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:31,742 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:31,743 : [INFO]  Batch number 16 model fetched from the server
2023-03-27 13:19:31,744 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-27 13:19:32,889 : [INFO]  Batch 16: Training set : loss - 0.5832, accuracy - 0.7174, recall - 0.913, AUC - 0.8718, F1 - 0.7636, precision - 0.6562, training time - -7.0 seconds
2023-03-27 13:19:32,890 : [INFO]  Batch 16: Testing set : loss - 0.566, accuracy - 0.7402, recall - 0.9412, AUC - 0.8865, F1 - 0.7837, precision - 0.6713
2023-03-27 13:19:32,900 : [INFO]  Batch 17 initialized 
2023-03-27 13:19:33,307 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:33,566 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-27 13:19:36,951 : [INFO]  ------------------------- Batch round 1, loss: 0.574 -------------------------
2023-03-27 13:19:36,951 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:36,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:36,956 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-27 13:19:38,653 : [INFO]  ------------------------- Batch round 2, loss: 0.5669 -------------------------
2023-03-27 13:19:38,654 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:38,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:38,659 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-27 13:19:40,381 : [INFO]  ------------------------- Batch round 3, loss: 0.5621 -------------------------
2023-03-27 13:19:40,381 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:40,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:40,388 : [INFO]  Batch number 17 model fetched from the server
2023-03-27 13:19:40,388 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-27 13:19:41,549 : [INFO]  Batch 17: Training set : loss - 0.5658, accuracy - 0.75, recall - 0.8804, AUC - 0.855, F1 - 0.7788, precision - 0.6983, training time - -7.0 seconds
2023-03-27 13:19:41,549 : [INFO]  Batch 17: Testing set : loss - 0.5861, accuracy - 0.7255, recall - 0.9412, AUC - 0.8599, F1 - 0.7742, precision - 0.6575
2023-03-27 13:19:41,559 : [INFO]  Batch 18 initialized 
2023-03-27 13:19:41,964 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:42,218 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-27 13:19:45,578 : [INFO]  ------------------------- Batch round 1, loss: 0.5586 -------------------------
2023-03-27 13:19:45,578 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:45,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:45,583 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-27 13:19:47,257 : [INFO]  ------------------------- Batch round 2, loss: 0.5476 -------------------------
2023-03-27 13:19:47,257 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:47,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:47,264 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-27 13:19:48,916 : [INFO]  ------------------------- Batch round 3, loss: 0.5478 -------------------------
2023-03-27 13:19:48,917 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:48,924 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:48,926 : [INFO]  Batch number 18 model fetched from the server
2023-03-27 13:19:48,926 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-27 13:19:50,065 : [INFO]  Batch 18: Training set : loss - 0.5449, accuracy - 0.7446, recall - 0.913, AUC - 0.8924, F1 - 0.7814, precision - 0.6829, training time - -7.0 seconds
2023-03-27 13:19:50,065 : [INFO]  Batch 18: Testing set : loss - 0.6008, accuracy - 0.701, recall - 0.8627, AUC - 0.8066, F1 - 0.7426, precision - 0.6519
2023-03-27 13:19:50,072 : [INFO]  Batch 19 initialized 
2023-03-27 13:19:50,494 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:50,749 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-27 13:19:54,112 : [INFO]  ------------------------- Batch round 1, loss: 0.5823 -------------------------
2023-03-27 13:19:54,112 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-27 13:19:54,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:54,140 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-27 13:19:55,754 : [INFO]  ------------------------- Batch round 2, loss: 0.5769 -------------------------
2023-03-27 13:19:55,754 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-27 13:19:55,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:55,834 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-27 13:19:57,441 : [INFO]  ------------------------- Batch round 3, loss: 0.5753 -------------------------
2023-03-27 13:19:57,441 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-27 13:19:57,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:19:57,515 : [INFO]  Batch number 19 model fetched from the server
2023-03-27 13:19:57,516 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-27 13:19:58,687 : [INFO]  Batch 19: Training set : loss - 0.5754, accuracy - 0.7174, recall - 0.8913, AUC - 0.8353, F1 - 0.7593, precision - 0.6613, training time - -7.0 seconds
2023-03-27 13:19:58,688 : [INFO]  Batch 19: Testing set : loss - 0.5853, accuracy - 0.7255, recall - 0.9216, AUC - 0.8468, F1 - 0.7705, precision - 0.662
2023-03-27 13:19:58,698 : [INFO]  Batch 20 initialized 
2023-03-27 13:19:59,101 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:19:59,360 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-27 13:20:02,825 : [INFO]  ------------------------- Batch round 1, loss: 0.5417 -------------------------
2023-03-27 13:20:02,825 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:02,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:02,830 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-27 13:20:04,580 : [INFO]  ------------------------- Batch round 2, loss: 0.538 -------------------------
2023-03-27 13:20:04,580 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:04,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:04,585 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-27 13:20:06,290 : [INFO]  ------------------------- Batch round 3, loss: 0.5346 -------------------------
2023-03-27 13:20:06,290 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:06,293 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:06,295 : [INFO]  Batch number 20 model fetched from the server
2023-03-27 13:20:06,296 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-27 13:20:07,504 : [INFO]  Batch 20: Training set : loss - 0.5376, accuracy - 0.788, recall - 0.9783, AUC - 0.9251, F1 - 0.8219, precision - 0.7087, training time - -7.0 seconds
2023-03-27 13:20:07,504 : [INFO]  Batch 20: Testing set : loss - 0.5724, accuracy - 0.7206, recall - 0.9118, AUC - 0.876, F1 - 0.7654, precision - 0.6596
2023-03-27 13:20:07,511 : [INFO]  Batch 21 initialized 
2023-03-27 13:20:07,936 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:08,199 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-27 13:20:11,611 : [INFO]  ------------------------- Batch round 1, loss: 0.5794 -------------------------
2023-03-27 13:20:11,611 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:11,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:11,616 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-27 13:20:13,321 : [INFO]  ------------------------- Batch round 2, loss: 0.5723 -------------------------
2023-03-27 13:20:13,321 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:13,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:13,327 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-27 13:20:15,077 : [INFO]  ------------------------- Batch round 3, loss: 0.5673 -------------------------
2023-03-27 13:20:15,078 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:15,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:15,083 : [INFO]  Batch number 21 model fetched from the server
2023-03-27 13:20:15,083 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-27 13:20:16,239 : [INFO]  Batch 21: Training set : loss - 0.5626, accuracy - 0.75, recall - 0.913, AUC - 0.8692, F1 - 0.785, precision - 0.6885, training time - -7.0 seconds
2023-03-27 13:20:16,239 : [INFO]  Batch 21: Testing set : loss - 0.5593, accuracy - 0.7647, recall - 0.951, AUC - 0.877, F1 - 0.8017, precision - 0.6929
2023-03-27 13:20:16,244 : [INFO]  Batch 22 initialized 
2023-03-27 13:20:16,657 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:16,924 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-27 13:20:20,356 : [INFO]  ------------------------- Batch round 1, loss: 0.5363 -------------------------
2023-03-27 13:20:20,357 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:20,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:20,363 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-27 13:20:22,234 : [INFO]  ------------------------- Batch round 2, loss: 0.5325 -------------------------
2023-03-27 13:20:22,234 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:22,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:22,239 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-27 13:20:23,926 : [INFO]  ------------------------- Batch round 3, loss: 0.5293 -------------------------
2023-03-27 13:20:23,926 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:23,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:23,931 : [INFO]  Batch number 22 model fetched from the server
2023-03-27 13:20:23,931 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-27 13:20:25,103 : [INFO]  Batch 22: Training set : loss - 0.5302, accuracy - 0.7826, recall - 0.9565, AUC - 0.9032, F1 - 0.8148, precision - 0.7097, training time - -7.0 seconds
2023-03-27 13:20:25,103 : [INFO]  Batch 22: Testing set : loss - 0.5623, accuracy - 0.7451, recall - 0.951, AUC - 0.8743, F1 - 0.7886, precision - 0.6736
2023-03-27 13:20:25,109 : [INFO]  Batch 23 initialized 
2023-03-27 13:20:25,525 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:25,793 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-27 13:20:29,219 : [INFO]  ------------------------- Batch round 1, loss: 0.5627 -------------------------
2023-03-27 13:20:29,219 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:29,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:29,225 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-27 13:20:30,938 : [INFO]  ------------------------- Batch round 2, loss: 0.5552 -------------------------
2023-03-27 13:20:30,938 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:30,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:30,989 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-27 13:20:32,678 : [INFO]  ------------------------- Batch round 3, loss: 0.5517 -------------------------
2023-03-27 13:20:32,678 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:32,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:32,699 : [INFO]  Batch number 23 model fetched from the server
2023-03-27 13:20:32,699 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-27 13:20:33,864 : [INFO]  Batch 23: Training set : loss - 0.5472, accuracy - 0.7554, recall - 0.8696, AUC - 0.8969, F1 - 0.7805, precision - 0.708, training time - -7.0 seconds
2023-03-27 13:20:33,864 : [INFO]  Batch 23: Testing set : loss - 0.5461, accuracy - 0.7598, recall - 0.9608, AUC - 0.9059, F1 - 0.8, precision - 0.6853
2023-03-27 13:20:33,877 : [INFO]  Batch 24 initialized 
2023-03-27 13:20:34,287 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:34,558 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-27 13:20:37,989 : [INFO]  ------------------------- Batch round 1, loss: 0.5791 -------------------------
2023-03-27 13:20:37,990 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:37,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:37,995 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-27 13:20:39,654 : [INFO]  ------------------------- Batch round 2, loss: 0.5775 -------------------------
2023-03-27 13:20:39,655 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:39,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:39,665 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-27 13:20:41,340 : [INFO]  ------------------------- Batch round 3, loss: 0.5736 -------------------------
2023-03-27 13:20:41,341 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:41,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:41,353 : [INFO]  Batch number 24 model fetched from the server
2023-03-27 13:20:41,353 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-27 13:20:42,510 : [INFO]  Batch 24: Training set : loss - 0.5706, accuracy - 0.7446, recall - 0.9457, AUC - 0.8803, F1 - 0.7873, precision - 0.6744, training time - -7.0 seconds
2023-03-27 13:20:42,510 : [INFO]  Batch 24: Testing set : loss - 0.5672, accuracy - 0.7451, recall - 0.9608, AUC - 0.8898, F1 - 0.7903, precision - 0.6712
2023-03-27 13:20:42,516 : [INFO]  Batch 25 initialized 
2023-03-27 13:20:42,925 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:43,200 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-27 13:20:46,630 : [INFO]  ------------------------- Batch round 1, loss: 0.55 -------------------------
2023-03-27 13:20:46,631 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:46,634 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:46,636 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-27 13:20:48,407 : [INFO]  ------------------------- Batch round 2, loss: 0.5503 -------------------------
2023-03-27 13:20:48,407 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:48,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:48,416 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-27 13:20:50,221 : [INFO]  ------------------------- Batch round 3, loss: 0.5489 -------------------------
2023-03-27 13:20:50,221 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:50,225 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:50,227 : [INFO]  Batch number 25 model fetched from the server
2023-03-27 13:20:50,227 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-27 13:20:51,434 : [INFO]  Batch 25: Training set : loss - 0.5456, accuracy - 0.7609, recall - 0.9783, AUC - 0.9292, F1 - 0.8036, precision - 0.6818, training time - -7.0 seconds
2023-03-27 13:20:51,435 : [INFO]  Batch 25: Testing set : loss - 0.5727, accuracy - 0.7108, recall - 0.9314, AUC - 0.8809, F1 - 0.7631, precision - 0.6463
2023-03-27 13:20:51,444 : [INFO]  Batch 26 initialized 
2023-03-27 13:20:51,861 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:20:52,137 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-27 13:20:55,651 : [INFO]  ------------------------- Batch round 1, loss: 0.5472 -------------------------
2023-03-27 13:20:55,651 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-27 13:20:55,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:55,657 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-27 13:20:57,413 : [INFO]  ------------------------- Batch round 2, loss: 0.5433 -------------------------
2023-03-27 13:20:57,413 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-27 13:20:57,417 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:57,419 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-27 13:20:59,205 : [INFO]  ------------------------- Batch round 3, loss: 0.5401 -------------------------
2023-03-27 13:20:59,205 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-27 13:20:59,208 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:20:59,210 : [INFO]  Batch number 26 model fetched from the server
2023-03-27 13:20:59,210 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-27 13:21:00,389 : [INFO]  Batch 26: Training set : loss - 0.5459, accuracy - 0.7663, recall - 0.9565, AUC - 0.9178, F1 - 0.8037, precision - 0.6929, training time - -7.0 seconds
2023-03-27 13:21:00,389 : [INFO]  Batch 26: Testing set : loss - 0.5236, accuracy - 0.8137, recall - 0.9804, AUC - 0.9418, F1 - 0.8403, precision - 0.7353
2023-03-27 13:21:00,427 : [INFO]  Batch 27 initialized 
2023-03-27 13:21:00,835 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:01,113 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-27 13:21:04,625 : [INFO]  ------------------------- Batch round 1, loss: 0.5668 -------------------------
2023-03-27 13:21:04,626 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:04,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:04,631 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-27 13:21:06,333 : [INFO]  ------------------------- Batch round 2, loss: 0.5622 -------------------------
2023-03-27 13:21:06,333 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:06,336 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:06,339 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-27 13:21:08,049 : [INFO]  ------------------------- Batch round 3, loss: 0.5583 -------------------------
2023-03-27 13:21:08,050 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:08,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:08,054 : [INFO]  Batch number 27 model fetched from the server
2023-03-27 13:21:08,055 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-27 13:21:09,218 : [INFO]  Batch 27: Training set : loss - 0.5584, accuracy - 0.7391, recall - 0.9239, AUC - 0.8866, F1 - 0.7798, precision - 0.6746, training time - -7.0 seconds
2023-03-27 13:21:09,219 : [INFO]  Batch 27: Testing set : loss - 0.5471, accuracy - 0.7745, recall - 0.9412, AUC - 0.8828, F1 - 0.8067, precision - 0.7059
2023-03-27 13:21:09,225 : [INFO]  Batch 28 initialized 
2023-03-27 13:21:09,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:09,915 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-27 13:21:13,295 : [INFO]  ------------------------- Batch round 1, loss: 0.5738 -------------------------
2023-03-27 13:21:13,295 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:13,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:13,301 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-27 13:21:14,959 : [INFO]  ------------------------- Batch round 2, loss: 0.5674 -------------------------
2023-03-27 13:21:14,959 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:14,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:14,964 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-27 13:21:16,684 : [INFO]  ------------------------- Batch round 3, loss: 0.5625 -------------------------
2023-03-27 13:21:16,684 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:16,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:16,689 : [INFO]  Batch number 28 model fetched from the server
2023-03-27 13:21:16,690 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-27 13:21:17,937 : [INFO]  Batch 28: Training set : loss - 0.5669, accuracy - 0.7283, recall - 0.913, AUC - 0.8679, F1 - 0.7706, precision - 0.6667, training time - -7.0 seconds
2023-03-27 13:21:17,937 : [INFO]  Batch 28: Testing set : loss - 0.5541, accuracy - 0.7598, recall - 0.902, AUC - 0.866, F1 - 0.7897, precision - 0.7023
2023-03-27 13:21:17,943 : [INFO]  Batch 29 initialized 
2023-03-27 13:21:18,364 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:18,654 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-27 13:21:22,138 : [INFO]  ------------------------- Batch round 1, loss: 0.5337 -------------------------
2023-03-27 13:21:22,138 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:22,141 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:22,144 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-27 13:21:23,888 : [INFO]  ------------------------- Batch round 2, loss: 0.529 -------------------------
2023-03-27 13:21:23,888 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:23,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:23,893 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-27 13:21:25,656 : [INFO]  ------------------------- Batch round 3, loss: 0.5255 -------------------------
2023-03-27 13:21:25,656 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:25,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:25,661 : [INFO]  Batch number 29 model fetched from the server
2023-03-27 13:21:25,661 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-27 13:21:26,854 : [INFO]  Batch 29: Training set : loss - 0.5281, accuracy - 0.788, recall - 0.9674, AUC - 0.9195, F1 - 0.8203, precision - 0.712, training time - -7.0 seconds
2023-03-27 13:21:26,854 : [INFO]  Batch 29: Testing set : loss - 0.5697, accuracy - 0.7157, recall - 0.9706, AUC - 0.8794, F1 - 0.7734, precision - 0.6429
2023-03-27 13:21:26,860 : [INFO]  Batch 30 initialized 
2023-03-27 13:21:27,273 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:27,556 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-27 13:21:30,945 : [INFO]  ------------------------- Batch round 1, loss: 0.5798 -------------------------
2023-03-27 13:21:30,945 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:30,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:30,950 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-27 13:21:32,611 : [INFO]  ------------------------- Batch round 2, loss: 0.5766 -------------------------
2023-03-27 13:21:32,611 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:32,615 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:32,617 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-27 13:21:34,346 : [INFO]  ------------------------- Batch round 3, loss: 0.5707 -------------------------
2023-03-27 13:21:34,346 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:34,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:34,351 : [INFO]  Batch number 30 model fetched from the server
2023-03-27 13:21:34,352 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-27 13:21:35,501 : [INFO]  Batch 30: Training set : loss - 0.5714, accuracy - 0.7446, recall - 0.913, AUC - 0.8591, F1 - 0.7814, precision - 0.6829, training time - -7.0 seconds
2023-03-27 13:21:35,501 : [INFO]  Batch 30: Testing set : loss - 0.5628, accuracy - 0.7451, recall - 0.9216, AUC - 0.8668, F1 - 0.7833, precision - 0.6812
2023-03-27 13:21:35,510 : [INFO]  Batch 31 initialized 
2023-03-27 13:21:35,922 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:36,205 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-27 13:21:39,628 : [INFO]  ------------------------- Batch round 1, loss: 0.5649 -------------------------
2023-03-27 13:21:39,628 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:39,631 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:39,634 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-27 13:21:41,297 : [INFO]  ------------------------- Batch round 2, loss: 0.5589 -------------------------
2023-03-27 13:21:41,297 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:41,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:41,304 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-27 13:21:43,054 : [INFO]  ------------------------- Batch round 3, loss: 0.5588 -------------------------
2023-03-27 13:21:43,055 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:43,058 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:43,060 : [INFO]  Batch number 31 model fetched from the server
2023-03-27 13:21:43,060 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-27 13:21:44,206 : [INFO]  Batch 31: Training set : loss - 0.5521, accuracy - 0.7609, recall - 0.9783, AUC - 0.8867, F1 - 0.8036, precision - 0.6818, training time - -7.0 seconds
2023-03-27 13:21:44,207 : [INFO]  Batch 31: Testing set : loss - 0.5806, accuracy - 0.7206, recall - 0.9118, AUC - 0.8464, F1 - 0.7654, precision - 0.6596
2023-03-27 13:21:44,211 : [INFO]  Batch 32 initialized 
2023-03-27 13:21:44,616 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:44,910 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-27 13:21:48,437 : [INFO]  ------------------------- Batch round 1, loss: 0.5198 -------------------------
2023-03-27 13:21:48,437 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:48,440 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:48,442 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-27 13:21:50,251 : [INFO]  ------------------------- Batch round 2, loss: 0.5171 -------------------------
2023-03-27 13:21:50,252 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:50,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:50,257 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-27 13:21:51,982 : [INFO]  ------------------------- Batch round 3, loss: 0.5151 -------------------------
2023-03-27 13:21:51,982 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-27 13:21:51,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:51,988 : [INFO]  Batch number 32 model fetched from the server
2023-03-27 13:21:51,988 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-27 13:21:53,156 : [INFO]  Batch 32: Training set : loss - 0.5214, accuracy - 0.7935, recall - 0.9674, AUC - 0.9426, F1 - 0.8241, precision - 0.7177, training time - -7.0 seconds
2023-03-27 13:21:53,156 : [INFO]  Batch 32: Testing set : loss - 0.5505, accuracy - 0.7402, recall - 0.9216, AUC - 0.8894, F1 - 0.7801, precision - 0.6763
2023-03-27 13:21:53,161 : [INFO]  Batch 33 initialized 
2023-03-27 13:21:53,567 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:21:53,859 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-27 13:21:57,314 : [INFO]  ------------------------- Batch round 1, loss: 0.5538 -------------------------
2023-03-27 13:21:57,314 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-27 13:21:57,317 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:57,320 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-27 13:21:59,018 : [INFO]  ------------------------- Batch round 2, loss: 0.5484 -------------------------
2023-03-27 13:21:59,019 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-27 13:21:59,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:21:59,024 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-27 13:22:00,701 : [INFO]  ------------------------- Batch round 3, loss: 0.5437 -------------------------
2023-03-27 13:22:00,701 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:00,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:00,718 : [INFO]  Batch number 33 model fetched from the server
2023-03-27 13:22:00,718 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-27 13:22:01,879 : [INFO]  Batch 33: Training set : loss - 0.5422, accuracy - 0.7717, recall - 0.9348, AUC - 0.9276, F1 - 0.8037, precision - 0.7049, training time - -7.0 seconds
2023-03-27 13:22:01,879 : [INFO]  Batch 33: Testing set : loss - 0.5657, accuracy - 0.7304, recall - 0.9608, AUC - 0.9044, F1 - 0.7809, precision - 0.6577
2023-03-27 13:22:01,890 : [INFO]  Batch 34 initialized 
2023-03-27 13:22:02,307 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:02,595 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-27 13:22:06,012 : [INFO]  ------------------------- Batch round 1, loss: 0.5256 -------------------------
2023-03-27 13:22:06,012 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:06,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:06,017 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-27 13:22:07,716 : [INFO]  ------------------------- Batch round 2, loss: 0.5206 -------------------------
2023-03-27 13:22:07,716 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:07,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:07,722 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-27 13:22:09,401 : [INFO]  ------------------------- Batch round 3, loss: 0.5165 -------------------------
2023-03-27 13:22:09,401 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:09,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:09,406 : [INFO]  Batch number 34 model fetched from the server
2023-03-27 13:22:09,406 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-27 13:22:10,550 : [INFO]  Batch 34: Training set : loss - 0.5171, accuracy - 0.8152, recall - 0.9348, AUC - 0.9261, F1 - 0.835, precision - 0.7544, training time - -7.0 seconds
2023-03-27 13:22:10,551 : [INFO]  Batch 34: Testing set : loss - 0.5853, accuracy - 0.7255, recall - 0.9314, AUC - 0.8364, F1 - 0.7724, precision - 0.6597
2023-03-27 13:22:10,559 : [INFO]  Batch 35 initialized 
2023-03-27 13:22:10,975 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:11,275 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-27 13:22:14,661 : [INFO]  ------------------------- Batch round 1, loss: 0.5465 -------------------------
2023-03-27 13:22:14,661 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:14,665 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:14,666 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-27 13:22:16,311 : [INFO]  ------------------------- Batch round 2, loss: 0.5397 -------------------------
2023-03-27 13:22:16,311 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:16,344 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:16,346 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-27 13:22:18,003 : [INFO]  ------------------------- Batch round 3, loss: 0.5349 -------------------------
2023-03-27 13:22:18,003 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:18,006 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:18,008 : [INFO]  Batch number 35 model fetched from the server
2023-03-27 13:22:18,008 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-27 13:22:19,181 : [INFO]  Batch 35: Training set : loss - 0.5366, accuracy - 0.7609, recall - 0.9239, AUC - 0.9023, F1 - 0.7944, precision - 0.6967, training time - -7.0 seconds
2023-03-27 13:22:19,182 : [INFO]  Batch 35: Testing set : loss - 0.5366, accuracy - 0.7745, recall - 0.9314, AUC - 0.8764, F1 - 0.8051, precision - 0.709
2023-03-27 13:22:19,188 : [INFO]  Batch 36 initialized 
2023-03-27 13:22:19,595 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:19,895 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-27 13:22:23,326 : [INFO]  ------------------------- Batch round 1, loss: 0.523 -------------------------
2023-03-27 13:22:23,326 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:23,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:23,331 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-27 13:22:25,044 : [INFO]  ------------------------- Batch round 2, loss: 0.52 -------------------------
2023-03-27 13:22:25,044 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:25,047 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:25,049 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-27 13:22:26,771 : [INFO]  ------------------------- Batch round 3, loss: 0.516 -------------------------
2023-03-27 13:22:26,771 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:26,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:26,780 : [INFO]  Batch number 36 model fetched from the server
2023-03-27 13:22:26,780 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-27 13:22:27,931 : [INFO]  Batch 36: Training set : loss - 0.5153, accuracy - 0.8098, recall - 0.9348, AUC - 0.9262, F1 - 0.8309, precision - 0.7478, training time - -7.0 seconds
2023-03-27 13:22:27,931 : [INFO]  Batch 36: Testing set : loss - 0.5319, accuracy - 0.7745, recall - 0.9706, AUC - 0.922, F1 - 0.8115, precision - 0.6972
2023-03-27 13:22:27,936 : [INFO]  Batch 37 initialized 
2023-03-27 13:22:28,343 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:28,642 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-27 13:22:32,004 : [INFO]  ------------------------- Batch round 1, loss: 0.5636 -------------------------
2023-03-27 13:22:32,005 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:32,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:32,087 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-27 13:22:33,757 : [INFO]  ------------------------- Batch round 2, loss: 0.5608 -------------------------
2023-03-27 13:22:33,757 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:33,762 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:33,764 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-27 13:22:35,445 : [INFO]  ------------------------- Batch round 3, loss: 0.5557 -------------------------
2023-03-27 13:22:35,446 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:35,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:35,521 : [INFO]  Batch number 37 model fetched from the server
2023-03-27 13:22:35,521 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-27 13:22:36,646 : [INFO]  Batch 37: Training set : loss - 0.5592, accuracy - 0.7391, recall - 0.9348, AUC - 0.8524, F1 - 0.7818, precision - 0.6719, training time - -7.0 seconds
2023-03-27 13:22:36,647 : [INFO]  Batch 37: Testing set : loss - 0.5432, accuracy - 0.7843, recall - 0.951, AUC - 0.902, F1 - 0.8151, precision - 0.7132
2023-03-27 13:22:36,656 : [INFO]  Batch 38 initialized 
2023-03-27 13:22:37,067 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:37,369 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-27 13:22:40,785 : [INFO]  ------------------------- Batch round 1, loss: 0.5444 -------------------------
2023-03-27 13:22:40,786 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:40,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:40,791 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-27 13:22:42,522 : [INFO]  ------------------------- Batch round 2, loss: 0.5378 -------------------------
2023-03-27 13:22:42,522 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:42,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:42,552 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-27 13:22:44,212 : [INFO]  ------------------------- Batch round 3, loss: 0.5372 -------------------------
2023-03-27 13:22:44,212 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:44,245 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:44,247 : [INFO]  Batch number 38 model fetched from the server
2023-03-27 13:22:44,248 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-27 13:22:45,416 : [INFO]  Batch 38: Training set : loss - 0.5345, accuracy - 0.788, recall - 0.9457, AUC - 0.9244, F1 - 0.8169, precision - 0.719, training time - -7.0 seconds
2023-03-27 13:22:45,416 : [INFO]  Batch 38: Testing set : loss - 0.5701, accuracy - 0.7255, recall - 0.8922, AUC - 0.8599, F1 - 0.7647, precision - 0.6691
2023-03-27 13:22:45,422 : [INFO]  Batch 39 initialized 
2023-03-27 13:22:45,822 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:46,124 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-27 13:22:49,542 : [INFO]  ------------------------- Batch round 1, loss: 0.5482 -------------------------
2023-03-27 13:22:49,543 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:49,546 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:49,548 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-27 13:22:51,241 : [INFO]  ------------------------- Batch round 2, loss: 0.5416 -------------------------
2023-03-27 13:22:51,241 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:51,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:51,246 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-27 13:22:52,939 : [INFO]  ------------------------- Batch round 3, loss: 0.5418 -------------------------
2023-03-27 13:22:52,939 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-27 13:22:52,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:52,955 : [INFO]  Batch number 39 model fetched from the server
2023-03-27 13:22:52,955 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-27 13:22:54,138 : [INFO]  Batch 39: Training set : loss - 0.5435, accuracy - 0.7717, recall - 0.9565, AUC - 0.921, F1 - 0.8073, precision - 0.6984, training time - -7.0 seconds
2023-03-27 13:22:54,138 : [INFO]  Batch 39: Testing set : loss - 0.5261, accuracy - 0.8039, recall - 0.9608, AUC - 0.9248, F1 - 0.8305, precision - 0.7313
2023-03-27 13:22:54,142 : [INFO]  Batch 40 initialized 
2023-03-27 13:22:54,556 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:22:54,859 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-27 13:22:58,274 : [INFO]  ------------------------- Batch round 1, loss: 0.5625 -------------------------
2023-03-27 13:22:58,275 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-27 13:22:58,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:58,279 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-27 13:22:59,964 : [INFO]  ------------------------- Batch round 2, loss: 0.5584 -------------------------
2023-03-27 13:22:59,965 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-27 13:22:59,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:22:59,969 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-27 13:23:01,654 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-27 13:23:01,654 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:01,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:01,659 : [INFO]  Batch number 40 model fetched from the server
2023-03-27 13:23:01,659 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-27 13:23:02,803 : [INFO]  Batch 40: Training set : loss - 0.5568, accuracy - 0.7554, recall - 0.9565, AUC - 0.8835, F1 - 0.7964, precision - 0.6822, training time - -7.0 seconds
2023-03-27 13:23:02,804 : [INFO]  Batch 40: Testing set : loss - 0.5552, accuracy - 0.75, recall - 0.9412, AUC - 0.8554, F1 - 0.7901, precision - 0.6809
2023-03-27 13:23:02,813 : [INFO]  Batch 41 initialized 
2023-03-27 13:23:03,225 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:03,531 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-27 13:23:06,930 : [INFO]  ------------------------- Batch round 1, loss: 0.5588 -------------------------
2023-03-27 13:23:06,930 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:06,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:06,936 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-27 13:23:08,596 : [INFO]  ------------------------- Batch round 2, loss: 0.5549 -------------------------
2023-03-27 13:23:08,596 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:08,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:08,610 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-27 13:23:10,242 : [INFO]  ------------------------- Batch round 3, loss: 0.5525 -------------------------
2023-03-27 13:23:10,242 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:10,258 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:10,260 : [INFO]  Batch number 41 model fetched from the server
2023-03-27 13:23:10,260 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-27 13:23:11,414 : [INFO]  Batch 41: Training set : loss - 0.5472, accuracy - 0.75, recall - 0.9348, AUC - 0.894, F1 - 0.789, precision - 0.6825, training time - -7.0 seconds
2023-03-27 13:23:11,414 : [INFO]  Batch 41: Testing set : loss - 0.5648, accuracy - 0.701, recall - 0.902, AUC - 0.8527, F1 - 0.751, precision - 0.6434
2023-03-27 13:23:11,420 : [INFO]  Batch 42 initialized 
2023-03-27 13:23:11,834 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:12,143 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-27 13:23:15,538 : [INFO]  ------------------------- Batch round 1, loss: 0.542 -------------------------
2023-03-27 13:23:15,539 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:15,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:15,544 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-27 13:23:17,243 : [INFO]  ------------------------- Batch round 2, loss: 0.5328 -------------------------
2023-03-27 13:23:17,244 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:17,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:17,292 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-27 13:23:19,092 : [INFO]  ------------------------- Batch round 3, loss: 0.5266 -------------------------
2023-03-27 13:23:19,092 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:19,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:19,097 : [INFO]  Batch number 42 model fetched from the server
2023-03-27 13:23:19,097 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-27 13:23:20,247 : [INFO]  Batch 42: Training set : loss - 0.5278, accuracy - 0.75, recall - 0.9239, AUC - 0.929, F1 - 0.787, precision - 0.6855, training time - -7.0 seconds
2023-03-27 13:23:20,247 : [INFO]  Batch 42: Testing set : loss - 0.5791, accuracy - 0.7206, recall - 0.9118, AUC - 0.8581, F1 - 0.7654, precision - 0.6596
2023-03-27 13:23:20,256 : [INFO]  Batch 43 initialized 
2023-03-27 13:23:20,664 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:20,976 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-27 13:23:24,430 : [INFO]  ------------------------- Batch round 1, loss: 0.5345 -------------------------
2023-03-27 13:23:24,430 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:24,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:24,435 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-27 13:23:26,113 : [INFO]  ------------------------- Batch round 2, loss: 0.5306 -------------------------
2023-03-27 13:23:26,113 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:26,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:26,118 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-27 13:23:27,802 : [INFO]  ------------------------- Batch round 3, loss: 0.5274 -------------------------
2023-03-27 13:23:27,802 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:27,805 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:27,807 : [INFO]  Batch number 43 model fetched from the server
2023-03-27 13:23:27,807 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-27 13:23:28,959 : [INFO]  Batch 43: Training set : loss - 0.5273, accuracy - 0.7554, recall - 0.9457, AUC - 0.9413, F1 - 0.7945, precision - 0.685, training time - -7.0 seconds
2023-03-27 13:23:28,960 : [INFO]  Batch 43: Testing set : loss - 0.54, accuracy - 0.75, recall - 1.0, AUC - 0.965, F1 - 0.8, precision - 0.6667
2023-03-27 13:23:28,970 : [INFO]  Batch 44 initialized 
2023-03-27 13:23:29,400 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:29,718 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-27 13:23:33,115 : [INFO]  ------------------------- Batch round 1, loss: 0.5456 -------------------------
2023-03-27 13:23:33,115 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:33,135 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:33,137 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-27 13:23:34,814 : [INFO]  ------------------------- Batch round 2, loss: 0.5391 -------------------------
2023-03-27 13:23:34,814 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:34,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:34,820 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-27 13:23:36,554 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-27 13:23:36,554 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:36,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:36,560 : [INFO]  Batch number 44 model fetched from the server
2023-03-27 13:23:36,560 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-27 13:23:37,706 : [INFO]  Batch 44: Training set : loss - 0.535, accuracy - 0.7826, recall - 0.9239, AUC - 0.8894, F1 - 0.8095, precision - 0.7203, training time - -7.0 seconds
2023-03-27 13:23:37,706 : [INFO]  Batch 44: Testing set : loss - 0.5539, accuracy - 0.7598, recall - 0.9412, AUC - 0.8924, F1 - 0.7967, precision - 0.6906
2023-03-27 13:23:37,711 : [INFO]  Batch 45 initialized 
2023-03-27 13:23:38,119 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:38,438 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-27 13:23:41,853 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-27 13:23:41,853 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:41,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:41,858 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-27 13:23:43,576 : [INFO]  ------------------------- Batch round 2, loss: 0.5493 -------------------------
2023-03-27 13:23:43,576 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:43,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:43,582 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-27 13:23:45,260 : [INFO]  ------------------------- Batch round 3, loss: 0.5451 -------------------------
2023-03-27 13:23:45,260 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:45,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:45,266 : [INFO]  Batch number 45 model fetched from the server
2023-03-27 13:23:45,266 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-27 13:23:46,456 : [INFO]  Batch 45: Training set : loss - 0.5485, accuracy - 0.7609, recall - 0.9565, AUC - 0.9006, F1 - 0.8, precision - 0.6875, training time - -7.0 seconds
2023-03-27 13:23:46,457 : [INFO]  Batch 45: Testing set : loss - 0.5232, accuracy - 0.7892, recall - 0.951, AUC - 0.9388, F1 - 0.8186, precision - 0.7185
2023-03-27 13:23:46,461 : [INFO]  Batch 46 initialized 
2023-03-27 13:23:46,870 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:47,186 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-27 13:23:50,754 : [INFO]  ------------------------- Batch round 1, loss: 0.525 -------------------------
2023-03-27 13:23:50,754 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:50,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:50,759 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-27 13:23:52,484 : [INFO]  ------------------------- Batch round 2, loss: 0.5182 -------------------------
2023-03-27 13:23:52,485 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-27 13:23:52,488 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:52,490 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-27 13:23:54,212 : [INFO]  ------------------------- Batch round 3, loss: 0.5154 -------------------------
2023-03-27 13:23:54,212 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-27 13:23:54,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:54,218 : [INFO]  Batch number 46 model fetched from the server
2023-03-27 13:23:54,218 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-27 13:23:55,355 : [INFO]  Batch 46: Training set : loss - 0.5204, accuracy - 0.7772, recall - 0.9674, AUC - 0.9594, F1 - 0.8128, precision - 0.7008, training time - -7.0 seconds
2023-03-27 13:23:55,355 : [INFO]  Batch 46: Testing set : loss - 0.5359, accuracy - 0.7745, recall - 0.9314, AUC - 0.9336, F1 - 0.8051, precision - 0.709
2023-03-27 13:23:55,359 : [INFO]  Batch 47 initialized 
2023-03-27 13:23:55,762 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:23:56,083 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-27 13:23:59,575 : [INFO]  ------------------------- Batch round 1, loss: 0.5149 -------------------------
2023-03-27 13:23:59,575 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-27 13:23:59,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:23:59,580 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-27 13:24:01,275 : [INFO]  ------------------------- Batch round 2, loss: 0.509 -------------------------
2023-03-27 13:24:01,276 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:01,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:01,281 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-27 13:24:02,949 : [INFO]  ------------------------- Batch round 3, loss: 0.5064 -------------------------
2023-03-27 13:24:02,950 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:02,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:02,955 : [INFO]  Batch number 47 model fetched from the server
2023-03-27 13:24:02,955 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-27 13:24:04,136 : [INFO]  Batch 47: Training set : loss - 0.5063, accuracy - 0.8315, recall - 0.9783, AUC - 0.9504, F1 - 0.8531, precision - 0.7563, training time - -7.0 seconds
2023-03-27 13:24:04,136 : [INFO]  Batch 47: Testing set : loss - 0.551, accuracy - 0.7451, recall - 0.951, AUC - 0.9067, F1 - 0.7886, precision - 0.6736
2023-03-27 13:24:04,141 : [INFO]  Batch 48 initialized 
2023-03-27 13:24:04,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:04,886 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-27 13:24:08,308 : [INFO]  ------------------------- Batch round 1, loss: 0.5461 -------------------------
2023-03-27 13:24:08,308 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:08,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:08,314 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-27 13:24:10,038 : [INFO]  ------------------------- Batch round 2, loss: 0.544 -------------------------
2023-03-27 13:24:10,038 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:10,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:10,044 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-27 13:24:11,737 : [INFO]  ------------------------- Batch round 3, loss: 0.5405 -------------------------
2023-03-27 13:24:11,737 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:11,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:11,742 : [INFO]  Batch number 48 model fetched from the server
2023-03-27 13:24:11,742 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-27 13:24:12,877 : [INFO]  Batch 48: Training set : loss - 0.5461, accuracy - 0.7554, recall - 0.913, AUC - 0.9106, F1 - 0.7887, precision - 0.6942, training time - -7.0 seconds
2023-03-27 13:24:12,877 : [INFO]  Batch 48: Testing set : loss - 0.5791, accuracy - 0.7059, recall - 0.902, AUC - 0.8854, F1 - 0.7541, precision - 0.6479
2023-03-27 13:24:12,883 : [INFO]  Batch 49 initialized 
2023-03-27 13:24:13,289 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:13,613 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-27 13:24:17,014 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-27 13:24:17,014 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:17,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:17,019 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-27 13:24:18,691 : [INFO]  ------------------------- Batch round 2, loss: 0.5516 -------------------------
2023-03-27 13:24:18,691 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:18,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:18,733 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-27 13:24:20,390 : [INFO]  ------------------------- Batch round 3, loss: 0.549 -------------------------
2023-03-27 13:24:20,390 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:20,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:20,413 : [INFO]  Batch number 49 model fetched from the server
2023-03-27 13:24:20,413 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-27 13:24:21,564 : [INFO]  Batch 49: Training set : loss - 0.5466, accuracy - 0.7609, recall - 0.9565, AUC - 0.9014, F1 - 0.8, precision - 0.6875, training time - -7.0 seconds
2023-03-27 13:24:21,564 : [INFO]  Batch 49: Testing set : loss - 0.5491, accuracy - 0.7402, recall - 0.9314, AUC - 0.9128, F1 - 0.7819, precision - 0.6738
2023-03-27 13:24:21,574 : [INFO]  Batch 50 initialized 
2023-03-27 13:24:21,984 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:22,309 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-27 13:24:25,745 : [INFO]  ------------------------- Batch round 1, loss: 0.5419 -------------------------
2023-03-27 13:24:25,746 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:25,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:25,751 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-27 13:24:27,433 : [INFO]  ------------------------- Batch round 2, loss: 0.5353 -------------------------
2023-03-27 13:24:27,433 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:27,436 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:27,438 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-27 13:24:29,128 : [INFO]  ------------------------- Batch round 3, loss: 0.5335 -------------------------
2023-03-27 13:24:29,128 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:29,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:29,133 : [INFO]  Batch number 50 model fetched from the server
2023-03-27 13:24:29,134 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-27 13:24:30,304 : [INFO]  Batch 50: Training set : loss - 0.5284, accuracy - 0.8207, recall - 0.9348, AUC - 0.8914, F1 - 0.839, precision - 0.7611, training time - -7.0 seconds
2023-03-27 13:24:30,304 : [INFO]  Batch 50: Testing set : loss - 0.565, accuracy - 0.7157, recall - 0.9608, AUC - 0.9226, F1 - 0.7717, precision - 0.6447
2023-03-27 13:24:30,308 : [INFO]  Batch 51 initialized 
2023-03-27 13:24:30,715 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:31,037 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-27 13:24:34,469 : [INFO]  ------------------------- Batch round 1, loss: 0.5534 -------------------------
2023-03-27 13:24:34,469 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:34,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:34,482 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-27 13:24:36,205 : [INFO]  ------------------------- Batch round 2, loss: 0.548 -------------------------
2023-03-27 13:24:36,205 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:36,245 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:36,247 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-27 13:24:37,883 : [INFO]  ------------------------- Batch round 3, loss: 0.5466 -------------------------
2023-03-27 13:24:37,883 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:37,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:37,907 : [INFO]  Batch number 51 model fetched from the server
2023-03-27 13:24:37,907 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-27 13:24:39,056 : [INFO]  Batch 51: Training set : loss - 0.5465, accuracy - 0.7772, recall - 0.9565, AUC - 0.9318, F1 - 0.8111, precision - 0.704, training time - -7.0 seconds
2023-03-27 13:24:39,056 : [INFO]  Batch 51: Testing set : loss - 0.5649, accuracy - 0.7255, recall - 0.9216, AUC - 0.8925, F1 - 0.7705, precision - 0.662
2023-03-27 13:24:39,060 : [INFO]  Batch 52 initialized 
2023-03-27 13:24:39,466 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:39,794 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-27 13:24:43,202 : [INFO]  ------------------------- Batch round 1, loss: 0.5346 -------------------------
2023-03-27 13:24:43,202 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:43,206 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:43,207 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-27 13:24:44,911 : [INFO]  ------------------------- Batch round 2, loss: 0.528 -------------------------
2023-03-27 13:24:44,911 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:44,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:44,916 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-27 13:24:46,587 : [INFO]  ------------------------- Batch round 3, loss: 0.5227 -------------------------
2023-03-27 13:24:46,587 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:46,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:46,592 : [INFO]  Batch number 52 model fetched from the server
2023-03-27 13:24:46,592 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-27 13:24:47,765 : [INFO]  Batch 52: Training set : loss - 0.5256, accuracy - 0.7772, recall - 0.9783, AUC - 0.9201, F1 - 0.8145, precision - 0.6977, training time - -7.0 seconds
2023-03-27 13:24:47,765 : [INFO]  Batch 52: Testing set : loss - 0.5397, accuracy - 0.7598, recall - 0.9608, AUC - 0.9462, F1 - 0.8, precision - 0.6853
2023-03-27 13:24:47,777 : [INFO]  Batch 53 initialized 
2023-03-27 13:24:48,179 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:48,507 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-27 13:24:51,951 : [INFO]  ------------------------- Batch round 1, loss: 0.5637 -------------------------
2023-03-27 13:24:51,951 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-27 13:24:51,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:51,957 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-27 13:24:53,667 : [INFO]  ------------------------- Batch round 2, loss: 0.5581 -------------------------
2023-03-27 13:24:53,667 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-27 13:24:53,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:53,672 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-27 13:24:55,366 : [INFO]  ------------------------- Batch round 3, loss: 0.5548 -------------------------
2023-03-27 13:24:55,366 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-27 13:24:55,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:24:55,371 : [INFO]  Batch number 53 model fetched from the server
2023-03-27 13:24:55,371 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-27 13:24:56,530 : [INFO]  Batch 53: Training set : loss - 0.5535, accuracy - 0.7446, recall - 0.9457, AUC - 0.912, F1 - 0.7873, precision - 0.6744, training time - -7.0 seconds
2023-03-27 13:24:56,530 : [INFO]  Batch 53: Testing set : loss - 0.5554, accuracy - 0.7549, recall - 0.951, AUC - 0.9196, F1 - 0.7951, precision - 0.6831
2023-03-27 13:24:56,536 : [INFO]  Batch 54 initialized 
2023-03-27 13:24:56,954 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:24:57,286 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-27 13:25:00,666 : [INFO]  ------------------------- Batch round 1, loss: 0.5443 -------------------------
2023-03-27 13:25:00,667 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:00,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:00,671 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-27 13:25:02,308 : [INFO]  ------------------------- Batch round 2, loss: 0.539 -------------------------
2023-03-27 13:25:02,308 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:02,337 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:02,340 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-27 13:25:04,012 : [INFO]  ------------------------- Batch round 3, loss: 0.5342 -------------------------
2023-03-27 13:25:04,012 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:04,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:04,031 : [INFO]  Batch number 54 model fetched from the server
2023-03-27 13:25:04,031 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-27 13:25:05,190 : [INFO]  Batch 54: Training set : loss - 0.5369, accuracy - 0.7717, recall - 0.9457, AUC - 0.9053, F1 - 0.8056, precision - 0.7016, training time - -7.0 seconds
2023-03-27 13:25:05,190 : [INFO]  Batch 54: Testing set : loss - 0.5467, accuracy - 0.7255, recall - 0.9804, AUC - 0.9299, F1 - 0.7812, precision - 0.6494
2023-03-27 13:25:05,198 : [INFO]  Batch 55 initialized 
2023-03-27 13:25:05,612 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:05,953 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-27 13:25:09,321 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-27 13:25:09,321 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:09,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:09,391 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-27 13:25:11,037 : [INFO]  ------------------------- Batch round 2, loss: 0.5652 -------------------------
2023-03-27 13:25:11,037 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:11,083 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:11,085 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-27 13:25:12,697 : [INFO]  ------------------------- Batch round 3, loss: 0.5599 -------------------------
2023-03-27 13:25:12,697 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:12,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:12,767 : [INFO]  Batch number 55 model fetched from the server
2023-03-27 13:25:12,767 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-27 13:25:13,906 : [INFO]  Batch 55: Training set : loss - 0.5595, accuracy - 0.7446, recall - 0.9891, AUC - 0.8898, F1 - 0.7948, precision - 0.6642, training time - -7.0 seconds
2023-03-27 13:25:13,906 : [INFO]  Batch 55: Testing set : loss - 0.5679, accuracy - 0.7157, recall - 0.9412, AUC - 0.8843, F1 - 0.768, precision - 0.6486
2023-03-27 13:25:13,911 : [INFO]  Batch 56 initialized 
2023-03-27 13:25:14,318 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:14,656 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-27 13:25:18,074 : [INFO]  ------------------------- Batch round 1, loss: 0.5667 -------------------------
2023-03-27 13:25:18,074 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:18,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:18,080 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-27 13:25:19,750 : [INFO]  ------------------------- Batch round 2, loss: 0.5607 -------------------------
2023-03-27 13:25:19,750 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:19,753 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:19,755 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-27 13:25:21,430 : [INFO]  ------------------------- Batch round 3, loss: 0.5598 -------------------------
2023-03-27 13:25:21,430 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:21,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:21,435 : [INFO]  Batch number 56 model fetched from the server
2023-03-27 13:25:21,435 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-27 13:25:22,623 : [INFO]  Batch 56: Training set : loss - 0.5565, accuracy - 0.7554, recall - 0.9457, AUC - 0.8799, F1 - 0.7945, precision - 0.685, training time - -7.0 seconds
2023-03-27 13:25:22,623 : [INFO]  Batch 56: Testing set : loss - 0.5944, accuracy - 0.7059, recall - 0.902, AUC - 0.8523, F1 - 0.7541, precision - 0.6479
2023-03-27 13:25:22,630 : [INFO]  Batch 57 initialized 
2023-03-27 13:25:23,047 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:23,386 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-27 13:25:26,869 : [INFO]  ------------------------- Batch round 1, loss: 0.547 -------------------------
2023-03-27 13:25:26,869 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:26,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:26,874 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-27 13:25:28,585 : [INFO]  ------------------------- Batch round 2, loss: 0.5364 -------------------------
2023-03-27 13:25:28,585 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:28,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:28,590 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-27 13:25:30,265 : [INFO]  ------------------------- Batch round 3, loss: 0.5331 -------------------------
2023-03-27 13:25:30,265 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:30,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:30,270 : [INFO]  Batch number 57 model fetched from the server
2023-03-27 13:25:30,270 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-27 13:25:31,452 : [INFO]  Batch 57: Training set : loss - 0.5334, accuracy - 0.7663, recall - 0.9783, AUC - 0.9267, F1 - 0.8072, precision - 0.687, training time - -7.0 seconds
2023-03-27 13:25:31,453 : [INFO]  Batch 57: Testing set : loss - 0.5412, accuracy - 0.7794, recall - 0.9608, AUC - 0.9238, F1 - 0.8133, precision - 0.705
2023-03-27 13:25:31,462 : [INFO]  Batch 58 initialized 
2023-03-27 13:25:31,869 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:32,204 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-27 13:25:35,611 : [INFO]  ------------------------- Batch round 1, loss: 0.5166 -------------------------
2023-03-27 13:25:35,611 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:35,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:35,617 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-27 13:25:37,309 : [INFO]  ------------------------- Batch round 2, loss: 0.5102 -------------------------
2023-03-27 13:25:37,309 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:37,312 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:37,314 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-27 13:25:38,930 : [INFO]  ------------------------- Batch round 3, loss: 0.5102 -------------------------
2023-03-27 13:25:38,930 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:38,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:38,935 : [INFO]  Batch number 58 model fetched from the server
2023-03-27 13:25:38,935 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-27 13:25:40,105 : [INFO]  Batch 58: Training set : loss - 0.5073, accuracy - 0.8043, recall - 0.9783, AUC - 0.9326, F1 - 0.8333, precision - 0.7258, training time - -7.0 seconds
2023-03-27 13:25:40,105 : [INFO]  Batch 58: Testing set : loss - 0.5326, accuracy - 0.799, recall - 0.9706, AUC - 0.9024, F1 - 0.8285, precision - 0.7226
2023-03-27 13:25:40,109 : [INFO]  Batch 59 initialized 
2023-03-27 13:25:40,519 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:40,862 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-27 13:25:44,268 : [INFO]  ------------------------- Batch round 1, loss: 0.5578 -------------------------
2023-03-27 13:25:44,268 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:44,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:44,273 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-27 13:25:45,919 : [INFO]  ------------------------- Batch round 2, loss: 0.5516 -------------------------
2023-03-27 13:25:45,920 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:45,923 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:45,925 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-27 13:25:47,572 : [INFO]  ------------------------- Batch round 3, loss: 0.5439 -------------------------
2023-03-27 13:25:47,572 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:47,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:47,585 : [INFO]  Batch number 59 model fetched from the server
2023-03-27 13:25:47,585 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-27 13:25:48,745 : [INFO]  Batch 59: Training set : loss - 0.5468, accuracy - 0.7717, recall - 0.9565, AUC - 0.9055, F1 - 0.8073, precision - 0.6984, training time - -7.0 seconds
2023-03-27 13:25:48,745 : [INFO]  Batch 59: Testing set : loss - 0.547, accuracy - 0.7843, recall - 0.951, AUC - 0.8962, F1 - 0.8151, precision - 0.7132
2023-03-27 13:25:48,755 : [INFO]  Batch 60 initialized 
2023-03-27 13:25:49,165 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:49,507 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-27 13:25:52,937 : [INFO]  ------------------------- Batch round 1, loss: 0.5315 -------------------------
2023-03-27 13:25:52,937 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-27 13:25:52,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:52,942 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-27 13:25:54,650 : [INFO]  ------------------------- Batch round 2, loss: 0.5242 -------------------------
2023-03-27 13:25:54,651 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-27 13:25:54,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:54,656 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-27 13:25:56,336 : [INFO]  ------------------------- Batch round 3, loss: 0.5182 -------------------------
2023-03-27 13:25:56,336 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-27 13:25:56,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:25:56,341 : [INFO]  Batch number 60 model fetched from the server
2023-03-27 13:25:56,341 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-27 13:25:57,495 : [INFO]  Batch 60: Training set : loss - 0.5218, accuracy - 0.788, recall - 0.913, AUC - 0.9118, F1 - 0.8116, precision - 0.7304, training time - -7.0 seconds
2023-03-27 13:25:57,495 : [INFO]  Batch 60: Testing set : loss - 0.5412, accuracy - 0.7745, recall - 0.9706, AUC - 0.9089, F1 - 0.8115, precision - 0.6972
2023-03-27 13:25:57,501 : [INFO]  Batch 61 initialized 
2023-03-27 13:25:57,905 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:25:58,250 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-27 13:26:01,638 : [INFO]  ------------------------- Batch round 1, loss: 0.5514 -------------------------
2023-03-27 13:26:01,639 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:01,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:01,655 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-27 13:26:03,291 : [INFO]  ------------------------- Batch round 2, loss: 0.5424 -------------------------
2023-03-27 13:26:03,292 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:03,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:03,335 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-27 13:26:04,993 : [INFO]  ------------------------- Batch round 3, loss: 0.5358 -------------------------
2023-03-27 13:26:04,993 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:05,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:05,048 : [INFO]  Batch number 61 model fetched from the server
2023-03-27 13:26:05,048 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-27 13:26:06,239 : [INFO]  Batch 61: Training set : loss - 0.5385, accuracy - 0.7717, recall - 0.9348, AUC - 0.9257, F1 - 0.8037, precision - 0.7049, training time - -7.0 seconds
2023-03-27 13:26:06,240 : [INFO]  Batch 61: Testing set : loss - 0.56, accuracy - 0.7402, recall - 0.9118, AUC - 0.8867, F1 - 0.7782, precision - 0.6788
2023-03-27 13:26:06,246 : [INFO]  Batch 62 initialized 
2023-03-27 13:26:06,656 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:06,992 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-27 13:26:10,357 : [INFO]  ------------------------- Batch round 1, loss: 0.5843 -------------------------
2023-03-27 13:26:10,358 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:10,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:10,433 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-27 13:26:12,094 : [INFO]  ------------------------- Batch round 2, loss: 0.5798 -------------------------
2023-03-27 13:26:12,094 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:12,112 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:12,114 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-27 13:26:13,764 : [INFO]  ------------------------- Batch round 3, loss: 0.5725 -------------------------
2023-03-27 13:26:13,764 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:13,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:13,798 : [INFO]  Batch number 62 model fetched from the server
2023-03-27 13:26:13,798 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-27 13:26:14,959 : [INFO]  Batch 62: Training set : loss - 0.5717, accuracy - 0.7065, recall - 0.9348, AUC - 0.885, F1 - 0.7611, precision - 0.6418, training time - -7.0 seconds
2023-03-27 13:26:14,959 : [INFO]  Batch 62: Testing set : loss - 0.5746, accuracy - 0.7451, recall - 0.951, AUC - 0.8553, F1 - 0.7886, precision - 0.6736
2023-03-27 13:26:14,964 : [INFO]  Batch 63 initialized 
2023-03-27 13:26:15,374 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:15,726 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-27 13:26:19,120 : [INFO]  ------------------------- Batch round 1, loss: 0.5367 -------------------------
2023-03-27 13:26:19,121 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:19,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:19,158 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-27 13:26:20,809 : [INFO]  ------------------------- Batch round 2, loss: 0.5304 -------------------------
2023-03-27 13:26:20,809 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:20,813 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:20,814 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-27 13:26:22,514 : [INFO]  ------------------------- Batch round 3, loss: 0.5252 -------------------------
2023-03-27 13:26:22,515 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:22,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:22,522 : [INFO]  Batch number 63 model fetched from the server
2023-03-27 13:26:22,522 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-27 13:26:23,695 : [INFO]  Batch 63: Training set : loss - 0.5337, accuracy - 0.7772, recall - 0.9348, AUC - 0.9132, F1 - 0.8075, precision - 0.7107, training time - -7.0 seconds
2023-03-27 13:26:23,696 : [INFO]  Batch 63: Testing set : loss - 0.5667, accuracy - 0.7255, recall - 0.9412, AUC - 0.8628, F1 - 0.7742, precision - 0.6575
2023-03-27 13:26:23,700 : [INFO]  Batch 64 initialized 
2023-03-27 13:26:24,107 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:24,463 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-27 13:26:27,895 : [INFO]  ------------------------- Batch round 1, loss: 0.5357 -------------------------
2023-03-27 13:26:27,895 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:27,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:27,899 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-27 13:26:29,618 : [INFO]  ------------------------- Batch round 2, loss: 0.5282 -------------------------
2023-03-27 13:26:29,618 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:29,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:29,623 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-27 13:26:31,329 : [INFO]  ------------------------- Batch round 3, loss: 0.5237 -------------------------
2023-03-27 13:26:31,330 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:31,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:31,334 : [INFO]  Batch number 64 model fetched from the server
2023-03-27 13:26:31,335 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-27 13:26:32,484 : [INFO]  Batch 64: Training set : loss - 0.5305, accuracy - 0.7989, recall - 0.9457, AUC - 0.9061, F1 - 0.8246, precision - 0.7311, training time - -7.0 seconds
2023-03-27 13:26:32,484 : [INFO]  Batch 64: Testing set : loss - 0.544, accuracy - 0.7451, recall - 0.9314, AUC - 0.916, F1 - 0.7851, precision - 0.6786
2023-03-27 13:26:32,494 : [INFO]  Batch 65 initialized 
2023-03-27 13:26:32,899 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:33,261 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-27 13:26:36,706 : [INFO]  ------------------------- Batch round 1, loss: 0.5505 -------------------------
2023-03-27 13:26:36,706 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:36,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:36,711 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-27 13:26:38,428 : [INFO]  ------------------------- Batch round 2, loss: 0.5455 -------------------------
2023-03-27 13:26:38,428 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:38,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:38,433 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-27 13:26:40,096 : [INFO]  ------------------------- Batch round 3, loss: 0.5419 -------------------------
2023-03-27 13:26:40,096 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:40,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:40,118 : [INFO]  Batch number 65 model fetched from the server
2023-03-27 13:26:40,118 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-27 13:26:41,281 : [INFO]  Batch 65: Training set : loss - 0.5421, accuracy - 0.7663, recall - 0.9565, AUC - 0.8961, F1 - 0.8037, precision - 0.6929, training time - -7.0 seconds
2023-03-27 13:26:41,281 : [INFO]  Batch 65: Testing set : loss - 0.5563, accuracy - 0.7598, recall - 0.9804, AUC - 0.8947, F1 - 0.8032, precision - 0.6803
2023-03-27 13:26:41,288 : [INFO]  Batch 66 initialized 
2023-03-27 13:26:41,693 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:42,052 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-27 13:26:45,462 : [INFO]  ------------------------- Batch round 1, loss: 0.5522 -------------------------
2023-03-27 13:26:45,462 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:45,466 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:45,468 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-27 13:26:47,166 : [INFO]  ------------------------- Batch round 2, loss: 0.5459 -------------------------
2023-03-27 13:26:47,166 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:47,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:47,172 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-27 13:26:48,824 : [INFO]  ------------------------- Batch round 3, loss: 0.5445 -------------------------
2023-03-27 13:26:48,825 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:48,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:48,829 : [INFO]  Batch number 66 model fetched from the server
2023-03-27 13:26:48,829 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-27 13:26:49,989 : [INFO]  Batch 66: Training set : loss - 0.5463, accuracy - 0.7717, recall - 0.9674, AUC - 0.9159, F1 - 0.8091, precision - 0.6953, training time - -7.0 seconds
2023-03-27 13:26:49,989 : [INFO]  Batch 66: Testing set : loss - 0.5578, accuracy - 0.75, recall - 0.9412, AUC - 0.9159, F1 - 0.7901, precision - 0.6809
2023-03-27 13:26:49,995 : [INFO]  Batch 67 initialized 
2023-03-27 13:26:50,407 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:50,763 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-27 13:26:54,181 : [INFO]  ------------------------- Batch round 1, loss: 0.5359 -------------------------
2023-03-27 13:26:54,181 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-27 13:26:54,184 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:54,186 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-27 13:26:55,869 : [INFO]  ------------------------- Batch round 2, loss: 0.534 -------------------------
2023-03-27 13:26:55,869 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-27 13:26:55,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:55,874 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-27 13:26:57,551 : [INFO]  ------------------------- Batch round 3, loss: 0.5318 -------------------------
2023-03-27 13:26:57,551 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-27 13:26:57,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:26:57,556 : [INFO]  Batch number 67 model fetched from the server
2023-03-27 13:26:57,556 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-27 13:26:58,753 : [INFO]  Batch 67: Training set : loss - 0.5326, accuracy - 0.7663, recall - 0.9457, AUC - 0.9188, F1 - 0.8018, precision - 0.696, training time - -7.0 seconds
2023-03-27 13:26:58,754 : [INFO]  Batch 67: Testing set : loss - 0.5534, accuracy - 0.7255, recall - 0.9608, AUC - 0.9222, F1 - 0.7778, precision - 0.6533
2023-03-27 13:26:58,758 : [INFO]  Batch 68 initialized 
2023-03-27 13:26:59,168 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:26:59,528 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-27 13:27:02,967 : [INFO]  ------------------------- Batch round 1, loss: 0.538 -------------------------
2023-03-27 13:27:02,967 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:02,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:02,972 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-27 13:27:04,677 : [INFO]  ------------------------- Batch round 2, loss: 0.5339 -------------------------
2023-03-27 13:27:04,677 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:04,680 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:04,683 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-27 13:27:06,427 : [INFO]  ------------------------- Batch round 3, loss: 0.5293 -------------------------
2023-03-27 13:27:06,427 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:06,430 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:06,432 : [INFO]  Batch number 68 model fetched from the server
2023-03-27 13:27:06,432 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-27 13:27:07,584 : [INFO]  Batch 68: Training set : loss - 0.5292, accuracy - 0.7935, recall - 0.9783, AUC - 0.9296, F1 - 0.8257, precision - 0.7143, training time - -7.0 seconds
2023-03-27 13:27:07,585 : [INFO]  Batch 68: Testing set : loss - 0.548, accuracy - 0.7598, recall - 0.9314, AUC - 0.8812, F1 - 0.795, precision - 0.6934
2023-03-27 13:27:07,593 : [INFO]  Batch 69 initialized 
2023-03-27 13:27:07,996 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:08,352 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-27 13:27:11,681 : [INFO]  ------------------------- Batch round 1, loss: 0.5507 -------------------------
2023-03-27 13:27:11,681 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:11,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:11,785 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-27 13:27:13,377 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-27 13:27:13,377 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:13,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:13,405 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-27 13:27:15,023 : [INFO]  ------------------------- Batch round 3, loss: 0.5468 -------------------------
2023-03-27 13:27:15,024 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:15,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:15,076 : [INFO]  Batch number 69 model fetched from the server
2023-03-27 13:27:15,076 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-27 13:27:16,237 : [INFO]  Batch 69: Training set : loss - 0.5515, accuracy - 0.7446, recall - 0.9565, AUC - 0.9172, F1 - 0.7892, precision - 0.6718, training time - -7.0 seconds
2023-03-27 13:27:16,237 : [INFO]  Batch 69: Testing set : loss - 0.5743, accuracy - 0.7108, recall - 0.9314, AUC - 0.8833, F1 - 0.7631, precision - 0.6463
2023-03-27 13:27:16,243 : [INFO]  Batch 70 initialized 
2023-03-27 13:27:16,647 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:17,012 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-27 13:27:20,395 : [INFO]  ------------------------- Batch round 1, loss: 0.5474 -------------------------
2023-03-27 13:27:20,395 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:20,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:20,400 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-27 13:27:22,071 : [INFO]  ------------------------- Batch round 2, loss: 0.5374 -------------------------
2023-03-27 13:27:22,071 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:22,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:22,079 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-27 13:27:23,746 : [INFO]  ------------------------- Batch round 3, loss: 0.5352 -------------------------
2023-03-27 13:27:23,746 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:23,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:23,751 : [INFO]  Batch number 70 model fetched from the server
2023-03-27 13:27:23,751 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-27 13:27:24,909 : [INFO]  Batch 70: Training set : loss - 0.5385, accuracy - 0.7663, recall - 0.9457, AUC - 0.9128, F1 - 0.8018, precision - 0.696, training time - -7.0 seconds
2023-03-27 13:27:24,909 : [INFO]  Batch 70: Testing set : loss - 0.5394, accuracy - 0.7451, recall - 0.9608, AUC - 0.9243, F1 - 0.7903, precision - 0.6712
2023-03-27 13:27:24,917 : [INFO]  Batch 71 initialized 
2023-03-27 13:27:25,324 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:25,689 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-27 13:27:29,118 : [INFO]  ------------------------- Batch round 1, loss: 0.5465 -------------------------
2023-03-27 13:27:29,119 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:29,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:29,124 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-27 13:27:30,785 : [INFO]  ------------------------- Batch round 2, loss: 0.5373 -------------------------
2023-03-27 13:27:30,786 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:30,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:30,792 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-27 13:27:32,460 : [INFO]  ------------------------- Batch round 3, loss: 0.5365 -------------------------
2023-03-27 13:27:32,460 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:32,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:32,465 : [INFO]  Batch number 71 model fetched from the server
2023-03-27 13:27:32,465 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-27 13:27:33,622 : [INFO]  Batch 71: Training set : loss - 0.5392, accuracy - 0.7717, recall - 0.9239, AUC - 0.8983, F1 - 0.8019, precision - 0.7083, training time - -7.0 seconds
2023-03-27 13:27:33,622 : [INFO]  Batch 71: Testing set : loss - 0.5488, accuracy - 0.7108, recall - 0.9118, AUC - 0.8889, F1 - 0.7592, precision - 0.6503
2023-03-27 13:27:33,628 : [INFO]  Batch 72 initialized 
2023-03-27 13:27:34,038 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:34,408 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-27 13:27:37,830 : [INFO]  ------------------------- Batch round 1, loss: 0.5604 -------------------------
2023-03-27 13:27:37,830 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:37,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:37,835 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-27 13:27:39,545 : [INFO]  ------------------------- Batch round 2, loss: 0.5513 -------------------------
2023-03-27 13:27:39,546 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:39,549 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:39,552 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-27 13:27:41,227 : [INFO]  ------------------------- Batch round 3, loss: 0.5432 -------------------------
2023-03-27 13:27:41,227 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:41,236 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:41,238 : [INFO]  Batch number 72 model fetched from the server
2023-03-27 13:27:41,238 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-27 13:27:42,394 : [INFO]  Batch 72: Training set : loss - 0.5445, accuracy - 0.7772, recall - 0.9565, AUC - 0.9027, F1 - 0.8111, precision - 0.704, training time - -7.0 seconds
2023-03-27 13:27:42,395 : [INFO]  Batch 72: Testing set : loss - 0.5828, accuracy - 0.6618, recall - 0.8922, AUC - 0.8657, F1 - 0.7251, precision - 0.6107
2023-03-27 13:27:42,400 : [INFO]  Batch 73 initialized 
2023-03-27 13:27:42,804 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:43,177 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-27 13:27:46,604 : [INFO]  ------------------------- Batch round 1, loss: 0.5672 -------------------------
2023-03-27 13:27:46,604 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:46,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:46,609 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-27 13:27:48,346 : [INFO]  ------------------------- Batch round 2, loss: 0.5626 -------------------------
2023-03-27 13:27:48,346 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:48,349 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:48,351 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-27 13:27:50,057 : [INFO]  ------------------------- Batch round 3, loss: 0.5606 -------------------------
2023-03-27 13:27:50,058 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:50,061 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:50,062 : [INFO]  Batch number 73 model fetched from the server
2023-03-27 13:27:50,063 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-27 13:27:51,222 : [INFO]  Batch 73: Training set : loss - 0.5608, accuracy - 0.7609, recall - 0.913, AUC - 0.8852, F1 - 0.7925, precision - 0.7, training time - -7.0 seconds
2023-03-27 13:27:51,222 : [INFO]  Batch 73: Testing set : loss - 0.5418, accuracy - 0.7549, recall - 0.902, AUC - 0.9097, F1 - 0.7863, precision - 0.697
2023-03-27 13:27:51,232 : [INFO]  Batch 74 initialized 
2023-03-27 13:27:51,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:27:51,998 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-27 13:27:55,373 : [INFO]  ------------------------- Batch round 1, loss: 0.5301 -------------------------
2023-03-27 13:27:55,374 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-27 13:27:55,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:55,396 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-27 13:27:57,065 : [INFO]  ------------------------- Batch round 2, loss: 0.5251 -------------------------
2023-03-27 13:27:57,065 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-27 13:27:57,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:57,070 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-27 13:27:58,736 : [INFO]  ------------------------- Batch round 3, loss: 0.5237 -------------------------
2023-03-27 13:27:58,736 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-27 13:27:58,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:27:58,742 : [INFO]  Batch number 74 model fetched from the server
2023-03-27 13:27:58,742 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-27 13:27:59,920 : [INFO]  Batch 74: Training set : loss - 0.5221, accuracy - 0.7935, recall - 0.9783, AUC - 0.9282, F1 - 0.8257, precision - 0.7143, training time - -7.0 seconds
2023-03-27 13:27:59,920 : [INFO]  Batch 74: Testing set : loss - 0.5727, accuracy - 0.7108, recall - 0.902, AUC - 0.8742, F1 - 0.7572, precision - 0.6525
2023-03-27 13:27:59,925 : [INFO]  Batch 75 initialized 
2023-03-27 13:28:00,334 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:00,713 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-27 13:28:04,097 : [INFO]  ------------------------- Batch round 1, loss: 0.5277 -------------------------
2023-03-27 13:28:04,097 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:04,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:04,102 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-27 13:28:05,770 : [INFO]  ------------------------- Batch round 2, loss: 0.519 -------------------------
2023-03-27 13:28:05,770 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:05,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:05,775 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-27 13:28:07,471 : [INFO]  ------------------------- Batch round 3, loss: 0.5135 -------------------------
2023-03-27 13:28:07,471 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:07,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:07,476 : [INFO]  Batch number 75 model fetched from the server
2023-03-27 13:28:07,476 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-27 13:28:08,616 : [INFO]  Batch 75: Training set : loss - 0.5082, accuracy - 0.8315, recall - 0.9783, AUC - 0.9506, F1 - 0.8531, precision - 0.7563, training time - -7.0 seconds
2023-03-27 13:28:08,618 : [INFO]  Batch 75: Testing set : loss - 0.5619, accuracy - 0.7255, recall - 0.951, AUC - 0.9212, F1 - 0.776, precision - 0.6554
2023-03-27 13:28:08,622 : [INFO]  Batch 76 initialized 
2023-03-27 13:28:09,022 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:09,389 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-27 13:28:12,830 : [INFO]  ------------------------- Batch round 1, loss: 0.5346 -------------------------
2023-03-27 13:28:12,830 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:12,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:12,835 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-27 13:28:14,554 : [INFO]  ------------------------- Batch round 2, loss: 0.5242 -------------------------
2023-03-27 13:28:14,554 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:14,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:14,559 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-27 13:28:16,264 : [INFO]  ------------------------- Batch round 3, loss: 0.5187 -------------------------
2023-03-27 13:28:16,264 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:16,290 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:16,292 : [INFO]  Batch number 76 model fetched from the server
2023-03-27 13:28:16,292 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-27 13:28:17,453 : [INFO]  Batch 76: Training set : loss - 0.5169, accuracy - 0.788, recall - 0.9783, AUC - 0.9418, F1 - 0.8219, precision - 0.7087, training time - -7.0 seconds
2023-03-27 13:28:17,453 : [INFO]  Batch 76: Testing set : loss - 0.5424, accuracy - 0.7304, recall - 0.9804, AUC - 0.9592, F1 - 0.7843, precision - 0.6536
2023-03-27 13:28:17,461 : [INFO]  Batch 77 initialized 
2023-03-27 13:28:17,871 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:18,248 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-27 13:28:21,670 : [INFO]  ------------------------- Batch round 1, loss: 0.5143 -------------------------
2023-03-27 13:28:21,670 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:21,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:21,675 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-27 13:28:23,349 : [INFO]  ------------------------- Batch round 2, loss: 0.5085 -------------------------
2023-03-27 13:28:23,350 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:23,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:23,355 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-27 13:28:25,014 : [INFO]  ------------------------- Batch round 3, loss: 0.5052 -------------------------
2023-03-27 13:28:25,014 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:25,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:25,019 : [INFO]  Batch number 77 model fetched from the server
2023-03-27 13:28:25,019 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-27 13:28:26,176 : [INFO]  Batch 77: Training set : loss - 0.5078, accuracy - 0.8315, recall - 0.9783, AUC - 0.9518, F1 - 0.8531, precision - 0.7563, training time - -7.0 seconds
2023-03-27 13:28:26,176 : [INFO]  Batch 77: Testing set : loss - 0.549, accuracy - 0.7549, recall - 0.9412, AUC - 0.9063, F1 - 0.7934, precision - 0.6857
2023-03-27 13:28:26,183 : [INFO]  Batch 78 initialized 
2023-03-27 13:28:26,603 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:26,981 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-27 13:28:30,391 : [INFO]  ------------------------- Batch round 1, loss: 0.5656 -------------------------
2023-03-27 13:28:30,391 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:30,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:30,414 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-27 13:28:32,077 : [INFO]  ------------------------- Batch round 2, loss: 0.5585 -------------------------
2023-03-27 13:28:32,077 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:32,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:32,109 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-27 13:28:33,759 : [INFO]  ------------------------- Batch round 3, loss: 0.5501 -------------------------
2023-03-27 13:28:33,759 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:33,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:33,782 : [INFO]  Batch number 78 model fetched from the server
2023-03-27 13:28:33,782 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-27 13:28:34,961 : [INFO]  Batch 78: Training set : loss - 0.5505, accuracy - 0.7391, recall - 0.9783, AUC - 0.9084, F1 - 0.7895, precision - 0.6618, training time - -7.0 seconds
2023-03-27 13:28:34,961 : [INFO]  Batch 78: Testing set : loss - 0.5459, accuracy - 0.7696, recall - 0.9608, AUC - 0.9216, F1 - 0.8066, precision - 0.695
2023-03-27 13:28:34,970 : [INFO]  Batch 79 initialized 
2023-03-27 13:28:35,407 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:35,792 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-27 13:28:39,203 : [INFO]  ------------------------- Batch round 1, loss: 0.5458 -------------------------
2023-03-27 13:28:39,204 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:39,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:39,209 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-27 13:28:40,940 : [INFO]  ------------------------- Batch round 2, loss: 0.5422 -------------------------
2023-03-27 13:28:40,940 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:40,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:40,946 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-27 13:28:42,639 : [INFO]  ------------------------- Batch round 3, loss: 0.5356 -------------------------
2023-03-27 13:28:42,640 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:42,681 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:42,683 : [INFO]  Batch number 79 model fetched from the server
2023-03-27 13:28:42,683 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-27 13:28:43,831 : [INFO]  Batch 79: Training set : loss - 0.5395, accuracy - 0.7609, recall - 0.9674, AUC - 0.909, F1 - 0.8018, precision - 0.6846, training time - -7.0 seconds
2023-03-27 13:28:43,831 : [INFO]  Batch 79: Testing set : loss - 0.5673, accuracy - 0.7255, recall - 0.902, AUC - 0.8616, F1 - 0.7667, precision - 0.6667
2023-03-27 13:28:43,835 : [INFO]  Batch 80 initialized 
2023-03-27 13:28:44,238 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:44,621 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-27 13:28:48,090 : [INFO]  ------------------------- Batch round 1, loss: 0.5685 -------------------------
2023-03-27 13:28:48,090 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:48,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:48,096 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-27 13:28:49,801 : [INFO]  ------------------------- Batch round 2, loss: 0.5576 -------------------------
2023-03-27 13:28:49,801 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:49,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:49,807 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-27 13:28:51,514 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-27 13:28:51,514 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-27 13:28:51,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:51,520 : [INFO]  Batch number 80 model fetched from the server
2023-03-27 13:28:51,520 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-27 13:28:52,700 : [INFO]  Batch 80: Training set : loss - 0.5547, accuracy - 0.7228, recall - 0.9674, AUC - 0.9109, F1 - 0.7773, precision - 0.6496, training time - -7.0 seconds
2023-03-27 13:28:52,700 : [INFO]  Batch 80: Testing set : loss - 0.5829, accuracy - 0.7157, recall - 0.9412, AUC - 0.8633, F1 - 0.768, precision - 0.6486
2023-03-27 13:28:52,704 : [INFO]  Batch 81 initialized 
2023-03-27 13:28:53,107 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:28:53,492 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-27 13:28:56,893 : [INFO]  ------------------------- Batch round 1, loss: 0.549 -------------------------
2023-03-27 13:28:56,894 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-27 13:28:56,935 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:56,937 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-27 13:28:58,586 : [INFO]  ------------------------- Batch round 2, loss: 0.543 -------------------------
2023-03-27 13:28:58,586 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-27 13:28:58,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:28:58,603 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-27 13:29:00,319 : [INFO]  ------------------------- Batch round 3, loss: 0.5423 -------------------------
2023-03-27 13:29:00,320 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:00,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:00,325 : [INFO]  Batch number 81 model fetched from the server
2023-03-27 13:29:00,325 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-27 13:29:01,484 : [INFO]  Batch 81: Training set : loss - 0.5391, accuracy - 0.7717, recall - 0.9565, AUC - 0.9176, F1 - 0.8073, precision - 0.6984, training time - -7.0 seconds
2023-03-27 13:29:01,484 : [INFO]  Batch 81: Testing set : loss - 0.5493, accuracy - 0.7549, recall - 0.9706, AUC - 0.9172, F1 - 0.7984, precision - 0.6781
2023-03-27 13:29:01,489 : [INFO]  Batch 82 initialized 
2023-03-27 13:29:01,909 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:02,299 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-27 13:29:05,741 : [INFO]  ------------------------- Batch round 1, loss: 0.544 -------------------------
2023-03-27 13:29:05,741 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:05,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:05,746 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-27 13:29:07,452 : [INFO]  ------------------------- Batch round 2, loss: 0.5408 -------------------------
2023-03-27 13:29:07,452 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:07,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:07,458 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-27 13:29:09,168 : [INFO]  ------------------------- Batch round 3, loss: 0.5361 -------------------------
2023-03-27 13:29:09,169 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:09,173 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:09,176 : [INFO]  Batch number 82 model fetched from the server
2023-03-27 13:29:09,176 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-27 13:29:10,333 : [INFO]  Batch 82: Training set : loss - 0.5368, accuracy - 0.7772, recall - 0.913, AUC - 0.9016, F1 - 0.8038, precision - 0.7179, training time - -7.0 seconds
2023-03-27 13:29:10,334 : [INFO]  Batch 82: Testing set : loss - 0.5318, accuracy - 0.7696, recall - 0.9706, AUC - 0.9202, F1 - 0.8082, precision - 0.6923
2023-03-27 13:29:10,338 : [INFO]  Batch 83 initialized 
2023-03-27 13:29:10,746 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:11,142 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-27 13:29:14,520 : [INFO]  ------------------------- Batch round 1, loss: 0.5536 -------------------------
2023-03-27 13:29:14,520 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:14,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:14,529 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-27 13:29:16,174 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-27 13:29:16,174 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:16,178 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:16,179 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-27 13:29:17,872 : [INFO]  ------------------------- Batch round 3, loss: 0.5418 -------------------------
2023-03-27 13:29:17,872 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:17,875 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:17,877 : [INFO]  Batch number 83 model fetched from the server
2023-03-27 13:29:17,877 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-27 13:29:19,010 : [INFO]  Batch 83: Training set : loss - 0.5465, accuracy - 0.7446, recall - 0.9457, AUC - 0.909, F1 - 0.7873, precision - 0.6744, training time - -7.0 seconds
2023-03-27 13:29:19,010 : [INFO]  Batch 83: Testing set : loss - 0.54, accuracy - 0.7647, recall - 0.9314, AUC - 0.8991, F1 - 0.7983, precision - 0.6985
2023-03-27 13:29:19,019 : [INFO]  Batch 84 initialized 
2023-03-27 13:29:19,424 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:19,813 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-27 13:29:23,290 : [INFO]  ------------------------- Batch round 1, loss: 0.5591 -------------------------
2023-03-27 13:29:23,290 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:23,294 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:23,295 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-27 13:29:24,966 : [INFO]  ------------------------- Batch round 2, loss: 0.5569 -------------------------
2023-03-27 13:29:24,966 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:24,969 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:24,971 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-27 13:29:26,632 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-27 13:29:26,632 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:26,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:26,670 : [INFO]  Batch number 84 model fetched from the server
2023-03-27 13:29:26,670 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-27 13:29:27,814 : [INFO]  Batch 84: Training set : loss - 0.5553, accuracy - 0.7391, recall - 0.9457, AUC - 0.9126, F1 - 0.7838, precision - 0.6692, training time - -7.0 seconds
2023-03-27 13:29:27,814 : [INFO]  Batch 84: Testing set : loss - 0.585, accuracy - 0.6667, recall - 0.902, AUC - 0.9001, F1 - 0.7302, precision - 0.6133
2023-03-27 13:29:27,823 : [INFO]  Batch 85 initialized 
2023-03-27 13:29:28,236 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:28,634 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-27 13:29:31,979 : [INFO]  ------------------------- Batch round 1, loss: 0.5613 -------------------------
2023-03-27 13:29:31,980 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:32,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:32,028 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-27 13:29:33,684 : [INFO]  ------------------------- Batch round 2, loss: 0.5535 -------------------------
2023-03-27 13:29:33,684 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:33,713 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:33,715 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-27 13:29:35,400 : [INFO]  ------------------------- Batch round 3, loss: 0.5488 -------------------------
2023-03-27 13:29:35,400 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:35,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:35,405 : [INFO]  Batch number 85 model fetched from the server
2023-03-27 13:29:35,405 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-27 13:29:36,575 : [INFO]  Batch 85: Training set : loss - 0.5544, accuracy - 0.7337, recall - 0.9239, AUC - 0.8958, F1 - 0.7763, precision - 0.6693, training time - -7.0 seconds
2023-03-27 13:29:36,575 : [INFO]  Batch 85: Testing set : loss - 0.5447, accuracy - 0.75, recall - 0.951, AUC - 0.911, F1 - 0.7918, precision - 0.6783
2023-03-27 13:29:36,585 : [INFO]  Batch 86 initialized 
2023-03-27 13:29:36,991 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:37,375 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-27 13:29:40,786 : [INFO]  ------------------------- Batch round 1, loss: 0.5612 -------------------------
2023-03-27 13:29:40,786 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:40,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:40,791 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-27 13:29:42,433 : [INFO]  ------------------------- Batch round 2, loss: 0.5541 -------------------------
2023-03-27 13:29:42,433 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:42,436 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:42,439 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-27 13:29:44,123 : [INFO]  ------------------------- Batch round 3, loss: 0.5507 -------------------------
2023-03-27 13:29:44,124 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:44,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:44,129 : [INFO]  Batch number 86 model fetched from the server
2023-03-27 13:29:44,129 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-27 13:29:45,290 : [INFO]  Batch 86: Training set : loss - 0.5559, accuracy - 0.7337, recall - 0.9457, AUC - 0.9022, F1 - 0.7803, precision - 0.6641, training time - -7.0 seconds
2023-03-27 13:29:45,290 : [INFO]  Batch 86: Testing set : loss - 0.5568, accuracy - 0.7451, recall - 0.9412, AUC - 0.901, F1 - 0.7869, precision - 0.6761
2023-03-27 13:29:45,294 : [INFO]  Batch 87 initialized 
2023-03-27 13:29:45,704 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:46,094 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-27 13:29:49,601 : [INFO]  ------------------------- Batch round 1, loss: 0.5616 -------------------------
2023-03-27 13:29:49,602 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:49,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:49,610 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-27 13:29:51,306 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-27 13:29:51,306 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-27 13:29:51,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:51,321 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-27 13:29:53,024 : [INFO]  ------------------------- Batch round 3, loss: 0.5506 -------------------------
2023-03-27 13:29:53,024 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-27 13:29:53,028 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:53,029 : [INFO]  Batch number 87 model fetched from the server
2023-03-27 13:29:53,030 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-27 13:29:54,194 : [INFO]  Batch 87: Training set : loss - 0.5469, accuracy - 0.7717, recall - 0.9674, AUC - 0.9145, F1 - 0.8091, precision - 0.6953, training time - -7.0 seconds
2023-03-27 13:29:54,194 : [INFO]  Batch 87: Testing set : loss - 0.5531, accuracy - 0.7696, recall - 0.9706, AUC - 0.9131, F1 - 0.8082, precision - 0.6923
2023-03-27 13:29:54,204 : [INFO]  Batch 88 initialized 
2023-03-27 13:29:54,613 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:29:55,003 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-27 13:29:58,409 : [INFO]  ------------------------- Batch round 1, loss: 0.5469 -------------------------
2023-03-27 13:29:58,409 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-27 13:29:58,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:29:58,414 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-27 13:30:00,082 : [INFO]  ------------------------- Batch round 2, loss: 0.5395 -------------------------
2023-03-27 13:30:00,082 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:00,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:00,087 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-27 13:30:01,750 : [INFO]  ------------------------- Batch round 3, loss: 0.5341 -------------------------
2023-03-27 13:30:01,750 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:01,753 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:01,755 : [INFO]  Batch number 88 model fetched from the server
2023-03-27 13:30:01,755 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-27 13:30:02,896 : [INFO]  Batch 88: Training set : loss - 0.5357, accuracy - 0.7772, recall - 0.9457, AUC - 0.9117, F1 - 0.8093, precision - 0.7073, training time - -7.0 seconds
2023-03-27 13:30:02,896 : [INFO]  Batch 88: Testing set : loss - 0.5535, accuracy - 0.75, recall - 0.9412, AUC - 0.9041, F1 - 0.7901, precision - 0.6809
2023-03-27 13:30:02,907 : [INFO]  Batch 89 initialized 
2023-03-27 13:30:03,317 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:03,716 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-27 13:30:07,092 : [INFO]  ------------------------- Batch round 1, loss: 0.5392 -------------------------
2023-03-27 13:30:07,092 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:07,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:07,097 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-27 13:30:08,749 : [INFO]  ------------------------- Batch round 2, loss: 0.5308 -------------------------
2023-03-27 13:30:08,750 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:08,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:08,784 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-27 13:30:10,412 : [INFO]  ------------------------- Batch round 3, loss: 0.5298 -------------------------
2023-03-27 13:30:10,412 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:10,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:10,417 : [INFO]  Batch number 89 model fetched from the server
2023-03-27 13:30:10,417 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-27 13:30:11,571 : [INFO]  Batch 89: Training set : loss - 0.5282, accuracy - 0.7826, recall - 0.9457, AUC - 0.8995, F1 - 0.8131, precision - 0.7131, training time - -7.0 seconds
2023-03-27 13:30:11,571 : [INFO]  Batch 89: Testing set : loss - 0.5206, accuracy - 0.8235, recall - 0.9608, AUC - 0.9522, F1 - 0.8448, precision - 0.7538
2023-03-27 13:30:11,576 : [INFO]  Batch 90 initialized 
2023-03-27 13:30:11,983 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:12,379 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-27 13:30:15,800 : [INFO]  ------------------------- Batch round 1, loss: 0.5672 -------------------------
2023-03-27 13:30:15,801 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:15,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:15,806 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-27 13:30:17,468 : [INFO]  ------------------------- Batch round 2, loss: 0.5591 -------------------------
2023-03-27 13:30:17,469 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:17,472 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:17,473 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-27 13:30:19,115 : [INFO]  ------------------------- Batch round 3, loss: 0.5528 -------------------------
2023-03-27 13:30:19,115 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:19,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:19,120 : [INFO]  Batch number 90 model fetched from the server
2023-03-27 13:30:19,120 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-27 13:30:20,270 : [INFO]  Batch 90: Training set : loss - 0.5512, accuracy - 0.75, recall - 0.9239, AUC - 0.8969, F1 - 0.787, precision - 0.6855, training time - -7.0 seconds
2023-03-27 13:30:20,270 : [INFO]  Batch 90: Testing set : loss - 0.5636, accuracy - 0.7353, recall - 0.9412, AUC - 0.894, F1 - 0.7805, precision - 0.6667
2023-03-27 13:30:20,278 : [INFO]  Batch 91 initialized 
2023-03-27 13:30:20,685 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:21,088 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-27 13:30:24,456 : [INFO]  ------------------------- Batch round 1, loss: 0.5574 -------------------------
2023-03-27 13:30:24,457 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:24,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:24,462 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-27 13:30:26,114 : [INFO]  ------------------------- Batch round 2, loss: 0.5512 -------------------------
2023-03-27 13:30:26,114 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:26,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:26,119 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-27 13:30:27,840 : [INFO]  ------------------------- Batch round 3, loss: 0.5444 -------------------------
2023-03-27 13:30:27,841 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:27,844 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:27,845 : [INFO]  Batch number 91 model fetched from the server
2023-03-27 13:30:27,845 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-27 13:30:29,047 : [INFO]  Batch 91: Training set : loss - 0.5487, accuracy - 0.7663, recall - 0.9565, AUC - 0.9341, F1 - 0.8037, precision - 0.6929, training time - -7.0 seconds
2023-03-27 13:30:29,048 : [INFO]  Batch 91: Testing set : loss - 0.5604, accuracy - 0.7255, recall - 0.951, AUC - 0.8921, F1 - 0.776, precision - 0.6554
2023-03-27 13:30:29,054 : [INFO]  Batch 92 initialized 
2023-03-27 13:30:29,453 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:29,864 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-27 13:30:33,283 : [INFO]  ------------------------- Batch round 1, loss: 0.5664 -------------------------
2023-03-27 13:30:33,283 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:33,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:33,288 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-27 13:30:34,961 : [INFO]  ------------------------- Batch round 2, loss: 0.555 -------------------------
2023-03-27 13:30:34,961 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:34,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:34,966 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-27 13:30:36,641 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-27 13:30:36,641 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:36,644 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:36,646 : [INFO]  Batch number 92 model fetched from the server
2023-03-27 13:30:36,646 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-27 13:30:37,788 : [INFO]  Batch 92: Training set : loss - 0.5532, accuracy - 0.7663, recall - 0.9348, AUC - 0.8869, F1 - 0.8, precision - 0.6992, training time - -7.0 seconds
2023-03-27 13:30:37,788 : [INFO]  Batch 92: Testing set : loss - 0.5469, accuracy - 0.7451, recall - 0.9706, AUC - 0.9161, F1 - 0.792, precision - 0.6689
2023-03-27 13:30:37,793 : [INFO]  Batch 93 initialized 
2023-03-27 13:30:38,203 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 13:30:38,607 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-27 13:30:42,065 : [INFO]  ------------------------- Batch round 1, loss: 0.5486 -------------------------
2023-03-27 13:30:42,065 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-27 13:30:42,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:42,071 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-27 13:30:43,765 : [INFO]  ------------------------- Batch round 2, loss: 0.5435 -------------------------
2023-03-27 13:30:43,765 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-27 13:30:43,768 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:43,770 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-27 13:30:45,623 : [INFO]  ------------------------- Batch round 3, loss: 0.5427 -------------------------
2023-03-27 13:30:45,623 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-27 13:30:45,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 13:30:45,629 : [INFO]  Batch number 93 model fetched from the server
2023-03-27 13:30:45,629 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-27 13:30:47,066 : [INFO]  Batch 93: Training set : loss - 0.547, accuracy - 0.7446, recall - 0.8696, AUC - 0.8937, F1 - 0.7729, precision - 0.6957, training time - -7.0 seconds
2023-03-27 13:30:47,066 : [INFO]  Batch 93: Testing set : loss - 0.586, accuracy - 0.6961, recall - 0.902, AUC - 0.8704, F1 - 0.748, precision - 0.6389
2023-03-27 13:30:47,067 : [INFO]  Result report : Accuracy - 0.746 (0.0302), Recall - 0.9393 (0.0264), AUC - 0.8907 (0.0314), F1 - 0.7874 (0.023), Precision - 0.6782 (0.0271)
2023-03-27 13:30:47,067 : [INFO]  Result report : Accuracy - 0.746 (0.0302), Recall - 0.9393 (0.0264), AUC - 0.8907 (0.0314), F1 - 0.7874 (0.023), Precision - 0.6782 (0.0271), Mean time for a batch - 6.86 (0.13) seconds
2023-03-27 13:30:47,068 : [INFO]  Distributed training done!
2023-03-27 13:30:47,068 : [INFO]  Training report : Total elapsed time 908.0500550609995 seconds, graph name wikipedia, graph ID 1, partition ID 1, training epochs 6, epochs 6
