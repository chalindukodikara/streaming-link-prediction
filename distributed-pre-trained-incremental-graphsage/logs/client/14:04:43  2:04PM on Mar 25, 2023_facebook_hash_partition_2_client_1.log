2023-03-25 14:04:43,904 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 14:04:43,904 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 1, epochs 8
2023-03-25 14:04:48,009 : [INFO]  Model initialized for training
2023-03-25 14:05:03,065 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:05:03,203 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 14:05:08,214 : [INFO]  Connected to the server
2023-03-25 14:05:08,398 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 14:05:08,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:05:08,409 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 14:05:08,409 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 14:05:33,730 : [INFO]  ------------------------- Training round 1, loss: 0.6788 -------------------------
2023-03-25 14:05:33,730 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 14:05:36,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:05:36,202 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 14:06:00,030 : [INFO]  ------------------------- Training round 2, loss: 0.6383 -------------------------
2023-03-25 14:06:00,030 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 14:06:01,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:06:01,299 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 14:06:26,046 : [INFO]  ------------------------- Training round 3, loss: 0.615 -------------------------
2023-03-25 14:06:26,047 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 14:06:27,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:06:27,973 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 14:07:01,236 : [INFO]  ------------------------- Training round 4, loss: 0.6044 -------------------------
2023-03-25 14:07:01,236 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 14:07:02,878 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:07:02,883 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 14:07:34,020 : [INFO]  ------------------------- Training round 5, loss: 0.6014 -------------------------
2023-03-25 14:07:34,020 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 14:07:35,671 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:07:35,674 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 14:08:30,610 : [INFO]  Initially trained model: Training set : loss - 0.6, accuracy - 0.69, recall - 0.87, AUC - 0.82, F1 - 0.74, precision - 0.64, training time - -147.0 seconds
2023-03-25 14:08:30,610 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 14:08:30,622 : [INFO]  Batch 1 initialized 
2023-03-25 14:08:31,155 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:08:31,288 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 14:08:31,288 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 14:08:36,936 : [INFO]  ------------------------- Batch round 1, loss: 0.5872 -------------------------
2023-03-25 14:08:36,936 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 14:08:40,032 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:40,035 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 14:08:43,151 : [INFO]  ------------------------- Batch round 2, loss: 0.5721 -------------------------
2023-03-25 14:08:43,152 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 14:08:43,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:43,543 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 14:08:46,731 : [INFO]  ------------------------- Batch round 3, loss: 0.5616 -------------------------
2023-03-25 14:08:46,731 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 14:08:47,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:47,051 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 14:08:47,051 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 14:08:48,521 : [INFO]  Batch 1: Training set : loss - 0.5591, accuracy - 0.7717, recall - 0.9022, AUC - 0.8657, F1 - 0.7981, precision - 0.7155, training time - -16.0 seconds
2023-03-25 14:08:48,521 : [INFO]  Batch 1: Testing set : loss - 0.5547, accuracy - 0.7549, recall - 0.9118, AUC - 0.8948, F1 - 0.7881, precision - 0.694
2023-03-25 14:08:48,534 : [INFO]  Batch 2 initialized 
2023-03-25 14:08:49,116 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:08:49,284 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 14:08:55,074 : [INFO]  ------------------------- Batch round 1, loss: 0.5512 -------------------------
2023-03-25 14:08:55,074 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 14:08:55,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:55,409 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 14:08:59,046 : [INFO]  ------------------------- Batch round 2, loss: 0.5491 -------------------------
2023-03-25 14:08:59,051 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 14:08:59,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:59,200 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 14:09:02,445 : [INFO]  ------------------------- Batch round 3, loss: 0.5398 -------------------------
2023-03-25 14:09:02,445 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:02,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:02,450 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 14:09:02,450 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 14:09:03,903 : [INFO]  Batch 2: Training set : loss - 0.534, accuracy - 0.8098, recall - 0.9565, AUC - 0.9064, F1 - 0.8341, precision - 0.7395, training time - -13.0 seconds
2023-03-25 14:09:03,903 : [INFO]  Batch 2: Testing set : loss - 0.5386, accuracy - 0.7598, recall - 0.9314, AUC - 0.9112, F1 - 0.795, precision - 0.6934
2023-03-25 14:09:03,916 : [INFO]  Batch 3 initialized 
2023-03-25 14:09:04,423 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:04,710 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 14:09:10,113 : [INFO]  ------------------------- Batch round 1, loss: 0.5423 -------------------------
2023-03-25 14:09:10,113 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:10,443 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:10,446 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 14:09:13,673 : [INFO]  ------------------------- Batch round 2, loss: 0.5365 -------------------------
2023-03-25 14:09:13,674 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:13,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:13,766 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 14:09:16,904 : [INFO]  ------------------------- Batch round 3, loss: 0.5315 -------------------------
2023-03-25 14:09:16,904 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:17,193 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:17,196 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 14:09:17,196 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 14:09:18,708 : [INFO]  Batch 3: Training set : loss - 0.5294, accuracy - 0.788, recall - 0.9457, AUC - 0.9201, F1 - 0.8169, precision - 0.719, training time - -12.0 seconds
2023-03-25 14:09:18,708 : [INFO]  Batch 3: Testing set : loss - 0.5574, accuracy - 0.7402, recall - 0.9314, AUC - 0.9158, F1 - 0.7819, precision - 0.6738
2023-03-25 14:09:18,722 : [INFO]  Batch 4 initialized 
2023-03-25 14:09:19,238 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:19,504 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 14:09:24,469 : [INFO]  ------------------------- Batch round 1, loss: 0.5527 -------------------------
2023-03-25 14:09:24,469 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:24,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:24,718 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 14:09:27,873 : [INFO]  ------------------------- Batch round 2, loss: 0.5497 -------------------------
2023-03-25 14:09:27,873 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:28,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:28,088 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 14:09:31,070 : [INFO]  ------------------------- Batch round 3, loss: 0.5381 -------------------------
2023-03-25 14:09:31,070 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:31,270 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:31,272 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 14:09:31,272 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 14:09:32,699 : [INFO]  Batch 4: Training set : loss - 0.5367, accuracy - 0.7826, recall - 0.913, AUC - 0.9021, F1 - 0.8077, precision - 0.7241, training time - -12.0 seconds
2023-03-25 14:09:32,699 : [INFO]  Batch 4: Testing set : loss - 0.5502, accuracy - 0.7353, recall - 0.9412, AUC - 0.9284, F1 - 0.7805, precision - 0.6667
2023-03-25 14:09:32,712 : [INFO]  Batch 5 initialized 
2023-03-25 14:09:33,277 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:33,539 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 14:09:38,756 : [INFO]  ------------------------- Batch round 1, loss: 0.5406 -------------------------
2023-03-25 14:09:38,757 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:38,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:38,979 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 14:09:41,799 : [INFO]  ------------------------- Batch round 2, loss: 0.5349 -------------------------
2023-03-25 14:09:41,800 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:41,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:41,952 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 14:09:44,649 : [INFO]  ------------------------- Batch round 3, loss: 0.525 -------------------------
2023-03-25 14:09:44,649 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:44,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:44,878 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 14:09:44,878 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 14:09:46,155 : [INFO]  Batch 5: Training set : loss - 0.5303, accuracy - 0.837, recall - 0.9457, AUC - 0.9002, F1 - 0.8529, precision - 0.7768, training time - -11.0 seconds
2023-03-25 14:09:46,156 : [INFO]  Batch 5: Testing set : loss - 0.5272, accuracy - 0.7745, recall - 0.9314, AUC - 0.9099, F1 - 0.8051, precision - 0.709
2023-03-25 14:09:46,169 : [INFO]  Batch 6 initialized 
2023-03-25 14:09:46,613 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:46,825 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 14:09:52,140 : [INFO]  ------------------------- Batch round 1, loss: 0.5419 -------------------------
2023-03-25 14:09:52,140 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:52,438 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:52,441 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 14:09:57,504 : [INFO]  ------------------------- Batch round 2, loss: 0.5266 -------------------------
2023-03-25 14:09:57,505 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:57,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:57,515 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 14:10:02,704 : [INFO]  ------------------------- Batch round 3, loss: 0.5251 -------------------------
2023-03-25 14:10:02,705 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:02,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:02,713 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 14:10:02,713 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 14:10:05,528 : [INFO]  Batch 6: Training set : loss - 0.5161, accuracy - 0.8207, recall - 0.9565, AUC - 0.9144, F1 - 0.8421, precision - 0.7521, training time - -16.0 seconds
2023-03-25 14:10:05,528 : [INFO]  Batch 6: Testing set : loss - 0.5621, accuracy - 0.6961, recall - 0.902, AUC - 0.8865, F1 - 0.748, precision - 0.6389
2023-03-25 14:10:05,546 : [INFO]  Batch 7 initialized 
2023-03-25 14:10:06,369 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:06,808 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 14:10:14,060 : [INFO]  ------------------------- Batch round 1, loss: 0.5418 -------------------------
2023-03-25 14:10:14,060 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 14:10:14,062 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:14,063 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 14:10:16,966 : [INFO]  ------------------------- Batch round 2, loss: 0.5336 -------------------------
2023-03-25 14:10:16,966 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 14:10:17,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:17,154 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 14:10:20,103 : [INFO]  ------------------------- Batch round 3, loss: 0.5295 -------------------------
2023-03-25 14:10:20,103 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:20,277 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:20,279 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 14:10:20,279 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 14:10:22,049 : [INFO]  Batch 7: Training set : loss - 0.5243, accuracy - 0.8152, recall - 0.9348, AUC - 0.9018, F1 - 0.835, precision - 0.7544, training time - -13.0 seconds
2023-03-25 14:10:22,049 : [INFO]  Batch 7: Testing set : loss - 0.5812, accuracy - 0.7059, recall - 0.8922, AUC - 0.8433, F1 - 0.7521, precision - 0.65
2023-03-25 14:10:22,062 : [INFO]  Batch 8 initialized 
2023-03-25 14:10:22,693 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:22,944 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 14:10:29,788 : [INFO]  ------------------------- Batch round 1, loss: 0.5656 -------------------------
2023-03-25 14:10:29,788 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 14:10:30,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:30,257 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 14:10:34,289 : [INFO]  ------------------------- Batch round 2, loss: 0.5573 -------------------------
2023-03-25 14:10:34,289 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 14:10:34,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:34,370 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 14:10:37,876 : [INFO]  ------------------------- Batch round 3, loss: 0.5516 -------------------------
2023-03-25 14:10:37,876 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:38,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:38,019 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 14:10:38,019 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 14:10:39,602 : [INFO]  Batch 8: Training set : loss - 0.5506, accuracy - 0.7391, recall - 0.9565, AUC - 0.9019, F1 - 0.7857, precision - 0.6667, training time - -15.0 seconds
2023-03-25 14:10:39,603 : [INFO]  Batch 8: Testing set : loss - 0.5783, accuracy - 0.7108, recall - 0.9118, AUC - 0.8577, F1 - 0.7592, precision - 0.6503
2023-03-25 14:10:39,613 : [INFO]  Batch 9 initialized 
2023-03-25 14:10:40,131 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:40,388 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 14:10:45,799 : [INFO]  ------------------------- Batch round 1, loss: 0.5851 -------------------------
2023-03-25 14:10:45,799 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 14:10:45,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:45,893 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 14:10:49,244 : [INFO]  ------------------------- Batch round 2, loss: 0.5735 -------------------------
2023-03-25 14:10:49,244 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 14:10:49,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:49,250 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 14:10:52,734 : [INFO]  ------------------------- Batch round 3, loss: 0.5557 -------------------------
2023-03-25 14:10:52,735 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:52,737 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:52,739 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 14:10:52,739 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 14:10:54,245 : [INFO]  Batch 9: Training set : loss - 0.5653, accuracy - 0.7446, recall - 0.9022, AUC - 0.8674, F1 - 0.7793, precision - 0.686, training time - -12.0 seconds
2023-03-25 14:10:54,246 : [INFO]  Batch 9: Testing set : loss - 0.6117, accuracy - 0.6765, recall - 0.8333, AUC - 0.802, F1 - 0.7203, precision - 0.6343
2023-03-25 14:10:54,258 : [INFO]  Batch 10 initialized 
2023-03-25 14:10:54,733 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:55,004 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 14:11:00,476 : [INFO]  ------------------------- Batch round 1, loss: 0.5592 -------------------------
2023-03-25 14:11:00,477 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:00,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:00,659 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 14:11:03,885 : [INFO]  ------------------------- Batch round 2, loss: 0.5422 -------------------------
2023-03-25 14:11:03,885 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:03,899 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:03,902 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 14:11:07,098 : [INFO]  ------------------------- Batch round 3, loss: 0.5344 -------------------------
2023-03-25 14:11:07,098 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:07,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:07,398 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 14:11:07,398 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 14:11:08,859 : [INFO]  Batch 10: Training set : loss - 0.5282, accuracy - 0.7935, recall - 0.9348, AUC - 0.8762, F1 - 0.819, precision - 0.7288, training time - -12.0 seconds
2023-03-25 14:11:08,859 : [INFO]  Batch 10: Testing set : loss - 0.5694, accuracy - 0.7255, recall - 0.8922, AUC - 0.8649, F1 - 0.7647, precision - 0.6691
2023-03-25 14:11:08,873 : [INFO]  Batch 11 initialized 
2023-03-25 14:11:09,426 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:09,706 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 14:11:15,067 : [INFO]  ------------------------- Batch round 1, loss: 0.5754 -------------------------
2023-03-25 14:11:15,067 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:15,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:15,299 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 14:11:18,546 : [INFO]  ------------------------- Batch round 2, loss: 0.5603 -------------------------
2023-03-25 14:11:18,546 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:18,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:18,781 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 14:11:21,981 : [INFO]  ------------------------- Batch round 3, loss: 0.5649 -------------------------
2023-03-25 14:11:21,981 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:22,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:22,160 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 14:11:22,160 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 14:11:23,616 : [INFO]  Batch 11: Training set : loss - 0.5574, accuracy - 0.7446, recall - 0.913, AUC - 0.8718, F1 - 0.7814, precision - 0.6829, training time - -12.0 seconds
2023-03-25 14:11:23,616 : [INFO]  Batch 11: Testing set : loss - 0.5739, accuracy - 0.7304, recall - 0.9314, AUC - 0.8665, F1 - 0.7755, precision - 0.6643
2023-03-25 14:11:23,632 : [INFO]  Batch 12 initialized 
2023-03-25 14:11:24,156 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:24,432 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 14:11:29,511 : [INFO]  ------------------------- Batch round 1, loss: 0.5633 -------------------------
2023-03-25 14:11:29,511 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:29,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:29,880 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 14:11:32,919 : [INFO]  ------------------------- Batch round 2, loss: 0.5492 -------------------------
2023-03-25 14:11:32,919 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:33,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:33,261 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 14:11:36,270 : [INFO]  ------------------------- Batch round 3, loss: 0.5426 -------------------------
2023-03-25 14:11:36,271 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:36,540 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:36,543 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 14:11:36,543 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 14:11:38,027 : [INFO]  Batch 12: Training set : loss - 0.5502, accuracy - 0.7609, recall - 0.8804, AUC - 0.868, F1 - 0.7864, precision - 0.7105, training time - -12.0 seconds
2023-03-25 14:11:38,028 : [INFO]  Batch 12: Testing set : loss - 0.577, accuracy - 0.6961, recall - 0.8627, AUC - 0.8442, F1 - 0.7395, precision - 0.6471
2023-03-25 14:11:38,064 : [INFO]  Batch 13 initialized 
2023-03-25 14:11:38,548 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:38,820 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 14:11:44,166 : [INFO]  ------------------------- Batch round 1, loss: 0.544 -------------------------
2023-03-25 14:11:44,167 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:44,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:44,172 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 14:11:47,197 : [INFO]  ------------------------- Batch round 2, loss: 0.5326 -------------------------
2023-03-25 14:11:47,198 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:47,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:47,359 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 14:11:50,725 : [INFO]  ------------------------- Batch round 3, loss: 0.5282 -------------------------
2023-03-25 14:11:50,726 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:50,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:50,909 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 14:11:50,909 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 14:11:53,931 : [INFO]  Batch 13: Training set : loss - 0.5225, accuracy - 0.8207, recall - 0.9457, AUC - 0.921, F1 - 0.8406, precision - 0.7565, training time - -12.0 seconds
2023-03-25 14:11:53,931 : [INFO]  Batch 13: Testing set : loss - 0.5635, accuracy - 0.6912, recall - 0.8824, AUC - 0.8903, F1 - 0.7407, precision - 0.6383
2023-03-25 14:11:53,939 : [INFO]  Batch 14 initialized 
2023-03-25 14:11:54,698 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:55,149 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 14:12:03,458 : [INFO]  ------------------------- Batch round 1, loss: 0.5277 -------------------------
2023-03-25 14:12:03,459 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:05,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:05,089 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 14:12:08,445 : [INFO]  ------------------------- Batch round 2, loss: 0.5264 -------------------------
2023-03-25 14:12:08,445 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:08,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:08,614 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 14:12:11,644 : [INFO]  ------------------------- Batch round 3, loss: 0.5204 -------------------------
2023-03-25 14:12:11,644 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:12,032 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:12,034 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 14:12:12,035 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 14:12:13,373 : [INFO]  Batch 14: Training set : loss - 0.5189, accuracy - 0.7717, recall - 0.9457, AUC - 0.9041, F1 - 0.8056, precision - 0.7016, training time - -17.0 seconds
2023-03-25 14:12:13,373 : [INFO]  Batch 14: Testing set : loss - 0.5595, accuracy - 0.7255, recall - 0.902, AUC - 0.8639, F1 - 0.7667, precision - 0.6667
2023-03-25 14:12:13,387 : [INFO]  Batch 15 initialized 
2023-03-25 14:12:13,911 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:12:14,220 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 14:12:19,569 : [INFO]  ------------------------- Batch round 1, loss: 0.5851 -------------------------
2023-03-25 14:12:19,570 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:19,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:19,948 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 14:12:23,034 : [INFO]  ------------------------- Batch round 2, loss: 0.5741 -------------------------
2023-03-25 14:12:23,034 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:23,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:23,346 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 14:12:26,363 : [INFO]  ------------------------- Batch round 3, loss: 0.5704 -------------------------
2023-03-25 14:12:26,363 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:27,061 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:27,063 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 14:12:27,063 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 14:12:28,518 : [INFO]  Batch 15: Training set : loss - 0.5662, accuracy - 0.7337, recall - 0.9239, AUC - 0.8601, F1 - 0.7763, precision - 0.6693, training time - -13.0 seconds
2023-03-25 14:12:28,518 : [INFO]  Batch 15: Testing set : loss - 0.5646, accuracy - 0.7304, recall - 0.9412, AUC - 0.8897, F1 - 0.7773, precision - 0.6621
2023-03-25 14:12:28,533 : [INFO]  Batch 16 initialized 
2023-03-25 14:12:28,983 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:12:29,234 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 14:12:34,106 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 14:12:34,106 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:34,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:34,268 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 14:12:37,460 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-25 14:12:37,460 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:37,468 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:37,470 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 14:12:40,837 : [INFO]  ------------------------- Batch round 3, loss: 0.5578 -------------------------
2023-03-25 14:12:40,837 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:40,843 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:40,846 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 14:12:40,847 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 14:12:42,810 : [INFO]  Batch 16: Training set : loss - 0.5548, accuracy - 0.7663, recall - 0.8913, AUC - 0.8383, F1 - 0.7923, precision - 0.713, training time - -12.0 seconds
2023-03-25 14:12:42,810 : [INFO]  Batch 16: Testing set : loss - 0.5541, accuracy - 0.7157, recall - 0.8529, AUC - 0.8721, F1 - 0.75, precision - 0.6692
2023-03-25 14:12:42,825 : [INFO]  Batch 17 initialized 
2023-03-25 14:12:43,574 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:12:43,843 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 14:12:49,485 : [INFO]  ------------------------- Batch round 1, loss: 0.5412 -------------------------
2023-03-25 14:12:49,485 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:49,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:49,505 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 14:12:52,497 : [INFO]  ------------------------- Batch round 2, loss: 0.5273 -------------------------
2023-03-25 14:12:52,497 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:52,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:52,836 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 14:12:55,686 : [INFO]  ------------------------- Batch round 3, loss: 0.5139 -------------------------
2023-03-25 14:12:55,686 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:55,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:55,756 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 14:12:55,756 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 14:12:57,166 : [INFO]  Batch 17: Training set : loss - 0.521, accuracy - 0.7772, recall - 0.9457, AUC - 0.9193, F1 - 0.8093, precision - 0.7073, training time - -12.0 seconds
2023-03-25 14:12:57,166 : [INFO]  Batch 17: Testing set : loss - 0.5681, accuracy - 0.7304, recall - 0.9706, AUC - 0.9204, F1 - 0.7826, precision - 0.6556
2023-03-25 14:12:57,176 : [INFO]  Batch 18 initialized 
