2023-03-25 19:49:56,072 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 19:49:56,072 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 6, epochs 6
2023-03-25 19:49:58,737 : [INFO]  Model initialized for training
2023-03-25 19:50:09,055 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:50:09,179 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 19:50:09,180 : [INFO]  Connected to the server
2023-03-25 19:50:09,264 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 19:50:09,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:50:09,272 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 19:50:09,272 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 19:52:24,978 : [INFO]  ------------------------- Training round 1, loss: 0.6222 -------------------------
2023-03-25 19:52:24,978 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 19:52:24,984 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:52:24,986 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 19:55:11,339 : [INFO]  ------------------------- Training round 2, loss: 0.5953 -------------------------
2023-03-25 19:55:11,344 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 19:55:11,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:55:11,913 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 19:58:04,919 : [INFO]  ------------------------- Training round 3, loss: 0.5918 -------------------------
2023-03-25 19:58:04,919 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 19:58:04,928 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:58:04,931 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 20:00:53,954 : [INFO]  ------------------------- Training round 4, loss: 0.5905 -------------------------
2023-03-25 20:00:53,954 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 20:00:54,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:00:54,271 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 20:03:37,323 : [INFO]  ------------------------- Training round 5, loss: 0.5888 -------------------------
2023-03-25 20:03:37,323 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 20:03:37,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:03:37,651 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-25 20:06:16,680 : [INFO]  ------------------------- Training round 6, loss: 0.5881 -------------------------
2023-03-25 20:06:16,680 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-25 20:06:41,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:06:41,997 : [INFO]  ------------------------- Initial model training: round 7 -------------------------
2023-03-25 20:09:21,118 : [INFO]  ------------------------- Training round 7, loss: 0.5872 -------------------------
2023-03-25 20:09:21,118 : [INFO]  ------------------------- Training, round 7: Sent local model to the server -------------------------
2023-03-25 20:09:21,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:09:21,212 : [INFO]  ------------------------- Initial model training: round 8 -------------------------
2023-03-25 20:11:59,070 : [INFO]  ------------------------- Training round 8, loss: 0.5865 -------------------------
2023-03-25 20:11:59,070 : [INFO]  ------------------------- Training, round 8: Sent local model to the server -------------------------
2023-03-25 20:11:59,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:11:59,359 : [INFO]  ################ Initial trained model: Final global model evalution after 8 rounds ################
2023-03-25 20:12:50,498 : [INFO]  Initially trained model: Training set : loss - 0.58, accuracy - 0.7, recall - 0.87, AUC - 0.84, F1 - 0.75, precision - 0.65, training time - -1310.0 seconds
2023-03-25 20:12:50,498 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.84, F1 - 0.74, precision - 0.64
2023-03-25 20:12:50,528 : [INFO]  Batch 1 initialized 
2023-03-25 20:12:51,054 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:12:51,208 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 20:12:51,208 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 20:12:55,776 : [INFO]  ------------------------- Batch round 1, loss: 0.5951 -------------------------
2023-03-25 20:12:55,776 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 20:12:56,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:12:56,130 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 20:12:58,576 : [INFO]  ------------------------- Batch round 2, loss: 0.5793 -------------------------
2023-03-25 20:12:58,576 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 20:12:58,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:12:58,583 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 20:13:00,977 : [INFO]  ------------------------- Batch round 3, loss: 0.5699 -------------------------
2023-03-25 20:13:00,978 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:01,115 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:01,117 : [INFO]  ------------------------- Batch 1 training: round 4 -------------------------
2023-03-25 20:13:03,618 : [INFO]  ------------------------- Batch round 4, loss: 0.5624 -------------------------
2023-03-25 20:13:03,618 : [INFO]  ------------------------- Batch 1, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:03,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:03,625 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 20:13:03,625 : [INFO]  ################ Batch 1: final global model evalution after 4 rounds ################
2023-03-25 20:13:05,120 : [INFO]  Batch 1: Training set : loss - 0.5664, accuracy - 0.7554, recall - 0.913, AUC - 0.8647, F1 - 0.7887, precision - 0.6942, training time - -12.0 seconds
2023-03-25 20:13:05,120 : [INFO]  Batch 1: Testing set : loss - 0.5627, accuracy - 0.75, recall - 0.8922, AUC - 0.8739, F1 - 0.7811, precision - 0.6947
2023-03-25 20:13:05,129 : [INFO]  Batch 2 initialized 
2023-03-25 20:13:05,620 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:05,808 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 20:13:10,177 : [INFO]  ------------------------- Batch round 1, loss: 0.566 -------------------------
2023-03-25 20:13:10,177 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:10,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:10,220 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 20:13:12,524 : [INFO]  ------------------------- Batch round 2, loss: 0.5507 -------------------------
2023-03-25 20:13:12,524 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 20:13:12,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:12,547 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 20:13:14,931 : [INFO]  ------------------------- Batch round 3, loss: 0.5398 -------------------------
2023-03-25 20:13:14,931 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:14,935 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:14,937 : [INFO]  ------------------------- Batch 2 training: round 4 -------------------------
2023-03-25 20:13:17,399 : [INFO]  ------------------------- Batch round 4, loss: 0.5406 -------------------------
2023-03-25 20:13:17,399 : [INFO]  ------------------------- Batch 2, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:17,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:17,404 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 20:13:17,404 : [INFO]  ################ Batch 2: final global model evalution after 4 rounds ################
2023-03-25 20:13:18,847 : [INFO]  Batch 2: Training set : loss - 0.5371, accuracy - 0.7826, recall - 0.9457, AUC - 0.8886, F1 - 0.8131, precision - 0.7131, training time - -12.0 seconds
2023-03-25 20:13:18,847 : [INFO]  Batch 2: Testing set : loss - 0.5645, accuracy - 0.7255, recall - 0.9118, AUC - 0.8834, F1 - 0.7686, precision - 0.6643
2023-03-25 20:13:18,858 : [INFO]  Batch 3 initialized 
2023-03-25 20:13:19,344 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:19,614 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 20:13:23,965 : [INFO]  ------------------------- Batch round 1, loss: 0.5346 -------------------------
2023-03-25 20:13:23,965 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:24,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:24,068 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 20:13:26,331 : [INFO]  ------------------------- Batch round 2, loss: 0.5409 -------------------------
2023-03-25 20:13:26,331 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 20:13:26,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:26,650 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 20:13:28,905 : [INFO]  ------------------------- Batch round 3, loss: 0.5355 -------------------------
2023-03-25 20:13:28,906 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:29,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:29,311 : [INFO]  ------------------------- Batch 3 training: round 4 -------------------------
2023-03-25 20:13:32,092 : [INFO]  ------------------------- Batch round 4, loss: 0.5329 -------------------------
2023-03-25 20:13:32,093 : [INFO]  ------------------------- Batch 3, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:32,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:32,113 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 20:13:32,113 : [INFO]  ################ Batch 3: final global model evalution after 4 rounds ################
2023-03-25 20:13:34,173 : [INFO]  Batch 3: Training set : loss - 0.5272, accuracy - 0.7826, recall - 0.8913, AUC - 0.886, F1 - 0.8039, precision - 0.7321, training time - -12.0 seconds
2023-03-25 20:13:34,174 : [INFO]  Batch 3: Testing set : loss - 0.5607, accuracy - 0.7255, recall - 0.9412, AUC - 0.8733, F1 - 0.7742, precision - 0.6575
2023-03-25 20:13:34,187 : [INFO]  Batch 4 initialized 
2023-03-25 20:13:34,706 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:34,976 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 20:13:40,303 : [INFO]  ------------------------- Batch round 1, loss: 0.563 -------------------------
2023-03-25 20:13:40,303 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:40,408 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:40,410 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 20:13:42,765 : [INFO]  ------------------------- Batch round 2, loss: 0.5447 -------------------------
2023-03-25 20:13:42,765 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 20:13:43,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:43,026 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 20:13:45,409 : [INFO]  ------------------------- Batch round 3, loss: 0.5394 -------------------------
2023-03-25 20:13:45,410 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 20:13:45,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:45,415 : [INFO]  ------------------------- Batch 4 training: round 4 -------------------------
2023-03-25 20:13:48,465 : [INFO]  ------------------------- Batch round 4, loss: 0.5324 -------------------------
2023-03-25 20:13:48,466 : [INFO]  ------------------------- Batch 4, round 4: Sent local model to the server -------------------------
2023-03-25 20:13:48,489 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:48,491 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 20:13:48,492 : [INFO]  ################ Batch 4: final global model evalution after 4 rounds ################
2023-03-25 20:13:50,675 : [INFO]  Batch 4: Training set : loss - 0.533, accuracy - 0.7772, recall - 0.9565, AUC - 0.9215, F1 - 0.8111, precision - 0.704, training time - -14.0 seconds
2023-03-25 20:13:50,675 : [INFO]  Batch 4: Testing set : loss - 0.5698, accuracy - 0.7304, recall - 0.951, AUC - 0.8906, F1 - 0.7791, precision - 0.6599
2023-03-25 20:13:50,689 : [INFO]  Batch 5 initialized 
2023-03-25 20:13:51,263 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:13:51,541 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 20:13:56,990 : [INFO]  ------------------------- Batch round 1, loss: 0.5511 -------------------------
2023-03-25 20:13:56,990 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 20:13:57,000 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:13:57,006 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 20:14:00,058 : [INFO]  ------------------------- Batch round 2, loss: 0.5348 -------------------------
2023-03-25 20:14:00,059 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:00,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:00,110 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 20:14:02,894 : [INFO]  ------------------------- Batch round 3, loss: 0.5293 -------------------------
2023-03-25 20:14:02,895 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:02,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:02,903 : [INFO]  ------------------------- Batch 5 training: round 4 -------------------------
2023-03-25 20:14:05,532 : [INFO]  ------------------------- Batch round 4, loss: 0.5154 -------------------------
2023-03-25 20:14:05,532 : [INFO]  ------------------------- Batch 5, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:05,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:05,538 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 20:14:05,538 : [INFO]  ################ Batch 5: final global model evalution after 4 rounds ################
2023-03-25 20:14:07,224 : [INFO]  Batch 5: Training set : loss - 0.5128, accuracy - 0.8098, recall - 0.9783, AUC - 0.9502, F1 - 0.8372, precision - 0.7317, training time - -14.0 seconds
2023-03-25 20:14:07,224 : [INFO]  Batch 5: Testing set : loss - 0.5797, accuracy - 0.7157, recall - 0.8627, AUC - 0.8231, F1 - 0.7521, precision - 0.6667
2023-03-25 20:14:07,234 : [INFO]  Batch 6 initialized 
2023-03-25 20:14:07,737 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:08,049 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 20:14:13,174 : [INFO]  ------------------------- Batch round 1, loss: 0.5677 -------------------------
2023-03-25 20:14:13,174 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 20:14:13,178 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:13,179 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 20:14:15,645 : [INFO]  ------------------------- Batch round 2, loss: 0.5558 -------------------------
2023-03-25 20:14:15,645 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:15,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:15,651 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 20:14:18,327 : [INFO]  ------------------------- Batch round 3, loss: 0.553 -------------------------
2023-03-25 20:14:18,327 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:18,331 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:18,334 : [INFO]  ------------------------- Batch 6 training: round 4 -------------------------
2023-03-25 20:14:21,233 : [INFO]  ------------------------- Batch round 4, loss: 0.5449 -------------------------
2023-03-25 20:14:21,233 : [INFO]  ------------------------- Batch 6, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:21,236 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:21,238 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 20:14:21,239 : [INFO]  ################ Batch 6: final global model evalution after 4 rounds ################
2023-03-25 20:14:22,840 : [INFO]  Batch 6: Training set : loss - 0.5435, accuracy - 0.7772, recall - 0.9348, AUC - 0.8868, F1 - 0.8075, precision - 0.7107, training time - -13.0 seconds
2023-03-25 20:14:22,840 : [INFO]  Batch 6: Testing set : loss - 0.5536, accuracy - 0.7598, recall - 0.9216, AUC - 0.9055, F1 - 0.7932, precision - 0.6963
2023-03-25 20:14:22,856 : [INFO]  Batch 7 initialized 
2023-03-25 20:14:23,398 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:23,700 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 20:14:28,768 : [INFO]  ------------------------- Batch round 1, loss: 0.57 -------------------------
2023-03-25 20:14:28,769 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 20:14:28,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:28,775 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 20:14:31,479 : [INFO]  ------------------------- Batch round 2, loss: 0.5549 -------------------------
2023-03-25 20:14:31,479 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:31,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:31,487 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 20:14:34,044 : [INFO]  ------------------------- Batch round 3, loss: 0.5543 -------------------------
2023-03-25 20:14:34,044 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:34,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:34,050 : [INFO]  ------------------------- Batch 7 training: round 4 -------------------------
2023-03-25 20:14:36,908 : [INFO]  ------------------------- Batch round 4, loss: 0.5554 -------------------------
2023-03-25 20:14:36,910 : [INFO]  ------------------------- Batch 7, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:37,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:37,282 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 20:14:37,282 : [INFO]  ################ Batch 7: final global model evalution after 4 rounds ################
2023-03-25 20:14:39,767 : [INFO]  Batch 7: Training set : loss - 0.5492, accuracy - 0.7663, recall - 0.9674, AUC - 0.8826, F1 - 0.8054, precision - 0.6899, training time - -14.0 seconds
2023-03-25 20:14:39,768 : [INFO]  Batch 7: Testing set : loss - 0.573, accuracy - 0.7304, recall - 0.8725, AUC - 0.8433, F1 - 0.7639, precision - 0.6794
2023-03-25 20:14:39,786 : [INFO]  Batch 8 initialized 
2023-03-25 20:14:40,385 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:40,722 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 20:14:46,225 : [INFO]  ------------------------- Batch round 1, loss: 0.5768 -------------------------
2023-03-25 20:14:46,225 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 20:14:46,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:46,231 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 20:14:49,184 : [INFO]  ------------------------- Batch round 2, loss: 0.5632 -------------------------
2023-03-25 20:14:49,185 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 20:14:49,532 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:49,540 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 20:14:53,610 : [INFO]  ------------------------- Batch round 3, loss: 0.5517 -------------------------
2023-03-25 20:14:53,610 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 20:14:53,613 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:53,614 : [INFO]  ------------------------- Batch 8 training: round 4 -------------------------
2023-03-25 20:14:55,832 : [INFO]  ------------------------- Batch round 4, loss: 0.5487 -------------------------
2023-03-25 20:14:55,833 : [INFO]  ------------------------- Batch 8, round 4: Sent local model to the server -------------------------
2023-03-25 20:14:56,096 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:14:56,098 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 20:14:56,098 : [INFO]  ################ Batch 8: final global model evalution after 4 rounds ################
2023-03-25 20:14:57,551 : [INFO]  Batch 8: Training set : loss - 0.553, accuracy - 0.7174, recall - 0.9022, AUC - 0.8915, F1 - 0.7615, precision - 0.6587, training time - -15.0 seconds
2023-03-25 20:14:57,551 : [INFO]  Batch 8: Testing set : loss - 0.5722, accuracy - 0.6961, recall - 0.8824, AUC - 0.8505, F1 - 0.7438, precision - 0.6429
2023-03-25 20:14:57,564 : [INFO]  Batch 9 initialized 
2023-03-25 20:14:58,019 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:14:58,420 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 20:15:04,099 : [INFO]  ------------------------- Batch round 1, loss: 0.5542 -------------------------
2023-03-25 20:15:04,100 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:04,186 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:04,189 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 20:15:06,997 : [INFO]  ------------------------- Batch round 2, loss: 0.5419 -------------------------
2023-03-25 20:15:06,997 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:07,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:07,003 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 20:15:09,670 : [INFO]  ------------------------- Batch round 3, loss: 0.5387 -------------------------
2023-03-25 20:15:09,670 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:09,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:09,783 : [INFO]  ------------------------- Batch 9 training: round 4 -------------------------
2023-03-25 20:15:12,262 : [INFO]  ------------------------- Batch round 4, loss: 0.5242 -------------------------
2023-03-25 20:15:12,262 : [INFO]  ------------------------- Batch 9, round 4: Sent local model to the server -------------------------
2023-03-25 20:15:12,344 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:12,346 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 20:15:12,346 : [INFO]  ################ Batch 9: final global model evalution after 4 rounds ################
2023-03-25 20:15:13,928 : [INFO]  Batch 9: Training set : loss - 0.5283, accuracy - 0.7772, recall - 0.9565, AUC - 0.9259, F1 - 0.8111, precision - 0.704, training time - -14.0 seconds
2023-03-25 20:15:13,928 : [INFO]  Batch 9: Testing set : loss - 0.5499, accuracy - 0.7304, recall - 0.8627, AUC - 0.873, F1 - 0.7619, precision - 0.6822
2023-03-25 20:15:13,941 : [INFO]  Batch 10 initialized 
2023-03-25 20:15:14,529 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:15:14,844 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 20:15:20,437 : [INFO]  ------------------------- Batch round 1, loss: 0.5473 -------------------------
2023-03-25 20:15:20,437 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:20,931 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:20,933 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 20:15:23,401 : [INFO]  ------------------------- Batch round 2, loss: 0.5346 -------------------------
2023-03-25 20:15:23,401 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:23,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:23,551 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 20:15:25,788 : [INFO]  ------------------------- Batch round 3, loss: 0.5397 -------------------------
2023-03-25 20:15:25,788 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:25,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:25,872 : [INFO]  ------------------------- Batch 10 training: round 4 -------------------------
2023-03-25 20:15:28,129 : [INFO]  ------------------------- Batch round 4, loss: 0.5331 -------------------------
2023-03-25 20:15:28,129 : [INFO]  ------------------------- Batch 10, round 4: Sent local model to the server -------------------------
2023-03-25 20:15:28,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:28,200 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 20:15:28,200 : [INFO]  ################ Batch 10: final global model evalution after 4 rounds ################
2023-03-25 20:15:29,983 : [INFO]  Batch 10: Training set : loss - 0.5261, accuracy - 0.7935, recall - 0.9674, AUC - 0.9222, F1 - 0.8241, precision - 0.7177, training time - -13.0 seconds
2023-03-25 20:15:29,983 : [INFO]  Batch 10: Testing set : loss - 0.5548, accuracy - 0.7157, recall - 0.902, AUC - 0.8849, F1 - 0.7603, precision - 0.6571
2023-03-25 20:15:29,996 : [INFO]  Batch 11 initialized 
2023-03-25 20:15:30,539 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:15:30,827 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 20:15:36,230 : [INFO]  ------------------------- Batch round 1, loss: 0.5731 -------------------------
2023-03-25 20:15:36,230 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:36,282 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:36,286 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 20:15:39,104 : [INFO]  ------------------------- Batch round 2, loss: 0.5641 -------------------------
2023-03-25 20:15:39,104 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:39,111 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:39,113 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 20:15:41,684 : [INFO]  ------------------------- Batch round 3, loss: 0.5574 -------------------------
2023-03-25 20:15:41,684 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:41,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:41,693 : [INFO]  ------------------------- Batch 11 training: round 4 -------------------------
2023-03-25 20:15:44,338 : [INFO]  ------------------------- Batch round 4, loss: 0.5516 -------------------------
2023-03-25 20:15:44,338 : [INFO]  ------------------------- Batch 11, round 4: Sent local model to the server -------------------------
2023-03-25 20:15:44,540 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:44,542 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 20:15:44,542 : [INFO]  ################ Batch 11: final global model evalution after 4 rounds ################
2023-03-25 20:15:46,233 : [INFO]  Batch 11: Training set : loss - 0.5516, accuracy - 0.7283, recall - 0.9239, AUC - 0.9042, F1 - 0.7727, precision - 0.6641, training time - -14.0 seconds
2023-03-25 20:15:46,233 : [INFO]  Batch 11: Testing set : loss - 0.5519, accuracy - 0.7255, recall - 0.9118, AUC - 0.9081, F1 - 0.7686, precision - 0.6643
2023-03-25 20:15:46,244 : [INFO]  Batch 12 initialized 
2023-03-25 20:15:46,801 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:15:47,178 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 20:15:52,661 : [INFO]  ------------------------- Batch round 1, loss: 0.5548 -------------------------
2023-03-25 20:15:52,661 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 20:15:52,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:52,671 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 20:15:55,398 : [INFO]  ------------------------- Batch round 2, loss: 0.5437 -------------------------
2023-03-25 20:15:55,399 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 20:15:55,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:55,405 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 20:15:58,110 : [INFO]  ------------------------- Batch round 3, loss: 0.5505 -------------------------
2023-03-25 20:15:58,110 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 20:15:58,114 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:15:58,116 : [INFO]  ------------------------- Batch 12 training: round 4 -------------------------
2023-03-25 20:16:00,603 : [INFO]  ------------------------- Batch round 4, loss: 0.5455 -------------------------
2023-03-25 20:16:00,604 : [INFO]  ------------------------- Batch 12, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:00,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:00,610 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 20:16:00,610 : [INFO]  ################ Batch 12: final global model evalution after 4 rounds ################
2023-03-25 20:16:02,178 : [INFO]  Batch 12: Training set : loss - 0.5316, accuracy - 0.7609, recall - 0.8478, AUC - 0.8819, F1 - 0.78, precision - 0.7222, training time - -13.0 seconds
2023-03-25 20:16:02,178 : [INFO]  Batch 12: Testing set : loss - 0.5916, accuracy - 0.6667, recall - 0.8431, AUC - 0.8176, F1 - 0.7167, precision - 0.6232
2023-03-25 20:16:02,188 : [INFO]  Batch 13 initialized 
2023-03-25 20:16:02,691 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:03,003 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 20:16:08,609 : [INFO]  ------------------------- Batch round 1, loss: 0.6057 -------------------------
2023-03-25 20:16:08,609 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:09,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:09,204 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 20:16:11,957 : [INFO]  ------------------------- Batch round 2, loss: 0.5945 -------------------------
2023-03-25 20:16:11,957 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:12,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:12,023 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 20:16:15,149 : [INFO]  ------------------------- Batch round 3, loss: 0.5952 -------------------------
2023-03-25 20:16:15,150 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 20:16:15,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:15,158 : [INFO]  ------------------------- Batch 13 training: round 4 -------------------------
2023-03-25 20:16:17,741 : [INFO]  ------------------------- Batch round 4, loss: 0.5822 -------------------------
2023-03-25 20:16:17,742 : [INFO]  ------------------------- Batch 13, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:17,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:17,777 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 20:16:17,777 : [INFO]  ################ Batch 13: final global model evalution after 4 rounds ################
2023-03-25 20:16:19,510 : [INFO]  Batch 13: Training set : loss - 0.5786, accuracy - 0.7283, recall - 0.913, AUC - 0.8338, F1 - 0.7706, precision - 0.6667, training time - -15.0 seconds
2023-03-25 20:16:19,510 : [INFO]  Batch 13: Testing set : loss - 0.5864, accuracy - 0.6765, recall - 0.8137, AUC - 0.817, F1 - 0.7155, precision - 0.6385
2023-03-25 20:16:19,531 : [INFO]  Batch 14 initialized 
2023-03-25 20:16:20,188 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:20,515 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 20:16:25,454 : [INFO]  ------------------------- Batch round 1, loss: 0.5572 -------------------------
2023-03-25 20:16:25,454 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:25,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:25,513 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 20:16:28,097 : [INFO]  ------------------------- Batch round 2, loss: 0.536 -------------------------
2023-03-25 20:16:28,097 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:28,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:28,103 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 20:16:30,565 : [INFO]  ------------------------- Batch round 3, loss: 0.5318 -------------------------
2023-03-25 20:16:30,565 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 20:16:30,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:30,571 : [INFO]  ------------------------- Batch 14 training: round 4 -------------------------
2023-03-25 20:16:33,072 : [INFO]  ------------------------- Batch round 4, loss: 0.5289 -------------------------
2023-03-25 20:16:33,072 : [INFO]  ------------------------- Batch 14, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:33,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:33,078 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 20:16:33,078 : [INFO]  ################ Batch 14: final global model evalution after 4 rounds ################
2023-03-25 20:16:34,668 : [INFO]  Batch 14: Training set : loss - 0.5207, accuracy - 0.8043, recall - 0.9239, AUC - 0.9029, F1 - 0.8252, precision - 0.7456, training time - -13.0 seconds
2023-03-25 20:16:34,668 : [INFO]  Batch 14: Testing set : loss - 0.5612, accuracy - 0.7206, recall - 0.8922, AUC - 0.8774, F1 - 0.7615, precision - 0.6642
2023-03-25 20:16:34,679 : [INFO]  Batch 15 initialized 
2023-03-25 20:16:35,277 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:35,663 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 20:16:40,861 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 20:16:40,862 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:40,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:40,869 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 20:16:43,617 : [INFO]  ------------------------- Batch round 2, loss: 0.5623 -------------------------
2023-03-25 20:16:43,617 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:43,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:43,624 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 20:16:46,297 : [INFO]  ------------------------- Batch round 3, loss: 0.5489 -------------------------
2023-03-25 20:16:46,297 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 20:16:46,301 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:46,303 : [INFO]  ------------------------- Batch 15 training: round 4 -------------------------
2023-03-25 20:16:48,887 : [INFO]  ------------------------- Batch round 4, loss: 0.5489 -------------------------
2023-03-25 20:16:48,888 : [INFO]  ------------------------- Batch 15, round 4: Sent local model to the server -------------------------
2023-03-25 20:16:48,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:48,894 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 20:16:48,894 : [INFO]  ################ Batch 15: final global model evalution after 4 rounds ################
2023-03-25 20:16:50,525 : [INFO]  Batch 15: Training set : loss - 0.5471, accuracy - 0.7772, recall - 0.9565, AUC - 0.8907, F1 - 0.8111, precision - 0.704, training time - -13.0 seconds
2023-03-25 20:16:50,526 : [INFO]  Batch 15: Testing set : loss - 0.5746, accuracy - 0.6961, recall - 0.8333, AUC - 0.8473, F1 - 0.7328, precision - 0.6538
2023-03-25 20:16:50,541 : [INFO]  Batch 16 initialized 
2023-03-25 20:16:51,080 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:16:51,411 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 20:16:56,408 : [INFO]  ------------------------- Batch round 1, loss: 0.56 -------------------------
2023-03-25 20:16:56,409 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 20:16:56,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:56,414 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 20:16:58,884 : [INFO]  ------------------------- Batch round 2, loss: 0.5491 -------------------------
2023-03-25 20:16:58,884 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 20:16:58,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:16:58,969 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 20:17:01,667 : [INFO]  ------------------------- Batch round 3, loss: 0.5388 -------------------------
2023-03-25 20:17:01,667 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:01,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:01,724 : [INFO]  ------------------------- Batch 16 training: round 4 -------------------------
2023-03-25 20:17:04,573 : [INFO]  ------------------------- Batch round 4, loss: 0.549 -------------------------
2023-03-25 20:17:04,573 : [INFO]  ------------------------- Batch 16, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:04,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:04,582 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 20:17:04,583 : [INFO]  ################ Batch 16: final global model evalution after 4 rounds ################
2023-03-25 20:17:06,536 : [INFO]  Batch 16: Training set : loss - 0.534, accuracy - 0.7772, recall - 0.9348, AUC - 0.9098, F1 - 0.8075, precision - 0.7107, training time - -13.0 seconds
2023-03-25 20:17:06,537 : [INFO]  Batch 16: Testing set : loss - 0.5387, accuracy - 0.7206, recall - 0.951, AUC - 0.9394, F1 - 0.7729, precision - 0.651
2023-03-25 20:17:06,564 : [INFO]  Batch 17 initialized 
2023-03-25 20:17:07,254 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:07,544 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 20:17:11,652 : [INFO]  ------------------------- Batch round 1, loss: 0.5579 -------------------------
2023-03-25 20:17:11,652 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:11,775 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:11,778 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 20:17:14,176 : [INFO]  ------------------------- Batch round 2, loss: 0.545 -------------------------
2023-03-25 20:17:14,176 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:14,203 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:14,205 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 20:17:16,301 : [INFO]  ------------------------- Batch round 3, loss: 0.534 -------------------------
2023-03-25 20:17:16,301 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:16,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:16,374 : [INFO]  ------------------------- Batch 17 training: round 4 -------------------------
2023-03-25 20:17:18,620 : [INFO]  ------------------------- Batch round 4, loss: 0.5282 -------------------------
2023-03-25 20:17:18,620 : [INFO]  ------------------------- Batch 17, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:18,672 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:18,674 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 20:17:18,674 : [INFO]  ################ Batch 17: final global model evalution after 4 rounds ################
2023-03-25 20:17:20,237 : [INFO]  Batch 17: Training set : loss - 0.5201, accuracy - 0.8152, recall - 0.9457, AUC - 0.9035, F1 - 0.8365, precision - 0.75, training time - -11.0 seconds
2023-03-25 20:17:20,237 : [INFO]  Batch 17: Testing set : loss - 0.5653, accuracy - 0.7304, recall - 0.902, AUC - 0.875, F1 - 0.7699, precision - 0.6715
2023-03-25 20:17:20,244 : [INFO]  Batch 18 initialized 
2023-03-25 20:17:20,819 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:21,094 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 20:17:25,084 : [INFO]  ------------------------- Batch round 1, loss: 0.5964 -------------------------
2023-03-25 20:17:25,084 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:25,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:25,286 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 20:17:27,675 : [INFO]  ------------------------- Batch round 2, loss: 0.5857 -------------------------
2023-03-25 20:17:27,675 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:27,678 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:27,680 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 20:17:29,737 : [INFO]  ------------------------- Batch round 3, loss: 0.5828 -------------------------
2023-03-25 20:17:29,737 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:29,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:29,924 : [INFO]  ------------------------- Batch 18 training: round 4 -------------------------
2023-03-25 20:17:31,973 : [INFO]  ------------------------- Batch round 4, loss: 0.5736 -------------------------
2023-03-25 20:17:31,974 : [INFO]  ------------------------- Batch 18, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:32,147 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:32,149 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 20:17:32,149 : [INFO]  ################ Batch 18: final global model evalution after 4 rounds ################
2023-03-25 20:17:33,594 : [INFO]  Batch 18: Training set : loss - 0.5748, accuracy - 0.7283, recall - 0.9457, AUC - 0.8512, F1 - 0.7768, precision - 0.6591, training time - -11.0 seconds
2023-03-25 20:17:33,595 : [INFO]  Batch 18: Testing set : loss - 0.59, accuracy - 0.6814, recall - 0.902, AUC - 0.8436, F1 - 0.739, precision - 0.6259
2023-03-25 20:17:33,609 : [INFO]  Batch 19 initialized 
2023-03-25 20:17:34,241 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:34,473 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 20:17:38,868 : [INFO]  ------------------------- Batch round 1, loss: 0.5972 -------------------------
2023-03-25 20:17:38,868 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:39,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:39,168 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 20:17:41,208 : [INFO]  ------------------------- Batch round 2, loss: 0.5921 -------------------------
2023-03-25 20:17:41,209 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:41,292 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:41,295 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 20:17:43,489 : [INFO]  ------------------------- Batch round 3, loss: 0.5817 -------------------------
2023-03-25 20:17:43,489 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:43,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:43,566 : [INFO]  ------------------------- Batch 19 training: round 4 -------------------------
2023-03-25 20:17:45,693 : [INFO]  ------------------------- Batch round 4, loss: 0.5708 -------------------------
2023-03-25 20:17:45,694 : [INFO]  ------------------------- Batch 19, round 4: Sent local model to the server -------------------------
2023-03-25 20:17:45,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:45,797 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 20:17:45,798 : [INFO]  ################ Batch 19: final global model evalution after 4 rounds ################
2023-03-25 20:17:47,188 : [INFO]  Batch 19: Training set : loss - 0.5749, accuracy - 0.7065, recall - 0.837, AUC - 0.8029, F1 - 0.7404, precision - 0.6638, training time - -11.0 seconds
2023-03-25 20:17:47,188 : [INFO]  Batch 19: Testing set : loss - 0.6059, accuracy - 0.6422, recall - 0.8529, AUC - 0.805, F1 - 0.7045, precision - 0.6
2023-03-25 20:17:47,199 : [INFO]  Batch 20 initialized 
2023-03-25 20:17:47,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:17:48,132 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 20:17:52,733 : [INFO]  ------------------------- Batch round 1, loss: 0.5474 -------------------------
2023-03-25 20:17:52,733 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 20:17:52,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:52,938 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 20:17:55,319 : [INFO]  ------------------------- Batch round 2, loss: 0.54 -------------------------
2023-03-25 20:17:55,320 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 20:17:55,338 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:55,340 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 20:17:57,643 : [INFO]  ------------------------- Batch round 3, loss: 0.5354 -------------------------
2023-03-25 20:17:57,643 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 20:17:57,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:17:57,735 : [INFO]  ------------------------- Batch 20 training: round 4 -------------------------
2023-03-25 20:17:59,988 : [INFO]  ------------------------- Batch round 4, loss: 0.5274 -------------------------
2023-03-25 20:17:59,988 : [INFO]  ------------------------- Batch 20, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:00,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:00,124 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 20:18:00,124 : [INFO]  ################ Batch 20: final global model evalution after 4 rounds ################
2023-03-25 20:18:01,420 : [INFO]  Batch 20: Training set : loss - 0.5291, accuracy - 0.7663, recall - 0.9565, AUC - 0.9292, F1 - 0.8037, precision - 0.6929, training time - -12.0 seconds
2023-03-25 20:18:01,421 : [INFO]  Batch 20: Testing set : loss - 0.5638, accuracy - 0.7157, recall - 0.951, AUC - 0.9055, F1 - 0.7698, precision - 0.6467
2023-03-25 20:18:01,433 : [INFO]  Batch 21 initialized 
2023-03-25 20:18:01,877 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:02,154 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 20:18:06,375 : [INFO]  ------------------------- Batch round 1, loss: 0.6159 -------------------------
2023-03-25 20:18:06,375 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:06,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:06,510 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 20:18:08,578 : [INFO]  ------------------------- Batch round 2, loss: 0.5998 -------------------------
2023-03-25 20:18:08,578 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:08,930 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:08,931 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 20:18:11,215 : [INFO]  ------------------------- Batch round 3, loss: 0.5758 -------------------------
2023-03-25 20:18:11,215 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:11,238 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:11,240 : [INFO]  ------------------------- Batch 21 training: round 4 -------------------------
2023-03-25 20:18:13,441 : [INFO]  ------------------------- Batch round 4, loss: 0.5703 -------------------------
2023-03-25 20:18:13,441 : [INFO]  ------------------------- Batch 21, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:13,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:13,484 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 20:18:13,484 : [INFO]  ################ Batch 21: final global model evalution after 4 rounds ################
2023-03-25 20:18:14,798 : [INFO]  Batch 21: Training set : loss - 0.5755, accuracy - 0.7337, recall - 0.8913, AUC - 0.8192, F1 - 0.77, precision - 0.6777, training time - -11.0 seconds
2023-03-25 20:18:14,799 : [INFO]  Batch 21: Testing set : loss - 0.5647, accuracy - 0.7353, recall - 0.9118, AUC - 0.8644, F1 - 0.775, precision - 0.6739
2023-03-25 20:18:14,811 : [INFO]  Batch 22 initialized 
2023-03-25 20:18:15,225 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:15,501 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 20:18:19,682 : [INFO]  ------------------------- Batch round 1, loss: 0.6007 -------------------------
2023-03-25 20:18:19,683 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:19,742 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:19,744 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 20:18:22,292 : [INFO]  ------------------------- Batch round 2, loss: 0.5795 -------------------------
2023-03-25 20:18:22,292 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:22,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:22,299 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 20:18:25,528 : [INFO]  ------------------------- Batch round 3, loss: 0.5661 -------------------------
2023-03-25 20:18:25,528 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:25,532 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:25,534 : [INFO]  ------------------------- Batch 22 training: round 4 -------------------------
2023-03-25 20:18:28,202 : [INFO]  ------------------------- Batch round 4, loss: 0.5725 -------------------------
2023-03-25 20:18:28,202 : [INFO]  ------------------------- Batch 22, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:28,206 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:28,208 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 20:18:28,208 : [INFO]  ################ Batch 22: final global model evalution after 4 rounds ################
2023-03-25 20:18:29,746 : [INFO]  Batch 22: Training set : loss - 0.551, accuracy - 0.7663, recall - 0.913, AUC - 0.8454, F1 - 0.7962, precision - 0.7059, training time - -13.0 seconds
2023-03-25 20:18:29,746 : [INFO]  Batch 22: Testing set : loss - 0.6439, accuracy - 0.6176, recall - 0.8725, AUC - 0.7539, F1 - 0.6953, precision - 0.5779
2023-03-25 20:18:29,753 : [INFO]  Batch 23 initialized 
2023-03-25 20:18:30,238 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:30,542 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 20:18:35,295 : [INFO]  ------------------------- Batch round 1, loss: 0.5811 -------------------------
2023-03-25 20:18:35,295 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:35,473 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:35,474 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 20:18:37,929 : [INFO]  ------------------------- Batch round 2, loss: 0.5584 -------------------------
2023-03-25 20:18:37,929 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:37,934 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:37,936 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 20:18:40,401 : [INFO]  ------------------------- Batch round 3, loss: 0.5551 -------------------------
2023-03-25 20:18:40,401 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:40,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:40,406 : [INFO]  ------------------------- Batch 23 training: round 4 -------------------------
2023-03-25 20:18:42,788 : [INFO]  ------------------------- Batch round 4, loss: 0.5441 -------------------------
2023-03-25 20:18:42,788 : [INFO]  ------------------------- Batch 23, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:42,791 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:42,793 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 20:18:42,793 : [INFO]  ################ Batch 23: final global model evalution after 4 rounds ################
2023-03-25 20:18:44,254 : [INFO]  Batch 23: Training set : loss - 0.5386, accuracy - 0.7609, recall - 0.9239, AUC - 0.9003, F1 - 0.7944, precision - 0.6967, training time - -12.0 seconds
2023-03-25 20:18:44,254 : [INFO]  Batch 23: Testing set : loss - 0.5727, accuracy - 0.7353, recall - 0.902, AUC - 0.8805, F1 - 0.7731, precision - 0.6765
2023-03-25 20:18:44,262 : [INFO]  Batch 24 initialized 
2023-03-25 20:18:44,705 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:44,986 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 20:18:49,230 : [INFO]  ------------------------- Batch round 1, loss: 0.6012 -------------------------
2023-03-25 20:18:49,230 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 20:18:49,234 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:49,236 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 20:18:51,640 : [INFO]  ------------------------- Batch round 2, loss: 0.5905 -------------------------
2023-03-25 20:18:51,640 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 20:18:51,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:51,645 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 20:18:54,149 : [INFO]  ------------------------- Batch round 3, loss: 0.5815 -------------------------
2023-03-25 20:18:54,149 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 20:18:54,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:54,155 : [INFO]  ------------------------- Batch 24 training: round 4 -------------------------
2023-03-25 20:18:56,506 : [INFO]  ------------------------- Batch round 4, loss: 0.5796 -------------------------
2023-03-25 20:18:56,506 : [INFO]  ------------------------- Batch 24, round 4: Sent local model to the server -------------------------
2023-03-25 20:18:56,509 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:18:56,511 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 20:18:56,511 : [INFO]  ################ Batch 24: final global model evalution after 4 rounds ################
2023-03-25 20:18:57,876 : [INFO]  Batch 24: Training set : loss - 0.5812, accuracy - 0.7011, recall - 0.8913, AUC - 0.8178, F1 - 0.7489, precision - 0.6457, training time - -12.0 seconds
2023-03-25 20:18:57,877 : [INFO]  Batch 24: Testing set : loss - 0.5904, accuracy - 0.6961, recall - 0.8922, AUC - 0.8254, F1 - 0.7459, precision - 0.6408
2023-03-25 20:18:57,888 : [INFO]  Batch 25 initialized 
2023-03-25 20:18:58,326 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:18:58,635 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 20:19:03,616 : [INFO]  ------------------------- Batch round 1, loss: 0.5763 -------------------------
2023-03-25 20:19:03,617 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:03,620 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:03,622 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 20:19:06,500 : [INFO]  ------------------------- Batch round 2, loss: 0.5594 -------------------------
2023-03-25 20:19:06,501 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:06,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:06,506 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 20:19:08,849 : [INFO]  ------------------------- Batch round 3, loss: 0.5614 -------------------------
2023-03-25 20:19:08,849 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:08,852 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:08,854 : [INFO]  ------------------------- Batch 25 training: round 4 -------------------------
2023-03-25 20:19:11,094 : [INFO]  ------------------------- Batch round 4, loss: 0.5468 -------------------------
2023-03-25 20:19:11,094 : [INFO]  ------------------------- Batch 25, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:11,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:11,099 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 20:19:11,099 : [INFO]  ################ Batch 25: final global model evalution after 4 rounds ################
2023-03-25 20:19:12,449 : [INFO]  Batch 25: Training set : loss - 0.5425, accuracy - 0.7391, recall - 0.9457, AUC - 0.8995, F1 - 0.7838, precision - 0.6692, training time - -12.0 seconds
2023-03-25 20:19:12,449 : [INFO]  Batch 25: Testing set : loss - 0.5785, accuracy - 0.7255, recall - 0.9314, AUC - 0.8693, F1 - 0.7724, precision - 0.6597
2023-03-25 20:19:12,460 : [INFO]  Batch 26 initialized 
2023-03-25 20:19:12,890 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:13,190 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 20:19:17,581 : [INFO]  ------------------------- Batch round 1, loss: 0.5791 -------------------------
2023-03-25 20:19:17,581 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:17,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:17,586 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 20:19:19,768 : [INFO]  ------------------------- Batch round 2, loss: 0.5586 -------------------------
2023-03-25 20:19:19,768 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:19,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:19,773 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 20:19:21,980 : [INFO]  ------------------------- Batch round 3, loss: 0.5562 -------------------------
2023-03-25 20:19:21,980 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:21,983 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:21,985 : [INFO]  ------------------------- Batch 26 training: round 4 -------------------------
2023-03-25 20:19:24,464 : [INFO]  ------------------------- Batch round 4, loss: 0.5522 -------------------------
2023-03-25 20:19:24,464 : [INFO]  ------------------------- Batch 26, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:24,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:24,469 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 20:19:24,469 : [INFO]  ################ Batch 26: final global model evalution after 4 rounds ################
2023-03-25 20:19:25,839 : [INFO]  Batch 26: Training set : loss - 0.5456, accuracy - 0.7826, recall - 0.913, AUC - 0.8721, F1 - 0.8077, precision - 0.7241, training time - -11.0 seconds
2023-03-25 20:19:25,839 : [INFO]  Batch 26: Testing set : loss - 0.5682, accuracy - 0.7353, recall - 0.902, AUC - 0.8476, F1 - 0.7731, precision - 0.6765
2023-03-25 20:19:25,848 : [INFO]  Batch 27 initialized 
2023-03-25 20:19:26,296 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:26,591 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 20:19:30,779 : [INFO]  ------------------------- Batch round 1, loss: 0.6132 -------------------------
2023-03-25 20:19:30,780 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:30,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:30,818 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 20:19:33,150 : [INFO]  ------------------------- Batch round 2, loss: 0.5918 -------------------------
2023-03-25 20:19:33,150 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:33,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:33,156 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 20:19:36,314 : [INFO]  ------------------------- Batch round 3, loss: 0.595 -------------------------
2023-03-25 20:19:36,314 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:36,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:36,523 : [INFO]  ------------------------- Batch 27 training: round 4 -------------------------
2023-03-25 20:19:38,766 : [INFO]  ------------------------- Batch round 4, loss: 0.5761 -------------------------
2023-03-25 20:19:38,766 : [INFO]  ------------------------- Batch 27, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:38,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:38,803 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 20:19:38,804 : [INFO]  ################ Batch 27: final global model evalution after 4 rounds ################
2023-03-25 20:19:40,278 : [INFO]  Batch 27: Training set : loss - 0.581, accuracy - 0.7283, recall - 0.9348, AUC - 0.8387, F1 - 0.7748, precision - 0.6615, training time - -12.0 seconds
2023-03-25 20:19:40,278 : [INFO]  Batch 27: Testing set : loss - 0.6031, accuracy - 0.6667, recall - 0.9118, AUC - 0.8273, F1 - 0.7323, precision - 0.6118
2023-03-25 20:19:40,290 : [INFO]  Batch 28 initialized 
2023-03-25 20:19:40,755 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:41,079 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 20:19:46,136 : [INFO]  ------------------------- Batch round 1, loss: 0.5709 -------------------------
2023-03-25 20:19:46,137 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 20:19:46,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:46,227 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 20:19:48,518 : [INFO]  ------------------------- Batch round 2, loss: 0.5602 -------------------------
2023-03-25 20:19:48,518 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 20:19:48,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:48,530 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 20:19:50,847 : [INFO]  ------------------------- Batch round 3, loss: 0.5491 -------------------------
2023-03-25 20:19:50,847 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 20:19:50,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:50,894 : [INFO]  ------------------------- Batch 28 training: round 4 -------------------------
2023-03-25 20:19:53,155 : [INFO]  ------------------------- Batch round 4, loss: 0.5379 -------------------------
2023-03-25 20:19:53,155 : [INFO]  ------------------------- Batch 28, round 4: Sent local model to the server -------------------------
2023-03-25 20:19:53,158 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:19:53,161 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 20:19:53,161 : [INFO]  ################ Batch 28: final global model evalution after 4 rounds ################
2023-03-25 20:19:54,574 : [INFO]  Batch 28: Training set : loss - 0.5349, accuracy - 0.7826, recall - 0.8913, AUC - 0.8791, F1 - 0.8039, precision - 0.7321, training time - -12.0 seconds
2023-03-25 20:19:54,575 : [INFO]  Batch 28: Testing set : loss - 0.5849, accuracy - 0.6961, recall - 0.8333, AUC - 0.8294, F1 - 0.7328, precision - 0.6538
2023-03-25 20:19:54,586 : [INFO]  Batch 29 initialized 
2023-03-25 20:19:55,080 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:19:55,392 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 20:19:59,827 : [INFO]  ------------------------- Batch round 1, loss: 0.5445 -------------------------
2023-03-25 20:19:59,827 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:00,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:00,125 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 20:20:02,214 : [INFO]  ------------------------- Batch round 2, loss: 0.5355 -------------------------
2023-03-25 20:20:02,214 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:02,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:02,433 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 20:20:04,668 : [INFO]  ------------------------- Batch round 3, loss: 0.5218 -------------------------
2023-03-25 20:20:04,668 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:04,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:04,881 : [INFO]  ------------------------- Batch 29 training: round 4 -------------------------
2023-03-25 20:20:07,464 : [INFO]  ------------------------- Batch round 4, loss: 0.5265 -------------------------
2023-03-25 20:20:07,465 : [INFO]  ------------------------- Batch 29, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:07,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:07,524 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 20:20:07,524 : [INFO]  ################ Batch 29: final global model evalution after 4 rounds ################
2023-03-25 20:20:09,196 : [INFO]  Batch 29: Training set : loss - 0.5198, accuracy - 0.8098, recall - 0.9783, AUC - 0.9179, F1 - 0.8372, precision - 0.7317, training time - -12.0 seconds
2023-03-25 20:20:09,196 : [INFO]  Batch 29: Testing set : loss - 0.5659, accuracy - 0.7255, recall - 0.8725, AUC - 0.8484, F1 - 0.7607, precision - 0.6742
2023-03-25 20:20:09,212 : [INFO]  Batch 30 initialized 
2023-03-25 20:20:09,919 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:10,226 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 20:20:14,710 : [INFO]  ------------------------- Batch round 1, loss: 0.5755 -------------------------
2023-03-25 20:20:14,710 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:14,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:14,827 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 20:20:17,032 : [INFO]  ------------------------- Batch round 2, loss: 0.5638 -------------------------
2023-03-25 20:20:17,032 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:17,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:17,089 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 20:20:19,442 : [INFO]  ------------------------- Batch round 3, loss: 0.5509 -------------------------
2023-03-25 20:20:19,442 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:19,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:19,542 : [INFO]  ------------------------- Batch 30 training: round 4 -------------------------
2023-03-25 20:20:22,097 : [INFO]  ------------------------- Batch round 4, loss: 0.5474 -------------------------
2023-03-25 20:20:22,098 : [INFO]  ------------------------- Batch 30, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:22,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:22,140 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 20:20:22,140 : [INFO]  ################ Batch 30: final global model evalution after 4 rounds ################
2023-03-25 20:20:23,561 : [INFO]  Batch 30: Training set : loss - 0.5388, accuracy - 0.7826, recall - 0.9348, AUC - 0.8987, F1 - 0.8113, precision - 0.7167, training time - -12.0 seconds
2023-03-25 20:20:23,561 : [INFO]  Batch 30: Testing set : loss - 0.5358, accuracy - 0.7549, recall - 0.951, AUC - 0.9354, F1 - 0.7951, precision - 0.6831
2023-03-25 20:20:23,574 : [INFO]  Batch 31 initialized 
2023-03-25 20:20:24,070 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:24,380 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 20:20:28,740 : [INFO]  ------------------------- Batch round 1, loss: 0.6023 -------------------------
2023-03-25 20:20:28,741 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:28,748 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:28,752 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 20:20:31,727 : [INFO]  ------------------------- Batch round 2, loss: 0.5914 -------------------------
2023-03-25 20:20:31,727 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:31,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:31,734 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 20:20:34,231 : [INFO]  ------------------------- Batch round 3, loss: 0.575 -------------------------
2023-03-25 20:20:34,231 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:34,235 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:34,237 : [INFO]  ------------------------- Batch 31 training: round 4 -------------------------
2023-03-25 20:20:36,502 : [INFO]  ------------------------- Batch round 4, loss: 0.5688 -------------------------
2023-03-25 20:20:36,502 : [INFO]  ------------------------- Batch 31, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:36,505 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:36,507 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 20:20:36,507 : [INFO]  ################ Batch 31: final global model evalution after 4 rounds ################
2023-03-25 20:20:37,941 : [INFO]  Batch 31: Training set : loss - 0.5627, accuracy - 0.7446, recall - 0.8261, AUC - 0.8485, F1 - 0.7638, precision - 0.7103, training time - -12.0 seconds
2023-03-25 20:20:37,941 : [INFO]  Batch 31: Testing set : loss - 0.5807, accuracy - 0.7059, recall - 0.8529, AUC - 0.8483, F1 - 0.7436, precision - 0.6591
2023-03-25 20:20:37,948 : [INFO]  Batch 32 initialized 
2023-03-25 20:20:38,374 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:38,692 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 20:20:43,031 : [INFO]  ------------------------- Batch round 1, loss: 0.5858 -------------------------
2023-03-25 20:20:43,032 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:43,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:43,038 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 20:20:45,525 : [INFO]  ------------------------- Batch round 2, loss: 0.5754 -------------------------
2023-03-25 20:20:45,526 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:45,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:45,533 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 20:20:47,835 : [INFO]  ------------------------- Batch round 3, loss: 0.5745 -------------------------
2023-03-25 20:20:47,835 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 20:20:47,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:47,840 : [INFO]  ------------------------- Batch 32 training: round 4 -------------------------
2023-03-25 20:20:50,117 : [INFO]  ------------------------- Batch round 4, loss: 0.5635 -------------------------
2023-03-25 20:20:50,117 : [INFO]  ------------------------- Batch 32, round 4: Sent local model to the server -------------------------
2023-03-25 20:20:50,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:50,121 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 20:20:50,121 : [INFO]  ################ Batch 32: final global model evalution after 4 rounds ################
2023-03-25 20:20:51,546 : [INFO]  Batch 32: Training set : loss - 0.5584, accuracy - 0.7391, recall - 0.8913, AUC - 0.8546, F1 - 0.7736, precision - 0.6833, training time - -11.0 seconds
2023-03-25 20:20:51,546 : [INFO]  Batch 32: Testing set : loss - 0.5592, accuracy - 0.7353, recall - 0.8824, AUC - 0.8582, F1 - 0.7692, precision - 0.6818
2023-03-25 20:20:51,555 : [INFO]  Batch 33 initialized 
2023-03-25 20:20:51,985 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:20:52,299 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 20:20:56,515 : [INFO]  ------------------------- Batch round 1, loss: 0.5938 -------------------------
2023-03-25 20:20:56,516 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 20:20:56,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:56,520 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 20:20:58,620 : [INFO]  ------------------------- Batch round 2, loss: 0.5823 -------------------------
2023-03-25 20:20:58,620 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 20:20:58,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:20:58,626 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 20:21:00,711 : [INFO]  ------------------------- Batch round 3, loss: 0.575 -------------------------
2023-03-25 20:21:00,711 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:00,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:00,717 : [INFO]  ------------------------- Batch 33 training: round 4 -------------------------
2023-03-25 20:21:02,821 : [INFO]  ------------------------- Batch round 4, loss: 0.5764 -------------------------
2023-03-25 20:21:02,821 : [INFO]  ------------------------- Batch 33, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:02,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:02,827 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 20:21:02,827 : [INFO]  ################ Batch 33: final global model evalution after 4 rounds ################
2023-03-25 20:21:04,161 : [INFO]  Batch 33: Training set : loss - 0.5867, accuracy - 0.7174, recall - 0.9022, AUC - 0.7644, F1 - 0.7615, precision - 0.6587, training time - -11.0 seconds
2023-03-25 20:21:04,161 : [INFO]  Batch 33: Testing set : loss - 0.5901, accuracy - 0.6912, recall - 0.8725, AUC - 0.7972, F1 - 0.7386, precision - 0.6403
2023-03-25 20:21:04,168 : [INFO]  Batch 34 initialized 
2023-03-25 20:21:04,675 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:04,987 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 20:21:08,808 : [INFO]  ------------------------- Batch round 1, loss: 0.5805 -------------------------
2023-03-25 20:21:08,808 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:08,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:08,960 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 20:21:11,013 : [INFO]  ------------------------- Batch round 2, loss: 0.5627 -------------------------
2023-03-25 20:21:11,013 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:11,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:11,074 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 20:21:13,231 : [INFO]  ------------------------- Batch round 3, loss: 0.5567 -------------------------
2023-03-25 20:21:13,231 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:13,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:13,326 : [INFO]  ------------------------- Batch 34 training: round 4 -------------------------
2023-03-25 20:21:15,742 : [INFO]  ------------------------- Batch round 4, loss: 0.5554 -------------------------
2023-03-25 20:21:15,742 : [INFO]  ------------------------- Batch 34, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:15,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:15,816 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 20:21:15,816 : [INFO]  ################ Batch 34: final global model evalution after 4 rounds ################
2023-03-25 20:21:17,301 : [INFO]  Batch 34: Training set : loss - 0.5555, accuracy - 0.7391, recall - 0.9022, AUC - 0.886, F1 - 0.7757, precision - 0.6803, training time - -11.0 seconds
2023-03-25 20:21:17,302 : [INFO]  Batch 34: Testing set : loss - 0.5349, accuracy - 0.7402, recall - 0.9412, AUC - 0.9275, F1 - 0.7837, precision - 0.6713
2023-03-25 20:21:17,314 : [INFO]  Batch 35 initialized 
2023-03-25 20:21:17,748 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:18,067 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 20:21:22,029 : [INFO]  ------------------------- Batch round 1, loss: 0.5539 -------------------------
2023-03-25 20:21:22,029 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:22,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:22,083 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 20:21:24,222 : [INFO]  ------------------------- Batch round 2, loss: 0.5505 -------------------------
2023-03-25 20:21:24,222 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:24,225 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:24,228 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 20:21:26,337 : [INFO]  ------------------------- Batch round 3, loss: 0.5466 -------------------------
2023-03-25 20:21:26,337 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:26,340 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:26,343 : [INFO]  ------------------------- Batch 35 training: round 4 -------------------------
2023-03-25 20:21:28,506 : [INFO]  ------------------------- Batch round 4, loss: 0.547 -------------------------
2023-03-25 20:21:28,507 : [INFO]  ------------------------- Batch 35, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:28,510 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:28,511 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 20:21:28,511 : [INFO]  ################ Batch 35: final global model evalution after 4 rounds ################
2023-03-25 20:21:29,815 : [INFO]  Batch 35: Training set : loss - 0.5404, accuracy - 0.7826, recall - 0.9022, AUC - 0.8926, F1 - 0.8058, precision - 0.7281, training time - -10.0 seconds
2023-03-25 20:21:29,815 : [INFO]  Batch 35: Testing set : loss - 0.5697, accuracy - 0.6814, recall - 0.8235, AUC - 0.8391, F1 - 0.721, precision - 0.6412
2023-03-25 20:21:29,828 : [INFO]  Batch 36 initialized 
2023-03-25 20:21:30,285 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:30,618 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 20:21:34,853 : [INFO]  ------------------------- Batch round 1, loss: 0.547 -------------------------
2023-03-25 20:21:34,853 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:34,944 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:34,946 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 20:21:37,412 : [INFO]  ------------------------- Batch round 2, loss: 0.5425 -------------------------
2023-03-25 20:21:37,413 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:37,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:37,417 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 20:21:39,684 : [INFO]  ------------------------- Batch round 3, loss: 0.5351 -------------------------
2023-03-25 20:21:39,684 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:39,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:39,689 : [INFO]  ------------------------- Batch 36 training: round 4 -------------------------
2023-03-25 20:21:41,857 : [INFO]  ------------------------- Batch round 4, loss: 0.5337 -------------------------
2023-03-25 20:21:41,857 : [INFO]  ------------------------- Batch 36, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:41,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:41,948 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 20:21:41,948 : [INFO]  ################ Batch 36: final global model evalution after 4 rounds ################
2023-03-25 20:21:43,342 : [INFO]  Batch 36: Training set : loss - 0.5331, accuracy - 0.7717, recall - 0.913, AUC - 0.8847, F1 - 0.8, precision - 0.7119, training time - -11.0 seconds
2023-03-25 20:21:43,343 : [INFO]  Batch 36: Testing set : loss - 0.5648, accuracy - 0.7451, recall - 0.8824, AUC - 0.8518, F1 - 0.7759, precision - 0.6923
2023-03-25 20:21:43,350 : [INFO]  Batch 37 initialized 
2023-03-25 20:21:43,804 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:44,124 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 20:21:47,955 : [INFO]  ------------------------- Batch round 1, loss: 0.5641 -------------------------
2023-03-25 20:21:47,955 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 20:21:48,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:48,071 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 20:21:50,260 : [INFO]  ------------------------- Batch round 2, loss: 0.5401 -------------------------
2023-03-25 20:21:50,260 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 20:21:50,281 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:50,283 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 20:21:52,482 : [INFO]  ------------------------- Batch round 3, loss: 0.5341 -------------------------
2023-03-25 20:21:52,482 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 20:21:52,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:52,488 : [INFO]  ------------------------- Batch 37 training: round 4 -------------------------
2023-03-25 20:21:54,598 : [INFO]  ------------------------- Batch round 4, loss: 0.5337 -------------------------
2023-03-25 20:21:54,599 : [INFO]  ------------------------- Batch 37, round 4: Sent local model to the server -------------------------
2023-03-25 20:21:54,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:21:54,671 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 20:21:54,671 : [INFO]  ################ Batch 37: final global model evalution after 4 rounds ################
2023-03-25 20:21:55,975 : [INFO]  Batch 37: Training set : loss - 0.5284, accuracy - 0.7609, recall - 0.9348, AUC - 0.9235, F1 - 0.7963, precision - 0.6935, training time - -11.0 seconds
2023-03-25 20:21:55,976 : [INFO]  Batch 37: Testing set : loss - 0.5827, accuracy - 0.701, recall - 0.8922, AUC - 0.8535, F1 - 0.749, precision - 0.6454
2023-03-25 20:21:55,988 : [INFO]  Batch 38 initialized 
2023-03-25 20:21:56,411 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:21:56,731 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 20:22:00,676 : [INFO]  ------------------------- Batch round 1, loss: 0.6012 -------------------------
2023-03-25 20:22:00,677 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 20:22:00,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:00,698 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 20:22:02,961 : [INFO]  ------------------------- Batch round 2, loss: 0.5852 -------------------------
2023-03-25 20:22:02,961 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 20:22:02,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:02,966 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 20:22:05,365 : [INFO]  ------------------------- Batch round 3, loss: 0.5685 -------------------------
2023-03-25 20:22:05,366 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 20:22:05,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:05,370 : [INFO]  ------------------------- Batch 38 training: round 4 -------------------------
2023-03-25 20:22:07,525 : [INFO]  ------------------------- Batch round 4, loss: 0.5584 -------------------------
2023-03-25 20:22:07,525 : [INFO]  ------------------------- Batch 38, round 4: Sent local model to the server -------------------------
2023-03-25 20:22:07,784 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:07,787 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 20:22:07,787 : [INFO]  ################ Batch 38: final global model evalution after 4 rounds ################
2023-03-25 20:22:09,163 : [INFO]  Batch 38: Training set : loss - 0.5513, accuracy - 0.7609, recall - 0.913, AUC - 0.8693, F1 - 0.7925, precision - 0.7, training time - -11.0 seconds
2023-03-25 20:22:09,163 : [INFO]  Batch 38: Testing set : loss - 0.5708, accuracy - 0.6961, recall - 0.8725, AUC - 0.8615, F1 - 0.7417, precision - 0.6449
2023-03-25 20:22:09,169 : [INFO]  Batch 39 initialized 
2023-03-25 20:22:09,598 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:22:09,929 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 20:22:13,769 : [INFO]  ------------------------- Batch round 1, loss: 0.5481 -------------------------
2023-03-25 20:22:13,769 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 20:22:13,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:13,800 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 20:22:15,912 : [INFO]  ------------------------- Batch round 2, loss: 0.5292 -------------------------
2023-03-25 20:22:15,912 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 20:22:15,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:15,917 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 20:22:17,960 : [INFO]  ------------------------- Batch round 3, loss: 0.5246 -------------------------
2023-03-25 20:22:17,960 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 20:22:17,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:17,965 : [INFO]  ------------------------- Batch 39 training: round 4 -------------------------
2023-03-25 20:22:20,025 : [INFO]  ------------------------- Batch round 4, loss: 0.5182 -------------------------
2023-03-25 20:22:20,025 : [INFO]  ------------------------- Batch 39, round 4: Sent local model to the server -------------------------
2023-03-25 20:22:20,028 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:20,030 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 20:22:20,030 : [INFO]  ################ Batch 39: final global model evalution after 4 rounds ################
2023-03-25 20:22:21,341 : [INFO]  Batch 39: Training set : loss - 0.5222, accuracy - 0.8152, recall - 0.9783, AUC - 0.9088, F1 - 0.8411, precision - 0.7377, training time - -10.0 seconds
2023-03-25 20:22:21,341 : [INFO]  Batch 39: Testing set : loss - 0.5531, accuracy - 0.7451, recall - 0.9216, AUC - 0.8946, F1 - 0.7833, precision - 0.6812
2023-03-25 20:22:21,353 : [INFO]  Batch 40 initialized 
2023-03-25 20:22:21,774 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:22:22,102 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 20:22:26,331 : [INFO]  ------------------------- Batch round 1, loss: 0.5546 -------------------------
2023-03-25 20:22:26,331 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 20:22:26,334 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:26,335 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 20:22:28,478 : [INFO]  ------------------------- Batch round 2, loss: 0.55 -------------------------
2023-03-25 20:22:28,478 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 20:22:28,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:22:28,485 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 20:22:31,067 : [INFO]  ------------------------- Batch round 3, loss: 0.536 -------------------------
2023-03-25 20:22:31,067 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 20:22:31,071 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
