2023-03-25 13:20:09,980 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 13:20:09,980 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 1, epochs 6
2023-03-25 13:20:12,489 : [INFO]  Model initialized for training
2023-03-25 13:20:28,074 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:20:28,395 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:20:28,396 : [INFO]  Connected to the server
2023-03-25 13:20:28,485 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:20:28,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:20:28,491 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:20:28,491 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:20:55,689 : [INFO]  ------------------------- Training round 1, loss: 0.6474 -------------------------
2023-03-25 13:20:55,690 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:20:55,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:20:55,694 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:21:21,297 : [INFO]  ------------------------- Training round 2, loss: 0.6068 -------------------------
2023-03-25 13:21:21,297 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:21:36,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:21:36,741 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:21:57,893 : [INFO]  ------------------------- Training round 3, loss: 0.5979 -------------------------
2023-03-25 13:21:57,893 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:21:58,114 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:21:58,116 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:22:21,969 : [INFO]  ------------------------- Training round 4, loss: 0.594 -------------------------
2023-03-25 13:22:21,969 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:22:22,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:22:22,053 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:23:03,084 : [INFO]  ------------------------- Training round 5, loss: 0.5924 -------------------------
2023-03-25 13:23:03,085 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:23:03,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:03,104 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:23:47,512 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.69, recall - 0.88, AUC - 0.84, F1 - 0.74, precision - 0.64, training time - -155.0 seconds
2023-03-25 13:23:47,512 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.88, AUC - 0.84, F1 - 0.74, precision - 0.64
2023-03-25 13:23:47,525 : [INFO]  Batch 1 initialized 
2023-03-25 13:23:47,966 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:23:48,086 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:23:48,086 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:23:52,261 : [INFO]  ------------------------- Batch round 1, loss: 0.5776 -------------------------
2023-03-25 13:23:52,261 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:23:52,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:52,399 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:23:54,837 : [INFO]  ------------------------- Batch round 2, loss: 0.561 -------------------------
2023-03-25 13:23:54,837 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:23:54,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:54,842 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:23:57,245 : [INFO]  ------------------------- Batch round 3, loss: 0.555 -------------------------
2023-03-25 13:23:57,245 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:23:57,249 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:23:57,250 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:23:57,251 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:23:58,575 : [INFO]  Batch 1: Training set : loss - 0.5513, accuracy - 0.7935, recall - 0.9348, AUC - 0.8902, F1 - 0.819, precision - 0.7288, training time - -9.0 seconds
2023-03-25 13:23:58,575 : [INFO]  Batch 1: Testing set : loss - 0.5744, accuracy - 0.7304, recall - 0.8922, AUC - 0.8656, F1 - 0.7679, precision - 0.6741
2023-03-25 13:23:58,584 : [INFO]  Batch 2 initialized 
2023-03-25 13:23:59,082 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:23:59,307 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:24:03,462 : [INFO]  ------------------------- Batch round 1, loss: 0.5605 -------------------------
2023-03-25 13:24:03,463 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:03,466 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:03,468 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:24:05,646 : [INFO]  ------------------------- Batch round 2, loss: 0.5485 -------------------------
2023-03-25 13:24:05,647 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:05,672 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:05,674 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:24:07,933 : [INFO]  ------------------------- Batch round 3, loss: 0.5343 -------------------------
2023-03-25 13:24:07,934 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:07,949 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:07,951 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:24:07,951 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:24:09,275 : [INFO]  Batch 2: Training set : loss - 0.5395, accuracy - 0.7554, recall - 0.9674, AUC - 0.9219, F1 - 0.7982, precision - 0.6794, training time - -9.0 seconds
2023-03-25 13:24:09,275 : [INFO]  Batch 2: Testing set : loss - 0.5725, accuracy - 0.701, recall - 0.902, AUC - 0.8754, F1 - 0.751, precision - 0.6434
2023-03-25 13:24:09,295 : [INFO]  Batch 3 initialized 
2023-03-25 13:24:09,739 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:10,010 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:24:14,073 : [INFO]  ------------------------- Batch round 1, loss: 0.5429 -------------------------
2023-03-25 13:24:14,073 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:14,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:14,181 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:24:16,468 : [INFO]  ------------------------- Batch round 2, loss: 0.5346 -------------------------
2023-03-25 13:24:16,468 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:16,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:16,530 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:24:18,816 : [INFO]  ------------------------- Batch round 3, loss: 0.5268 -------------------------
2023-03-25 13:24:18,816 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:18,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:18,929 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:24:18,929 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:24:20,331 : [INFO]  Batch 3: Training set : loss - 0.5289, accuracy - 0.7717, recall - 0.9239, AUC - 0.9025, F1 - 0.8019, precision - 0.7083, training time - -9.0 seconds
2023-03-25 13:24:20,331 : [INFO]  Batch 3: Testing set : loss - 0.5582, accuracy - 0.7206, recall - 0.951, AUC - 0.8792, F1 - 0.7729, precision - 0.651
2023-03-25 13:24:20,347 : [INFO]  Batch 4 initialized 
2023-03-25 13:24:20,841 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:21,134 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 13:24:25,347 : [INFO]  ------------------------- Batch round 1, loss: 0.5425 -------------------------
2023-03-25 13:24:25,347 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:25,386 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:25,388 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 13:24:27,771 : [INFO]  ------------------------- Batch round 2, loss: 0.5311 -------------------------
2023-03-25 13:24:27,771 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:27,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:27,777 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 13:24:30,096 : [INFO]  ------------------------- Batch round 3, loss: 0.5192 -------------------------
2023-03-25 13:24:30,096 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:30,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:30,102 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 13:24:30,102 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 13:24:31,450 : [INFO]  Batch 4: Training set : loss - 0.5143, accuracy - 0.788, recall - 0.9457, AUC - 0.9428, F1 - 0.8169, precision - 0.719, training time - -9.0 seconds
2023-03-25 13:24:31,450 : [INFO]  Batch 4: Testing set : loss - 0.5544, accuracy - 0.7206, recall - 0.9314, AUC - 0.8971, F1 - 0.7692, precision - 0.6552
2023-03-25 13:24:31,463 : [INFO]  Batch 5 initialized 
2023-03-25 13:24:31,885 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:32,131 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 13:24:36,374 : [INFO]  ------------------------- Batch round 1, loss: 0.5411 -------------------------
2023-03-25 13:24:36,374 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:36,378 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:36,379 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 13:24:38,759 : [INFO]  ------------------------- Batch round 2, loss: 0.5266 -------------------------
2023-03-25 13:24:38,759 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:38,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:38,982 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 13:24:41,534 : [INFO]  ------------------------- Batch round 3, loss: 0.522 -------------------------
2023-03-25 13:24:41,534 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:41,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:41,539 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 13:24:41,539 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 13:24:42,849 : [INFO]  Batch 5: Training set : loss - 0.52, accuracy - 0.8207, recall - 0.9891, AUC - 0.9487, F1 - 0.8465, precision - 0.7398, training time - -9.0 seconds
2023-03-25 13:24:42,849 : [INFO]  Batch 5: Testing set : loss - 0.5867, accuracy - 0.7059, recall - 0.8627, AUC - 0.8122, F1 - 0.7458, precision - 0.6567
2023-03-25 13:24:42,863 : [INFO]  Batch 6 initialized 
2023-03-25 13:24:43,296 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:43,531 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 13:24:47,734 : [INFO]  ------------------------- Batch round 1, loss: 0.567 -------------------------
2023-03-25 13:24:47,734 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:47,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:47,743 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 13:24:49,864 : [INFO]  ------------------------- Batch round 2, loss: 0.5609 -------------------------
2023-03-25 13:24:49,864 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 13:24:50,124 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:50,126 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 13:24:52,223 : [INFO]  ------------------------- Batch round 3, loss: 0.5518 -------------------------
2023-03-25 13:24:52,223 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 13:24:52,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:52,254 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 13:24:52,254 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 13:24:53,522 : [INFO]  Batch 6: Training set : loss - 0.5423, accuracy - 0.7826, recall - 0.9783, AUC - 0.9292, F1 - 0.8182, precision - 0.7031, training time - -9.0 seconds
2023-03-25 13:24:53,523 : [INFO]  Batch 6: Testing set : loss - 0.558, accuracy - 0.7157, recall - 0.902, AUC - 0.8931, F1 - 0.7603, precision - 0.6571
2023-03-25 13:24:53,533 : [INFO]  Batch 7 initialized 
2023-03-25 13:24:53,957 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:24:54,181 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 13:24:58,291 : [INFO]  ------------------------- Batch round 1, loss: 0.5683 -------------------------
2023-03-25 13:24:58,291 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 13:24:58,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:24:58,399 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 13:25:00,990 : [INFO]  ------------------------- Batch round 2, loss: 0.5574 -------------------------
2023-03-25 13:25:00,990 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:00,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:00,997 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 13:25:04,047 : [INFO]  ------------------------- Batch round 3, loss: 0.5537 -------------------------
2023-03-25 13:25:04,047 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:04,053 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:04,056 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 13:25:04,056 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 13:25:05,661 : [INFO]  Batch 7: Training set : loss - 0.5492, accuracy - 0.7446, recall - 0.9348, AUC - 0.8845, F1 - 0.7854, precision - 0.6772, training time - -10.0 seconds
2023-03-25 13:25:05,662 : [INFO]  Batch 7: Testing set : loss - 0.5676, accuracy - 0.7402, recall - 0.8725, AUC - 0.8537, F1 - 0.7706, precision - 0.6899
2023-03-25 13:25:05,668 : [INFO]  Batch 8 initialized 
2023-03-25 13:25:06,162 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:06,402 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 13:25:10,569 : [INFO]  ------------------------- Batch round 1, loss: 0.5628 -------------------------
2023-03-25 13:25:10,569 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:10,595 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:10,597 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 13:25:12,876 : [INFO]  ------------------------- Batch round 2, loss: 0.552 -------------------------
2023-03-25 13:25:12,876 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:12,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:12,881 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 13:25:15,038 : [INFO]  ------------------------- Batch round 3, loss: 0.5409 -------------------------
2023-03-25 13:25:15,038 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:15,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:15,055 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 13:25:15,055 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 13:25:16,719 : [INFO]  Batch 8: Training set : loss - 0.5459, accuracy - 0.7609, recall - 0.8804, AUC - 0.8943, F1 - 0.7864, precision - 0.7105, training time - -9.0 seconds
2023-03-25 13:25:16,719 : [INFO]  Batch 8: Testing set : loss - 0.5606, accuracy - 0.7255, recall - 0.902, AUC - 0.8783, F1 - 0.7667, precision - 0.6667
2023-03-25 13:25:16,731 : [INFO]  Batch 9 initialized 
2023-03-25 13:25:17,250 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:17,546 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 13:25:22,477 : [INFO]  ------------------------- Batch round 1, loss: 0.5444 -------------------------
2023-03-25 13:25:22,477 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:22,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:22,704 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 13:25:25,106 : [INFO]  ------------------------- Batch round 2, loss: 0.5386 -------------------------
2023-03-25 13:25:25,107 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:25,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:25,262 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 13:25:27,704 : [INFO]  ------------------------- Batch round 3, loss: 0.5248 -------------------------
2023-03-25 13:25:27,705 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:27,819 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:27,821 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 13:25:27,821 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 13:25:29,773 : [INFO]  Batch 9: Training set : loss - 0.5213, accuracy - 0.7935, recall - 0.9457, AUC - 0.9253, F1 - 0.8208, precision - 0.725, training time - -10.0 seconds
2023-03-25 13:25:29,773 : [INFO]  Batch 9: Testing set : loss - 0.5311, accuracy - 0.7402, recall - 0.8824, AUC - 0.9065, F1 - 0.7725, precision - 0.687
2023-03-25 13:25:29,788 : [INFO]  Batch 10 initialized 
2023-03-25 13:25:30,458 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:30,756 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 13:25:34,978 : [INFO]  ------------------------- Batch round 1, loss: 0.5439 -------------------------
2023-03-25 13:25:34,978 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:35,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:35,049 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 13:25:37,627 : [INFO]  ------------------------- Batch round 2, loss: 0.5341 -------------------------
2023-03-25 13:25:37,628 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:37,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:37,661 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 13:25:40,173 : [INFO]  ------------------------- Batch round 3, loss: 0.5322 -------------------------
2023-03-25 13:25:40,173 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:40,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:40,184 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 13:25:40,184 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 13:25:42,031 : [INFO]  Batch 10: Training set : loss - 0.5219, accuracy - 0.7935, recall - 0.9783, AUC - 0.9272, F1 - 0.8257, precision - 0.7143, training time - -9.0 seconds
2023-03-25 13:25:42,031 : [INFO]  Batch 10: Testing set : loss - 0.5596, accuracy - 0.7255, recall - 0.902, AUC - 0.8799, F1 - 0.7667, precision - 0.6667
2023-03-25 13:25:42,049 : [INFO]  Batch 11 initialized 
2023-03-25 13:25:42,494 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:42,820 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 13:25:47,418 : [INFO]  ------------------------- Batch round 1, loss: 0.5593 -------------------------
2023-03-25 13:25:47,418 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 13:25:47,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:47,453 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 13:25:49,800 : [INFO]  ------------------------- Batch round 2, loss: 0.5559 -------------------------
2023-03-25 13:25:49,800 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 13:25:49,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:49,805 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 13:25:52,532 : [INFO]  ------------------------- Batch round 3, loss: 0.538 -------------------------
2023-03-25 13:25:52,533 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 13:25:53,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:25:53,375 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 13:25:53,376 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 13:25:54,630 : [INFO]  Batch 11: Training set : loss - 0.5422, accuracy - 0.7337, recall - 0.9348, AUC - 0.9278, F1 - 0.7783, precision - 0.6667, training time - -11.0 seconds
2023-03-25 13:25:54,630 : [INFO]  Batch 11: Testing set : loss - 0.5473, accuracy - 0.7206, recall - 0.9412, AUC - 0.9248, F1 - 0.7711, precision - 0.6531
2023-03-25 13:25:54,638 : [INFO]  Batch 12 initialized 
2023-03-25 13:25:55,079 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:25:55,374 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 13:26:00,085 : [INFO]  ------------------------- Batch round 1, loss: 0.566 -------------------------
2023-03-25 13:26:00,085 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 13:26:00,088 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:00,090 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 13:26:02,567 : [INFO]  ------------------------- Batch round 2, loss: 0.5538 -------------------------
2023-03-25 13:26:02,567 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 13:26:02,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:02,572 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 13:26:05,454 : [INFO]  ------------------------- Batch round 3, loss: 0.5428 -------------------------
2023-03-25 13:26:05,454 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 13:26:05,788 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:05,790 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 13:26:05,790 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 13:26:07,259 : [INFO]  Batch 12: Training set : loss - 0.5368, accuracy - 0.7717, recall - 0.8478, AUC - 0.8769, F1 - 0.7879, precision - 0.7358, training time - -10.0 seconds
2023-03-25 13:26:07,259 : [INFO]  Batch 12: Testing set : loss - 0.5873, accuracy - 0.6765, recall - 0.8922, AUC - 0.8635, F1 - 0.7339, precision - 0.6233
2023-03-25 13:26:07,265 : [INFO]  Batch 13 initialized 
2023-03-25 13:26:08,075 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:26:08,360 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 13:26:12,632 : [INFO]  ------------------------- Batch round 1, loss: 0.5874 -------------------------
2023-03-25 13:26:12,632 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 13:26:12,737 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:12,740 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 13:26:15,475 : [INFO]  ------------------------- Batch round 2, loss: 0.577 -------------------------
2023-03-25 13:26:15,475 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 13:26:15,478 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:15,480 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 13:26:18,372 : [INFO]  ------------------------- Batch round 3, loss: 0.57 -------------------------
2023-03-25 13:26:18,373 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 13:26:18,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:26:18,406 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 13:26:18,406 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 13:26:20,953 : [INFO]  Batch 13: Training set : loss - 0.567, accuracy - 0.75, recall - 0.9239, AUC - 0.8523, F1 - 0.787, precision - 0.6855, training time - -10.0 seconds
2023-03-25 13:26:20,954 : [INFO]  Batch 13: Testing set : loss - 0.5883, accuracy - 0.6618, recall - 0.8235, AUC - 0.8213, F1 - 0.7089, precision - 0.6222
2023-03-25 13:26:20,966 : [INFO]  Batch 14 initialized 
2023-03-25 13:26:21,510 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:26:21,878 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 13:26:26,541 : [INFO]  ------------------------- Batch round 1, loss: 0.5522 -------------------------
2023-03-25 13:26:26,542 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 13:26:26,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
