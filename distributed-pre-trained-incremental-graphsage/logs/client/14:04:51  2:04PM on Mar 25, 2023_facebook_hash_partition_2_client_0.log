2023-03-25 14:04:51,731 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 14:04:51,731 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 1, epochs 8
2023-03-25 14:04:55,360 : [INFO]  Model initialized for training
2023-03-25 14:05:09,360 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:05:09,491 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 14:05:09,491 : [INFO]  Connected to the server
2023-03-25 14:05:09,585 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 14:05:09,586 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:05:09,594 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 14:05:09,594 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 14:05:36,194 : [INFO]  ------------------------- Training round 1, loss: 0.6768 -------------------------
2023-03-25 14:05:36,194 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 14:05:36,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:05:36,202 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 14:06:01,294 : [INFO]  ------------------------- Training round 2, loss: 0.6358 -------------------------
2023-03-25 14:06:01,295 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 14:06:01,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:06:01,299 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 14:06:27,965 : [INFO]  ------------------------- Training round 3, loss: 0.6146 -------------------------
2023-03-25 14:06:27,965 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 14:06:27,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:06:27,973 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 14:07:02,873 : [INFO]  ------------------------- Training round 4, loss: 0.606 -------------------------
2023-03-25 14:07:02,873 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 14:07:02,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:07:02,883 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 14:07:35,667 : [INFO]  ------------------------- Training round 5, loss: 0.6017 -------------------------
2023-03-25 14:07:35,667 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 14:07:35,672 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:07:35,674 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 14:08:33,816 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.82, F1 - 0.74, precision - 0.64, training time - -146.0 seconds
2023-03-25 14:08:33,816 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 14:08:33,831 : [INFO]  Batch 1 initialized 
2023-03-25 14:08:34,446 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:08:34,653 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 14:08:34,654 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 14:08:40,029 : [INFO]  ------------------------- Batch round 1, loss: 0.6063 -------------------------
2023-03-25 14:08:40,029 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 14:08:40,033 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:40,035 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 14:08:43,537 : [INFO]  ------------------------- Batch round 2, loss: 0.579 -------------------------
2023-03-25 14:08:43,538 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 14:08:43,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:43,543 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 14:08:47,044 : [INFO]  ------------------------- Batch round 3, loss: 0.5732 -------------------------
2023-03-25 14:08:47,044 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 14:08:47,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:47,051 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 14:08:47,051 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 14:08:48,618 : [INFO]  Batch 1: Training set : loss - 0.5766, accuracy - 0.7554, recall - 0.9348, AUC - 0.84, F1 - 0.7926, precision - 0.688, training time - -12.0 seconds
2023-03-25 14:08:48,619 : [INFO]  Batch 1: Testing set : loss - 0.5614, accuracy - 0.75, recall - 0.8627, AUC - 0.8618, F1 - 0.7753, precision - 0.704
2023-03-25 14:08:48,631 : [INFO]  Batch 2 initialized 
2023-03-25 14:08:49,214 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:08:49,383 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 14:08:55,402 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-25 14:08:55,402 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 14:08:55,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:55,410 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 14:08:59,192 : [INFO]  ------------------------- Batch round 2, loss: 0.5525 -------------------------
2023-03-25 14:08:59,192 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 14:08:59,196 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:08:59,201 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 14:09:02,306 : [INFO]  ------------------------- Batch round 3, loss: 0.5429 -------------------------
2023-03-25 14:09:02,306 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:02,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:02,450 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 14:09:02,450 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 14:09:03,965 : [INFO]  Batch 2: Training set : loss - 0.5431, accuracy - 0.7772, recall - 0.9565, AUC - 0.8964, F1 - 0.8111, precision - 0.704, training time - -13.0 seconds
2023-03-25 14:09:03,965 : [INFO]  Batch 2: Testing set : loss - 0.5635, accuracy - 0.7451, recall - 0.902, AUC - 0.8658, F1 - 0.7797, precision - 0.6866
2023-03-25 14:09:03,971 : [INFO]  Batch 3 initialized 
2023-03-25 14:09:04,501 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:04,779 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 14:09:10,440 : [INFO]  ------------------------- Batch round 1, loss: 0.5329 -------------------------
2023-03-25 14:09:10,440 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:10,443 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:10,446 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 14:09:13,759 : [INFO]  ------------------------- Batch round 2, loss: 0.5219 -------------------------
2023-03-25 14:09:13,759 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:13,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:13,766 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 14:09:17,190 : [INFO]  ------------------------- Batch round 3, loss: 0.5241 -------------------------
2023-03-25 14:09:17,190 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:17,193 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:17,196 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 14:09:17,196 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 14:09:18,723 : [INFO]  Batch 3: Training set : loss - 0.5286, accuracy - 0.7935, recall - 0.9022, AUC - 0.8686, F1 - 0.8137, precision - 0.7411, training time - -12.0 seconds
2023-03-25 14:09:18,723 : [INFO]  Batch 3: Testing set : loss - 0.5647, accuracy - 0.6961, recall - 0.951, AUC - 0.8665, F1 - 0.7578, precision - 0.6299
2023-03-25 14:09:18,735 : [INFO]  Batch 4 initialized 
2023-03-25 14:09:19,253 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:19,521 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 14:09:24,711 : [INFO]  ------------------------- Batch round 1, loss: 0.5482 -------------------------
2023-03-25 14:09:24,711 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:24,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:24,718 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 14:09:28,083 : [INFO]  ------------------------- Batch round 2, loss: 0.5345 -------------------------
2023-03-25 14:09:28,083 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:28,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:28,088 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 14:09:31,267 : [INFO]  ------------------------- Batch round 3, loss: 0.5286 -------------------------
2023-03-25 14:09:31,267 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:31,270 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:31,272 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 14:09:31,272 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 14:09:32,770 : [INFO]  Batch 4: Training set : loss - 0.5271, accuracy - 0.7772, recall - 0.9565, AUC - 0.9155, F1 - 0.8111, precision - 0.704, training time - -12.0 seconds
2023-03-25 14:09:32,770 : [INFO]  Batch 4: Testing set : loss - 0.5887, accuracy - 0.6471, recall - 0.9118, AUC - 0.864, F1 - 0.7209, precision - 0.5962
2023-03-25 14:09:32,781 : [INFO]  Batch 5 initialized 
2023-03-25 14:09:33,376 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:33,629 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 14:09:38,974 : [INFO]  ------------------------- Batch round 1, loss: 0.5424 -------------------------
2023-03-25 14:09:38,974 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:38,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:38,979 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 14:09:41,947 : [INFO]  ------------------------- Batch round 2, loss: 0.5339 -------------------------
2023-03-25 14:09:41,947 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:41,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:41,952 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 14:09:44,873 : [INFO]  ------------------------- Batch round 3, loss: 0.5209 -------------------------
2023-03-25 14:09:44,873 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 14:09:44,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:44,878 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 14:09:44,878 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 14:09:46,254 : [INFO]  Batch 5: Training set : loss - 0.52, accuracy - 0.788, recall - 0.9565, AUC - 0.9357, F1 - 0.8186, precision - 0.7154, training time - -11.0 seconds
2023-03-25 14:09:46,254 : [INFO]  Batch 5: Testing set : loss - 0.5838, accuracy - 0.6814, recall - 0.8725, AUC - 0.8209, F1 - 0.7325, precision - 0.6312
2023-03-25 14:09:46,261 : [INFO]  Batch 6 initialized 
2023-03-25 14:09:46,712 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:09:46,928 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 14:09:52,432 : [INFO]  ------------------------- Batch round 1, loss: 0.564 -------------------------
2023-03-25 14:09:52,432 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 14:09:52,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:52,441 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 14:09:56,817 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-25 14:09:56,817 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 14:09:57,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:09:57,515 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 14:10:02,502 : [INFO]  ------------------------- Batch round 3, loss: 0.551 -------------------------
2023-03-25 14:10:02,503 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:02,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:02,713 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 14:10:02,713 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 14:10:05,548 : [INFO]  Batch 6: Training set : loss - 0.5483, accuracy - 0.75, recall - 0.9565, AUC - 0.8756, F1 - 0.7928, precision - 0.6769, training time - -16.0 seconds
2023-03-25 14:10:05,548 : [INFO]  Batch 6: Testing set : loss - 0.5599, accuracy - 0.7255, recall - 0.902, AUC - 0.8818, F1 - 0.7667, precision - 0.6667
2023-03-25 14:10:05,560 : [INFO]  Batch 7 initialized 
2023-03-25 14:10:06,384 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:06,786 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 14:10:14,002 : [INFO]  ------------------------- Batch round 1, loss: 0.5745 -------------------------
2023-03-25 14:10:14,002 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 14:10:14,062 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:14,064 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 14:10:17,149 : [INFO]  ------------------------- Batch round 2, loss: 0.5644 -------------------------
2023-03-25 14:10:17,149 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 14:10:17,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:17,154 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 14:10:20,273 : [INFO]  ------------------------- Batch round 3, loss: 0.5523 -------------------------
2023-03-25 14:10:20,273 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:20,277 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:20,279 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 14:10:20,279 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 14:10:22,152 : [INFO]  Batch 7: Training set : loss - 0.5505, accuracy - 0.788, recall - 0.9457, AUC - 0.8667, F1 - 0.8169, precision - 0.719, training time - -13.0 seconds
2023-03-25 14:10:22,152 : [INFO]  Batch 7: Testing set : loss - 0.5861, accuracy - 0.6961, recall - 0.8431, AUC - 0.8112, F1 - 0.735, precision - 0.6515
2023-03-25 14:10:22,165 : [INFO]  Batch 8 initialized 
2023-03-25 14:10:22,768 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:23,012 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 14:10:30,247 : [INFO]  ------------------------- Batch round 1, loss: 0.5856 -------------------------
2023-03-25 14:10:30,247 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 14:10:30,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:30,257 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 14:10:34,360 : [INFO]  ------------------------- Batch round 2, loss: 0.5672 -------------------------
2023-03-25 14:10:34,360 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 14:10:34,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:34,370 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 14:10:38,011 : [INFO]  ------------------------- Batch round 3, loss: 0.5597 -------------------------
2023-03-25 14:10:38,011 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:38,016 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:38,019 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 14:10:38,019 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 14:10:39,708 : [INFO]  Batch 8: Training set : loss - 0.5655, accuracy - 0.7228, recall - 0.8804, AUC - 0.8391, F1 - 0.7606, precision - 0.6694, training time - -15.0 seconds
2023-03-25 14:10:39,708 : [INFO]  Batch 8: Testing set : loss - 0.5755, accuracy - 0.7255, recall - 0.8824, AUC - 0.8331, F1 - 0.7627, precision - 0.6716
2023-03-25 14:10:39,716 : [INFO]  Batch 9 initialized 
2023-03-25 14:10:40,265 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:40,518 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 14:10:45,887 : [INFO]  ------------------------- Batch round 1, loss: 0.5504 -------------------------
2023-03-25 14:10:45,887 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 14:10:45,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:45,893 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 14:10:49,219 : [INFO]  ------------------------- Batch round 2, loss: 0.5451 -------------------------
2023-03-25 14:10:49,219 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 14:10:49,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:49,250 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 14:10:52,515 : [INFO]  ------------------------- Batch round 3, loss: 0.5368 -------------------------
2023-03-25 14:10:52,515 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 14:10:52,738 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:10:52,739 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 14:10:52,740 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 14:10:54,288 : [INFO]  Batch 9: Training set : loss - 0.5302, accuracy - 0.7446, recall - 0.9348, AUC - 0.913, F1 - 0.7854, precision - 0.6772, training time - -12.0 seconds
2023-03-25 14:10:54,288 : [INFO]  Batch 9: Testing set : loss - 0.5477, accuracy - 0.7059, recall - 0.8824, AUC - 0.8837, F1 - 0.75, precision - 0.6522
2023-03-25 14:10:54,297 : [INFO]  Batch 10 initialized 
2023-03-25 14:10:54,813 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:10:55,081 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 14:11:00,654 : [INFO]  ------------------------- Batch round 1, loss: 0.5516 -------------------------
2023-03-25 14:11:00,654 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:00,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:00,659 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 14:11:03,896 : [INFO]  ------------------------- Batch round 2, loss: 0.5413 -------------------------
2023-03-25 14:11:03,896 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:03,899 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:03,901 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 14:11:07,394 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 14:11:07,394 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:07,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:07,398 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 14:11:07,398 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 14:11:08,906 : [INFO]  Batch 10: Training set : loss - 0.5311, accuracy - 0.7826, recall - 0.9783, AUC - 0.9204, F1 - 0.8182, precision - 0.7031, training time - -12.0 seconds
2023-03-25 14:11:08,907 : [INFO]  Batch 10: Testing set : loss - 0.5444, accuracy - 0.7304, recall - 0.902, AUC - 0.8948, F1 - 0.7699, precision - 0.6715
2023-03-25 14:11:08,917 : [INFO]  Batch 11 initialized 
2023-03-25 14:11:09,467 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:09,753 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 14:11:15,294 : [INFO]  ------------------------- Batch round 1, loss: 0.563 -------------------------
2023-03-25 14:11:15,294 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:15,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:15,299 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 14:11:18,776 : [INFO]  ------------------------- Batch round 2, loss: 0.5644 -------------------------
2023-03-25 14:11:18,776 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:18,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:18,781 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 14:11:22,154 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-25 14:11:22,154 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:22,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:22,160 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 14:11:22,160 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 14:11:23,706 : [INFO]  Batch 11: Training set : loss - 0.5567, accuracy - 0.7554, recall - 0.913, AUC - 0.8715, F1 - 0.7887, precision - 0.6942, training time - -12.0 seconds
2023-03-25 14:11:23,707 : [INFO]  Batch 11: Testing set : loss - 0.5558, accuracy - 0.7353, recall - 0.902, AUC - 0.8915, F1 - 0.7731, precision - 0.6765
2023-03-25 14:11:23,715 : [INFO]  Batch 12 initialized 
2023-03-25 14:11:24,216 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:24,500 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 14:11:29,874 : [INFO]  ------------------------- Batch round 1, loss: 0.5675 -------------------------
2023-03-25 14:11:29,874 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:29,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:29,879 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 14:11:33,256 : [INFO]  ------------------------- Batch round 2, loss: 0.5575 -------------------------
2023-03-25 14:11:33,256 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:33,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:33,261 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 14:11:36,536 : [INFO]  ------------------------- Batch round 3, loss: 0.5537 -------------------------
2023-03-25 14:11:36,536 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:36,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:36,543 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 14:11:36,543 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 14:11:38,128 : [INFO]  Batch 12: Training set : loss - 0.5495, accuracy - 0.7717, recall - 0.8913, AUC - 0.8811, F1 - 0.7961, precision - 0.7193, training time - -12.0 seconds
2023-03-25 14:11:38,128 : [INFO]  Batch 12: Testing set : loss - 0.6063, accuracy - 0.6765, recall - 0.8235, AUC - 0.8082, F1 - 0.7179, precision - 0.6364
2023-03-25 14:11:38,134 : [INFO]  Batch 13 initialized 
2023-03-25 14:11:38,628 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:38,901 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 14:11:44,149 : [INFO]  ------------------------- Batch round 1, loss: 0.5915 -------------------------
2023-03-25 14:11:44,149 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 14:11:44,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:44,172 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 14:11:47,352 : [INFO]  ------------------------- Batch round 2, loss: 0.5745 -------------------------
2023-03-25 14:11:47,353 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 14:11:47,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:47,359 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 14:11:50,902 : [INFO]  ------------------------- Batch round 3, loss: 0.5718 -------------------------
2023-03-25 14:11:50,903 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 14:11:50,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:11:50,909 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 14:11:50,909 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 14:11:54,594 : [INFO]  Batch 13: Training set : loss - 0.5745, accuracy - 0.7391, recall - 0.8696, AUC - 0.8318, F1 - 0.7692, precision - 0.6897, training time - -12.0 seconds
2023-03-25 14:11:54,595 : [INFO]  Batch 13: Testing set : loss - 0.603, accuracy - 0.6471, recall - 0.8039, AUC - 0.7889, F1 - 0.6949, precision - 0.6119
2023-03-25 14:11:54,621 : [INFO]  Batch 14 initialized 
2023-03-25 14:11:55,382 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:11:55,638 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 14:12:05,083 : [INFO]  ------------------------- Batch round 1, loss: 0.5495 -------------------------
2023-03-25 14:12:05,083 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:05,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:05,089 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 14:12:08,608 : [INFO]  ------------------------- Batch round 2, loss: 0.5345 -------------------------
2023-03-25 14:12:08,608 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:08,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:08,615 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 14:12:12,029 : [INFO]  ------------------------- Batch round 3, loss: 0.5258 -------------------------
2023-03-25 14:12:12,029 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:12,032 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:12,034 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 14:12:12,035 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 14:12:13,493 : [INFO]  Batch 14: Training set : loss - 0.5251, accuracy - 0.7989, recall - 0.9239, AUC - 0.899, F1 - 0.8213, precision - 0.7391, training time - -16.0 seconds
2023-03-25 14:12:13,493 : [INFO]  Batch 14: Testing set : loss - 0.5652, accuracy - 0.7108, recall - 0.8824, AUC - 0.868, F1 - 0.7531, precision - 0.6569
2023-03-25 14:12:13,502 : [INFO]  Batch 15 initialized 
2023-03-25 14:12:14,041 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:12:14,366 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 14:12:19,942 : [INFO]  ------------------------- Batch round 1, loss: 0.5674 -------------------------
2023-03-25 14:12:19,942 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:19,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:19,948 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 14:12:23,335 : [INFO]  ------------------------- Batch round 2, loss: 0.553 -------------------------
2023-03-25 14:12:23,335 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:23,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:23,346 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 14:12:27,057 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 14:12:27,057 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:27,061 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:27,063 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 14:12:27,063 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 14:12:28,610 : [INFO]  Batch 15: Training set : loss - 0.5338, accuracy - 0.7772, recall - 0.9239, AUC - 0.8922, F1 - 0.8057, precision - 0.7143, training time - -13.0 seconds
2023-03-25 14:12:28,610 : [INFO]  Batch 15: Testing set : loss - 0.5823, accuracy - 0.6912, recall - 0.8039, AUC - 0.8292, F1 - 0.7225, precision - 0.656
2023-03-25 14:12:28,619 : [INFO]  Batch 16 initialized 
2023-03-25 14:12:29,087 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:12:29,333 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 14:12:34,262 : [INFO]  ------------------------- Batch round 1, loss: 0.5545 -------------------------
2023-03-25 14:12:34,262 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:34,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:34,268 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 14:12:37,465 : [INFO]  ------------------------- Batch round 2, loss: 0.5434 -------------------------
2023-03-25 14:12:37,465 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:37,468 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:37,470 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 14:12:40,466 : [INFO]  ------------------------- Batch round 3, loss: 0.5341 -------------------------
2023-03-25 14:12:40,467 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:40,843 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:40,847 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 14:12:40,848 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 14:12:42,800 : [INFO]  Batch 16: Training set : loss - 0.5334, accuracy - 0.7663, recall - 0.913, AUC - 0.9019, F1 - 0.7962, precision - 0.7059, training time - -12.0 seconds
2023-03-25 14:12:42,801 : [INFO]  Batch 16: Testing set : loss - 0.5419, accuracy - 0.7549, recall - 0.9314, AUC - 0.8892, F1 - 0.7917, precision - 0.6884
2023-03-25 14:12:42,815 : [INFO]  Batch 17 initialized 
2023-03-25 14:12:43,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:12:43,907 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 14:12:49,499 : [INFO]  ------------------------- Batch round 1, loss: 0.5522 -------------------------
2023-03-25 14:12:49,500 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 14:12:49,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:49,505 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 14:12:52,831 : [INFO]  ------------------------- Batch round 2, loss: 0.5392 -------------------------
2023-03-25 14:12:52,831 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 14:12:52,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:52,836 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 14:12:55,751 : [INFO]  ------------------------- Batch round 3, loss: 0.5368 -------------------------
2023-03-25 14:12:55,751 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 14:12:55,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:12:55,756 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 14:12:55,756 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 14:12:57,216 : [INFO]  Batch 17: Training set : loss - 0.53, accuracy - 0.7772, recall - 0.9348, AUC - 0.8976, F1 - 0.8075, precision - 0.7107, training time - -12.0 seconds
2023-03-25 14:12:57,216 : [INFO]  Batch 17: Testing set : loss - 0.5738, accuracy - 0.7157, recall - 0.9118, AUC - 0.8716, F1 - 0.7623, precision - 0.6549
2023-03-25 14:12:57,227 : [INFO]  Batch 18 initialized 
2023-03-25 14:12:57,949 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:12:58,278 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 14:13:02,387 : [INFO]  ------------------------- Batch round 1, loss: 0.557 -------------------------
2023-03-25 14:13:02,387 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 14:13:02,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
