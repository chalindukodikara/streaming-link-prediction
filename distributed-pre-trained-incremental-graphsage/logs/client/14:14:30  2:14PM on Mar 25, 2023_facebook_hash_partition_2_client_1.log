2023-03-25 14:14:30,814 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 14:14:30,814 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 1, epochs 8
2023-03-25 14:14:33,255 : [INFO]  Model initialized for training
2023-03-25 14:14:47,656 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:14:47,842 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 14:14:47,843 : [INFO]  Connected to the server
2023-03-25 14:14:47,966 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 14:14:47,966 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:14:47,977 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 14:14:47,977 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 14:15:19,259 : [INFO]  ------------------------- Training round 1, loss: 0.6645 -------------------------
2023-03-25 14:15:19,259 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 14:15:24,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:15:24,959 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 14:15:52,617 : [INFO]  ------------------------- Training round 2, loss: 0.622 -------------------------
2023-03-25 14:15:52,617 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 14:15:52,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:15:52,623 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 14:16:19,875 : [INFO]  ------------------------- Training round 3, loss: 0.607 -------------------------
2023-03-25 14:16:19,875 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 14:16:19,878 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:16:19,881 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 14:16:46,491 : [INFO]  ------------------------- Training round 4, loss: 0.6017 -------------------------
2023-03-25 14:16:46,491 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 14:16:46,494 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:16:46,496 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 14:17:13,747 : [INFO]  ------------------------- Training round 5, loss: 0.6003 -------------------------
2023-03-25 14:17:13,747 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 14:17:13,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:17:13,753 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 14:18:08,050 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.82, F1 - 0.74, precision - 0.64, training time - -146.0 seconds
2023-03-25 14:18:08,050 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 14:18:08,060 : [INFO]  Batch 1 initialized 
2023-03-25 14:18:08,584 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:18:08,714 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 14:18:08,714 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 14:18:14,180 : [INFO]  ------------------------- Batch round 1, loss: 0.5836 -------------------------
2023-03-25 14:18:14,180 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 14:18:14,184 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:14,186 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 14:18:18,167 : [INFO]  ------------------------- Batch round 2, loss: 0.5696 -------------------------
2023-03-25 14:18:18,168 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 14:18:18,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:18,184 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 14:18:21,798 : [INFO]  ------------------------- Batch round 3, loss: 0.5591 -------------------------
2023-03-25 14:18:21,798 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 14:18:21,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:21,973 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 14:18:21,973 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 14:18:23,715 : [INFO]  Batch 1: Training set : loss - 0.5571, accuracy - 0.7663, recall - 0.913, AUC - 0.8756, F1 - 0.7962, precision - 0.7059, training time - -13.0 seconds
2023-03-25 14:18:23,715 : [INFO]  Batch 1: Testing set : loss - 0.5529, accuracy - 0.7402, recall - 0.902, AUC - 0.8906, F1 - 0.7764, precision - 0.6815
2023-03-25 14:18:23,729 : [INFO]  Batch 2 initialized 
2023-03-25 14:18:24,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:18:25,074 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 14:18:31,657 : [INFO]  ------------------------- Batch round 1, loss: 0.5426 -------------------------
2023-03-25 14:18:31,657 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 14:18:31,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:31,759 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 14:18:34,641 : [INFO]  ------------------------- Batch round 2, loss: 0.5364 -------------------------
2023-03-25 14:18:34,641 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 14:18:34,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:34,648 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 14:18:37,574 : [INFO]  ------------------------- Batch round 3, loss: 0.5297 -------------------------
2023-03-25 14:18:37,574 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 14:18:37,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:37,579 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 14:18:37,579 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 14:18:38,983 : [INFO]  Batch 2: Training set : loss - 0.5194, accuracy - 0.8315, recall - 0.9674, AUC - 0.909, F1 - 0.8517, precision - 0.7607, training time - -13.0 seconds
2023-03-25 14:18:38,983 : [INFO]  Batch 2: Testing set : loss - 0.5376, accuracy - 0.7892, recall - 0.9412, AUC - 0.909, F1 - 0.817, precision - 0.7218
2023-03-25 14:18:38,993 : [INFO]  Batch 3 initialized 
2023-03-25 14:18:39,425 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:18:39,658 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 14:18:44,466 : [INFO]  ------------------------- Batch round 1, loss: 0.5434 -------------------------
2023-03-25 14:18:44,466 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 14:18:44,469 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:44,471 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 14:18:47,484 : [INFO]  ------------------------- Batch round 2, loss: 0.5315 -------------------------
2023-03-25 14:18:47,484 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 14:18:47,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:47,490 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 14:18:50,890 : [INFO]  ------------------------- Batch round 3, loss: 0.5226 -------------------------
2023-03-25 14:18:50,890 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 14:18:50,893 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:50,895 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 14:18:50,895 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 14:18:52,360 : [INFO]  Batch 3: Training set : loss - 0.5255, accuracy - 0.8152, recall - 0.9565, AUC - 0.9309, F1 - 0.8381, precision - 0.7458, training time - -11.0 seconds
2023-03-25 14:18:52,360 : [INFO]  Batch 3: Testing set : loss - 0.5613, accuracy - 0.7255, recall - 0.9314, AUC - 0.9097, F1 - 0.7724, precision - 0.6597
2023-03-25 14:18:52,369 : [INFO]  Batch 4 initialized 
2023-03-25 14:18:52,845 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:18:53,081 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 14:18:59,158 : [INFO]  ------------------------- Batch round 1, loss: 0.559 -------------------------
2023-03-25 14:18:59,158 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 14:18:59,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:18:59,171 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 14:19:02,346 : [INFO]  ------------------------- Batch round 2, loss: 0.5415 -------------------------
2023-03-25 14:19:02,346 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 14:19:02,603 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:02,605 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 14:19:06,057 : [INFO]  ------------------------- Batch round 3, loss: 0.5334 -------------------------
2023-03-25 14:19:06,057 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 14:19:06,119 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:06,122 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 14:19:06,122 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 14:19:07,577 : [INFO]  Batch 4: Training set : loss - 0.5341, accuracy - 0.8098, recall - 0.9348, AUC - 0.9037, F1 - 0.8309, precision - 0.7478, training time - -13.0 seconds
2023-03-25 14:19:07,578 : [INFO]  Batch 4: Testing set : loss - 0.5513, accuracy - 0.7255, recall - 0.9412, AUC - 0.9286, F1 - 0.7742, precision - 0.6575
2023-03-25 14:19:07,590 : [INFO]  Batch 5 initialized 
2023-03-25 14:19:08,079 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:19:08,326 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 14:19:13,640 : [INFO]  ------------------------- Batch round 1, loss: 0.5428 -------------------------
2023-03-25 14:19:13,640 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 14:19:13,698 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:13,700 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 14:19:17,026 : [INFO]  ------------------------- Batch round 2, loss: 0.5329 -------------------------
2023-03-25 14:19:17,026 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 14:19:17,030 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:17,032 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 14:19:20,608 : [INFO]  ------------------------- Batch round 3, loss: 0.5256 -------------------------
2023-03-25 14:19:20,608 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 14:19:20,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:20,614 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 14:19:20,614 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 14:19:22,212 : [INFO]  Batch 5: Training set : loss - 0.5283, accuracy - 0.8098, recall - 0.9348, AUC - 0.9005, F1 - 0.8309, precision - 0.7478, training time - -12.0 seconds
2023-03-25 14:19:22,212 : [INFO]  Batch 5: Testing set : loss - 0.5462, accuracy - 0.7353, recall - 0.902, AUC - 0.9018, F1 - 0.7731, precision - 0.6765
2023-03-25 14:19:22,229 : [INFO]  Batch 6 initialized 
2023-03-25 14:19:22,783 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:19:23,078 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 14:19:28,016 : [INFO]  ------------------------- Batch round 1, loss: 0.5494 -------------------------
2023-03-25 14:19:28,017 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 14:19:28,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:28,241 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 14:19:31,506 : [INFO]  ------------------------- Batch round 2, loss: 0.529 -------------------------
2023-03-25 14:19:31,506 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 14:19:31,509 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:31,512 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 14:19:34,540 : [INFO]  ------------------------- Batch round 3, loss: 0.5242 -------------------------
2023-03-25 14:19:34,541 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 14:19:34,545 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:34,548 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 14:19:34,549 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 14:19:35,910 : [INFO]  Batch 6: Training set : loss - 0.5112, accuracy - 0.8261, recall - 0.9348, AUC - 0.9065, F1 - 0.8431, precision - 0.7679, training time - -11.0 seconds
2023-03-25 14:19:35,910 : [INFO]  Batch 6: Testing set : loss - 0.5661, accuracy - 0.701, recall - 0.902, AUC - 0.8751, F1 - 0.751, precision - 0.6434
2023-03-25 14:19:35,919 : [INFO]  Batch 7 initialized 
2023-03-25 14:19:36,405 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:19:36,650 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 14:19:42,230 : [INFO]  ------------------------- Batch round 1, loss: 0.5371 -------------------------
2023-03-25 14:19:42,231 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 14:19:42,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:42,235 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 14:19:45,513 : [INFO]  ------------------------- Batch round 2, loss: 0.5249 -------------------------
2023-03-25 14:19:45,513 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 14:19:45,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:45,554 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 14:19:48,624 : [INFO]  ------------------------- Batch round 3, loss: 0.5202 -------------------------
2023-03-25 14:19:48,624 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 14:19:48,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:48,630 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 14:19:48,630 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 14:19:50,125 : [INFO]  Batch 7: Training set : loss - 0.5178, accuracy - 0.8043, recall - 0.9348, AUC - 0.908, F1 - 0.8269, precision - 0.7414, training time - -12.0 seconds
2023-03-25 14:19:50,125 : [INFO]  Batch 7: Testing set : loss - 0.5747, accuracy - 0.6912, recall - 0.8922, AUC - 0.8657, F1 - 0.7429, precision - 0.6364
2023-03-25 14:19:50,132 : [INFO]  Batch 8 initialized 
2023-03-25 14:19:50,639 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:19:50,969 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 14:19:56,324 : [INFO]  ------------------------- Batch round 1, loss: 0.5652 -------------------------
2023-03-25 14:19:56,325 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 14:19:56,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:56,330 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 14:19:59,505 : [INFO]  ------------------------- Batch round 2, loss: 0.546 -------------------------
2023-03-25 14:19:59,505 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 14:19:59,509 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:19:59,511 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 14:20:02,687 : [INFO]  ------------------------- Batch round 3, loss: 0.5455 -------------------------
2023-03-25 14:20:02,687 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 14:20:02,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:02,692 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 14:20:02,692 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 14:20:04,076 : [INFO]  Batch 8: Training set : loss - 0.5524, accuracy - 0.7609, recall - 0.9348, AUC - 0.8871, F1 - 0.7963, precision - 0.6935, training time - -12.0 seconds
2023-03-25 14:20:04,077 : [INFO]  Batch 8: Testing set : loss - 0.5837, accuracy - 0.6961, recall - 0.8725, AUC - 0.8492, F1 - 0.7417, precision - 0.6449
2023-03-25 14:20:04,089 : [INFO]  Batch 9 initialized 
2023-03-25 14:20:04,558 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:20:04,824 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 14:20:11,545 : [INFO]  ------------------------- Batch round 1, loss: 0.582 -------------------------
2023-03-25 14:20:11,545 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 14:20:11,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:11,555 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 14:20:15,191 : [INFO]  ------------------------- Batch round 2, loss: 0.5635 -------------------------
2023-03-25 14:20:15,191 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 14:20:15,194 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:15,196 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 14:20:18,726 : [INFO]  ------------------------- Batch round 3, loss: 0.551 -------------------------
2023-03-25 14:20:18,726 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 14:20:18,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:18,731 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 14:20:18,731 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 14:20:20,247 : [INFO]  Batch 9: Training set : loss - 0.5595, accuracy - 0.7446, recall - 0.8804, AUC - 0.8598, F1 - 0.7751, precision - 0.6923, training time - -14.0 seconds
2023-03-25 14:20:20,247 : [INFO]  Batch 9: Testing set : loss - 0.6092, accuracy - 0.6569, recall - 0.8137, AUC - 0.7899, F1 - 0.7034, precision - 0.6194
2023-03-25 14:20:20,260 : [INFO]  Batch 10 initialized 
2023-03-25 14:20:20,774 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:20:21,032 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 14:20:26,755 : [INFO]  ------------------------- Batch round 1, loss: 0.5531 -------------------------
2023-03-25 14:20:26,755 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 14:20:26,759 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:26,761 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 14:20:30,592 : [INFO]  ------------------------- Batch round 2, loss: 0.5359 -------------------------
2023-03-25 14:20:30,592 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 14:20:30,597 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:30,599 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 14:20:33,886 : [INFO]  ------------------------- Batch round 3, loss: 0.5191 -------------------------
2023-03-25 14:20:33,886 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 14:20:33,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:33,891 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 14:20:33,891 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 14:20:35,392 : [INFO]  Batch 10: Training set : loss - 0.5175, accuracy - 0.7989, recall - 0.9457, AUC - 0.8886, F1 - 0.8246, precision - 0.7311, training time - -13.0 seconds
2023-03-25 14:20:35,392 : [INFO]  Batch 10: Testing set : loss - 0.5695, accuracy - 0.7059, recall - 0.902, AUC - 0.8753, F1 - 0.7541, precision - 0.6479
2023-03-25 14:20:35,405 : [INFO]  Batch 11 initialized 
2023-03-25 14:20:35,867 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:20:36,162 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 14:20:41,935 : [INFO]  ------------------------- Batch round 1, loss: 0.5708 -------------------------
2023-03-25 14:20:41,935 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 14:20:41,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:41,942 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 14:20:45,191 : [INFO]  ------------------------- Batch round 2, loss: 0.5617 -------------------------
2023-03-25 14:20:45,191 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 14:20:45,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:45,213 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 14:20:48,724 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-25 14:20:48,724 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 14:20:48,728 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:48,730 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 14:20:48,730 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 14:20:50,264 : [INFO]  Batch 11: Training set : loss - 0.5512, accuracy - 0.7772, recall - 0.8913, AUC - 0.8616, F1 - 0.8, precision - 0.7257, training time - -13.0 seconds
2023-03-25 14:20:50,265 : [INFO]  Batch 11: Testing set : loss - 0.5616, accuracy - 0.7304, recall - 0.9314, AUC - 0.9022, F1 - 0.7755, precision - 0.6643
2023-03-25 14:20:50,271 : [INFO]  Batch 12 initialized 
2023-03-25 14:20:50,762 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:20:51,090 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 14:20:56,646 : [INFO]  ------------------------- Batch round 1, loss: 0.5604 -------------------------
2023-03-25 14:20:56,647 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 14:20:56,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:20:56,820 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 14:20:59,985 : [INFO]  ------------------------- Batch round 2, loss: 0.5469 -------------------------
2023-03-25 14:20:59,985 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 14:21:00,230 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:00,233 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 14:21:03,761 : [INFO]  ------------------------- Batch round 3, loss: 0.5428 -------------------------
2023-03-25 14:21:03,762 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 14:21:03,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:03,767 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 14:21:03,767 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 14:21:05,213 : [INFO]  Batch 12: Training set : loss - 0.5377, accuracy - 0.8043, recall - 0.913, AUC - 0.8768, F1 - 0.8235, precision - 0.75, training time - -13.0 seconds
2023-03-25 14:21:05,213 : [INFO]  Batch 12: Testing set : loss - 0.5743, accuracy - 0.701, recall - 0.8824, AUC - 0.8472, F1 - 0.7469, precision - 0.6475
2023-03-25 14:21:05,220 : [INFO]  Batch 13 initialized 
2023-03-25 14:21:05,685 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:21:05,972 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 14:21:11,221 : [INFO]  ------------------------- Batch round 1, loss: 0.535 -------------------------
2023-03-25 14:21:11,221 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 14:21:11,334 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:11,336 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 14:21:14,341 : [INFO]  ------------------------- Batch round 2, loss: 0.5249 -------------------------
2023-03-25 14:21:14,341 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 14:21:14,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:14,376 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 14:21:17,766 : [INFO]  ------------------------- Batch round 3, loss: 0.5188 -------------------------
2023-03-25 14:21:17,766 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 14:21:17,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:17,771 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 14:21:17,771 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 14:21:19,244 : [INFO]  Batch 13: Training set : loss - 0.5242, accuracy - 0.7935, recall - 0.913, AUC - 0.8924, F1 - 0.8155, precision - 0.7368, training time - -12.0 seconds
2023-03-25 14:21:19,244 : [INFO]  Batch 13: Testing set : loss - 0.56, accuracy - 0.6961, recall - 0.9216, AUC - 0.9048, F1 - 0.752, precision - 0.6351
2023-03-25 14:21:19,252 : [INFO]  Batch 14 initialized 
2023-03-25 14:21:19,820 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:21:20,096 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 14:21:25,372 : [INFO]  ------------------------- Batch round 1, loss: 0.5383 -------------------------
2023-03-25 14:21:25,372 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 14:21:25,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:25,658 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 14:21:28,895 : [INFO]  ------------------------- Batch round 2, loss: 0.5272 -------------------------
2023-03-25 14:21:28,896 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 14:21:28,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:28,950 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 14:21:32,318 : [INFO]  ------------------------- Batch round 3, loss: 0.5183 -------------------------
2023-03-25 14:21:32,318 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 14:21:32,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:32,373 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 14:21:32,373 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 14:21:33,770 : [INFO]  Batch 14: Training set : loss - 0.5171, accuracy - 0.788, recall - 0.9348, AUC - 0.9183, F1 - 0.8152, precision - 0.7227, training time - -12.0 seconds
2023-03-25 14:21:33,770 : [INFO]  Batch 14: Testing set : loss - 0.5544, accuracy - 0.7304, recall - 0.9118, AUC - 0.9145, F1 - 0.7718, precision - 0.6691
2023-03-25 14:21:33,776 : [INFO]  Batch 15 initialized 
2023-03-25 14:21:34,222 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:21:34,493 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 14:21:40,116 : [INFO]  ------------------------- Batch round 1, loss: 0.5895 -------------------------
2023-03-25 14:21:40,116 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 14:21:40,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:40,318 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 14:21:43,633 : [INFO]  ------------------------- Batch round 2, loss: 0.5833 -------------------------
2023-03-25 14:21:43,634 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 14:21:43,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:43,641 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 14:21:47,153 : [INFO]  ------------------------- Batch round 3, loss: 0.5777 -------------------------
2023-03-25 14:21:47,153 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 14:21:47,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:47,289 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 14:21:47,289 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 14:21:48,742 : [INFO]  Batch 15: Training set : loss - 0.5751, accuracy - 0.7174, recall - 0.9457, AUC - 0.8596, F1 - 0.7699, precision - 0.6493, training time - -13.0 seconds
2023-03-25 14:21:48,743 : [INFO]  Batch 15: Testing set : loss - 0.5641, accuracy - 0.7108, recall - 0.951, AUC - 0.8863, F1 - 0.7668, precision - 0.6424
2023-03-25 14:21:48,749 : [INFO]  Batch 16 initialized 
2023-03-25 14:21:49,320 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:21:49,613 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 14:21:55,016 : [INFO]  ------------------------- Batch round 1, loss: 0.569 -------------------------
2023-03-25 14:21:55,016 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 14:21:55,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:55,021 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 14:21:58,470 : [INFO]  ------------------------- Batch round 2, loss: 0.562 -------------------------
2023-03-25 14:21:58,471 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 14:21:58,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:21:58,476 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 14:22:01,620 : [INFO]  ------------------------- Batch round 3, loss: 0.5548 -------------------------
2023-03-25 14:22:01,621 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 14:22:01,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:22:01,792 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 14:22:01,792 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 14:22:03,457 : [INFO]  Batch 16: Training set : loss - 0.5497, accuracy - 0.7717, recall - 0.913, AUC - 0.8859, F1 - 0.8, precision - 0.7119, training time - -12.0 seconds
2023-03-25 14:22:03,458 : [INFO]  Batch 16: Testing set : loss - 0.5646, accuracy - 0.7206, recall - 0.902, AUC - 0.8803, F1 - 0.7635, precision - 0.6619
2023-03-25 14:22:03,464 : [INFO]  Batch 17 initialized 
2023-03-25 14:22:03,961 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:22:04,225 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 14:22:09,673 : [INFO]  ------------------------- Batch round 1, loss: 0.5309 -------------------------
2023-03-25 14:22:09,673 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 14:22:09,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:22:09,678 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 14:22:13,875 : [INFO]  ------------------------- Batch round 2, loss: 0.5153 -------------------------
2023-03-25 14:22:13,876 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 14:22:13,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:22:13,880 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 14:22:17,440 : [INFO]  ------------------------- Batch round 3, loss: 0.5063 -------------------------
2023-03-25 14:22:17,440 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 14:22:17,811 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:22:17,813 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 14:22:17,813 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 14:22:19,120 : [INFO]  Batch 17: Training set : loss - 0.5041, accuracy - 0.8207, recall - 0.9457, AUC - 0.9271, F1 - 0.8406, precision - 0.7565, training time - -14.0 seconds
2023-03-25 14:22:19,120 : [INFO]  Batch 17: Testing set : loss - 0.5612, accuracy - 0.7353, recall - 0.9804, AUC - 0.909, F1 - 0.7874, precision - 0.6579
2023-03-25 14:22:19,125 : [INFO]  Batch 18 initialized 
2023-03-25 14:22:19,554 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:22:19,829 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 14:22:24,781 : [INFO]  ------------------------- Batch round 1, loss: 0.5733 -------------------------
2023-03-25 14:22:24,781 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 14:22:24,784 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:22:24,786 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 14:22:28,066 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-25 14:22:28,066 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 14:22:28,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:22:28,071 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 14:22:33,566 : [INFO]  ------------------------- Batch round 3, loss: 0.5536 -------------------------
2023-03-25 14:22:33,566 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 14:22:33,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:22:33,576 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 14:22:33,576 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 14:22:36,279 : [INFO]  Batch 18: Training set : loss - 0.5518, accuracy - 0.7446, recall - 0.9022, AUC - 0.8605, F1 - 0.7793, precision - 0.686, training time - -14.0 seconds
2023-03-25 14:22:36,279 : [INFO]  Batch 18: Testing set : loss - 0.5894, accuracy - 0.7059, recall - 0.8431, AUC - 0.8013, F1 - 0.7414, precision - 0.6615
2023-03-25 14:22:36,291 : [INFO]  Batch 19 initialized 
2023-03-25 14:22:37,170 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:22:37,461 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
