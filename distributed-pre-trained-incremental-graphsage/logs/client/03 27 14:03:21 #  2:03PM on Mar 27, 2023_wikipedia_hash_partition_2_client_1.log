2023-03-27 14:03:21,676 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-27 14:03:21,676 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 1, training epochs 6, epochs 6
2023-03-27 14:03:24,561 : [INFO]  Model initialized for training
2023-03-27 14:03:26,978 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:03:27,002 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-27 14:03:27,003 : [INFO]  Connected to the server
2023-03-27 14:03:27,135 : [INFO]  Distributed training for streaming graphs started!
2023-03-27 14:03:27,136 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:03:27,150 : [INFO]  ################################## Initial model training started ##################################
2023-03-27 14:03:27,150 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-27 14:03:52,354 : [INFO]  ------------------------- Training round 1, loss: 0.6609 -------------------------
2023-03-27 14:03:52,354 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-27 14:03:52,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:03:52,358 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-27 14:04:15,977 : [INFO]  ------------------------- Training round 2, loss: 0.5977 -------------------------
2023-03-27 14:04:15,977 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-27 14:04:16,388 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:04:16,390 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-27 14:04:37,495 : [INFO]  ------------------------- Training round 3, loss: 0.5849 -------------------------
2023-03-27 14:04:37,495 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-27 14:04:37,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:04:37,586 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-27 14:04:56,879 : [INFO]  ------------------------- Training round 4, loss: 0.5766 -------------------------
2023-03-27 14:04:56,880 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-27 14:04:57,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:04:57,108 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-27 14:05:16,507 : [INFO]  ------------------------- Training round 5, loss: 0.5733 -------------------------
2023-03-27 14:05:16,507 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-27 14:05:16,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:16,660 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-27 14:05:36,615 : [INFO]  ------------------------- Training round 6, loss: 0.5707 -------------------------
2023-03-27 14:05:36,615 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-27 14:05:36,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:36,693 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-27 14:05:43,935 : [INFO]  Initially trained model: Training set : loss - 0.57, accuracy - 0.73, recall - 0.9, AUC - 0.87, F1 - 0.77, precision - 0.67, training time - -130.0 seconds
2023-03-27 14:05:43,935 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.73, recall - 0.91, AUC - 0.87, F1 - 0.77, precision - 0.67
2023-03-27 14:05:43,944 : [INFO]  Batch 1 initialized 
2023-03-27 14:05:44,345 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:05:44,450 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-27 14:05:44,450 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-27 14:05:48,371 : [INFO]  ------------------------- Batch round 1, loss: 0.5521 -------------------------
2023-03-27 14:05:48,372 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-27 14:05:48,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:48,578 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-27 14:05:50,821 : [INFO]  ------------------------- Batch round 2, loss: 0.5445 -------------------------
2023-03-27 14:05:50,821 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-27 14:05:50,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:50,879 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-27 14:05:53,030 : [INFO]  ------------------------- Batch round 3, loss: 0.54 -------------------------
2023-03-27 14:05:53,030 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-27 14:05:53,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:53,099 : [INFO]  Batch number 1 model fetched from the server
2023-03-27 14:05:53,099 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-27 14:05:54,717 : [INFO]  Batch 1: Training set : loss - 0.538, accuracy - 0.788, recall - 0.9783, AUC - 0.8882, F1 - 0.8219, precision - 0.7087, training time - -9.0 seconds
2023-03-27 14:05:54,718 : [INFO]  Batch 1: Testing set : loss - 0.5562, accuracy - 0.7696, recall - 0.9804, AUC - 0.8927, F1 - 0.8097, precision - 0.6897
2023-03-27 14:05:54,728 : [INFO]  Batch 2 initialized 
2023-03-27 14:05:55,187 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:05:55,315 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-27 14:05:59,347 : [INFO]  ------------------------- Batch round 1, loss: 0.5838 -------------------------
2023-03-27 14:05:59,347 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-27 14:05:59,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:05:59,394 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-27 14:06:01,697 : [INFO]  ------------------------- Batch round 2, loss: 0.5792 -------------------------
2023-03-27 14:06:01,697 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:01,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:01,703 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-27 14:06:03,923 : [INFO]  ------------------------- Batch round 3, loss: 0.5748 -------------------------
2023-03-27 14:06:03,923 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:03,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:03,928 : [INFO]  Batch number 2 model fetched from the server
2023-03-27 14:06:03,928 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-27 14:06:05,325 : [INFO]  Batch 2: Training set : loss - 0.5802, accuracy - 0.7446, recall - 0.9674, AUC - 0.8256, F1 - 0.7911, precision - 0.6692, training time - -9.0 seconds
2023-03-27 14:06:05,325 : [INFO]  Batch 2: Testing set : loss - 0.5738, accuracy - 0.7549, recall - 0.9412, AUC - 0.8417, F1 - 0.7934, precision - 0.6857
2023-03-27 14:06:05,329 : [INFO]  Batch 3 initialized 
2023-03-27 14:06:05,797 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:06,024 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-27 14:06:10,522 : [INFO]  ------------------------- Batch round 1, loss: 0.5565 -------------------------
2023-03-27 14:06:10,523 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:10,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:10,593 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-27 14:06:14,115 : [INFO]  ------------------------- Batch round 2, loss: 0.5508 -------------------------
2023-03-27 14:06:14,115 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:14,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:14,120 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-27 14:06:16,290 : [INFO]  ------------------------- Batch round 3, loss: 0.5445 -------------------------
2023-03-27 14:06:16,290 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:16,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:16,344 : [INFO]  Batch number 3 model fetched from the server
2023-03-27 14:06:16,344 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-27 14:06:17,739 : [INFO]  Batch 3: Training set : loss - 0.5373, accuracy - 0.7935, recall - 0.9674, AUC - 0.8794, F1 - 0.8241, precision - 0.7177, training time - -10.0 seconds
2023-03-27 14:06:17,739 : [INFO]  Batch 3: Testing set : loss - 0.5814, accuracy - 0.7304, recall - 0.951, AUC - 0.834, F1 - 0.7791, precision - 0.6599
2023-03-27 14:06:17,743 : [INFO]  Batch 4 initialized 
2023-03-27 14:06:18,380 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:18,633 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-27 14:06:22,633 : [INFO]  ------------------------- Batch round 1, loss: 0.5552 -------------------------
2023-03-27 14:06:22,633 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:22,757 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:22,759 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-27 14:06:25,136 : [INFO]  ------------------------- Batch round 2, loss: 0.5532 -------------------------
2023-03-27 14:06:25,137 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:25,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:25,141 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-27 14:06:27,430 : [INFO]  ------------------------- Batch round 3, loss: 0.5476 -------------------------
2023-03-27 14:06:27,430 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:27,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:27,435 : [INFO]  Batch number 4 model fetched from the server
2023-03-27 14:06:27,435 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-27 14:06:28,798 : [INFO]  Batch 4: Training set : loss - 0.5464, accuracy - 0.7446, recall - 0.9348, AUC - 0.9006, F1 - 0.7854, precision - 0.6772, training time - -9.0 seconds
2023-03-27 14:06:28,798 : [INFO]  Batch 4: Testing set : loss - 0.5414, accuracy - 0.7696, recall - 0.951, AUC - 0.9027, F1 - 0.805, precision - 0.6978
2023-03-27 14:06:28,807 : [INFO]  Batch 5 initialized 
2023-03-27 14:06:29,219 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:29,433 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-27 14:06:33,643 : [INFO]  ------------------------- Batch round 1, loss: 0.565 -------------------------
2023-03-27 14:06:33,643 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:33,646 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:33,647 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-27 14:06:35,861 : [INFO]  ------------------------- Batch round 2, loss: 0.5603 -------------------------
2023-03-27 14:06:35,861 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:35,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:35,865 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-27 14:06:38,069 : [INFO]  ------------------------- Batch round 3, loss: 0.561 -------------------------
2023-03-27 14:06:38,070 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:38,073 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:38,075 : [INFO]  Batch number 5 model fetched from the server
2023-03-27 14:06:38,075 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-27 14:06:39,439 : [INFO]  Batch 5: Training set : loss - 0.5574, accuracy - 0.7337, recall - 0.9457, AUC - 0.8949, F1 - 0.7803, precision - 0.6641, training time - -9.0 seconds
2023-03-27 14:06:39,439 : [INFO]  Batch 5: Testing set : loss - 0.5809, accuracy - 0.7108, recall - 0.8922, AUC - 0.8431, F1 - 0.7552, precision - 0.6547
2023-03-27 14:06:39,450 : [INFO]  Batch 6 initialized 
2023-03-27 14:06:39,859 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:40,098 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-27 14:06:44,138 : [INFO]  ------------------------- Batch round 1, loss: 0.5677 -------------------------
2023-03-27 14:06:44,138 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:44,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:44,258 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-27 14:06:46,469 : [INFO]  ------------------------- Batch round 2, loss: 0.5601 -------------------------
2023-03-27 14:06:46,469 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:46,559 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:46,562 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-27 14:06:48,882 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-27 14:06:48,882 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-27 14:06:49,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:49,041 : [INFO]  Batch number 6 model fetched from the server
2023-03-27 14:06:49,041 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-27 14:06:50,484 : [INFO]  Batch 6: Training set : loss - 0.5602, accuracy - 0.75, recall - 0.9457, AUC - 0.8735, F1 - 0.7909, precision - 0.6797, training time - -9.0 seconds
2023-03-27 14:06:50,484 : [INFO]  Batch 6: Testing set : loss - 0.5498, accuracy - 0.7598, recall - 0.951, AUC - 0.8966, F1 - 0.7984, precision - 0.6879
2023-03-27 14:06:50,495 : [INFO]  Batch 7 initialized 
2023-03-27 14:06:50,944 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:06:51,181 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-27 14:06:55,442 : [INFO]  ------------------------- Batch round 1, loss: 0.538 -------------------------
2023-03-27 14:06:55,442 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-27 14:06:55,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:55,560 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-27 14:06:58,113 : [INFO]  ------------------------- Batch round 2, loss: 0.5292 -------------------------
2023-03-27 14:06:58,113 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-27 14:06:58,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:06:58,224 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-27 14:07:00,541 : [INFO]  ------------------------- Batch round 3, loss: 0.5231 -------------------------
2023-03-27 14:07:00,541 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:00,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:00,546 : [INFO]  Batch number 7 model fetched from the server
2023-03-27 14:07:00,546 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-27 14:07:02,307 : [INFO]  Batch 7: Training set : loss - 0.5199, accuracy - 0.8315, recall - 0.913, AUC - 0.9115, F1 - 0.8442, precision - 0.785, training time - -9.0 seconds
2023-03-27 14:07:02,307 : [INFO]  Batch 7: Testing set : loss - 0.5642, accuracy - 0.7598, recall - 0.9314, AUC - 0.8492, F1 - 0.795, precision - 0.6934
2023-03-27 14:07:02,311 : [INFO]  Batch 8 initialized 
2023-03-27 14:07:02,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:02,971 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-27 14:07:07,517 : [INFO]  ------------------------- Batch round 1, loss: 0.5588 -------------------------
2023-03-27 14:07:07,518 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:07,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:07,527 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-27 14:07:09,894 : [INFO]  ------------------------- Batch round 2, loss: 0.5544 -------------------------
2023-03-27 14:07:09,894 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:09,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:09,900 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-27 14:07:12,464 : [INFO]  ------------------------- Batch round 3, loss: 0.5492 -------------------------
2023-03-27 14:07:12,464 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:12,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:12,469 : [INFO]  Batch number 8 model fetched from the server
2023-03-27 14:07:12,469 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-27 14:07:13,873 : [INFO]  Batch 8: Training set : loss - 0.5497, accuracy - 0.7717, recall - 0.9348, AUC - 0.8928, F1 - 0.8037, precision - 0.7049, training time - -9.0 seconds
2023-03-27 14:07:13,873 : [INFO]  Batch 8: Testing set : loss - 0.5938, accuracy - 0.7206, recall - 0.8922, AUC - 0.8291, F1 - 0.7615, precision - 0.6642
2023-03-27 14:07:13,883 : [INFO]  Batch 9 initialized 
2023-03-27 14:07:14,296 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:14,552 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-27 14:07:18,492 : [INFO]  ------------------------- Batch round 1, loss: 0.5417 -------------------------
2023-03-27 14:07:18,492 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:18,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:18,567 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-27 14:07:20,947 : [INFO]  ------------------------- Batch round 2, loss: 0.5345 -------------------------
2023-03-27 14:07:20,948 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:20,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:20,961 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-27 14:07:23,352 : [INFO]  ------------------------- Batch round 3, loss: 0.5371 -------------------------
2023-03-27 14:07:23,352 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:23,370 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:23,372 : [INFO]  Batch number 9 model fetched from the server
2023-03-27 14:07:23,372 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-27 14:07:24,734 : [INFO]  Batch 9: Training set : loss - 0.5383, accuracy - 0.7717, recall - 0.9348, AUC - 0.9271, F1 - 0.8037, precision - 0.7049, training time - -9.0 seconds
2023-03-27 14:07:24,734 : [INFO]  Batch 9: Testing set : loss - 0.5525, accuracy - 0.7696, recall - 0.9314, AUC - 0.8744, F1 - 0.8017, precision - 0.7037
2023-03-27 14:07:24,740 : [INFO]  Batch 10 initialized 
2023-03-27 14:07:25,150 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:25,383 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-27 14:07:29,625 : [INFO]  ------------------------- Batch round 1, loss: 0.5657 -------------------------
2023-03-27 14:07:29,626 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:29,756 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:29,759 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-27 14:07:32,260 : [INFO]  ------------------------- Batch round 2, loss: 0.5615 -------------------------
2023-03-27 14:07:32,261 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:32,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:32,387 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-27 14:07:34,851 : [INFO]  ------------------------- Batch round 3, loss: 0.5612 -------------------------
2023-03-27 14:07:34,851 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:34,862 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:34,865 : [INFO]  Batch number 10 model fetched from the server
2023-03-27 14:07:34,866 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-27 14:07:36,423 : [INFO]  Batch 10: Training set : loss - 0.5569, accuracy - 0.7717, recall - 0.9674, AUC - 0.9021, F1 - 0.8091, precision - 0.6953, training time - -9.0 seconds
2023-03-27 14:07:36,423 : [INFO]  Batch 10: Testing set : loss - 0.5457, accuracy - 0.7549, recall - 0.9608, AUC - 0.9265, F1 - 0.7967, precision - 0.6806
2023-03-27 14:07:36,456 : [INFO]  Batch 11 initialized 
2023-03-27 14:07:36,914 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:37,168 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-27 14:07:41,199 : [INFO]  ------------------------- Batch round 1, loss: 0.5627 -------------------------
2023-03-27 14:07:41,200 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:41,241 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:41,242 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-27 14:07:43,383 : [INFO]  ------------------------- Batch round 2, loss: 0.5606 -------------------------
2023-03-27 14:07:43,384 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:43,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:43,401 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-27 14:07:45,564 : [INFO]  ------------------------- Batch round 3, loss: 0.5555 -------------------------
2023-03-27 14:07:45,565 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:45,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:45,570 : [INFO]  Batch number 11 model fetched from the server
2023-03-27 14:07:45,570 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-27 14:07:47,134 : [INFO]  Batch 11: Training set : loss - 0.5554, accuracy - 0.75, recall - 0.913, AUC - 0.8794, F1 - 0.785, precision - 0.6885, training time - -8.0 seconds
2023-03-27 14:07:47,135 : [INFO]  Batch 11: Testing set : loss - 0.5664, accuracy - 0.7451, recall - 0.9118, AUC - 0.8504, F1 - 0.7815, precision - 0.6838
2023-03-27 14:07:47,144 : [INFO]  Batch 12 initialized 
2023-03-27 14:07:47,687 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:48,012 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-27 14:07:52,195 : [INFO]  ------------------------- Batch round 1, loss: 0.5823 -------------------------
2023-03-27 14:07:52,196 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-27 14:07:52,320 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:52,322 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-27 14:07:54,712 : [INFO]  ------------------------- Batch round 2, loss: 0.5779 -------------------------
2023-03-27 14:07:54,713 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-27 14:07:54,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:54,875 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-27 14:07:57,204 : [INFO]  ------------------------- Batch round 3, loss: 0.5746 -------------------------
2023-03-27 14:07:57,204 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-27 14:07:57,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:07:57,313 : [INFO]  Batch number 12 model fetched from the server
2023-03-27 14:07:57,313 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-27 14:07:58,723 : [INFO]  Batch 12: Training set : loss - 0.5753, accuracy - 0.7391, recall - 0.8696, AUC - 0.8451, F1 - 0.7692, precision - 0.6897, training time - -9.0 seconds
2023-03-27 14:07:58,723 : [INFO]  Batch 12: Testing set : loss - 0.5265, accuracy - 0.8088, recall - 0.9216, AUC - 0.9174, F1 - 0.8282, precision - 0.752
2023-03-27 14:07:58,734 : [INFO]  Batch 13 initialized 
2023-03-27 14:07:59,186 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:07:59,523 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-27 14:08:03,822 : [INFO]  ------------------------- Batch round 1, loss: 0.5407 -------------------------
2023-03-27 14:08:03,822 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:03,908 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:03,910 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-27 14:08:06,378 : [INFO]  ------------------------- Batch round 2, loss: 0.537 -------------------------
2023-03-27 14:08:06,379 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:06,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:06,386 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-27 14:08:08,984 : [INFO]  ------------------------- Batch round 3, loss: 0.5343 -------------------------
2023-03-27 14:08:08,984 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:08,987 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:08,989 : [INFO]  Batch number 13 model fetched from the server
2023-03-27 14:08:08,989 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-27 14:08:10,811 : [INFO]  Batch 13: Training set : loss - 0.5336, accuracy - 0.788, recall - 0.9565, AUC - 0.9087, F1 - 0.8186, precision - 0.7154, training time - -9.0 seconds
2023-03-27 14:08:10,811 : [INFO]  Batch 13: Testing set : loss - 0.5612, accuracy - 0.7598, recall - 0.951, AUC - 0.875, F1 - 0.7984, precision - 0.6879
2023-03-27 14:08:10,821 : [INFO]  Batch 14 initialized 
2023-03-27 14:08:11,260 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:11,493 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-27 14:08:15,451 : [INFO]  ------------------------- Batch round 1, loss: 0.521 -------------------------
2023-03-27 14:08:15,451 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:15,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:15,515 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-27 14:08:17,805 : [INFO]  ------------------------- Batch round 2, loss: 0.5168 -------------------------
2023-03-27 14:08:17,805 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:17,808 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:17,810 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-27 14:08:20,018 : [INFO]  ------------------------- Batch round 3, loss: 0.514 -------------------------
2023-03-27 14:08:20,018 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:20,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:20,041 : [INFO]  Batch number 14 model fetched from the server
2023-03-27 14:08:20,041 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-27 14:08:21,437 : [INFO]  Batch 14: Training set : loss - 0.5105, accuracy - 0.8261, recall - 0.9674, AUC - 0.9269, F1 - 0.8476, precision - 0.7542, training time - -9.0 seconds
2023-03-27 14:08:21,438 : [INFO]  Batch 14: Testing set : loss - 0.5326, accuracy - 0.8088, recall - 0.951, AUC - 0.9122, F1 - 0.8326, precision - 0.7405
2023-03-27 14:08:21,448 : [INFO]  Batch 15 initialized 
2023-03-27 14:08:21,853 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:22,104 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-27 14:08:26,108 : [INFO]  ------------------------- Batch round 1, loss: 0.5394 -------------------------
2023-03-27 14:08:26,109 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:26,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:26,157 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-27 14:08:28,352 : [INFO]  ------------------------- Batch round 2, loss: 0.5314 -------------------------
2023-03-27 14:08:28,352 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:28,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:28,358 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-27 14:08:30,612 : [INFO]  ------------------------- Batch round 3, loss: 0.5286 -------------------------
2023-03-27 14:08:30,613 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:30,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:30,617 : [INFO]  Batch number 15 model fetched from the server
2023-03-27 14:08:30,617 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-27 14:08:31,968 : [INFO]  Batch 15: Training set : loss - 0.5284, accuracy - 0.7989, recall - 0.9674, AUC - 0.9446, F1 - 0.8279, precision - 0.7236, training time - -9.0 seconds
2023-03-27 14:08:31,968 : [INFO]  Batch 15: Testing set : loss - 0.5715, accuracy - 0.7549, recall - 0.9216, AUC - 0.8619, F1 - 0.7899, precision - 0.6912
2023-03-27 14:08:31,978 : [INFO]  Batch 16 initialized 
2023-03-27 14:08:32,392 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:32,648 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-27 14:08:36,520 : [INFO]  ------------------------- Batch round 1, loss: 0.5968 -------------------------
2023-03-27 14:08:36,521 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:36,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:36,580 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-27 14:08:38,795 : [INFO]  ------------------------- Batch round 2, loss: 0.5902 -------------------------
2023-03-27 14:08:38,795 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:38,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:38,835 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-27 14:08:41,044 : [INFO]  ------------------------- Batch round 3, loss: 0.5845 -------------------------
2023-03-27 14:08:41,044 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:41,280 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:41,282 : [INFO]  Batch number 16 model fetched from the server
2023-03-27 14:08:41,282 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-27 14:08:42,878 : [INFO]  Batch 16: Training set : loss - 0.586, accuracy - 0.7011, recall - 0.913, AUC - 0.8626, F1 - 0.7534, precision - 0.6412, training time - -9.0 seconds
2023-03-27 14:08:42,878 : [INFO]  Batch 16: Testing set : loss - 0.5602, accuracy - 0.7451, recall - 0.9314, AUC - 0.8884, F1 - 0.7851, precision - 0.6786
2023-03-27 14:08:42,882 : [INFO]  Batch 17 initialized 
2023-03-27 14:08:43,319 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:43,605 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-27 14:08:48,053 : [INFO]  ------------------------- Batch round 1, loss: 0.5697 -------------------------
2023-03-27 14:08:48,053 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-27 14:08:48,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:48,058 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-27 14:08:50,393 : [INFO]  ------------------------- Batch round 2, loss: 0.5657 -------------------------
2023-03-27 14:08:50,393 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-27 14:08:50,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:50,411 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-27 14:08:53,152 : [INFO]  ------------------------- Batch round 3, loss: 0.5596 -------------------------
2023-03-27 14:08:53,153 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-27 14:08:53,224 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:08:53,226 : [INFO]  Batch number 17 model fetched from the server
2023-03-27 14:08:53,226 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-27 14:08:54,861 : [INFO]  Batch 17: Training set : loss - 0.5618, accuracy - 0.75, recall - 0.8696, AUC - 0.8592, F1 - 0.7767, precision - 0.7018, training time - -10.0 seconds
2023-03-27 14:08:54,861 : [INFO]  Batch 17: Testing set : loss - 0.5812, accuracy - 0.7402, recall - 0.951, AUC - 0.8659, F1 - 0.7854, precision - 0.669
2023-03-27 14:08:54,872 : [INFO]  Batch 18 initialized 
2023-03-27 14:08:55,284 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:08:55,536 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-27 14:09:00,020 : [INFO]  ------------------------- Batch round 1, loss: 0.5556 -------------------------
2023-03-27 14:09:00,020 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:00,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:00,043 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-27 14:09:02,398 : [INFO]  ------------------------- Batch round 2, loss: 0.5465 -------------------------
2023-03-27 14:09:02,398 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:02,428 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:02,430 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-27 14:09:04,769 : [INFO]  ------------------------- Batch round 3, loss: 0.5444 -------------------------
2023-03-27 14:09:04,769 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:04,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:04,854 : [INFO]  Batch number 18 model fetched from the server
2023-03-27 14:09:04,854 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-27 14:09:06,509 : [INFO]  Batch 18: Training set : loss - 0.5478, accuracy - 0.7554, recall - 0.9022, AUC - 0.8906, F1 - 0.7867, precision - 0.6975, training time - -9.0 seconds
2023-03-27 14:09:06,509 : [INFO]  Batch 18: Testing set : loss - 0.5983, accuracy - 0.701, recall - 0.8627, AUC - 0.8078, F1 - 0.7426, precision - 0.6519
2023-03-27 14:09:06,519 : [INFO]  Batch 19 initialized 
2023-03-27 14:09:06,954 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:07,315 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-27 14:09:11,804 : [INFO]  ------------------------- Batch round 1, loss: 0.5796 -------------------------
2023-03-27 14:09:11,804 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:11,983 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:11,985 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-27 14:09:14,367 : [INFO]  ------------------------- Batch round 2, loss: 0.5736 -------------------------
2023-03-27 14:09:14,368 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:14,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:14,460 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-27 14:09:16,896 : [INFO]  ------------------------- Batch round 3, loss: 0.5743 -------------------------
2023-03-27 14:09:16,896 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:17,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:17,080 : [INFO]  Batch number 19 model fetched from the server
2023-03-27 14:09:17,081 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-27 14:09:18,698 : [INFO]  Batch 19: Training set : loss - 0.5736, accuracy - 0.7228, recall - 0.8913, AUC - 0.8345, F1 - 0.7628, precision - 0.6667, training time - -10.0 seconds
2023-03-27 14:09:18,698 : [INFO]  Batch 19: Testing set : loss - 0.5832, accuracy - 0.7206, recall - 0.9216, AUC - 0.85, F1 - 0.7673, precision - 0.6573
2023-03-27 14:09:18,709 : [INFO]  Batch 20 initialized 
2023-03-27 14:09:19,122 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:19,389 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-27 14:09:23,834 : [INFO]  ------------------------- Batch round 1, loss: 0.5397 -------------------------
2023-03-27 14:09:23,834 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:23,837 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:23,839 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-27 14:09:26,088 : [INFO]  ------------------------- Batch round 2, loss: 0.5368 -------------------------
2023-03-27 14:09:26,089 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:26,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:26,094 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-27 14:09:28,322 : [INFO]  ------------------------- Batch round 3, loss: 0.5342 -------------------------
2023-03-27 14:09:28,322 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:28,326 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:28,327 : [INFO]  Batch number 20 model fetched from the server
2023-03-27 14:09:28,328 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-27 14:09:29,808 : [INFO]  Batch 20: Training set : loss - 0.5362, accuracy - 0.7826, recall - 0.9783, AUC - 0.9296, F1 - 0.8182, precision - 0.7031, training time - -9.0 seconds
2023-03-27 14:09:29,808 : [INFO]  Batch 20: Testing set : loss - 0.5706, accuracy - 0.7059, recall - 0.9118, AUC - 0.8837, F1 - 0.7561, precision - 0.6458
2023-03-27 14:09:29,813 : [INFO]  Batch 21 initialized 
2023-03-27 14:09:30,239 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:30,532 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-27 14:09:34,958 : [INFO]  ------------------------- Batch round 1, loss: 0.5791 -------------------------
2023-03-27 14:09:34,958 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:35,055 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:35,058 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-27 14:09:37,626 : [INFO]  ------------------------- Batch round 2, loss: 0.5722 -------------------------
2023-03-27 14:09:37,626 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:37,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:37,631 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-27 14:09:40,077 : [INFO]  ------------------------- Batch round 3, loss: 0.5679 -------------------------
2023-03-27 14:09:40,077 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:40,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:40,082 : [INFO]  Batch number 21 model fetched from the server
2023-03-27 14:09:40,082 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-27 14:09:41,467 : [INFO]  Batch 21: Training set : loss - 0.5667, accuracy - 0.7554, recall - 0.913, AUC - 0.8619, F1 - 0.7887, precision - 0.6942, training time - -10.0 seconds
2023-03-27 14:09:41,467 : [INFO]  Batch 21: Testing set : loss - 0.5562, accuracy - 0.7892, recall - 0.9804, AUC - 0.8856, F1 - 0.823, precision - 0.7092
2023-03-27 14:09:41,474 : [INFO]  Batch 22 initialized 
2023-03-27 14:09:42,033 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:42,336 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-27 14:09:46,859 : [INFO]  ------------------------- Batch round 1, loss: 0.5377 -------------------------
2023-03-27 14:09:46,859 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:47,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:47,003 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-27 14:09:49,386 : [INFO]  ------------------------- Batch round 2, loss: 0.534 -------------------------
2023-03-27 14:09:49,386 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-27 14:09:49,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:49,391 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-27 14:09:51,593 : [INFO]  ------------------------- Batch round 3, loss: 0.5308 -------------------------
2023-03-27 14:09:51,593 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-27 14:09:51,820 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:51,822 : [INFO]  Batch number 22 model fetched from the server
2023-03-27 14:09:51,822 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-27 14:09:53,343 : [INFO]  Batch 22: Training set : loss - 0.5311, accuracy - 0.7826, recall - 0.9565, AUC - 0.9024, F1 - 0.8148, precision - 0.7097, training time - -9.0 seconds
2023-03-27 14:09:53,343 : [INFO]  Batch 22: Testing set : loss - 0.56, accuracy - 0.7696, recall - 0.951, AUC - 0.8816, F1 - 0.805, precision - 0.6978
2023-03-27 14:09:53,347 : [INFO]  Batch 23 initialized 
2023-03-27 14:09:53,780 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:09:54,082 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-27 14:09:58,514 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-27 14:09:58,514 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-27 14:09:58,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:09:58,712 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-27 14:10:01,193 : [INFO]  ------------------------- Batch round 2, loss: 0.556 -------------------------
2023-03-27 14:10:01,194 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:01,318 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:01,320 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-27 14:10:03,637 : [INFO]  ------------------------- Batch round 3, loss: 0.5518 -------------------------
2023-03-27 14:10:03,637 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:03,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:03,723 : [INFO]  Batch number 23 model fetched from the server
2023-03-27 14:10:03,723 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-27 14:10:05,366 : [INFO]  Batch 23: Training set : loss - 0.5478, accuracy - 0.7717, recall - 0.8804, AUC - 0.8986, F1 - 0.7941, precision - 0.7232, training time - -10.0 seconds
2023-03-27 14:10:05,367 : [INFO]  Batch 23: Testing set : loss - 0.5436, accuracy - 0.7647, recall - 0.951, AUC - 0.9163, F1 - 0.8017, precision - 0.6929
2023-03-27 14:10:05,378 : [INFO]  Batch 24 initialized 
2023-03-27 14:10:05,942 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:06,236 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-27 14:10:10,145 : [INFO]  ------------------------- Batch round 1, loss: 0.5781 -------------------------
2023-03-27 14:10:10,145 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:10,224 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:10,226 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-27 14:10:12,331 : [INFO]  ------------------------- Batch round 2, loss: 0.5759 -------------------------
2023-03-27 14:10:12,331 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:12,435 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:12,437 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-27 14:10:14,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5728 -------------------------
2023-03-27 14:10:14,579 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:14,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:14,650 : [INFO]  Batch number 24 model fetched from the server
2023-03-27 14:10:14,650 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-27 14:10:16,143 : [INFO]  Batch 24: Training set : loss - 0.5726, accuracy - 0.7391, recall - 0.9457, AUC - 0.8793, F1 - 0.7838, precision - 0.6692, training time - -8.0 seconds
2023-03-27 14:10:16,143 : [INFO]  Batch 24: Testing set : loss - 0.564, accuracy - 0.75, recall - 0.9608, AUC - 0.9024, F1 - 0.7935, precision - 0.6759
2023-03-27 14:10:16,154 : [INFO]  Batch 25 initialized 
2023-03-27 14:10:16,596 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:16,897 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-27 14:10:21,422 : [INFO]  ------------------------- Batch round 1, loss: 0.5498 -------------------------
2023-03-27 14:10:21,422 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:21,502 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:21,505 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-27 14:10:23,853 : [INFO]  ------------------------- Batch round 2, loss: 0.5517 -------------------------
2023-03-27 14:10:23,853 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:23,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:23,859 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-27 14:10:26,209 : [INFO]  ------------------------- Batch round 3, loss: 0.5473 -------------------------
2023-03-27 14:10:26,210 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:26,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:26,215 : [INFO]  Batch number 25 model fetched from the server
2023-03-27 14:10:26,215 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-27 14:10:27,625 : [INFO]  Batch 25: Training set : loss - 0.5471, accuracy - 0.7609, recall - 0.9674, AUC - 0.9294, F1 - 0.8018, precision - 0.6846, training time - -9.0 seconds
2023-03-27 14:10:27,625 : [INFO]  Batch 25: Testing set : loss - 0.5691, accuracy - 0.7255, recall - 0.9608, AUC - 0.8913, F1 - 0.7778, precision - 0.6533
2023-03-27 14:10:27,636 : [INFO]  Batch 26 initialized 
2023-03-27 14:10:28,046 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:28,326 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-27 14:10:32,359 : [INFO]  ------------------------- Batch round 1, loss: 0.5463 -------------------------
2023-03-27 14:10:32,359 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:32,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:32,435 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-27 14:10:34,653 : [INFO]  ------------------------- Batch round 2, loss: 0.5464 -------------------------
2023-03-27 14:10:34,653 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:34,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:34,665 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-27 14:10:36,958 : [INFO]  ------------------------- Batch round 3, loss: 0.5422 -------------------------
2023-03-27 14:10:36,958 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:36,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:36,980 : [INFO]  Batch number 26 model fetched from the server
2023-03-27 14:10:36,980 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-27 14:10:38,337 : [INFO]  Batch 26: Training set : loss - 0.5442, accuracy - 0.7609, recall - 0.9565, AUC - 0.9186, F1 - 0.8, precision - 0.6875, training time - -9.0 seconds
2023-03-27 14:10:38,337 : [INFO]  Batch 26: Testing set : loss - 0.5277, accuracy - 0.8039, recall - 0.9804, AUC - 0.9356, F1 - 0.8333, precision - 0.7246
2023-03-27 14:10:38,347 : [INFO]  Batch 27 initialized 
2023-03-27 14:10:38,757 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:39,036 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-27 14:10:43,107 : [INFO]  ------------------------- Batch round 1, loss: 0.5675 -------------------------
2023-03-27 14:10:43,107 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:43,111 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:43,113 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-27 14:10:45,362 : [INFO]  ------------------------- Batch round 2, loss: 0.5611 -------------------------
2023-03-27 14:10:45,362 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:45,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:45,367 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-27 14:10:48,392 : [INFO]  ------------------------- Batch round 3, loss: 0.5576 -------------------------
2023-03-27 14:10:48,392 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:48,395 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:48,397 : [INFO]  Batch number 27 model fetched from the server
2023-03-27 14:10:48,397 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-27 14:10:49,815 : [INFO]  Batch 27: Training set : loss - 0.5601, accuracy - 0.75, recall - 0.9565, AUC - 0.8906, F1 - 0.7928, precision - 0.6769, training time - -9.0 seconds
2023-03-27 14:10:49,815 : [INFO]  Batch 27: Testing set : loss - 0.5487, accuracy - 0.7598, recall - 0.9412, AUC - 0.8849, F1 - 0.7967, precision - 0.6906
2023-03-27 14:10:49,820 : [INFO]  Batch 28 initialized 
2023-03-27 14:10:50,265 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:10:50,571 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-27 14:10:54,784 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-27 14:10:54,785 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-27 14:10:54,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:54,789 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-27 14:10:56,959 : [INFO]  ------------------------- Batch round 2, loss: 0.565 -------------------------
2023-03-27 14:10:56,959 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-27 14:10:57,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:57,045 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-27 14:10:59,827 : [INFO]  ------------------------- Batch round 3, loss: 0.5608 -------------------------
2023-03-27 14:10:59,827 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-27 14:10:59,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:10:59,979 : [INFO]  Batch number 28 model fetched from the server
2023-03-27 14:10:59,980 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-27 14:11:02,059 : [INFO]  Batch 28: Training set : loss - 0.5595, accuracy - 0.7554, recall - 0.9239, AUC - 0.8704, F1 - 0.7907, precision - 0.6911, training time - -9.0 seconds
2023-03-27 14:11:02,059 : [INFO]  Batch 28: Testing set : loss - 0.5539, accuracy - 0.75, recall - 0.902, AUC - 0.8718, F1 - 0.783, precision - 0.6917
2023-03-27 14:11:02,073 : [INFO]  Batch 29 initialized 
2023-03-27 14:11:02,698 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:03,059 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-27 14:11:07,219 : [INFO]  ------------------------- Batch round 1, loss: 0.5359 -------------------------
2023-03-27 14:11:07,219 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:07,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:07,249 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-27 14:11:09,970 : [INFO]  ------------------------- Batch round 2, loss: 0.5293 -------------------------
2023-03-27 14:11:09,970 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:09,973 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:09,975 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-27 14:11:12,395 : [INFO]  ------------------------- Batch round 3, loss: 0.5252 -------------------------
2023-03-27 14:11:12,395 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:12,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:12,400 : [INFO]  Batch number 29 model fetched from the server
2023-03-27 14:11:12,400 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-27 14:11:13,857 : [INFO]  Batch 29: Training set : loss - 0.529, accuracy - 0.7826, recall - 0.9783, AUC - 0.9252, F1 - 0.8182, precision - 0.7031, training time - -9.0 seconds
2023-03-27 14:11:13,857 : [INFO]  Batch 29: Testing set : loss - 0.5712, accuracy - 0.7353, recall - 0.9706, AUC - 0.8788, F1 - 0.7857, precision - 0.66
2023-03-27 14:11:13,861 : [INFO]  Batch 30 initialized 
2023-03-27 14:11:14,264 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:14,594 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-27 14:11:18,705 : [INFO]  ------------------------- Batch round 1, loss: 0.5775 -------------------------
2023-03-27 14:11:18,705 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:18,708 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:18,710 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-27 14:11:21,511 : [INFO]  ------------------------- Batch round 2, loss: 0.5763 -------------------------
2023-03-27 14:11:21,511 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:21,515 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:21,516 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-27 14:11:23,890 : [INFO]  ------------------------- Batch round 3, loss: 0.5707 -------------------------
2023-03-27 14:11:23,891 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:23,898 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:23,899 : [INFO]  Batch number 30 model fetched from the server
2023-03-27 14:11:23,900 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-27 14:11:25,318 : [INFO]  Batch 30: Training set : loss - 0.5631, accuracy - 0.7446, recall - 0.9022, AUC - 0.8738, F1 - 0.7793, precision - 0.686, training time - -9.0 seconds
2023-03-27 14:11:25,318 : [INFO]  Batch 30: Testing set : loss - 0.571, accuracy - 0.7451, recall - 0.9216, AUC - 0.8535, F1 - 0.7833, precision - 0.6812
2023-03-27 14:11:25,323 : [INFO]  Batch 31 initialized 
2023-03-27 14:11:25,876 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:26,364 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-27 14:11:31,363 : [INFO]  ------------------------- Batch round 1, loss: 0.5653 -------------------------
2023-03-27 14:11:31,363 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:31,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:31,404 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-27 14:11:34,194 : [INFO]  ------------------------- Batch round 2, loss: 0.5609 -------------------------
2023-03-27 14:11:34,194 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:34,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:34,259 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-27 14:11:36,465 : [INFO]  ------------------------- Batch round 3, loss: 0.5598 -------------------------
2023-03-27 14:11:36,465 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:36,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:36,484 : [INFO]  Batch number 31 model fetched from the server
2023-03-27 14:11:36,484 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-27 14:11:37,998 : [INFO]  Batch 31: Training set : loss - 0.5593, accuracy - 0.7554, recall - 0.9674, AUC - 0.8739, F1 - 0.7982, precision - 0.6794, training time - -10.0 seconds
2023-03-27 14:11:37,998 : [INFO]  Batch 31: Testing set : loss - 0.5815, accuracy - 0.7206, recall - 0.9216, AUC - 0.8357, F1 - 0.7673, precision - 0.6573
2023-03-27 14:11:38,028 : [INFO]  Batch 32 initialized 
2023-03-27 14:11:38,666 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:38,965 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-27 14:11:44,129 : [INFO]  ------------------------- Batch round 1, loss: 0.5224 -------------------------
2023-03-27 14:11:44,130 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:44,133 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:44,134 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-27 14:11:46,350 : [INFO]  ------------------------- Batch round 2, loss: 0.5178 -------------------------
2023-03-27 14:11:46,351 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:46,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:46,374 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-27 14:11:48,614 : [INFO]  ------------------------- Batch round 3, loss: 0.5132 -------------------------
2023-03-27 14:11:48,614 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-27 14:11:48,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:48,622 : [INFO]  Batch number 32 model fetched from the server
2023-03-27 14:11:48,622 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-27 14:11:50,049 : [INFO]  Batch 32: Training set : loss - 0.5146, accuracy - 0.8152, recall - 0.9674, AUC - 0.9445, F1 - 0.8396, precision - 0.7417, training time - -10.0 seconds
2023-03-27 14:11:50,049 : [INFO]  Batch 32: Testing set : loss - 0.5493, accuracy - 0.7353, recall - 0.9314, AUC - 0.8932, F1 - 0.7787, precision - 0.669
2023-03-27 14:11:50,053 : [INFO]  Batch 33 initialized 
2023-03-27 14:11:50,462 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:11:50,760 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-27 14:11:55,041 : [INFO]  ------------------------- Batch round 1, loss: 0.5531 -------------------------
2023-03-27 14:11:55,041 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-27 14:11:55,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:55,078 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-27 14:11:57,942 : [INFO]  ------------------------- Batch round 2, loss: 0.5477 -------------------------
2023-03-27 14:11:57,942 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-27 14:11:57,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:11:57,948 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-27 14:12:00,639 : [INFO]  ------------------------- Batch round 3, loss: 0.5419 -------------------------
2023-03-27 14:12:00,639 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:00,642 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:00,644 : [INFO]  Batch number 33 model fetched from the server
2023-03-27 14:12:00,644 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-27 14:12:02,083 : [INFO]  Batch 33: Training set : loss - 0.5467, accuracy - 0.7717, recall - 0.9457, AUC - 0.9095, F1 - 0.8056, precision - 0.7016, training time - -10.0 seconds
2023-03-27 14:12:02,084 : [INFO]  Batch 33: Testing set : loss - 0.5663, accuracy - 0.7402, recall - 0.9608, AUC - 0.8954, F1 - 0.7871, precision - 0.6667
2023-03-27 14:12:02,096 : [INFO]  Batch 34 initialized 
2023-03-27 14:12:02,632 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:02,918 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-27 14:12:07,227 : [INFO]  ------------------------- Batch round 1, loss: 0.5247 -------------------------
2023-03-27 14:12:07,227 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:07,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:07,273 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-27 14:12:09,616 : [INFO]  ------------------------- Batch round 2, loss: 0.5188 -------------------------
2023-03-27 14:12:09,617 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:09,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:09,625 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-27 14:12:12,156 : [INFO]  ------------------------- Batch round 3, loss: 0.5177 -------------------------
2023-03-27 14:12:12,156 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:12,257 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:12,258 : [INFO]  Batch number 34 model fetched from the server
2023-03-27 14:12:12,259 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-27 14:12:13,822 : [INFO]  Batch 34: Training set : loss - 0.5176, accuracy - 0.8261, recall - 0.9348, AUC - 0.9111, F1 - 0.8431, precision - 0.7679, training time - -9.0 seconds
2023-03-27 14:12:13,822 : [INFO]  Batch 34: Testing set : loss - 0.5827, accuracy - 0.7255, recall - 0.9216, AUC - 0.8422, F1 - 0.7705, precision - 0.662
2023-03-27 14:12:13,831 : [INFO]  Batch 35 initialized 
2023-03-27 14:12:14,254 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:14,551 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-27 14:12:18,422 : [INFO]  ------------------------- Batch round 1, loss: 0.546 -------------------------
2023-03-27 14:12:18,423 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:18,447 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:18,449 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-27 14:12:20,586 : [INFO]  ------------------------- Batch round 2, loss: 0.539 -------------------------
2023-03-27 14:12:20,586 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:20,589 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:20,591 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-27 14:12:22,741 : [INFO]  ------------------------- Batch round 3, loss: 0.532 -------------------------
2023-03-27 14:12:22,741 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:22,768 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:22,770 : [INFO]  Batch number 35 model fetched from the server
2023-03-27 14:12:22,770 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-27 14:12:24,119 : [INFO]  Batch 35: Training set : loss - 0.5339, accuracy - 0.7717, recall - 0.9348, AUC - 0.9024, F1 - 0.8037, precision - 0.7049, training time - -8.0 seconds
2023-03-27 14:12:24,120 : [INFO]  Batch 35: Testing set : loss - 0.5321, accuracy - 0.7794, recall - 0.9314, AUC - 0.8818, F1 - 0.8085, precision - 0.7143
2023-03-27 14:12:24,128 : [INFO]  Batch 36 initialized 
2023-03-27 14:12:24,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:24,883 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-27 14:12:28,891 : [INFO]  ------------------------- Batch round 1, loss: 0.5263 -------------------------
2023-03-27 14:12:28,892 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:28,960 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:28,962 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-27 14:12:31,506 : [INFO]  ------------------------- Batch round 2, loss: 0.5209 -------------------------
2023-03-27 14:12:31,506 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:31,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:31,570 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-27 14:12:33,949 : [INFO]  ------------------------- Batch round 3, loss: 0.5204 -------------------------
2023-03-27 14:12:33,950 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:33,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:33,987 : [INFO]  Batch number 36 model fetched from the server
2023-03-27 14:12:33,987 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-27 14:12:35,394 : [INFO]  Batch 36: Training set : loss - 0.5255, accuracy - 0.7935, recall - 0.913, AUC - 0.9093, F1 - 0.8155, precision - 0.7368, training time - -9.0 seconds
2023-03-27 14:12:35,394 : [INFO]  Batch 36: Testing set : loss - 0.5361, accuracy - 0.7745, recall - 0.9706, AUC - 0.9116, F1 - 0.8115, precision - 0.6972
2023-03-27 14:12:35,399 : [INFO]  Batch 37 initialized 
2023-03-27 14:12:35,818 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:36,113 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-27 14:12:40,402 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-27 14:12:40,403 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:40,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:40,594 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-27 14:12:42,674 : [INFO]  ------------------------- Batch round 2, loss: 0.5567 -------------------------
2023-03-27 14:12:42,674 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:42,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:42,817 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-27 14:12:44,914 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-27 14:12:44,914 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:45,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:45,081 : [INFO]  Batch number 37 model fetched from the server
2023-03-27 14:12:45,081 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-27 14:12:46,434 : [INFO]  Batch 37: Training set : loss - 0.5569, accuracy - 0.7446, recall - 0.9348, AUC - 0.8446, F1 - 0.7854, precision - 0.6772, training time - -9.0 seconds
2023-03-27 14:12:46,434 : [INFO]  Batch 37: Testing set : loss - 0.5447, accuracy - 0.7696, recall - 0.9412, AUC - 0.9123, F1 - 0.8033, precision - 0.7007
2023-03-27 14:12:46,443 : [INFO]  Batch 38 initialized 
2023-03-27 14:12:46,862 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:47,156 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-27 14:12:51,099 : [INFO]  ------------------------- Batch round 1, loss: 0.5474 -------------------------
2023-03-27 14:12:51,099 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-27 14:12:51,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:51,212 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-27 14:12:53,360 : [INFO]  ------------------------- Batch round 2, loss: 0.5389 -------------------------
2023-03-27 14:12:53,360 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-27 14:12:53,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:53,458 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-27 14:12:55,641 : [INFO]  ------------------------- Batch round 3, loss: 0.5365 -------------------------
2023-03-27 14:12:55,641 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-27 14:12:55,722 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:12:55,724 : [INFO]  Batch number 38 model fetched from the server
2023-03-27 14:12:55,724 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-27 14:12:57,091 : [INFO]  Batch 38: Training set : loss - 0.5363, accuracy - 0.7935, recall - 0.9457, AUC - 0.9105, F1 - 0.8208, precision - 0.725, training time - -9.0 seconds
2023-03-27 14:12:57,091 : [INFO]  Batch 38: Testing set : loss - 0.5731, accuracy - 0.7304, recall - 0.8824, AUC - 0.861, F1 - 0.766, precision - 0.6767
2023-03-27 14:12:57,130 : [INFO]  Batch 39 initialized 
2023-03-27 14:12:57,552 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:12:57,872 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-27 14:13:01,742 : [INFO]  ------------------------- Batch round 1, loss: 0.5506 -------------------------
2023-03-27 14:13:01,742 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:01,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:01,780 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-27 14:13:03,933 : [INFO]  ------------------------- Batch round 2, loss: 0.5452 -------------------------
2023-03-27 14:13:03,933 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:03,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:03,938 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-27 14:13:06,151 : [INFO]  ------------------------- Batch round 3, loss: 0.5434 -------------------------
2023-03-27 14:13:06,151 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:06,173 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:06,175 : [INFO]  Batch number 39 model fetched from the server
2023-03-27 14:13:06,175 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-27 14:13:07,652 : [INFO]  Batch 39: Training set : loss - 0.5424, accuracy - 0.7663, recall - 0.9674, AUC - 0.9205, F1 - 0.8054, precision - 0.6899, training time - -8.0 seconds
2023-03-27 14:13:07,652 : [INFO]  Batch 39: Testing set : loss - 0.5271, accuracy - 0.799, recall - 0.9608, AUC - 0.9047, F1 - 0.827, precision - 0.7259
2023-03-27 14:13:07,658 : [INFO]  Batch 40 initialized 
2023-03-27 14:13:08,084 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:08,395 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-27 14:13:12,352 : [INFO]  ------------------------- Batch round 1, loss: 0.5662 -------------------------
2023-03-27 14:13:12,353 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:12,358 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:12,360 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-27 14:13:14,567 : [INFO]  ------------------------- Batch round 2, loss: 0.5599 -------------------------
2023-03-27 14:13:14,567 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:14,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:14,572 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-27 14:13:16,794 : [INFO]  ------------------------- Batch round 3, loss: 0.5584 -------------------------
2023-03-27 14:13:16,795 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:16,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:16,800 : [INFO]  Batch number 40 model fetched from the server
2023-03-27 14:13:16,800 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-27 14:13:18,146 : [INFO]  Batch 40: Training set : loss - 0.5597, accuracy - 0.7283, recall - 0.9674, AUC - 0.8897, F1 - 0.7807, precision - 0.6544, training time - -8.0 seconds
2023-03-27 14:13:18,147 : [INFO]  Batch 40: Testing set : loss - 0.5565, accuracy - 0.7696, recall - 0.951, AUC - 0.8595, F1 - 0.805, precision - 0.6978
2023-03-27 14:13:18,156 : [INFO]  Batch 41 initialized 
2023-03-27 14:13:18,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:18,871 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-27 14:13:22,753 : [INFO]  ------------------------- Batch round 1, loss: 0.5585 -------------------------
2023-03-27 14:13:22,753 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:22,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:22,851 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-27 14:13:24,967 : [INFO]  ------------------------- Batch round 2, loss: 0.5534 -------------------------
2023-03-27 14:13:24,967 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:25,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:25,078 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-27 14:13:27,258 : [INFO]  ------------------------- Batch round 3, loss: 0.5507 -------------------------
2023-03-27 14:13:27,259 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:27,320 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:27,322 : [INFO]  Batch number 41 model fetched from the server
2023-03-27 14:13:27,322 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-27 14:13:28,799 : [INFO]  Batch 41: Training set : loss - 0.5525, accuracy - 0.7446, recall - 0.9457, AUC - 0.8897, F1 - 0.7873, precision - 0.6744, training time - -8.0 seconds
2023-03-27 14:13:28,799 : [INFO]  Batch 41: Testing set : loss - 0.5565, accuracy - 0.7157, recall - 0.9118, AUC - 0.8534, F1 - 0.7623, precision - 0.6549
2023-03-27 14:13:28,809 : [INFO]  Batch 42 initialized 
2023-03-27 14:13:29,246 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:29,562 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-27 14:13:33,536 : [INFO]  ------------------------- Batch round 1, loss: 0.5396 -------------------------
2023-03-27 14:13:33,537 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:33,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:33,575 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-27 14:13:35,775 : [INFO]  ------------------------- Batch round 2, loss: 0.5324 -------------------------
2023-03-27 14:13:35,775 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:35,838 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:35,840 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-27 14:13:38,048 : [INFO]  ------------------------- Batch round 3, loss: 0.5228 -------------------------
2023-03-27 14:13:38,048 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:38,083 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:38,085 : [INFO]  Batch number 42 model fetched from the server
2023-03-27 14:13:38,085 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-27 14:13:39,429 : [INFO]  Batch 42: Training set : loss - 0.524, accuracy - 0.7717, recall - 0.9239, AUC - 0.9179, F1 - 0.8019, precision - 0.7083, training time - -9.0 seconds
2023-03-27 14:13:39,429 : [INFO]  Batch 42: Testing set : loss - 0.5776, accuracy - 0.7206, recall - 0.9216, AUC - 0.8679, F1 - 0.7673, precision - 0.6573
2023-03-27 14:13:39,439 : [INFO]  Batch 43 initialized 
2023-03-27 14:13:39,919 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:40,299 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-27 14:13:45,067 : [INFO]  ------------------------- Batch round 1, loss: 0.5385 -------------------------
2023-03-27 14:13:45,068 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:45,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:45,097 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-27 14:13:47,556 : [INFO]  ------------------------- Batch round 2, loss: 0.5331 -------------------------
2023-03-27 14:13:47,556 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:47,559 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:47,561 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-27 14:13:49,741 : [INFO]  ------------------------- Batch round 3, loss: 0.5309 -------------------------
2023-03-27 14:13:49,741 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-27 14:13:49,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:49,753 : [INFO]  Batch number 43 model fetched from the server
2023-03-27 14:13:49,753 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-27 14:13:51,166 : [INFO]  Batch 43: Training set : loss - 0.5292, accuracy - 0.7609, recall - 0.9457, AUC - 0.9309, F1 - 0.7982, precision - 0.6905, training time - -9.0 seconds
2023-03-27 14:13:51,166 : [INFO]  Batch 43: Testing set : loss - 0.5399, accuracy - 0.7402, recall - 1.0, AUC - 0.9663, F1 - 0.7938, precision - 0.6581
2023-03-27 14:13:51,175 : [INFO]  Batch 44 initialized 
2023-03-27 14:13:51,577 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:13:51,954 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-27 14:13:56,730 : [INFO]  ------------------------- Batch round 1, loss: 0.5487 -------------------------
2023-03-27 14:13:56,730 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-27 14:13:56,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:56,818 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-27 14:13:59,216 : [INFO]  ------------------------- Batch round 2, loss: 0.5438 -------------------------
2023-03-27 14:13:59,217 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-27 14:13:59,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:13:59,254 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-27 14:14:01,743 : [INFO]  ------------------------- Batch round 3, loss: 0.5394 -------------------------
2023-03-27 14:14:01,743 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:01,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:01,829 : [INFO]  Batch number 44 model fetched from the server
2023-03-27 14:14:01,829 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-27 14:14:03,322 : [INFO]  Batch 44: Training set : loss - 0.5395, accuracy - 0.7826, recall - 0.9239, AUC - 0.882, F1 - 0.8095, precision - 0.7203, training time - -10.0 seconds
2023-03-27 14:14:03,323 : [INFO]  Batch 44: Testing set : loss - 0.5525, accuracy - 0.7794, recall - 0.9314, AUC - 0.8879, F1 - 0.8085, precision - 0.7143
2023-03-27 14:14:03,334 : [INFO]  Batch 45 initialized 
2023-03-27 14:14:03,786 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:04,125 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-27 14:14:08,308 : [INFO]  ------------------------- Batch round 1, loss: 0.5645 -------------------------
2023-03-27 14:14:08,309 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:08,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:08,360 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-27 14:14:11,099 : [INFO]  ------------------------- Batch round 2, loss: 0.553 -------------------------
2023-03-27 14:14:11,099 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:11,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:11,104 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-27 14:14:13,428 : [INFO]  ------------------------- Batch round 3, loss: 0.5444 -------------------------
2023-03-27 14:14:13,429 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:13,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:13,433 : [INFO]  Batch number 45 model fetched from the server
2023-03-27 14:14:13,434 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-27 14:14:14,810 : [INFO]  Batch 45: Training set : loss - 0.5497, accuracy - 0.7609, recall - 0.9457, AUC - 0.8974, F1 - 0.7982, precision - 0.6905, training time - -9.0 seconds
2023-03-27 14:14:14,810 : [INFO]  Batch 45: Testing set : loss - 0.5277, accuracy - 0.799, recall - 0.9412, AUC - 0.9238, F1 - 0.824, precision - 0.7328
2023-03-27 14:14:14,817 : [INFO]  Batch 46 initialized 
2023-03-27 14:14:15,220 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:15,545 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-27 14:14:19,519 : [INFO]  ------------------------- Batch round 1, loss: 0.526 -------------------------
2023-03-27 14:14:19,519 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:19,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:19,525 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-27 14:14:21,730 : [INFO]  ------------------------- Batch round 2, loss: 0.5238 -------------------------
2023-03-27 14:14:21,730 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:21,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:21,735 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-27 14:14:24,163 : [INFO]  ------------------------- Batch round 3, loss: 0.5186 -------------------------
2023-03-27 14:14:24,163 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:24,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:24,168 : [INFO]  Batch number 46 model fetched from the server
2023-03-27 14:14:24,168 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-27 14:14:25,719 : [INFO]  Batch 46: Training set : loss - 0.5198, accuracy - 0.8152, recall - 0.9674, AUC - 0.9593, F1 - 0.8396, precision - 0.7417, training time - -9.0 seconds
2023-03-27 14:14:25,719 : [INFO]  Batch 46: Testing set : loss - 0.5349, accuracy - 0.7843, recall - 0.9412, AUC - 0.9352, F1 - 0.8136, precision - 0.7164
2023-03-27 14:14:25,727 : [INFO]  Batch 47 initialized 
2023-03-27 14:14:26,144 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:26,467 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-27 14:14:30,524 : [INFO]  ------------------------- Batch round 1, loss: 0.5165 -------------------------
2023-03-27 14:14:30,524 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:30,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:30,530 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-27 14:14:32,964 : [INFO]  ------------------------- Batch round 2, loss: 0.51 -------------------------
2023-03-27 14:14:32,964 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:32,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:32,970 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-27 14:14:35,514 : [INFO]  ------------------------- Batch round 3, loss: 0.5087 -------------------------
2023-03-27 14:14:35,514 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:35,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:35,519 : [INFO]  Batch number 47 model fetched from the server
2023-03-27 14:14:35,519 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-27 14:14:36,941 : [INFO]  Batch 47: Training set : loss - 0.5058, accuracy - 0.8207, recall - 0.9565, AUC - 0.9471, F1 - 0.8421, precision - 0.7521, training time - -9.0 seconds
2023-03-27 14:14:36,942 : [INFO]  Batch 47: Testing set : loss - 0.5459, accuracy - 0.7549, recall - 0.9608, AUC - 0.9087, F1 - 0.7967, precision - 0.6806
2023-03-27 14:14:36,946 : [INFO]  Batch 48 initialized 
2023-03-27 14:14:37,369 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:37,707 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-27 14:14:41,815 : [INFO]  ------------------------- Batch round 1, loss: 0.5458 -------------------------
2023-03-27 14:14:41,815 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:41,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:41,820 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-27 14:14:44,093 : [INFO]  ------------------------- Batch round 2, loss: 0.5428 -------------------------
2023-03-27 14:14:44,094 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:44,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:44,099 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-27 14:14:46,403 : [INFO]  ------------------------- Batch round 3, loss: 0.5385 -------------------------
2023-03-27 14:14:46,403 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:46,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:46,408 : [INFO]  Batch number 48 model fetched from the server
2023-03-27 14:14:46,408 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-27 14:14:47,923 : [INFO]  Batch 48: Training set : loss - 0.5451, accuracy - 0.7446, recall - 0.913, AUC - 0.9041, F1 - 0.7814, precision - 0.6829, training time - -9.0 seconds
2023-03-27 14:14:47,923 : [INFO]  Batch 48: Testing set : loss - 0.5856, accuracy - 0.701, recall - 0.9118, AUC - 0.8787, F1 - 0.753, precision - 0.6414
2023-03-27 14:14:47,931 : [INFO]  Batch 49 initialized 
2023-03-27 14:14:48,663 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:14:49,014 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-27 14:14:53,575 : [INFO]  ------------------------- Batch round 1, loss: 0.5625 -------------------------
2023-03-27 14:14:53,575 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-27 14:14:53,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:53,666 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-27 14:14:56,086 : [INFO]  ------------------------- Batch round 2, loss: 0.5561 -------------------------
2023-03-27 14:14:56,086 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-27 14:14:56,194 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:56,196 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-27 14:14:58,463 : [INFO]  ------------------------- Batch round 3, loss: 0.5525 -------------------------
2023-03-27 14:14:58,463 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-27 14:14:58,559 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:14:58,561 : [INFO]  Batch number 49 model fetched from the server
2023-03-27 14:14:58,561 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-27 14:14:59,945 : [INFO]  Batch 49: Training set : loss - 0.5497, accuracy - 0.7772, recall - 0.9457, AUC - 0.8922, F1 - 0.8093, precision - 0.7073, training time - -10.0 seconds
2023-03-27 14:14:59,945 : [INFO]  Batch 49: Testing set : loss - 0.5534, accuracy - 0.7402, recall - 0.9314, AUC - 0.9071, F1 - 0.7819, precision - 0.6738
2023-03-27 14:14:59,956 : [INFO]  Batch 50 initialized 
2023-03-27 14:15:00,396 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:00,721 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-27 14:15:04,839 : [INFO]  ------------------------- Batch round 1, loss: 0.5423 -------------------------
2023-03-27 14:15:04,839 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:04,849 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:04,851 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-27 14:15:07,074 : [INFO]  ------------------------- Batch round 2, loss: 0.5355 -------------------------
2023-03-27 14:15:07,075 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:07,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:07,079 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-27 14:15:09,739 : [INFO]  ------------------------- Batch round 3, loss: 0.5328 -------------------------
2023-03-27 14:15:09,740 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:09,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:09,745 : [INFO]  Batch number 50 model fetched from the server
2023-03-27 14:15:09,745 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-27 14:15:11,204 : [INFO]  Batch 50: Training set : loss - 0.5337, accuracy - 0.8043, recall - 0.9348, AUC - 0.8816, F1 - 0.8269, precision - 0.7414, training time - -9.0 seconds
2023-03-27 14:15:11,204 : [INFO]  Batch 50: Testing set : loss - 0.5711, accuracy - 0.7157, recall - 0.9608, AUC - 0.9217, F1 - 0.7717, precision - 0.6447
2023-03-27 14:15:11,210 : [INFO]  Batch 51 initialized 
2023-03-27 14:15:11,676 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:12,012 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-27 14:15:16,009 : [INFO]  ------------------------- Batch round 1, loss: 0.5529 -------------------------
2023-03-27 14:15:16,009 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:16,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:16,046 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-27 14:15:18,456 : [INFO]  ------------------------- Batch round 2, loss: 0.5488 -------------------------
2023-03-27 14:15:18,456 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:18,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:18,514 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-27 14:15:21,057 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-27 14:15:21,057 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:21,112 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:21,114 : [INFO]  Batch number 51 model fetched from the server
2023-03-27 14:15:21,114 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-27 14:15:22,457 : [INFO]  Batch 51: Training set : loss - 0.5461, accuracy - 0.7772, recall - 0.9565, AUC - 0.9362, F1 - 0.8111, precision - 0.704, training time - -9.0 seconds
2023-03-27 14:15:22,458 : [INFO]  Batch 51: Testing set : loss - 0.5645, accuracy - 0.7206, recall - 0.9314, AUC - 0.892, F1 - 0.7692, precision - 0.6552
2023-03-27 14:15:22,465 : [INFO]  Batch 52 initialized 
2023-03-27 14:15:22,905 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:23,229 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-27 14:15:27,551 : [INFO]  ------------------------- Batch round 1, loss: 0.5362 -------------------------
2023-03-27 14:15:27,551 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:27,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:27,593 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-27 14:15:29,933 : [INFO]  ------------------------- Batch round 2, loss: 0.5299 -------------------------
2023-03-27 14:15:29,933 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:30,034 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:30,036 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-27 14:15:32,216 : [INFO]  ------------------------- Batch round 3, loss: 0.526 -------------------------
2023-03-27 14:15:32,217 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:32,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:32,250 : [INFO]  Batch number 52 model fetched from the server
2023-03-27 14:15:32,250 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-27 14:15:33,649 : [INFO]  Batch 52: Training set : loss - 0.5226, accuracy - 0.7826, recall - 0.9783, AUC - 0.9237, F1 - 0.8182, precision - 0.7031, training time - -9.0 seconds
2023-03-27 14:15:33,649 : [INFO]  Batch 52: Testing set : loss - 0.5469, accuracy - 0.7696, recall - 0.9412, AUC - 0.9323, F1 - 0.8033, precision - 0.7007
2023-03-27 14:15:33,653 : [INFO]  Batch 53 initialized 
2023-03-27 14:15:34,085 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:34,453 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-27 14:15:39,665 : [INFO]  ------------------------- Batch round 1, loss: 0.561 -------------------------
2023-03-27 14:15:39,665 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:40,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:40,131 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-27 14:15:42,766 : [INFO]  ------------------------- Batch round 2, loss: 0.5562 -------------------------
2023-03-27 14:15:42,767 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:42,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:42,772 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-27 14:15:44,994 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-27 14:15:44,995 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:44,998 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:45,000 : [INFO]  Batch number 53 model fetched from the server
2023-03-27 14:15:45,000 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-27 14:15:46,383 : [INFO]  Batch 53: Training set : loss - 0.5535, accuracy - 0.7446, recall - 0.9457, AUC - 0.8925, F1 - 0.7873, precision - 0.6744, training time - -11.0 seconds
2023-03-27 14:15:46,383 : [INFO]  Batch 53: Testing set : loss - 0.5556, accuracy - 0.7598, recall - 0.9608, AUC - 0.9119, F1 - 0.8, precision - 0.6853
2023-03-27 14:15:46,387 : [INFO]  Batch 54 initialized 
2023-03-27 14:15:46,807 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:47,168 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-27 14:15:51,281 : [INFO]  ------------------------- Batch round 1, loss: 0.5421 -------------------------
2023-03-27 14:15:51,281 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-27 14:15:51,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:51,383 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-27 14:15:53,577 : [INFO]  ------------------------- Batch round 2, loss: 0.539 -------------------------
2023-03-27 14:15:53,577 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-27 14:15:53,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:53,600 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-27 14:15:56,098 : [INFO]  ------------------------- Batch round 3, loss: 0.5323 -------------------------
2023-03-27 14:15:56,099 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-27 14:15:56,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:15:56,105 : [INFO]  Batch number 54 model fetched from the server
2023-03-27 14:15:56,105 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-27 14:15:57,604 : [INFO]  Batch 54: Training set : loss - 0.5349, accuracy - 0.7663, recall - 0.9457, AUC - 0.9051, F1 - 0.8018, precision - 0.696, training time - -9.0 seconds
2023-03-27 14:15:57,605 : [INFO]  Batch 54: Testing set : loss - 0.5459, accuracy - 0.7451, recall - 0.9804, AUC - 0.9419, F1 - 0.7937, precision - 0.6667
2023-03-27 14:15:57,614 : [INFO]  Batch 55 initialized 
2023-03-27 14:15:58,032 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:15:58,368 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-27 14:16:02,303 : [INFO]  ------------------------- Batch round 1, loss: 0.5651 -------------------------
2023-03-27 14:16:02,303 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:02,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:02,489 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-27 14:16:05,735 : [INFO]  ------------------------- Batch round 2, loss: 0.5627 -------------------------
2023-03-27 14:16:05,736 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:05,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:05,916 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-27 14:16:08,354 : [INFO]  ------------------------- Batch round 3, loss: 0.5594 -------------------------
2023-03-27 14:16:08,354 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:08,462 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:08,464 : [INFO]  Batch number 55 model fetched from the server
2023-03-27 14:16:08,464 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-27 14:16:10,155 : [INFO]  Batch 55: Training set : loss - 0.5631, accuracy - 0.7609, recall - 0.9891, AUC - 0.8738, F1 - 0.8053, precision - 0.6791, training time - -10.0 seconds
2023-03-27 14:16:10,155 : [INFO]  Batch 55: Testing set : loss - 0.572, accuracy - 0.7108, recall - 0.9314, AUC - 0.8859, F1 - 0.7631, precision - 0.6463
2023-03-27 14:16:10,161 : [INFO]  Batch 56 initialized 
2023-03-27 14:16:10,675 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:11,009 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-27 14:16:15,852 : [INFO]  ------------------------- Batch round 1, loss: 0.5664 -------------------------
2023-03-27 14:16:15,853 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:16,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:16,043 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-27 14:16:18,496 : [INFO]  ------------------------- Batch round 2, loss: 0.5618 -------------------------
2023-03-27 14:16:18,496 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:18,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:18,560 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-27 14:16:20,920 : [INFO]  ------------------------- Batch round 3, loss: 0.5619 -------------------------
2023-03-27 14:16:20,920 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:20,942 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:20,945 : [INFO]  Batch number 56 model fetched from the server
2023-03-27 14:16:20,945 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-27 14:16:22,464 : [INFO]  Batch 56: Training set : loss - 0.5573, accuracy - 0.7391, recall - 0.9348, AUC - 0.8858, F1 - 0.7818, precision - 0.6719, training time - -10.0 seconds
2023-03-27 14:16:22,464 : [INFO]  Batch 56: Testing set : loss - 0.5955, accuracy - 0.6863, recall - 0.8725, AUC - 0.8532, F1 - 0.7355, precision - 0.6357
2023-03-27 14:16:22,474 : [INFO]  Batch 57 initialized 
2023-03-27 14:16:22,952 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:23,343 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-27 14:16:28,893 : [INFO]  ------------------------- Batch round 1, loss: 0.5457 -------------------------
2023-03-27 14:16:28,894 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:28,938 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:28,940 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-27 14:16:31,788 : [INFO]  ------------------------- Batch round 2, loss: 0.5363 -------------------------
2023-03-27 14:16:31,789 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:31,792 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:31,794 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-27 14:16:34,600 : [INFO]  ------------------------- Batch round 3, loss: 0.5313 -------------------------
2023-03-27 14:16:34,600 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:34,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:34,649 : [INFO]  Batch number 57 model fetched from the server
2023-03-27 14:16:34,649 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-27 14:16:36,339 : [INFO]  Batch 57: Training set : loss - 0.5361, accuracy - 0.7663, recall - 0.9674, AUC - 0.9237, F1 - 0.8054, precision - 0.6899, training time - -11.0 seconds
2023-03-27 14:16:36,339 : [INFO]  Batch 57: Testing set : loss - 0.5422, accuracy - 0.7549, recall - 0.9412, AUC - 0.9215, F1 - 0.7934, precision - 0.6857
2023-03-27 14:16:36,358 : [INFO]  Batch 58 initialized 
2023-03-27 14:16:36,804 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:37,216 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-27 14:16:42,756 : [INFO]  ------------------------- Batch round 1, loss: 0.5166 -------------------------
2023-03-27 14:16:42,756 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:42,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:42,850 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-27 14:16:44,963 : [INFO]  ------------------------- Batch round 2, loss: 0.5103 -------------------------
2023-03-27 14:16:44,964 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:44,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:44,968 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-27 14:16:47,102 : [INFO]  ------------------------- Batch round 3, loss: 0.5114 -------------------------
2023-03-27 14:16:47,102 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:47,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:47,158 : [INFO]  Batch number 58 model fetched from the server
2023-03-27 14:16:47,158 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-27 14:16:48,499 : [INFO]  Batch 58: Training set : loss - 0.5065, accuracy - 0.8207, recall - 0.9783, AUC - 0.9361, F1 - 0.8451, precision - 0.7438, training time - -10.0 seconds
2023-03-27 14:16:48,499 : [INFO]  Batch 58: Testing set : loss - 0.5327, accuracy - 0.8088, recall - 0.9804, AUC - 0.8995, F1 - 0.8368, precision - 0.7299
2023-03-27 14:16:48,509 : [INFO]  Batch 59 initialized 
2023-03-27 14:16:48,920 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:16:49,256 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-27 14:16:53,941 : [INFO]  ------------------------- Batch round 1, loss: 0.5617 -------------------------
2023-03-27 14:16:53,941 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-27 14:16:53,973 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:53,975 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-27 14:16:56,233 : [INFO]  ------------------------- Batch round 2, loss: 0.555 -------------------------
2023-03-27 14:16:56,233 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-27 14:16:56,272 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:56,274 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-27 14:16:58,625 : [INFO]  ------------------------- Batch round 3, loss: 0.5451 -------------------------
2023-03-27 14:16:58,625 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-27 14:16:58,736 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:16:58,738 : [INFO]  Batch number 59 model fetched from the server
2023-03-27 14:16:58,739 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-27 14:17:00,174 : [INFO]  Batch 59: Training set : loss - 0.5458, accuracy - 0.7663, recall - 0.9565, AUC - 0.9109, F1 - 0.8037, precision - 0.6929, training time - -9.0 seconds
2023-03-27 14:17:00,174 : [INFO]  Batch 59: Testing set : loss - 0.54, accuracy - 0.7794, recall - 0.951, AUC - 0.909, F1 - 0.8117, precision - 0.708
2023-03-27 14:17:00,182 : [INFO]  Batch 60 initialized 
2023-03-27 14:17:00,617 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:00,964 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-27 14:17:05,102 : [INFO]  ------------------------- Batch round 1, loss: 0.5247 -------------------------
2023-03-27 14:17:05,103 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:05,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:05,162 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-27 14:17:07,475 : [INFO]  ------------------------- Batch round 2, loss: 0.5219 -------------------------
2023-03-27 14:17:07,475 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:07,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:07,499 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-27 14:17:09,739 : [INFO]  ------------------------- Batch round 3, loss: 0.5166 -------------------------
2023-03-27 14:17:09,739 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:09,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:09,773 : [INFO]  Batch number 60 model fetched from the server
2023-03-27 14:17:09,773 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-27 14:17:11,212 : [INFO]  Batch 60: Training set : loss - 0.5225, accuracy - 0.7935, recall - 0.913, AUC - 0.9133, F1 - 0.8155, precision - 0.7368, training time - -9.0 seconds
2023-03-27 14:17:11,213 : [INFO]  Batch 60: Testing set : loss - 0.5456, accuracy - 0.7549, recall - 0.9608, AUC - 0.9095, F1 - 0.7967, precision - 0.6806
2023-03-27 14:17:11,217 : [INFO]  Batch 61 initialized 
2023-03-27 14:17:11,636 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:12,019 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-27 14:17:16,264 : [INFO]  ------------------------- Batch round 1, loss: 0.5499 -------------------------
2023-03-27 14:17:16,264 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:16,400 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:16,402 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-27 14:17:18,555 : [INFO]  ------------------------- Batch round 2, loss: 0.5417 -------------------------
2023-03-27 14:17:18,555 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:18,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:18,629 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-27 14:17:20,752 : [INFO]  ------------------------- Batch round 3, loss: 0.5337 -------------------------
2023-03-27 14:17:20,752 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:20,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:20,805 : [INFO]  Batch number 61 model fetched from the server
2023-03-27 14:17:20,805 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-27 14:17:22,187 : [INFO]  Batch 61: Training set : loss - 0.5398, accuracy - 0.788, recall - 0.9457, AUC - 0.9182, F1 - 0.8169, precision - 0.719, training time - -9.0 seconds
2023-03-27 14:17:22,187 : [INFO]  Batch 61: Testing set : loss - 0.5544, accuracy - 0.7255, recall - 0.9118, AUC - 0.8897, F1 - 0.7686, precision - 0.6643
2023-03-27 14:17:22,198 : [INFO]  Batch 62 initialized 
2023-03-27 14:17:22,631 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:22,991 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-27 14:17:27,422 : [INFO]  ------------------------- Batch round 1, loss: 0.5821 -------------------------
2023-03-27 14:17:27,423 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:27,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:27,776 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-27 14:17:30,223 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-27 14:17:30,223 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:30,384 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:30,386 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-27 14:17:32,692 : [INFO]  ------------------------- Batch round 3, loss: 0.5665 -------------------------
2023-03-27 14:17:32,692 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:32,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:32,749 : [INFO]  Batch number 62 model fetched from the server
2023-03-27 14:17:32,749 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-27 14:17:34,107 : [INFO]  Batch 62: Training set : loss - 0.5667, accuracy - 0.7011, recall - 0.9348, AUC - 0.8926, F1 - 0.7577, precision - 0.637, training time - -10.0 seconds
2023-03-27 14:17:34,107 : [INFO]  Batch 62: Testing set : loss - 0.5754, accuracy - 0.7549, recall - 0.9314, AUC - 0.8577, F1 - 0.7917, precision - 0.6884
2023-03-27 14:17:34,116 : [INFO]  Batch 63 initialized 
2023-03-27 14:17:34,521 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:34,880 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-27 14:17:40,191 : [INFO]  ------------------------- Batch round 1, loss: 0.536 -------------------------
2023-03-27 14:17:40,191 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:40,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:40,347 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-27 14:17:43,279 : [INFO]  ------------------------- Batch round 2, loss: 0.5306 -------------------------
2023-03-27 14:17:43,280 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:43,363 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:43,365 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-27 14:17:46,089 : [INFO]  ------------------------- Batch round 3, loss: 0.5239 -------------------------
2023-03-27 14:17:46,090 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-27 14:17:46,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:46,200 : [INFO]  Batch number 63 model fetched from the server
2023-03-27 14:17:46,200 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-27 14:17:48,102 : [INFO]  Batch 63: Training set : loss - 0.5218, accuracy - 0.788, recall - 0.9348, AUC - 0.9194, F1 - 0.8152, precision - 0.7227, training time - -11.0 seconds
2023-03-27 14:17:48,103 : [INFO]  Batch 63: Testing set : loss - 0.5702, accuracy - 0.7108, recall - 0.9412, AUC - 0.8346, F1 - 0.7649, precision - 0.6443
2023-03-27 14:17:48,115 : [INFO]  Batch 64 initialized 
2023-03-27 14:17:48,739 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:17:49,324 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-27 14:17:55,135 : [INFO]  ------------------------- Batch round 1, loss: 0.534 -------------------------
2023-03-27 14:17:55,136 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-27 14:17:55,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:55,143 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-27 14:17:58,707 : [INFO]  ------------------------- Batch round 2, loss: 0.5273 -------------------------
2023-03-27 14:17:58,708 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-27 14:17:59,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:17:59,301 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-27 14:18:03,578 : [INFO]  ------------------------- Batch round 3, loss: 0.5187 -------------------------
2023-03-27 14:18:03,579 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:03,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:03,587 : [INFO]  Batch number 64 model fetched from the server
2023-03-27 14:18:03,587 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-27 14:18:06,596 : [INFO]  Batch 64: Training set : loss - 0.5145, accuracy - 0.8098, recall - 0.9674, AUC - 0.9292, F1 - 0.8357, precision - 0.7355, training time - -14.0 seconds
2023-03-27 14:18:06,598 : [INFO]  Batch 64: Testing set : loss - 0.5428, accuracy - 0.75, recall - 0.951, AUC - 0.9194, F1 - 0.7918, precision - 0.6783
2023-03-27 14:18:06,606 : [INFO]  Batch 65 initialized 
2023-03-27 14:18:07,252 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:07,770 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-27 14:18:12,789 : [INFO]  ------------------------- Batch round 1, loss: 0.5515 -------------------------
2023-03-27 14:18:12,789 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:13,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:13,076 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-27 14:18:15,247 : [INFO]  ------------------------- Batch round 2, loss: 0.5473 -------------------------
2023-03-27 14:18:15,248 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:15,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:15,337 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-27 14:18:17,548 : [INFO]  ------------------------- Batch round 3, loss: 0.5429 -------------------------
2023-03-27 14:18:17,548 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:17,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:17,624 : [INFO]  Batch number 65 model fetched from the server
2023-03-27 14:18:17,624 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-27 14:18:18,966 : [INFO]  Batch 65: Training set : loss - 0.5437, accuracy - 0.7826, recall - 0.9565, AUC - 0.8977, F1 - 0.8148, precision - 0.7097, training time - -10.0 seconds
2023-03-27 14:18:18,967 : [INFO]  Batch 65: Testing set : loss - 0.545, accuracy - 0.7598, recall - 0.9804, AUC - 0.9167, F1 - 0.8032, precision - 0.6803
2023-03-27 14:18:18,977 : [INFO]  Batch 66 initialized 
2023-03-27 14:18:19,478 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:19,860 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-27 14:18:24,964 : [INFO]  ------------------------- Batch round 1, loss: 0.5524 -------------------------
2023-03-27 14:18:24,964 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:24,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:24,969 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-27 14:18:27,664 : [INFO]  ------------------------- Batch round 2, loss: 0.5462 -------------------------
2023-03-27 14:18:27,664 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:27,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:27,669 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-27 14:18:30,420 : [INFO]  ------------------------- Batch round 3, loss: 0.5434 -------------------------
2023-03-27 14:18:30,421 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:30,425 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:30,428 : [INFO]  Batch number 66 model fetched from the server
2023-03-27 14:18:30,428 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-27 14:18:32,322 : [INFO]  Batch 66: Training set : loss - 0.5468, accuracy - 0.7663, recall - 0.9565, AUC - 0.9112, F1 - 0.8037, precision - 0.6929, training time - -11.0 seconds
2023-03-27 14:18:32,322 : [INFO]  Batch 66: Testing set : loss - 0.5572, accuracy - 0.7549, recall - 0.951, AUC - 0.9074, F1 - 0.7951, precision - 0.6831
2023-03-27 14:18:32,330 : [INFO]  Batch 67 initialized 
2023-03-27 14:18:32,982 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:33,411 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-27 14:18:38,263 : [INFO]  ------------------------- Batch round 1, loss: 0.5415 -------------------------
2023-03-27 14:18:38,263 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:38,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:38,327 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-27 14:18:41,122 : [INFO]  ------------------------- Batch round 2, loss: 0.5381 -------------------------
2023-03-27 14:18:41,122 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:41,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:41,193 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-27 14:18:45,712 : [INFO]  ------------------------- Batch round 3, loss: 0.536 -------------------------
2023-03-27 14:18:45,713 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-27 14:18:45,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:45,723 : [INFO]  Batch number 67 model fetched from the server
2023-03-27 14:18:45,724 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-27 14:18:48,614 : [INFO]  Batch 67: Training set : loss - 0.5388, accuracy - 0.7554, recall - 0.9348, AUC - 0.9185, F1 - 0.7926, precision - 0.688, training time - -12.0 seconds
2023-03-27 14:18:48,614 : [INFO]  Batch 67: Testing set : loss - 0.561, accuracy - 0.7206, recall - 0.9608, AUC - 0.9208, F1 - 0.7747, precision - 0.649
2023-03-27 14:18:48,620 : [INFO]  Batch 68 initialized 
2023-03-27 14:18:49,570 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:18:50,275 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-27 14:18:56,713 : [INFO]  ------------------------- Batch round 1, loss: 0.5391 -------------------------
2023-03-27 14:18:56,714 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-27 14:18:56,736 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:56,738 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-27 14:18:59,547 : [INFO]  ------------------------- Batch round 2, loss: 0.534 -------------------------
2023-03-27 14:18:59,548 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-27 14:18:59,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:18:59,619 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-27 14:19:03,116 : [INFO]  ------------------------- Batch round 3, loss: 0.5282 -------------------------
2023-03-27 14:19:03,116 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:03,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:03,122 : [INFO]  Batch number 68 model fetched from the server
2023-03-27 14:19:03,122 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-27 14:19:04,720 : [INFO]  Batch 68: Training set : loss - 0.531, accuracy - 0.7989, recall - 0.9783, AUC - 0.9343, F1 - 0.8295, precision - 0.72, training time - -13.0 seconds
2023-03-27 14:19:04,721 : [INFO]  Batch 68: Testing set : loss - 0.5465, accuracy - 0.7598, recall - 0.9314, AUC - 0.8832, F1 - 0.795, precision - 0.6934
2023-03-27 14:19:04,729 : [INFO]  Batch 69 initialized 
2023-03-27 14:19:05,190 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:05,631 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-27 14:19:11,632 : [INFO]  ------------------------- Batch round 1, loss: 0.5523 -------------------------
2023-03-27 14:19:11,633 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-27 14:19:11,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:11,827 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-27 14:19:14,653 : [INFO]  ------------------------- Batch round 2, loss: 0.5533 -------------------------
2023-03-27 14:19:14,653 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-27 14:19:14,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:14,834 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-27 14:19:17,567 : [INFO]  ------------------------- Batch round 3, loss: 0.5507 -------------------------
2023-03-27 14:19:17,568 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:17,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:17,688 : [INFO]  Batch number 69 model fetched from the server
2023-03-27 14:19:17,688 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-27 14:19:19,227 : [INFO]  Batch 69: Training set : loss - 0.5506, accuracy - 0.7609, recall - 0.9674, AUC - 0.9171, F1 - 0.8018, precision - 0.6846, training time - -12.0 seconds
2023-03-27 14:19:19,227 : [INFO]  Batch 69: Testing set : loss - 0.5801, accuracy - 0.6814, recall - 0.902, AUC - 0.8839, F1 - 0.739, precision - 0.6259
2023-03-27 14:19:19,235 : [INFO]  Batch 70 initialized 
2023-03-27 14:19:19,701 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:20,126 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-27 14:19:26,178 : [INFO]  ------------------------- Batch round 1, loss: 0.5443 -------------------------
2023-03-27 14:19:26,178 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-27 14:19:26,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:26,241 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-27 14:19:29,232 : [INFO]  ------------------------- Batch round 2, loss: 0.5381 -------------------------
2023-03-27 14:19:29,233 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-27 14:19:29,359 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:29,362 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-27 14:19:32,623 : [INFO]  ------------------------- Batch round 3, loss: 0.5339 -------------------------
2023-03-27 14:19:32,623 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:32,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:32,646 : [INFO]  Batch number 70 model fetched from the server
2023-03-27 14:19:32,646 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-27 14:19:35,340 : [INFO]  Batch 70: Training set : loss - 0.5356, accuracy - 0.7554, recall - 0.9457, AUC - 0.9214, F1 - 0.7945, precision - 0.685, training time - -13.0 seconds
2023-03-27 14:19:35,341 : [INFO]  Batch 70: Testing set : loss - 0.537, accuracy - 0.7451, recall - 0.951, AUC - 0.9293, F1 - 0.7886, precision - 0.6736
2023-03-27 14:19:35,351 : [INFO]  Batch 71 initialized 
2023-03-27 14:19:36,401 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:37,158 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-27 14:19:43,163 : [INFO]  ------------------------- Batch round 1, loss: 0.5485 -------------------------
2023-03-27 14:19:43,163 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-27 14:19:43,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:43,619 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-27 14:19:47,274 : [INFO]  ------------------------- Batch round 2, loss: 0.5388 -------------------------
2023-03-27 14:19:47,275 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-27 14:19:47,283 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:47,291 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-27 14:19:50,862 : [INFO]  ------------------------- Batch round 3, loss: 0.5402 -------------------------
2023-03-27 14:19:50,862 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-27 14:19:50,966 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:19:50,970 : [INFO]  Batch number 71 model fetched from the server
2023-03-27 14:19:50,971 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-27 14:19:53,453 : [INFO]  Batch 71: Training set : loss - 0.5396, accuracy - 0.7663, recall - 0.9457, AUC - 0.9094, F1 - 0.8018, precision - 0.696, training time - -14.0 seconds
2023-03-27 14:19:53,454 : [INFO]  Batch 71: Testing set : loss - 0.5421, accuracy - 0.7402, recall - 0.9412, AUC - 0.8985, F1 - 0.7837, precision - 0.6713
2023-03-27 14:19:53,461 : [INFO]  Batch 72 initialized 
2023-03-27 14:19:54,355 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:19:55,141 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-27 14:20:01,052 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-27 14:20:01,053 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:01,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:01,191 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-27 14:20:04,295 : [INFO]  ------------------------- Batch round 2, loss: 0.5479 -------------------------
2023-03-27 14:20:04,295 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:04,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:04,481 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-27 14:20:06,858 : [INFO]  ------------------------- Batch round 3, loss: 0.5413 -------------------------
2023-03-27 14:20:06,858 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:06,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:06,863 : [INFO]  Batch number 72 model fetched from the server
2023-03-27 14:20:06,863 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-27 14:20:08,526 : [INFO]  Batch 72: Training set : loss - 0.5446, accuracy - 0.7826, recall - 0.9565, AUC - 0.9035, F1 - 0.8148, precision - 0.7097, training time - -12.0 seconds
2023-03-27 14:20:08,526 : [INFO]  Batch 72: Testing set : loss - 0.5699, accuracy - 0.6912, recall - 0.8922, AUC - 0.8691, F1 - 0.7429, precision - 0.6364
2023-03-27 14:20:08,532 : [INFO]  Batch 73 initialized 
2023-03-27 14:20:09,377 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:09,829 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-27 14:20:15,975 : [INFO]  ------------------------- Batch round 1, loss: 0.5662 -------------------------
2023-03-27 14:20:15,975 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:15,979 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:15,982 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-27 14:20:19,741 : [INFO]  ------------------------- Batch round 2, loss: 0.564 -------------------------
2023-03-27 14:20:19,742 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:20,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:20,155 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-27 14:20:22,932 : [INFO]  ------------------------- Batch round 3, loss: 0.5617 -------------------------
2023-03-27 14:20:22,932 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:23,005 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:23,008 : [INFO]  Batch number 73 model fetched from the server
2023-03-27 14:20:23,009 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-27 14:20:25,144 : [INFO]  Batch 73: Training set : loss - 0.5642, accuracy - 0.7772, recall - 0.9457, AUC - 0.8707, F1 - 0.8093, precision - 0.7073, training time - -13.0 seconds
2023-03-27 14:20:25,144 : [INFO]  Batch 73: Testing set : loss - 0.5412, accuracy - 0.7745, recall - 0.9216, AUC - 0.9051, F1 - 0.8034, precision - 0.7121
2023-03-27 14:20:25,152 : [INFO]  Batch 74 initialized 
2023-03-27 14:20:25,803 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:26,450 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-27 14:20:32,031 : [INFO]  ------------------------- Batch round 1, loss: 0.5344 -------------------------
2023-03-27 14:20:32,031 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:32,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:32,199 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-27 14:20:34,673 : [INFO]  ------------------------- Batch round 2, loss: 0.5312 -------------------------
2023-03-27 14:20:34,674 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:34,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:34,712 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-27 14:20:38,056 : [INFO]  ------------------------- Batch round 3, loss: 0.5291 -------------------------
2023-03-27 14:20:38,056 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:38,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:38,414 : [INFO]  Batch number 74 model fetched from the server
2023-03-27 14:20:38,414 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-27 14:20:40,332 : [INFO]  Batch 74: Training set : loss - 0.5256, accuracy - 0.7826, recall - 0.9783, AUC - 0.9252, F1 - 0.8182, precision - 0.7031, training time - -12.0 seconds
2023-03-27 14:20:40,333 : [INFO]  Batch 74: Testing set : loss - 0.5711, accuracy - 0.7157, recall - 0.9118, AUC - 0.8734, F1 - 0.7623, precision - 0.6549
2023-03-27 14:20:40,338 : [INFO]  Batch 75 initialized 
2023-03-27 14:20:40,908 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:41,405 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-27 14:20:48,450 : [INFO]  ------------------------- Batch round 1, loss: 0.5324 -------------------------
2023-03-27 14:20:48,450 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-27 14:20:48,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:48,520 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-27 14:20:51,092 : [INFO]  ------------------------- Batch round 2, loss: 0.5207 -------------------------
2023-03-27 14:20:51,092 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-27 14:20:51,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:51,137 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-27 14:20:53,913 : [INFO]  ------------------------- Batch round 3, loss: 0.5154 -------------------------
2023-03-27 14:20:53,914 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-27 14:20:53,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:20:53,978 : [INFO]  Batch number 75 model fetched from the server
2023-03-27 14:20:53,978 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-27 14:20:55,715 : [INFO]  Batch 75: Training set : loss - 0.5178, accuracy - 0.8152, recall - 0.9783, AUC - 0.9472, F1 - 0.8411, precision - 0.7377, training time - -13.0 seconds
2023-03-27 14:20:55,715 : [INFO]  Batch 75: Testing set : loss - 0.5516, accuracy - 0.7549, recall - 0.9804, AUC - 0.9293, F1 - 0.8, precision - 0.6757
2023-03-27 14:20:55,726 : [INFO]  Batch 76 initialized 
2023-03-27 14:20:56,266 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:20:56,804 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-27 14:21:01,951 : [INFO]  ------------------------- Batch round 1, loss: 0.5383 -------------------------
2023-03-27 14:21:01,952 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:02,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:02,026 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-27 14:21:04,597 : [INFO]  ------------------------- Batch round 2, loss: 0.5317 -------------------------
2023-03-27 14:21:04,597 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:04,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:04,772 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-27 14:21:07,457 : [INFO]  ------------------------- Batch round 3, loss: 0.5293 -------------------------
2023-03-27 14:21:07,457 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:07,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:07,482 : [INFO]  Batch number 76 model fetched from the server
2023-03-27 14:21:07,482 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-27 14:21:09,250 : [INFO]  Batch 76: Training set : loss - 0.5295, accuracy - 0.7826, recall - 0.9891, AUC - 0.94, F1 - 0.8198, precision - 0.7, training time - -11.0 seconds
2023-03-27 14:21:09,250 : [INFO]  Batch 76: Testing set : loss - 0.5438, accuracy - 0.7402, recall - 0.9804, AUC - 0.9519, F1 - 0.7905, precision - 0.6623
2023-03-27 14:21:09,259 : [INFO]  Batch 77 initialized 
2023-03-27 14:21:09,847 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:10,320 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-27 14:21:15,220 : [INFO]  ------------------------- Batch round 1, loss: 0.5192 -------------------------
2023-03-27 14:21:15,221 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:15,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:15,246 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-27 14:21:17,896 : [INFO]  ------------------------- Batch round 2, loss: 0.5134 -------------------------
2023-03-27 14:21:17,896 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:17,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:17,902 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-27 14:21:20,574 : [INFO]  ------------------------- Batch round 3, loss: 0.5098 -------------------------
2023-03-27 14:21:20,574 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:20,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:20,579 : [INFO]  Batch number 77 model fetched from the server
2023-03-27 14:21:20,579 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-27 14:21:22,215 : [INFO]  Batch 77: Training set : loss - 0.5102, accuracy - 0.8152, recall - 0.9783, AUC - 0.9569, F1 - 0.8411, precision - 0.7377, training time - -10.0 seconds
2023-03-27 14:21:22,215 : [INFO]  Batch 77: Testing set : loss - 0.555, accuracy - 0.7206, recall - 0.9412, AUC - 0.8934, F1 - 0.7711, precision - 0.6531
2023-03-27 14:21:22,223 : [INFO]  Batch 78 initialized 
2023-03-27 14:21:22,737 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:23,225 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-27 14:21:28,154 : [INFO]  ------------------------- Batch round 1, loss: 0.5613 -------------------------
2023-03-27 14:21:28,154 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:28,273 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:28,275 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-27 14:21:30,863 : [INFO]  ------------------------- Batch round 2, loss: 0.5534 -------------------------
2023-03-27 14:21:30,864 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:30,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:30,947 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-27 14:21:33,569 : [INFO]  ------------------------- Batch round 3, loss: 0.549 -------------------------
2023-03-27 14:21:33,569 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:33,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:33,632 : [INFO]  Batch number 78 model fetched from the server
2023-03-27 14:21:33,632 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-27 14:21:35,415 : [INFO]  Batch 78: Training set : loss - 0.5506, accuracy - 0.7609, recall - 0.9783, AUC - 0.8993, F1 - 0.8036, precision - 0.6818, training time - -10.0 seconds
2023-03-27 14:21:35,416 : [INFO]  Batch 78: Testing set : loss - 0.5473, accuracy - 0.75, recall - 0.9706, AUC - 0.9123, F1 - 0.7952, precision - 0.6735
2023-03-27 14:21:35,424 : [INFO]  Batch 79 initialized 
2023-03-27 14:21:35,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:36,441 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-27 14:21:41,508 : [INFO]  ------------------------- Batch round 1, loss: 0.5519 -------------------------
2023-03-27 14:21:41,508 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:41,574 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:41,576 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-27 14:21:44,246 : [INFO]  ------------------------- Batch round 2, loss: 0.5432 -------------------------
2023-03-27 14:21:44,247 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:44,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:44,252 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-27 14:21:47,117 : [INFO]  ------------------------- Batch round 3, loss: 0.5383 -------------------------
2023-03-27 14:21:47,118 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-27 14:21:47,121 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:47,123 : [INFO]  Batch number 79 model fetched from the server
2023-03-27 14:21:47,123 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-27 14:21:48,822 : [INFO]  Batch 79: Training set : loss - 0.5499, accuracy - 0.7337, recall - 0.9239, AUC - 0.8951, F1 - 0.7763, precision - 0.6693, training time - -11.0 seconds
2023-03-27 14:21:48,822 : [INFO]  Batch 79: Testing set : loss - 0.5786, accuracy - 0.7206, recall - 0.8922, AUC - 0.8492, F1 - 0.7615, precision - 0.6642
2023-03-27 14:21:48,832 : [INFO]  Batch 80 initialized 
2023-03-27 14:21:49,368 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:21:49,850 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-27 14:21:55,071 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-27 14:21:55,072 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-27 14:21:55,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:55,079 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-27 14:21:57,899 : [INFO]  ------------------------- Batch round 2, loss: 0.5462 -------------------------
2023-03-27 14:21:57,899 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-27 14:21:57,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:21:57,904 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-27 14:22:00,460 : [INFO]  ------------------------- Batch round 3, loss: 0.5411 -------------------------
2023-03-27 14:22:00,460 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:00,463 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:00,468 : [INFO]  Batch number 80 model fetched from the server
2023-03-27 14:22:00,468 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-27 14:22:02,146 : [INFO]  Batch 80: Training set : loss - 0.5415, accuracy - 0.7391, recall - 0.9674, AUC - 0.9181, F1 - 0.7876, precision - 0.6642, training time - -11.0 seconds
2023-03-27 14:22:02,146 : [INFO]  Batch 80: Testing set : loss - 0.5761, accuracy - 0.7059, recall - 0.9412, AUC - 0.8617, F1 - 0.7619, precision - 0.64
2023-03-27 14:22:02,158 : [INFO]  Batch 81 initialized 
2023-03-27 14:22:02,651 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:03,122 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-27 14:22:08,053 : [INFO]  ------------------------- Batch round 1, loss: 0.5532 -------------------------
2023-03-27 14:22:08,054 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:08,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:08,112 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-27 14:22:10,716 : [INFO]  ------------------------- Batch round 2, loss: 0.5486 -------------------------
2023-03-27 14:22:10,716 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:10,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:10,760 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-27 14:22:13,285 : [INFO]  ------------------------- Batch round 3, loss: 0.5457 -------------------------
2023-03-27 14:22:13,285 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:13,339 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:13,342 : [INFO]  Batch number 81 model fetched from the server
2023-03-27 14:22:13,342 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-27 14:22:14,990 : [INFO]  Batch 81: Training set : loss - 0.541, accuracy - 0.7554, recall - 0.9565, AUC - 0.9253, F1 - 0.7964, precision - 0.6822, training time - -10.0 seconds
2023-03-27 14:22:14,991 : [INFO]  Batch 81: Testing set : loss - 0.5538, accuracy - 0.7451, recall - 0.951, AUC - 0.8909, F1 - 0.7886, precision - 0.6736
2023-03-27 14:22:14,999 : [INFO]  Batch 82 initialized 
2023-03-27 14:22:15,489 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:15,948 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-27 14:22:20,828 : [INFO]  ------------------------- Batch round 1, loss: 0.549 -------------------------
2023-03-27 14:22:20,828 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:20,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:20,953 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-27 14:22:23,552 : [INFO]  ------------------------- Batch round 2, loss: 0.5409 -------------------------
2023-03-27 14:22:23,553 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:23,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:23,816 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-27 14:22:26,576 : [INFO]  ------------------------- Batch round 3, loss: 0.5373 -------------------------
2023-03-27 14:22:26,576 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:26,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:26,582 : [INFO]  Batch number 82 model fetched from the server
2023-03-27 14:22:26,582 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-27 14:22:28,226 : [INFO]  Batch 82: Training set : loss - 0.5432, accuracy - 0.7609, recall - 0.9022, AUC - 0.8944, F1 - 0.7905, precision - 0.7034, training time - -11.0 seconds
2023-03-27 14:22:28,226 : [INFO]  Batch 82: Testing set : loss - 0.5347, accuracy - 0.7451, recall - 0.951, AUC - 0.9124, F1 - 0.7886, precision - 0.6736
2023-03-27 14:22:28,236 : [INFO]  Batch 83 initialized 
2023-03-27 14:22:28,740 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:29,205 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-27 14:22:35,165 : [INFO]  ------------------------- Batch round 1, loss: 0.5588 -------------------------
2023-03-27 14:22:35,166 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:35,344 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:35,346 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-27 14:22:38,961 : [INFO]  ------------------------- Batch round 2, loss: 0.5546 -------------------------
2023-03-27 14:22:38,962 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:38,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:38,970 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-27 14:22:42,080 : [INFO]  ------------------------- Batch round 3, loss: 0.5475 -------------------------
2023-03-27 14:22:42,080 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-27 14:22:42,187 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:42,189 : [INFO]  Batch number 83 model fetched from the server
2023-03-27 14:22:42,189 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-27 14:22:44,270 : [INFO]  Batch 83: Training set : loss - 0.5514, accuracy - 0.7609, recall - 0.9457, AUC - 0.9074, F1 - 0.7982, precision - 0.6905, training time - -13.0 seconds
2023-03-27 14:22:44,270 : [INFO]  Batch 83: Testing set : loss - 0.5519, accuracy - 0.7745, recall - 0.9412, AUC - 0.8812, F1 - 0.8067, precision - 0.7059
2023-03-27 14:22:44,280 : [INFO]  Batch 84 initialized 
2023-03-27 14:22:45,184 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:22:46,018 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-27 14:22:54,114 : [INFO]  ------------------------- Batch round 1, loss: 0.5582 -------------------------
2023-03-27 14:22:54,117 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-27 14:22:54,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:54,252 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-27 14:22:57,463 : [INFO]  ------------------------- Batch round 2, loss: 0.5548 -------------------------
2023-03-27 14:22:57,463 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-27 14:22:57,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:22:57,621 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-27 14:23:00,585 : [INFO]  ------------------------- Batch round 3, loss: 0.5515 -------------------------
2023-03-27 14:23:00,585 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:00,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:00,595 : [INFO]  Batch number 84 model fetched from the server
2023-03-27 14:23:00,595 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-27 14:23:02,094 : [INFO]  Batch 84: Training set : loss - 0.5481, accuracy - 0.7554, recall - 0.9457, AUC - 0.9115, F1 - 0.7945, precision - 0.685, training time - -15.0 seconds
2023-03-27 14:23:02,094 : [INFO]  Batch 84: Testing set : loss - 0.5862, accuracy - 0.701, recall - 0.9314, AUC - 0.8914, F1 - 0.757, precision - 0.6376
2023-03-27 14:23:02,108 : [INFO]  Batch 85 initialized 
2023-03-27 14:23:02,610 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:03,077 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-27 14:23:07,925 : [INFO]  ------------------------- Batch round 1, loss: 0.5624 -------------------------
2023-03-27 14:23:07,925 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:08,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:08,087 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-27 14:23:11,087 : [INFO]  ------------------------- Batch round 2, loss: 0.5538 -------------------------
2023-03-27 14:23:11,087 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:11,262 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:11,266 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-27 14:23:14,682 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-27 14:23:14,683 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:14,688 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:14,690 : [INFO]  Batch number 85 model fetched from the server
2023-03-27 14:23:14,690 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-27 14:23:16,894 : [INFO]  Batch 85: Training set : loss - 0.5512, accuracy - 0.7663, recall - 0.9457, AUC - 0.9077, F1 - 0.8018, precision - 0.696, training time - -12.0 seconds
2023-03-27 14:23:16,894 : [INFO]  Batch 85: Testing set : loss - 0.5533, accuracy - 0.7402, recall - 0.951, AUC - 0.9064, F1 - 0.7854, precision - 0.669
2023-03-27 14:23:16,902 : [INFO]  Batch 86 initialized 
2023-03-27 14:23:17,549 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:17,959 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-27 14:23:22,974 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-27 14:23:22,975 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:22,981 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:22,985 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-27 14:23:26,598 : [INFO]  ------------------------- Batch round 2, loss: 0.5613 -------------------------
2023-03-27 14:23:26,599 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:26,604 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:26,607 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-27 14:23:29,991 : [INFO]  ------------------------- Batch round 3, loss: 0.557 -------------------------
2023-03-27 14:23:29,992 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:30,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:30,021 : [INFO]  Batch number 86 model fetched from the server
2023-03-27 14:23:30,022 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-27 14:23:32,044 : [INFO]  Batch 86: Training set : loss - 0.5599, accuracy - 0.7283, recall - 0.9565, AUC - 0.9034, F1 - 0.7788, precision - 0.6567, training time - -12.0 seconds
2023-03-27 14:23:32,044 : [INFO]  Batch 86: Testing set : loss - 0.5572, accuracy - 0.7402, recall - 0.9412, AUC - 0.8998, F1 - 0.7837, precision - 0.6713
2023-03-27 14:23:32,050 : [INFO]  Batch 87 initialized 
2023-03-27 14:23:32,784 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:33,324 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-27 14:23:39,892 : [INFO]  ------------------------- Batch round 1, loss: 0.5642 -------------------------
2023-03-27 14:23:39,893 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:39,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:39,919 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-27 14:23:42,668 : [INFO]  ------------------------- Batch round 2, loss: 0.5597 -------------------------
2023-03-27 14:23:42,668 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:42,760 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:42,763 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-27 14:23:45,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5551 -------------------------
2023-03-27 14:23:45,580 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-27 14:23:45,647 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:45,650 : [INFO]  Batch number 87 model fetched from the server
2023-03-27 14:23:45,650 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-27 14:23:47,541 : [INFO]  Batch 87: Training set : loss - 0.5543, accuracy - 0.75, recall - 0.9565, AUC - 0.9022, F1 - 0.7928, precision - 0.6769, training time - -12.0 seconds
2023-03-27 14:23:47,542 : [INFO]  Batch 87: Testing set : loss - 0.5496, accuracy - 0.799, recall - 0.9804, AUC - 0.9012, F1 - 0.8299, precision - 0.7194
2023-03-27 14:23:47,552 : [INFO]  Batch 88 initialized 
2023-03-27 14:23:48,093 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:23:48,657 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-27 14:23:54,139 : [INFO]  ------------------------- Batch round 1, loss: 0.5563 -------------------------
2023-03-27 14:23:54,139 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-27 14:23:54,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:54,164 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-27 14:23:57,124 : [INFO]  ------------------------- Batch round 2, loss: 0.5535 -------------------------
2023-03-27 14:23:57,124 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-27 14:23:57,150 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:23:57,153 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-27 14:24:00,358 : [INFO]  ------------------------- Batch round 3, loss: 0.548 -------------------------
2023-03-27 14:24:00,358 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:00,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:00,387 : [INFO]  Batch number 88 model fetched from the server
2023-03-27 14:24:00,388 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-27 14:24:02,239 : [INFO]  Batch 88: Training set : loss - 0.5533, accuracy - 0.7391, recall - 0.9348, AUC - 0.8921, F1 - 0.7818, precision - 0.6719, training time - -12.0 seconds
2023-03-27 14:24:02,239 : [INFO]  Batch 88: Testing set : loss - 0.5445, accuracy - 0.7745, recall - 0.9608, AUC - 0.9065, F1 - 0.8099, precision - 0.7
2023-03-27 14:24:02,251 : [INFO]  Batch 89 initialized 
2023-03-27 14:24:02,846 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:03,391 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-27 14:24:09,505 : [INFO]  ------------------------- Batch round 1, loss: 0.5519 -------------------------
2023-03-27 14:24:09,506 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:09,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:09,570 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-27 14:24:12,705 : [INFO]  ------------------------- Batch round 2, loss: 0.5408 -------------------------
2023-03-27 14:24:12,705 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:12,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:12,711 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-27 14:24:15,780 : [INFO]  ------------------------- Batch round 3, loss: 0.5379 -------------------------
2023-03-27 14:24:15,781 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:15,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:15,797 : [INFO]  Batch number 89 model fetched from the server
2023-03-27 14:24:15,797 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-27 14:24:17,668 : [INFO]  Batch 89: Training set : loss - 0.5369, accuracy - 0.788, recall - 0.9565, AUC - 0.888, F1 - 0.8186, precision - 0.7154, training time - -12.0 seconds
2023-03-27 14:24:17,668 : [INFO]  Batch 89: Testing set : loss - 0.53, accuracy - 0.7794, recall - 0.9608, AUC - 0.9472, F1 - 0.8133, precision - 0.705
2023-03-27 14:24:17,683 : [INFO]  Batch 90 initialized 
2023-03-27 14:24:18,291 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:18,879 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-27 14:24:24,455 : [INFO]  ------------------------- Batch round 1, loss: 0.5769 -------------------------
2023-03-27 14:24:24,455 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:24,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:24,532 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-27 14:24:27,417 : [INFO]  ------------------------- Batch round 2, loss: 0.5683 -------------------------
2023-03-27 14:24:27,417 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:27,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:27,509 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-27 14:24:30,303 : [INFO]  ------------------------- Batch round 3, loss: 0.5615 -------------------------
2023-03-27 14:24:30,303 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:30,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:30,387 : [INFO]  Batch number 90 model fetched from the server
2023-03-27 14:24:30,387 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-27 14:24:32,217 : [INFO]  Batch 90: Training set : loss - 0.5618, accuracy - 0.7228, recall - 0.913, AUC - 0.8874, F1 - 0.7671, precision - 0.6614, training time - -12.0 seconds
2023-03-27 14:24:32,218 : [INFO]  Batch 90: Testing set : loss - 0.5695, accuracy - 0.7206, recall - 0.951, AUC - 0.8905, F1 - 0.7729, precision - 0.651
2023-03-27 14:24:32,233 : [INFO]  Batch 91 initialized 
2023-03-27 14:24:32,754 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:33,362 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-27 14:24:38,998 : [INFO]  ------------------------- Batch round 1, loss: 0.5601 -------------------------
2023-03-27 14:24:38,999 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:39,055 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:39,060 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-27 14:24:41,886 : [INFO]  ------------------------- Batch round 2, loss: 0.5525 -------------------------
2023-03-27 14:24:41,886 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:41,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:41,892 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-27 14:24:44,820 : [INFO]  ------------------------- Batch round 3, loss: 0.5483 -------------------------
2023-03-27 14:24:44,821 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-27 14:24:44,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:44,826 : [INFO]  Batch number 91 model fetched from the server
2023-03-27 14:24:44,826 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-27 14:24:46,865 : [INFO]  Batch 91: Training set : loss - 0.5455, accuracy - 0.7446, recall - 0.9457, AUC - 0.9334, F1 - 0.7873, precision - 0.6744, training time - -11.0 seconds
2023-03-27 14:24:46,865 : [INFO]  Batch 91: Testing set : loss - 0.5598, accuracy - 0.7402, recall - 0.9608, AUC - 0.8952, F1 - 0.7871, precision - 0.6667
2023-03-27 14:24:46,879 : [INFO]  Batch 92 initialized 
2023-03-27 14:24:47,920 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:24:48,907 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-27 14:24:54,600 : [INFO]  ------------------------- Batch round 1, loss: 0.5625 -------------------------
2023-03-27 14:24:54,600 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-27 14:24:54,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:54,627 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-27 14:24:57,393 : [INFO]  ------------------------- Batch round 2, loss: 0.5521 -------------------------
2023-03-27 14:24:57,393 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-27 14:24:57,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:24:57,399 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-27 14:25:00,355 : [INFO]  ------------------------- Batch round 3, loss: 0.5526 -------------------------
2023-03-27 14:25:00,355 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-27 14:25:00,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:00,363 : [INFO]  Batch number 92 model fetched from the server
2023-03-27 14:25:00,364 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-27 14:25:02,142 : [INFO]  Batch 92: Training set : loss - 0.5494, accuracy - 0.7663, recall - 0.9348, AUC - 0.8869, F1 - 0.8, precision - 0.6992, training time - -11.0 seconds
2023-03-27 14:25:02,142 : [INFO]  Batch 92: Testing set : loss - 0.5549, accuracy - 0.7549, recall - 0.9608, AUC - 0.8952, F1 - 0.7967, precision - 0.6806
2023-03-27 14:25:02,153 : [INFO]  Batch 93 initialized 
2023-03-27 14:25:02,691 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:25:03,226 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-27 14:25:08,773 : [INFO]  ------------------------- Batch round 1, loss: 0.553 -------------------------
2023-03-27 14:25:08,773 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-27 14:25:08,776 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:08,778 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-27 14:25:11,596 : [INFO]  ------------------------- Batch round 2, loss: 0.5488 -------------------------
2023-03-27 14:25:11,596 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-27 14:25:11,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:11,663 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-27 14:25:14,405 : [INFO]  ------------------------- Batch round 3, loss: 0.5439 -------------------------
2023-03-27 14:25:14,405 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-27 14:25:14,453 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:25:14,455 : [INFO]  Batch number 93 model fetched from the server
2023-03-27 14:25:14,455 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-27 14:25:16,397 : [INFO]  Batch 93: Training set : loss - 0.5448, accuracy - 0.75, recall - 0.8913, AUC - 0.8995, F1 - 0.781, precision - 0.6949, training time - -11.0 seconds
2023-03-27 14:25:16,398 : [INFO]  Batch 93: Testing set : loss - 0.5752, accuracy - 0.7108, recall - 0.902, AUC - 0.8701, F1 - 0.7572, precision - 0.6525
2023-03-27 14:25:16,409 : [INFO]  Result report : Accuracy - 0.747 (0.0287), Recall - 0.9409 (0.0264), AUC - 0.8901 (0.0301), F1 - 0.7883 (0.022), Precision - 0.6787 (0.0256)
2023-03-27 14:25:16,409 : [INFO]  Result report : Accuracy - 0.747 (0.0287), Recall - 0.9409 (0.0264), AUC - 0.8901 (0.0301), F1 - 0.7883 (0.022), Precision - 0.6787 (0.0256), Mean time for a batch - 10.07 (1.49) seconds
2023-03-27 14:25:16,409 : [INFO]  Distributed training done!
2023-03-27 14:25:16,409 : [INFO]  Training report : Total elapsed time 1309.2733842359994 seconds, graph name wikipedia, graph ID 1, partition ID 1, training epochs 6, epochs 6
