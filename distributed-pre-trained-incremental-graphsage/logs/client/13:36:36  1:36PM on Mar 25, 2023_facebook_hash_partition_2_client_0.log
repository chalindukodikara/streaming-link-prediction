2023-03-25 13:36:36,932 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 13:36:36,932 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 1, epochs 8
2023-03-25 13:36:39,709 : [INFO]  Model initialized for training
2023-03-25 13:36:52,697 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:36:52,829 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 13:36:52,830 : [INFO]  Connected to the server
2023-03-25 13:36:52,919 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 13:36:52,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:36:52,926 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 13:36:52,926 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 13:37:16,572 : [INFO]  ------------------------- Training round 1, loss: 0.6768 -------------------------
2023-03-25 13:37:16,572 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 13:37:16,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:37:16,577 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 13:37:39,031 : [INFO]  ------------------------- Training round 2, loss: 0.6358 -------------------------
2023-03-25 13:37:39,031 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 13:37:39,034 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:37:39,037 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 13:38:01,536 : [INFO]  ------------------------- Training round 3, loss: 0.6146 -------------------------
2023-03-25 13:38:01,536 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 13:38:01,540 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:38:01,541 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 13:38:25,594 : [INFO]  ------------------------- Training round 4, loss: 0.606 -------------------------
2023-03-25 13:38:25,614 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 13:38:25,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:38:25,620 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 13:38:51,359 : [INFO]  ------------------------- Training round 5, loss: 0.6017 -------------------------
2023-03-25 13:38:51,359 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 13:38:51,362 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:38:51,364 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 13:39:37,961 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.82, F1 - 0.74, precision - 0.64, training time - -118.0 seconds
2023-03-25 13:39:37,961 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 13:39:37,978 : [INFO]  Batch 1 initialized 
2023-03-25 13:39:38,562 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:39:38,672 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 13:39:38,672 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 13:39:43,787 : [INFO]  ------------------------- Batch round 1, loss: 0.6063 -------------------------
2023-03-25 13:39:43,787 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 13:39:43,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:43,792 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 13:39:46,579 : [INFO]  ------------------------- Batch round 2, loss: 0.579 -------------------------
2023-03-25 13:39:46,579 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 13:39:46,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:46,584 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 13:39:49,793 : [INFO]  ------------------------- Batch round 3, loss: 0.5732 -------------------------
2023-03-25 13:39:49,793 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 13:39:49,797 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:49,799 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 13:39:49,799 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 13:39:51,249 : [INFO]  Batch 1: Training set : loss - 0.5766, accuracy - 0.7554, recall - 0.9348, AUC - 0.84, F1 - 0.7926, precision - 0.688, training time - -11.0 seconds
2023-03-25 13:39:51,250 : [INFO]  Batch 1: Testing set : loss - 0.5614, accuracy - 0.75, recall - 0.8627, AUC - 0.8618, F1 - 0.7753, precision - 0.704
2023-03-25 13:39:51,266 : [INFO]  Batch 2 initialized 
2023-03-25 13:39:51,922 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:39:52,076 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 13:39:58,143 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-25 13:39:58,143 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 13:39:58,212 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:39:58,215 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 13:40:02,262 : [INFO]  ------------------------- Batch round 2, loss: 0.5525 -------------------------
2023-03-25 13:40:02,263 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:02,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:02,727 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 13:40:05,953 : [INFO]  ------------------------- Batch round 3, loss: 0.5429 -------------------------
2023-03-25 13:40:05,953 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:05,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:05,959 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 13:40:05,959 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 13:40:07,342 : [INFO]  Batch 2: Training set : loss - 0.5431, accuracy - 0.7772, recall - 0.9565, AUC - 0.8964, F1 - 0.8111, precision - 0.704, training time - -14.0 seconds
2023-03-25 13:40:07,342 : [INFO]  Batch 2: Testing set : loss - 0.5635, accuracy - 0.7451, recall - 0.902, AUC - 0.8658, F1 - 0.7797, precision - 0.6866
2023-03-25 13:40:07,354 : [INFO]  Batch 3 initialized 
2023-03-25 13:40:07,798 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:08,033 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 13:40:12,906 : [INFO]  ------------------------- Batch round 1, loss: 0.5329 -------------------------
2023-03-25 13:40:12,907 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:12,951 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:12,953 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 13:40:15,898 : [INFO]  ------------------------- Batch round 2, loss: 0.5219 -------------------------
2023-03-25 13:40:15,899 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:16,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:16,177 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 13:40:19,477 : [INFO]  ------------------------- Batch round 3, loss: 0.5241 -------------------------
2023-03-25 13:40:19,477 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:19,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:19,482 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 13:40:19,482 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 13:40:20,828 : [INFO]  Batch 3: Training set : loss - 0.5286, accuracy - 0.7935, recall - 0.9022, AUC - 0.8686, F1 - 0.8137, precision - 0.7411, training time - -11.0 seconds
2023-03-25 13:40:20,829 : [INFO]  Batch 3: Testing set : loss - 0.5647, accuracy - 0.6961, recall - 0.951, AUC - 0.8665, F1 - 0.7578, precision - 0.6299
2023-03-25 13:40:20,837 : [INFO]  Batch 4 initialized 
2023-03-25 13:40:21,317 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:21,634 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 13:40:26,635 : [INFO]  ------------------------- Batch round 1, loss: 0.5482 -------------------------
2023-03-25 13:40:26,635 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:26,638 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:26,640 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 13:40:29,598 : [INFO]  ------------------------- Batch round 2, loss: 0.5345 -------------------------
2023-03-25 13:40:29,598 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:29,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:29,603 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 13:40:32,444 : [INFO]  ------------------------- Batch round 3, loss: 0.5286 -------------------------
2023-03-25 13:40:32,444 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:32,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:32,455 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 13:40:32,455 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 13:40:34,067 : [INFO]  Batch 4: Training set : loss - 0.5271, accuracy - 0.7772, recall - 0.9565, AUC - 0.9155, F1 - 0.8111, precision - 0.704, training time - -11.0 seconds
2023-03-25 13:40:34,067 : [INFO]  Batch 4: Testing set : loss - 0.5887, accuracy - 0.6471, recall - 0.9118, AUC - 0.864, F1 - 0.7209, precision - 0.5962
2023-03-25 13:40:34,077 : [INFO]  Batch 5 initialized 
2023-03-25 13:40:34,571 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:34,821 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 13:40:39,652 : [INFO]  ------------------------- Batch round 1, loss: 0.5424 -------------------------
2023-03-25 13:40:39,652 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:39,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:39,657 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 13:40:42,799 : [INFO]  ------------------------- Batch round 2, loss: 0.5339 -------------------------
2023-03-25 13:40:42,799 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:42,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:42,804 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 13:40:45,679 : [INFO]  ------------------------- Batch round 3, loss: 0.5209 -------------------------
2023-03-25 13:40:45,680 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:45,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:45,685 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 13:40:45,685 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 13:40:47,062 : [INFO]  Batch 5: Training set : loss - 0.52, accuracy - 0.788, recall - 0.9565, AUC - 0.9357, F1 - 0.8186, precision - 0.7154, training time - -11.0 seconds
2023-03-25 13:40:47,062 : [INFO]  Batch 5: Testing set : loss - 0.5838, accuracy - 0.6814, recall - 0.8725, AUC - 0.8209, F1 - 0.7325, precision - 0.6312
2023-03-25 13:40:47,069 : [INFO]  Batch 6 initialized 
2023-03-25 13:40:47,509 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:47,752 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 13:40:52,401 : [INFO]  ------------------------- Batch round 1, loss: 0.564 -------------------------
2023-03-25 13:40:52,401 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 13:40:52,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:52,406 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 13:40:55,104 : [INFO]  ------------------------- Batch round 2, loss: 0.5563 -------------------------
2023-03-25 13:40:55,104 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 13:40:55,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:55,136 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 13:40:57,864 : [INFO]  ------------------------- Batch round 3, loss: 0.551 -------------------------
2023-03-25 13:40:57,864 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 13:40:57,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:40:57,915 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 13:40:57,916 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 13:40:59,273 : [INFO]  Batch 6: Training set : loss - 0.5483, accuracy - 0.75, recall - 0.9565, AUC - 0.8756, F1 - 0.7928, precision - 0.6769, training time - -10.0 seconds
2023-03-25 13:40:59,273 : [INFO]  Batch 6: Testing set : loss - 0.5599, accuracy - 0.7255, recall - 0.902, AUC - 0.8818, F1 - 0.7667, precision - 0.6667
2023-03-25 13:40:59,282 : [INFO]  Batch 7 initialized 
2023-03-25 13:40:59,746 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:40:59,989 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 13:41:04,933 : [INFO]  ------------------------- Batch round 1, loss: 0.5745 -------------------------
2023-03-25 13:41:04,933 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:04,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:04,938 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 13:41:07,754 : [INFO]  ------------------------- Batch round 2, loss: 0.5644 -------------------------
2023-03-25 13:41:07,755 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:07,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:07,760 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 13:41:10,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5523 -------------------------
2023-03-25 13:41:10,579 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:10,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:10,584 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 13:41:10,584 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 13:41:11,937 : [INFO]  Batch 7: Training set : loss - 0.5505, accuracy - 0.788, recall - 0.9457, AUC - 0.8667, F1 - 0.8169, precision - 0.719, training time - -11.0 seconds
2023-03-25 13:41:11,937 : [INFO]  Batch 7: Testing set : loss - 0.5861, accuracy - 0.6961, recall - 0.8431, AUC - 0.8112, F1 - 0.735, precision - 0.6515
2023-03-25 13:41:11,946 : [INFO]  Batch 8 initialized 
2023-03-25 13:41:12,392 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:12,631 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 13:41:17,158 : [INFO]  ------------------------- Batch round 1, loss: 0.5856 -------------------------
2023-03-25 13:41:17,158 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:17,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:17,163 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 13:41:19,961 : [INFO]  ------------------------- Batch round 2, loss: 0.5672 -------------------------
2023-03-25 13:41:19,961 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:19,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:19,966 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 13:41:22,779 : [INFO]  ------------------------- Batch round 3, loss: 0.5597 -------------------------
2023-03-25 13:41:22,779 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:22,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:22,785 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 13:41:22,785 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 13:41:24,143 : [INFO]  Batch 8: Training set : loss - 0.5655, accuracy - 0.7228, recall - 0.8804, AUC - 0.8391, F1 - 0.7606, precision - 0.6694, training time - -10.0 seconds
2023-03-25 13:41:24,143 : [INFO]  Batch 8: Testing set : loss - 0.5755, accuracy - 0.7255, recall - 0.8824, AUC - 0.8331, F1 - 0.7627, precision - 0.6716
2023-03-25 13:41:24,149 : [INFO]  Batch 9 initialized 
2023-03-25 13:41:24,572 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:24,821 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 13:41:29,322 : [INFO]  ------------------------- Batch round 1, loss: 0.5504 -------------------------
2023-03-25 13:41:29,322 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:29,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:29,495 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 13:41:32,242 : [INFO]  ------------------------- Batch round 2, loss: 0.5451 -------------------------
2023-03-25 13:41:32,243 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:32,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:32,362 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 13:41:35,225 : [INFO]  ------------------------- Batch round 3, loss: 0.5368 -------------------------
2023-03-25 13:41:35,225 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:35,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:35,325 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 13:41:35,325 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 13:41:36,647 : [INFO]  Batch 9: Training set : loss - 0.5302, accuracy - 0.7446, recall - 0.9348, AUC - 0.913, F1 - 0.7854, precision - 0.6772, training time - -11.0 seconds
2023-03-25 13:41:36,647 : [INFO]  Batch 9: Testing set : loss - 0.5477, accuracy - 0.7059, recall - 0.8824, AUC - 0.8837, F1 - 0.75, precision - 0.6522
2023-03-25 13:41:36,653 : [INFO]  Batch 10 initialized 
2023-03-25 13:41:37,094 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:37,342 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 13:41:41,883 : [INFO]  ------------------------- Batch round 1, loss: 0.5516 -------------------------
2023-03-25 13:41:41,883 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:41,903 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:41,905 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 13:41:44,690 : [INFO]  ------------------------- Batch round 2, loss: 0.5413 -------------------------
2023-03-25 13:41:44,690 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:44,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:44,772 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 13:41:47,538 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 13:41:47,538 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:47,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:47,603 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 13:41:47,603 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 13:41:48,898 : [INFO]  Batch 10: Training set : loss - 0.5311, accuracy - 0.7826, recall - 0.9783, AUC - 0.9204, F1 - 0.8182, precision - 0.7031, training time - -10.0 seconds
2023-03-25 13:41:48,899 : [INFO]  Batch 10: Testing set : loss - 0.5444, accuracy - 0.7304, recall - 0.902, AUC - 0.8948, F1 - 0.7699, precision - 0.6715
2023-03-25 13:41:48,926 : [INFO]  Batch 11 initialized 
2023-03-25 13:41:49,357 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:41:49,616 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 13:41:54,228 : [INFO]  ------------------------- Batch round 1, loss: 0.563 -------------------------
2023-03-25 13:41:54,228 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 13:41:54,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:54,233 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 13:41:57,081 : [INFO]  ------------------------- Batch round 2, loss: 0.5644 -------------------------
2023-03-25 13:41:57,081 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 13:41:57,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:57,087 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 13:41:59,863 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-25 13:41:59,863 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 13:41:59,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:41:59,868 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 13:41:59,868 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 13:42:01,157 : [INFO]  Batch 11: Training set : loss - 0.5567, accuracy - 0.7554, recall - 0.913, AUC - 0.8715, F1 - 0.7887, precision - 0.6942, training time - -10.0 seconds
2023-03-25 13:42:01,158 : [INFO]  Batch 11: Testing set : loss - 0.5558, accuracy - 0.7353, recall - 0.902, AUC - 0.8915, F1 - 0.7731, precision - 0.6765
2023-03-25 13:42:01,166 : [INFO]  Batch 12 initialized 
2023-03-25 13:42:01,592 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:01,841 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 13:42:07,041 : [INFO]  ------------------------- Batch round 1, loss: 0.5675 -------------------------
2023-03-25 13:42:07,041 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:07,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:07,046 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 13:42:10,361 : [INFO]  ------------------------- Batch round 2, loss: 0.5575 -------------------------
2023-03-25 13:42:10,361 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:10,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:10,366 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 13:42:13,253 : [INFO]  ------------------------- Batch round 3, loss: 0.5537 -------------------------
2023-03-25 13:42:13,253 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:13,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:13,258 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 13:42:13,258 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 13:42:14,620 : [INFO]  Batch 12: Training set : loss - 0.5495, accuracy - 0.7717, recall - 0.8913, AUC - 0.8811, F1 - 0.7961, precision - 0.7193, training time - -11.0 seconds
2023-03-25 13:42:14,620 : [INFO]  Batch 12: Testing set : loss - 0.6063, accuracy - 0.6765, recall - 0.8235, AUC - 0.8082, F1 - 0.7179, precision - 0.6364
2023-03-25 13:42:14,628 : [INFO]  Batch 13 initialized 
2023-03-25 13:42:15,094 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:15,346 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 13:42:19,996 : [INFO]  ------------------------- Batch round 1, loss: 0.5915 -------------------------
2023-03-25 13:42:19,996 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:20,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:20,003 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 13:42:22,846 : [INFO]  ------------------------- Batch round 2, loss: 0.5745 -------------------------
2023-03-25 13:42:22,846 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:23,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:23,105 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 13:42:25,999 : [INFO]  ------------------------- Batch round 3, loss: 0.5718 -------------------------
2023-03-25 13:42:25,999 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:26,002 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:26,004 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 13:42:26,004 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 13:42:27,416 : [INFO]  Batch 13: Training set : loss - 0.5745, accuracy - 0.7391, recall - 0.8696, AUC - 0.8318, F1 - 0.7692, precision - 0.6897, training time - -11.0 seconds
2023-03-25 13:42:27,416 : [INFO]  Batch 13: Testing set : loss - 0.603, accuracy - 0.6471, recall - 0.8039, AUC - 0.7889, F1 - 0.6949, precision - 0.6119
2023-03-25 13:42:27,422 : [INFO]  Batch 14 initialized 
2023-03-25 13:42:27,919 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:28,194 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 13:42:32,935 : [INFO]  ------------------------- Batch round 1, loss: 0.5495 -------------------------
2023-03-25 13:42:32,936 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:32,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:32,942 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 13:42:35,827 : [INFO]  ------------------------- Batch round 2, loss: 0.5345 -------------------------
2023-03-25 13:42:35,828 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:35,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:35,833 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 13:42:38,787 : [INFO]  ------------------------- Batch round 3, loss: 0.5258 -------------------------
2023-03-25 13:42:38,787 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:38,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:38,792 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 13:42:38,792 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 13:42:40,258 : [INFO]  Batch 14: Training set : loss - 0.5251, accuracy - 0.7989, recall - 0.9239, AUC - 0.899, F1 - 0.8213, precision - 0.7391, training time - -11.0 seconds
2023-03-25 13:42:40,258 : [INFO]  Batch 14: Testing set : loss - 0.5652, accuracy - 0.7108, recall - 0.8824, AUC - 0.868, F1 - 0.7531, precision - 0.6569
2023-03-25 13:42:40,266 : [INFO]  Batch 15 initialized 
2023-03-25 13:42:40,744 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:41,005 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 13:42:46,083 : [INFO]  ------------------------- Batch round 1, loss: 0.5674 -------------------------
2023-03-25 13:42:46,084 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 13:42:46,125 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:46,127 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 13:42:49,581 : [INFO]  ------------------------- Batch round 2, loss: 0.553 -------------------------
2023-03-25 13:42:49,581 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 13:42:49,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:49,626 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 13:42:52,910 : [INFO]  ------------------------- Batch round 3, loss: 0.5407 -------------------------
2023-03-25 13:42:52,911 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 13:42:52,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:42:52,916 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 13:42:52,916 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 13:42:54,420 : [INFO]  Batch 15: Training set : loss - 0.5338, accuracy - 0.7772, recall - 0.9239, AUC - 0.8922, F1 - 0.8057, precision - 0.7143, training time - -12.0 seconds
2023-03-25 13:42:54,421 : [INFO]  Batch 15: Testing set : loss - 0.5823, accuracy - 0.6912, recall - 0.8039, AUC - 0.8292, F1 - 0.7225, precision - 0.656
2023-03-25 13:42:54,427 : [INFO]  Batch 16 initialized 
2023-03-25 13:42:54,880 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:42:55,163 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 13:42:59,985 : [INFO]  ------------------------- Batch round 1, loss: 0.5545 -------------------------
2023-03-25 13:42:59,985 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:00,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:00,299 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 13:43:03,129 : [INFO]  ------------------------- Batch round 2, loss: 0.5434 -------------------------
2023-03-25 13:43:03,129 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:03,229 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:03,232 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 13:43:05,976 : [INFO]  ------------------------- Batch round 3, loss: 0.5341 -------------------------
2023-03-25 13:43:05,976 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:06,061 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:06,063 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 13:43:06,063 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 13:43:07,344 : [INFO]  Batch 16: Training set : loss - 0.5334, accuracy - 0.7663, recall - 0.913, AUC - 0.9019, F1 - 0.7962, precision - 0.7059, training time - -11.0 seconds
2023-03-25 13:43:07,344 : [INFO]  Batch 16: Testing set : loss - 0.5419, accuracy - 0.7549, recall - 0.9314, AUC - 0.8892, F1 - 0.7917, precision - 0.6884
2023-03-25 13:43:07,359 : [INFO]  Batch 17 initialized 
2023-03-25 13:43:07,816 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:08,094 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 13:43:12,883 : [INFO]  ------------------------- Batch round 1, loss: 0.5522 -------------------------
2023-03-25 13:43:12,883 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:12,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:12,888 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 13:43:15,627 : [INFO]  ------------------------- Batch round 2, loss: 0.5392 -------------------------
2023-03-25 13:43:15,627 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:15,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:15,666 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 13:43:18,390 : [INFO]  ------------------------- Batch round 3, loss: 0.5368 -------------------------
2023-03-25 13:43:18,391 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:18,436 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:18,438 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 13:43:18,438 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 13:43:19,731 : [INFO]  Batch 17: Training set : loss - 0.53, accuracy - 0.7772, recall - 0.9348, AUC - 0.8976, F1 - 0.8075, precision - 0.7107, training time - -10.0 seconds
2023-03-25 13:43:19,731 : [INFO]  Batch 17: Testing set : loss - 0.5738, accuracy - 0.7157, recall - 0.9118, AUC - 0.8716, F1 - 0.7623, precision - 0.6549
2023-03-25 13:43:19,744 : [INFO]  Batch 18 initialized 
2023-03-25 13:43:20,196 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:20,467 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 13:43:25,081 : [INFO]  ------------------------- Batch round 1, loss: 0.557 -------------------------
2023-03-25 13:43:25,081 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:25,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:25,298 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 13:43:28,022 : [INFO]  ------------------------- Batch round 2, loss: 0.5566 -------------------------
2023-03-25 13:43:28,022 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:28,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:28,233 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 13:43:30,922 : [INFO]  ------------------------- Batch round 3, loss: 0.5423 -------------------------
2023-03-25 13:43:30,923 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:31,132 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:31,133 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 13:43:31,134 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 13:43:32,404 : [INFO]  Batch 18: Training set : loss - 0.5459, accuracy - 0.7391, recall - 0.9565, AUC - 0.8716, F1 - 0.7857, precision - 0.6667, training time - -11.0 seconds
2023-03-25 13:43:32,405 : [INFO]  Batch 18: Testing set : loss - 0.59, accuracy - 0.6765, recall - 0.9412, AUC - 0.8382, F1 - 0.7442, precision - 0.6154
2023-03-25 13:43:32,419 : [INFO]  Batch 19 initialized 
2023-03-25 13:43:32,855 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:33,120 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 13:43:37,975 : [INFO]  ------------------------- Batch round 1, loss: 0.5853 -------------------------
2023-03-25 13:43:37,975 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:38,132 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:38,133 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 13:43:40,935 : [INFO]  ------------------------- Batch round 2, loss: 0.5687 -------------------------
2023-03-25 13:43:40,935 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:41,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:41,006 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 13:43:43,778 : [INFO]  ------------------------- Batch round 3, loss: 0.5583 -------------------------
2023-03-25 13:43:43,778 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:43,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:43,804 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 13:43:43,804 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 13:43:45,116 : [INFO]  Batch 19: Training set : loss - 0.5527, accuracy - 0.7663, recall - 0.8696, AUC - 0.8365, F1 - 0.7882, precision - 0.7207, training time - -11.0 seconds
2023-03-25 13:43:45,117 : [INFO]  Batch 19: Testing set : loss - 0.6013, accuracy - 0.6618, recall - 0.8137, AUC - 0.8052, F1 - 0.7064, precision - 0.6241
2023-03-25 13:43:45,130 : [INFO]  Batch 20 initialized 
2023-03-25 13:43:45,561 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:45,842 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 13:43:50,500 : [INFO]  ------------------------- Batch round 1, loss: 0.5499 -------------------------
2023-03-25 13:43:50,500 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 13:43:50,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:50,552 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 13:43:53,391 : [INFO]  ------------------------- Batch round 2, loss: 0.5362 -------------------------
2023-03-25 13:43:53,391 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 13:43:53,454 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:53,457 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 13:43:56,328 : [INFO]  ------------------------- Batch round 3, loss: 0.5343 -------------------------
2023-03-25 13:43:56,328 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 13:43:56,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:43:56,396 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 13:43:56,396 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 13:43:57,750 : [INFO]  Batch 20: Training set : loss - 0.5334, accuracy - 0.7717, recall - 0.9783, AUC - 0.9312, F1 - 0.8108, precision - 0.6923, training time - -11.0 seconds
2023-03-25 13:43:57,750 : [INFO]  Batch 20: Testing set : loss - 0.5695, accuracy - 0.6863, recall - 0.8922, AUC - 0.8545, F1 - 0.7398, precision - 0.6319
2023-03-25 13:43:57,795 : [INFO]  Batch 21 initialized 
2023-03-25 13:43:58,244 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:43:58,533 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 13:44:04,504 : [INFO]  ------------------------- Batch round 1, loss: 0.5774 -------------------------
2023-03-25 13:44:04,505 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:04,508 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:04,510 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 13:44:07,466 : [INFO]  ------------------------- Batch round 2, loss: 0.57 -------------------------
2023-03-25 13:44:07,466 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:07,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:07,505 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 13:44:10,412 : [INFO]  ------------------------- Batch round 3, loss: 0.5698 -------------------------
2023-03-25 13:44:10,412 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:10,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:10,457 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 13:44:10,457 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 13:44:11,855 : [INFO]  Batch 21: Training set : loss - 0.5618, accuracy - 0.7663, recall - 0.9348, AUC - 0.8182, F1 - 0.8, precision - 0.6992, training time - -12.0 seconds
2023-03-25 13:44:11,855 : [INFO]  Batch 21: Testing set : loss - 0.5531, accuracy - 0.7745, recall - 0.9412, AUC - 0.8527, F1 - 0.8067, precision - 0.7059
2023-03-25 13:44:11,865 : [INFO]  Batch 22 initialized 
2023-03-25 13:44:12,317 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:12,559 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 13:44:17,418 : [INFO]  ------------------------- Batch round 1, loss: 0.5973 -------------------------
2023-03-25 13:44:17,419 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:17,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:17,424 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 13:44:21,707 : [INFO]  ------------------------- Batch round 2, loss: 0.5849 -------------------------
2023-03-25 13:44:21,708 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:21,711 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:21,713 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 13:44:24,906 : [INFO]  ------------------------- Batch round 3, loss: 0.5753 -------------------------
2023-03-25 13:44:24,906 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:24,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:24,911 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 13:44:24,911 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 13:44:26,378 : [INFO]  Batch 22: Training set : loss - 0.5738, accuracy - 0.75, recall - 0.913, AUC - 0.843, F1 - 0.785, precision - 0.6885, training time - -12.0 seconds
2023-03-25 13:44:26,378 : [INFO]  Batch 22: Testing set : loss - 0.6695, accuracy - 0.6029, recall - 0.7941, AUC - 0.7158, F1 - 0.6667, precision - 0.5745
2023-03-25 13:44:26,383 : [INFO]  Batch 23 initialized 
2023-03-25 13:44:26,811 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:27,095 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 13:44:32,150 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-25 13:44:32,150 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:32,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:32,429 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 13:44:35,518 : [INFO]  ------------------------- Batch round 2, loss: 0.5445 -------------------------
2023-03-25 13:44:35,518 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:35,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:35,525 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 13:44:39,625 : [INFO]  ------------------------- Batch round 3, loss: 0.5291 -------------------------
2023-03-25 13:44:39,625 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:39,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:39,727 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 13:44:39,727 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 13:44:41,121 : [INFO]  Batch 23: Training set : loss - 0.5239, accuracy - 0.7989, recall - 0.9239, AUC - 0.9168, F1 - 0.8213, precision - 0.7391, training time - -13.0 seconds
2023-03-25 13:44:41,121 : [INFO]  Batch 23: Testing set : loss - 0.5823, accuracy - 0.6961, recall - 0.9216, AUC - 0.855, F1 - 0.752, precision - 0.6351
2023-03-25 13:44:41,126 : [INFO]  Batch 24 initialized 
2023-03-25 13:44:41,552 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:41,844 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 13:44:47,055 : [INFO]  ------------------------- Batch round 1, loss: 0.5892 -------------------------
2023-03-25 13:44:47,056 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 13:44:47,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:47,061 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 13:44:50,098 : [INFO]  ------------------------- Batch round 2, loss: 0.581 -------------------------
2023-03-25 13:44:50,098 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 13:44:50,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:50,103 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 13:44:54,129 : [INFO]  ------------------------- Batch round 3, loss: 0.5651 -------------------------
2023-03-25 13:44:54,129 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 13:44:54,242 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:44:54,244 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 13:44:54,244 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 13:44:55,863 : [INFO]  Batch 24: Training set : loss - 0.5588, accuracy - 0.7609, recall - 0.913, AUC - 0.8559, F1 - 0.7925, precision - 0.7, training time - -12.0 seconds
2023-03-25 13:44:55,864 : [INFO]  Batch 24: Testing set : loss - 0.5853, accuracy - 0.6961, recall - 0.8824, AUC - 0.845, F1 - 0.7438, precision - 0.6429
2023-03-25 13:44:55,880 : [INFO]  Batch 25 initialized 
2023-03-25 13:44:56,830 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:44:57,193 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 13:45:02,379 : [INFO]  ------------------------- Batch round 1, loss: 0.5663 -------------------------
2023-03-25 13:45:02,379 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:02,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:02,383 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 13:45:05,416 : [INFO]  ------------------------- Batch round 2, loss: 0.557 -------------------------
2023-03-25 13:45:05,416 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:05,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:05,421 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 13:45:08,706 : [INFO]  ------------------------- Batch round 3, loss: 0.5526 -------------------------
2023-03-25 13:45:08,706 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:08,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:08,711 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 13:45:08,711 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 13:45:10,038 : [INFO]  Batch 25: Training set : loss - 0.5426, accuracy - 0.75, recall - 0.9348, AUC - 0.9013, F1 - 0.789, precision - 0.6825, training time - -12.0 seconds
2023-03-25 13:45:10,038 : [INFO]  Batch 25: Testing set : loss - 0.5765, accuracy - 0.701, recall - 0.9118, AUC - 0.8747, F1 - 0.753, precision - 0.6414
2023-03-25 13:45:10,046 : [INFO]  Batch 26 initialized 
2023-03-25 13:45:10,475 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:10,775 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 13:45:16,741 : [INFO]  ------------------------- Batch round 1, loss: 0.5771 -------------------------
2023-03-25 13:45:16,741 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:16,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:16,759 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 13:45:19,824 : [INFO]  ------------------------- Batch round 2, loss: 0.5675 -------------------------
2023-03-25 13:45:19,824 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:19,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:19,829 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 13:45:22,699 : [INFO]  ------------------------- Batch round 3, loss: 0.5595 -------------------------
2023-03-25 13:45:22,699 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:22,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:22,705 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 13:45:22,705 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 13:45:24,217 : [INFO]  Batch 26: Training set : loss - 0.5565, accuracy - 0.7391, recall - 0.8804, AUC - 0.8648, F1 - 0.7714, precision - 0.6864, training time - -12.0 seconds
2023-03-25 13:45:24,217 : [INFO]  Batch 26: Testing set : loss - 0.5652, accuracy - 0.7402, recall - 0.951, AUC - 0.8635, F1 - 0.7854, precision - 0.669
2023-03-25 13:45:24,223 : [INFO]  Batch 27 initialized 
2023-03-25 13:45:24,801 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:25,116 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 13:45:30,213 : [INFO]  ------------------------- Batch round 1, loss: 0.6011 -------------------------
2023-03-25 13:45:30,213 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:30,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:30,218 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 13:45:34,060 : [INFO]  ------------------------- Batch round 2, loss: 0.5864 -------------------------
2023-03-25 13:45:34,060 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:34,063 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:34,066 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 13:45:37,692 : [INFO]  ------------------------- Batch round 3, loss: 0.5754 -------------------------
2023-03-25 13:45:37,692 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:37,696 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:37,698 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 13:45:37,698 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 13:45:39,054 : [INFO]  Batch 27: Training set : loss - 0.5762, accuracy - 0.6902, recall - 0.8913, AUC - 0.8515, F1 - 0.7421, precision - 0.6357, training time - -13.0 seconds
2023-03-25 13:45:39,054 : [INFO]  Batch 27: Testing set : loss - 0.5729, accuracy - 0.7059, recall - 0.9608, AUC - 0.8707, F1 - 0.7656, precision - 0.6364
2023-03-25 13:45:39,064 : [INFO]  Batch 28 initialized 
2023-03-25 13:45:39,505 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:39,801 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 13:45:45,668 : [INFO]  ------------------------- Batch round 1, loss: 0.5778 -------------------------
2023-03-25 13:45:45,668 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 13:45:45,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:45,694 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 13:45:48,959 : [INFO]  ------------------------- Batch round 2, loss: 0.5628 -------------------------
2023-03-25 13:45:48,959 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 13:45:48,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:48,969 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 13:45:52,260 : [INFO]  ------------------------- Batch round 3, loss: 0.5556 -------------------------
2023-03-25 13:45:52,260 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 13:45:52,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:45:52,289 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 13:45:52,289 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 13:45:53,755 : [INFO]  Batch 28: Training set : loss - 0.544, accuracy - 0.7609, recall - 0.8696, AUC - 0.8602, F1 - 0.7843, precision - 0.7143, training time - -12.0 seconds
2023-03-25 13:45:53,755 : [INFO]  Batch 28: Testing set : loss - 0.5811, accuracy - 0.7206, recall - 0.8725, AUC - 0.8314, F1 - 0.7574, precision - 0.6692
2023-03-25 13:45:53,771 : [INFO]  Batch 29 initialized 
2023-03-25 13:45:54,427 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:45:54,843 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 13:46:00,740 : [INFO]  ------------------------- Batch round 1, loss: 0.5598 -------------------------
2023-03-25 13:46:00,740 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:01,093 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:01,095 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 13:46:04,053 : [INFO]  ------------------------- Batch round 2, loss: 0.5524 -------------------------
2023-03-25 13:46:04,053 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:04,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:04,291 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 13:46:07,324 : [INFO]  ------------------------- Batch round 3, loss: 0.537 -------------------------
2023-03-25 13:46:07,324 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:07,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:07,581 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 13:46:07,581 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 13:46:09,099 : [INFO]  Batch 29: Training set : loss - 0.5384, accuracy - 0.7554, recall - 0.9565, AUC - 0.8882, F1 - 0.7964, precision - 0.6822, training time - -13.0 seconds
2023-03-25 13:46:09,099 : [INFO]  Batch 29: Testing set : loss - 0.5622, accuracy - 0.7402, recall - 0.9412, AUC - 0.8595, F1 - 0.7837, precision - 0.6713
2023-03-25 13:46:09,109 : [INFO]  Batch 30 initialized 
2023-03-25 13:46:09,544 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:09,820 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 13:46:14,770 : [INFO]  ------------------------- Batch round 1, loss: 0.5714 -------------------------
2023-03-25 13:46:14,770 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:14,883 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:14,886 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 13:46:18,083 : [INFO]  ------------------------- Batch round 2, loss: 0.556 -------------------------
2023-03-25 13:46:18,083 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:18,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:18,088 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 13:46:20,962 : [INFO]  ------------------------- Batch round 3, loss: 0.5387 -------------------------
2023-03-25 13:46:20,962 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:20,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:20,997 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 13:46:20,997 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 13:46:22,685 : [INFO]  Batch 30: Training set : loss - 0.5369, accuracy - 0.7935, recall - 0.9348, AUC - 0.8692, F1 - 0.819, precision - 0.7288, training time - -11.0 seconds
2023-03-25 13:46:22,686 : [INFO]  Batch 30: Testing set : loss - 0.5405, accuracy - 0.75, recall - 0.9804, AUC - 0.9384, F1 - 0.7968, precision - 0.6711
2023-03-25 13:46:22,694 : [INFO]  Batch 31 initialized 
2023-03-25 13:46:23,136 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:23,469 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 13:46:28,448 : [INFO]  ------------------------- Batch round 1, loss: 0.6128 -------------------------
2023-03-25 13:46:28,448 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:28,454 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:28,457 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 13:46:32,074 : [INFO]  ------------------------- Batch round 2, loss: 0.5749 -------------------------
2023-03-25 13:46:32,074 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:32,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:32,080 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 13:46:34,982 : [INFO]  ------------------------- Batch round 3, loss: 0.5651 -------------------------
2023-03-25 13:46:34,982 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:35,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:35,104 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 13:46:35,104 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 13:46:36,447 : [INFO]  Batch 31: Training set : loss - 0.5629, accuracy - 0.75, recall - 0.8478, AUC - 0.8506, F1 - 0.7723, precision - 0.7091, training time - -12.0 seconds
2023-03-25 13:46:36,447 : [INFO]  Batch 31: Testing set : loss - 0.5858, accuracy - 0.6765, recall - 0.8333, AUC - 0.8413, F1 - 0.7203, precision - 0.6343
2023-03-25 13:46:36,455 : [INFO]  Batch 32 initialized 
2023-03-25 13:46:36,884 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:37,194 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 13:46:42,952 : [INFO]  ------------------------- Batch round 1, loss: 0.6008 -------------------------
2023-03-25 13:46:42,952 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:42,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:42,957 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 13:46:46,488 : [INFO]  ------------------------- Batch round 2, loss: 0.584 -------------------------
2023-03-25 13:46:46,488 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:46,492 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:46,495 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 13:46:50,000 : [INFO]  ------------------------- Batch round 3, loss: 0.5721 -------------------------
2023-03-25 13:46:50,000 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 13:46:50,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:50,004 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 13:46:50,005 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 13:46:51,311 : [INFO]  Batch 32: Training set : loss - 0.5713, accuracy - 0.712, recall - 0.8804, AUC - 0.8256, F1 - 0.7535, precision - 0.6585, training time - -13.0 seconds
2023-03-25 13:46:51,311 : [INFO]  Batch 32: Testing set : loss - 0.5822, accuracy - 0.6716, recall - 0.8235, AUC - 0.8137, F1 - 0.7149, precision - 0.6316
2023-03-25 13:46:51,317 : [INFO]  Batch 33 initialized 
2023-03-25 13:46:51,742 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:46:52,049 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 13:46:56,671 : [INFO]  ------------------------- Batch round 1, loss: 0.5868 -------------------------
2023-03-25 13:46:56,671 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 13:46:56,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:56,676 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 13:46:59,509 : [INFO]  ------------------------- Batch round 2, loss: 0.5799 -------------------------
2023-03-25 13:46:59,509 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 13:46:59,512 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:46:59,514 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 13:47:02,250 : [INFO]  ------------------------- Batch round 3, loss: 0.5682 -------------------------
2023-03-25 13:47:02,251 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:02,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:02,255 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 13:47:02,255 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 13:47:03,614 : [INFO]  Batch 33: Training set : loss - 0.5873, accuracy - 0.7011, recall - 0.9022, AUC - 0.8025, F1 - 0.7511, precision - 0.6434, training time - -10.0 seconds
2023-03-25 13:47:03,614 : [INFO]  Batch 33: Testing set : loss - 0.581, accuracy - 0.6961, recall - 0.8725, AUC - 0.8329, F1 - 0.7417, precision - 0.6449
2023-03-25 13:47:03,620 : [INFO]  Batch 34 initialized 
2023-03-25 13:47:04,048 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:04,354 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 13:47:08,845 : [INFO]  ------------------------- Batch round 1, loss: 0.5605 -------------------------
2023-03-25 13:47:08,845 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:08,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:08,887 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 13:47:11,598 : [INFO]  ------------------------- Batch round 2, loss: 0.5542 -------------------------
2023-03-25 13:47:11,598 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:11,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:11,686 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 13:47:14,451 : [INFO]  ------------------------- Batch round 3, loss: 0.5467 -------------------------
2023-03-25 13:47:14,451 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:14,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:14,462 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 13:47:14,462 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 13:47:15,751 : [INFO]  Batch 34: Training set : loss - 0.5512, accuracy - 0.75, recall - 0.8804, AUC - 0.8674, F1 - 0.7788, precision - 0.6983, training time - -10.0 seconds
2023-03-25 13:47:15,752 : [INFO]  Batch 34: Testing set : loss - 0.5538, accuracy - 0.7059, recall - 0.9314, AUC - 0.911, F1 - 0.76, precision - 0.6419
2023-03-25 13:47:15,762 : [INFO]  Batch 35 initialized 
2023-03-25 13:47:16,210 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:16,513 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 13:47:21,086 : [INFO]  ------------------------- Batch round 1, loss: 0.5576 -------------------------
2023-03-25 13:47:21,086 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:21,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:21,092 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 13:47:24,502 : [INFO]  ------------------------- Batch round 2, loss: 0.5513 -------------------------
2023-03-25 13:47:24,502 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:24,506 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:24,508 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 13:47:27,513 : [INFO]  ------------------------- Batch round 3, loss: 0.5406 -------------------------
2023-03-25 13:47:27,513 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:27,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:27,519 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 13:47:27,519 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 13:47:28,853 : [INFO]  Batch 35: Training set : loss - 0.54, accuracy - 0.7772, recall - 0.8804, AUC - 0.897, F1 - 0.798, precision - 0.7297, training time - -11.0 seconds
2023-03-25 13:47:28,853 : [INFO]  Batch 35: Testing set : loss - 0.5863, accuracy - 0.6912, recall - 0.7745, AUC - 0.7973, F1 - 0.7149, precision - 0.6639
2023-03-25 13:47:28,860 : [INFO]  Batch 36 initialized 
2023-03-25 13:47:29,293 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:29,609 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 13:47:34,152 : [INFO]  ------------------------- Batch round 1, loss: 0.5465 -------------------------
2023-03-25 13:47:34,152 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:34,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:34,172 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 13:47:37,011 : [INFO]  ------------------------- Batch round 2, loss: 0.5357 -------------------------
2023-03-25 13:47:37,012 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:37,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:37,017 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 13:47:39,763 : [INFO]  ------------------------- Batch round 3, loss: 0.5324 -------------------------
2023-03-25 13:47:39,763 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:40,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:40,022 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 13:47:40,022 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-25 13:47:41,306 : [INFO]  Batch 36: Training set : loss - 0.5328, accuracy - 0.75, recall - 0.913, AUC - 0.9109, F1 - 0.785, precision - 0.6885, training time - -10.0 seconds
2023-03-25 13:47:41,306 : [INFO]  Batch 36: Testing set : loss - 0.572, accuracy - 0.7059, recall - 0.8824, AUC - 0.8564, F1 - 0.75, precision - 0.6522
2023-03-25 13:47:41,319 : [INFO]  Batch 37 initialized 
2023-03-25 13:47:41,752 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:42,068 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 13:47:46,595 : [INFO]  ------------------------- Batch round 1, loss: 0.5413 -------------------------
2023-03-25 13:47:46,595 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:46,620 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:46,622 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 13:47:49,453 : [INFO]  ------------------------- Batch round 2, loss: 0.532 -------------------------
2023-03-25 13:47:49,453 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 13:47:49,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:49,494 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 13:47:52,302 : [INFO]  ------------------------- Batch round 3, loss: 0.5184 -------------------------
2023-03-25 13:47:52,302 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 13:47:52,306 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:52,307 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 13:47:52,307 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-25 13:47:53,588 : [INFO]  Batch 37: Training set : loss - 0.5166, accuracy - 0.8207, recall - 0.9348, AUC - 0.9114, F1 - 0.839, precision - 0.7611, training time - -10.0 seconds
2023-03-25 13:47:53,588 : [INFO]  Batch 37: Testing set : loss - 0.5958, accuracy - 0.6667, recall - 0.902, AUC - 0.8267, F1 - 0.7302, precision - 0.6133
2023-03-25 13:47:53,602 : [INFO]  Batch 38 initialized 
2023-03-25 13:47:54,023 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:47:54,338 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 13:47:58,901 : [INFO]  ------------------------- Batch round 1, loss: 0.5921 -------------------------
2023-03-25 13:47:58,901 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 13:47:59,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:47:59,156 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 13:48:02,048 : [INFO]  ------------------------- Batch round 2, loss: 0.5724 -------------------------
2023-03-25 13:48:02,048 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:02,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:02,053 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 13:48:04,901 : [INFO]  ------------------------- Batch round 3, loss: 0.5558 -------------------------
2023-03-25 13:48:04,901 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:04,904 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:04,906 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 13:48:04,906 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-25 13:48:06,262 : [INFO]  Batch 38: Training set : loss - 0.5554, accuracy - 0.7554, recall - 0.913, AUC - 0.8732, F1 - 0.7887, precision - 0.6942, training time - -11.0 seconds
2023-03-25 13:48:06,262 : [INFO]  Batch 38: Testing set : loss - 0.5697, accuracy - 0.6912, recall - 0.8922, AUC - 0.8762, F1 - 0.7429, precision - 0.6364
2023-03-25 13:48:06,273 : [INFO]  Batch 39 initialized 
2023-03-25 13:48:06,710 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:07,030 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 13:48:11,538 : [INFO]  ------------------------- Batch round 1, loss: 0.5276 -------------------------
2023-03-25 13:48:11,538 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:11,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:11,543 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 13:48:14,275 : [INFO]  ------------------------- Batch round 2, loss: 0.5186 -------------------------
2023-03-25 13:48:14,275 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:14,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:14,280 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 13:48:16,972 : [INFO]  ------------------------- Batch round 3, loss: 0.5157 -------------------------
2023-03-25 13:48:16,972 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:16,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:16,977 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 13:48:16,977 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-25 13:48:18,298 : [INFO]  Batch 39: Training set : loss - 0.5198, accuracy - 0.8152, recall - 0.9674, AUC - 0.926, F1 - 0.8396, precision - 0.7417, training time - -10.0 seconds
2023-03-25 13:48:18,298 : [INFO]  Batch 39: Testing set : loss - 0.5535, accuracy - 0.7598, recall - 0.9216, AUC - 0.8754, F1 - 0.7932, precision - 0.6963
2023-03-25 13:48:18,303 : [INFO]  Batch 40 initialized 
2023-03-25 13:48:18,724 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:19,052 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 13:48:23,993 : [INFO]  ------------------------- Batch round 1, loss: 0.5693 -------------------------
2023-03-25 13:48:23,993 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:23,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:23,997 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 13:48:26,904 : [INFO]  ------------------------- Batch round 2, loss: 0.5561 -------------------------
2023-03-25 13:48:26,904 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:26,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:26,909 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 13:48:29,770 : [INFO]  ------------------------- Batch round 3, loss: 0.544 -------------------------
2023-03-25 13:48:29,770 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:29,966 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:29,967 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 13:48:29,967 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-25 13:48:31,300 : [INFO]  Batch 40: Training set : loss - 0.5398, accuracy - 0.7717, recall - 0.9565, AUC - 0.9059, F1 - 0.8073, precision - 0.6984, training time - -11.0 seconds
2023-03-25 13:48:31,300 : [INFO]  Batch 40: Testing set : loss - 0.6096, accuracy - 0.6618, recall - 0.8627, AUC - 0.8152, F1 - 0.7184, precision - 0.6154
2023-03-25 13:48:31,306 : [INFO]  Batch 41 initialized 
2023-03-25 13:48:31,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:32,064 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 13:48:36,632 : [INFO]  ------------------------- Batch round 1, loss: 0.5633 -------------------------
2023-03-25 13:48:36,632 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:36,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:36,637 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 13:48:39,484 : [INFO]  ------------------------- Batch round 2, loss: 0.5449 -------------------------
2023-03-25 13:48:39,484 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:39,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:39,489 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 13:48:42,328 : [INFO]  ------------------------- Batch round 3, loss: 0.5344 -------------------------
2023-03-25 13:48:42,328 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:42,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:42,334 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 13:48:42,334 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-25 13:48:43,667 : [INFO]  Batch 41: Training set : loss - 0.5391, accuracy - 0.7826, recall - 0.9239, AUC - 0.869, F1 - 0.8095, precision - 0.7203, training time - -10.0 seconds
2023-03-25 13:48:43,667 : [INFO]  Batch 41: Testing set : loss - 0.5891, accuracy - 0.6863, recall - 0.9216, AUC - 0.8763, F1 - 0.746, precision - 0.6267
2023-03-25 13:48:43,676 : [INFO]  Batch 42 initialized 
2023-03-25 13:48:44,115 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:44,443 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 13:48:49,013 : [INFO]  ------------------------- Batch round 1, loss: 0.6064 -------------------------
2023-03-25 13:48:49,013 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 13:48:49,016 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:49,018 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 13:48:51,791 : [INFO]  ------------------------- Batch round 2, loss: 0.5909 -------------------------
2023-03-25 13:48:51,791 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 13:48:51,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:51,796 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 13:48:54,603 : [INFO]  ------------------------- Batch round 3, loss: 0.5867 -------------------------
2023-03-25 13:48:54,603 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 13:48:54,606 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:48:54,608 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 13:48:54,608 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-25 13:48:55,920 : [INFO]  Batch 42: Training set : loss - 0.5844, accuracy - 0.7228, recall - 0.913, AUC - 0.8127, F1 - 0.7671, precision - 0.6614, training time - -10.0 seconds
2023-03-25 13:48:55,920 : [INFO]  Batch 42: Testing set : loss - 0.5691, accuracy - 0.701, recall - 0.8431, AUC - 0.8429, F1 - 0.7382, precision - 0.6565
2023-03-25 13:48:55,929 : [INFO]  Batch 43 initialized 
2023-03-25 13:48:56,372 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:48:56,694 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 13:49:01,230 : [INFO]  ------------------------- Batch round 1, loss: 0.5665 -------------------------
2023-03-25 13:49:01,230 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:01,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:01,235 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 13:49:04,103 : [INFO]  ------------------------- Batch round 2, loss: 0.5632 -------------------------
2023-03-25 13:49:04,103 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:04,107 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:04,109 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 13:49:06,842 : [INFO]  ------------------------- Batch round 3, loss: 0.5545 -------------------------
2023-03-25 13:49:06,842 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:06,845 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:06,847 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 13:49:06,847 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-25 13:49:08,155 : [INFO]  Batch 43: Training set : loss - 0.5512, accuracy - 0.7554, recall - 0.913, AUC - 0.8853, F1 - 0.7887, precision - 0.6942, training time - -10.0 seconds
2023-03-25 13:49:08,155 : [INFO]  Batch 43: Testing set : loss - 0.5844, accuracy - 0.7108, recall - 0.9412, AUC - 0.8886, F1 - 0.7649, precision - 0.6443
2023-03-25 13:49:08,162 : [INFO]  Batch 44 initialized 
2023-03-25 13:49:08,602 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:08,939 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 13:49:13,519 : [INFO]  ------------------------- Batch round 1, loss: 0.5394 -------------------------
2023-03-25 13:49:13,519 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:13,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:13,694 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 13:49:16,490 : [INFO]  ------------------------- Batch round 2, loss: 0.5258 -------------------------
2023-03-25 13:49:16,490 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:16,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:16,496 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 13:49:19,201 : [INFO]  ------------------------- Batch round 3, loss: 0.5194 -------------------------
2023-03-25 13:49:19,202 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:19,405 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:19,407 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 13:49:19,407 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-25 13:49:20,704 : [INFO]  Batch 44: Training set : loss - 0.5203, accuracy - 0.7826, recall - 0.9891, AUC - 0.9517, F1 - 0.8198, precision - 0.7, training time - -10.0 seconds
2023-03-25 13:49:20,704 : [INFO]  Batch 44: Testing set : loss - 0.5493, accuracy - 0.7304, recall - 0.902, AUC - 0.8798, F1 - 0.7699, precision - 0.6715
2023-03-25 13:49:20,713 : [INFO]  Batch 45 initialized 
2023-03-25 13:49:21,147 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:21,483 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 13:49:26,192 : [INFO]  ------------------------- Batch round 1, loss: 0.5707 -------------------------
2023-03-25 13:49:26,192 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:26,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:26,197 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 13:49:29,355 : [INFO]  ------------------------- Batch round 2, loss: 0.5571 -------------------------
2023-03-25 13:49:29,356 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:29,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:29,374 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 13:49:32,339 : [INFO]  ------------------------- Batch round 3, loss: 0.5515 -------------------------
2023-03-25 13:49:32,339 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:32,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:32,344 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 13:49:32,344 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-25 13:49:33,647 : [INFO]  Batch 45: Training set : loss - 0.5513, accuracy - 0.7772, recall - 0.9457, AUC - 0.9075, F1 - 0.8093, precision - 0.7073, training time - -11.0 seconds
2023-03-25 13:49:33,647 : [INFO]  Batch 45: Testing set : loss - 0.5655, accuracy - 0.7206, recall - 0.9118, AUC - 0.8849, F1 - 0.7654, precision - 0.6596
2023-03-25 13:49:33,656 : [INFO]  Batch 46 initialized 
2023-03-25 13:49:34,084 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:34,420 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 13:49:38,989 : [INFO]  ------------------------- Batch round 1, loss: 0.5611 -------------------------
2023-03-25 13:49:38,990 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:38,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:38,995 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 13:49:41,829 : [INFO]  ------------------------- Batch round 2, loss: 0.5529 -------------------------
2023-03-25 13:49:41,829 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:41,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:41,834 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 13:49:44,708 : [INFO]  ------------------------- Batch round 3, loss: 0.5518 -------------------------
2023-03-25 13:49:44,708 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:44,711 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:44,713 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 13:49:44,714 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-25 13:49:46,040 : [INFO]  Batch 46: Training set : loss - 0.5517, accuracy - 0.75, recall - 0.9022, AUC - 0.8891, F1 - 0.783, precision - 0.6917, training time - -10.0 seconds
2023-03-25 13:49:46,040 : [INFO]  Batch 46: Testing set : loss - 0.6008, accuracy - 0.652, recall - 0.8824, AUC - 0.8488, F1 - 0.7171, precision - 0.604
2023-03-25 13:49:46,047 : [INFO]  Batch 47 initialized 
2023-03-25 13:49:46,537 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:46,875 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 13:49:51,334 : [INFO]  ------------------------- Batch round 1, loss: 0.5728 -------------------------
2023-03-25 13:49:51,334 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 13:49:51,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:51,631 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 13:49:54,391 : [INFO]  ------------------------- Batch round 2, loss: 0.5496 -------------------------
2023-03-25 13:49:54,391 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 13:49:54,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:54,396 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 13:49:57,227 : [INFO]  ------------------------- Batch round 3, loss: 0.5498 -------------------------
2023-03-25 13:49:57,227 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 13:49:57,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:49:57,233 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 13:49:57,233 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-25 13:49:58,533 : [INFO]  Batch 47: Training set : loss - 0.562, accuracy - 0.7446, recall - 0.9457, AUC - 0.8986, F1 - 0.7873, precision - 0.6744, training time - -10.0 seconds
2023-03-25 13:49:58,534 : [INFO]  Batch 47: Testing set : loss - 0.6108, accuracy - 0.652, recall - 0.8922, AUC - 0.8511, F1 - 0.7194, precision - 0.6026
2023-03-25 13:49:58,547 : [INFO]  Batch 48 initialized 
2023-03-25 13:49:58,979 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:49:59,321 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 13:50:03,906 : [INFO]  ------------------------- Batch round 1, loss: 0.5441 -------------------------
2023-03-25 13:50:03,906 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:03,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:03,970 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 13:50:06,794 : [INFO]  ------------------------- Batch round 2, loss: 0.5291 -------------------------
2023-03-25 13:50:06,794 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:06,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:06,852 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 13:50:09,589 : [INFO]  ------------------------- Batch round 3, loss: 0.5226 -------------------------
2023-03-25 13:50:09,589 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:09,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:09,654 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 13:50:09,654 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-25 13:50:10,950 : [INFO]  Batch 48: Training set : loss - 0.5231, accuracy - 0.7772, recall - 1.0, AUC - 0.927, F1 - 0.8178, precision - 0.6917, training time - -10.0 seconds
2023-03-25 13:50:10,950 : [INFO]  Batch 48: Testing set : loss - 0.5779, accuracy - 0.7108, recall - 0.9216, AUC - 0.8838, F1 - 0.7611, precision - 0.6483
2023-03-25 13:50:10,963 : [INFO]  Batch 49 initialized 
2023-03-25 13:50:11,391 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:11,731 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 13:50:17,814 : [INFO]  ------------------------- Batch round 1, loss: 0.5435 -------------------------
2023-03-25 13:50:17,814 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:18,305 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:18,308 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 13:50:22,878 : [INFO]  ------------------------- Batch round 2, loss: 0.5391 -------------------------
2023-03-25 13:50:22,878 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:23,292 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:23,312 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 13:50:27,665 : [INFO]  ------------------------- Batch round 3, loss: 0.5358 -------------------------
2023-03-25 13:50:27,665 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:27,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:27,890 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 13:50:27,891 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-25 13:50:30,282 : [INFO]  Batch 49: Training set : loss - 0.5423, accuracy - 0.7663, recall - 0.9239, AUC - 0.9068, F1 - 0.7981, precision - 0.7025, training time - -16.0 seconds
2023-03-25 13:50:30,283 : [INFO]  Batch 49: Testing set : loss - 0.5978, accuracy - 0.6618, recall - 0.8529, AUC - 0.816, F1 - 0.716, precision - 0.617
2023-03-25 13:50:30,296 : [INFO]  Batch 50 initialized 
2023-03-25 13:50:31,150 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:31,635 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 13:50:37,478 : [INFO]  ------------------------- Batch round 1, loss: 0.5516 -------------------------
2023-03-25 13:50:37,478 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:37,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:37,672 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 13:50:40,457 : [INFO]  ------------------------- Batch round 2, loss: 0.5522 -------------------------
2023-03-25 13:50:40,457 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:40,514 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:40,516 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 13:50:43,346 : [INFO]  ------------------------- Batch round 3, loss: 0.5498 -------------------------
2023-03-25 13:50:43,346 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:43,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:43,369 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 13:50:43,369 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-25 13:50:44,742 : [INFO]  Batch 50: Training set : loss - 0.5426, accuracy - 0.7609, recall - 0.9348, AUC - 0.8699, F1 - 0.7963, precision - 0.6935, training time - -12.0 seconds
2023-03-25 13:50:44,742 : [INFO]  Batch 50: Testing set : loss - 0.5806, accuracy - 0.7304, recall - 0.951, AUC - 0.8839, F1 - 0.7791, precision - 0.6599
2023-03-25 13:50:44,754 : [INFO]  Batch 51 initialized 
2023-03-25 13:50:45,244 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:45,611 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 13:50:50,310 : [INFO]  ------------------------- Batch round 1, loss: 0.5803 -------------------------
2023-03-25 13:50:50,310 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 13:50:50,314 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:50,315 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 13:50:53,200 : [INFO]  ------------------------- Batch round 2, loss: 0.5757 -------------------------
2023-03-25 13:50:53,200 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 13:50:53,205 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:53,207 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 13:50:56,197 : [INFO]  ------------------------- Batch round 3, loss: 0.5646 -------------------------
2023-03-25 13:50:56,197 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 13:50:56,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:50:56,487 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 13:50:56,487 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-25 13:50:57,730 : [INFO]  Batch 51: Training set : loss - 0.5756, accuracy - 0.7065, recall - 0.913, AUC - 0.8414, F1 - 0.7568, precision - 0.6462, training time - -11.0 seconds
2023-03-25 13:50:57,730 : [INFO]  Batch 51: Testing set : loss - 0.5758, accuracy - 0.701, recall - 0.902, AUC - 0.835, F1 - 0.751, precision - 0.6434
2023-03-25 13:50:57,738 : [INFO]  Batch 52 initialized 
2023-03-25 13:50:58,227 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:50:58,588 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 13:51:03,345 : [INFO]  ------------------------- Batch round 1, loss: 0.558 -------------------------
2023-03-25 13:51:03,346 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:03,370 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:03,372 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 13:51:06,582 : [INFO]  ------------------------- Batch round 2, loss: 0.5419 -------------------------
2023-03-25 13:51:06,582 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:06,589 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:06,591 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 13:51:09,706 : [INFO]  ------------------------- Batch round 3, loss: 0.533 -------------------------
2023-03-25 13:51:09,707 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:09,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:09,820 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 13:51:09,820 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-25 13:51:11,198 : [INFO]  Batch 52: Training set : loss - 0.5331, accuracy - 0.7989, recall - 0.9239, AUC - 0.9115, F1 - 0.8213, precision - 0.7391, training time - -11.0 seconds
2023-03-25 13:51:11,198 : [INFO]  Batch 52: Testing set : loss - 0.5818, accuracy - 0.6961, recall - 0.8725, AUC - 0.8665, F1 - 0.7417, precision - 0.6449
2023-03-25 13:51:11,212 : [INFO]  Batch 53 initialized 
2023-03-25 13:51:11,712 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:12,063 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 13:51:16,762 : [INFO]  ------------------------- Batch round 1, loss: 0.5842 -------------------------
2023-03-25 13:51:16,762 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:16,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:16,767 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 13:51:19,721 : [INFO]  ------------------------- Batch round 2, loss: 0.5748 -------------------------
2023-03-25 13:51:19,722 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:19,727 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:19,729 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 13:51:22,590 : [INFO]  ------------------------- Batch round 3, loss: 0.5659 -------------------------
2023-03-25 13:51:22,590 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:22,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:22,596 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 13:51:22,596 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-25 13:51:23,954 : [INFO]  Batch 53: Training set : loss - 0.5677, accuracy - 0.7391, recall - 0.8804, AUC - 0.8487, F1 - 0.7714, precision - 0.6864, training time - -11.0 seconds
2023-03-25 13:51:23,955 : [INFO]  Batch 53: Testing set : loss - 0.5938, accuracy - 0.652, recall - 0.8431, AUC - 0.8181, F1 - 0.7078, precision - 0.6099
2023-03-25 13:51:23,961 : [INFO]  Batch 54 initialized 
2023-03-25 13:51:24,422 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:24,802 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 13:51:29,487 : [INFO]  ------------------------- Batch round 1, loss: 0.6034 -------------------------
2023-03-25 13:51:29,487 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:29,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:29,493 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 13:51:32,349 : [INFO]  ------------------------- Batch round 2, loss: 0.5897 -------------------------
2023-03-25 13:51:32,350 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:32,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:32,354 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 13:51:35,228 : [INFO]  ------------------------- Batch round 3, loss: 0.5837 -------------------------
2023-03-25 13:51:35,228 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:35,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:35,362 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 13:51:35,362 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-25 13:51:36,675 : [INFO]  Batch 54: Training set : loss - 0.5828, accuracy - 0.7228, recall - 0.8696, AUC - 0.826, F1 - 0.7583, precision - 0.6723, training time - -11.0 seconds
2023-03-25 13:51:36,675 : [INFO]  Batch 54: Testing set : loss - 0.5853, accuracy - 0.7108, recall - 0.8333, AUC - 0.8281, F1 - 0.7424, precision - 0.6693
2023-03-25 13:51:36,682 : [INFO]  Batch 55 initialized 
2023-03-25 13:51:37,134 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:37,492 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 13:51:42,143 : [INFO]  ------------------------- Batch round 1, loss: 0.5556 -------------------------
2023-03-25 13:51:42,143 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:42,146 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:42,148 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 13:51:44,955 : [INFO]  ------------------------- Batch round 2, loss: 0.5422 -------------------------
2023-03-25 13:51:44,955 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:45,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:45,147 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 13:51:47,947 : [INFO]  ------------------------- Batch round 3, loss: 0.5424 -------------------------
2023-03-25 13:51:47,947 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 13:51:47,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:47,952 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 13:51:47,952 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-25 13:51:49,268 : [INFO]  Batch 55: Training set : loss - 0.5526, accuracy - 0.7337, recall - 0.9239, AUC - 0.8608, F1 - 0.7763, precision - 0.6693, training time - -10.0 seconds
2023-03-25 13:51:49,269 : [INFO]  Batch 55: Testing set : loss - 0.6011, accuracy - 0.6422, recall - 0.8922, AUC - 0.805, F1 - 0.7137, precision - 0.5948
2023-03-25 13:51:49,280 : [INFO]  Batch 56 initialized 
2023-03-25 13:51:49,707 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:51:50,061 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 13:51:54,564 : [INFO]  ------------------------- Batch round 1, loss: 0.5673 -------------------------
2023-03-25 13:51:54,565 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 13:51:54,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:54,627 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 13:51:57,466 : [INFO]  ------------------------- Batch round 2, loss: 0.5473 -------------------------
2023-03-25 13:51:57,466 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 13:51:57,560 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:51:57,562 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 13:52:00,316 : [INFO]  ------------------------- Batch round 3, loss: 0.5382 -------------------------
2023-03-25 13:52:00,317 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:00,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:00,383 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 13:52:00,383 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-25 13:52:01,705 : [INFO]  Batch 56: Training set : loss - 0.5412, accuracy - 0.7989, recall - 0.913, AUC - 0.8853, F1 - 0.8195, precision - 0.7434, training time - -10.0 seconds
2023-03-25 13:52:01,706 : [INFO]  Batch 56: Testing set : loss - 0.5585, accuracy - 0.7206, recall - 0.902, AUC - 0.8681, F1 - 0.7635, precision - 0.6619
2023-03-25 13:52:01,719 : [INFO]  Batch 57 initialized 
2023-03-25 13:52:02,153 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:02,507 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 13:52:08,118 : [INFO]  ------------------------- Batch round 1, loss: 0.5455 -------------------------
2023-03-25 13:52:08,119 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:08,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:08,176 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 13:52:12,374 : [INFO]  ------------------------- Batch round 2, loss: 0.5361 -------------------------
2023-03-25 13:52:12,374 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:12,417 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:12,420 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 13:52:16,009 : [INFO]  ------------------------- Batch round 3, loss: 0.5362 -------------------------
2023-03-25 13:52:16,009 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:16,386 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:16,388 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 13:52:16,388 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-25 13:52:18,047 : [INFO]  Batch 57: Training set : loss - 0.5243, accuracy - 0.7772, recall - 0.9457, AUC - 0.9224, F1 - 0.8093, precision - 0.7073, training time - -14.0 seconds
2023-03-25 13:52:18,048 : [INFO]  Batch 57: Testing set : loss - 0.5861, accuracy - 0.6618, recall - 0.8529, AUC - 0.8607, F1 - 0.716, precision - 0.617
2023-03-25 13:52:18,061 : [INFO]  Batch 58 initialized 
2023-03-25 13:52:18,552 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:19,129 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 13:52:24,996 : [INFO]  ------------------------- Batch round 1, loss: 0.5255 -------------------------
2023-03-25 13:52:24,996 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:25,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:25,329 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 13:52:28,863 : [INFO]  ------------------------- Batch round 2, loss: 0.5192 -------------------------
2023-03-25 13:52:28,863 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:28,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:28,960 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 13:52:32,407 : [INFO]  ------------------------- Batch round 3, loss: 0.5199 -------------------------
2023-03-25 13:52:32,408 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:32,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:32,530 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 13:52:32,530 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-25 13:52:34,010 : [INFO]  Batch 58: Training set : loss - 0.5092, accuracy - 0.7989, recall - 0.9348, AUC - 0.909, F1 - 0.823, precision - 0.735, training time - -13.0 seconds
2023-03-25 13:52:34,010 : [INFO]  Batch 58: Testing set : loss - 0.5699, accuracy - 0.6716, recall - 0.9216, AUC - 0.8848, F1 - 0.7373, precision - 0.6144
2023-03-25 13:52:34,023 : [INFO]  Batch 59 initialized 
2023-03-25 13:52:34,478 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:34,834 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 13:52:39,582 : [INFO]  ------------------------- Batch round 1, loss: 0.561 -------------------------
2023-03-25 13:52:39,582 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:39,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:39,632 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 13:52:42,783 : [INFO]  ------------------------- Batch round 2, loss: 0.5402 -------------------------
2023-03-25 13:52:42,783 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:43,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:43,139 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 13:52:46,136 : [INFO]  ------------------------- Batch round 3, loss: 0.5357 -------------------------
2023-03-25 13:52:46,136 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 13:52:46,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:46,482 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 13:52:46,482 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-25 13:52:48,151 : [INFO]  Batch 59: Training set : loss - 0.531, accuracy - 0.7717, recall - 0.8913, AUC - 0.8895, F1 - 0.7961, precision - 0.7193, training time - -12.0 seconds
2023-03-25 13:52:48,151 : [INFO]  Batch 59: Testing set : loss - 0.5553, accuracy - 0.7255, recall - 0.9412, AUC - 0.9148, F1 - 0.7742, precision - 0.6575
2023-03-25 13:52:48,160 : [INFO]  Batch 60 initialized 
2023-03-25 13:52:48,652 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:52:49,057 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 13:52:54,947 : [INFO]  ------------------------- Batch round 1, loss: 0.5546 -------------------------
2023-03-25 13:52:54,948 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 13:52:54,952 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:54,954 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 13:52:58,134 : [INFO]  ------------------------- Batch round 2, loss: 0.5338 -------------------------
2023-03-25 13:52:58,134 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 13:52:58,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:52:58,139 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 13:53:01,167 : [INFO]  ------------------------- Batch round 3, loss: 0.5332 -------------------------
2023-03-25 13:53:01,167 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:01,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:01,199 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 13:53:01,199 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-25 13:53:02,666 : [INFO]  Batch 60: Training set : loss - 0.5249, accuracy - 0.7663, recall - 0.8913, AUC - 0.8784, F1 - 0.7923, precision - 0.713, training time - -12.0 seconds
2023-03-25 13:53:02,666 : [INFO]  Batch 60: Testing set : loss - 0.5828, accuracy - 0.6814, recall - 0.8627, AUC - 0.8516, F1 - 0.7303, precision - 0.6331
2023-03-25 13:53:02,678 : [INFO]  Batch 61 initialized 
2023-03-25 13:53:03,271 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:03,632 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 13:53:09,584 : [INFO]  ------------------------- Batch round 1, loss: 0.6217 -------------------------
2023-03-25 13:53:09,584 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:09,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:09,590 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 13:53:12,857 : [INFO]  ------------------------- Batch round 2, loss: 0.6025 -------------------------
2023-03-25 13:53:12,857 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:12,860 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:12,863 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 13:53:15,909 : [INFO]  ------------------------- Batch round 3, loss: 0.5843 -------------------------
2023-03-25 13:53:15,909 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:15,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:15,916 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 13:53:15,916 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-25 13:53:17,388 : [INFO]  Batch 61: Training set : loss - 0.596, accuracy - 0.7337, recall - 0.8804, AUC - 0.7743, F1 - 0.7678, precision - 0.6807, training time - -12.0 seconds
2023-03-25 13:53:17,388 : [INFO]  Batch 61: Testing set : loss - 0.5716, accuracy - 0.7402, recall - 0.8627, AUC - 0.8467, F1 - 0.7686, precision - 0.6929
2023-03-25 13:53:17,398 : [INFO]  Batch 62 initialized 
2023-03-25 13:53:17,917 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:18,346 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 13:53:23,584 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 13:53:23,584 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:23,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:23,590 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 13:53:26,832 : [INFO]  ------------------------- Batch round 2, loss: 0.5414 -------------------------
2023-03-25 13:53:26,833 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:26,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:26,839 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 13:53:30,097 : [INFO]  ------------------------- Batch round 3, loss: 0.5361 -------------------------
2023-03-25 13:53:30,097 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:30,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:30,102 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 13:53:30,102 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-25 13:53:31,475 : [INFO]  Batch 62: Training set : loss - 0.543, accuracy - 0.7663, recall - 0.9022, AUC - 0.8632, F1 - 0.7943, precision - 0.7094, training time - -12.0 seconds
2023-03-25 13:53:31,475 : [INFO]  Batch 62: Testing set : loss - 0.6045, accuracy - 0.652, recall - 0.7451, AUC - 0.7942, F1 - 0.6816, precision - 0.6281
2023-03-25 13:53:31,481 : [INFO]  Batch 63 initialized 
2023-03-25 13:53:31,938 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:32,289 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 13:53:37,063 : [INFO]  ------------------------- Batch round 1, loss: 0.5589 -------------------------
2023-03-25 13:53:37,063 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:37,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:37,069 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 13:53:40,089 : [INFO]  ------------------------- Batch round 2, loss: 0.549 -------------------------
2023-03-25 13:53:40,089 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:40,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:40,094 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 13:53:43,199 : [INFO]  ------------------------- Batch round 3, loss: 0.5487 -------------------------
2023-03-25 13:53:43,199 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:43,202 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:43,204 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 13:53:43,204 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-25 13:53:44,515 : [INFO]  Batch 63: Training set : loss - 0.5443, accuracy - 0.7772, recall - 0.9348, AUC - 0.8824, F1 - 0.8075, precision - 0.7107, training time - -11.0 seconds
2023-03-25 13:53:44,515 : [INFO]  Batch 63: Testing set : loss - 0.6018, accuracy - 0.652, recall - 0.8431, AUC - 0.8033, F1 - 0.7078, precision - 0.6099
2023-03-25 13:53:44,523 : [INFO]  Batch 64 initialized 
2023-03-25 13:53:44,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:45,350 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 13:53:50,397 : [INFO]  ------------------------- Batch round 1, loss: 0.5532 -------------------------
2023-03-25 13:53:50,397 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 13:53:50,441 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:50,444 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 13:53:53,697 : [INFO]  ------------------------- Batch round 2, loss: 0.543 -------------------------
2023-03-25 13:53:53,697 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 13:53:53,833 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:53,835 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 13:53:56,759 : [INFO]  ------------------------- Batch round 3, loss: 0.5367 -------------------------
2023-03-25 13:53:56,759 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 13:53:56,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:53:56,805 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 13:53:56,805 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-25 13:53:58,416 : [INFO]  Batch 64: Training set : loss - 0.5348, accuracy - 0.788, recall - 0.9348, AUC - 0.8885, F1 - 0.8152, precision - 0.7227, training time - -11.0 seconds
2023-03-25 13:53:58,416 : [INFO]  Batch 64: Testing set : loss - 0.5575, accuracy - 0.7549, recall - 0.9314, AUC - 0.892, F1 - 0.7917, precision - 0.6884
2023-03-25 13:53:58,425 : [INFO]  Batch 65 initialized 
2023-03-25 13:53:58,895 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:53:59,288 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 13:54:03,961 : [INFO]  ------------------------- Batch round 1, loss: 0.5699 -------------------------
2023-03-25 13:54:03,961 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:03,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:03,967 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 13:54:06,763 : [INFO]  ------------------------- Batch round 2, loss: 0.5559 -------------------------
2023-03-25 13:54:06,764 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:06,767 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:06,769 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 13:54:09,817 : [INFO]  ------------------------- Batch round 3, loss: 0.5483 -------------------------
2023-03-25 13:54:09,817 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:09,822 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:09,824 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 13:54:09,824 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-25 13:54:11,552 : [INFO]  Batch 65: Training set : loss - 0.556, accuracy - 0.7446, recall - 0.9783, AUC - 0.9158, F1 - 0.793, precision - 0.6667, training time - -11.0 seconds
2023-03-25 13:54:11,552 : [INFO]  Batch 65: Testing set : loss - 0.5803, accuracy - 0.7059, recall - 0.9216, AUC - 0.8886, F1 - 0.7581, precision - 0.6438
2023-03-25 13:54:11,559 : [INFO]  Batch 66 initialized 
2023-03-25 13:54:12,031 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:12,393 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 13:54:17,250 : [INFO]  ------------------------- Batch round 1, loss: 0.5465 -------------------------
2023-03-25 13:54:17,250 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:17,317 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:17,320 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 13:54:20,801 : [INFO]  ------------------------- Batch round 2, loss: 0.5357 -------------------------
2023-03-25 13:54:20,801 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:20,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:20,807 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 13:54:23,828 : [INFO]  ------------------------- Batch round 3, loss: 0.5346 -------------------------
2023-03-25 13:54:23,828 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:23,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:23,932 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 13:54:23,932 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-25 13:54:25,529 : [INFO]  Batch 66: Training set : loss - 0.5379, accuracy - 0.7609, recall - 0.9457, AUC - 0.8913, F1 - 0.7982, precision - 0.6905, training time - -12.0 seconds
2023-03-25 13:54:25,530 : [INFO]  Batch 66: Testing set : loss - 0.5642, accuracy - 0.7402, recall - 0.9608, AUC - 0.8628, F1 - 0.7871, precision - 0.6667
2023-03-25 13:54:25,539 : [INFO]  Batch 67 initialized 
2023-03-25 13:54:26,069 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:26,458 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 13:54:31,022 : [INFO]  ------------------------- Batch round 1, loss: 0.564 -------------------------
2023-03-25 13:54:31,022 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:31,273 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:31,275 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 13:54:33,921 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-25 13:54:33,921 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:34,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:34,162 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 13:54:36,873 : [INFO]  ------------------------- Batch round 3, loss: 0.5514 -------------------------
2023-03-25 13:54:36,874 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:37,121 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:37,123 : [INFO]  Batch number 67 model fetched from the server
2023-03-25 13:54:37,123 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-25 13:54:38,440 : [INFO]  Batch 67: Training set : loss - 0.5584, accuracy - 0.712, recall - 0.913, AUC - 0.8817, F1 - 0.7602, precision - 0.6512, training time - -11.0 seconds
2023-03-25 13:54:38,440 : [INFO]  Batch 67: Testing set : loss - 0.5669, accuracy - 0.7157, recall - 0.9118, AUC - 0.8651, F1 - 0.7623, precision - 0.6549
2023-03-25 13:54:38,452 : [INFO]  Batch 68 initialized 
2023-03-25 13:54:38,908 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:39,277 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-25 13:54:44,065 : [INFO]  ------------------------- Batch round 1, loss: 0.5493 -------------------------
2023-03-25 13:54:44,065 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:44,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:44,071 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-25 13:54:47,175 : [INFO]  ------------------------- Batch round 2, loss: 0.5425 -------------------------
2023-03-25 13:54:47,175 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-25 13:54:47,178 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:47,180 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-25 13:54:50,184 : [INFO]  ------------------------- Batch round 3, loss: 0.5345 -------------------------
2023-03-25 13:54:50,184 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-25 13:54:50,326 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:50,328 : [INFO]  Batch number 68 model fetched from the server
2023-03-25 13:54:50,328 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-25 13:54:51,713 : [INFO]  Batch 68: Training set : loss - 0.5403, accuracy - 0.7554, recall - 0.9565, AUC - 0.8977, F1 - 0.7964, precision - 0.6822, training time - -11.0 seconds
2023-03-25 13:54:51,713 : [INFO]  Batch 68: Testing set : loss - 0.5773, accuracy - 0.6814, recall - 0.8922, AUC - 0.8625, F1 - 0.7368, precision - 0.6276
2023-03-25 13:54:51,724 : [INFO]  Batch 69 initialized 
2023-03-25 13:54:52,148 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:54:52,530 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-25 13:54:57,368 : [INFO]  ------------------------- Batch round 1, loss: 0.5611 -------------------------
2023-03-25 13:54:57,368 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-25 13:54:57,373 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:54:57,375 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-25 13:55:00,191 : [INFO]  ------------------------- Batch round 2, loss: 0.5524 -------------------------
2023-03-25 13:55:00,191 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:00,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:00,218 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-25 13:55:03,046 : [INFO]  ------------------------- Batch round 3, loss: 0.5533 -------------------------
2023-03-25 13:55:03,046 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:03,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:03,103 : [INFO]  Batch number 69 model fetched from the server
2023-03-25 13:55:03,103 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-25 13:55:04,713 : [INFO]  Batch 69: Training set : loss - 0.5511, accuracy - 0.7554, recall - 0.9565, AUC - 0.8746, F1 - 0.7964, precision - 0.6822, training time - -11.0 seconds
2023-03-25 13:55:04,713 : [INFO]  Batch 69: Testing set : loss - 0.5949, accuracy - 0.6912, recall - 0.9118, AUC - 0.8311, F1 - 0.747, precision - 0.6327
2023-03-25 13:55:04,728 : [INFO]  Batch 70 initialized 
2023-03-25 13:55:05,233 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:05,560 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-25 13:55:10,378 : [INFO]  ------------------------- Batch round 1, loss: 0.5369 -------------------------
2023-03-25 13:55:10,378 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:10,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:10,383 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-25 13:55:13,227 : [INFO]  ------------------------- Batch round 2, loss: 0.5256 -------------------------
2023-03-25 13:55:13,227 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:13,300 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:13,303 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-25 13:55:16,041 : [INFO]  ------------------------- Batch round 3, loss: 0.511 -------------------------
2023-03-25 13:55:16,041 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:16,164 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:16,166 : [INFO]  Batch number 70 model fetched from the server
2023-03-25 13:55:16,167 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-25 13:55:17,507 : [INFO]  Batch 70: Training set : loss - 0.526, accuracy - 0.7772, recall - 0.9891, AUC - 0.9231, F1 - 0.8161, precision - 0.6947, training time - -11.0 seconds
2023-03-25 13:55:17,507 : [INFO]  Batch 70: Testing set : loss - 0.5939, accuracy - 0.6912, recall - 0.9608, AUC - 0.863, F1 - 0.7568, precision - 0.6242
2023-03-25 13:55:17,521 : [INFO]  Batch 71 initialized 
2023-03-25 13:55:17,964 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:18,357 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-25 13:55:23,022 : [INFO]  ------------------------- Batch round 1, loss: 0.5623 -------------------------
2023-03-25 13:55:23,023 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:23,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:23,028 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-25 13:55:25,808 : [INFO]  ------------------------- Batch round 2, loss: 0.5448 -------------------------
2023-03-25 13:55:25,808 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:25,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:25,813 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-25 13:55:28,707 : [INFO]  ------------------------- Batch round 3, loss: 0.5388 -------------------------
2023-03-25 13:55:28,707 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:28,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:28,712 : [INFO]  Batch number 71 model fetched from the server
2023-03-25 13:55:28,713 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-25 13:55:30,333 : [INFO]  Batch 71: Training set : loss - 0.5281, accuracy - 0.7554, recall - 0.8804, AUC - 0.8856, F1 - 0.7826, precision - 0.7043, training time - -10.0 seconds
2023-03-25 13:55:30,333 : [INFO]  Batch 71: Testing set : loss - 0.6094, accuracy - 0.6471, recall - 0.7941, AUC - 0.8043, F1 - 0.6923, precision - 0.6136
2023-03-25 13:55:30,339 : [INFO]  Batch 72 initialized 
2023-03-25 13:55:30,812 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:31,202 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-25 13:55:36,560 : [INFO]  ------------------------- Batch round 1, loss: 0.5896 -------------------------
2023-03-25 13:55:36,560 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:36,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:36,566 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-25 13:55:39,574 : [INFO]  ------------------------- Batch round 2, loss: 0.572 -------------------------
2023-03-25 13:55:39,574 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:39,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:39,580 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-25 13:55:42,705 : [INFO]  ------------------------- Batch round 3, loss: 0.5563 -------------------------
2023-03-25 13:55:42,705 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:42,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:42,710 : [INFO]  Batch number 72 model fetched from the server
2023-03-25 13:55:42,711 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-25 13:55:44,063 : [INFO]  Batch 72: Training set : loss - 0.5622, accuracy - 0.712, recall - 0.913, AUC - 0.8693, F1 - 0.7602, precision - 0.6512, training time - -12.0 seconds
2023-03-25 13:55:44,063 : [INFO]  Batch 72: Testing set : loss - 0.6022, accuracy - 0.6569, recall - 0.8235, AUC - 0.8093, F1 - 0.7059, precision - 0.6176
2023-03-25 13:55:44,071 : [INFO]  Batch 73 initialized 
2023-03-25 13:55:44,538 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:44,924 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-25 13:55:49,963 : [INFO]  ------------------------- Batch round 1, loss: 0.5502 -------------------------
2023-03-25 13:55:49,963 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-25 13:55:49,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:49,969 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-25 13:55:53,241 : [INFO]  ------------------------- Batch round 2, loss: 0.5285 -------------------------
2023-03-25 13:55:53,241 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-25 13:55:53,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:53,270 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-25 13:55:56,203 : [INFO]  ------------------------- Batch round 3, loss: 0.5207 -------------------------
2023-03-25 13:55:56,203 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-25 13:55:56,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:55:56,433 : [INFO]  Batch number 73 model fetched from the server
2023-03-25 13:55:56,434 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-25 13:55:57,751 : [INFO]  Batch 73: Training set : loss - 0.5206, accuracy - 0.8152, recall - 0.9565, AUC - 0.8972, F1 - 0.8381, precision - 0.7458, training time - -12.0 seconds
2023-03-25 13:55:57,751 : [INFO]  Batch 73: Testing set : loss - 0.606, accuracy - 0.6569, recall - 0.9118, AUC - 0.8424, F1 - 0.7266, precision - 0.6039
2023-03-25 13:55:57,777 : [INFO]  Batch 74 initialized 
2023-03-25 13:55:58,210 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:55:58,602 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-25 13:56:03,297 : [INFO]  ------------------------- Batch round 1, loss: 0.5647 -------------------------
2023-03-25 13:56:03,297 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:03,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:03,335 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-25 13:56:06,185 : [INFO]  ------------------------- Batch round 2, loss: 0.5579 -------------------------
2023-03-25 13:56:06,185 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:06,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:06,190 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-25 13:56:09,097 : [INFO]  ------------------------- Batch round 3, loss: 0.5455 -------------------------
2023-03-25 13:56:09,097 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:09,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:09,103 : [INFO]  Batch number 74 model fetched from the server
2023-03-25 13:56:09,103 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-25 13:56:10,573 : [INFO]  Batch 74: Training set : loss - 0.535, accuracy - 0.8207, recall - 0.9457, AUC - 0.8897, F1 - 0.8406, precision - 0.7565, training time - -11.0 seconds
2023-03-25 13:56:10,573 : [INFO]  Batch 74: Testing set : loss - 0.5557, accuracy - 0.7304, recall - 0.9216, AUC - 0.8841, F1 - 0.7737, precision - 0.6667
2023-03-25 13:56:10,587 : [INFO]  Batch 75 initialized 
2023-03-25 13:56:11,060 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:11,472 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-25 13:56:16,389 : [INFO]  ------------------------- Batch round 1, loss: 0.5474 -------------------------
2023-03-25 13:56:16,390 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:16,557 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:16,559 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-25 13:56:19,477 : [INFO]  ------------------------- Batch round 2, loss: 0.5356 -------------------------
2023-03-25 13:56:19,477 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:19,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:19,642 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-25 13:56:22,516 : [INFO]  ------------------------- Batch round 3, loss: 0.5249 -------------------------
2023-03-25 13:56:22,517 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:22,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:22,657 : [INFO]  Batch number 75 model fetched from the server
2023-03-25 13:56:22,657 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-25 13:56:24,074 : [INFO]  Batch 75: Training set : loss - 0.5347, accuracy - 0.7772, recall - 0.9783, AUC - 0.9344, F1 - 0.8145, precision - 0.6977, training time - -11.0 seconds
2023-03-25 13:56:24,074 : [INFO]  Batch 75: Testing set : loss - 0.5539, accuracy - 0.7402, recall - 0.9118, AUC - 0.8958, F1 - 0.7782, precision - 0.6788
2023-03-25 13:56:24,098 : [INFO]  Batch 76 initialized 
2023-03-25 13:56:24,624 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:25,046 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-25 13:56:29,856 : [INFO]  ------------------------- Batch round 1, loss: 0.5304 -------------------------
2023-03-25 13:56:29,857 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:30,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:30,006 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-25 13:56:32,870 : [INFO]  ------------------------- Batch round 2, loss: 0.5247 -------------------------
2023-03-25 13:56:32,870 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:32,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:32,978 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-25 13:56:35,790 : [INFO]  ------------------------- Batch round 3, loss: 0.5147 -------------------------
2023-03-25 13:56:35,790 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:35,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:35,948 : [INFO]  Batch number 76 model fetched from the server
2023-03-25 13:56:35,948 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-25 13:56:37,328 : [INFO]  Batch 76: Training set : loss - 0.5149, accuracy - 0.7935, recall - 0.9565, AUC - 0.9109, F1 - 0.8224, precision - 0.7213, training time - -11.0 seconds
2023-03-25 13:56:37,329 : [INFO]  Batch 76: Testing set : loss - 0.5724, accuracy - 0.701, recall - 0.8922, AUC - 0.8665, F1 - 0.749, precision - 0.6454
2023-03-25 13:56:37,343 : [INFO]  Batch 77 initialized 
2023-03-25 13:56:37,866 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:38,369 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-25 13:56:43,105 : [INFO]  ------------------------- Batch round 1, loss: 0.5502 -------------------------
2023-03-25 13:56:43,105 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:43,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:43,163 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-25 13:56:46,036 : [INFO]  ------------------------- Batch round 2, loss: 0.536 -------------------------
2023-03-25 13:56:46,036 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:46,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:46,122 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-25 13:56:49,380 : [INFO]  ------------------------- Batch round 3, loss: 0.5237 -------------------------
2023-03-25 13:56:49,380 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-25 13:56:49,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:49,385 : [INFO]  Batch number 77 model fetched from the server
2023-03-25 13:56:49,386 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-25 13:56:50,946 : [INFO]  Batch 77: Training set : loss - 0.53, accuracy - 0.8043, recall - 0.9457, AUC - 0.9035, F1 - 0.8286, precision - 0.7373, training time - -11.0 seconds
2023-03-25 13:56:50,947 : [INFO]  Batch 77: Testing set : loss - 0.5557, accuracy - 0.7549, recall - 0.902, AUC - 0.866, F1 - 0.7863, precision - 0.697
2023-03-25 13:56:50,960 : [INFO]  Batch 78 initialized 
2023-03-25 13:56:51,526 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:56:51,970 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-25 13:56:56,663 : [INFO]  ------------------------- Batch round 1, loss: 0.5471 -------------------------
2023-03-25 13:56:56,663 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-25 13:56:56,666 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:56,668 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-25 13:56:59,455 : [INFO]  ------------------------- Batch round 2, loss: 0.5337 -------------------------
2023-03-25 13:56:59,455 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-25 13:56:59,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:56:59,460 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-25 13:57:02,230 : [INFO]  ------------------------- Batch round 3, loss: 0.5268 -------------------------
2023-03-25 13:57:02,230 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:02,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:02,235 : [INFO]  Batch number 78 model fetched from the server
2023-03-25 13:57:02,235 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-25 13:57:03,556 : [INFO]  Batch 78: Training set : loss - 0.5233, accuracy - 0.8098, recall - 0.913, AUC - 0.8789, F1 - 0.8276, precision - 0.7568, training time - -10.0 seconds
2023-03-25 13:57:03,556 : [INFO]  Batch 78: Testing set : loss - 0.6003, accuracy - 0.6716, recall - 0.902, AUC - 0.826, F1 - 0.7331, precision - 0.6174
2023-03-25 13:57:03,566 : [INFO]  Batch 79 initialized 
2023-03-25 13:57:04,017 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:04,400 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-25 13:57:08,881 : [INFO]  ------------------------- Batch round 1, loss: 0.5854 -------------------------
2023-03-25 13:57:08,881 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:08,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:08,977 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-25 13:57:11,664 : [INFO]  ------------------------- Batch round 2, loss: 0.5746 -------------------------
2023-03-25 13:57:11,664 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:12,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:12,088 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-25 13:57:14,774 : [INFO]  ------------------------- Batch round 3, loss: 0.565 -------------------------
2023-03-25 13:57:14,774 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:14,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:14,915 : [INFO]  Batch number 79 model fetched from the server
2023-03-25 13:57:14,915 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-25 13:57:16,294 : [INFO]  Batch 79: Training set : loss - 0.5658, accuracy - 0.7391, recall - 0.9239, AUC - 0.8538, F1 - 0.7798, precision - 0.6746, training time - -11.0 seconds
2023-03-25 13:57:16,295 : [INFO]  Batch 79: Testing set : loss - 0.5694, accuracy - 0.7059, recall - 0.902, AUC - 0.8707, F1 - 0.7541, precision - 0.6479
2023-03-25 13:57:16,307 : [INFO]  Batch 80 initialized 
2023-03-25 13:57:16,755 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:17,144 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-25 13:57:21,793 : [INFO]  ------------------------- Batch round 1, loss: 0.553 -------------------------
2023-03-25 13:57:21,793 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:21,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:21,798 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-25 13:57:24,656 : [INFO]  ------------------------- Batch round 2, loss: 0.5362 -------------------------
2023-03-25 13:57:24,656 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:24,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:24,661 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-25 13:57:27,577 : [INFO]  ------------------------- Batch round 3, loss: 0.5351 -------------------------
2023-03-25 13:57:27,577 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:27,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:27,582 : [INFO]  Batch number 80 model fetched from the server
2023-03-25 13:57:27,582 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-25 13:57:28,922 : [INFO]  Batch 80: Training set : loss - 0.5363, accuracy - 0.7772, recall - 0.8696, AUC - 0.866, F1 - 0.796, precision - 0.7339, training time - -10.0 seconds
2023-03-25 13:57:28,922 : [INFO]  Batch 80: Testing set : loss - 0.5952, accuracy - 0.6569, recall - 0.8824, AUC - 0.8466, F1 - 0.72, precision - 0.6081
2023-03-25 13:57:28,929 : [INFO]  Batch 81 initialized 
2023-03-25 13:57:29,357 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:29,770 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-25 13:57:34,382 : [INFO]  ------------------------- Batch round 1, loss: 0.5615 -------------------------
2023-03-25 13:57:34,382 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:34,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:34,387 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-25 13:57:37,196 : [INFO]  ------------------------- Batch round 2, loss: 0.5543 -------------------------
2023-03-25 13:57:37,196 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:37,199 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:37,200 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-25 13:57:40,020 : [INFO]  ------------------------- Batch round 3, loss: 0.5393 -------------------------
2023-03-25 13:57:40,020 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:40,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:40,025 : [INFO]  Batch number 81 model fetched from the server
2023-03-25 13:57:40,025 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-25 13:57:41,338 : [INFO]  Batch 81: Training set : loss - 0.5364, accuracy - 0.788, recall - 0.9457, AUC - 0.8769, F1 - 0.8169, precision - 0.719, training time - -10.0 seconds
2023-03-25 13:57:41,338 : [INFO]  Batch 81: Testing set : loss - 0.563, accuracy - 0.75, recall - 0.8824, AUC - 0.8692, F1 - 0.7792, precision - 0.6977
2023-03-25 13:57:41,350 : [INFO]  Batch 82 initialized 
2023-03-25 13:57:41,784 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:42,185 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-25 13:57:46,668 : [INFO]  ------------------------- Batch round 1, loss: 0.5767 -------------------------
2023-03-25 13:57:46,668 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:46,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:46,746 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-25 13:57:49,459 : [INFO]  ------------------------- Batch round 2, loss: 0.5413 -------------------------
2023-03-25 13:57:49,459 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-25 13:57:49,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:49,482 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-25 13:57:52,253 : [INFO]  ------------------------- Batch round 3, loss: 0.5254 -------------------------
2023-03-25 13:57:52,253 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-25 13:57:52,257 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:52,259 : [INFO]  Batch number 82 model fetched from the server
2023-03-25 13:57:52,259 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-25 13:57:53,576 : [INFO]  Batch 82: Training set : loss - 0.5286, accuracy - 0.7663, recall - 0.9457, AUC - 0.896, F1 - 0.8018, precision - 0.696, training time - -10.0 seconds
2023-03-25 13:57:53,576 : [INFO]  Batch 82: Testing set : loss - 0.5715, accuracy - 0.7157, recall - 0.8824, AUC - 0.8385, F1 - 0.7563, precision - 0.6618
2023-03-25 13:57:53,585 : [INFO]  Batch 83 initialized 
2023-03-25 13:57:54,015 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:57:54,421 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-25 13:57:58,966 : [INFO]  ------------------------- Batch round 1, loss: 0.5701 -------------------------
2023-03-25 13:57:58,966 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-25 13:57:58,969 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:57:58,971 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-25 13:58:01,732 : [INFO]  ------------------------- Batch round 2, loss: 0.5663 -------------------------
2023-03-25 13:58:01,733 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:01,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:01,743 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-25 13:58:04,580 : [INFO]  ------------------------- Batch round 3, loss: 0.5653 -------------------------
2023-03-25 13:58:04,580 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:04,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:04,585 : [INFO]  Batch number 83 model fetched from the server
2023-03-25 13:58:04,585 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-25 13:58:05,884 : [INFO]  Batch 83: Training set : loss - 0.5583, accuracy - 0.7283, recall - 0.913, AUC - 0.8323, F1 - 0.7706, precision - 0.6667, training time - -10.0 seconds
2023-03-25 13:58:05,884 : [INFO]  Batch 83: Testing set : loss - 0.5417, accuracy - 0.7451, recall - 0.9412, AUC - 0.8876, F1 - 0.7869, precision - 0.6761
2023-03-25 13:58:05,895 : [INFO]  Batch 84 initialized 
2023-03-25 13:58:06,323 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:06,727 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-25 13:58:11,327 : [INFO]  ------------------------- Batch round 1, loss: 0.5434 -------------------------
2023-03-25 13:58:11,327 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:11,331 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:11,332 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-25 13:58:14,133 : [INFO]  ------------------------- Batch round 2, loss: 0.5368 -------------------------
2023-03-25 13:58:14,134 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:14,136 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:14,138 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-25 13:58:16,895 : [INFO]  ------------------------- Batch round 3, loss: 0.5253 -------------------------
2023-03-25 13:58:16,895 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:16,899 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:16,901 : [INFO]  Batch number 84 model fetched from the server
2023-03-25 13:58:16,901 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-25 13:58:18,214 : [INFO]  Batch 84: Training set : loss - 0.5331, accuracy - 0.7609, recall - 0.913, AUC - 0.8959, F1 - 0.7925, precision - 0.7, training time - -10.0 seconds
2023-03-25 13:58:18,214 : [INFO]  Batch 84: Testing set : loss - 0.5988, accuracy - 0.6912, recall - 0.951, AUC - 0.848, F1 - 0.7549, precision - 0.6258
2023-03-25 13:58:18,228 : [INFO]  Batch 85 initialized 
2023-03-25 13:58:18,660 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:19,066 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-25 13:58:23,453 : [INFO]  ------------------------- Batch round 1, loss: 0.5293 -------------------------
2023-03-25 13:58:23,453 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:23,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:23,736 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-25 13:58:26,390 : [INFO]  ------------------------- Batch round 2, loss: 0.5196 -------------------------
2023-03-25 13:58:26,390 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:26,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:26,401 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-25 13:58:29,079 : [INFO]  ------------------------- Batch round 3, loss: 0.509 -------------------------
2023-03-25 13:58:29,079 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:29,135 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:29,138 : [INFO]  Batch number 85 model fetched from the server
2023-03-25 13:58:29,138 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-25 13:58:30,420 : [INFO]  Batch 85: Training set : loss - 0.5135, accuracy - 0.7989, recall - 0.9457, AUC - 0.9211, F1 - 0.8246, precision - 0.7311, training time - -10.0 seconds
2023-03-25 13:58:30,420 : [INFO]  Batch 85: Testing set : loss - 0.5282, accuracy - 0.8137, recall - 0.9216, AUC - 0.9064, F1 - 0.8319, precision - 0.7581
2023-03-25 13:58:30,429 : [INFO]  Batch 86 initialized 
2023-03-25 13:58:30,855 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:31,262 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-25 13:58:35,876 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-25 13:58:35,876 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:35,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:35,904 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-25 13:58:38,733 : [INFO]  ------------------------- Batch round 2, loss: 0.5503 -------------------------
2023-03-25 13:58:38,733 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:38,756 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:38,759 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-25 13:58:41,554 : [INFO]  ------------------------- Batch round 3, loss: 0.5535 -------------------------
2023-03-25 13:58:41,555 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:41,569 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:41,571 : [INFO]  Batch number 86 model fetched from the server
2023-03-25 13:58:41,571 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-25 13:58:42,874 : [INFO]  Batch 86: Training set : loss - 0.5475, accuracy - 0.788, recall - 0.9348, AUC - 0.865, F1 - 0.8152, precision - 0.7227, training time - -10.0 seconds
2023-03-25 13:58:42,874 : [INFO]  Batch 86: Testing set : loss - 0.5508, accuracy - 0.75, recall - 0.9314, AUC - 0.8845, F1 - 0.7884, precision - 0.6835
2023-03-25 13:58:42,885 : [INFO]  Batch 87 initialized 
2023-03-25 13:58:43,319 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:43,737 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-25 13:58:48,192 : [INFO]  ------------------------- Batch round 1, loss: 0.5717 -------------------------
2023-03-25 13:58:48,192 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-25 13:58:48,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:48,198 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-25 13:58:50,910 : [INFO]  ------------------------- Batch round 2, loss: 0.565 -------------------------
2023-03-25 13:58:50,910 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-25 13:58:50,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:50,924 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-25 13:58:53,592 : [INFO]  ------------------------- Batch round 3, loss: 0.5653 -------------------------
2023-03-25 13:58:53,592 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-25 13:58:53,604 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:58:53,606 : [INFO]  Batch number 87 model fetched from the server
2023-03-25 13:58:53,606 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-25 13:58:54,883 : [INFO]  Batch 87: Training set : loss - 0.5652, accuracy - 0.7174, recall - 0.9457, AUC - 0.8755, F1 - 0.7699, precision - 0.6493, training time - -10.0 seconds
2023-03-25 13:58:54,883 : [INFO]  Batch 87: Testing set : loss - 0.5352, accuracy - 0.7353, recall - 0.9706, AUC - 0.9225, F1 - 0.7857, precision - 0.66
2023-03-25 13:58:54,896 : [INFO]  Batch 88 initialized 
2023-03-25 13:58:55,326 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:58:55,739 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-25 13:59:00,305 : [INFO]  ------------------------- Batch round 1, loss: 0.5623 -------------------------
2023-03-25 13:59:00,305 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:00,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:00,312 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-25 13:59:03,163 : [INFO]  ------------------------- Batch round 2, loss: 0.5495 -------------------------
2023-03-25 13:59:03,163 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:03,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:03,168 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-25 13:59:05,993 : [INFO]  ------------------------- Batch round 3, loss: 0.5359 -------------------------
2023-03-25 13:59:05,993 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:05,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:05,998 : [INFO]  Batch number 88 model fetched from the server
2023-03-25 13:59:05,998 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-25 13:59:07,323 : [INFO]  Batch 88: Training set : loss - 0.5391, accuracy - 0.7663, recall - 0.9565, AUC - 0.9062, F1 - 0.8037, precision - 0.6929, training time - -10.0 seconds
2023-03-25 13:59:07,323 : [INFO]  Batch 88: Testing set : loss - 0.5713, accuracy - 0.6863, recall - 0.9216, AUC - 0.8759, F1 - 0.746, precision - 0.6267
2023-03-25 13:59:07,329 : [INFO]  Batch 89 initialized 
2023-03-25 13:59:07,759 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:08,280 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-25 13:59:13,950 : [INFO]  ------------------------- Batch round 1, loss: 0.5667 -------------------------
2023-03-25 13:59:13,950 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:14,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:14,061 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-25 13:59:17,753 : [INFO]  ------------------------- Batch round 2, loss: 0.5517 -------------------------
2023-03-25 13:59:17,759 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:17,777 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:17,779 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-25 13:59:20,506 : [INFO]  ------------------------- Batch round 3, loss: 0.5423 -------------------------
2023-03-25 13:59:20,506 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:20,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:20,603 : [INFO]  Batch number 89 model fetched from the server
2023-03-25 13:59:20,603 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-25 13:59:22,045 : [INFO]  Batch 89: Training set : loss - 0.5359, accuracy - 0.7826, recall - 0.9457, AUC - 0.8667, F1 - 0.8131, precision - 0.7131, training time - -12.0 seconds
2023-03-25 13:59:22,046 : [INFO]  Batch 89: Testing set : loss - 0.5538, accuracy - 0.7549, recall - 0.9412, AUC - 0.883, F1 - 0.7934, precision - 0.6857
2023-03-25 13:59:22,112 : [INFO]  Batch 90 initialized 
2023-03-25 13:59:22,564 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:23,164 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-25 13:59:27,691 : [INFO]  ------------------------- Batch round 1, loss: 0.5742 -------------------------
2023-03-25 13:59:27,691 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:27,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:27,697 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-25 13:59:30,514 : [INFO]  ------------------------- Batch round 2, loss: 0.5503 -------------------------
2023-03-25 13:59:30,514 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:30,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:30,559 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-25 13:59:33,408 : [INFO]  ------------------------- Batch round 3, loss: 0.5398 -------------------------
2023-03-25 13:59:33,408 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:33,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:33,413 : [INFO]  Batch number 90 model fetched from the server
2023-03-25 13:59:33,413 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-25 13:59:34,714 : [INFO]  Batch 90: Training set : loss - 0.5472, accuracy - 0.7554, recall - 0.9457, AUC - 0.887, F1 - 0.7945, precision - 0.685, training time - -10.0 seconds
2023-03-25 13:59:34,714 : [INFO]  Batch 90: Testing set : loss - 0.6002, accuracy - 0.6912, recall - 0.8431, AUC - 0.7999, F1 - 0.7319, precision - 0.6466
2023-03-25 13:59:34,720 : [INFO]  Batch 91 initialized 
2023-03-25 13:59:35,152 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:35,571 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-25 13:59:40,282 : [INFO]  ------------------------- Batch round 1, loss: 0.5724 -------------------------
2023-03-25 13:59:40,282 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:40,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:40,287 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-25 13:59:43,737 : [INFO]  ------------------------- Batch round 2, loss: 0.5523 -------------------------
2023-03-25 13:59:43,737 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:43,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:43,742 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-25 13:59:46,914 : [INFO]  ------------------------- Batch round 3, loss: 0.5386 -------------------------
2023-03-25 13:59:46,915 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-25 13:59:47,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:47,094 : [INFO]  Batch number 91 model fetched from the server
2023-03-25 13:59:47,094 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-25 13:59:48,754 : [INFO]  Batch 91: Training set : loss - 0.5564, accuracy - 0.7554, recall - 0.9239, AUC - 0.883, F1 - 0.7907, precision - 0.6911, training time - -12.0 seconds
2023-03-25 13:59:48,755 : [INFO]  Batch 91: Testing set : loss - 0.595, accuracy - 0.6961, recall - 0.9314, AUC - 0.8483, F1 - 0.754, precision - 0.6333
2023-03-25 13:59:48,765 : [INFO]  Batch 92 initialized 
2023-03-25 13:59:49,276 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 13:59:49,717 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-25 13:59:54,932 : [INFO]  ------------------------- Batch round 1, loss: 0.5193 -------------------------
2023-03-25 13:59:54,932 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-25 13:59:55,437 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:55,439 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-25 13:59:58,702 : [INFO]  ------------------------- Batch round 2, loss: 0.5162 -------------------------
2023-03-25 13:59:58,702 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-25 13:59:59,098 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 13:59:59,100 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-25 14:00:02,630 : [INFO]  ------------------------- Batch round 3, loss: 0.5079 -------------------------
2023-03-25 14:00:02,630 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-25 14:00:03,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:00:03,212 : [INFO]  Batch number 92 model fetched from the server
2023-03-25 14:00:03,212 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-25 14:00:04,540 : [INFO]  Batch 92: Training set : loss - 0.5132, accuracy - 0.8207, recall - 0.8913, AUC - 0.8854, F1 - 0.8325, precision - 0.781, training time - -13.0 seconds
2023-03-25 14:00:04,540 : [INFO]  Batch 92: Testing set : loss - 0.5738, accuracy - 0.7255, recall - 0.8922, AUC - 0.8684, F1 - 0.7647, precision - 0.6691
2023-03-25 14:00:04,551 : [INFO]  Batch 93 initialized 
2023-03-25 14:00:04,995 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 14:00:05,399 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-25 14:00:10,283 : [INFO]  ------------------------- Batch round 1, loss: 0.5425 -------------------------
2023-03-25 14:00:10,283 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-25 14:00:10,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 14:00:10,366 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-25 14:00:13,201 : [INFO]  ------------------------- Batch round 2, loss: 0.5259 -------------------------
2023-03-25 14:00:13,201 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-25 14:00:16,067 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
