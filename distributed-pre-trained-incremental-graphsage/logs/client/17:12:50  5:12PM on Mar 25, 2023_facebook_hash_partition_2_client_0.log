2023-03-25 17:12:50,866 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 17:12:50,866 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 2, epochs 6
2023-03-25 17:12:55,473 : [INFO]  Model initialized for training
2023-03-25 17:13:16,226 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:13:16,535 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 17:13:16,536 : [INFO]  Connected to the server
2023-03-25 17:13:16,720 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 17:13:16,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:13:16,735 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 17:13:16,736 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 17:14:33,084 : [INFO]  ------------------------- Training round 1, loss: 0.6567 -------------------------
2023-03-25 17:14:33,085 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 17:14:33,204 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:14:33,209 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 17:15:21,815 : [INFO]  ------------------------- Training round 2, loss: 0.61 -------------------------
2023-03-25 17:15:21,815 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 17:15:21,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:15:21,894 : [INFO]  ################ Initial trained model: Final global model evalution after 2 rounds ################
2023-03-25 17:16:14,023 : [INFO]  Initially trained model: Training set : loss - 0.6, accuracy - 0.68, recall - 0.87, AUC - 0.8, F1 - 0.73, precision - 0.63, training time - -125.0 seconds
2023-03-25 17:16:14,023 : [INFO]  Initially trained model: Testing set : loss - 0.6, accuracy - 0.68, recall - 0.88, AUC - 0.81, F1 - 0.73, precision - 0.63
2023-03-25 17:16:14,037 : [INFO]  Batch 1 initialized 
2023-03-25 17:16:14,591 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:14,737 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 17:16:14,737 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 17:16:20,007 : [INFO]  ------------------------- Batch round 1, loss: 0.6308 -------------------------
2023-03-25 17:16:20,007 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:20,010 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:20,012 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 17:16:22,480 : [INFO]  ------------------------- Batch round 2, loss: 0.6257 -------------------------
2023-03-25 17:16:22,480 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:22,483 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:22,485 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 17:16:22,485 : [INFO]  ################ Batch 1: final global model evalution after 2 rounds ################
2023-03-25 17:16:24,315 : [INFO]  Batch 1: Training set : loss - 0.6491, accuracy - 0.6467, recall - 0.9239, AUC - 0.7093, F1 - 0.7234, precision - 0.5944, training time - -8.0 seconds
2023-03-25 17:16:24,316 : [INFO]  Batch 1: Testing set : loss - 0.5985, accuracy - 0.7304, recall - 0.8824, AUC - 0.8225, F1 - 0.766, precision - 0.6767
2023-03-25 17:16:24,322 : [INFO]  Batch 2 initialized 
2023-03-25 17:16:24,945 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:25,246 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 17:16:31,221 : [INFO]  ------------------------- Batch round 1, loss: 0.5923 -------------------------
2023-03-25 17:16:31,221 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:31,390 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:31,392 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 17:16:34,299 : [INFO]  ------------------------- Batch round 2, loss: 0.5947 -------------------------
2023-03-25 17:16:34,299 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:34,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:34,305 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 17:16:34,305 : [INFO]  ################ Batch 2: final global model evalution after 2 rounds ################
2023-03-25 17:16:35,954 : [INFO]  Batch 2: Training set : loss - 0.6095, accuracy - 0.7446, recall - 0.9674, AUC - 0.7732, F1 - 0.7911, precision - 0.6692, training time - -9.0 seconds
2023-03-25 17:16:35,954 : [INFO]  Batch 2: Testing set : loss - 0.6122, accuracy - 0.7157, recall - 0.9216, AUC - 0.7758, F1 - 0.7642, precision - 0.6528
2023-03-25 17:16:35,970 : [INFO]  Batch 3 initialized 
2023-03-25 17:16:36,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:36,909 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 17:16:42,382 : [INFO]  ------------------------- Batch round 1, loss: 0.5724 -------------------------
2023-03-25 17:16:42,382 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:42,387 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:42,389 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 17:16:44,872 : [INFO]  ------------------------- Batch round 2, loss: 0.5793 -------------------------
2023-03-25 17:16:44,872 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:44,899 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:44,902 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 17:16:44,902 : [INFO]  ################ Batch 3: final global model evalution after 2 rounds ################
2023-03-25 17:16:46,576 : [INFO]  Batch 3: Training set : loss - 0.5862, accuracy - 0.7337, recall - 0.9022, AUC - 0.824, F1 - 0.7721, precision - 0.6748, training time - -8.0 seconds
2023-03-25 17:16:46,576 : [INFO]  Batch 3: Testing set : loss - 0.5931, accuracy - 0.7255, recall - 0.9804, AUC - 0.8311, F1 - 0.7812, precision - 0.6494
2023-03-25 17:16:46,590 : [INFO]  Batch 4 initialized 
2023-03-25 17:16:47,119 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:47,405 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 17:16:53,024 : [INFO]  ------------------------- Batch round 1, loss: 0.5928 -------------------------
2023-03-25 17:16:53,024 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 17:16:53,030 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:53,033 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 17:16:55,668 : [INFO]  ------------------------- Batch round 2, loss: 0.5944 -------------------------
2023-03-25 17:16:55,668 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 17:16:55,673 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:16:55,676 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 17:16:55,676 : [INFO]  ################ Batch 4: final global model evalution after 2 rounds ################
2023-03-25 17:16:57,500 : [INFO]  Batch 4: Training set : loss - 0.61, accuracy - 0.6902, recall - 0.913, AUC - 0.8227, F1 - 0.7467, precision - 0.6316, training time - -8.0 seconds
2023-03-25 17:16:57,500 : [INFO]  Batch 4: Testing set : loss - 0.6145, accuracy - 0.6912, recall - 0.9412, AUC - 0.7915, F1 - 0.7529, precision - 0.6275
2023-03-25 17:16:57,512 : [INFO]  Batch 5 initialized 
2023-03-25 17:16:58,338 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:16:58,683 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 17:17:03,477 : [INFO]  ------------------------- Batch round 1, loss: 0.5794 -------------------------
2023-03-25 17:17:03,478 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:03,481 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:03,483 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 17:17:05,729 : [INFO]  ------------------------- Batch round 2, loss: 0.5866 -------------------------
2023-03-25 17:17:05,729 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:05,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:05,735 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 17:17:05,735 : [INFO]  ################ Batch 5: final global model evalution after 2 rounds ################
2023-03-25 17:17:07,321 : [INFO]  Batch 5: Training set : loss - 0.6042, accuracy - 0.75, recall - 0.9348, AUC - 0.7935, F1 - 0.789, precision - 0.6825, training time - -7.0 seconds
2023-03-25 17:17:07,321 : [INFO]  Batch 5: Testing set : loss - 0.6341, accuracy - 0.6716, recall - 0.8725, AUC - 0.7333, F1 - 0.7265, precision - 0.6224
2023-03-25 17:17:07,331 : [INFO]  Batch 6 initialized 
2023-03-25 17:17:07,790 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:08,095 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 17:17:12,400 : [INFO]  ------------------------- Batch round 1, loss: 0.5816 -------------------------
2023-03-25 17:17:12,400 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:12,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:12,405 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 17:17:14,549 : [INFO]  ------------------------- Batch round 2, loss: 0.5835 -------------------------
2023-03-25 17:17:14,550 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:14,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:14,555 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 17:17:14,555 : [INFO]  ################ Batch 6: final global model evalution after 2 rounds ################
2023-03-25 17:17:15,983 : [INFO]  Batch 6: Training set : loss - 0.6019, accuracy - 0.6848, recall - 0.9457, AUC - 0.8022, F1 - 0.75, precision - 0.6214, training time - -6.0 seconds
2023-03-25 17:17:15,983 : [INFO]  Batch 6: Testing set : loss - 0.6009, accuracy - 0.7206, recall - 0.9412, AUC - 0.7816, F1 - 0.7711, precision - 0.6531
2023-03-25 17:17:15,992 : [INFO]  Batch 7 initialized 
2023-03-25 17:17:16,839 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:17,267 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 17:17:21,817 : [INFO]  ------------------------- Batch round 1, loss: 0.6043 -------------------------
2023-03-25 17:17:21,817 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:21,821 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:21,823 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 17:17:24,630 : [INFO]  ------------------------- Batch round 2, loss: 0.6072 -------------------------
2023-03-25 17:17:24,630 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:24,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:24,637 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 17:17:24,638 : [INFO]  ################ Batch 7: final global model evalution after 2 rounds ################
2023-03-25 17:17:26,545 : [INFO]  Batch 7: Training set : loss - 0.6215, accuracy - 0.6576, recall - 0.913, AUC - 0.7756, F1 - 0.7273, precision - 0.6043, training time - -7.0 seconds
2023-03-25 17:17:26,545 : [INFO]  Batch 7: Testing set : loss - 0.6297, accuracy - 0.6176, recall - 0.8235, AUC - 0.759, F1 - 0.6829, precision - 0.5833
2023-03-25 17:17:26,558 : [INFO]  Batch 8 initialized 
2023-03-25 17:17:27,095 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:27,451 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 17:17:32,998 : [INFO]  ------------------------- Batch round 1, loss: 0.5926 -------------------------
2023-03-25 17:17:32,998 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:33,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:33,005 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 17:17:35,640 : [INFO]  ------------------------- Batch round 2, loss: 0.59 -------------------------
2023-03-25 17:17:35,640 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:35,644 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:35,647 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 17:17:35,647 : [INFO]  ################ Batch 8: final global model evalution after 2 rounds ################
2023-03-25 17:17:37,272 : [INFO]  Batch 8: Training set : loss - 0.6155, accuracy - 0.7065, recall - 0.8913, AUC - 0.7827, F1 - 0.7523, precision - 0.6508, training time - -8.0 seconds
2023-03-25 17:17:37,272 : [INFO]  Batch 8: Testing set : loss - 0.6028, accuracy - 0.6961, recall - 0.8627, AUC - 0.8053, F1 - 0.7395, precision - 0.6471
2023-03-25 17:17:37,279 : [INFO]  Batch 9 initialized 
2023-03-25 17:17:37,800 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:38,112 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 17:17:42,937 : [INFO]  ------------------------- Batch round 1, loss: 0.5914 -------------------------
2023-03-25 17:17:42,937 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:43,123 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:43,125 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 17:17:45,600 : [INFO]  ------------------------- Batch round 2, loss: 0.5881 -------------------------
2023-03-25 17:17:45,600 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:45,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:45,727 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 17:17:45,728 : [INFO]  ################ Batch 9: final global model evalution after 2 rounds ################
2023-03-25 17:17:47,603 : [INFO]  Batch 9: Training set : loss - 0.6111, accuracy - 0.6576, recall - 0.9457, AUC - 0.8207, F1 - 0.7342, precision - 0.6, training time - -8.0 seconds
2023-03-25 17:17:47,604 : [INFO]  Batch 9: Testing set : loss - 0.6055, accuracy - 0.6471, recall - 0.8333, AUC - 0.8073, F1 - 0.7025, precision - 0.6071
2023-03-25 17:17:47,616 : [INFO]  Batch 10 initialized 
2023-03-25 17:17:48,170 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:48,481 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 17:17:54,082 : [INFO]  ------------------------- Batch round 1, loss: 0.5849 -------------------------
2023-03-25 17:17:54,082 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 17:17:54,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:54,089 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 17:17:56,602 : [INFO]  ------------------------- Batch round 2, loss: 0.5893 -------------------------
2023-03-25 17:17:56,603 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 17:17:56,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:17:56,708 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 17:17:56,708 : [INFO]  ################ Batch 10: final global model evalution after 2 rounds ################
2023-03-25 17:17:58,282 : [INFO]  Batch 10: Training set : loss - 0.5972, accuracy - 0.712, recall - 0.9348, AUC - 0.8305, F1 - 0.7644, precision - 0.6466, training time - -8.0 seconds
2023-03-25 17:17:58,282 : [INFO]  Batch 10: Testing set : loss - 0.5864, accuracy - 0.7157, recall - 0.9118, AUC - 0.8667, F1 - 0.7623, precision - 0.6549
2023-03-25 17:17:58,295 : [INFO]  Batch 11 initialized 
2023-03-25 17:17:58,818 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:17:59,125 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 17:18:03,674 : [INFO]  ------------------------- Batch round 1, loss: 0.5911 -------------------------
2023-03-25 17:18:03,674 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:03,678 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:03,680 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 17:18:06,128 : [INFO]  ------------------------- Batch round 2, loss: 0.5912 -------------------------
2023-03-25 17:18:06,129 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:06,135 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:06,138 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 17:18:06,138 : [INFO]  ################ Batch 11: final global model evalution after 2 rounds ################
2023-03-25 17:18:08,172 : [INFO]  Batch 11: Training set : loss - 0.6063, accuracy - 0.7011, recall - 0.8913, AUC - 0.7723, F1 - 0.7489, precision - 0.6457, training time - -7.0 seconds
2023-03-25 17:18:08,172 : [INFO]  Batch 11: Testing set : loss - 0.5994, accuracy - 0.6961, recall - 0.8627, AUC - 0.8063, F1 - 0.7395, precision - 0.6471
2023-03-25 17:18:08,183 : [INFO]  Batch 12 initialized 
2023-03-25 17:18:08,767 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:09,101 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 17:18:16,262 : [INFO]  ------------------------- Batch round 1, loss: 0.5889 -------------------------
2023-03-25 17:18:16,262 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:16,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:16,267 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 17:18:19,466 : [INFO]  ------------------------- Batch round 2, loss: 0.6032 -------------------------
2023-03-25 17:18:19,466 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:19,472 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:19,477 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 17:18:19,478 : [INFO]  ################ Batch 12: final global model evalution after 2 rounds ################
2023-03-25 17:18:21,757 : [INFO]  Batch 12: Training set : loss - 0.6195, accuracy - 0.6848, recall - 0.8587, AUC - 0.7794, F1 - 0.7315, precision - 0.6371, training time - -10.0 seconds
2023-03-25 17:18:21,758 : [INFO]  Batch 12: Testing set : loss - 0.6302, accuracy - 0.6618, recall - 0.8235, AUC - 0.7339, F1 - 0.7089, precision - 0.6222
2023-03-25 17:18:21,771 : [INFO]  Batch 13 initialized 
2023-03-25 17:18:22,567 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:22,910 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 17:18:29,321 : [INFO]  ------------------------- Batch round 1, loss: 0.6105 -------------------------
2023-03-25 17:18:29,321 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:29,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:29,356 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 17:18:32,856 : [INFO]  ------------------------- Batch round 2, loss: 0.6041 -------------------------
2023-03-25 17:18:32,857 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:32,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:32,868 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 17:18:32,868 : [INFO]  ################ Batch 13: final global model evalution after 2 rounds ################
2023-03-25 17:18:35,051 : [INFO]  Batch 13: Training set : loss - 0.6253, accuracy - 0.6576, recall - 0.8478, AUC - 0.7378, F1 - 0.7123, precision - 0.6142, training time - -10.0 seconds
2023-03-25 17:18:35,052 : [INFO]  Batch 13: Testing set : loss - 0.6042, accuracy - 0.6814, recall - 0.8725, AUC - 0.812, F1 - 0.7325, precision - 0.6312
2023-03-25 17:18:35,065 : [INFO]  Batch 14 initialized 
2023-03-25 17:18:35,971 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:36,404 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 17:18:43,159 : [INFO]  ------------------------- Batch round 1, loss: 0.5816 -------------------------
2023-03-25 17:18:43,160 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:43,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:43,173 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 17:18:45,649 : [INFO]  ------------------------- Batch round 2, loss: 0.5882 -------------------------
2023-03-25 17:18:45,649 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:45,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:45,654 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 17:18:45,655 : [INFO]  ################ Batch 14: final global model evalution after 2 rounds ################
2023-03-25 17:18:47,291 : [INFO]  Batch 14: Training set : loss - 0.6011, accuracy - 0.7391, recall - 0.9348, AUC - 0.8064, F1 - 0.7818, precision - 0.6719, training time - -9.0 seconds
2023-03-25 17:18:47,291 : [INFO]  Batch 14: Testing set : loss - 0.606, accuracy - 0.6716, recall - 0.9118, AUC - 0.826, F1 - 0.7352, precision - 0.6159
2023-03-25 17:18:47,304 : [INFO]  Batch 15 initialized 
2023-03-25 17:18:47,851 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:18:48,124 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 17:18:53,535 : [INFO]  ------------------------- Batch round 1, loss: 0.5933 -------------------------
2023-03-25 17:18:53,535 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 17:18:53,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:53,547 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 17:18:57,377 : [INFO]  ------------------------- Batch round 2, loss: 0.5949 -------------------------
2023-03-25 17:18:57,377 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 17:18:57,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:18:57,385 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 17:18:57,385 : [INFO]  ################ Batch 15: final global model evalution after 2 rounds ################
2023-03-25 17:19:00,116 : [INFO]  Batch 15: Training set : loss - 0.6098, accuracy - 0.7446, recall - 0.9457, AUC - 0.7797, F1 - 0.7873, precision - 0.6744, training time - -9.0 seconds
2023-03-25 17:19:00,116 : [INFO]  Batch 15: Testing set : loss - 0.6377, accuracy - 0.6176, recall - 0.8529, AUC - 0.7435, F1 - 0.6905, precision - 0.58
2023-03-25 17:19:00,129 : [INFO]  Batch 16 initialized 
2023-03-25 17:19:01,248 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:01,675 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 17:19:07,279 : [INFO]  ------------------------- Batch round 1, loss: 0.5944 -------------------------
2023-03-25 17:19:07,279 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:07,349 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:07,352 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 17:19:10,262 : [INFO]  ------------------------- Batch round 2, loss: 0.5943 -------------------------
2023-03-25 17:19:10,262 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 17:19:10,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:10,688 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 17:19:10,688 : [INFO]  ################ Batch 16: final global model evalution after 2 rounds ################
2023-03-25 17:19:12,730 : [INFO]  Batch 16: Training set : loss - 0.6044, accuracy - 0.7011, recall - 0.9674, AUC - 0.8106, F1 - 0.7639, precision - 0.6312, training time - -9.0 seconds
2023-03-25 17:19:12,731 : [INFO]  Batch 16: Testing set : loss - 0.5633, accuracy - 0.75, recall - 0.951, AUC - 0.8843, F1 - 0.7918, precision - 0.6783
2023-03-25 17:19:12,744 : [INFO]  Batch 17 initialized 
2023-03-25 17:19:13,492 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:14,082 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 17:19:20,427 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 17:19:20,427 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:20,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:20,523 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 17:19:23,107 : [INFO]  ------------------------- Batch round 2, loss: 0.5707 -------------------------
2023-03-25 17:19:23,107 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 17:19:23,111 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:23,114 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 17:19:23,114 : [INFO]  ################ Batch 17: final global model evalution after 2 rounds ################
2023-03-25 17:19:24,902 : [INFO]  Batch 17: Training set : loss - 0.5845, accuracy - 0.75, recall - 0.9674, AUC - 0.8626, F1 - 0.7946, precision - 0.6742, training time - -9.0 seconds
2023-03-25 17:19:24,902 : [INFO]  Batch 17: Testing set : loss - 0.6004, accuracy - 0.6863, recall - 0.8725, AUC - 0.8187, F1 - 0.7355, precision - 0.6357
2023-03-25 17:19:24,916 : [INFO]  Batch 18 initialized 
2023-03-25 17:19:25,768 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:25,993 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 17:19:30,044 : [INFO]  ------------------------- Batch round 1, loss: 0.5877 -------------------------
2023-03-25 17:19:30,044 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:30,425 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:30,427 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 17:19:32,516 : [INFO]  ------------------------- Batch round 2, loss: 0.5844 -------------------------
2023-03-25 17:19:32,516 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 17:19:32,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:32,697 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 17:19:32,697 : [INFO]  ################ Batch 18: final global model evalution after 2 rounds ################
2023-03-25 17:19:33,992 : [INFO]  Batch 18: Training set : loss - 0.6039, accuracy - 0.7065, recall - 0.9239, AUC - 0.7929, F1 - 0.7589, precision - 0.6439, training time - -7.0 seconds
2023-03-25 17:19:33,992 : [INFO]  Batch 18: Testing set : loss - 0.5958, accuracy - 0.7157, recall - 0.9412, AUC - 0.8267, F1 - 0.768, precision - 0.6486
2023-03-25 17:19:34,004 : [INFO]  Batch 19 initialized 
2023-03-25 17:19:34,442 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:19:34,689 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 17:19:38,747 : [INFO]  ------------------------- Batch round 1, loss: 0.6029 -------------------------
2023-03-25 17:19:38,747 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 17:19:38,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:19:38,916 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 17:19:41,069 : [INFO]  ------------------------- Batch round 2, loss: 0.604 -------------------------
2023-03-25 17:19:41,069 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 17:19:41,071 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
