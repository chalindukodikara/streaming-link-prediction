2023-03-25 17:20:05,222 : [WARNING]  ####################################### New Training Session: Client 0 #######################################
2023-03-25 17:20:05,222 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 0, training epochs 6, epochs 6
2023-03-25 17:20:08,135 : [INFO]  Model initialized for training
2023-03-25 17:20:24,038 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:20:24,190 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 17:20:24,191 : [INFO]  Connected to the server
2023-03-25 17:20:24,282 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 17:20:24,282 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:20:24,290 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 17:20:24,290 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 17:23:20,864 : [INFO]  ------------------------- Training round 1, loss: 0.6222 -------------------------
2023-03-25 17:23:20,865 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 17:23:30,927 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:23:30,930 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 17:26:28,940 : [INFO]  ------------------------- Training round 2, loss: 0.5953 -------------------------
2023-03-25 17:26:28,941 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 17:26:30,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:26:30,883 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 17:29:25,164 : [INFO]  ------------------------- Training round 3, loss: 0.5929 -------------------------
2023-03-25 17:29:25,164 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 17:29:26,727 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:29:26,730 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 17:32:17,758 : [INFO]  ------------------------- Training round 4, loss: 0.5923 -------------------------
2023-03-25 17:32:17,758 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 17:32:31,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:32:31,075 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 17:35:25,022 : [INFO]  ------------------------- Training round 5, loss: 0.5911 -------------------------
2023-03-25 17:35:25,023 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 17:35:26,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:35:26,808 : [INFO]  ################ Initial trained model: Final global model evalution after 5 rounds ################
2023-03-25 17:36:25,845 : [INFO]  Initially trained model: Training set : loss - 0.59, accuracy - 0.7, recall - 0.86, AUC - 0.83, F1 - 0.74, precision - 0.65, training time - -903.0 seconds
2023-03-25 17:36:25,845 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.69, recall - 0.87, AUC - 0.83, F1 - 0.74, precision - 0.64
2023-03-25 17:36:25,853 : [INFO]  Batch 1 initialized 
2023-03-25 17:36:26,412 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:36:26,526 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 17:36:26,526 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 17:36:31,685 : [INFO]  ------------------------- Batch round 1, loss: 0.5814 -------------------------
2023-03-25 17:36:31,685 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 17:36:32,379 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:32,381 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 17:36:35,403 : [INFO]  ------------------------- Batch round 2, loss: 0.5948 -------------------------
2023-03-25 17:36:35,404 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 17:36:35,408 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:35,410 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 17:36:38,300 : [INFO]  ------------------------- Batch round 3, loss: 0.5846 -------------------------
2023-03-25 17:36:38,300 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 17:36:38,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:38,307 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 17:36:38,307 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-25 17:36:40,070 : [INFO]  Batch 1: Training set : loss - 0.6105, accuracy - 0.6685, recall - 0.8587, AUC - 0.767, F1 - 0.7215, precision - 0.622, training time - -12.0 seconds
2023-03-25 17:36:40,070 : [INFO]  Batch 1: Testing set : loss - 0.5816, accuracy - 0.6814, recall - 0.8235, AUC - 0.8195, F1 - 0.721, precision - 0.6412
2023-03-25 17:36:40,080 : [INFO]  Batch 2 initialized 
2023-03-25 17:36:40,641 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:36:40,795 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 17:36:45,901 : [INFO]  ------------------------- Batch round 1, loss: 0.5654 -------------------------
2023-03-25 17:36:45,901 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 17:36:45,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:45,909 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 17:36:48,572 : [INFO]  ------------------------- Batch round 2, loss: 0.5663 -------------------------
2023-03-25 17:36:48,572 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 17:36:48,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:48,587 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 17:36:51,304 : [INFO]  ------------------------- Batch round 3, loss: 0.5597 -------------------------
2023-03-25 17:36:51,304 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 17:36:51,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:51,311 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 17:36:51,311 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-25 17:36:53,059 : [INFO]  Batch 2: Training set : loss - 0.5741, accuracy - 0.7772, recall - 0.9565, AUC - 0.8381, F1 - 0.8111, precision - 0.704, training time - -11.0 seconds
2023-03-25 17:36:53,060 : [INFO]  Batch 2: Testing set : loss - 0.5902, accuracy - 0.7059, recall - 0.9118, AUC - 0.8131, F1 - 0.7561, precision - 0.6458
2023-03-25 17:36:53,075 : [INFO]  Batch 3 initialized 
2023-03-25 17:36:53,627 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:36:53,852 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 17:36:58,909 : [INFO]  ------------------------- Batch round 1, loss: 0.5424 -------------------------
2023-03-25 17:36:58,909 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 17:36:59,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:36:59,006 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 17:37:01,798 : [INFO]  ------------------------- Batch round 2, loss: 0.5441 -------------------------
2023-03-25 17:37:01,798 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:01,875 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:01,878 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 17:37:04,643 : [INFO]  ------------------------- Batch round 3, loss: 0.5425 -------------------------
2023-03-25 17:37:04,643 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:04,682 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:04,684 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 17:37:04,684 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-25 17:37:06,377 : [INFO]  Batch 3: Training set : loss - 0.5497, accuracy - 0.7609, recall - 0.8804, AUC - 0.842, F1 - 0.7864, precision - 0.7105, training time - -11.0 seconds
2023-03-25 17:37:06,377 : [INFO]  Batch 3: Testing set : loss - 0.5712, accuracy - 0.7157, recall - 0.9314, AUC - 0.8143, F1 - 0.7661, precision - 0.6507
2023-03-25 17:37:06,389 : [INFO]  Batch 4 initialized 
2023-03-25 17:37:06,997 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:07,208 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 17:37:12,427 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-25 17:37:12,427 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:12,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:12,454 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 17:37:15,249 : [INFO]  ------------------------- Batch round 2, loss: 0.5691 -------------------------
2023-03-25 17:37:15,249 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:15,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:15,256 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 17:37:17,940 : [INFO]  ------------------------- Batch round 3, loss: 0.5674 -------------------------
2023-03-25 17:37:17,940 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:17,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:17,948 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 17:37:17,948 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-25 17:37:19,659 : [INFO]  Batch 4: Training set : loss - 0.5856, accuracy - 0.6957, recall - 0.9022, AUC - 0.8615, F1 - 0.7477, precision - 0.6385, training time - -11.0 seconds
2023-03-25 17:37:19,659 : [INFO]  Batch 4: Testing set : loss - 0.5778, accuracy - 0.7206, recall - 0.951, AUC - 0.8601, F1 - 0.7729, precision - 0.651
2023-03-25 17:37:19,672 : [INFO]  Batch 5 initialized 
2023-03-25 17:37:20,231 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:20,466 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 17:37:25,657 : [INFO]  ------------------------- Batch round 1, loss: 0.548 -------------------------
2023-03-25 17:37:25,657 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:25,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:25,670 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 17:37:28,504 : [INFO]  ------------------------- Batch round 2, loss: 0.5474 -------------------------
2023-03-25 17:37:28,505 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:28,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:28,523 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 17:37:31,353 : [INFO]  ------------------------- Batch round 3, loss: 0.5437 -------------------------
2023-03-25 17:37:31,353 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:31,357 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:31,360 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 17:37:31,360 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-25 17:37:33,069 : [INFO]  Batch 5: Training set : loss - 0.5637, accuracy - 0.7391, recall - 0.9348, AUC - 0.8689, F1 - 0.7818, precision - 0.6719, training time - -11.0 seconds
2023-03-25 17:37:33,070 : [INFO]  Batch 5: Testing set : loss - 0.611, accuracy - 0.6569, recall - 0.8333, AUC - 0.7693, F1 - 0.7083, precision - 0.6159
2023-03-25 17:37:33,084 : [INFO]  Batch 6 initialized 
2023-03-25 17:37:33,642 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:33,871 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 17:37:38,945 : [INFO]  ------------------------- Batch round 1, loss: 0.562 -------------------------
2023-03-25 17:37:38,945 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:39,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:39,020 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 17:37:41,683 : [INFO]  ------------------------- Batch round 2, loss: 0.5582 -------------------------
2023-03-25 17:37:41,684 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:41,738 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:41,740 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 17:37:44,445 : [INFO]  ------------------------- Batch round 3, loss: 0.5684 -------------------------
2023-03-25 17:37:44,445 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:44,488 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:44,491 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 17:37:44,491 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-25 17:37:46,181 : [INFO]  Batch 6: Training set : loss - 0.5767, accuracy - 0.7065, recall - 0.9457, AUC - 0.8301, F1 - 0.7632, precision - 0.6397, training time - -11.0 seconds
2023-03-25 17:37:46,182 : [INFO]  Batch 6: Testing set : loss - 0.5619, accuracy - 0.7353, recall - 0.9216, AUC - 0.865, F1 - 0.7769, precision - 0.6714
2023-03-25 17:37:46,197 : [INFO]  Batch 7 initialized 
2023-03-25 17:37:46,748 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:37:46,986 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 17:37:52,214 : [INFO]  ------------------------- Batch round 1, loss: 0.5819 -------------------------
2023-03-25 17:37:52,214 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 17:37:52,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:52,247 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 17:37:55,113 : [INFO]  ------------------------- Batch round 2, loss: 0.583 -------------------------
2023-03-25 17:37:55,113 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 17:37:55,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:55,120 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 17:37:57,917 : [INFO]  ------------------------- Batch round 3, loss: 0.5805 -------------------------
2023-03-25 17:37:57,917 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 17:37:57,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:37:57,970 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 17:37:57,970 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-25 17:37:59,759 : [INFO]  Batch 7: Training set : loss - 0.608, accuracy - 0.6467, recall - 0.913, AUC - 0.801, F1 - 0.721, precision - 0.5957, training time - -11.0 seconds
2023-03-25 17:37:59,759 : [INFO]  Batch 7: Testing set : loss - 0.6294, accuracy - 0.5882, recall - 0.7647, AUC - 0.7637, F1 - 0.65, precision - 0.5652
2023-03-25 17:37:59,773 : [INFO]  Batch 8 initialized 
2023-03-25 17:38:00,343 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:00,570 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 17:38:05,749 : [INFO]  ------------------------- Batch round 1, loss: 0.5634 -------------------------
2023-03-25 17:38:05,749 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:05,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:05,781 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 17:38:08,621 : [INFO]  ------------------------- Batch round 2, loss: 0.5643 -------------------------
2023-03-25 17:38:08,621 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:08,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:08,633 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 17:38:11,600 : [INFO]  ------------------------- Batch round 3, loss: 0.5676 -------------------------
2023-03-25 17:38:11,600 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:11,605 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:11,608 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 17:38:11,608 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-25 17:38:13,379 : [INFO]  Batch 8: Training set : loss - 0.5795, accuracy - 0.6957, recall - 0.8913, AUC - 0.834, F1 - 0.7455, precision - 0.6406, training time - -11.0 seconds
2023-03-25 17:38:13,380 : [INFO]  Batch 8: Testing set : loss - 0.5797, accuracy - 0.701, recall - 0.8627, AUC - 0.8262, F1 - 0.7426, precision - 0.6519
2023-03-25 17:38:13,394 : [INFO]  Batch 9 initialized 
2023-03-25 17:38:13,967 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:14,217 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 17:38:19,491 : [INFO]  ------------------------- Batch round 1, loss: 0.5485 -------------------------
2023-03-25 17:38:19,491 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:19,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:19,704 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 17:38:22,554 : [INFO]  ------------------------- Batch round 2, loss: 0.5538 -------------------------
2023-03-25 17:38:22,555 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:22,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:22,747 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 17:38:25,625 : [INFO]  ------------------------- Batch round 3, loss: 0.5466 -------------------------
2023-03-25 17:38:25,625 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:25,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:25,776 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 17:38:25,777 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-25 17:38:27,544 : [INFO]  Batch 9: Training set : loss - 0.5663, accuracy - 0.7065, recall - 0.913, AUC - 0.891, F1 - 0.7568, precision - 0.6462, training time - -12.0 seconds
2023-03-25 17:38:27,545 : [INFO]  Batch 9: Testing set : loss - 0.5785, accuracy - 0.6961, recall - 0.8431, AUC - 0.8342, F1 - 0.735, precision - 0.6515
2023-03-25 17:38:27,560 : [INFO]  Batch 10 initialized 
2023-03-25 17:38:28,152 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:28,381 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 17:38:33,714 : [INFO]  ------------------------- Batch round 1, loss: 0.5495 -------------------------
2023-03-25 17:38:33,714 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:33,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:33,903 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 17:38:36,789 : [INFO]  ------------------------- Batch round 2, loss: 0.553 -------------------------
2023-03-25 17:38:36,789 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:36,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:36,852 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 17:38:39,883 : [INFO]  ------------------------- Batch round 3, loss: 0.5527 -------------------------
2023-03-25 17:38:39,883 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:39,888 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:39,890 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 17:38:39,890 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-25 17:38:41,673 : [INFO]  Batch 10: Training set : loss - 0.5601, accuracy - 0.7446, recall - 0.913, AUC - 0.8544, F1 - 0.7814, precision - 0.6829, training time - -12.0 seconds
2023-03-25 17:38:41,673 : [INFO]  Batch 10: Testing set : loss - 0.5744, accuracy - 0.6961, recall - 0.8824, AUC - 0.8556, F1 - 0.7438, precision - 0.6429
2023-03-25 17:38:41,683 : [INFO]  Batch 11 initialized 
2023-03-25 17:38:42,238 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:42,462 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 17:38:47,721 : [INFO]  ------------------------- Batch round 1, loss: 0.584 -------------------------
2023-03-25 17:38:47,722 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 17:38:47,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:47,785 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 17:38:50,626 : [INFO]  ------------------------- Batch round 2, loss: 0.5829 -------------------------
2023-03-25 17:38:50,626 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 17:38:50,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:50,713 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 17:38:53,519 : [INFO]  ------------------------- Batch round 3, loss: 0.5797 -------------------------
2023-03-25 17:38:53,519 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 17:38:53,543 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:38:53,546 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 17:38:53,546 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-25 17:38:55,292 : [INFO]  Batch 11: Training set : loss - 0.6088, accuracy - 0.6467, recall - 0.8696, AUC - 0.7966, F1 - 0.7111, precision - 0.6015, training time - -11.0 seconds
2023-03-25 17:38:55,292 : [INFO]  Batch 11: Testing set : loss - 0.5878, accuracy - 0.6569, recall - 0.8824, AUC - 0.8277, F1 - 0.72, precision - 0.6081
2023-03-25 17:38:55,300 : [INFO]  Batch 12 initialized 
2023-03-25 17:38:55,855 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:38:56,107 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 17:39:01,530 : [INFO]  ------------------------- Batch round 1, loss: 0.568 -------------------------
2023-03-25 17:39:01,530 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:01,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:01,539 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 17:39:04,492 : [INFO]  ------------------------- Batch round 2, loss: 0.5719 -------------------------
2023-03-25 17:39:04,492 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:04,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:04,500 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 17:39:07,444 : [INFO]  ------------------------- Batch round 3, loss: 0.5694 -------------------------
2023-03-25 17:39:07,444 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:07,675 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:07,677 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 17:39:07,677 : [INFO]  ################ Batch 12: final global model evalution after 3 rounds ################
2023-03-25 17:39:09,474 : [INFO]  Batch 12: Training set : loss - 0.6002, accuracy - 0.6793, recall - 0.7935, AUC - 0.7857, F1 - 0.7122, precision - 0.646, training time - -12.0 seconds
2023-03-25 17:39:09,474 : [INFO]  Batch 12: Testing set : loss - 0.6327, accuracy - 0.5882, recall - 0.7549, AUC - 0.7389, F1 - 0.6471, precision - 0.5662
2023-03-25 17:39:09,482 : [INFO]  Batch 13 initialized 
2023-03-25 17:39:10,059 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:10,314 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 17:39:15,564 : [INFO]  ------------------------- Batch round 1, loss: 0.601 -------------------------
2023-03-25 17:39:15,564 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:15,633 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:15,636 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 17:39:18,515 : [INFO]  ------------------------- Batch round 2, loss: 0.6003 -------------------------
2023-03-25 17:39:18,515 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:18,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:18,523 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 17:39:21,385 : [INFO]  ------------------------- Batch round 3, loss: 0.5986 -------------------------
2023-03-25 17:39:21,385 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:21,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:21,392 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 17:39:21,392 : [INFO]  ################ Batch 13: final global model evalution after 3 rounds ################
2023-03-25 17:39:23,122 : [INFO]  Batch 13: Training set : loss - 0.6238, accuracy - 0.6413, recall - 0.8261, AUC - 0.7345, F1 - 0.6972, precision - 0.6032, training time - -11.0 seconds
2023-03-25 17:39:23,122 : [INFO]  Batch 13: Testing set : loss - 0.6165, accuracy - 0.6225, recall - 0.8137, AUC - 0.7698, F1 - 0.6831, precision - 0.5887
2023-03-25 17:39:23,132 : [INFO]  Batch 14 initialized 
2023-03-25 17:39:23,776 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:24,041 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 17:39:29,225 : [INFO]  ------------------------- Batch round 1, loss: 0.5543 -------------------------
2023-03-25 17:39:29,225 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:29,249 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:29,252 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 17:39:32,019 : [INFO]  ------------------------- Batch round 2, loss: 0.5543 -------------------------
2023-03-25 17:39:32,019 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:32,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:32,029 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 17:39:34,825 : [INFO]  ------------------------- Batch round 3, loss: 0.5489 -------------------------
2023-03-25 17:39:34,826 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:34,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:34,833 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 17:39:34,833 : [INFO]  ################ Batch 14: final global model evalution after 3 rounds ################
2023-03-25 17:39:36,565 : [INFO]  Batch 14: Training set : loss - 0.5618, accuracy - 0.7446, recall - 0.9022, AUC - 0.8536, F1 - 0.7793, precision - 0.686, training time - -11.0 seconds
2023-03-25 17:39:36,565 : [INFO]  Batch 14: Testing set : loss - 0.5907, accuracy - 0.6618, recall - 0.8725, AUC - 0.828, F1 - 0.7206, precision - 0.6138
2023-03-25 17:39:36,574 : [INFO]  Batch 15 initialized 
2023-03-25 17:39:37,129 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:37,386 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 17:39:42,663 : [INFO]  ------------------------- Batch round 1, loss: 0.5708 -------------------------
2023-03-25 17:39:42,663 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:42,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:42,670 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 17:39:45,571 : [INFO]  ------------------------- Batch round 2, loss: 0.5787 -------------------------
2023-03-25 17:39:45,571 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:45,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:45,581 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 17:39:48,437 : [INFO]  ------------------------- Batch round 3, loss: 0.5726 -------------------------
2023-03-25 17:39:48,438 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 17:39:48,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:48,570 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 17:39:48,570 : [INFO]  ################ Batch 15: final global model evalution after 3 rounds ################
2023-03-25 17:39:50,346 : [INFO]  Batch 15: Training set : loss - 0.5971, accuracy - 0.6739, recall - 0.8696, AUC - 0.7997, F1 - 0.7273, precision - 0.625, training time - -11.0 seconds
2023-03-25 17:39:50,346 : [INFO]  Batch 15: Testing set : loss - 0.6226, accuracy - 0.6324, recall - 0.8333, AUC - 0.785, F1 - 0.6939, precision - 0.5944
2023-03-25 17:39:50,353 : [INFO]  Batch 16 initialized 
2023-03-25 17:39:50,916 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:39:51,173 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 17:39:56,228 : [INFO]  ------------------------- Batch round 1, loss: 0.5677 -------------------------
2023-03-25 17:39:56,228 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 17:39:56,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:56,345 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 17:39:59,067 : [INFO]  ------------------------- Batch round 2, loss: 0.5694 -------------------------
2023-03-25 17:39:59,067 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 17:39:59,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:39:59,221 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 17:40:02,048 : [INFO]  ------------------------- Batch round 3, loss: 0.5672 -------------------------
2023-03-25 17:40:02,048 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:02,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:02,144 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 17:40:02,144 : [INFO]  ################ Batch 16: final global model evalution after 3 rounds ################
2023-03-25 17:40:03,845 : [INFO]  Batch 16: Training set : loss - 0.5751, accuracy - 0.712, recall - 0.9348, AUC - 0.8511, F1 - 0.7644, precision - 0.6466, training time - -11.0 seconds
2023-03-25 17:40:03,845 : [INFO]  Batch 16: Testing set : loss - 0.554, accuracy - 0.7206, recall - 0.9412, AUC - 0.877, F1 - 0.7711, precision - 0.6531
2023-03-25 17:40:03,853 : [INFO]  Batch 17 initialized 
2023-03-25 17:40:04,438 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:04,694 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 17:40:09,791 : [INFO]  ------------------------- Batch round 1, loss: 0.5596 -------------------------
2023-03-25 17:40:09,791 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:09,914 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:09,917 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 17:40:12,643 : [INFO]  ------------------------- Batch round 2, loss: 0.5605 -------------------------
2023-03-25 17:40:12,643 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:12,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:12,718 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 17:40:15,423 : [INFO]  ------------------------- Batch round 3, loss: 0.5576 -------------------------
2023-03-25 17:40:15,423 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:15,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:15,460 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 17:40:15,460 : [INFO]  ################ Batch 17: final global model evalution after 3 rounds ################
2023-03-25 17:40:17,163 : [INFO]  Batch 17: Training set : loss - 0.5754, accuracy - 0.75, recall - 0.9565, AUC - 0.8552, F1 - 0.7928, precision - 0.6769, training time - -11.0 seconds
2023-03-25 17:40:17,163 : [INFO]  Batch 17: Testing set : loss - 0.5895, accuracy - 0.6618, recall - 0.8725, AUC - 0.8403, F1 - 0.7206, precision - 0.6138
2023-03-25 17:40:17,177 : [INFO]  Batch 18 initialized 
2023-03-25 17:40:17,736 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:18,008 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 17:40:23,091 : [INFO]  ------------------------- Batch round 1, loss: 0.5727 -------------------------
2023-03-25 17:40:23,091 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:23,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:23,353 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 17:40:26,267 : [INFO]  ------------------------- Batch round 2, loss: 0.5711 -------------------------
2023-03-25 17:40:26,267 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:26,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:26,304 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 17:40:28,980 : [INFO]  ------------------------- Batch round 3, loss: 0.5716 -------------------------
2023-03-25 17:40:28,980 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:29,193 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:29,196 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 17:40:29,196 : [INFO]  ################ Batch 18: final global model evalution after 3 rounds ################
2023-03-25 17:40:30,938 : [INFO]  Batch 18: Training set : loss - 0.5789, accuracy - 0.6957, recall - 0.9022, AUC - 0.8152, F1 - 0.7477, precision - 0.6385, training time - -11.0 seconds
2023-03-25 17:40:30,938 : [INFO]  Batch 18: Testing set : loss - 0.5834, accuracy - 0.7059, recall - 0.8824, AUC - 0.8273, F1 - 0.75, precision - 0.6522
2023-03-25 17:40:30,948 : [INFO]  Batch 19 initialized 
2023-03-25 17:40:31,531 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:31,794 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 17:40:37,050 : [INFO]  ------------------------- Batch round 1, loss: 0.5774 -------------------------
2023-03-25 17:40:37,050 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:37,151 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:37,154 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 17:40:39,959 : [INFO]  ------------------------- Batch round 2, loss: 0.5849 -------------------------
2023-03-25 17:40:39,959 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:40,017 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:40,021 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 17:40:42,868 : [INFO]  ------------------------- Batch round 3, loss: 0.5825 -------------------------
2023-03-25 17:40:42,868 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:42,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:42,923 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 17:40:42,923 : [INFO]  ################ Batch 19: final global model evalution after 3 rounds ################
2023-03-25 17:40:44,708 : [INFO]  Batch 19: Training set : loss - 0.5993, accuracy - 0.6739, recall - 0.8804, AUC - 0.7869, F1 - 0.7297, precision - 0.6231, training time - -11.0 seconds
2023-03-25 17:40:44,708 : [INFO]  Batch 19: Testing set : loss - 0.5853, accuracy - 0.701, recall - 0.9216, AUC - 0.8443, F1 - 0.755, precision - 0.6395
2023-03-25 17:40:44,723 : [INFO]  Batch 20 initialized 
2023-03-25 17:40:45,296 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:45,566 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 17:40:50,876 : [INFO]  ------------------------- Batch round 1, loss: 0.5541 -------------------------
2023-03-25 17:40:50,876 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 17:40:51,001 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:51,004 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 17:40:54,028 : [INFO]  ------------------------- Batch round 2, loss: 0.5586 -------------------------
2023-03-25 17:40:54,028 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 17:40:54,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:54,051 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 17:40:56,917 : [INFO]  ------------------------- Batch round 3, loss: 0.5527 -------------------------
2023-03-25 17:40:56,917 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 17:40:57,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:40:57,046 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 17:40:57,046 : [INFO]  ################ Batch 20: final global model evalution after 3 rounds ################
2023-03-25 17:40:58,849 : [INFO]  Batch 20: Training set : loss - 0.5698, accuracy - 0.7446, recall - 0.9674, AUC - 0.8681, F1 - 0.7911, precision - 0.6692, training time - -11.0 seconds
2023-03-25 17:40:58,849 : [INFO]  Batch 20: Testing set : loss - 0.5711, accuracy - 0.7304, recall - 0.9314, AUC - 0.8582, F1 - 0.7755, precision - 0.6643
2023-03-25 17:40:58,864 : [INFO]  Batch 21 initialized 
2023-03-25 17:40:59,429 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:40:59,699 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 17:41:04,943 : [INFO]  ------------------------- Batch round 1, loss: 0.6072 -------------------------
2023-03-25 17:41:04,943 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:05,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:05,021 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 17:41:07,822 : [INFO]  ------------------------- Batch round 2, loss: 0.6216 -------------------------
2023-03-25 17:41:07,822 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:07,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:07,936 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 17:41:10,747 : [INFO]  ------------------------- Batch round 3, loss: 0.6138 -------------------------
2023-03-25 17:41:10,747 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:10,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:10,781 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 17:41:10,781 : [INFO]  ################ Batch 21: final global model evalution after 3 rounds ################
2023-03-25 17:41:12,589 : [INFO]  Batch 21: Training set : loss - 0.6516, accuracy - 0.6359, recall - 0.9022, AUC - 0.6866, F1 - 0.7124, precision - 0.5887, training time - -11.0 seconds
2023-03-25 17:41:12,589 : [INFO]  Batch 21: Testing set : loss - 0.6022, accuracy - 0.701, recall - 0.9412, AUC - 0.8042, F1 - 0.7589, precision - 0.6358
2023-03-25 17:41:12,603 : [INFO]  Batch 22 initialized 
2023-03-25 17:41:13,163 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:13,434 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 17:41:18,949 : [INFO]  ------------------------- Batch round 1, loss: 0.6114 -------------------------
2023-03-25 17:41:18,949 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:18,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:18,957 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 17:41:21,939 : [INFO]  ------------------------- Batch round 2, loss: 0.62 -------------------------
2023-03-25 17:41:21,939 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:21,944 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:21,946 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 17:41:24,925 : [INFO]  ------------------------- Batch round 3, loss: 0.6128 -------------------------
2023-03-25 17:41:24,925 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:24,931 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:24,934 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 17:41:24,934 : [INFO]  ################ Batch 22: final global model evalution after 3 rounds ################
2023-03-25 17:41:26,738 : [INFO]  Batch 22: Training set : loss - 0.6337, accuracy - 0.6087, recall - 0.913, AUC - 0.7727, F1 - 0.7, precision - 0.5676, training time - -12.0 seconds
2023-03-25 17:41:26,739 : [INFO]  Batch 22: Testing set : loss - 0.6327, accuracy - 0.6127, recall - 0.8529, AUC - 0.7436, F1 - 0.6877, precision - 0.5762
2023-03-25 17:41:26,747 : [INFO]  Batch 23 initialized 
2023-03-25 17:41:27,298 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:27,577 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 17:41:33,146 : [INFO]  ------------------------- Batch round 1, loss: 0.5763 -------------------------
2023-03-25 17:41:33,146 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:33,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:33,155 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 17:41:36,156 : [INFO]  ------------------------- Batch round 2, loss: 0.576 -------------------------
2023-03-25 17:41:36,156 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:36,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:36,164 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 17:41:39,088 : [INFO]  ------------------------- Batch round 3, loss: 0.5696 -------------------------
2023-03-25 17:41:39,089 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:39,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:39,096 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 17:41:39,096 : [INFO]  ################ Batch 23: final global model evalution after 3 rounds ################
2023-03-25 17:41:40,975 : [INFO]  Batch 23: Training set : loss - 0.5864, accuracy - 0.6902, recall - 0.8913, AUC - 0.8433, F1 - 0.7421, precision - 0.6357, training time - -12.0 seconds
2023-03-25 17:41:40,976 : [INFO]  Batch 23: Testing set : loss - 0.5947, accuracy - 0.701, recall - 0.9608, AUC - 0.8648, F1 - 0.7626, precision - 0.6323
2023-03-25 17:41:40,983 : [INFO]  Batch 24 initialized 
2023-03-25 17:41:41,560 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:41,844 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 17:41:47,349 : [INFO]  ------------------------- Batch round 1, loss: 0.6078 -------------------------
2023-03-25 17:41:47,349 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 17:41:47,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:47,357 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 17:41:50,269 : [INFO]  ------------------------- Batch round 2, loss: 0.6081 -------------------------
2023-03-25 17:41:50,269 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 17:41:50,275 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:50,277 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 17:41:53,285 : [INFO]  ------------------------- Batch round 3, loss: 0.6034 -------------------------
2023-03-25 17:41:53,285 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 17:41:53,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:41:53,293 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 17:41:53,293 : [INFO]  ################ Batch 24: final global model evalution after 3 rounds ################
2023-03-25 17:41:55,061 : [INFO]  Batch 24: Training set : loss - 0.6263, accuracy - 0.663, recall - 0.8804, AUC - 0.7418, F1 - 0.7232, precision - 0.6136, training time - -11.0 seconds
2023-03-25 17:41:55,062 : [INFO]  Batch 24: Testing set : loss - 0.6109, accuracy - 0.6961, recall - 0.9118, AUC - 0.8024, F1 - 0.75, precision - 0.637
2023-03-25 17:41:55,075 : [INFO]  Batch 25 initialized 
2023-03-25 17:41:55,631 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:41:55,916 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 17:42:01,417 : [INFO]  ------------------------- Batch round 1, loss: 0.5748 -------------------------
2023-03-25 17:42:01,418 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:01,423 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:01,425 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 17:42:04,482 : [INFO]  ------------------------- Batch round 2, loss: 0.5778 -------------------------
2023-03-25 17:42:04,482 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:04,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:04,490 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 17:42:07,497 : [INFO]  ------------------------- Batch round 3, loss: 0.5754 -------------------------
2023-03-25 17:42:07,497 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:07,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:07,505 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 17:42:07,505 : [INFO]  ################ Batch 25: final global model evalution after 3 rounds ################
2023-03-25 17:42:09,308 : [INFO]  Batch 25: Training set : loss - 0.5999, accuracy - 0.663, recall - 0.8913, AUC - 0.8318, F1 - 0.7257, precision - 0.6119, training time - -12.0 seconds
2023-03-25 17:42:09,308 : [INFO]  Batch 25: Testing set : loss - 0.6205, accuracy - 0.6422, recall - 0.902, AUC - 0.8121, F1 - 0.716, precision - 0.5935
2023-03-25 17:42:09,317 : [INFO]  Batch 26 initialized 
2023-03-25 17:42:09,882 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:10,173 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 17:42:15,560 : [INFO]  ------------------------- Batch round 1, loss: 0.5861 -------------------------
2023-03-25 17:42:15,560 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:15,566 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:15,568 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 17:42:18,446 : [INFO]  ------------------------- Batch round 2, loss: 0.5845 -------------------------
2023-03-25 17:42:18,446 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:18,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:18,454 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 17:42:21,330 : [INFO]  ------------------------- Batch round 3, loss: 0.5906 -------------------------
2023-03-25 17:42:21,330 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:21,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:21,338 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 17:42:21,338 : [INFO]  ################ Batch 26: final global model evalution after 3 rounds ################
2023-03-25 17:42:23,157 : [INFO]  Batch 26: Training set : loss - 0.6148, accuracy - 0.6685, recall - 0.8478, AUC - 0.775, F1 - 0.7189, precision - 0.624, training time - -11.0 seconds
2023-03-25 17:42:23,158 : [INFO]  Batch 26: Testing set : loss - 0.6298, accuracy - 0.6373, recall - 0.9118, AUC - 0.7773, F1 - 0.7154, precision - 0.5886
2023-03-25 17:42:23,176 : [INFO]  Batch 27 initialized 
2023-03-25 17:42:23,751 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:24,029 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 17:42:29,224 : [INFO]  ------------------------- Batch round 1, loss: 0.6248 -------------------------
2023-03-25 17:42:29,225 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:29,232 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:29,235 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 17:42:31,985 : [INFO]  ------------------------- Batch round 2, loss: 0.6277 -------------------------
2023-03-25 17:42:31,985 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:32,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:32,022 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 17:42:34,975 : [INFO]  ------------------------- Batch round 3, loss: 0.6314 -------------------------
2023-03-25 17:42:34,975 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:34,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:34,983 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 17:42:34,983 : [INFO]  ################ Batch 27: final global model evalution after 3 rounds ################
2023-03-25 17:42:36,765 : [INFO]  Batch 27: Training set : loss - 0.6661, accuracy - 0.5761, recall - 0.8913, AUC - 0.7131, F1 - 0.6777, precision - 0.5467, training time - -11.0 seconds
2023-03-25 17:42:36,766 : [INFO]  Batch 27: Testing set : loss - 0.6472, accuracy - 0.5931, recall - 0.9412, AUC - 0.7834, F1 - 0.6982, precision - 0.5549
2023-03-25 17:42:36,780 : [INFO]  Batch 28 initialized 
2023-03-25 17:42:37,340 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:37,629 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 17:42:43,204 : [INFO]  ------------------------- Batch round 1, loss: 0.576 -------------------------
2023-03-25 17:42:43,205 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:43,409 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:43,413 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 17:42:46,350 : [INFO]  ------------------------- Batch round 2, loss: 0.5705 -------------------------
2023-03-25 17:42:46,350 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 17:42:46,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:46,402 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 17:42:49,213 : [INFO]  ------------------------- Batch round 3, loss: 0.5762 -------------------------
2023-03-25 17:42:49,213 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 17:42:49,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:49,263 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 17:42:49,263 : [INFO]  ################ Batch 28: final global model evalution after 3 rounds ################
2023-03-25 17:42:51,007 : [INFO]  Batch 28: Training set : loss - 0.5914, accuracy - 0.7337, recall - 0.8804, AUC - 0.8318, F1 - 0.7678, precision - 0.6807, training time - -12.0 seconds
2023-03-25 17:42:51,007 : [INFO]  Batch 28: Testing set : loss - 0.601, accuracy - 0.7108, recall - 0.951, AUC - 0.833, F1 - 0.7668, precision - 0.6424
2023-03-25 17:42:51,016 : [INFO]  Batch 29 initialized 
2023-03-25 17:42:51,577 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:42:51,876 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 17:42:57,254 : [INFO]  ------------------------- Batch round 1, loss: 0.5625 -------------------------
2023-03-25 17:42:57,254 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 17:42:57,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:42:57,482 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 17:43:00,247 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 17:43:00,247 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:00,438 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:00,442 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 17:43:03,143 : [INFO]  ------------------------- Batch round 3, loss: 0.5646 -------------------------
2023-03-25 17:43:03,143 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:03,425 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:03,428 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 17:43:03,428 : [INFO]  ################ Batch 29: final global model evalution after 3 rounds ################
2023-03-25 17:43:05,195 : [INFO]  Batch 29: Training set : loss - 0.5856, accuracy - 0.6793, recall - 0.9348, AUC - 0.8377, F1 - 0.7446, precision - 0.6187, training time - -12.0 seconds
2023-03-25 17:43:05,195 : [INFO]  Batch 29: Testing set : loss - 0.5753, accuracy - 0.7157, recall - 0.8922, AUC - 0.8357, F1 - 0.7583, precision - 0.6594
2023-03-25 17:43:05,203 : [INFO]  Batch 30 initialized 
2023-03-25 17:43:05,771 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:06,057 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 17:43:11,333 : [INFO]  ------------------------- Batch round 1, loss: 0.5757 -------------------------
2023-03-25 17:43:11,333 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:11,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:11,459 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 17:43:14,422 : [INFO]  ------------------------- Batch round 2, loss: 0.5702 -------------------------
2023-03-25 17:43:14,423 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:14,441 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:14,449 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 17:43:17,362 : [INFO]  ------------------------- Batch round 3, loss: 0.5687 -------------------------
2023-03-25 17:43:17,362 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:17,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:17,430 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 17:43:17,430 : [INFO]  ################ Batch 30: final global model evalution after 3 rounds ################
2023-03-25 17:43:19,244 : [INFO]  Batch 30: Training set : loss - 0.5894, accuracy - 0.6902, recall - 0.8696, AUC - 0.8092, F1 - 0.7373, precision - 0.64, training time - -11.0 seconds
2023-03-25 17:43:19,244 : [INFO]  Batch 30: Testing set : loss - 0.5701, accuracy - 0.6961, recall - 0.9216, AUC - 0.89, F1 - 0.752, precision - 0.6351
2023-03-25 17:43:19,270 : [INFO]  Batch 31 initialized 
2023-03-25 17:43:19,823 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:20,119 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 17:43:25,778 : [INFO]  ------------------------- Batch round 1, loss: 0.5969 -------------------------
2023-03-25 17:43:25,779 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:25,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:25,786 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 17:43:28,826 : [INFO]  ------------------------- Batch round 2, loss: 0.5967 -------------------------
2023-03-25 17:43:28,826 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:28,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:28,835 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 17:43:31,806 : [INFO]  ------------------------- Batch round 3, loss: 0.5971 -------------------------
2023-03-25 17:43:31,806 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:31,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:31,818 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 17:43:31,818 : [INFO]  ################ Batch 31: final global model evalution after 3 rounds ################
2023-03-25 17:43:33,664 : [INFO]  Batch 31: Training set : loss - 0.6112, accuracy - 0.6685, recall - 0.8478, AUC - 0.7811, F1 - 0.7189, precision - 0.624, training time - -12.0 seconds
2023-03-25 17:43:33,664 : [INFO]  Batch 31: Testing set : loss - 0.6049, accuracy - 0.6765, recall - 0.8627, AUC - 0.8187, F1 - 0.7273, precision - 0.6286
2023-03-25 17:43:33,677 : [INFO]  Batch 32 initialized 
2023-03-25 17:43:34,283 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:34,639 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 17:43:40,122 : [INFO]  ------------------------- Batch round 1, loss: 0.6042 -------------------------
2023-03-25 17:43:40,123 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:40,132 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:40,135 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 17:43:43,220 : [INFO]  ------------------------- Batch round 2, loss: 0.6011 -------------------------
2023-03-25 17:43:43,220 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:43,227 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:43,230 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 17:43:46,191 : [INFO]  ------------------------- Batch round 3, loss: 0.6054 -------------------------
2023-03-25 17:43:46,191 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:46,196 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:46,199 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 17:43:46,199 : [INFO]  ################ Batch 32: final global model evalution after 3 rounds ################
2023-03-25 17:43:48,051 : [INFO]  Batch 32: Training set : loss - 0.6227, accuracy - 0.6467, recall - 0.8804, AUC - 0.7914, F1 - 0.7137, precision - 0.6, training time - -12.0 seconds
2023-03-25 17:43:48,052 : [INFO]  Batch 32: Testing set : loss - 0.5876, accuracy - 0.7108, recall - 0.8725, AUC - 0.8197, F1 - 0.7511, precision - 0.6593
2023-03-25 17:43:48,059 : [INFO]  Batch 33 initialized 
2023-03-25 17:43:48,611 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:43:48,906 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 17:43:54,211 : [INFO]  ------------------------- Batch round 1, loss: 0.5877 -------------------------
2023-03-25 17:43:54,212 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 17:43:54,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:54,220 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 17:43:57,031 : [INFO]  ------------------------- Batch round 2, loss: 0.5908 -------------------------
2023-03-25 17:43:57,031 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 17:43:57,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:57,038 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 17:43:59,826 : [INFO]  ------------------------- Batch round 3, loss: 0.5895 -------------------------
2023-03-25 17:43:59,827 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 17:43:59,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:43:59,835 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 17:43:59,835 : [INFO]  ################ Batch 33: final global model evalution after 3 rounds ################
2023-03-25 17:44:01,589 : [INFO]  Batch 33: Training set : loss - 0.6115, accuracy - 0.6793, recall - 0.8587, AUC - 0.7352, F1 - 0.7281, precision - 0.632, training time - -11.0 seconds
2023-03-25 17:44:01,589 : [INFO]  Batch 33: Testing set : loss - 0.5969, accuracy - 0.701, recall - 0.8725, AUC - 0.7796, F1 - 0.7448, precision - 0.6496
2023-03-25 17:44:01,597 : [INFO]  Batch 34 initialized 
2023-03-25 17:44:02,165 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:02,462 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 17:44:07,719 : [INFO]  ------------------------- Batch round 1, loss: 0.5707 -------------------------
2023-03-25 17:44:07,719 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:07,762 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:07,765 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 17:44:10,487 : [INFO]  ------------------------- Batch round 2, loss: 0.5813 -------------------------
2023-03-25 17:44:10,487 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:10,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:10,553 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 17:44:13,456 : [INFO]  ------------------------- Batch round 3, loss: 0.5752 -------------------------
2023-03-25 17:44:13,457 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:13,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:13,554 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 17:44:13,554 : [INFO]  ################ Batch 34: final global model evalution after 3 rounds ################
2023-03-25 17:44:15,392 : [INFO]  Batch 34: Training set : loss - 0.593, accuracy - 0.6739, recall - 0.8804, AUC - 0.8248, F1 - 0.7297, precision - 0.6231, training time - -11.0 seconds
2023-03-25 17:44:15,393 : [INFO]  Batch 34: Testing set : loss - 0.566, accuracy - 0.6765, recall - 0.9314, AUC - 0.9111, F1 - 0.7422, precision - 0.6169
2023-03-25 17:44:15,406 : [INFO]  Batch 35 initialized 
2023-03-25 17:44:15,971 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:16,277 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 17:44:21,668 : [INFO]  ------------------------- Batch round 1, loss: 0.5576 -------------------------
2023-03-25 17:44:21,669 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:21,732 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:21,735 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 17:44:24,592 : [INFO]  ------------------------- Batch round 2, loss: 0.5535 -------------------------
2023-03-25 17:44:24,592 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:24,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:24,622 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 17:44:27,478 : [INFO]  ------------------------- Batch round 3, loss: 0.5548 -------------------------
2023-03-25 17:44:27,478 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:27,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:27,486 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 17:44:27,487 : [INFO]  ################ Batch 35: final global model evalution after 3 rounds ################
2023-03-25 17:44:29,275 : [INFO]  Batch 35: Training set : loss - 0.5669, accuracy - 0.7011, recall - 0.8696, AUC - 0.8611, F1 - 0.7442, precision - 0.6504, training time - -11.0 seconds
2023-03-25 17:44:29,275 : [INFO]  Batch 35: Testing set : loss - 0.6003, accuracy - 0.6569, recall - 0.7549, AUC - 0.767, F1 - 0.6875, precision - 0.6311
2023-03-25 17:44:29,292 : [INFO]  Batch 36 initialized 
2023-03-25 17:44:29,913 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:30,242 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 17:44:35,643 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 17:44:35,643 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:35,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:35,653 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 17:44:38,560 : [INFO]  ------------------------- Batch round 2, loss: 0.5612 -------------------------
2023-03-25 17:44:38,560 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:38,641 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:38,644 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 17:44:41,542 : [INFO]  ------------------------- Batch round 3, loss: 0.5647 -------------------------
2023-03-25 17:44:41,542 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:41,641 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:41,643 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 17:44:41,644 : [INFO]  ################ Batch 36: final global model evalution after 3 rounds ################
2023-03-25 17:44:43,539 : [INFO]  Batch 36: Training set : loss - 0.5796, accuracy - 0.6957, recall - 0.913, AUC - 0.8663, F1 - 0.75, precision - 0.6364, training time - -11.0 seconds
2023-03-25 17:44:43,539 : [INFO]  Batch 36: Testing set : loss - 0.6065, accuracy - 0.6569, recall - 0.8824, AUC - 0.8001, F1 - 0.72, precision - 0.6081
2023-03-25 17:44:43,549 : [INFO]  Batch 37 initialized 
2023-03-25 17:44:44,140 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:44,458 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 17:44:49,762 : [INFO]  ------------------------- Batch round 1, loss: 0.548 -------------------------
2023-03-25 17:44:49,762 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 17:44:49,855 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:49,858 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 17:44:52,638 : [INFO]  ------------------------- Batch round 2, loss: 0.5538 -------------------------
2023-03-25 17:44:52,638 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 17:44:52,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:52,735 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 17:44:55,505 : [INFO]  ------------------------- Batch round 3, loss: 0.547 -------------------------
2023-03-25 17:44:55,505 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 17:44:55,626 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:44:55,630 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 17:44:55,630 : [INFO]  ################ Batch 37: final global model evalution after 3 rounds ################
2023-03-25 17:44:57,388 : [INFO]  Batch 37: Training set : loss - 0.5581, accuracy - 0.7663, recall - 0.9565, AUC - 0.8995, F1 - 0.8037, precision - 0.6929, training time - -11.0 seconds
2023-03-25 17:44:57,389 : [INFO]  Batch 37: Testing set : loss - 0.5943, accuracy - 0.652, recall - 0.902, AUC - 0.8425, F1 - 0.7216, precision - 0.6013
2023-03-25 17:44:57,404 : [INFO]  Batch 38 initialized 
2023-03-25 17:44:57,971 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:44:58,276 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 17:45:03,721 : [INFO]  ------------------------- Batch round 1, loss: 0.5771 -------------------------
2023-03-25 17:45:03,721 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:03,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:03,732 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 17:45:06,687 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-25 17:45:06,687 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:06,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:06,816 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 17:45:09,781 : [INFO]  ------------------------- Batch round 3, loss: 0.5777 -------------------------
2023-03-25 17:45:09,782 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:09,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:09,791 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 17:45:09,791 : [INFO]  ################ Batch 38: final global model evalution after 3 rounds ################
2023-03-25 17:45:11,642 : [INFO]  Batch 38: Training set : loss - 0.5844, accuracy - 0.7065, recall - 0.9022, AUC - 0.8227, F1 - 0.7545, precision - 0.6484, training time - -12.0 seconds
2023-03-25 17:45:11,642 : [INFO]  Batch 38: Testing set : loss - 0.5907, accuracy - 0.6765, recall - 0.8922, AUC - 0.8455, F1 - 0.7339, precision - 0.6233
2023-03-25 17:45:11,650 : [INFO]  Batch 39 initialized 
2023-03-25 17:45:12,233 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:12,534 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 17:45:17,716 : [INFO]  ------------------------- Batch round 1, loss: 0.5532 -------------------------
2023-03-25 17:45:17,716 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:17,722 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:17,724 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 17:45:20,603 : [INFO]  ------------------------- Batch round 2, loss: 0.5509 -------------------------
2023-03-25 17:45:20,603 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:20,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:20,613 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 17:45:23,360 : [INFO]  ------------------------- Batch round 3, loss: 0.5528 -------------------------
2023-03-25 17:45:23,360 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:23,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:23,368 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 17:45:23,369 : [INFO]  ################ Batch 39: final global model evalution after 3 rounds ################
2023-03-25 17:45:25,137 : [INFO]  Batch 39: Training set : loss - 0.5683, accuracy - 0.7391, recall - 0.9674, AUC - 0.8859, F1 - 0.7876, precision - 0.6642, training time - -11.0 seconds
2023-03-25 17:45:25,138 : [INFO]  Batch 39: Testing set : loss - 0.5511, accuracy - 0.7892, recall - 0.9314, AUC - 0.866, F1 - 0.8155, precision - 0.7252
2023-03-25 17:45:25,159 : [INFO]  Batch 40 initialized 
2023-03-25 17:45:25,734 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:26,061 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 17:45:31,512 : [INFO]  ------------------------- Batch round 1, loss: 0.5824 -------------------------
2023-03-25 17:45:31,512 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:31,518 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:31,520 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 17:45:34,479 : [INFO]  ------------------------- Batch round 2, loss: 0.5779 -------------------------
2023-03-25 17:45:34,479 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:34,486 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:34,489 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 17:45:37,446 : [INFO]  ------------------------- Batch round 3, loss: 0.5791 -------------------------
2023-03-25 17:45:37,446 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:37,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:37,454 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 17:45:37,454 : [INFO]  ################ Batch 40: final global model evalution after 3 rounds ################
2023-03-25 17:45:39,211 : [INFO]  Batch 40: Training set : loss - 0.5958, accuracy - 0.6957, recall - 0.8804, AUC - 0.8248, F1 - 0.7431, precision - 0.6429, training time - -11.0 seconds
2023-03-25 17:45:39,211 : [INFO]  Batch 40: Testing set : loss - 0.6004, accuracy - 0.6765, recall - 0.8824, AUC - 0.8328, F1 - 0.7317, precision - 0.625
2023-03-25 17:45:39,221 : [INFO]  Batch 41 initialized 
2023-03-25 17:45:39,788 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:40,111 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 17:45:45,454 : [INFO]  ------------------------- Batch round 1, loss: 0.5709 -------------------------
2023-03-25 17:45:45,454 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:45,540 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:45,543 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 17:45:48,513 : [INFO]  ------------------------- Batch round 2, loss: 0.5697 -------------------------
2023-03-25 17:45:48,513 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 17:45:48,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:48,522 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 17:45:51,487 : [INFO]  ------------------------- Batch round 3, loss: 0.5698 -------------------------
2023-03-25 17:45:51,487 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 17:45:51,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:51,496 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 17:45:51,496 : [INFO]  ################ Batch 41: final global model evalution after 3 rounds ################
2023-03-25 17:45:53,299 : [INFO]  Batch 41: Training set : loss - 0.5841, accuracy - 0.6848, recall - 0.8913, AUC - 0.838, F1 - 0.7387, precision - 0.6308, training time - -11.0 seconds
2023-03-25 17:45:53,299 : [INFO]  Batch 41: Testing set : loss - 0.5885, accuracy - 0.6863, recall - 0.9118, AUC - 0.8398, F1 - 0.744, precision - 0.6284
2023-03-25 17:45:53,313 : [INFO]  Batch 42 initialized 
2023-03-25 17:45:53,874 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:45:54,188 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 17:45:59,585 : [INFO]  ------------------------- Batch round 1, loss: 0.5943 -------------------------
2023-03-25 17:45:59,585 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 17:45:59,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:45:59,813 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 17:46:02,640 : [INFO]  ------------------------- Batch round 2, loss: 0.601 -------------------------
2023-03-25 17:46:02,641 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:02,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:02,651 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 17:46:05,552 : [INFO]  ------------------------- Batch round 3, loss: 0.6065 -------------------------
2023-03-25 17:46:05,552 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:05,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:05,561 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 17:46:05,562 : [INFO]  ################ Batch 42: final global model evalution after 3 rounds ################
2023-03-25 17:46:07,340 : [INFO]  Batch 42: Training set : loss - 0.608, accuracy - 0.6739, recall - 0.8804, AUC - 0.7851, F1 - 0.7297, precision - 0.6231, training time - -11.0 seconds
2023-03-25 17:46:07,340 : [INFO]  Batch 42: Testing set : loss - 0.5848, accuracy - 0.6814, recall - 0.902, AUC - 0.8402, F1 - 0.739, precision - 0.6259
2023-03-25 17:46:07,354 : [INFO]  Batch 43 initialized 
2023-03-25 17:46:07,942 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:08,276 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 17:46:13,599 : [INFO]  ------------------------- Batch round 1, loss: 0.5606 -------------------------
2023-03-25 17:46:13,600 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:13,681 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:13,683 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 17:46:16,501 : [INFO]  ------------------------- Batch round 2, loss: 0.5647 -------------------------
2023-03-25 17:46:16,501 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:16,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:16,510 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 17:46:19,304 : [INFO]  ------------------------- Batch round 3, loss: 0.5652 -------------------------
2023-03-25 17:46:19,305 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:19,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:19,313 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 17:46:19,313 : [INFO]  ################ Batch 43: final global model evalution after 3 rounds ################
2023-03-25 17:46:21,021 : [INFO]  Batch 43: Training set : loss - 0.5781, accuracy - 0.7065, recall - 0.913, AUC - 0.8523, F1 - 0.7568, precision - 0.6462, training time - -11.0 seconds
2023-03-25 17:46:21,022 : [INFO]  Batch 43: Testing set : loss - 0.5638, accuracy - 0.7696, recall - 0.8922, AUC - 0.8378, F1 - 0.7948, precision - 0.7165
2023-03-25 17:46:21,044 : [INFO]  Batch 44 initialized 
2023-03-25 17:46:21,614 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:21,936 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 17:46:27,309 : [INFO]  ------------------------- Batch round 1, loss: 0.5505 -------------------------
2023-03-25 17:46:27,309 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:27,315 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:27,318 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 17:46:30,177 : [INFO]  ------------------------- Batch round 2, loss: 0.5493 -------------------------
2023-03-25 17:46:30,177 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:30,183 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:30,186 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 17:46:33,031 : [INFO]  ------------------------- Batch round 3, loss: 0.5489 -------------------------
2023-03-25 17:46:33,031 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:33,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:33,045 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 17:46:33,045 : [INFO]  ################ Batch 44: final global model evalution after 3 rounds ################
2023-03-25 17:46:34,754 : [INFO]  Batch 44: Training set : loss - 0.5634, accuracy - 0.7391, recall - 0.9565, AUC - 0.8908, F1 - 0.7857, precision - 0.6667, training time - -11.0 seconds
2023-03-25 17:46:34,754 : [INFO]  Batch 44: Testing set : loss - 0.57, accuracy - 0.6618, recall - 0.8922, AUC - 0.8626, F1 - 0.7251, precision - 0.6107
2023-03-25 17:46:34,764 : [INFO]  Batch 45 initialized 
2023-03-25 17:46:35,315 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:35,688 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 17:46:41,196 : [INFO]  ------------------------- Batch round 1, loss: 0.5678 -------------------------
2023-03-25 17:46:41,196 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:41,203 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:41,205 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 17:46:44,118 : [INFO]  ------------------------- Batch round 2, loss: 0.5651 -------------------------
2023-03-25 17:46:44,118 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:44,124 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:44,126 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 17:46:47,068 : [INFO]  ------------------------- Batch round 3, loss: 0.5749 -------------------------
2023-03-25 17:46:47,068 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 17:46:47,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:47,079 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 17:46:47,079 : [INFO]  ################ Batch 45: final global model evalution after 3 rounds ################
2023-03-25 17:46:48,885 : [INFO]  Batch 45: Training set : loss - 0.5932, accuracy - 0.6739, recall - 0.837, AUC - 0.8199, F1 - 0.7196, precision - 0.6311, training time - -11.0 seconds
2023-03-25 17:46:48,885 : [INFO]  Batch 45: Testing set : loss - 0.5688, accuracy - 0.7206, recall - 0.8627, AUC - 0.8501, F1 - 0.7554, precision - 0.6718
2023-03-25 17:46:48,894 : [INFO]  Batch 46 initialized 
2023-03-25 17:46:49,460 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:46:49,782 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 17:46:55,186 : [INFO]  ------------------------- Batch round 1, loss: 0.5733 -------------------------
2023-03-25 17:46:55,186 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 17:46:55,225 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:55,229 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 17:46:58,109 : [INFO]  ------------------------- Batch round 2, loss: 0.5777 -------------------------
2023-03-25 17:46:58,109 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 17:46:58,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:46:58,123 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 17:47:00,989 : [INFO]  ------------------------- Batch round 3, loss: 0.5711 -------------------------
2023-03-25 17:47:00,989 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:01,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:01,023 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 17:47:01,023 : [INFO]  ################ Batch 46: final global model evalution after 3 rounds ################
2023-03-25 17:47:02,882 : [INFO]  Batch 46: Training set : loss - 0.5891, accuracy - 0.6467, recall - 0.8804, AUC - 0.8325, F1 - 0.7137, precision - 0.6, training time - -11.0 seconds
2023-03-25 17:47:02,882 : [INFO]  Batch 46: Testing set : loss - 0.593, accuracy - 0.6961, recall - 0.8725, AUC - 0.8113, F1 - 0.7417, precision - 0.6449
2023-03-25 17:47:02,893 : [INFO]  Batch 47 initialized 
2023-03-25 17:47:03,474 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:03,813 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 17:47:09,107 : [INFO]  ------------------------- Batch round 1, loss: 0.5498 -------------------------
2023-03-25 17:47:09,107 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:09,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:09,194 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 17:47:12,020 : [INFO]  ------------------------- Batch round 2, loss: 0.5555 -------------------------
2023-03-25 17:47:12,020 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:12,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:12,077 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 17:47:14,844 : [INFO]  ------------------------- Batch round 3, loss: 0.5547 -------------------------
2023-03-25 17:47:14,844 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:14,916 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:14,919 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 17:47:14,919 : [INFO]  ################ Batch 47: final global model evalution after 3 rounds ################
2023-03-25 17:47:16,631 : [INFO]  Batch 47: Training set : loss - 0.5627, accuracy - 0.7826, recall - 0.9022, AUC - 0.851, F1 - 0.8058, precision - 0.7281, training time - -11.0 seconds
2023-03-25 17:47:16,631 : [INFO]  Batch 47: Testing set : loss - 0.6013, accuracy - 0.6471, recall - 0.8725, AUC - 0.8044, F1 - 0.712, precision - 0.6014
2023-03-25 17:47:16,647 : [INFO]  Batch 48 initialized 
2023-03-25 17:47:17,239 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:17,576 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 17:47:22,825 : [INFO]  ------------------------- Batch round 1, loss: 0.5508 -------------------------
2023-03-25 17:47:22,825 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:22,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:22,984 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 17:47:25,790 : [INFO]  ------------------------- Batch round 2, loss: 0.5528 -------------------------
2023-03-25 17:47:25,791 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:25,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:25,880 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 17:47:28,696 : [INFO]  ------------------------- Batch round 3, loss: 0.5554 -------------------------
2023-03-25 17:47:28,696 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:28,810 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:28,813 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 17:47:28,813 : [INFO]  ################ Batch 48: final global model evalution after 3 rounds ################
2023-03-25 17:47:30,551 : [INFO]  Batch 48: Training set : loss - 0.5641, accuracy - 0.7283, recall - 0.9022, AUC - 0.8475, F1 - 0.7685, precision - 0.6694, training time - -11.0 seconds
2023-03-25 17:47:30,551 : [INFO]  Batch 48: Testing set : loss - 0.5885, accuracy - 0.6765, recall - 0.8725, AUC - 0.846, F1 - 0.7295, precision - 0.6268
2023-03-25 17:47:30,565 : [INFO]  Batch 49 initialized 
2023-03-25 17:47:31,240 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:31,579 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 17:47:36,877 : [INFO]  ------------------------- Batch round 1, loss: 0.5561 -------------------------
2023-03-25 17:47:36,877 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:37,033 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:37,035 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 17:47:39,862 : [INFO]  ------------------------- Batch round 2, loss: 0.557 -------------------------
2023-03-25 17:47:39,862 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:39,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:39,997 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 17:47:42,853 : [INFO]  ------------------------- Batch round 3, loss: 0.5537 -------------------------
2023-03-25 17:47:42,853 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:42,992 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:42,995 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 17:47:42,995 : [INFO]  ################ Batch 49: final global model evalution after 3 rounds ################
2023-03-25 17:47:44,760 : [INFO]  Batch 49: Training set : loss - 0.5651, accuracy - 0.7446, recall - 0.9239, AUC - 0.8654, F1 - 0.7834, precision - 0.68, training time - -11.0 seconds
2023-03-25 17:47:44,760 : [INFO]  Batch 49: Testing set : loss - 0.5852, accuracy - 0.6716, recall - 0.8627, AUC - 0.8258, F1 - 0.7243, precision - 0.6241
2023-03-25 17:47:44,775 : [INFO]  Batch 50 initialized 
2023-03-25 17:47:45,360 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:45,700 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 17:47:51,133 : [INFO]  ------------------------- Batch round 1, loss: 0.5555 -------------------------
2023-03-25 17:47:51,133 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 17:47:51,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:51,265 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 17:47:54,142 : [INFO]  ------------------------- Batch round 2, loss: 0.5585 -------------------------
2023-03-25 17:47:54,143 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 17:47:54,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:54,270 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 17:47:57,038 : [INFO]  ------------------------- Batch round 3, loss: 0.5579 -------------------------
2023-03-25 17:47:57,038 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 17:47:57,093 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:47:57,096 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 17:47:57,096 : [INFO]  ################ Batch 50: final global model evalution after 3 rounds ################
2023-03-25 17:47:58,863 : [INFO]  Batch 50: Training set : loss - 0.5716, accuracy - 0.75, recall - 0.9348, AUC - 0.8563, F1 - 0.789, precision - 0.6825, training time - -11.0 seconds
2023-03-25 17:47:58,863 : [INFO]  Batch 50: Testing set : loss - 0.597, accuracy - 0.7157, recall - 0.951, AUC - 0.8298, F1 - 0.7698, precision - 0.6467
2023-03-25 17:47:58,887 : [INFO]  Batch 51 initialized 
2023-03-25 17:47:59,464 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:47:59,804 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 17:48:05,255 : [INFO]  ------------------------- Batch round 1, loss: 0.5774 -------------------------
2023-03-25 17:48:05,255 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:05,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:05,263 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 17:48:08,026 : [INFO]  ------------------------- Batch round 2, loss: 0.5783 -------------------------
2023-03-25 17:48:08,026 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:08,032 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:08,034 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 17:48:10,784 : [INFO]  ------------------------- Batch round 3, loss: 0.5814 -------------------------
2023-03-25 17:48:10,785 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:10,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:10,820 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 17:48:10,820 : [INFO]  ################ Batch 51: final global model evalution after 3 rounds ################
2023-03-25 17:48:12,580 : [INFO]  Batch 51: Training set : loss - 0.6114, accuracy - 0.6685, recall - 0.9239, AUC - 0.8202, F1 - 0.7359, precision - 0.6115, training time - -11.0 seconds
2023-03-25 17:48:12,580 : [INFO]  Batch 51: Testing set : loss - 0.6434, accuracy - 0.6078, recall - 0.8922, AUC - 0.7519, F1 - 0.6947, precision - 0.5688
2023-03-25 17:48:12,590 : [INFO]  Batch 52 initialized 
2023-03-25 17:48:13,159 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:13,502 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 17:48:18,716 : [INFO]  ------------------------- Batch round 1, loss: 0.5518 -------------------------
2023-03-25 17:48:18,716 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:18,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:18,830 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 17:48:21,557 : [INFO]  ------------------------- Batch round 2, loss: 0.5525 -------------------------
2023-03-25 17:48:21,557 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:21,694 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:21,697 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 17:48:24,494 : [INFO]  ------------------------- Batch round 3, loss: 0.5522 -------------------------
2023-03-25 17:48:24,494 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:24,606 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:24,609 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 17:48:24,609 : [INFO]  ################ Batch 52: final global model evalution after 3 rounds ################
2023-03-25 17:48:26,392 : [INFO]  Batch 52: Training set : loss - 0.5625, accuracy - 0.7772, recall - 0.9457, AUC - 0.8703, F1 - 0.8093, precision - 0.7073, training time - -11.0 seconds
2023-03-25 17:48:26,396 : [INFO]  Batch 52: Testing set : loss - 0.5612, accuracy - 0.7353, recall - 0.8922, AUC - 0.871, F1 - 0.7712, precision - 0.6791
2023-03-25 17:48:26,415 : [INFO]  Batch 53 initialized 
2023-03-25 17:48:26,975 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:27,310 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 17:48:32,886 : [INFO]  ------------------------- Batch round 1, loss: 0.5871 -------------------------
2023-03-25 17:48:32,886 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:32,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:32,895 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 17:48:35,843 : [INFO]  ------------------------- Batch round 2, loss: 0.5981 -------------------------
2023-03-25 17:48:35,843 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:35,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:35,853 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 17:48:38,641 : [INFO]  ------------------------- Batch round 3, loss: 0.5966 -------------------------
2023-03-25 17:48:38,642 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:38,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:38,651 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 17:48:38,651 : [INFO]  ################ Batch 53: final global model evalution after 3 rounds ################
2023-03-25 17:48:40,460 : [INFO]  Batch 53: Training set : loss - 0.6011, accuracy - 0.6848, recall - 0.837, AUC - 0.8087, F1 - 0.7264, precision - 0.6417, training time - -11.0 seconds
2023-03-25 17:48:40,460 : [INFO]  Batch 53: Testing set : loss - 0.5894, accuracy - 0.6863, recall - 0.8824, AUC - 0.8318, F1 - 0.7377, precision - 0.6338
2023-03-25 17:48:40,472 : [INFO]  Batch 54 initialized 
2023-03-25 17:48:41,044 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:41,402 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 17:48:46,710 : [INFO]  ------------------------- Batch round 1, loss: 0.6102 -------------------------
2023-03-25 17:48:46,710 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 17:48:46,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:46,718 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 17:48:49,577 : [INFO]  ------------------------- Batch round 2, loss: 0.6048 -------------------------
2023-03-25 17:48:49,577 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 17:48:49,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:49,586 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 17:48:52,445 : [INFO]  ------------------------- Batch round 3, loss: 0.6128 -------------------------
2023-03-25 17:48:52,445 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 17:48:52,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:48:52,454 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 17:48:52,454 : [INFO]  ################ Batch 54: final global model evalution after 3 rounds ################
2023-03-25 17:48:54,221 : [INFO]  Batch 54: Training set : loss - 0.626, accuracy - 0.663, recall - 0.8913, AUC - 0.7472, F1 - 0.7257, precision - 0.6119, training time - -11.0 seconds
2023-03-25 17:48:54,221 : [INFO]  Batch 54: Testing set : loss - 0.6104, accuracy - 0.6618, recall - 0.8235, AUC - 0.7777, F1 - 0.7089, precision - 0.6222
2023-03-25 17:48:54,229 : [INFO]  Batch 55 initialized 
2023-03-25 17:48:54,794 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:48:55,146 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 17:49:00,585 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-25 17:49:00,585 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:00,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:00,594 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 17:49:03,531 : [INFO]  ------------------------- Batch round 2, loss: 0.5633 -------------------------
2023-03-25 17:49:03,531 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:03,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:03,539 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 17:49:06,405 : [INFO]  ------------------------- Batch round 3, loss: 0.5584 -------------------------
2023-03-25 17:49:06,406 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:06,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:06,524 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 17:49:06,524 : [INFO]  ################ Batch 55: final global model evalution after 3 rounds ################
2023-03-25 17:49:08,301 : [INFO]  Batch 55: Training set : loss - 0.5823, accuracy - 0.7011, recall - 0.913, AUC - 0.8462, F1 - 0.7534, precision - 0.6412, training time - -11.0 seconds
2023-03-25 17:49:08,302 : [INFO]  Batch 55: Testing set : loss - 0.6152, accuracy - 0.6912, recall - 0.9314, AUC - 0.7983, F1 - 0.751, precision - 0.6291
2023-03-25 17:49:08,315 : [INFO]  Batch 56 initialized 
2023-03-25 17:49:08,882 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:09,241 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 17:49:14,580 : [INFO]  ------------------------- Batch round 1, loss: 0.5848 -------------------------
2023-03-25 17:49:14,580 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:14,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:14,687 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 17:49:17,575 : [INFO]  ------------------------- Batch round 2, loss: 0.5878 -------------------------
2023-03-25 17:49:17,575 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:17,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:17,710 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 17:49:20,493 : [INFO]  ------------------------- Batch round 3, loss: 0.5869 -------------------------
2023-03-25 17:49:20,493 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:20,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:20,569 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 17:49:20,570 : [INFO]  ################ Batch 56: final global model evalution after 3 rounds ################
2023-03-25 17:49:22,342 : [INFO]  Batch 56: Training set : loss - 0.6017, accuracy - 0.6739, recall - 0.913, AUC - 0.7984, F1 - 0.7368, precision - 0.6176, training time - -11.0 seconds
2023-03-25 17:49:22,342 : [INFO]  Batch 56: Testing set : loss - 0.5756, accuracy - 0.6912, recall - 0.8627, AUC - 0.8413, F1 - 0.7364, precision - 0.6423
2023-03-25 17:49:22,356 : [INFO]  Batch 57 initialized 
2023-03-25 17:49:22,933 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:23,276 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 17:49:28,468 : [INFO]  ------------------------- Batch round 1, loss: 0.5472 -------------------------
2023-03-25 17:49:28,468 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:28,729 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:28,732 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 17:49:31,628 : [INFO]  ------------------------- Batch round 2, loss: 0.5488 -------------------------
2023-03-25 17:49:31,628 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:31,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:31,781 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 17:49:34,462 : [INFO]  ------------------------- Batch round 3, loss: 0.548 -------------------------
2023-03-25 17:49:34,462 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:34,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:34,640 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 17:49:34,640 : [INFO]  ################ Batch 57: final global model evalution after 3 rounds ################
2023-03-25 17:49:36,380 : [INFO]  Batch 57: Training set : loss - 0.5578, accuracy - 0.7337, recall - 0.913, AUC - 0.8886, F1 - 0.7742, precision - 0.672, training time - -11.0 seconds
2023-03-25 17:49:36,381 : [INFO]  Batch 57: Testing set : loss - 0.5642, accuracy - 0.701, recall - 0.8824, AUC - 0.8872, F1 - 0.7469, precision - 0.6475
2023-03-25 17:49:36,396 : [INFO]  Batch 58 initialized 
2023-03-25 17:49:36,960 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:37,312 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 17:49:42,487 : [INFO]  ------------------------- Batch round 1, loss: 0.5501 -------------------------
2023-03-25 17:49:42,488 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:42,673 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:42,675 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 17:49:45,388 : [INFO]  ------------------------- Batch round 2, loss: 0.5547 -------------------------
2023-03-25 17:49:45,388 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:45,545 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:45,548 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 17:49:48,248 : [INFO]  ------------------------- Batch round 3, loss: 0.5518 -------------------------
2023-03-25 17:49:48,249 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 17:49:48,391 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:48,393 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 17:49:48,393 : [INFO]  ################ Batch 58: final global model evalution after 3 rounds ################
2023-03-25 17:49:50,213 : [INFO]  Batch 58: Training set : loss - 0.5653, accuracy - 0.7228, recall - 0.9239, AUC - 0.8585, F1 - 0.7692, precision - 0.6589, training time - -11.0 seconds
2023-03-25 17:49:50,213 : [INFO]  Batch 58: Testing set : loss - 0.582, accuracy - 0.6863, recall - 0.9412, AUC - 0.8653, F1 - 0.75, precision - 0.6234
2023-03-25 17:49:50,226 : [INFO]  Batch 59 initialized 
2023-03-25 17:49:50,804 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:49:51,161 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 17:49:56,567 : [INFO]  ------------------------- Batch round 1, loss: 0.5727 -------------------------
2023-03-25 17:49:56,567 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 17:49:56,574 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:56,576 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 17:49:59,298 : [INFO]  ------------------------- Batch round 2, loss: 0.5766 -------------------------
2023-03-25 17:49:59,298 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 17:49:59,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:49:59,347 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 17:50:02,045 : [INFO]  ------------------------- Batch round 3, loss: 0.5712 -------------------------
2023-03-25 17:50:02,045 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:02,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:02,125 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 17:50:02,125 : [INFO]  ################ Batch 59: final global model evalution after 3 rounds ################
2023-03-25 17:50:03,882 : [INFO]  Batch 59: Training set : loss - 0.599, accuracy - 0.6793, recall - 0.837, AUC - 0.8131, F1 - 0.723, precision - 0.6364, training time - -11.0 seconds
2023-03-25 17:50:03,883 : [INFO]  Batch 59: Testing set : loss - 0.581, accuracy - 0.6863, recall - 0.9118, AUC - 0.8703, F1 - 0.744, precision - 0.6284
2023-03-25 17:50:03,890 : [INFO]  Batch 60 initialized 
2023-03-25 17:50:04,457 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:04,814 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 17:50:10,087 : [INFO]  ------------------------- Batch round 1, loss: 0.5654 -------------------------
2023-03-25 17:50:10,088 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:10,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:10,170 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 17:50:13,028 : [INFO]  ------------------------- Batch round 2, loss: 0.5676 -------------------------
2023-03-25 17:50:13,028 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:13,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:13,041 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 17:50:15,840 : [INFO]  ------------------------- Batch round 3, loss: 0.5661 -------------------------
2023-03-25 17:50:15,840 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:15,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:15,928 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 17:50:15,928 : [INFO]  ################ Batch 60: final global model evalution after 3 rounds ################
2023-03-25 17:50:17,645 : [INFO]  Batch 60: Training set : loss - 0.5743, accuracy - 0.7337, recall - 0.9348, AUC - 0.8638, F1 - 0.7783, precision - 0.6667, training time - -11.0 seconds
2023-03-25 17:50:17,645 : [INFO]  Batch 60: Testing set : loss - 0.5723, accuracy - 0.701, recall - 0.8725, AUC - 0.8487, F1 - 0.7448, precision - 0.6496
2023-03-25 17:50:17,659 : [INFO]  Batch 61 initialized 
2023-03-25 17:50:18,211 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:18,556 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 17:50:23,948 : [INFO]  ------------------------- Batch round 1, loss: 0.6211 -------------------------
2023-03-25 17:50:23,949 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:24,007 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:24,010 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 17:50:26,952 : [INFO]  ------------------------- Batch round 2, loss: 0.6275 -------------------------
2023-03-25 17:50:26,952 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:26,959 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:26,961 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 17:50:29,812 : [INFO]  ------------------------- Batch round 3, loss: 0.617 -------------------------
2023-03-25 17:50:29,812 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:29,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:29,821 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 17:50:29,821 : [INFO]  ################ Batch 61: final global model evalution after 3 rounds ################
2023-03-25 17:50:31,590 : [INFO]  Batch 61: Training set : loss - 0.644, accuracy - 0.625, recall - 0.8804, AUC - 0.7453, F1 - 0.7013, precision - 0.5827, training time - -11.0 seconds
2023-03-25 17:50:31,591 : [INFO]  Batch 61: Testing set : loss - 0.5966, accuracy - 0.6618, recall - 0.8627, AUC - 0.8293, F1 - 0.7184, precision - 0.6154
2023-03-25 17:50:31,601 : [INFO]  Batch 62 initialized 
2023-03-25 17:50:32,175 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:32,530 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 17:50:37,905 : [INFO]  ------------------------- Batch round 1, loss: 0.5851 -------------------------
2023-03-25 17:50:37,905 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:37,987 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:37,990 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 17:50:40,944 : [INFO]  ------------------------- Batch round 2, loss: 0.5872 -------------------------
2023-03-25 17:50:40,944 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:40,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:40,953 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 17:50:43,870 : [INFO]  ------------------------- Batch round 3, loss: 0.5851 -------------------------
2023-03-25 17:50:43,870 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:43,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:43,966 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 17:50:43,966 : [INFO]  ################ Batch 62: final global model evalution after 3 rounds ################
2023-03-25 17:50:45,780 : [INFO]  Batch 62: Training set : loss - 0.6073, accuracy - 0.663, recall - 0.8152, AUC - 0.7764, F1 - 0.7075, precision - 0.625, training time - -11.0 seconds
2023-03-25 17:50:45,780 : [INFO]  Batch 62: Testing set : loss - 0.618, accuracy - 0.6569, recall - 0.7647, AUC - 0.7455, F1 - 0.6903, precision - 0.629
2023-03-25 17:50:45,796 : [INFO]  Batch 63 initialized 
2023-03-25 17:50:46,363 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:50:46,720 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 17:50:51,980 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-25 17:50:51,980 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 17:50:51,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:51,989 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 17:50:54,929 : [INFO]  ------------------------- Batch round 2, loss: 0.5587 -------------------------
2023-03-25 17:50:54,929 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 17:50:54,937 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:54,939 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 17:50:57,922 : [INFO]  ------------------------- Batch round 3, loss: 0.5558 -------------------------
2023-03-25 17:50:57,923 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 17:50:57,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:50:57,931 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 17:50:57,931 : [INFO]  ################ Batch 63: final global model evalution after 3 rounds ################
2023-03-25 17:50:59,650 : [INFO]  Batch 63: Training set : loss - 0.5655, accuracy - 0.7609, recall - 0.9022, AUC - 0.8468, F1 - 0.7905, precision - 0.7034, training time - -11.0 seconds
2023-03-25 17:50:59,650 : [INFO]  Batch 63: Testing set : loss - 0.5847, accuracy - 0.6814, recall - 0.8627, AUC - 0.8036, F1 - 0.7303, precision - 0.6331
2023-03-25 17:50:59,658 : [INFO]  Batch 64 initialized 
2023-03-25 17:51:00,226 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:00,588 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 17:51:05,715 : [INFO]  ------------------------- Batch round 1, loss: 0.5469 -------------------------
2023-03-25 17:51:05,715 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:05,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:05,853 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 17:51:08,689 : [INFO]  ------------------------- Batch round 2, loss: 0.5488 -------------------------
2023-03-25 17:51:08,689 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:08,807 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:08,810 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 17:51:11,615 : [INFO]  ------------------------- Batch round 3, loss: 0.5458 -------------------------
2023-03-25 17:51:11,615 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:11,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:11,768 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 17:51:11,769 : [INFO]  ################ Batch 64: final global model evalution after 3 rounds ################
2023-03-25 17:51:13,598 : [INFO]  Batch 64: Training set : loss - 0.5591, accuracy - 0.7337, recall - 0.9022, AUC - 0.8712, F1 - 0.7721, precision - 0.6748, training time - -11.0 seconds
2023-03-25 17:51:13,598 : [INFO]  Batch 64: Testing set : loss - 0.5761, accuracy - 0.7059, recall - 0.9216, AUC - 0.8594, F1 - 0.7581, precision - 0.6438
2023-03-25 17:51:13,610 : [INFO]  Batch 65 initialized 
2023-03-25 17:51:14,189 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:14,552 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 17:51:19,953 : [INFO]  ------------------------- Batch round 1, loss: 0.5807 -------------------------
2023-03-25 17:51:19,953 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:19,961 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:19,965 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 17:51:23,074 : [INFO]  ------------------------- Batch round 2, loss: 0.5772 -------------------------
2023-03-25 17:51:23,074 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:23,096 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:23,104 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 17:51:26,116 : [INFO]  ------------------------- Batch round 3, loss: 0.582 -------------------------
2023-03-25 17:51:26,116 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:26,123 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:26,126 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 17:51:26,126 : [INFO]  ################ Batch 65: final global model evalution after 3 rounds ################
2023-03-25 17:51:27,863 : [INFO]  Batch 65: Training set : loss - 0.5932, accuracy - 0.6413, recall - 0.8913, AUC - 0.8244, F1 - 0.713, precision - 0.5942, training time - -12.0 seconds
2023-03-25 17:51:27,863 : [INFO]  Batch 65: Testing set : loss - 0.5846, accuracy - 0.6618, recall - 0.902, AUC - 0.8537, F1 - 0.7273, precision - 0.6093
2023-03-25 17:51:27,878 : [INFO]  Batch 66 initialized 
2023-03-25 17:51:28,448 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:28,824 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 17:51:34,131 : [INFO]  ------------------------- Batch round 1, loss: 0.5417 -------------------------
2023-03-25 17:51:34,131 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:34,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:34,243 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 17:51:37,049 : [INFO]  ------------------------- Batch round 2, loss: 0.5467 -------------------------
2023-03-25 17:51:37,049 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:37,125 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:37,129 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 17:51:39,866 : [INFO]  ------------------------- Batch round 3, loss: 0.5431 -------------------------
2023-03-25 17:51:39,866 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:39,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:39,961 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 17:51:39,961 : [INFO]  ################ Batch 66: final global model evalution after 3 rounds ################
2023-03-25 17:51:41,680 : [INFO]  Batch 66: Training set : loss - 0.5583, accuracy - 0.7717, recall - 0.9565, AUC - 0.8669, F1 - 0.8073, precision - 0.6984, training time - -11.0 seconds
2023-03-25 17:51:41,680 : [INFO]  Batch 66: Testing set : loss - 0.5849, accuracy - 0.701, recall - 0.9314, AUC - 0.8627, F1 - 0.757, precision - 0.6376
2023-03-25 17:51:41,696 : [INFO]  Batch 67 initialized 
2023-03-25 17:51:42,263 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:42,637 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 17:51:47,952 : [INFO]  ------------------------- Batch round 1, loss: 0.5736 -------------------------
2023-03-25 17:51:47,952 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 17:51:48,234 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:48,238 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 17:51:51,212 : [INFO]  ------------------------- Batch round 2, loss: 0.5738 -------------------------
2023-03-25 17:51:51,212 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 17:51:51,414 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:51,417 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 17:51:54,226 : [INFO]  ------------------------- Batch round 3, loss: 0.5677 -------------------------
2023-03-25 17:51:54,226 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 17:51:54,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:51:54,499 : [INFO]  Batch number 67 model fetched from the server
2023-03-25 17:51:54,499 : [INFO]  ################ Batch 67: final global model evalution after 3 rounds ################
2023-03-25 17:51:56,401 : [INFO]  Batch 67: Training set : loss - 0.591, accuracy - 0.6902, recall - 0.9022, AUC - 0.8293, F1 - 0.7444, precision - 0.6336, training time - -12.0 seconds
2023-03-25 17:51:56,401 : [INFO]  Batch 67: Testing set : loss - 0.5732, accuracy - 0.7059, recall - 0.9118, AUC - 0.8403, F1 - 0.7561, precision - 0.6458
2023-03-25 17:51:56,416 : [INFO]  Batch 68 initialized 
2023-03-25 17:51:57,013 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:51:57,381 : [INFO]  ------------------------- Batch 68 training: round 1 -------------------------
2023-03-25 17:52:02,752 : [INFO]  ------------------------- Batch round 1, loss: 0.5597 -------------------------
2023-03-25 17:52:02,753 : [INFO]  ------------------------- Batch 68, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:02,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:02,805 : [INFO]  ------------------------- Batch 68 training: round 2 -------------------------
2023-03-25 17:52:05,570 : [INFO]  ------------------------- Batch round 2, loss: 0.5549 -------------------------
2023-03-25 17:52:05,571 : [INFO]  ------------------------- Batch 68, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:05,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:05,603 : [INFO]  ------------------------- Batch 68 training: round 3 -------------------------
2023-03-25 17:52:08,412 : [INFO]  ------------------------- Batch round 3, loss: 0.5598 -------------------------
2023-03-25 17:52:08,412 : [INFO]  ------------------------- Batch 68, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:08,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:08,422 : [INFO]  Batch number 68 model fetched from the server
2023-03-25 17:52:08,423 : [INFO]  ################ Batch 68: final global model evalution after 3 rounds ################
2023-03-25 17:52:10,194 : [INFO]  Batch 68: Training set : loss - 0.5775, accuracy - 0.7011, recall - 0.9348, AUC - 0.8589, F1 - 0.7577, precision - 0.637, training time - -11.0 seconds
2023-03-25 17:52:10,194 : [INFO]  Batch 68: Testing set : loss - 0.5897, accuracy - 0.6814, recall - 0.8627, AUC - 0.836, F1 - 0.7303, precision - 0.6331
2023-03-25 17:52:10,206 : [INFO]  Batch 69 initialized 
2023-03-25 17:52:10,762 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:11,162 : [INFO]  ------------------------- Batch 69 training: round 1 -------------------------
2023-03-25 17:52:16,512 : [INFO]  ------------------------- Batch round 1, loss: 0.5751 -------------------------
2023-03-25 17:52:16,512 : [INFO]  ------------------------- Batch 69, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:16,575 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:16,577 : [INFO]  ------------------------- Batch 69 training: round 2 -------------------------
2023-03-25 17:52:19,317 : [INFO]  ------------------------- Batch round 2, loss: 0.5822 -------------------------
2023-03-25 17:52:19,317 : [INFO]  ------------------------- Batch 69, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:19,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:19,414 : [INFO]  ------------------------- Batch 69 training: round 3 -------------------------
2023-03-25 17:52:22,220 : [INFO]  ------------------------- Batch round 3, loss: 0.5768 -------------------------
2023-03-25 17:52:22,220 : [INFO]  ------------------------- Batch 69, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:22,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:22,313 : [INFO]  Batch number 69 model fetched from the server
2023-03-25 17:52:22,313 : [INFO]  ################ Batch 69: final global model evalution after 3 rounds ################
2023-03-25 17:52:24,089 : [INFO]  Batch 69: Training set : loss - 0.6069, accuracy - 0.6196, recall - 0.8696, AUC - 0.8295, F1 - 0.6957, precision - 0.5797, training time - -11.0 seconds
2023-03-25 17:52:24,089 : [INFO]  Batch 69: Testing set : loss - 0.6046, accuracy - 0.6471, recall - 0.8824, AUC - 0.7974, F1 - 0.7143, precision - 0.6
2023-03-25 17:52:24,099 : [INFO]  Batch 70 initialized 
2023-03-25 17:52:24,684 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:25,055 : [INFO]  ------------------------- Batch 70 training: round 1 -------------------------
2023-03-25 17:52:30,421 : [INFO]  ------------------------- Batch round 1, loss: 0.5608 -------------------------
2023-03-25 17:52:30,422 : [INFO]  ------------------------- Batch 70, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:30,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:30,527 : [INFO]  ------------------------- Batch 70 training: round 2 -------------------------
2023-03-25 17:52:33,338 : [INFO]  ------------------------- Batch round 2, loss: 0.5616 -------------------------
2023-03-25 17:52:33,338 : [INFO]  ------------------------- Batch 70, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:33,461 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:33,464 : [INFO]  ------------------------- Batch 70 training: round 3 -------------------------
2023-03-25 17:52:36,220 : [INFO]  ------------------------- Batch round 3, loss: 0.5571 -------------------------
2023-03-25 17:52:36,221 : [INFO]  ------------------------- Batch 70, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:36,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:36,357 : [INFO]  Batch number 70 model fetched from the server
2023-03-25 17:52:36,357 : [INFO]  ################ Batch 70: final global model evalution after 3 rounds ################
2023-03-25 17:52:38,166 : [INFO]  Batch 70: Training set : loss - 0.5757, accuracy - 0.7283, recall - 0.9674, AUC - 0.8578, F1 - 0.7807, precision - 0.6544, training time - -11.0 seconds
2023-03-25 17:52:38,166 : [INFO]  Batch 70: Testing set : loss - 0.6082, accuracy - 0.6667, recall - 0.902, AUC - 0.7911, F1 - 0.7302, precision - 0.6133
2023-03-25 17:52:38,180 : [INFO]  Batch 71 initialized 
2023-03-25 17:52:38,763 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:39,132 : [INFO]  ------------------------- Batch 71 training: round 1 -------------------------
2023-03-25 17:52:44,494 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-25 17:52:44,494 : [INFO]  ------------------------- Batch 71, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:44,556 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:44,558 : [INFO]  ------------------------- Batch 71 training: round 2 -------------------------
2023-03-25 17:52:47,441 : [INFO]  ------------------------- Batch round 2, loss: 0.5557 -------------------------
2023-03-25 17:52:47,442 : [INFO]  ------------------------- Batch 71, round 2: Sent local model to the server -------------------------
2023-03-25 17:52:47,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:47,451 : [INFO]  ------------------------- Batch 71 training: round 3 -------------------------
2023-03-25 17:52:50,246 : [INFO]  ------------------------- Batch round 3, loss: 0.5602 -------------------------
2023-03-25 17:52:50,247 : [INFO]  ------------------------- Batch 71, round 3: Sent local model to the server -------------------------
2023-03-25 17:52:50,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:50,256 : [INFO]  Batch number 71 model fetched from the server
2023-03-25 17:52:50,256 : [INFO]  ################ Batch 71: final global model evalution after 3 rounds ################
2023-03-25 17:52:52,005 : [INFO]  Batch 71: Training set : loss - 0.5697, accuracy - 0.7228, recall - 0.8261, AUC - 0.8242, F1 - 0.7488, precision - 0.6847, training time - -11.0 seconds
2023-03-25 17:52:52,005 : [INFO]  Batch 71: Testing set : loss - 0.6177, accuracy - 0.6422, recall - 0.7843, AUC - 0.7706, F1 - 0.6867, precision - 0.6107
2023-03-25 17:52:52,012 : [INFO]  Batch 72 initialized 
2023-03-25 17:52:52,559 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:52:52,938 : [INFO]  ------------------------- Batch 72 training: round 1 -------------------------
2023-03-25 17:52:58,243 : [INFO]  ------------------------- Batch round 1, loss: 0.5614 -------------------------
2023-03-25 17:52:58,243 : [INFO]  ------------------------- Batch 72, round 1: Sent local model to the server -------------------------
2023-03-25 17:52:58,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:52:58,257 : [INFO]  ------------------------- Batch 72 training: round 2 -------------------------
2023-03-25 17:53:01,110 : [INFO]  ------------------------- Batch round 2, loss: 0.5601 -------------------------
2023-03-25 17:53:01,110 : [INFO]  ------------------------- Batch 72, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:01,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:01,119 : [INFO]  ------------------------- Batch 72 training: round 3 -------------------------
2023-03-25 17:53:04,013 : [INFO]  ------------------------- Batch round 3, loss: 0.5599 -------------------------
2023-03-25 17:53:04,013 : [INFO]  ------------------------- Batch 72, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:04,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:04,023 : [INFO]  Batch number 72 model fetched from the server
2023-03-25 17:53:04,023 : [INFO]  ################ Batch 72: final global model evalution after 3 rounds ################
2023-03-25 17:53:05,810 : [INFO]  Batch 72: Training set : loss - 0.5722, accuracy - 0.7174, recall - 0.9239, AUC - 0.8489, F1 - 0.7658, precision - 0.6538, training time - -11.0 seconds
2023-03-25 17:53:05,810 : [INFO]  Batch 72: Testing set : loss - 0.5945, accuracy - 0.7157, recall - 0.8922, AUC - 0.8403, F1 - 0.7583, precision - 0.6594
2023-03-25 17:53:05,820 : [INFO]  Batch 73 initialized 
2023-03-25 17:53:06,388 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:06,765 : [INFO]  ------------------------- Batch 73 training: round 1 -------------------------
2023-03-25 17:53:12,322 : [INFO]  ------------------------- Batch round 1, loss: 0.5655 -------------------------
2023-03-25 17:53:12,322 : [INFO]  ------------------------- Batch 73, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:12,330 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:12,332 : [INFO]  ------------------------- Batch 73 training: round 2 -------------------------
2023-03-25 17:53:15,253 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 17:53:15,253 : [INFO]  ------------------------- Batch 73, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:15,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:15,298 : [INFO]  ------------------------- Batch 73 training: round 3 -------------------------
2023-03-25 17:53:18,180 : [INFO]  ------------------------- Batch round 3, loss: 0.5717 -------------------------
2023-03-25 17:53:18,181 : [INFO]  ------------------------- Batch 73, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:18,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:18,192 : [INFO]  Batch number 73 model fetched from the server
2023-03-25 17:53:18,192 : [INFO]  ################ Batch 73: final global model evalution after 3 rounds ################
2023-03-25 17:53:19,993 : [INFO]  Batch 73: Training set : loss - 0.5798, accuracy - 0.712, recall - 0.9565, AUC - 0.8504, F1 - 0.7686, precision - 0.6423, training time - -11.0 seconds
2023-03-25 17:53:19,993 : [INFO]  Batch 73: Testing set : loss - 0.5965, accuracy - 0.6765, recall - 0.9314, AUC - 0.8208, F1 - 0.7422, precision - 0.6169
2023-03-25 17:53:20,015 : [INFO]  Batch 74 initialized 
2023-03-25 17:53:20,612 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:21,007 : [INFO]  ------------------------- Batch 74 training: round 1 -------------------------
2023-03-25 17:53:26,476 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-25 17:53:26,477 : [INFO]  ------------------------- Batch 74, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:26,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:26,496 : [INFO]  ------------------------- Batch 74 training: round 2 -------------------------
2023-03-25 17:53:29,253 : [INFO]  ------------------------- Batch round 2, loss: 0.5616 -------------------------
2023-03-25 17:53:29,253 : [INFO]  ------------------------- Batch 74, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:29,260 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:29,263 : [INFO]  ------------------------- Batch 74 training: round 3 -------------------------
2023-03-25 17:53:32,071 : [INFO]  ------------------------- Batch round 3, loss: 0.5593 -------------------------
2023-03-25 17:53:32,072 : [INFO]  ------------------------- Batch 74, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:32,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:32,118 : [INFO]  Batch number 74 model fetched from the server
2023-03-25 17:53:32,118 : [INFO]  ################ Batch 74: final global model evalution after 3 rounds ################
2023-03-25 17:53:33,906 : [INFO]  Batch 74: Training set : loss - 0.5722, accuracy - 0.7283, recall - 0.9022, AUC - 0.8442, F1 - 0.7685, precision - 0.6694, training time - -11.0 seconds
2023-03-25 17:53:33,906 : [INFO]  Batch 74: Testing set : loss - 0.5649, accuracy - 0.7157, recall - 0.9314, AUC - 0.8817, F1 - 0.7661, precision - 0.6507
2023-03-25 17:53:33,915 : [INFO]  Batch 75 initialized 
2023-03-25 17:53:34,493 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:34,888 : [INFO]  ------------------------- Batch 75 training: round 1 -------------------------
2023-03-25 17:53:40,205 : [INFO]  ------------------------- Batch round 1, loss: 0.5464 -------------------------
2023-03-25 17:53:40,205 : [INFO]  ------------------------- Batch 75, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:40,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:40,368 : [INFO]  ------------------------- Batch 75 training: round 2 -------------------------
2023-03-25 17:53:43,203 : [INFO]  ------------------------- Batch round 2, loss: 0.5481 -------------------------
2023-03-25 17:53:43,203 : [INFO]  ------------------------- Batch 75, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:43,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:43,306 : [INFO]  ------------------------- Batch 75 training: round 3 -------------------------
2023-03-25 17:53:46,047 : [INFO]  ------------------------- Batch round 3, loss: 0.5515 -------------------------
2023-03-25 17:53:46,048 : [INFO]  ------------------------- Batch 75, round 3: Sent local model to the server -------------------------
2023-03-25 17:53:46,232 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:46,235 : [INFO]  Batch number 75 model fetched from the server
2023-03-25 17:53:46,236 : [INFO]  ################ Batch 75: final global model evalution after 3 rounds ################
2023-03-25 17:53:48,096 : [INFO]  Batch 75: Training set : loss - 0.5621, accuracy - 0.7391, recall - 0.913, AUC - 0.8584, F1 - 0.7778, precision - 0.6774, training time - -11.0 seconds
2023-03-25 17:53:48,096 : [INFO]  Batch 75: Testing set : loss - 0.5514, accuracy - 0.75, recall - 0.8824, AUC - 0.8827, F1 - 0.7792, precision - 0.6977
2023-03-25 17:53:48,104 : [INFO]  Batch 76 initialized 
2023-03-25 17:53:48,661 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:53:49,055 : [INFO]  ------------------------- Batch 76 training: round 1 -------------------------
2023-03-25 17:53:54,323 : [INFO]  ------------------------- Batch round 1, loss: 0.5666 -------------------------
2023-03-25 17:53:54,323 : [INFO]  ------------------------- Batch 76, round 1: Sent local model to the server -------------------------
2023-03-25 17:53:54,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:54,460 : [INFO]  ------------------------- Batch 76 training: round 2 -------------------------
2023-03-25 17:53:57,248 : [INFO]  ------------------------- Batch round 2, loss: 0.5666 -------------------------
2023-03-25 17:53:57,248 : [INFO]  ------------------------- Batch 76, round 2: Sent local model to the server -------------------------
2023-03-25 17:53:57,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:53:57,402 : [INFO]  ------------------------- Batch 76 training: round 3 -------------------------
2023-03-25 17:54:00,192 : [INFO]  ------------------------- Batch round 3, loss: 0.5665 -------------------------
2023-03-25 17:54:00,192 : [INFO]  ------------------------- Batch 76, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:00,472 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:00,474 : [INFO]  Batch number 76 model fetched from the server
2023-03-25 17:54:00,475 : [INFO]  ################ Batch 76: final global model evalution after 3 rounds ################
2023-03-25 17:54:02,227 : [INFO]  Batch 76: Training set : loss - 0.5807, accuracy - 0.6848, recall - 0.837, AUC - 0.813, F1 - 0.7264, precision - 0.6417, training time - -11.0 seconds
2023-03-25 17:54:02,228 : [INFO]  Batch 76: Testing set : loss - 0.5859, accuracy - 0.6765, recall - 0.8529, AUC - 0.8446, F1 - 0.725, precision - 0.6304
2023-03-25 17:54:02,240 : [INFO]  Batch 77 initialized 
2023-03-25 17:54:02,800 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:03,185 : [INFO]  ------------------------- Batch 77 training: round 1 -------------------------
2023-03-25 17:54:08,460 : [INFO]  ------------------------- Batch round 1, loss: 0.568 -------------------------
2023-03-25 17:54:08,460 : [INFO]  ------------------------- Batch 77, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:08,494 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:08,496 : [INFO]  ------------------------- Batch 77 training: round 2 -------------------------
2023-03-25 17:54:11,417 : [INFO]  ------------------------- Batch round 2, loss: 0.5606 -------------------------
2023-03-25 17:54:11,417 : [INFO]  ------------------------- Batch 77, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:11,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:11,426 : [INFO]  ------------------------- Batch 77 training: round 3 -------------------------
2023-03-25 17:54:14,204 : [INFO]  ------------------------- Batch round 3, loss: 0.5665 -------------------------
2023-03-25 17:54:14,205 : [INFO]  ------------------------- Batch 77, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:14,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:14,306 : [INFO]  Batch number 77 model fetched from the server
2023-03-25 17:54:14,306 : [INFO]  ################ Batch 77: final global model evalution after 3 rounds ################
2023-03-25 17:54:16,064 : [INFO]  Batch 77: Training set : loss - 0.586, accuracy - 0.6957, recall - 0.9239, AUC - 0.8638, F1 - 0.7522, precision - 0.6343, training time - -11.0 seconds
2023-03-25 17:54:16,064 : [INFO]  Batch 77: Testing set : loss - 0.6104, accuracy - 0.6422, recall - 0.8627, AUC - 0.7917, F1 - 0.7068, precision - 0.5986
2023-03-25 17:54:16,072 : [INFO]  Batch 78 initialized 
2023-03-25 17:54:16,646 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:17,025 : [INFO]  ------------------------- Batch 78 training: round 1 -------------------------
2023-03-25 17:54:22,328 : [INFO]  ------------------------- Batch round 1, loss: 0.5456 -------------------------
2023-03-25 17:54:22,328 : [INFO]  ------------------------- Batch 78, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:22,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:22,346 : [INFO]  ------------------------- Batch 78 training: round 2 -------------------------
2023-03-25 17:54:25,181 : [INFO]  ------------------------- Batch round 2, loss: 0.5454 -------------------------
2023-03-25 17:54:25,181 : [INFO]  ------------------------- Batch 78, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:25,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:25,190 : [INFO]  ------------------------- Batch 78 training: round 3 -------------------------
2023-03-25 17:54:28,034 : [INFO]  ------------------------- Batch round 3, loss: 0.5485 -------------------------
2023-03-25 17:54:28,034 : [INFO]  ------------------------- Batch 78, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:28,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:28,045 : [INFO]  Batch number 78 model fetched from the server
2023-03-25 17:54:28,045 : [INFO]  ################ Batch 78: final global model evalution after 3 rounds ################
2023-03-25 17:54:29,772 : [INFO]  Batch 78: Training set : loss - 0.5513, accuracy - 0.75, recall - 0.9348, AUC - 0.8845, F1 - 0.789, precision - 0.6825, training time - -11.0 seconds
2023-03-25 17:54:29,772 : [INFO]  Batch 78: Testing set : loss - 0.5916, accuracy - 0.7157, recall - 0.9216, AUC - 0.8157, F1 - 0.7642, precision - 0.6528
2023-03-25 17:54:29,788 : [INFO]  Batch 79 initialized 
2023-03-25 17:54:30,374 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:30,760 : [INFO]  ------------------------- Batch 79 training: round 1 -------------------------
2023-03-25 17:54:36,024 : [INFO]  ------------------------- Batch round 1, loss: 0.5925 -------------------------
2023-03-25 17:54:36,024 : [INFO]  ------------------------- Batch 79, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:36,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:36,210 : [INFO]  ------------------------- Batch 79 training: round 2 -------------------------
2023-03-25 17:54:39,067 : [INFO]  ------------------------- Batch round 2, loss: 0.5825 -------------------------
2023-03-25 17:54:39,068 : [INFO]  ------------------------- Batch 79, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:39,205 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:39,208 : [INFO]  ------------------------- Batch 79 training: round 3 -------------------------
2023-03-25 17:54:41,997 : [INFO]  ------------------------- Batch round 3, loss: 0.5829 -------------------------
2023-03-25 17:54:41,998 : [INFO]  ------------------------- Batch 79, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:42,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:42,222 : [INFO]  Batch number 79 model fetched from the server
2023-03-25 17:54:42,222 : [INFO]  ################ Batch 79: final global model evalution after 3 rounds ################
2023-03-25 17:54:44,024 : [INFO]  Batch 79: Training set : loss - 0.5937, accuracy - 0.7065, recall - 0.9022, AUC - 0.8138, F1 - 0.7545, precision - 0.6484, training time - -11.0 seconds
2023-03-25 17:54:44,025 : [INFO]  Batch 79: Testing set : loss - 0.5697, accuracy - 0.7206, recall - 0.8922, AUC - 0.8596, F1 - 0.7615, precision - 0.6642
2023-03-25 17:54:44,055 : [INFO]  Batch 80 initialized 
2023-03-25 17:54:44,611 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:44,989 : [INFO]  ------------------------- Batch 80 training: round 1 -------------------------
2023-03-25 17:54:50,481 : [INFO]  ------------------------- Batch round 1, loss: 0.557 -------------------------
2023-03-25 17:54:50,481 : [INFO]  ------------------------- Batch 80, round 1: Sent local model to the server -------------------------
2023-03-25 17:54:50,547 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:50,550 : [INFO]  ------------------------- Batch 80 training: round 2 -------------------------
2023-03-25 17:54:53,507 : [INFO]  ------------------------- Batch round 2, loss: 0.5572 -------------------------
2023-03-25 17:54:53,507 : [INFO]  ------------------------- Batch 80, round 2: Sent local model to the server -------------------------
2023-03-25 17:54:53,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:53,519 : [INFO]  ------------------------- Batch 80 training: round 3 -------------------------
2023-03-25 17:54:56,513 : [INFO]  ------------------------- Batch round 3, loss: 0.546 -------------------------
2023-03-25 17:54:56,513 : [INFO]  ------------------------- Batch 80, round 3: Sent local model to the server -------------------------
2023-03-25 17:54:56,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:54:56,523 : [INFO]  Batch number 80 model fetched from the server
2023-03-25 17:54:56,523 : [INFO]  ################ Batch 80: final global model evalution after 3 rounds ################
2023-03-25 17:54:58,371 : [INFO]  Batch 80: Training set : loss - 0.563, accuracy - 0.7283, recall - 0.8696, AUC - 0.8539, F1 - 0.7619, precision - 0.678, training time - -12.0 seconds
2023-03-25 17:54:58,371 : [INFO]  Batch 80: Testing set : loss - 0.5651, accuracy - 0.7598, recall - 0.902, AUC - 0.8691, F1 - 0.7897, precision - 0.7023
2023-03-25 17:54:58,380 : [INFO]  Batch 81 initialized 
2023-03-25 17:54:58,974 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:54:59,356 : [INFO]  ------------------------- Batch 81 training: round 1 -------------------------
2023-03-25 17:55:04,734 : [INFO]  ------------------------- Batch round 1, loss: 0.5809 -------------------------
2023-03-25 17:55:04,734 : [INFO]  ------------------------- Batch 81, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:04,742 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:04,744 : [INFO]  ------------------------- Batch 81 training: round 2 -------------------------
2023-03-25 17:55:07,597 : [INFO]  ------------------------- Batch round 2, loss: 0.5848 -------------------------
2023-03-25 17:55:07,598 : [INFO]  ------------------------- Batch 81, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:07,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:07,613 : [INFO]  ------------------------- Batch 81 training: round 3 -------------------------
2023-03-25 17:55:10,532 : [INFO]  ------------------------- Batch round 3, loss: 0.5908 -------------------------
2023-03-25 17:55:10,532 : [INFO]  ------------------------- Batch 81, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:10,542 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:10,545 : [INFO]  Batch number 81 model fetched from the server
2023-03-25 17:55:10,545 : [INFO]  ################ Batch 81: final global model evalution after 3 rounds ################
2023-03-25 17:55:12,329 : [INFO]  Batch 81: Training set : loss - 0.6114, accuracy - 0.6087, recall - 0.8152, AUC - 0.7886, F1 - 0.6757, precision - 0.5769, training time - -11.0 seconds
2023-03-25 17:55:12,330 : [INFO]  Batch 81: Testing set : loss - 0.6007, accuracy - 0.6569, recall - 0.8137, AUC - 0.801, F1 - 0.7034, precision - 0.6194
2023-03-25 17:55:12,343 : [INFO]  Batch 82 initialized 
2023-03-25 17:55:13,070 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:13,465 : [INFO]  ------------------------- Batch 82 training: round 1 -------------------------
2023-03-25 17:55:18,906 : [INFO]  ------------------------- Batch round 1, loss: 0.565 -------------------------
2023-03-25 17:55:18,906 : [INFO]  ------------------------- Batch 82, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:18,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:18,971 : [INFO]  ------------------------- Batch 82 training: round 2 -------------------------
2023-03-25 17:55:21,811 : [INFO]  ------------------------- Batch round 2, loss: 0.5655 -------------------------
2023-03-25 17:55:21,811 : [INFO]  ------------------------- Batch 82, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:21,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:21,821 : [INFO]  ------------------------- Batch 82 training: round 3 -------------------------
2023-03-25 17:55:24,686 : [INFO]  ------------------------- Batch round 3, loss: 0.5608 -------------------------
2023-03-25 17:55:24,686 : [INFO]  ------------------------- Batch 82, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:24,694 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:24,698 : [INFO]  Batch number 82 model fetched from the server
2023-03-25 17:55:24,699 : [INFO]  ################ Batch 82: final global model evalution after 3 rounds ################
2023-03-25 17:55:26,447 : [INFO]  Batch 82: Training set : loss - 0.5789, accuracy - 0.6957, recall - 0.9348, AUC - 0.8649, F1 - 0.7544, precision - 0.6324, training time - -11.0 seconds
2023-03-25 17:55:26,447 : [INFO]  Batch 82: Testing set : loss - 0.5875, accuracy - 0.6716, recall - 0.8725, AUC - 0.8308, F1 - 0.7265, precision - 0.6224
2023-03-25 17:55:26,463 : [INFO]  Batch 83 initialized 
2023-03-25 17:55:27,037 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:27,426 : [INFO]  ------------------------- Batch 83 training: round 1 -------------------------
2023-03-25 17:55:32,807 : [INFO]  ------------------------- Batch round 1, loss: 0.568 -------------------------
2023-03-25 17:55:32,807 : [INFO]  ------------------------- Batch 83, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:32,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:32,889 : [INFO]  ------------------------- Batch 83 training: round 2 -------------------------
2023-03-25 17:55:35,717 : [INFO]  ------------------------- Batch round 2, loss: 0.57 -------------------------
2023-03-25 17:55:35,717 : [INFO]  ------------------------- Batch 83, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:35,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:35,728 : [INFO]  ------------------------- Batch 83 training: round 3 -------------------------
2023-03-25 17:55:38,538 : [INFO]  ------------------------- Batch round 3, loss: 0.5637 -------------------------
2023-03-25 17:55:38,538 : [INFO]  ------------------------- Batch 83, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:38,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:38,556 : [INFO]  Batch number 83 model fetched from the server
2023-03-25 17:55:38,557 : [INFO]  ################ Batch 83: final global model evalution after 3 rounds ################
2023-03-25 17:55:40,435 : [INFO]  Batch 83: Training set : loss - 0.5771, accuracy - 0.7283, recall - 0.8804, AUC - 0.8154, F1 - 0.7642, precision - 0.675, training time - -11.0 seconds
2023-03-25 17:55:40,436 : [INFO]  Batch 83: Testing set : loss - 0.5664, accuracy - 0.7353, recall - 0.8725, AUC - 0.8491, F1 - 0.7672, precision - 0.6846
2023-03-25 17:55:40,447 : [INFO]  Batch 84 initialized 
2023-03-25 17:55:41,045 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:41,450 : [INFO]  ------------------------- Batch 84 training: round 1 -------------------------
2023-03-25 17:55:46,864 : [INFO]  ------------------------- Batch round 1, loss: 0.5728 -------------------------
2023-03-25 17:55:46,864 : [INFO]  ------------------------- Batch 84, round 1: Sent local model to the server -------------------------
2023-03-25 17:55:46,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:46,875 : [INFO]  ------------------------- Batch 84 training: round 2 -------------------------
2023-03-25 17:55:49,757 : [INFO]  ------------------------- Batch round 2, loss: 0.5775 -------------------------
2023-03-25 17:55:49,757 : [INFO]  ------------------------- Batch 84, round 2: Sent local model to the server -------------------------
2023-03-25 17:55:49,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:49,768 : [INFO]  ------------------------- Batch 84 training: round 3 -------------------------
2023-03-25 17:55:52,697 : [INFO]  ------------------------- Batch round 3, loss: 0.5813 -------------------------
2023-03-25 17:55:52,697 : [INFO]  ------------------------- Batch 84, round 3: Sent local model to the server -------------------------
2023-03-25 17:55:52,704 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:55:52,707 : [INFO]  Batch number 84 model fetched from the server
2023-03-25 17:55:52,707 : [INFO]  ################ Batch 84: final global model evalution after 3 rounds ################
2023-03-25 17:55:54,489 : [INFO]  Batch 84: Training set : loss - 0.6017, accuracy - 0.6522, recall - 0.837, AUC - 0.812, F1 - 0.7064, precision - 0.6111, training time - -11.0 seconds
2023-03-25 17:55:54,489 : [INFO]  Batch 84: Testing set : loss - 0.6028, accuracy - 0.6618, recall - 0.8529, AUC - 0.7817, F1 - 0.716, precision - 0.617
2023-03-25 17:55:54,502 : [INFO]  Batch 85 initialized 
2023-03-25 17:55:55,080 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:55:55,491 : [INFO]  ------------------------- Batch 85 training: round 1 -------------------------
2023-03-25 17:56:00,782 : [INFO]  ------------------------- Batch round 1, loss: 0.5369 -------------------------
2023-03-25 17:56:00,783 : [INFO]  ------------------------- Batch 85, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:00,883 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:00,886 : [INFO]  ------------------------- Batch 85 training: round 2 -------------------------
2023-03-25 17:56:03,620 : [INFO]  ------------------------- Batch round 2, loss: 0.537 -------------------------
2023-03-25 17:56:03,620 : [INFO]  ------------------------- Batch 85, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:03,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:03,704 : [INFO]  ------------------------- Batch 85 training: round 3 -------------------------
2023-03-25 17:56:06,410 : [INFO]  ------------------------- Batch round 3, loss: 0.5377 -------------------------
2023-03-25 17:56:06,410 : [INFO]  ------------------------- Batch 85, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:06,486 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:06,488 : [INFO]  Batch number 85 model fetched from the server
2023-03-25 17:56:06,488 : [INFO]  ################ Batch 85: final global model evalution after 3 rounds ################
2023-03-25 17:56:08,246 : [INFO]  Batch 85: Training set : loss - 0.5508, accuracy - 0.7446, recall - 0.913, AUC - 0.8912, F1 - 0.7814, precision - 0.6829, training time - -11.0 seconds
2023-03-25 17:56:08,246 : [INFO]  Batch 85: Testing set : loss - 0.5608, accuracy - 0.7304, recall - 0.9706, AUC - 0.922, F1 - 0.7826, precision - 0.6556
2023-03-25 17:56:08,254 : [INFO]  Batch 86 initialized 
2023-03-25 17:56:08,817 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:09,224 : [INFO]  ------------------------- Batch 86 training: round 1 -------------------------
2023-03-25 17:56:14,458 : [INFO]  ------------------------- Batch round 1, loss: 0.5844 -------------------------
2023-03-25 17:56:14,458 : [INFO]  ------------------------- Batch 86, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:14,722 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:14,724 : [INFO]  ------------------------- Batch 86 training: round 2 -------------------------
2023-03-25 17:56:17,562 : [INFO]  ------------------------- Batch round 2, loss: 0.5858 -------------------------
2023-03-25 17:56:17,563 : [INFO]  ------------------------- Batch 86, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:17,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:17,620 : [INFO]  ------------------------- Batch 86 training: round 3 -------------------------
2023-03-25 17:56:20,496 : [INFO]  ------------------------- Batch round 3, loss: 0.5817 -------------------------
2023-03-25 17:56:20,496 : [INFO]  ------------------------- Batch 86, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:20,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:20,555 : [INFO]  Batch number 86 model fetched from the server
2023-03-25 17:56:20,555 : [INFO]  ################ Batch 86: final global model evalution after 3 rounds ################
2023-03-25 17:56:22,387 : [INFO]  Batch 86: Training set : loss - 0.5957, accuracy - 0.6902, recall - 0.8696, AUC - 0.8134, F1 - 0.7373, precision - 0.64, training time - -11.0 seconds
2023-03-25 17:56:22,387 : [INFO]  Batch 86: Testing set : loss - 0.5536, accuracy - 0.75, recall - 0.9412, AUC - 0.8891, F1 - 0.7901, precision - 0.6809
2023-03-25 17:56:22,404 : [INFO]  Batch 87 initialized 
2023-03-25 17:56:22,997 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:23,405 : [INFO]  ------------------------- Batch 87 training: round 1 -------------------------
2023-03-25 17:56:28,691 : [INFO]  ------------------------- Batch round 1, loss: 0.5571 -------------------------
2023-03-25 17:56:28,691 : [INFO]  ------------------------- Batch 87, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:28,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:28,801 : [INFO]  ------------------------- Batch 87 training: round 2 -------------------------
2023-03-25 17:56:31,625 : [INFO]  ------------------------- Batch round 2, loss: 0.5559 -------------------------
2023-03-25 17:56:31,625 : [INFO]  ------------------------- Batch 87, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:31,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:31,673 : [INFO]  ------------------------- Batch 87 training: round 3 -------------------------
2023-03-25 17:56:34,572 : [INFO]  ------------------------- Batch round 3, loss: 0.5498 -------------------------
2023-03-25 17:56:34,572 : [INFO]  ------------------------- Batch 87, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:34,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:34,583 : [INFO]  Batch number 87 model fetched from the server
2023-03-25 17:56:34,583 : [INFO]  ################ Batch 87: final global model evalution after 3 rounds ################
2023-03-25 17:56:36,358 : [INFO]  Batch 87: Training set : loss - 0.5647, accuracy - 0.7663, recall - 0.9457, AUC - 0.8693, F1 - 0.8018, precision - 0.696, training time - -11.0 seconds
2023-03-25 17:56:36,358 : [INFO]  Batch 87: Testing set : loss - 0.5586, accuracy - 0.75, recall - 0.9608, AUC - 0.9042, F1 - 0.7935, precision - 0.6759
2023-03-25 17:56:36,371 : [INFO]  Batch 88 initialized 
2023-03-25 17:56:36,940 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:37,356 : [INFO]  ------------------------- Batch 88 training: round 1 -------------------------
2023-03-25 17:56:42,738 : [INFO]  ------------------------- Batch round 1, loss: 0.581 -------------------------
2023-03-25 17:56:42,738 : [INFO]  ------------------------- Batch 88, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:42,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:42,750 : [INFO]  ------------------------- Batch 88 training: round 2 -------------------------
2023-03-25 17:56:45,572 : [INFO]  ------------------------- Batch round 2, loss: 0.5799 -------------------------
2023-03-25 17:56:45,573 : [INFO]  ------------------------- Batch 88, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:45,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:45,666 : [INFO]  ------------------------- Batch 88 training: round 3 -------------------------
2023-03-25 17:56:48,496 : [INFO]  ------------------------- Batch round 3, loss: 0.5757 -------------------------
2023-03-25 17:56:48,497 : [INFO]  ------------------------- Batch 88, round 3: Sent local model to the server -------------------------
2023-03-25 17:56:48,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:48,508 : [INFO]  Batch number 88 model fetched from the server
2023-03-25 17:56:48,508 : [INFO]  ################ Batch 88: final global model evalution after 3 rounds ################
2023-03-25 17:56:50,260 : [INFO]  Batch 88: Training set : loss - 0.5901, accuracy - 0.6902, recall - 0.8261, AUC - 0.8014, F1 - 0.7273, precision - 0.6496, training time - -11.0 seconds
2023-03-25 17:56:50,261 : [INFO]  Batch 88: Testing set : loss - 0.5712, accuracy - 0.7059, recall - 0.8824, AUC - 0.8544, F1 - 0.75, precision - 0.6522
2023-03-25 17:56:50,272 : [INFO]  Batch 89 initialized 
2023-03-25 17:56:50,844 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:56:51,260 : [INFO]  ------------------------- Batch 89 training: round 1 -------------------------
2023-03-25 17:56:56,621 : [INFO]  ------------------------- Batch round 1, loss: 0.5725 -------------------------
2023-03-25 17:56:56,621 : [INFO]  ------------------------- Batch 89, round 1: Sent local model to the server -------------------------
2023-03-25 17:56:56,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:56,632 : [INFO]  ------------------------- Batch 89 training: round 2 -------------------------
2023-03-25 17:56:59,263 : [INFO]  ------------------------- Batch round 2, loss: 0.5682 -------------------------
2023-03-25 17:56:59,263 : [INFO]  ------------------------- Batch 89, round 2: Sent local model to the server -------------------------
2023-03-25 17:56:59,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:56:59,374 : [INFO]  ------------------------- Batch 89 training: round 3 -------------------------
2023-03-25 17:57:02,270 : [INFO]  ------------------------- Batch round 3, loss: 0.5651 -------------------------
2023-03-25 17:57:02,270 : [INFO]  ------------------------- Batch 89, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:02,353 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:02,356 : [INFO]  Batch number 89 model fetched from the server
2023-03-25 17:57:02,356 : [INFO]  ################ Batch 89: final global model evalution after 3 rounds ################
2023-03-25 17:57:04,160 : [INFO]  Batch 89: Training set : loss - 0.5751, accuracy - 0.6902, recall - 0.9239, AUC - 0.8586, F1 - 0.7489, precision - 0.6296, training time - -11.0 seconds
2023-03-25 17:57:04,161 : [INFO]  Batch 89: Testing set : loss - 0.5782, accuracy - 0.6961, recall - 0.9118, AUC - 0.8445, F1 - 0.75, precision - 0.637
2023-03-25 17:57:04,176 : [INFO]  Batch 90 initialized 
2023-03-25 17:57:04,740 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:05,165 : [INFO]  ------------------------- Batch 90 training: round 1 -------------------------
2023-03-25 17:57:10,584 : [INFO]  ------------------------- Batch round 1, loss: 0.5645 -------------------------
2023-03-25 17:57:10,584 : [INFO]  ------------------------- Batch 90, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:10,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:10,627 : [INFO]  ------------------------- Batch 90 training: round 2 -------------------------
2023-03-25 17:57:13,405 : [INFO]  ------------------------- Batch round 2, loss: 0.5667 -------------------------
2023-03-25 17:57:13,406 : [INFO]  ------------------------- Batch 90, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:13,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:13,493 : [INFO]  ------------------------- Batch 90 training: round 3 -------------------------
2023-03-25 17:57:16,387 : [INFO]  ------------------------- Batch round 3, loss: 0.5736 -------------------------
2023-03-25 17:57:16,387 : [INFO]  ------------------------- Batch 90, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:16,420 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:16,423 : [INFO]  Batch number 90 model fetched from the server
2023-03-25 17:57:16,423 : [INFO]  ################ Batch 90: final global model evalution after 3 rounds ################
2023-03-25 17:57:18,167 : [INFO]  Batch 90: Training set : loss - 0.5783, accuracy - 0.6848, recall - 0.8478, AUC - 0.8222, F1 - 0.729, precision - 0.6393, training time - -11.0 seconds
2023-03-25 17:57:18,167 : [INFO]  Batch 90: Testing set : loss - 0.6084, accuracy - 0.6716, recall - 0.8333, AUC - 0.7753, F1 - 0.7173, precision - 0.6296
2023-03-25 17:57:18,178 : [INFO]  Batch 91 initialized 
2023-03-25 17:57:18,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:19,164 : [INFO]  ------------------------- Batch 91 training: round 1 -------------------------
2023-03-25 17:57:24,619 : [INFO]  ------------------------- Batch round 1, loss: 0.5629 -------------------------
2023-03-25 17:57:24,619 : [INFO]  ------------------------- Batch 91, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:24,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:24,630 : [INFO]  ------------------------- Batch 91 training: round 2 -------------------------
2023-03-25 17:57:27,516 : [INFO]  ------------------------- Batch round 2, loss: 0.5612 -------------------------
2023-03-25 17:57:27,516 : [INFO]  ------------------------- Batch 91, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:27,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:27,527 : [INFO]  ------------------------- Batch 91 training: round 3 -------------------------
2023-03-25 17:57:30,395 : [INFO]  ------------------------- Batch round 3, loss: 0.5692 -------------------------
2023-03-25 17:57:30,396 : [INFO]  ------------------------- Batch 91, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:30,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:30,405 : [INFO]  Batch number 91 model fetched from the server
2023-03-25 17:57:30,405 : [INFO]  ################ Batch 91: final global model evalution after 3 rounds ################
2023-03-25 17:57:32,193 : [INFO]  Batch 91: Training set : loss - 0.5703, accuracy - 0.7011, recall - 0.8696, AUC - 0.8356, F1 - 0.7442, precision - 0.6504, training time - -11.0 seconds
2023-03-25 17:57:32,194 : [INFO]  Batch 91: Testing set : loss - 0.5691, accuracy - 0.7059, recall - 0.902, AUC - 0.8693, F1 - 0.7541, precision - 0.6479
2023-03-25 17:57:32,203 : [INFO]  Batch 92 initialized 
2023-03-25 17:57:32,803 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:33,228 : [INFO]  ------------------------- Batch 92 training: round 1 -------------------------
2023-03-25 17:57:38,465 : [INFO]  ------------------------- Batch round 1, loss: 0.5253 -------------------------
2023-03-25 17:57:38,465 : [INFO]  ------------------------- Batch 92, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:38,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:38,720 : [INFO]  ------------------------- Batch 92 training: round 2 -------------------------
2023-03-25 17:57:41,788 : [INFO]  ------------------------- Batch round 2, loss: 0.528 -------------------------
2023-03-25 17:57:41,788 : [INFO]  ------------------------- Batch 92, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:41,835 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:41,838 : [INFO]  ------------------------- Batch 92 training: round 3 -------------------------
2023-03-25 17:57:44,603 : [INFO]  ------------------------- Batch round 3, loss: 0.5273 -------------------------
2023-03-25 17:57:44,603 : [INFO]  ------------------------- Batch 92, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:44,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:44,879 : [INFO]  Batch number 92 model fetched from the server
2023-03-25 17:57:44,879 : [INFO]  ################ Batch 92: final global model evalution after 3 rounds ################
2023-03-25 17:57:46,606 : [INFO]  Batch 92: Training set : loss - 0.5317, accuracy - 0.7609, recall - 0.9457, AUC - 0.9229, F1 - 0.7982, precision - 0.6905, training time - -12.0 seconds
2023-03-25 17:57:46,606 : [INFO]  Batch 92: Testing set : loss - 0.5727, accuracy - 0.701, recall - 0.8922, AUC - 0.8385, F1 - 0.749, precision - 0.6454
2023-03-25 17:57:46,637 : [INFO]  Batch 93 initialized 
2023-03-25 17:57:47,302 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:57:47,713 : [INFO]  ------------------------- Batch 93 training: round 1 -------------------------
2023-03-25 17:57:53,080 : [INFO]  ------------------------- Batch round 1, loss: 0.5452 -------------------------
2023-03-25 17:57:53,080 : [INFO]  ------------------------- Batch 93, round 1: Sent local model to the server -------------------------
2023-03-25 17:57:53,212 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:53,216 : [INFO]  ------------------------- Batch 93 training: round 2 -------------------------
2023-03-25 17:57:56,065 : [INFO]  ------------------------- Batch round 2, loss: 0.547 -------------------------
2023-03-25 17:57:56,065 : [INFO]  ------------------------- Batch 93, round 2: Sent local model to the server -------------------------
2023-03-25 17:57:56,097 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:56,102 : [INFO]  ------------------------- Batch 93 training: round 3 -------------------------
2023-03-25 17:57:58,954 : [INFO]  ------------------------- Batch round 3, loss: 0.5496 -------------------------
2023-03-25 17:57:58,954 : [INFO]  ------------------------- Batch 93, round 3: Sent local model to the server -------------------------
2023-03-25 17:57:58,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:57:58,989 : [INFO]  Batch number 93 model fetched from the server
2023-03-25 17:57:58,989 : [INFO]  ################ Batch 93: final global model evalution after 3 rounds ################
2023-03-25 17:58:00,752 : [INFO]  Batch 93: Training set : loss - 0.5564, accuracy - 0.75, recall - 0.9348, AUC - 0.8762, F1 - 0.789, precision - 0.6825, training time - -11.0 seconds
2023-03-25 17:58:00,753 : [INFO]  Batch 93: Testing set : loss - 0.577, accuracy - 0.7157, recall - 0.8725, AUC - 0.8445, F1 - 0.7542, precision - 0.6642
2023-03-25 17:58:00,764 : [INFO]  Batch 94 initialized 
2023-03-25 17:58:01,341 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:01,761 : [INFO]  ------------------------- Batch 94 training: round 1 -------------------------
2023-03-25 17:58:07,273 : [INFO]  ------------------------- Batch round 1, loss: 0.5801 -------------------------
2023-03-25 17:58:07,273 : [INFO]  ------------------------- Batch 94, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:07,289 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:07,292 : [INFO]  ------------------------- Batch 94 training: round 2 -------------------------
2023-03-25 17:58:10,159 : [INFO]  ------------------------- Batch round 2, loss: 0.5758 -------------------------
2023-03-25 17:58:10,159 : [INFO]  ------------------------- Batch 94, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:10,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:10,204 : [INFO]  ------------------------- Batch 94 training: round 3 -------------------------
2023-03-25 17:58:13,101 : [INFO]  ------------------------- Batch round 3, loss: 0.5763 -------------------------
2023-03-25 17:58:13,101 : [INFO]  ------------------------- Batch 94, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:13,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:13,134 : [INFO]  Batch number 94 model fetched from the server
2023-03-25 17:58:13,134 : [INFO]  ################ Batch 94: final global model evalution after 3 rounds ################
2023-03-25 17:58:14,911 : [INFO]  Batch 94: Training set : loss - 0.5928, accuracy - 0.6848, recall - 0.8913, AUC - 0.8076, F1 - 0.7387, precision - 0.6308, training time - -11.0 seconds
2023-03-25 17:58:14,912 : [INFO]  Batch 94: Testing set : loss - 0.5926, accuracy - 0.7059, recall - 0.9216, AUC - 0.8422, F1 - 0.7581, precision - 0.6438
2023-03-25 17:58:14,923 : [INFO]  Batch 95 initialized 
2023-03-25 17:58:15,491 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:15,916 : [INFO]  ------------------------- Batch 95 training: round 1 -------------------------
2023-03-25 17:58:21,295 : [INFO]  ------------------------- Batch round 1, loss: 0.5702 -------------------------
2023-03-25 17:58:21,296 : [INFO]  ------------------------- Batch 95, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:21,303 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:21,305 : [INFO]  ------------------------- Batch 95 training: round 2 -------------------------
2023-03-25 17:58:24,300 : [INFO]  ------------------------- Batch round 2, loss: 0.5718 -------------------------
2023-03-25 17:58:24,300 : [INFO]  ------------------------- Batch 95, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:24,308 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:24,310 : [INFO]  ------------------------- Batch 95 training: round 3 -------------------------
2023-03-25 17:58:27,174 : [INFO]  ------------------------- Batch round 3, loss: 0.5647 -------------------------
2023-03-25 17:58:27,174 : [INFO]  ------------------------- Batch 95, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:27,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:27,184 : [INFO]  Batch number 95 model fetched from the server
2023-03-25 17:58:27,184 : [INFO]  ################ Batch 95: final global model evalution after 3 rounds ################
2023-03-25 17:58:28,976 : [INFO]  Batch 95: Training set : loss - 0.5856, accuracy - 0.7174, recall - 0.8478, AUC - 0.7986, F1 - 0.75, precision - 0.6724, training time - -11.0 seconds
2023-03-25 17:58:28,976 : [INFO]  Batch 95: Testing set : loss - 0.574, accuracy - 0.701, recall - 0.8431, AUC - 0.8467, F1 - 0.7382, precision - 0.6565
2023-03-25 17:58:28,983 : [INFO]  Batch 96 initialized 
2023-03-25 17:58:29,534 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:29,952 : [INFO]  ------------------------- Batch 96 training: round 1 -------------------------
2023-03-25 17:58:35,490 : [INFO]  ------------------------- Batch round 1, loss: 0.5604 -------------------------
2023-03-25 17:58:35,490 : [INFO]  ------------------------- Batch 96, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:35,498 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:35,502 : [INFO]  ------------------------- Batch 96 training: round 2 -------------------------
2023-03-25 17:58:38,555 : [INFO]  ------------------------- Batch round 2, loss: 0.5627 -------------------------
2023-03-25 17:58:38,555 : [INFO]  ------------------------- Batch 96, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:38,597 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:38,600 : [INFO]  ------------------------- Batch 96 training: round 3 -------------------------
2023-03-25 17:58:41,616 : [INFO]  ------------------------- Batch round 3, loss: 0.5559 -------------------------
2023-03-25 17:58:41,616 : [INFO]  ------------------------- Batch 96, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:41,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:41,628 : [INFO]  Batch number 96 model fetched from the server
2023-03-25 17:58:41,628 : [INFO]  ################ Batch 96: final global model evalution after 3 rounds ################
2023-03-25 17:58:43,432 : [INFO]  Batch 96: Training set : loss - 0.5681, accuracy - 0.7446, recall - 0.8804, AUC - 0.8575, F1 - 0.7751, precision - 0.6923, training time - -12.0 seconds
2023-03-25 17:58:43,433 : [INFO]  Batch 96: Testing set : loss - 0.5608, accuracy - 0.7304, recall - 0.9216, AUC - 0.9022, F1 - 0.7737, precision - 0.6667
2023-03-25 17:58:43,443 : [INFO]  Batch 97 initialized 
2023-03-25 17:58:44,024 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:44,445 : [INFO]  ------------------------- Batch 97 training: round 1 -------------------------
2023-03-25 17:58:49,831 : [INFO]  ------------------------- Batch round 1, loss: 0.5919 -------------------------
2023-03-25 17:58:49,832 : [INFO]  ------------------------- Batch 97, round 1: Sent local model to the server -------------------------
2023-03-25 17:58:49,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:49,878 : [INFO]  ------------------------- Batch 97 training: round 2 -------------------------
2023-03-25 17:58:52,787 : [INFO]  ------------------------- Batch round 2, loss: 0.5932 -------------------------
2023-03-25 17:58:52,787 : [INFO]  ------------------------- Batch 97, round 2: Sent local model to the server -------------------------
2023-03-25 17:58:52,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:52,942 : [INFO]  ------------------------- Batch 97 training: round 3 -------------------------
2023-03-25 17:58:55,810 : [INFO]  ------------------------- Batch round 3, loss: 0.5899 -------------------------
2023-03-25 17:58:55,810 : [INFO]  ------------------------- Batch 97, round 3: Sent local model to the server -------------------------
2023-03-25 17:58:55,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:58:55,875 : [INFO]  Batch number 97 model fetched from the server
2023-03-25 17:58:55,875 : [INFO]  ################ Batch 97: final global model evalution after 3 rounds ################
2023-03-25 17:58:57,639 : [INFO]  Batch 97: Training set : loss - 0.6012, accuracy - 0.6685, recall - 0.837, AUC - 0.7944, F1 - 0.7163, precision - 0.626, training time - -11.0 seconds
2023-03-25 17:58:57,640 : [INFO]  Batch 97: Testing set : loss - 0.5628, accuracy - 0.7549, recall - 0.951, AUC - 0.899, F1 - 0.7951, precision - 0.6831
2023-03-25 17:58:57,656 : [INFO]  Batch 98 initialized 
2023-03-25 17:58:58,255 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:58:58,673 : [INFO]  ------------------------- Batch 98 training: round 1 -------------------------
2023-03-25 17:59:04,195 : [INFO]  ------------------------- Batch round 1, loss: 0.5586 -------------------------
2023-03-25 17:59:04,195 : [INFO]  ------------------------- Batch 98, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:04,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:04,329 : [INFO]  ------------------------- Batch 98 training: round 2 -------------------------
2023-03-25 17:59:07,335 : [INFO]  ------------------------- Batch round 2, loss: 0.563 -------------------------
2023-03-25 17:59:07,335 : [INFO]  ------------------------- Batch 98, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:07,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:07,345 : [INFO]  ------------------------- Batch 98 training: round 3 -------------------------
2023-03-25 17:59:10,236 : [INFO]  ------------------------- Batch round 3, loss: 0.5593 -------------------------
2023-03-25 17:59:10,237 : [INFO]  ------------------------- Batch 98, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:10,276 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:10,279 : [INFO]  Batch number 98 model fetched from the server
2023-03-25 17:59:10,279 : [INFO]  ################ Batch 98: final global model evalution after 3 rounds ################
2023-03-25 17:59:12,052 : [INFO]  Batch 98: Training set : loss - 0.5721, accuracy - 0.6902, recall - 0.8913, AUC - 0.8526, F1 - 0.7421, precision - 0.6357, training time - -12.0 seconds
2023-03-25 17:59:12,052 : [INFO]  Batch 98: Testing set : loss - 0.5892, accuracy - 0.6569, recall - 0.8627, AUC - 0.8347, F1 - 0.7154, precision - 0.6111
2023-03-25 17:59:12,067 : [INFO]  Batch 99 initialized 
2023-03-25 17:59:12,644 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:13,074 : [INFO]  ------------------------- Batch 99 training: round 1 -------------------------
2023-03-25 17:59:18,588 : [INFO]  ------------------------- Batch round 1, loss: 0.5382 -------------------------
2023-03-25 17:59:18,588 : [INFO]  ------------------------- Batch 99, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:18,655 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:18,658 : [INFO]  ------------------------- Batch 99 training: round 2 -------------------------
2023-03-25 17:59:21,454 : [INFO]  ------------------------- Batch round 2, loss: 0.5405 -------------------------
2023-03-25 17:59:21,455 : [INFO]  ------------------------- Batch 99, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:21,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:21,571 : [INFO]  ------------------------- Batch 99 training: round 3 -------------------------
2023-03-25 17:59:24,438 : [INFO]  ------------------------- Batch round 3, loss: 0.5365 -------------------------
2023-03-25 17:59:24,438 : [INFO]  ------------------------- Batch 99, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:24,486 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:24,489 : [INFO]  Batch number 99 model fetched from the server
2023-03-25 17:59:24,489 : [INFO]  ################ Batch 99: final global model evalution after 3 rounds ################
2023-03-25 17:59:26,226 : [INFO]  Batch 99: Training set : loss - 0.548, accuracy - 0.7337, recall - 0.9457, AUC - 0.9064, F1 - 0.7803, precision - 0.6641, training time - -11.0 seconds
2023-03-25 17:59:26,227 : [INFO]  Batch 99: Testing set : loss - 0.5825, accuracy - 0.701, recall - 0.902, AUC - 0.831, F1 - 0.751, precision - 0.6434
2023-03-25 17:59:26,240 : [INFO]  Batch 100 initialized 
2023-03-25 17:59:26,783 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:27,215 : [INFO]  ------------------------- Batch 100 training: round 1 -------------------------
2023-03-25 17:59:32,504 : [INFO]  ------------------------- Batch round 1, loss: 0.5925 -------------------------
2023-03-25 17:59:32,504 : [INFO]  ------------------------- Batch 100, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:32,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:32,515 : [INFO]  ------------------------- Batch 100 training: round 2 -------------------------
2023-03-25 17:59:35,302 : [INFO]  ------------------------- Batch round 2, loss: 0.5937 -------------------------
2023-03-25 17:59:35,302 : [INFO]  ------------------------- Batch 100, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:35,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:35,313 : [INFO]  ------------------------- Batch 100 training: round 3 -------------------------
2023-03-25 17:59:38,278 : [INFO]  ------------------------- Batch round 3, loss: 0.5901 -------------------------
2023-03-25 17:59:38,278 : [INFO]  ------------------------- Batch 100, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:38,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:38,292 : [INFO]  Batch number 100 model fetched from the server
2023-03-25 17:59:38,292 : [INFO]  ################ Batch 100: final global model evalution after 3 rounds ################
2023-03-25 17:59:40,058 : [INFO]  Batch 100: Training set : loss - 0.6087, accuracy - 0.6739, recall - 0.913, AUC - 0.7889, F1 - 0.7368, precision - 0.6176, training time - -11.0 seconds
2023-03-25 17:59:40,059 : [INFO]  Batch 100: Testing set : loss - 0.5694, accuracy - 0.7353, recall - 0.9216, AUC - 0.8642, F1 - 0.7769, precision - 0.6714
2023-03-25 17:59:40,068 : [INFO]  Batch 101 initialized 
2023-03-25 17:59:40,643 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:41,086 : [INFO]  ------------------------- Batch 101 training: round 1 -------------------------
2023-03-25 17:59:46,325 : [INFO]  ------------------------- Batch round 1, loss: 0.5683 -------------------------
2023-03-25 17:59:46,326 : [INFO]  ------------------------- Batch 101, round 1: Sent local model to the server -------------------------
2023-03-25 17:59:46,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:46,435 : [INFO]  ------------------------- Batch 101 training: round 2 -------------------------
2023-03-25 17:59:49,255 : [INFO]  ------------------------- Batch round 2, loss: 0.5681 -------------------------
2023-03-25 17:59:49,255 : [INFO]  ------------------------- Batch 101, round 2: Sent local model to the server -------------------------
2023-03-25 17:59:49,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:49,300 : [INFO]  ------------------------- Batch 101 training: round 3 -------------------------
2023-03-25 17:59:52,025 : [INFO]  ------------------------- Batch round 3, loss: 0.5701 -------------------------
2023-03-25 17:59:52,025 : [INFO]  ------------------------- Batch 101, round 3: Sent local model to the server -------------------------
2023-03-25 17:59:52,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 17:59:52,088 : [INFO]  Batch number 101 model fetched from the server
2023-03-25 17:59:52,088 : [INFO]  ################ Batch 101: final global model evalution after 3 rounds ################
2023-03-25 17:59:53,777 : [INFO]  Batch 101: Training set : loss - 0.583, accuracy - 0.6957, recall - 0.9239, AUC - 0.8287, F1 - 0.7522, precision - 0.6343, training time - -11.0 seconds
2023-03-25 17:59:53,778 : [INFO]  Batch 101: Testing set : loss - 0.5496, accuracy - 0.7304, recall - 0.9216, AUC - 0.8886, F1 - 0.7737, precision - 0.6667
2023-03-25 17:59:53,793 : [INFO]  Batch 102 initialized 
2023-03-25 17:59:54,396 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 17:59:54,846 : [INFO]  ------------------------- Batch 102 training: round 1 -------------------------
2023-03-25 18:00:00,253 : [INFO]  ------------------------- Batch round 1, loss: 0.5582 -------------------------
2023-03-25 18:00:00,253 : [INFO]  ------------------------- Batch 102, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:00,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:00,379 : [INFO]  ------------------------- Batch 102 training: round 2 -------------------------
2023-03-25 18:00:03,227 : [INFO]  ------------------------- Batch round 2, loss: 0.5601 -------------------------
2023-03-25 18:00:03,227 : [INFO]  ------------------------- Batch 102, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:03,314 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:03,317 : [INFO]  ------------------------- Batch 102 training: round 3 -------------------------
2023-03-25 18:00:06,140 : [INFO]  ------------------------- Batch round 3, loss: 0.5558 -------------------------
2023-03-25 18:00:06,140 : [INFO]  ------------------------- Batch 102, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:06,249 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:06,252 : [INFO]  Batch number 102 model fetched from the server
2023-03-25 18:00:06,252 : [INFO]  ################ Batch 102: final global model evalution after 3 rounds ################
2023-03-25 18:00:08,042 : [INFO]  Batch 102: Training set : loss - 0.5722, accuracy - 0.6848, recall - 0.8696, AUC - 0.8187, F1 - 0.7339, precision - 0.6349, training time - -11.0 seconds
2023-03-25 18:00:08,042 : [INFO]  Batch 102: Testing set : loss - 0.6062, accuracy - 0.6667, recall - 0.8333, AUC - 0.7918, F1 - 0.7143, precision - 0.625
2023-03-25 18:00:08,057 : [INFO]  Batch 103 initialized 
2023-03-25 18:00:08,631 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:09,049 : [INFO]  ------------------------- Batch 103 training: round 1 -------------------------
2023-03-25 18:00:14,534 : [INFO]  ------------------------- Batch round 1, loss: 0.5417 -------------------------
2023-03-25 18:00:14,534 : [INFO]  ------------------------- Batch 103, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:14,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:14,626 : [INFO]  ------------------------- Batch 103 training: round 2 -------------------------
2023-03-25 18:00:17,526 : [INFO]  ------------------------- Batch round 2, loss: 0.5379 -------------------------
2023-03-25 18:00:17,526 : [INFO]  ------------------------- Batch 103, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:17,534 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:17,536 : [INFO]  ------------------------- Batch 103 training: round 3 -------------------------
2023-03-25 18:00:20,421 : [INFO]  ------------------------- Batch round 3, loss: 0.5419 -------------------------
2023-03-25 18:00:20,421 : [INFO]  ------------------------- Batch 103, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:20,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:20,442 : [INFO]  Batch number 103 model fetched from the server
2023-03-25 18:00:20,442 : [INFO]  ################ Batch 103: final global model evalution after 3 rounds ################
2023-03-25 18:00:22,277 : [INFO]  Batch 103: Training set : loss - 0.5495, accuracy - 0.7391, recall - 0.8913, AUC - 0.8713, F1 - 0.7736, precision - 0.6833, training time - -11.0 seconds
2023-03-25 18:00:22,277 : [INFO]  Batch 103: Testing set : loss - 0.5828, accuracy - 0.6863, recall - 0.8725, AUC - 0.8297, F1 - 0.7355, precision - 0.6357
2023-03-25 18:00:22,287 : [INFO]  Batch 104 initialized 
2023-03-25 18:00:22,869 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:23,328 : [INFO]  ------------------------- Batch 104 training: round 1 -------------------------
2023-03-25 18:00:28,666 : [INFO]  ------------------------- Batch round 1, loss: 0.5769 -------------------------
2023-03-25 18:00:28,666 : [INFO]  ------------------------- Batch 104, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:28,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:28,737 : [INFO]  ------------------------- Batch 104 training: round 2 -------------------------
2023-03-25 18:00:31,564 : [INFO]  ------------------------- Batch round 2, loss: 0.5791 -------------------------
2023-03-25 18:00:31,565 : [INFO]  ------------------------- Batch 104, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:31,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:31,687 : [INFO]  ------------------------- Batch 104 training: round 3 -------------------------
2023-03-25 18:00:34,529 : [INFO]  ------------------------- Batch round 3, loss: 0.5791 -------------------------
2023-03-25 18:00:34,529 : [INFO]  ------------------------- Batch 104, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:34,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:34,652 : [INFO]  Batch number 104 model fetched from the server
2023-03-25 18:00:34,652 : [INFO]  ################ Batch 104: final global model evalution after 3 rounds ################
2023-03-25 18:00:36,403 : [INFO]  Batch 104: Training set : loss - 0.5975, accuracy - 0.6848, recall - 0.913, AUC - 0.8234, F1 - 0.7434, precision - 0.6269, training time - -11.0 seconds
2023-03-25 18:00:36,404 : [INFO]  Batch 104: Testing set : loss - 0.6046, accuracy - 0.6765, recall - 0.8431, AUC - 0.7955, F1 - 0.7227, precision - 0.6324
2023-03-25 18:00:36,417 : [INFO]  Batch 105 initialized 
2023-03-25 18:00:37,002 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:37,441 : [INFO]  ------------------------- Batch 105 training: round 1 -------------------------
2023-03-25 18:00:42,872 : [INFO]  ------------------------- Batch round 1, loss: 0.5309 -------------------------
2023-03-25 18:00:42,872 : [INFO]  ------------------------- Batch 105, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:43,059 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:43,062 : [INFO]  ------------------------- Batch 105 training: round 2 -------------------------
2023-03-25 18:00:45,835 : [INFO]  ------------------------- Batch round 2, loss: 0.5325 -------------------------
2023-03-25 18:00:45,836 : [INFO]  ------------------------- Batch 105, round 2: Sent local model to the server -------------------------
2023-03-25 18:00:46,012 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:46,015 : [INFO]  ------------------------- Batch 105 training: round 3 -------------------------
2023-03-25 18:00:48,879 : [INFO]  ------------------------- Batch round 3, loss: 0.5313 -------------------------
2023-03-25 18:00:48,880 : [INFO]  ------------------------- Batch 105, round 3: Sent local model to the server -------------------------
2023-03-25 18:00:49,058 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:49,061 : [INFO]  Batch number 105 model fetched from the server
2023-03-25 18:00:49,061 : [INFO]  ################ Batch 105: final global model evalution after 3 rounds ################
2023-03-25 18:00:50,816 : [INFO]  Batch 105: Training set : loss - 0.5401, accuracy - 0.788, recall - 0.9348, AUC - 0.8987, F1 - 0.8152, precision - 0.7227, training time - -12.0 seconds
2023-03-25 18:00:50,817 : [INFO]  Batch 105: Testing set : loss - 0.5625, accuracy - 0.7206, recall - 0.8824, AUC - 0.8692, F1 - 0.7595, precision - 0.6667
2023-03-25 18:00:50,828 : [INFO]  Batch 106 initialized 
2023-03-25 18:00:51,413 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:00:51,861 : [INFO]  ------------------------- Batch 106 training: round 1 -------------------------
2023-03-25 18:00:57,401 : [INFO]  ------------------------- Batch round 1, loss: 0.5783 -------------------------
2023-03-25 18:00:57,402 : [INFO]  ------------------------- Batch 106, round 1: Sent local model to the server -------------------------
2023-03-25 18:00:57,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:00:57,570 : [INFO]  ------------------------- Batch 106 training: round 2 -------------------------
2023-03-25 18:01:00,590 : [INFO]  ------------------------- Batch round 2, loss: 0.5809 -------------------------
2023-03-25 18:01:00,590 : [INFO]  ------------------------- Batch 106, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:00,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:00,601 : [INFO]  ------------------------- Batch 106 training: round 3 -------------------------
2023-03-25 18:01:03,541 : [INFO]  ------------------------- Batch round 3, loss: 0.5857 -------------------------
2023-03-25 18:01:03,542 : [INFO]  ------------------------- Batch 106, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:03,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:03,552 : [INFO]  Batch number 106 model fetched from the server
2023-03-25 18:01:03,553 : [INFO]  ################ Batch 106: final global model evalution after 3 rounds ################
2023-03-25 18:01:05,336 : [INFO]  Batch 106: Training set : loss - 0.5991, accuracy - 0.6467, recall - 0.8804, AUC - 0.8157, F1 - 0.7137, precision - 0.6, training time - -12.0 seconds
2023-03-25 18:01:05,336 : [INFO]  Batch 106: Testing set : loss - 0.5799, accuracy - 0.7108, recall - 0.8922, AUC - 0.8529, F1 - 0.7552, precision - 0.6547
2023-03-25 18:01:05,346 : [INFO]  Batch 107 initialized 
2023-03-25 18:01:05,906 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:06,362 : [INFO]  ------------------------- Batch 107 training: round 1 -------------------------
2023-03-25 18:01:11,882 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-25 18:01:11,882 : [INFO]  ------------------------- Batch 107, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:11,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:11,892 : [INFO]  ------------------------- Batch 107 training: round 2 -------------------------
2023-03-25 18:01:14,762 : [INFO]  ------------------------- Batch round 2, loss: 0.5624 -------------------------
2023-03-25 18:01:14,762 : [INFO]  ------------------------- Batch 107, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:14,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:14,774 : [INFO]  ------------------------- Batch 107 training: round 3 -------------------------
2023-03-25 18:01:17,702 : [INFO]  ------------------------- Batch round 3, loss: 0.5562 -------------------------
2023-03-25 18:01:17,702 : [INFO]  ------------------------- Batch 107, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:17,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:17,713 : [INFO]  Batch number 107 model fetched from the server
2023-03-25 18:01:17,713 : [INFO]  ################ Batch 107: final global model evalution after 3 rounds ################
2023-03-25 18:01:19,480 : [INFO]  Batch 107: Training set : loss - 0.5773, accuracy - 0.712, recall - 0.9348, AUC - 0.8694, F1 - 0.7644, precision - 0.6466, training time - -11.0 seconds
2023-03-25 18:01:19,480 : [INFO]  Batch 107: Testing set : loss - 0.6236, accuracy - 0.6275, recall - 0.7941, AUC - 0.7721, F1 - 0.6807, precision - 0.5956
2023-03-25 18:01:19,491 : [INFO]  Batch 108 initialized 
2023-03-25 18:01:20,131 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:20,581 : [INFO]  ------------------------- Batch 108 training: round 1 -------------------------
2023-03-25 18:01:26,030 : [INFO]  ------------------------- Batch round 1, loss: 0.6177 -------------------------
2023-03-25 18:01:26,030 : [INFO]  ------------------------- Batch 108, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:26,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:26,040 : [INFO]  ------------------------- Batch 108 training: round 2 -------------------------
2023-03-25 18:01:28,874 : [INFO]  ------------------------- Batch round 2, loss: 0.6161 -------------------------
2023-03-25 18:01:28,874 : [INFO]  ------------------------- Batch 108, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:28,881 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:28,884 : [INFO]  ------------------------- Batch 108 training: round 3 -------------------------
2023-03-25 18:01:31,935 : [INFO]  ------------------------- Batch round 3, loss: 0.6124 -------------------------
2023-03-25 18:01:31,935 : [INFO]  ------------------------- Batch 108, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:31,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:31,945 : [INFO]  Batch number 108 model fetched from the server
2023-03-25 18:01:31,945 : [INFO]  ################ Batch 108: final global model evalution after 3 rounds ################
2023-03-25 18:01:33,780 : [INFO]  Batch 108: Training set : loss - 0.6357, accuracy - 0.6522, recall - 0.9022, AUC - 0.7556, F1 - 0.7217, precision - 0.6014, training time - -11.0 seconds
2023-03-25 18:01:33,780 : [INFO]  Batch 108: Testing set : loss - 0.6331, accuracy - 0.6029, recall - 0.902, AUC - 0.7687, F1 - 0.6943, precision - 0.5644
2023-03-25 18:01:33,789 : [INFO]  Batch 109 initialized 
2023-03-25 18:01:34,370 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:34,823 : [INFO]  ------------------------- Batch 109 training: round 1 -------------------------
2023-03-25 18:01:40,143 : [INFO]  ------------------------- Batch round 1, loss: 0.5648 -------------------------
2023-03-25 18:01:40,143 : [INFO]  ------------------------- Batch 109, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:40,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:40,198 : [INFO]  ------------------------- Batch 109 training: round 2 -------------------------
2023-03-25 18:01:42,992 : [INFO]  ------------------------- Batch round 2, loss: 0.5628 -------------------------
2023-03-25 18:01:42,992 : [INFO]  ------------------------- Batch 109, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:43,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:43,095 : [INFO]  ------------------------- Batch 109 training: round 3 -------------------------
2023-03-25 18:01:45,938 : [INFO]  ------------------------- Batch round 3, loss: 0.5587 -------------------------
2023-03-25 18:01:45,938 : [INFO]  ------------------------- Batch 109, round 3: Sent local model to the server -------------------------
2023-03-25 18:01:46,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:46,017 : [INFO]  Batch number 109 model fetched from the server
2023-03-25 18:01:46,017 : [INFO]  ################ Batch 109: final global model evalution after 3 rounds ################
2023-03-25 18:01:47,817 : [INFO]  Batch 109: Training set : loss - 0.5617, accuracy - 0.75, recall - 0.8913, AUC - 0.8653, F1 - 0.781, precision - 0.6949, training time - -11.0 seconds
2023-03-25 18:01:47,817 : [INFO]  Batch 109: Testing set : loss - 0.628, accuracy - 0.6667, recall - 0.8529, AUC - 0.7534, F1 - 0.719, precision - 0.6214
2023-03-25 18:01:47,830 : [INFO]  Batch 110 initialized 
2023-03-25 18:01:48,400 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:01:48,849 : [INFO]  ------------------------- Batch 110 training: round 1 -------------------------
2023-03-25 18:01:54,248 : [INFO]  ------------------------- Batch round 1, loss: 0.5879 -------------------------
2023-03-25 18:01:54,249 : [INFO]  ------------------------- Batch 110, round 1: Sent local model to the server -------------------------
2023-03-25 18:01:54,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:54,266 : [INFO]  ------------------------- Batch 110 training: round 2 -------------------------
2023-03-25 18:01:57,121 : [INFO]  ------------------------- Batch round 2, loss: 0.5869 -------------------------
2023-03-25 18:01:57,122 : [INFO]  ------------------------- Batch 110, round 2: Sent local model to the server -------------------------
2023-03-25 18:01:57,236 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:01:57,238 : [INFO]  ------------------------- Batch 110 training: round 3 -------------------------
2023-03-25 18:02:00,076 : [INFO]  ------------------------- Batch round 3, loss: 0.5887 -------------------------
2023-03-25 18:02:00,076 : [INFO]  ------------------------- Batch 110, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:00,084 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:00,088 : [INFO]  Batch number 110 model fetched from the server
2023-03-25 18:02:00,088 : [INFO]  ################ Batch 110: final global model evalution after 3 rounds ################
2023-03-25 18:02:01,864 : [INFO]  Batch 110: Training set : loss - 0.6171, accuracy - 0.6413, recall - 0.913, AUC - 0.8146, F1 - 0.7179, precision - 0.5915, training time - -11.0 seconds
2023-03-25 18:02:01,865 : [INFO]  Batch 110: Testing set : loss - 0.6138, accuracy - 0.6275, recall - 0.9216, AUC - 0.8381, F1 - 0.7121, precision - 0.5802
2023-03-25 18:02:01,872 : [INFO]  Batch 111 initialized 
2023-03-25 18:02:02,441 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:02,896 : [INFO]  ------------------------- Batch 111 training: round 1 -------------------------
2023-03-25 18:02:08,113 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 18:02:08,113 : [INFO]  ------------------------- Batch 111, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:08,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:08,221 : [INFO]  ------------------------- Batch 111 training: round 2 -------------------------
2023-03-25 18:02:10,933 : [INFO]  ------------------------- Batch round 2, loss: 0.5663 -------------------------
2023-03-25 18:02:10,934 : [INFO]  ------------------------- Batch 111, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:11,040 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:11,043 : [INFO]  ------------------------- Batch 111 training: round 3 -------------------------
2023-03-25 18:02:13,744 : [INFO]  ------------------------- Batch round 3, loss: 0.5691 -------------------------
2023-03-25 18:02:13,744 : [INFO]  ------------------------- Batch 111, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:13,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:13,818 : [INFO]  Batch number 111 model fetched from the server
2023-03-25 18:02:13,819 : [INFO]  ################ Batch 111: final global model evalution after 3 rounds ################
2023-03-25 18:02:15,530 : [INFO]  Batch 111: Training set : loss - 0.589, accuracy - 0.7174, recall - 0.913, AUC - 0.8147, F1 - 0.7636, precision - 0.6562, training time - -11.0 seconds
2023-03-25 18:02:15,531 : [INFO]  Batch 111: Testing set : loss - 0.6009, accuracy - 0.6422, recall - 0.8725, AUC - 0.8085, F1 - 0.7092, precision - 0.5973
2023-03-25 18:02:15,545 : [INFO]  Batch 112 initialized 
2023-03-25 18:02:16,109 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:16,559 : [INFO]  ------------------------- Batch 112 training: round 1 -------------------------
2023-03-25 18:02:21,837 : [INFO]  ------------------------- Batch round 1, loss: 0.528 -------------------------
2023-03-25 18:02:21,837 : [INFO]  ------------------------- Batch 112, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:21,881 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:21,884 : [INFO]  ------------------------- Batch 112 training: round 2 -------------------------
2023-03-25 18:02:24,677 : [INFO]  ------------------------- Batch round 2, loss: 0.53 -------------------------
2023-03-25 18:02:24,677 : [INFO]  ------------------------- Batch 112, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:24,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:24,710 : [INFO]  ------------------------- Batch 112 training: round 3 -------------------------
2023-03-25 18:02:27,527 : [INFO]  ------------------------- Batch round 3, loss: 0.5288 -------------------------
2023-03-25 18:02:27,527 : [INFO]  ------------------------- Batch 112, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:27,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:27,576 : [INFO]  Batch number 112 model fetched from the server
2023-03-25 18:02:27,576 : [INFO]  ################ Batch 112: final global model evalution after 3 rounds ################
2023-03-25 18:02:29,328 : [INFO]  Batch 112: Training set : loss - 0.5429, accuracy - 0.7554, recall - 0.9565, AUC - 0.9205, F1 - 0.7964, precision - 0.6822, training time - -11.0 seconds
2023-03-25 18:02:29,328 : [INFO]  Batch 112: Testing set : loss - 0.5697, accuracy - 0.6961, recall - 0.8922, AUC - 0.8596, F1 - 0.7459, precision - 0.6408
2023-03-25 18:02:29,342 : [INFO]  Batch 113 initialized 
2023-03-25 18:02:29,914 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:30,379 : [INFO]  ------------------------- Batch 113 training: round 1 -------------------------
2023-03-25 18:02:35,670 : [INFO]  ------------------------- Batch round 1, loss: 0.5562 -------------------------
2023-03-25 18:02:35,670 : [INFO]  ------------------------- Batch 113, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:35,679 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:35,681 : [INFO]  ------------------------- Batch 113 training: round 2 -------------------------
2023-03-25 18:02:38,561 : [INFO]  ------------------------- Batch round 2, loss: 0.557 -------------------------
2023-03-25 18:02:38,561 : [INFO]  ------------------------- Batch 113, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:38,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:38,582 : [INFO]  ------------------------- Batch 113 training: round 3 -------------------------
2023-03-25 18:02:41,406 : [INFO]  ------------------------- Batch round 3, loss: 0.5534 -------------------------
2023-03-25 18:02:41,406 : [INFO]  ------------------------- Batch 113, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:41,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:41,416 : [INFO]  Batch number 113 model fetched from the server
2023-03-25 18:02:41,416 : [INFO]  ################ Batch 113: final global model evalution after 3 rounds ################
2023-03-25 18:02:43,474 : [INFO]  Batch 113: Training set : loss - 0.5654, accuracy - 0.7554, recall - 0.9457, AUC - 0.8877, F1 - 0.7945, precision - 0.685, training time - -11.0 seconds
2023-03-25 18:02:43,474 : [INFO]  Batch 113: Testing set : loss - 0.5865, accuracy - 0.6912, recall - 0.8725, AUC - 0.8355, F1 - 0.7386, precision - 0.6403
2023-03-25 18:02:43,488 : [INFO]  Batch 114 initialized 
2023-03-25 18:02:44,054 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:44,515 : [INFO]  ------------------------- Batch 114 training: round 1 -------------------------
2023-03-25 18:02:49,846 : [INFO]  ------------------------- Batch round 1, loss: 0.5852 -------------------------
2023-03-25 18:02:49,847 : [INFO]  ------------------------- Batch 114, round 1: Sent local model to the server -------------------------
2023-03-25 18:02:49,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:49,929 : [INFO]  ------------------------- Batch 114 training: round 2 -------------------------
2023-03-25 18:02:52,804 : [INFO]  ------------------------- Batch round 2, loss: 0.5809 -------------------------
2023-03-25 18:02:52,804 : [INFO]  ------------------------- Batch 114, round 2: Sent local model to the server -------------------------
2023-03-25 18:02:52,857 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:52,861 : [INFO]  ------------------------- Batch 114 training: round 3 -------------------------
2023-03-25 18:02:55,676 : [INFO]  ------------------------- Batch round 3, loss: 0.5855 -------------------------
2023-03-25 18:02:55,676 : [INFO]  ------------------------- Batch 114, round 3: Sent local model to the server -------------------------
2023-03-25 18:02:55,685 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:02:55,688 : [INFO]  Batch number 114 model fetched from the server
2023-03-25 18:02:55,689 : [INFO]  ################ Batch 114: final global model evalution after 3 rounds ################
2023-03-25 18:02:57,447 : [INFO]  Batch 114: Training set : loss - 0.5992, accuracy - 0.6685, recall - 0.913, AUC - 0.8294, F1 - 0.7336, precision - 0.6131, training time - -11.0 seconds
2023-03-25 18:02:57,447 : [INFO]  Batch 114: Testing set : loss - 0.5697, accuracy - 0.7108, recall - 0.9216, AUC - 0.8894, F1 - 0.7611, precision - 0.6483
2023-03-25 18:02:57,462 : [INFO]  Batch 115 initialized 
2023-03-25 18:02:58,036 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:02:58,501 : [INFO]  ------------------------- Batch 115 training: round 1 -------------------------
2023-03-25 18:03:03,987 : [INFO]  ------------------------- Batch round 1, loss: 0.5744 -------------------------
2023-03-25 18:03:03,988 : [INFO]  ------------------------- Batch 115, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:03,997 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:03,999 : [INFO]  ------------------------- Batch 115 training: round 2 -------------------------
2023-03-25 18:03:06,898 : [INFO]  ------------------------- Batch round 2, loss: 0.5791 -------------------------
2023-03-25 18:03:06,898 : [INFO]  ------------------------- Batch 115, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:06,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:06,909 : [INFO]  ------------------------- Batch 115 training: round 3 -------------------------
2023-03-25 18:03:09,836 : [INFO]  ------------------------- Batch round 3, loss: 0.5828 -------------------------
2023-03-25 18:03:09,837 : [INFO]  ------------------------- Batch 115, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:09,845 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:09,848 : [INFO]  Batch number 115 model fetched from the server
2023-03-25 18:03:09,848 : [INFO]  ################ Batch 115: final global model evalution after 3 rounds ################
2023-03-25 18:03:11,605 : [INFO]  Batch 115: Training set : loss - 0.5956, accuracy - 0.6739, recall - 0.8261, AUC - 0.7955, F1 - 0.717, precision - 0.6333, training time - -11.0 seconds
2023-03-25 18:03:11,605 : [INFO]  Batch 115: Testing set : loss - 0.5899, accuracy - 0.6863, recall - 0.8725, AUC - 0.8404, F1 - 0.7355, precision - 0.6357
2023-03-25 18:03:11,616 : [INFO]  Batch 116 initialized 
2023-03-25 18:03:12,178 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:12,632 : [INFO]  ------------------------- Batch 116 training: round 1 -------------------------
2023-03-25 18:03:18,020 : [INFO]  ------------------------- Batch round 1, loss: 0.5795 -------------------------
2023-03-25 18:03:18,020 : [INFO]  ------------------------- Batch 116, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:18,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:18,031 : [INFO]  ------------------------- Batch 116 training: round 2 -------------------------
2023-03-25 18:03:20,882 : [INFO]  ------------------------- Batch round 2, loss: 0.575 -------------------------
2023-03-25 18:03:20,882 : [INFO]  ------------------------- Batch 116, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:20,890 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:20,893 : [INFO]  ------------------------- Batch 116 training: round 3 -------------------------
2023-03-25 18:03:23,695 : [INFO]  ------------------------- Batch round 3, loss: 0.5731 -------------------------
2023-03-25 18:03:23,695 : [INFO]  ------------------------- Batch 116, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:23,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:23,742 : [INFO]  Batch number 116 model fetched from the server
2023-03-25 18:03:23,743 : [INFO]  ################ Batch 116: final global model evalution after 3 rounds ################
2023-03-25 18:03:25,481 : [INFO]  Batch 116: Training set : loss - 0.597, accuracy - 0.6793, recall - 0.8804, AUC - 0.8035, F1 - 0.733, precision - 0.6279, training time - -11.0 seconds
2023-03-25 18:03:25,481 : [INFO]  Batch 116: Testing set : loss - 0.578, accuracy - 0.6912, recall - 0.902, AUC - 0.8556, F1 - 0.7449, precision - 0.6345
2023-03-25 18:03:25,492 : [INFO]  Batch 117 initialized 
2023-03-25 18:03:26,067 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:26,537 : [INFO]  ------------------------- Batch 117 training: round 1 -------------------------
2023-03-25 18:03:31,973 : [INFO]  ------------------------- Batch round 1, loss: 0.5773 -------------------------
2023-03-25 18:03:31,973 : [INFO]  ------------------------- Batch 117, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:31,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:31,984 : [INFO]  ------------------------- Batch 117 training: round 2 -------------------------
2023-03-25 18:03:35,039 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-25 18:03:35,039 : [INFO]  ------------------------- Batch 117, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:35,049 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:35,053 : [INFO]  ------------------------- Batch 117 training: round 3 -------------------------
2023-03-25 18:03:37,925 : [INFO]  ------------------------- Batch round 3, loss: 0.5839 -------------------------
2023-03-25 18:03:37,925 : [INFO]  ------------------------- Batch 117, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:37,936 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:37,939 : [INFO]  Batch number 117 model fetched from the server
2023-03-25 18:03:37,939 : [INFO]  ################ Batch 117: final global model evalution after 3 rounds ################
2023-03-25 18:03:39,718 : [INFO]  Batch 117: Training set : loss - 0.587, accuracy - 0.7174, recall - 0.9239, AUC - 0.8306, F1 - 0.7658, precision - 0.6538, training time - -11.0 seconds
2023-03-25 18:03:39,718 : [INFO]  Batch 117: Testing set : loss - 0.5712, accuracy - 0.7255, recall - 0.8725, AUC - 0.8317, F1 - 0.7607, precision - 0.6742
2023-03-25 18:03:39,731 : [INFO]  Batch 118 initialized 
2023-03-25 18:03:40,308 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:40,784 : [INFO]  ------------------------- Batch 118 training: round 1 -------------------------
2023-03-25 18:03:46,163 : [INFO]  ------------------------- Batch round 1, loss: 0.557 -------------------------
2023-03-25 18:03:46,163 : [INFO]  ------------------------- Batch 118, round 1: Sent local model to the server -------------------------
2023-03-25 18:03:46,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:46,234 : [INFO]  ------------------------- Batch 118 training: round 2 -------------------------
2023-03-25 18:03:49,010 : [INFO]  ------------------------- Batch round 2, loss: 0.5621 -------------------------
2023-03-25 18:03:49,010 : [INFO]  ------------------------- Batch 118, round 2: Sent local model to the server -------------------------
2023-03-25 18:03:49,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:49,111 : [INFO]  ------------------------- Batch 118 training: round 3 -------------------------
2023-03-25 18:03:51,954 : [INFO]  ------------------------- Batch round 3, loss: 0.5571 -------------------------
2023-03-25 18:03:51,954 : [INFO]  ------------------------- Batch 118, round 3: Sent local model to the server -------------------------
2023-03-25 18:03:52,018 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:03:52,021 : [INFO]  Batch number 118 model fetched from the server
2023-03-25 18:03:52,021 : [INFO]  ################ Batch 118: final global model evalution after 3 rounds ################
2023-03-25 18:03:53,769 : [INFO]  Batch 118: Training set : loss - 0.5805, accuracy - 0.7228, recall - 0.8478, AUC - 0.8178, F1 - 0.7536, precision - 0.6783, training time - -11.0 seconds
2023-03-25 18:03:53,769 : [INFO]  Batch 118: Testing set : loss - 0.5915, accuracy - 0.6667, recall - 0.8627, AUC - 0.8192, F1 - 0.7213, precision - 0.6197
2023-03-25 18:03:53,783 : [INFO]  Batch 119 initialized 
2023-03-25 18:03:54,348 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:03:54,814 : [INFO]  ------------------------- Batch 119 training: round 1 -------------------------
2023-03-25 18:04:00,022 : [INFO]  ------------------------- Batch round 1, loss: 0.5424 -------------------------
2023-03-25 18:04:00,022 : [INFO]  ------------------------- Batch 119, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:00,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:00,287 : [INFO]  ------------------------- Batch 119 training: round 2 -------------------------
2023-03-25 18:04:03,072 : [INFO]  ------------------------- Batch round 2, loss: 0.5466 -------------------------
2023-03-25 18:04:03,073 : [INFO]  ------------------------- Batch 119, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:03,227 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:03,229 : [INFO]  ------------------------- Batch 119 training: round 3 -------------------------
2023-03-25 18:04:05,860 : [INFO]  ------------------------- Batch round 3, loss: 0.5475 -------------------------
2023-03-25 18:04:05,861 : [INFO]  ------------------------- Batch 119, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:06,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:06,082 : [INFO]  Batch number 119 model fetched from the server
2023-03-25 18:04:06,082 : [INFO]  ################ Batch 119: final global model evalution after 3 rounds ################
2023-03-25 18:04:07,809 : [INFO]  Batch 119: Training set : loss - 0.5576, accuracy - 0.7554, recall - 0.9348, AUC - 0.9074, F1 - 0.7926, precision - 0.688, training time - -11.0 seconds
2023-03-25 18:04:07,809 : [INFO]  Batch 119: Testing set : loss - 0.5841, accuracy - 0.7059, recall - 0.9314, AUC - 0.8533, F1 - 0.76, precision - 0.6419
2023-03-25 18:04:07,824 : [INFO]  Batch 120 initialized 
2023-03-25 18:04:08,403 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:08,870 : [INFO]  ------------------------- Batch 120 training: round 1 -------------------------
2023-03-25 18:04:14,324 : [INFO]  ------------------------- Batch round 1, loss: 0.5555 -------------------------
2023-03-25 18:04:14,325 : [INFO]  ------------------------- Batch 120, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:14,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:14,405 : [INFO]  ------------------------- Batch 120 training: round 2 -------------------------
2023-03-25 18:04:17,287 : [INFO]  ------------------------- Batch round 2, loss: 0.5587 -------------------------
2023-03-25 18:04:17,288 : [INFO]  ------------------------- Batch 120, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:17,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:17,299 : [INFO]  ------------------------- Batch 120 training: round 3 -------------------------
2023-03-25 18:04:20,156 : [INFO]  ------------------------- Batch round 3, loss: 0.5534 -------------------------
2023-03-25 18:04:20,156 : [INFO]  ------------------------- Batch 120, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:20,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:20,290 : [INFO]  Batch number 120 model fetched from the server
2023-03-25 18:04:20,290 : [INFO]  ################ Batch 120: final global model evalution after 3 rounds ################
2023-03-25 18:04:22,052 : [INFO]  Batch 120: Training set : loss - 0.5598, accuracy - 0.7446, recall - 0.8696, AUC - 0.8534, F1 - 0.7729, precision - 0.6957, training time - -11.0 seconds
2023-03-25 18:04:22,052 : [INFO]  Batch 120: Testing set : loss - 0.5788, accuracy - 0.7255, recall - 0.9314, AUC - 0.8522, F1 - 0.7724, precision - 0.6597
2023-03-25 18:04:22,067 : [INFO]  Batch 121 initialized 
2023-03-25 18:04:22,692 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:23,159 : [INFO]  ------------------------- Batch 121 training: round 1 -------------------------
2023-03-25 18:04:28,620 : [INFO]  ------------------------- Batch round 1, loss: 0.5626 -------------------------
2023-03-25 18:04:28,620 : [INFO]  ------------------------- Batch 121, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:28,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:28,744 : [INFO]  ------------------------- Batch 121 training: round 2 -------------------------
2023-03-25 18:04:31,556 : [INFO]  ------------------------- Batch round 2, loss: 0.5628 -------------------------
2023-03-25 18:04:31,556 : [INFO]  ------------------------- Batch 121, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:31,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:31,812 : [INFO]  ------------------------- Batch 121 training: round 3 -------------------------
2023-03-25 18:04:34,529 : [INFO]  ------------------------- Batch round 3, loss: 0.5628 -------------------------
2023-03-25 18:04:34,529 : [INFO]  ------------------------- Batch 121, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:34,753 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:34,755 : [INFO]  Batch number 121 model fetched from the server
2023-03-25 18:04:34,756 : [INFO]  ################ Batch 121: final global model evalution after 3 rounds ################
2023-03-25 18:04:36,473 : [INFO]  Batch 121: Training set : loss - 0.5834, accuracy - 0.6304, recall - 0.913, AUC - 0.8529, F1 - 0.7119, precision - 0.5833, training time - -12.0 seconds
2023-03-25 18:04:36,473 : [INFO]  Batch 121: Testing set : loss - 0.5554, accuracy - 0.7255, recall - 0.9216, AUC - 0.9026, F1 - 0.7705, precision - 0.662
2023-03-25 18:04:36,489 : [INFO]  Batch 122 initialized 
2023-03-25 18:04:37,057 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:37,503 : [INFO]  ------------------------- Batch 122 training: round 1 -------------------------
2023-03-25 18:04:43,224 : [INFO]  ------------------------- Batch round 1, loss: 0.5674 -------------------------
2023-03-25 18:04:43,224 : [INFO]  ------------------------- Batch 122, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:43,414 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:43,417 : [INFO]  ------------------------- Batch 122 training: round 2 -------------------------
2023-03-25 18:04:46,322 : [INFO]  ------------------------- Batch round 2, loss: 0.5774 -------------------------
2023-03-25 18:04:46,322 : [INFO]  ------------------------- Batch 122, round 2: Sent local model to the server -------------------------
2023-03-25 18:04:46,337 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:46,340 : [INFO]  ------------------------- Batch 122 training: round 3 -------------------------
2023-03-25 18:04:49,282 : [INFO]  ------------------------- Batch round 3, loss: 0.5743 -------------------------
2023-03-25 18:04:49,283 : [INFO]  ------------------------- Batch 122, round 3: Sent local model to the server -------------------------
2023-03-25 18:04:49,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:49,301 : [INFO]  Batch number 122 model fetched from the server
2023-03-25 18:04:49,302 : [INFO]  ################ Batch 122: final global model evalution after 3 rounds ################
2023-03-25 18:04:51,249 : [INFO]  Batch 122: Training set : loss - 0.5901, accuracy - 0.6848, recall - 0.8152, AUC - 0.8051, F1 - 0.7212, precision - 0.6466, training time - -12.0 seconds
2023-03-25 18:04:51,250 : [INFO]  Batch 122: Testing set : loss - 0.5882, accuracy - 0.6765, recall - 0.8431, AUC - 0.8236, F1 - 0.7227, precision - 0.6324
2023-03-25 18:04:51,265 : [INFO]  Batch 123 initialized 
2023-03-25 18:04:51,830 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:04:52,308 : [INFO]  ------------------------- Batch 123 training: round 1 -------------------------
2023-03-25 18:04:57,767 : [INFO]  ------------------------- Batch round 1, loss: 0.5756 -------------------------
2023-03-25 18:04:57,767 : [INFO]  ------------------------- Batch 123, round 1: Sent local model to the server -------------------------
2023-03-25 18:04:57,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:04:57,837 : [INFO]  ------------------------- Batch 123 training: round 2 -------------------------
2023-03-25 18:05:00,667 : [INFO]  ------------------------- Batch round 2, loss: 0.576 -------------------------
2023-03-25 18:05:00,667 : [INFO]  ------------------------- Batch 123, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:00,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:00,837 : [INFO]  ------------------------- Batch 123 training: round 3 -------------------------
2023-03-25 18:05:03,648 : [INFO]  ------------------------- Batch round 3, loss: 0.5777 -------------------------
2023-03-25 18:05:03,648 : [INFO]  ------------------------- Batch 123, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:03,671 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:03,674 : [INFO]  Batch number 123 model fetched from the server
2023-03-25 18:05:03,674 : [INFO]  ################ Batch 123: final global model evalution after 3 rounds ################
2023-03-25 18:05:05,501 : [INFO]  Batch 123: Training set : loss - 0.5801, accuracy - 0.7228, recall - 0.9022, AUC - 0.8333, F1 - 0.765, precision - 0.664, training time - -11.0 seconds
2023-03-25 18:05:05,501 : [INFO]  Batch 123: Testing set : loss - 0.5921, accuracy - 0.7059, recall - 0.8529, AUC - 0.8088, F1 - 0.7436, precision - 0.6591
2023-03-25 18:05:05,519 : [INFO]  Batch 124 initialized 
2023-03-25 18:05:06,132 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:06,607 : [INFO]  ------------------------- Batch 124 training: round 1 -------------------------
2023-03-25 18:05:12,319 : [INFO]  ------------------------- Batch round 1, loss: 0.5852 -------------------------
2023-03-25 18:05:12,320 : [INFO]  ------------------------- Batch 124, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:12,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:12,331 : [INFO]  ------------------------- Batch 124 training: round 2 -------------------------
2023-03-25 18:05:15,404 : [INFO]  ------------------------- Batch round 2, loss: 0.5857 -------------------------
2023-03-25 18:05:15,404 : [INFO]  ------------------------- Batch 124, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:15,412 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:15,415 : [INFO]  ------------------------- Batch 124 training: round 3 -------------------------
2023-03-25 18:05:18,418 : [INFO]  ------------------------- Batch round 3, loss: 0.5884 -------------------------
2023-03-25 18:05:18,418 : [INFO]  ------------------------- Batch 124, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:18,531 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:18,534 : [INFO]  Batch number 124 model fetched from the server
2023-03-25 18:05:18,534 : [INFO]  ################ Batch 124: final global model evalution after 3 rounds ################
2023-03-25 18:05:20,361 : [INFO]  Batch 124: Training set : loss - 0.5992, accuracy - 0.6739, recall - 0.7935, AUC - 0.7772, F1 - 0.7087, precision - 0.6404, training time - -12.0 seconds
2023-03-25 18:05:20,361 : [INFO]  Batch 124: Testing set : loss - 0.5629, accuracy - 0.7304, recall - 0.8824, AUC - 0.857, F1 - 0.766, precision - 0.6767
2023-03-25 18:05:20,370 : [INFO]  Batch 125 initialized 
2023-03-25 18:05:20,914 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:21,396 : [INFO]  ------------------------- Batch 125 training: round 1 -------------------------
2023-03-25 18:05:26,972 : [INFO]  ------------------------- Batch round 1, loss: 0.591 -------------------------
2023-03-25 18:05:26,972 : [INFO]  ------------------------- Batch 125, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:26,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:26,985 : [INFO]  ------------------------- Batch 125 training: round 2 -------------------------
2023-03-25 18:05:30,069 : [INFO]  ------------------------- Batch round 2, loss: 0.5866 -------------------------
2023-03-25 18:05:30,069 : [INFO]  ------------------------- Batch 125, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:30,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:30,080 : [INFO]  ------------------------- Batch 125 training: round 3 -------------------------
2023-03-25 18:05:33,181 : [INFO]  ------------------------- Batch round 3, loss: 0.5915 -------------------------
2023-03-25 18:05:33,181 : [INFO]  ------------------------- Batch 125, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:33,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:33,192 : [INFO]  Batch number 125 model fetched from the server
2023-03-25 18:05:33,192 : [INFO]  ################ Batch 125: final global model evalution after 3 rounds ################
2023-03-25 18:05:35,078 : [INFO]  Batch 125: Training set : loss - 0.5896, accuracy - 0.6739, recall - 0.8804, AUC - 0.8288, F1 - 0.7297, precision - 0.6231, training time - -12.0 seconds
2023-03-25 18:05:35,078 : [INFO]  Batch 125: Testing set : loss - 0.6054, accuracy - 0.6716, recall - 0.8824, AUC - 0.7937, F1 - 0.7287, precision - 0.6207
2023-03-25 18:05:35,086 : [INFO]  Batch 126 initialized 
2023-03-25 18:05:35,642 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:36,130 : [INFO]  ------------------------- Batch 126 training: round 1 -------------------------
2023-03-25 18:05:41,659 : [INFO]  ------------------------- Batch round 1, loss: 0.6192 -------------------------
2023-03-25 18:05:41,659 : [INFO]  ------------------------- Batch 126, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:41,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:41,670 : [INFO]  ------------------------- Batch 126 training: round 2 -------------------------
2023-03-25 18:05:44,631 : [INFO]  ------------------------- Batch round 2, loss: 0.6161 -------------------------
2023-03-25 18:05:44,631 : [INFO]  ------------------------- Batch 126, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:44,639 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:44,642 : [INFO]  ------------------------- Batch 126 training: round 3 -------------------------
2023-03-25 18:05:47,651 : [INFO]  ------------------------- Batch round 3, loss: 0.617 -------------------------
2023-03-25 18:05:47,652 : [INFO]  ------------------------- Batch 126, round 3: Sent local model to the server -------------------------
2023-03-25 18:05:47,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:47,667 : [INFO]  Batch number 126 model fetched from the server
2023-03-25 18:05:47,667 : [INFO]  ################ Batch 126: final global model evalution after 3 rounds ################
2023-03-25 18:05:49,518 : [INFO]  Batch 126: Training set : loss - 0.6276, accuracy - 0.6685, recall - 0.8587, AUC - 0.738, F1 - 0.7215, precision - 0.622, training time - -12.0 seconds
2023-03-25 18:05:49,518 : [INFO]  Batch 126: Testing set : loss - 0.5719, accuracy - 0.75, recall - 0.9314, AUC - 0.8583, F1 - 0.7884, precision - 0.6835
2023-03-25 18:05:49,556 : [INFO]  Batch 127 initialized 
2023-03-25 18:05:50,122 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:05:50,581 : [INFO]  ------------------------- Batch 127 training: round 1 -------------------------
2023-03-25 18:05:55,867 : [INFO]  ------------------------- Batch round 1, loss: 0.6083 -------------------------
2023-03-25 18:05:55,868 : [INFO]  ------------------------- Batch 127, round 1: Sent local model to the server -------------------------
2023-03-25 18:05:55,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:55,880 : [INFO]  ------------------------- Batch 127 training: round 2 -------------------------
2023-03-25 18:05:58,657 : [INFO]  ------------------------- Batch round 2, loss: 0.612 -------------------------
2023-03-25 18:05:58,657 : [INFO]  ------------------------- Batch 127, round 2: Sent local model to the server -------------------------
2023-03-25 18:05:58,813 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:05:58,816 : [INFO]  ------------------------- Batch 127 training: round 3 -------------------------
2023-03-25 18:06:01,591 : [INFO]  ------------------------- Batch round 3, loss: 0.6085 -------------------------
2023-03-25 18:06:01,592 : [INFO]  ------------------------- Batch 127, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:01,601 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:01,604 : [INFO]  Batch number 127 model fetched from the server
2023-03-25 18:06:01,604 : [INFO]  ################ Batch 127: final global model evalution after 3 rounds ################
2023-03-25 18:06:03,362 : [INFO]  Batch 127: Training set : loss - 0.6366, accuracy - 0.6522, recall - 0.9674, AUC - 0.7554, F1 - 0.7355, precision - 0.5933, training time - -11.0 seconds
2023-03-25 18:06:03,362 : [INFO]  Batch 127: Testing set : loss - 0.665, accuracy - 0.6225, recall - 0.9608, AUC - 0.691, F1 - 0.7179, precision - 0.5731
2023-03-25 18:06:03,378 : [INFO]  Batch 128 initialized 
2023-03-25 18:06:03,943 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:04,427 : [INFO]  ------------------------- Batch 128 training: round 1 -------------------------
2023-03-25 18:06:09,935 : [INFO]  ------------------------- Batch round 1, loss: 0.5669 -------------------------
2023-03-25 18:06:09,936 : [INFO]  ------------------------- Batch 128, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:09,945 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:09,947 : [INFO]  ------------------------- Batch 128 training: round 2 -------------------------
2023-03-25 18:06:12,800 : [INFO]  ------------------------- Batch round 2, loss: 0.5671 -------------------------
2023-03-25 18:06:12,800 : [INFO]  ------------------------- Batch 128, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:12,810 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:12,812 : [INFO]  ------------------------- Batch 128 training: round 3 -------------------------
2023-03-25 18:06:15,556 : [INFO]  ------------------------- Batch round 3, loss: 0.5734 -------------------------
2023-03-25 18:06:15,556 : [INFO]  ------------------------- Batch 128, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:15,565 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:15,567 : [INFO]  Batch number 128 model fetched from the server
2023-03-25 18:06:15,567 : [INFO]  ################ Batch 128: final global model evalution after 3 rounds ################
2023-03-25 18:06:17,372 : [INFO]  Batch 128: Training set : loss - 0.5796, accuracy - 0.6848, recall - 0.8478, AUC - 0.8215, F1 - 0.729, precision - 0.6393, training time - -11.0 seconds
2023-03-25 18:06:17,373 : [INFO]  Batch 128: Testing set : loss - 0.5685, accuracy - 0.6814, recall - 0.8137, AUC - 0.8433, F1 - 0.7186, precision - 0.6434
2023-03-25 18:06:17,386 : [INFO]  Batch 129 initialized 
2023-03-25 18:06:17,973 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:18,460 : [INFO]  ------------------------- Batch 129 training: round 1 -------------------------
2023-03-25 18:06:23,808 : [INFO]  ------------------------- Batch round 1, loss: 0.576 -------------------------
2023-03-25 18:06:23,809 : [INFO]  ------------------------- Batch 129, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:23,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:23,820 : [INFO]  ------------------------- Batch 129 training: round 2 -------------------------
2023-03-25 18:06:26,803 : [INFO]  ------------------------- Batch round 2, loss: 0.5772 -------------------------
2023-03-25 18:06:26,803 : [INFO]  ------------------------- Batch 129, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:26,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:26,814 : [INFO]  ------------------------- Batch 129 training: round 3 -------------------------
2023-03-25 18:06:29,635 : [INFO]  ------------------------- Batch round 3, loss: 0.5766 -------------------------
2023-03-25 18:06:29,635 : [INFO]  ------------------------- Batch 129, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:29,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:29,647 : [INFO]  Batch number 129 model fetched from the server
2023-03-25 18:06:29,648 : [INFO]  ################ Batch 129: final global model evalution after 3 rounds ################
2023-03-25 18:06:31,462 : [INFO]  Batch 129: Training set : loss - 0.5819, accuracy - 0.7283, recall - 0.9022, AUC - 0.8248, F1 - 0.7685, precision - 0.6694, training time - -11.0 seconds
2023-03-25 18:06:31,462 : [INFO]  Batch 129: Testing set : loss - 0.575, accuracy - 0.7108, recall - 0.9216, AUC - 0.8674, F1 - 0.7611, precision - 0.6483
2023-03-25 18:06:31,475 : [INFO]  Batch 130 initialized 
2023-03-25 18:06:32,064 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:32,553 : [INFO]  ------------------------- Batch 130 training: round 1 -------------------------
2023-03-25 18:06:38,011 : [INFO]  ------------------------- Batch round 1, loss: 0.5547 -------------------------
2023-03-25 18:06:38,011 : [INFO]  ------------------------- Batch 130, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:38,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:38,023 : [INFO]  ------------------------- Batch 130 training: round 2 -------------------------
2023-03-25 18:06:40,907 : [INFO]  ------------------------- Batch round 2, loss: 0.5482 -------------------------
2023-03-25 18:06:40,907 : [INFO]  ------------------------- Batch 130, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:40,917 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:40,919 : [INFO]  ------------------------- Batch 130 training: round 3 -------------------------
2023-03-25 18:06:43,772 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 18:06:43,772 : [INFO]  ------------------------- Batch 130, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:43,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:43,785 : [INFO]  Batch number 130 model fetched from the server
2023-03-25 18:06:43,785 : [INFO]  ################ Batch 130: final global model evalution after 3 rounds ################
2023-03-25 18:06:45,528 : [INFO]  Batch 130: Training set : loss - 0.5589, accuracy - 0.7717, recall - 0.9239, AUC - 0.8862, F1 - 0.8019, precision - 0.7083, training time - -11.0 seconds
2023-03-25 18:06:45,528 : [INFO]  Batch 130: Testing set : loss - 0.5817, accuracy - 0.6863, recall - 0.8627, AUC - 0.8451, F1 - 0.7333, precision - 0.6377
2023-03-25 18:06:45,542 : [INFO]  Batch 131 initialized 
2023-03-25 18:06:46,105 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:06:46,593 : [INFO]  ------------------------- Batch 131 training: round 1 -------------------------
2023-03-25 18:06:51,946 : [INFO]  ------------------------- Batch round 1, loss: 0.5603 -------------------------
2023-03-25 18:06:51,946 : [INFO]  ------------------------- Batch 131, round 1: Sent local model to the server -------------------------
2023-03-25 18:06:51,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:51,957 : [INFO]  ------------------------- Batch 131 training: round 2 -------------------------
2023-03-25 18:06:54,790 : [INFO]  ------------------------- Batch round 2, loss: 0.5622 -------------------------
2023-03-25 18:06:54,790 : [INFO]  ------------------------- Batch 131, round 2: Sent local model to the server -------------------------
2023-03-25 18:06:54,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:54,801 : [INFO]  ------------------------- Batch 131 training: round 3 -------------------------
2023-03-25 18:06:57,669 : [INFO]  ------------------------- Batch round 3, loss: 0.559 -------------------------
2023-03-25 18:06:57,669 : [INFO]  ------------------------- Batch 131, round 3: Sent local model to the server -------------------------
2023-03-25 18:06:57,685 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:06:57,688 : [INFO]  Batch number 131 model fetched from the server
2023-03-25 18:06:57,688 : [INFO]  ################ Batch 131: final global model evalution after 3 rounds ################
2023-03-25 18:06:59,499 : [INFO]  Batch 131: Training set : loss - 0.5773, accuracy - 0.7065, recall - 0.8587, AUC - 0.8056, F1 - 0.7453, precision - 0.6583, training time - -11.0 seconds
2023-03-25 18:06:59,499 : [INFO]  Batch 131: Testing set : loss - 0.5916, accuracy - 0.6961, recall - 0.8922, AUC - 0.7994, F1 - 0.7459, precision - 0.6408
2023-03-25 18:06:59,509 : [INFO]  Batch 132 initialized 
2023-03-25 18:07:00,093 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:00,590 : [INFO]  ------------------------- Batch 132 training: round 1 -------------------------
2023-03-25 18:07:06,004 : [INFO]  ------------------------- Batch round 1, loss: 0.5837 -------------------------
2023-03-25 18:07:06,004 : [INFO]  ------------------------- Batch 132, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:06,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:06,085 : [INFO]  ------------------------- Batch 132 training: round 2 -------------------------
2023-03-25 18:07:08,892 : [INFO]  ------------------------- Batch round 2, loss: 0.5857 -------------------------
2023-03-25 18:07:08,892 : [INFO]  ------------------------- Batch 132, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:08,946 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:08,949 : [INFO]  ------------------------- Batch 132 training: round 3 -------------------------
2023-03-25 18:07:11,944 : [INFO]  ------------------------- Batch round 3, loss: 0.5882 -------------------------
2023-03-25 18:07:11,944 : [INFO]  ------------------------- Batch 132, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:11,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:11,955 : [INFO]  Batch number 132 model fetched from the server
2023-03-25 18:07:11,955 : [INFO]  ################ Batch 132: final global model evalution after 3 rounds ################
2023-03-25 18:07:13,681 : [INFO]  Batch 132: Training set : loss - 0.5957, accuracy - 0.7011, recall - 0.8478, AUC - 0.7999, F1 - 0.7393, precision - 0.6555, training time - -11.0 seconds
2023-03-25 18:07:13,681 : [INFO]  Batch 132: Testing set : loss - 0.5797, accuracy - 0.7255, recall - 0.902, AUC - 0.8441, F1 - 0.7667, precision - 0.6667
2023-03-25 18:07:13,694 : [INFO]  Batch 133 initialized 
2023-03-25 18:07:14,260 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:14,758 : [INFO]  ------------------------- Batch 133 training: round 1 -------------------------
2023-03-25 18:07:20,113 : [INFO]  ------------------------- Batch round 1, loss: 0.5894 -------------------------
2023-03-25 18:07:20,113 : [INFO]  ------------------------- Batch 133, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:20,132 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:20,134 : [INFO]  ------------------------- Batch 133 training: round 2 -------------------------
2023-03-25 18:07:22,876 : [INFO]  ------------------------- Batch round 2, loss: 0.5868 -------------------------
2023-03-25 18:07:22,876 : [INFO]  ------------------------- Batch 133, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:22,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:22,987 : [INFO]  ------------------------- Batch 133 training: round 3 -------------------------
2023-03-25 18:07:25,815 : [INFO]  ------------------------- Batch round 3, loss: 0.5835 -------------------------
2023-03-25 18:07:25,815 : [INFO]  ------------------------- Batch 133, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:25,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:25,974 : [INFO]  Batch number 133 model fetched from the server
2023-03-25 18:07:25,974 : [INFO]  ################ Batch 133: final global model evalution after 3 rounds ################
2023-03-25 18:07:27,742 : [INFO]  Batch 133: Training set : loss - 0.598, accuracy - 0.6793, recall - 0.8804, AUC - 0.8059, F1 - 0.733, precision - 0.6279, training time - -11.0 seconds
2023-03-25 18:07:27,742 : [INFO]  Batch 133: Testing set : loss - 0.556, accuracy - 0.7255, recall - 0.8922, AUC - 0.8738, F1 - 0.7647, precision - 0.6691
2023-03-25 18:07:27,756 : [INFO]  Batch 134 initialized 
2023-03-25 18:07:28,335 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:28,820 : [INFO]  ------------------------- Batch 134 training: round 1 -------------------------
2023-03-25 18:07:34,243 : [INFO]  ------------------------- Batch round 1, loss: 0.5552 -------------------------
2023-03-25 18:07:34,243 : [INFO]  ------------------------- Batch 134, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:34,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:34,433 : [INFO]  ------------------------- Batch 134 training: round 2 -------------------------
2023-03-25 18:07:37,297 : [INFO]  ------------------------- Batch round 2, loss: 0.5509 -------------------------
2023-03-25 18:07:37,297 : [INFO]  ------------------------- Batch 134, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:37,397 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:37,400 : [INFO]  ------------------------- Batch 134 training: round 3 -------------------------
2023-03-25 18:07:40,192 : [INFO]  ------------------------- Batch round 3, loss: 0.5577 -------------------------
2023-03-25 18:07:40,192 : [INFO]  ------------------------- Batch 134, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:40,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:40,299 : [INFO]  Batch number 134 model fetched from the server
2023-03-25 18:07:40,299 : [INFO]  ################ Batch 134: final global model evalution after 3 rounds ################
2023-03-25 18:07:42,087 : [INFO]  Batch 134: Training set : loss - 0.5646, accuracy - 0.7228, recall - 0.9348, AUC - 0.878, F1 - 0.7713, precision - 0.6565, training time - -11.0 seconds
2023-03-25 18:07:42,087 : [INFO]  Batch 134: Testing set : loss - 0.5969, accuracy - 0.6863, recall - 0.8529, AUC - 0.8364, F1 - 0.7311, precision - 0.6397
2023-03-25 18:07:42,105 : [INFO]  Batch 135 initialized 
2023-03-25 18:07:42,696 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:43,171 : [INFO]  ------------------------- Batch 135 training: round 1 -------------------------
2023-03-25 18:07:48,731 : [INFO]  ------------------------- Batch round 1, loss: 0.5291 -------------------------
2023-03-25 18:07:48,732 : [INFO]  ------------------------- Batch 135, round 1: Sent local model to the server -------------------------
2023-03-25 18:07:48,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:48,864 : [INFO]  ------------------------- Batch 135 training: round 2 -------------------------
2023-03-25 18:07:51,751 : [INFO]  ------------------------- Batch round 2, loss: 0.5431 -------------------------
2023-03-25 18:07:51,752 : [INFO]  ------------------------- Batch 135, round 2: Sent local model to the server -------------------------
2023-03-25 18:07:51,829 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:51,832 : [INFO]  ------------------------- Batch 135 training: round 3 -------------------------
2023-03-25 18:07:54,649 : [INFO]  ------------------------- Batch round 3, loss: 0.5368 -------------------------
2023-03-25 18:07:54,649 : [INFO]  ------------------------- Batch 135, round 3: Sent local model to the server -------------------------
2023-03-25 18:07:54,726 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:07:54,729 : [INFO]  Batch number 135 model fetched from the server
2023-03-25 18:07:54,729 : [INFO]  ################ Batch 135: final global model evalution after 3 rounds ################
2023-03-25 18:07:56,484 : [INFO]  Batch 135: Training set : loss - 0.5441, accuracy - 0.75, recall - 0.913, AUC - 0.913, F1 - 0.785, precision - 0.6885, training time - -12.0 seconds
2023-03-25 18:07:56,484 : [INFO]  Batch 135: Testing set : loss - 0.5711, accuracy - 0.6961, recall - 0.8922, AUC - 0.852, F1 - 0.7459, precision - 0.6408
2023-03-25 18:07:56,499 : [INFO]  Batch 136 initialized 
2023-03-25 18:07:57,074 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:07:57,578 : [INFO]  ------------------------- Batch 136 training: round 1 -------------------------
2023-03-25 18:08:02,969 : [INFO]  ------------------------- Batch round 1, loss: 0.5859 -------------------------
2023-03-25 18:08:02,969 : [INFO]  ------------------------- Batch 136, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:03,191 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:03,195 : [INFO]  ------------------------- Batch 136 training: round 2 -------------------------
2023-03-25 18:08:05,972 : [INFO]  ------------------------- Batch round 2, loss: 0.5838 -------------------------
2023-03-25 18:08:05,972 : [INFO]  ------------------------- Batch 136, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:06,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:06,046 : [INFO]  ------------------------- Batch 136 training: round 3 -------------------------
2023-03-25 18:08:08,844 : [INFO]  ------------------------- Batch round 3, loss: 0.5887 -------------------------
2023-03-25 18:08:08,844 : [INFO]  ------------------------- Batch 136, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:08,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:08,973 : [INFO]  Batch number 136 model fetched from the server
2023-03-25 18:08:08,973 : [INFO]  ################ Batch 136: final global model evalution after 3 rounds ################
2023-03-25 18:08:10,744 : [INFO]  Batch 136: Training set : loss - 0.6033, accuracy - 0.6522, recall - 0.8804, AUC - 0.8251, F1 - 0.7168, precision - 0.6045, training time - -11.0 seconds
2023-03-25 18:08:10,744 : [INFO]  Batch 136: Testing set : loss - 0.596, accuracy - 0.652, recall - 0.8627, AUC - 0.8346, F1 - 0.7126, precision - 0.6069
2023-03-25 18:08:10,781 : [INFO]  Batch 137 initialized 
2023-03-25 18:08:11,354 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:11,849 : [INFO]  ------------------------- Batch 137 training: round 1 -------------------------
2023-03-25 18:08:17,178 : [INFO]  ------------------------- Batch round 1, loss: 0.5767 -------------------------
2023-03-25 18:08:17,178 : [INFO]  ------------------------- Batch 137, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:17,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:17,334 : [INFO]  ------------------------- Batch 137 training: round 2 -------------------------
2023-03-25 18:08:20,219 : [INFO]  ------------------------- Batch round 2, loss: 0.5702 -------------------------
2023-03-25 18:08:20,220 : [INFO]  ------------------------- Batch 137, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:20,355 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:20,359 : [INFO]  ------------------------- Batch 137 training: round 3 -------------------------
2023-03-25 18:08:23,234 : [INFO]  ------------------------- Batch round 3, loss: 0.5789 -------------------------
2023-03-25 18:08:23,234 : [INFO]  ------------------------- Batch 137, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:23,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:23,421 : [INFO]  Batch number 137 model fetched from the server
2023-03-25 18:08:23,422 : [INFO]  ################ Batch 137: final global model evalution after 3 rounds ################
2023-03-25 18:08:25,174 : [INFO]  Batch 137: Training set : loss - 0.5846, accuracy - 0.7228, recall - 0.837, AUC - 0.8021, F1 - 0.7512, precision - 0.6814, training time - -12.0 seconds
2023-03-25 18:08:25,174 : [INFO]  Batch 137: Testing set : loss - 0.5607, accuracy - 0.7549, recall - 0.902, AUC - 0.8589, F1 - 0.7863, precision - 0.697
2023-03-25 18:08:25,196 : [INFO]  Batch 138 initialized 
2023-03-25 18:08:25,780 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:26,282 : [INFO]  ------------------------- Batch 138 training: round 1 -------------------------
2023-03-25 18:08:31,851 : [INFO]  ------------------------- Batch round 1, loss: 0.5902 -------------------------
2023-03-25 18:08:31,851 : [INFO]  ------------------------- Batch 138, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:31,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:31,894 : [INFO]  ------------------------- Batch 138 training: round 2 -------------------------
2023-03-25 18:08:35,032 : [INFO]  ------------------------- Batch round 2, loss: 0.5875 -------------------------
2023-03-25 18:08:35,032 : [INFO]  ------------------------- Batch 138, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:35,062 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:35,070 : [INFO]  ------------------------- Batch 138 training: round 3 -------------------------
2023-03-25 18:08:38,064 : [INFO]  ------------------------- Batch round 3, loss: 0.5847 -------------------------
2023-03-25 18:08:38,064 : [INFO]  ------------------------- Batch 138, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:38,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:38,077 : [INFO]  Batch number 138 model fetched from the server
2023-03-25 18:08:38,077 : [INFO]  ################ Batch 138: final global model evalution after 3 rounds ################
2023-03-25 18:08:39,846 : [INFO]  Batch 138: Training set : loss - 0.6087, accuracy - 0.6304, recall - 0.9239, AUC - 0.8408, F1 - 0.7143, precision - 0.5822, training time - -12.0 seconds
2023-03-25 18:08:39,846 : [INFO]  Batch 138: Testing set : loss - 0.55, accuracy - 0.7206, recall - 0.9216, AUC - 0.9165, F1 - 0.7673, precision - 0.6573
2023-03-25 18:08:39,860 : [INFO]  Batch 139 initialized 
2023-03-25 18:08:40,431 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:40,921 : [INFO]  ------------------------- Batch 139 training: round 1 -------------------------
2023-03-25 18:08:46,304 : [INFO]  ------------------------- Batch round 1, loss: 0.5642 -------------------------
2023-03-25 18:08:46,304 : [INFO]  ------------------------- Batch 139, round 1: Sent local model to the server -------------------------
2023-03-25 18:08:46,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:46,403 : [INFO]  ------------------------- Batch 139 training: round 2 -------------------------
2023-03-25 18:08:49,297 : [INFO]  ------------------------- Batch round 2, loss: 0.571 -------------------------
2023-03-25 18:08:49,298 : [INFO]  ------------------------- Batch 139, round 2: Sent local model to the server -------------------------
2023-03-25 18:08:49,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:49,380 : [INFO]  ------------------------- Batch 139 training: round 3 -------------------------
2023-03-25 18:08:52,235 : [INFO]  ------------------------- Batch round 3, loss: 0.5606 -------------------------
2023-03-25 18:08:52,235 : [INFO]  ------------------------- Batch 139, round 3: Sent local model to the server -------------------------
2023-03-25 18:08:52,290 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:08:52,293 : [INFO]  Batch number 139 model fetched from the server
2023-03-25 18:08:52,293 : [INFO]  ################ Batch 139: final global model evalution after 3 rounds ################
2023-03-25 18:08:54,098 : [INFO]  Batch 139: Training set : loss - 0.5724, accuracy - 0.7283, recall - 0.8804, AUC - 0.8283, F1 - 0.7642, precision - 0.675, training time - -11.0 seconds
2023-03-25 18:08:54,099 : [INFO]  Batch 139: Testing set : loss - 0.5809, accuracy - 0.6961, recall - 0.9314, AUC - 0.8783, F1 - 0.754, precision - 0.6333
2023-03-25 18:08:54,108 : [INFO]  Batch 140 initialized 
2023-03-25 18:08:54,678 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:08:55,187 : [INFO]  ------------------------- Batch 140 training: round 1 -------------------------
2023-03-25 18:09:00,569 : [INFO]  ------------------------- Batch round 1, loss: 0.5737 -------------------------
2023-03-25 18:09:00,569 : [INFO]  ------------------------- Batch 140, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:00,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:00,665 : [INFO]  ------------------------- Batch 140 training: round 2 -------------------------
2023-03-25 18:09:03,618 : [INFO]  ------------------------- Batch round 2, loss: 0.5698 -------------------------
2023-03-25 18:09:03,618 : [INFO]  ------------------------- Batch 140, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:03,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:03,699 : [INFO]  ------------------------- Batch 140 training: round 3 -------------------------
2023-03-25 18:09:06,691 : [INFO]  ------------------------- Batch round 3, loss: 0.572 -------------------------
2023-03-25 18:09:06,691 : [INFO]  ------------------------- Batch 140, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:06,728 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:06,731 : [INFO]  Batch number 140 model fetched from the server
2023-03-25 18:09:06,731 : [INFO]  ################ Batch 140: final global model evalution after 3 rounds ################
2023-03-25 18:09:08,483 : [INFO]  Batch 140: Training set : loss - 0.5829, accuracy - 0.6739, recall - 0.8587, AUC - 0.8362, F1 - 0.7248, precision - 0.627, training time - -12.0 seconds
2023-03-25 18:09:08,483 : [INFO]  Batch 140: Testing set : loss - 0.5775, accuracy - 0.7059, recall - 0.8824, AUC - 0.8411, F1 - 0.75, precision - 0.6522
2023-03-25 18:09:08,497 : [INFO]  Batch 141 initialized 
2023-03-25 18:09:09,068 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:09,577 : [INFO]  ------------------------- Batch 141 training: round 1 -------------------------
2023-03-25 18:09:15,056 : [INFO]  ------------------------- Batch round 1, loss: 0.5753 -------------------------
2023-03-25 18:09:15,056 : [INFO]  ------------------------- Batch 141, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:15,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:15,067 : [INFO]  ------------------------- Batch 141 training: round 2 -------------------------
2023-03-25 18:09:18,017 : [INFO]  ------------------------- Batch round 2, loss: 0.5694 -------------------------
2023-03-25 18:09:18,017 : [INFO]  ------------------------- Batch 141, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:18,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:18,031 : [INFO]  ------------------------- Batch 141 training: round 3 -------------------------
2023-03-25 18:09:20,868 : [INFO]  ------------------------- Batch round 3, loss: 0.5737 -------------------------
2023-03-25 18:09:20,868 : [INFO]  ------------------------- Batch 141, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:20,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:20,883 : [INFO]  Batch number 141 model fetched from the server
2023-03-25 18:09:20,883 : [INFO]  ################ Batch 141: final global model evalution after 3 rounds ################
2023-03-25 18:09:22,635 : [INFO]  Batch 141: Training set : loss - 0.5978, accuracy - 0.6304, recall - 0.837, AUC - 0.8042, F1 - 0.6937, precision - 0.5923, training time - -11.0 seconds
2023-03-25 18:09:22,635 : [INFO]  Batch 141: Testing set : loss - 0.5804, accuracy - 0.701, recall - 0.9118, AUC - 0.8393, F1 - 0.753, precision - 0.6414
2023-03-25 18:09:22,646 : [INFO]  Batch 142 initialized 
2023-03-25 18:09:23,235 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:23,759 : [INFO]  ------------------------- Batch 142 training: round 1 -------------------------
2023-03-25 18:09:29,299 : [INFO]  ------------------------- Batch round 1, loss: 0.5745 -------------------------
2023-03-25 18:09:29,299 : [INFO]  ------------------------- Batch 142, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:29,308 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:29,311 : [INFO]  ------------------------- Batch 142 training: round 2 -------------------------
2023-03-25 18:09:32,204 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-25 18:09:32,204 : [INFO]  ------------------------- Batch 142, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:32,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:32,217 : [INFO]  ------------------------- Batch 142 training: round 3 -------------------------
2023-03-25 18:09:35,197 : [INFO]  ------------------------- Batch round 3, loss: 0.5713 -------------------------
2023-03-25 18:09:35,197 : [INFO]  ------------------------- Batch 142, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:35,208 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:35,210 : [INFO]  Batch number 142 model fetched from the server
2023-03-25 18:09:35,210 : [INFO]  ################ Batch 142: final global model evalution after 3 rounds ################
2023-03-25 18:09:37,037 : [INFO]  Batch 142: Training set : loss - 0.5803, accuracy - 0.7391, recall - 0.8913, AUC - 0.8309, F1 - 0.7736, precision - 0.6833, training time - -11.0 seconds
2023-03-25 18:09:37,037 : [INFO]  Batch 142: Testing set : loss - 0.6041, accuracy - 0.6667, recall - 0.8627, AUC - 0.7878, F1 - 0.7213, precision - 0.6197
2023-03-25 18:09:37,047 : [INFO]  Batch 143 initialized 
2023-03-25 18:09:37,611 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:38,122 : [INFO]  ------------------------- Batch 143 training: round 1 -------------------------
2023-03-25 18:09:43,398 : [INFO]  ------------------------- Batch round 1, loss: 0.5757 -------------------------
2023-03-25 18:09:43,398 : [INFO]  ------------------------- Batch 143, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:43,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:43,418 : [INFO]  ------------------------- Batch 143 training: round 2 -------------------------
2023-03-25 18:09:46,366 : [INFO]  ------------------------- Batch round 2, loss: 0.5781 -------------------------
2023-03-25 18:09:46,366 : [INFO]  ------------------------- Batch 143, round 2: Sent local model to the server -------------------------
2023-03-25 18:09:46,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:46,380 : [INFO]  ------------------------- Batch 143 training: round 3 -------------------------
2023-03-25 18:09:49,377 : [INFO]  ------------------------- Batch round 3, loss: 0.5757 -------------------------
2023-03-25 18:09:49,377 : [INFO]  ------------------------- Batch 143, round 3: Sent local model to the server -------------------------
2023-03-25 18:09:49,409 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:49,420 : [INFO]  Batch number 143 model fetched from the server
2023-03-25 18:09:49,421 : [INFO]  ################ Batch 143: final global model evalution after 3 rounds ################
2023-03-25 18:09:51,336 : [INFO]  Batch 143: Training set : loss - 0.5904, accuracy - 0.6848, recall - 0.8913, AUC - 0.8182, F1 - 0.7387, precision - 0.6308, training time - -11.0 seconds
2023-03-25 18:09:51,336 : [INFO]  Batch 143: Testing set : loss - 0.5751, accuracy - 0.7157, recall - 0.8529, AUC - 0.8291, F1 - 0.75, precision - 0.6692
2023-03-25 18:09:51,350 : [INFO]  Batch 144 initialized 
2023-03-25 18:09:51,917 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:09:52,432 : [INFO]  ------------------------- Batch 144 training: round 1 -------------------------
2023-03-25 18:09:57,849 : [INFO]  ------------------------- Batch round 1, loss: 0.5613 -------------------------
2023-03-25 18:09:57,849 : [INFO]  ------------------------- Batch 144, round 1: Sent local model to the server -------------------------
2023-03-25 18:09:57,935 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:09:57,938 : [INFO]  ------------------------- Batch 144 training: round 2 -------------------------
2023-03-25 18:10:00,826 : [INFO]  ------------------------- Batch round 2, loss: 0.5653 -------------------------
2023-03-25 18:10:00,826 : [INFO]  ------------------------- Batch 144, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:00,926 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:00,929 : [INFO]  ------------------------- Batch 144 training: round 3 -------------------------
2023-03-25 18:10:03,860 : [INFO]  ------------------------- Batch round 3, loss: 0.5643 -------------------------
2023-03-25 18:10:03,860 : [INFO]  ------------------------- Batch 144, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:03,919 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:03,922 : [INFO]  Batch number 144 model fetched from the server
2023-03-25 18:10:03,922 : [INFO]  ################ Batch 144: final global model evalution after 3 rounds ################
2023-03-25 18:10:05,726 : [INFO]  Batch 144: Training set : loss - 0.5878, accuracy - 0.6793, recall - 0.9022, AUC - 0.8358, F1 - 0.7378, precision - 0.6241, training time - -11.0 seconds
2023-03-25 18:10:05,727 : [INFO]  Batch 144: Testing set : loss - 0.6013, accuracy - 0.6324, recall - 0.8725, AUC - 0.8331, F1 - 0.7036, precision - 0.5894
2023-03-25 18:10:05,736 : [INFO]  Batch 145 initialized 
2023-03-25 18:10:06,306 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:06,824 : [INFO]  ------------------------- Batch 145 training: round 1 -------------------------
2023-03-25 18:10:12,275 : [INFO]  ------------------------- Batch round 1, loss: 0.5587 -------------------------
2023-03-25 18:10:12,275 : [INFO]  ------------------------- Batch 145, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:12,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:12,335 : [INFO]  ------------------------- Batch 145 training: round 2 -------------------------
2023-03-25 18:10:15,165 : [INFO]  ------------------------- Batch round 2, loss: 0.5608 -------------------------
2023-03-25 18:10:15,166 : [INFO]  ------------------------- Batch 145, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:15,241 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:15,245 : [INFO]  ------------------------- Batch 145 training: round 3 -------------------------
2023-03-25 18:10:18,083 : [INFO]  ------------------------- Batch round 3, loss: 0.5631 -------------------------
2023-03-25 18:10:18,083 : [INFO]  ------------------------- Batch 145, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:18,133 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:18,137 : [INFO]  Batch number 145 model fetched from the server
2023-03-25 18:10:18,137 : [INFO]  ################ Batch 145: final global model evalution after 3 rounds ################
2023-03-25 18:10:19,911 : [INFO]  Batch 145: Training set : loss - 0.5726, accuracy - 0.7065, recall - 0.8696, AUC - 0.8423, F1 - 0.7477, precision - 0.6557, training time - -11.0 seconds
2023-03-25 18:10:19,911 : [INFO]  Batch 145: Testing set : loss - 0.5768, accuracy - 0.701, recall - 0.8824, AUC - 0.8563, F1 - 0.7469, precision - 0.6475
2023-03-25 18:10:19,954 : [INFO]  Batch 146 initialized 
2023-03-25 18:10:20,532 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:21,055 : [INFO]  ------------------------- Batch 146 training: round 1 -------------------------
2023-03-25 18:10:26,660 : [INFO]  ------------------------- Batch round 1, loss: 0.5744 -------------------------
2023-03-25 18:10:26,660 : [INFO]  ------------------------- Batch 146, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:26,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:26,672 : [INFO]  ------------------------- Batch 146 training: round 2 -------------------------
2023-03-25 18:10:29,649 : [INFO]  ------------------------- Batch round 2, loss: 0.5796 -------------------------
2023-03-25 18:10:29,649 : [INFO]  ------------------------- Batch 146, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:29,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:29,661 : [INFO]  ------------------------- Batch 146 training: round 3 -------------------------
2023-03-25 18:10:32,698 : [INFO]  ------------------------- Batch round 3, loss: 0.5719 -------------------------
2023-03-25 18:10:32,699 : [INFO]  ------------------------- Batch 146, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:32,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:32,711 : [INFO]  Batch number 146 model fetched from the server
2023-03-25 18:10:32,712 : [INFO]  ################ Batch 146: final global model evalution after 3 rounds ################
2023-03-25 18:10:34,570 : [INFO]  Batch 146: Training set : loss - 0.5825, accuracy - 0.712, recall - 0.8913, AUC - 0.8403, F1 - 0.7558, precision - 0.656, training time - -12.0 seconds
2023-03-25 18:10:34,570 : [INFO]  Batch 146: Testing set : loss - 0.6032, accuracy - 0.6961, recall - 0.8333, AUC - 0.7903, F1 - 0.7328, precision - 0.6538
2023-03-25 18:10:34,580 : [INFO]  Batch 147 initialized 
2023-03-25 18:10:35,149 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:35,670 : [INFO]  ------------------------- Batch 147 training: round 1 -------------------------
2023-03-25 18:10:41,098 : [INFO]  ------------------------- Batch round 1, loss: 0.551 -------------------------
2023-03-25 18:10:41,098 : [INFO]  ------------------------- Batch 147, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:41,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:41,166 : [INFO]  ------------------------- Batch 147 training: round 2 -------------------------
2023-03-25 18:10:43,949 : [INFO]  ------------------------- Batch round 2, loss: 0.5505 -------------------------
2023-03-25 18:10:43,949 : [INFO]  ------------------------- Batch 147, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:44,015 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:44,018 : [INFO]  ------------------------- Batch 147 training: round 3 -------------------------
2023-03-25 18:10:46,874 : [INFO]  ------------------------- Batch round 3, loss: 0.5507 -------------------------
2023-03-25 18:10:46,874 : [INFO]  ------------------------- Batch 147, round 3: Sent local model to the server -------------------------
2023-03-25 18:10:46,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:46,892 : [INFO]  Batch number 147 model fetched from the server
2023-03-25 18:10:46,893 : [INFO]  ################ Batch 147: final global model evalution after 3 rounds ################
2023-03-25 18:10:48,787 : [INFO]  Batch 147: Training set : loss - 0.5613, accuracy - 0.7391, recall - 0.9565, AUC - 0.8706, F1 - 0.7857, precision - 0.6667, training time - -11.0 seconds
2023-03-25 18:10:48,787 : [INFO]  Batch 147: Testing set : loss - 0.5665, accuracy - 0.7353, recall - 0.902, AUC - 0.8696, F1 - 0.7731, precision - 0.6765
2023-03-25 18:10:48,797 : [INFO]  Batch 148 initialized 
2023-03-25 18:10:49,370 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:10:49,894 : [INFO]  ------------------------- Batch 148 training: round 1 -------------------------
2023-03-25 18:10:55,564 : [INFO]  ------------------------- Batch round 1, loss: 0.5687 -------------------------
2023-03-25 18:10:55,565 : [INFO]  ------------------------- Batch 148, round 1: Sent local model to the server -------------------------
2023-03-25 18:10:55,631 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:55,634 : [INFO]  ------------------------- Batch 148 training: round 2 -------------------------
2023-03-25 18:10:58,598 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 18:10:58,598 : [INFO]  ------------------------- Batch 148, round 2: Sent local model to the server -------------------------
2023-03-25 18:10:58,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:10:58,709 : [INFO]  ------------------------- Batch 148 training: round 3 -------------------------
2023-03-25 18:11:01,604 : [INFO]  ------------------------- Batch round 3, loss: 0.5628 -------------------------
2023-03-25 18:11:01,605 : [INFO]  ------------------------- Batch 148, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:01,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:01,667 : [INFO]  Batch number 148 model fetched from the server
2023-03-25 18:11:01,667 : [INFO]  ################ Batch 148: final global model evalution after 3 rounds ################
2023-03-25 18:11:03,463 : [INFO]  Batch 148: Training set : loss - 0.5846, accuracy - 0.6793, recall - 0.837, AUC - 0.8177, F1 - 0.723, precision - 0.6364, training time - -12.0 seconds
2023-03-25 18:11:03,464 : [INFO]  Batch 148: Testing set : loss - 0.553, accuracy - 0.7451, recall - 0.8824, AUC - 0.858, F1 - 0.7759, precision - 0.6923
2023-03-25 18:11:03,478 : [INFO]  Batch 149 initialized 
2023-03-25 18:11:04,025 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:04,559 : [INFO]  ------------------------- Batch 149 training: round 1 -------------------------
2023-03-25 18:11:09,887 : [INFO]  ------------------------- Batch round 1, loss: 0.5832 -------------------------
2023-03-25 18:11:09,887 : [INFO]  ------------------------- Batch 149, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:09,979 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:09,982 : [INFO]  ------------------------- Batch 149 training: round 2 -------------------------
2023-03-25 18:11:12,865 : [INFO]  ------------------------- Batch round 2, loss: 0.5843 -------------------------
2023-03-25 18:11:12,865 : [INFO]  ------------------------- Batch 149, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:12,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:12,936 : [INFO]  ------------------------- Batch 149 training: round 3 -------------------------
2023-03-25 18:11:15,937 : [INFO]  ------------------------- Batch round 3, loss: 0.5772 -------------------------
2023-03-25 18:11:15,937 : [INFO]  ------------------------- Batch 149, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:15,998 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:16,001 : [INFO]  Batch number 149 model fetched from the server
2023-03-25 18:11:16,001 : [INFO]  ################ Batch 149: final global model evalution after 3 rounds ################
2023-03-25 18:11:17,771 : [INFO]  Batch 149: Training set : loss - 0.6083, accuracy - 0.663, recall - 0.9239, AUC - 0.8119, F1 - 0.7328, precision - 0.6071, training time - -11.0 seconds
2023-03-25 18:11:17,771 : [INFO]  Batch 149: Testing set : loss - 0.5783, accuracy - 0.7255, recall - 0.902, AUC - 0.875, F1 - 0.7667, precision - 0.6667
2023-03-25 18:11:17,811 : [INFO]  Batch 150 initialized 
2023-03-25 18:11:18,384 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:18,912 : [INFO]  ------------------------- Batch 150 training: round 1 -------------------------
2023-03-25 18:11:24,339 : [INFO]  ------------------------- Batch round 1, loss: 0.5655 -------------------------
2023-03-25 18:11:24,339 : [INFO]  ------------------------- Batch 150, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:24,539 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:24,541 : [INFO]  ------------------------- Batch 150 training: round 2 -------------------------
2023-03-25 18:11:27,315 : [INFO]  ------------------------- Batch round 2, loss: 0.5624 -------------------------
2023-03-25 18:11:27,315 : [INFO]  ------------------------- Batch 150, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:27,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:27,511 : [INFO]  ------------------------- Batch 150 training: round 3 -------------------------
2023-03-25 18:11:30,348 : [INFO]  ------------------------- Batch round 3, loss: 0.5669 -------------------------
2023-03-25 18:11:30,349 : [INFO]  ------------------------- Batch 150, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:30,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:30,521 : [INFO]  Batch number 150 model fetched from the server
2023-03-25 18:11:30,521 : [INFO]  ################ Batch 150: final global model evalution after 3 rounds ################
2023-03-25 18:11:32,312 : [INFO]  Batch 150: Training set : loss - 0.5803, accuracy - 0.712, recall - 0.837, AUC - 0.8207, F1 - 0.744, precision - 0.6696, training time - -12.0 seconds
2023-03-25 18:11:32,312 : [INFO]  Batch 150: Testing set : loss - 0.6108, accuracy - 0.6569, recall - 0.8529, AUC - 0.7858, F1 - 0.7131, precision - 0.6127
2023-03-25 18:11:32,326 : [INFO]  Batch 151 initialized 
2023-03-25 18:11:32,886 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:33,403 : [INFO]  ------------------------- Batch 151 training: round 1 -------------------------
2023-03-25 18:11:38,861 : [INFO]  ------------------------- Batch round 1, loss: 0.5577 -------------------------
2023-03-25 18:11:38,862 : [INFO]  ------------------------- Batch 151, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:38,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:38,917 : [INFO]  ------------------------- Batch 151 training: round 2 -------------------------
2023-03-25 18:11:41,699 : [INFO]  ------------------------- Batch round 2, loss: 0.5579 -------------------------
2023-03-25 18:11:41,699 : [INFO]  ------------------------- Batch 151, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:41,709 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:41,711 : [INFO]  ------------------------- Batch 151 training: round 3 -------------------------
2023-03-25 18:11:44,486 : [INFO]  ------------------------- Batch round 3, loss: 0.5615 -------------------------
2023-03-25 18:11:44,487 : [INFO]  ------------------------- Batch 151, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:44,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:44,529 : [INFO]  Batch number 151 model fetched from the server
2023-03-25 18:11:44,529 : [INFO]  ################ Batch 151: final global model evalution after 3 rounds ################
2023-03-25 18:11:46,272 : [INFO]  Batch 151: Training set : loss - 0.5697, accuracy - 0.7283, recall - 0.9022, AUC - 0.8701, F1 - 0.7685, precision - 0.6694, training time - -11.0 seconds
2023-03-25 18:11:46,272 : [INFO]  Batch 151: Testing set : loss - 0.5488, accuracy - 0.7353, recall - 0.951, AUC - 0.9178, F1 - 0.7823, precision - 0.6644
2023-03-25 18:11:46,281 : [INFO]  Batch 152 initialized 
2023-03-25 18:11:46,839 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:11:47,365 : [INFO]  ------------------------- Batch 152 training: round 1 -------------------------
2023-03-25 18:11:52,849 : [INFO]  ------------------------- Batch round 1, loss: 0.5887 -------------------------
2023-03-25 18:11:52,849 : [INFO]  ------------------------- Batch 152, round 1: Sent local model to the server -------------------------
2023-03-25 18:11:52,970 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:52,973 : [INFO]  ------------------------- Batch 152 training: round 2 -------------------------
2023-03-25 18:11:55,910 : [INFO]  ------------------------- Batch round 2, loss: 0.5854 -------------------------
2023-03-25 18:11:55,910 : [INFO]  ------------------------- Batch 152, round 2: Sent local model to the server -------------------------
2023-03-25 18:11:55,920 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:55,923 : [INFO]  ------------------------- Batch 152 training: round 3 -------------------------
2023-03-25 18:11:58,782 : [INFO]  ------------------------- Batch round 3, loss: 0.5902 -------------------------
2023-03-25 18:11:58,782 : [INFO]  ------------------------- Batch 152, round 3: Sent local model to the server -------------------------
2023-03-25 18:11:58,847 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:11:58,850 : [INFO]  Batch number 152 model fetched from the server
2023-03-25 18:11:58,850 : [INFO]  ################ Batch 152: final global model evalution after 3 rounds ################
2023-03-25 18:12:00,653 : [INFO]  Batch 152: Training set : loss - 0.6112, accuracy - 0.6359, recall - 0.9239, AUC - 0.8322, F1 - 0.7173, precision - 0.5862, training time - -11.0 seconds
2023-03-25 18:12:00,653 : [INFO]  Batch 152: Testing set : loss - 0.5952, accuracy - 0.6667, recall - 0.951, AUC - 0.8644, F1 - 0.7405, precision - 0.6062
2023-03-25 18:12:00,664 : [INFO]  Batch 153 initialized 
2023-03-25 18:12:01,226 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:01,759 : [INFO]  ------------------------- Batch 153 training: round 1 -------------------------
2023-03-25 18:12:07,274 : [INFO]  ------------------------- Batch round 1, loss: 0.5967 -------------------------
2023-03-25 18:12:07,274 : [INFO]  ------------------------- Batch 153, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:07,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:07,286 : [INFO]  ------------------------- Batch 153 training: round 2 -------------------------
2023-03-25 18:12:10,274 : [INFO]  ------------------------- Batch round 2, loss: 0.591 -------------------------
2023-03-25 18:12:10,274 : [INFO]  ------------------------- Batch 153, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:10,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:10,289 : [INFO]  ------------------------- Batch 153 training: round 3 -------------------------
2023-03-25 18:12:13,242 : [INFO]  ------------------------- Batch round 3, loss: 0.5925 -------------------------
2023-03-25 18:12:13,242 : [INFO]  ------------------------- Batch 153, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:13,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:13,255 : [INFO]  Batch number 153 model fetched from the server
2023-03-25 18:12:13,255 : [INFO]  ################ Batch 153: final global model evalution after 3 rounds ################
2023-03-25 18:12:15,042 : [INFO]  Batch 153: Training set : loss - 0.6023, accuracy - 0.6359, recall - 0.8478, AUC - 0.8199, F1 - 0.6996, precision - 0.5954, training time - -11.0 seconds
2023-03-25 18:12:15,042 : [INFO]  Batch 153: Testing set : loss - 0.5952, accuracy - 0.6716, recall - 0.8922, AUC - 0.8438, F1 - 0.7309, precision - 0.619
2023-03-25 18:12:15,052 : [INFO]  Batch 154 initialized 
2023-03-25 18:12:15,618 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:16,125 : [INFO]  ------------------------- Batch 154 training: round 1 -------------------------
2023-03-25 18:12:21,538 : [INFO]  ------------------------- Batch round 1, loss: 0.5761 -------------------------
2023-03-25 18:12:21,538 : [INFO]  ------------------------- Batch 154, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:21,547 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:21,550 : [INFO]  ------------------------- Batch 154 training: round 2 -------------------------
2023-03-25 18:12:24,563 : [INFO]  ------------------------- Batch round 2, loss: 0.5844 -------------------------
2023-03-25 18:12:24,564 : [INFO]  ------------------------- Batch 154, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:24,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:24,576 : [INFO]  ------------------------- Batch 154 training: round 3 -------------------------
2023-03-25 18:12:27,631 : [INFO]  ------------------------- Batch round 3, loss: 0.5805 -------------------------
2023-03-25 18:12:27,631 : [INFO]  ------------------------- Batch 154, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:27,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:27,644 : [INFO]  Batch number 154 model fetched from the server
2023-03-25 18:12:27,644 : [INFO]  ################ Batch 154: final global model evalution after 3 rounds ################
2023-03-25 18:12:29,429 : [INFO]  Batch 154: Training set : loss - 0.5918, accuracy - 0.7011, recall - 0.8587, AUC - 0.822, F1 - 0.7418, precision - 0.6529, training time - -12.0 seconds
2023-03-25 18:12:29,429 : [INFO]  Batch 154: Testing set : loss - 0.6089, accuracy - 0.6471, recall - 0.8529, AUC - 0.7884, F1 - 0.7073, precision - 0.6042
2023-03-25 18:12:29,437 : [INFO]  Batch 155 initialized 
2023-03-25 18:12:29,995 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:30,519 : [INFO]  ------------------------- Batch 155 training: round 1 -------------------------
2023-03-25 18:12:36,210 : [INFO]  ------------------------- Batch round 1, loss: 0.5904 -------------------------
2023-03-25 18:12:36,210 : [INFO]  ------------------------- Batch 155, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:36,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:36,222 : [INFO]  ------------------------- Batch 155 training: round 2 -------------------------
2023-03-25 18:12:39,294 : [INFO]  ------------------------- Batch round 2, loss: 0.5945 -------------------------
2023-03-25 18:12:39,294 : [INFO]  ------------------------- Batch 155, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:39,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:39,306 : [INFO]  ------------------------- Batch 155 training: round 3 -------------------------
2023-03-25 18:12:42,488 : [INFO]  ------------------------- Batch round 3, loss: 0.5912 -------------------------
2023-03-25 18:12:42,489 : [INFO]  ------------------------- Batch 155, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:42,500 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:42,504 : [INFO]  Batch number 155 model fetched from the server
2023-03-25 18:12:42,504 : [INFO]  ################ Batch 155: final global model evalution after 3 rounds ################
2023-03-25 18:12:44,380 : [INFO]  Batch 155: Training set : loss - 0.6062, accuracy - 0.6793, recall - 0.7935, AUC - 0.7628, F1 - 0.7122, precision - 0.646, training time - -12.0 seconds
2023-03-25 18:12:44,380 : [INFO]  Batch 155: Testing set : loss - 0.6121, accuracy - 0.6716, recall - 0.8137, AUC - 0.7622, F1 - 0.7124, precision - 0.6336
2023-03-25 18:12:44,391 : [INFO]  Batch 156 initialized 
2023-03-25 18:12:44,963 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:12:45,483 : [INFO]  ------------------------- Batch 156 training: round 1 -------------------------
2023-03-25 18:12:50,990 : [INFO]  ------------------------- Batch round 1, loss: 0.5781 -------------------------
2023-03-25 18:12:50,991 : [INFO]  ------------------------- Batch 156, round 1: Sent local model to the server -------------------------
2023-03-25 18:12:51,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:51,006 : [INFO]  ------------------------- Batch 156 training: round 2 -------------------------
2023-03-25 18:12:53,917 : [INFO]  ------------------------- Batch round 2, loss: 0.5741 -------------------------
2023-03-25 18:12:53,917 : [INFO]  ------------------------- Batch 156, round 2: Sent local model to the server -------------------------
2023-03-25 18:12:53,927 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:53,930 : [INFO]  ------------------------- Batch 156 training: round 3 -------------------------
2023-03-25 18:12:57,161 : [INFO]  ------------------------- Batch round 3, loss: 0.5747 -------------------------
2023-03-25 18:12:57,161 : [INFO]  ------------------------- Batch 156, round 3: Sent local model to the server -------------------------
2023-03-25 18:12:57,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:12:57,194 : [INFO]  Batch number 156 model fetched from the server
2023-03-25 18:12:57,194 : [INFO]  ################ Batch 156: final global model evalution after 3 rounds ################
2023-03-25 18:12:59,023 : [INFO]  Batch 156: Training set : loss - 0.5932, accuracy - 0.7065, recall - 0.8152, AUC - 0.7766, F1 - 0.7353, precision - 0.6696, training time - -12.0 seconds
2023-03-25 18:12:59,023 : [INFO]  Batch 156: Testing set : loss - 0.5927, accuracy - 0.6814, recall - 0.8529, AUC - 0.8182, F1 - 0.728, precision - 0.635
2023-03-25 18:12:59,036 : [INFO]  Batch 157 initialized 
2023-03-25 18:12:59,621 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:00,155 : [INFO]  ------------------------- Batch 157 training: round 1 -------------------------
2023-03-25 18:13:05,629 : [INFO]  ------------------------- Batch round 1, loss: 0.5827 -------------------------
2023-03-25 18:13:05,629 : [INFO]  ------------------------- Batch 157, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:05,691 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:05,694 : [INFO]  ------------------------- Batch 157 training: round 2 -------------------------
2023-03-25 18:13:08,539 : [INFO]  ------------------------- Batch round 2, loss: 0.5775 -------------------------
2023-03-25 18:13:08,539 : [INFO]  ------------------------- Batch 157, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:08,585 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:08,589 : [INFO]  ------------------------- Batch 157 training: round 3 -------------------------
2023-03-25 18:13:11,403 : [INFO]  ------------------------- Batch round 3, loss: 0.576 -------------------------
2023-03-25 18:13:11,403 : [INFO]  ------------------------- Batch 157, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:11,469 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:11,473 : [INFO]  Batch number 157 model fetched from the server
2023-03-25 18:13:11,473 : [INFO]  ################ Batch 157: final global model evalution after 3 rounds ################
2023-03-25 18:13:13,203 : [INFO]  Batch 157: Training set : loss - 0.5879, accuracy - 0.7011, recall - 0.8696, AUC - 0.8199, F1 - 0.7442, precision - 0.6504, training time - -11.0 seconds
2023-03-25 18:13:13,203 : [INFO]  Batch 157: Testing set : loss - 0.5534, accuracy - 0.7549, recall - 0.9706, AUC - 0.9021, F1 - 0.7984, precision - 0.6781
2023-03-25 18:13:13,221 : [INFO]  Batch 158 initialized 
2023-03-25 18:13:13,776 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:14,302 : [INFO]  ------------------------- Batch 158 training: round 1 -------------------------
2023-03-25 18:13:19,539 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-25 18:13:19,540 : [INFO]  ------------------------- Batch 158, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:19,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:19,753 : [INFO]  ------------------------- Batch 158 training: round 2 -------------------------
2023-03-25 18:13:22,657 : [INFO]  ------------------------- Batch round 2, loss: 0.5765 -------------------------
2023-03-25 18:13:22,657 : [INFO]  ------------------------- Batch 158, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:22,797 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:22,799 : [INFO]  ------------------------- Batch 158 training: round 3 -------------------------
2023-03-25 18:13:25,892 : [INFO]  ------------------------- Batch round 3, loss: 0.5657 -------------------------
2023-03-25 18:13:25,892 : [INFO]  ------------------------- Batch 158, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:25,925 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:25,932 : [INFO]  Batch number 158 model fetched from the server
2023-03-25 18:13:25,932 : [INFO]  ################ Batch 158: final global model evalution after 3 rounds ################
2023-03-25 18:13:27,738 : [INFO]  Batch 158: Training set : loss - 0.5794, accuracy - 0.7011, recall - 0.8696, AUC - 0.8311, F1 - 0.7442, precision - 0.6504, training time - -12.0 seconds
2023-03-25 18:13:27,738 : [INFO]  Batch 158: Testing set : loss - 0.5924, accuracy - 0.6765, recall - 0.8922, AUC - 0.8388, F1 - 0.7339, precision - 0.6233
2023-03-25 18:13:27,747 : [INFO]  Batch 159 initialized 
2023-03-25 18:13:28,331 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:28,876 : [INFO]  ------------------------- Batch 159 training: round 1 -------------------------
2023-03-25 18:13:34,391 : [INFO]  ------------------------- Batch round 1, loss: 0.5586 -------------------------
2023-03-25 18:13:34,391 : [INFO]  ------------------------- Batch 159, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:34,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:34,436 : [INFO]  ------------------------- Batch 159 training: round 2 -------------------------
2023-03-25 18:13:37,330 : [INFO]  ------------------------- Batch round 2, loss: 0.558 -------------------------
2023-03-25 18:13:37,330 : [INFO]  ------------------------- Batch 159, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:37,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:37,369 : [INFO]  ------------------------- Batch 159 training: round 3 -------------------------
2023-03-25 18:13:40,212 : [INFO]  ------------------------- Batch round 3, loss: 0.5564 -------------------------
2023-03-25 18:13:40,212 : [INFO]  ------------------------- Batch 159, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:40,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:40,254 : [INFO]  Batch number 159 model fetched from the server
2023-03-25 18:13:40,255 : [INFO]  ################ Batch 159: final global model evalution after 3 rounds ################
2023-03-25 18:13:42,082 : [INFO]  Batch 159: Training set : loss - 0.5629, accuracy - 0.7609, recall - 0.8913, AUC - 0.8588, F1 - 0.7885, precision - 0.7069, training time - -11.0 seconds
2023-03-25 18:13:42,083 : [INFO]  Batch 159: Testing set : loss - 0.5742, accuracy - 0.7157, recall - 0.8922, AUC - 0.8579, F1 - 0.7583, precision - 0.6594
2023-03-25 18:13:42,096 : [INFO]  Batch 160 initialized 
2023-03-25 18:13:42,668 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:43,203 : [INFO]  ------------------------- Batch 160 training: round 1 -------------------------
2023-03-25 18:13:48,442 : [INFO]  ------------------------- Batch round 1, loss: 0.5561 -------------------------
2023-03-25 18:13:48,442 : [INFO]  ------------------------- Batch 160, round 1: Sent local model to the server -------------------------
2023-03-25 18:13:48,700 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:48,703 : [INFO]  ------------------------- Batch 160 training: round 2 -------------------------
2023-03-25 18:13:51,420 : [INFO]  ------------------------- Batch round 2, loss: 0.5624 -------------------------
2023-03-25 18:13:51,420 : [INFO]  ------------------------- Batch 160, round 2: Sent local model to the server -------------------------
2023-03-25 18:13:51,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:51,666 : [INFO]  ------------------------- Batch 160 training: round 3 -------------------------
2023-03-25 18:13:54,584 : [INFO]  ------------------------- Batch round 3, loss: 0.561 -------------------------
2023-03-25 18:13:54,584 : [INFO]  ------------------------- Batch 160, round 3: Sent local model to the server -------------------------
2023-03-25 18:13:54,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:13:54,698 : [INFO]  Batch number 160 model fetched from the server
2023-03-25 18:13:54,698 : [INFO]  ################ Batch 160: final global model evalution after 3 rounds ################
2023-03-25 18:13:56,409 : [INFO]  Batch 160: Training set : loss - 0.5716, accuracy - 0.712, recall - 0.913, AUC - 0.8682, F1 - 0.7602, precision - 0.6512, training time - -11.0 seconds
2023-03-25 18:13:56,409 : [INFO]  Batch 160: Testing set : loss - 0.5791, accuracy - 0.7059, recall - 0.902, AUC - 0.8488, F1 - 0.7541, precision - 0.6479
2023-03-25 18:13:56,416 : [INFO]  Batch 161 initialized 
2023-03-25 18:13:56,980 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:13:57,488 : [INFO]  ------------------------- Batch 161 training: round 1 -------------------------
2023-03-25 18:14:02,665 : [INFO]  ------------------------- Batch round 1, loss: 0.6006 -------------------------
2023-03-25 18:14:02,666 : [INFO]  ------------------------- Batch 161, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:03,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:03,078 : [INFO]  ------------------------- Batch 161 training: round 2 -------------------------
2023-03-25 18:14:05,830 : [INFO]  ------------------------- Batch round 2, loss: 0.5981 -------------------------
2023-03-25 18:14:05,831 : [INFO]  ------------------------- Batch 161, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:06,140 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:06,143 : [INFO]  ------------------------- Batch 161 training: round 3 -------------------------
2023-03-25 18:14:08,806 : [INFO]  ------------------------- Batch round 3, loss: 0.6061 -------------------------
2023-03-25 18:14:08,806 : [INFO]  ------------------------- Batch 161, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:09,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:09,169 : [INFO]  Batch number 161 model fetched from the server
2023-03-25 18:14:09,169 : [INFO]  ################ Batch 161: final global model evalution after 3 rounds ################
2023-03-25 18:14:10,951 : [INFO]  Batch 161: Training set : loss - 0.6084, accuracy - 0.6739, recall - 0.8913, AUC - 0.7843, F1 - 0.7321, precision - 0.6212, training time - -12.0 seconds
2023-03-25 18:14:10,951 : [INFO]  Batch 161: Testing set : loss - 0.5677, accuracy - 0.7108, recall - 0.902, AUC - 0.8675, F1 - 0.7572, precision - 0.6525
2023-03-25 18:14:10,965 : [INFO]  Batch 162 initialized 
2023-03-25 18:14:11,549 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:12,081 : [INFO]  ------------------------- Batch 162 training: round 1 -------------------------
2023-03-25 18:14:17,437 : [INFO]  ------------------------- Batch round 1, loss: 0.5793 -------------------------
2023-03-25 18:14:17,438 : [INFO]  ------------------------- Batch 162, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:17,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:17,450 : [INFO]  ------------------------- Batch 162 training: round 2 -------------------------
2023-03-25 18:14:20,259 : [INFO]  ------------------------- Batch round 2, loss: 0.5782 -------------------------
2023-03-25 18:14:20,259 : [INFO]  ------------------------- Batch 162, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:20,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:20,271 : [INFO]  ------------------------- Batch 162 training: round 3 -------------------------
2023-03-25 18:14:23,146 : [INFO]  ------------------------- Batch round 3, loss: 0.5728 -------------------------
2023-03-25 18:14:23,146 : [INFO]  ------------------------- Batch 162, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:23,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:23,160 : [INFO]  Batch number 162 model fetched from the server
2023-03-25 18:14:23,160 : [INFO]  ################ Batch 162: final global model evalution after 3 rounds ################
2023-03-25 18:14:24,922 : [INFO]  Batch 162: Training set : loss - 0.5954, accuracy - 0.663, recall - 0.8696, AUC - 0.8088, F1 - 0.7207, precision - 0.6154, training time - -11.0 seconds
2023-03-25 18:14:24,923 : [INFO]  Batch 162: Testing set : loss - 0.5716, accuracy - 0.7108, recall - 0.9216, AUC - 0.8585, F1 - 0.7611, precision - 0.6483
2023-03-25 18:14:24,933 : [INFO]  Batch 163 initialized 
2023-03-25 18:14:25,505 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:26,059 : [INFO]  ------------------------- Batch 163 training: round 1 -------------------------
2023-03-25 18:14:31,448 : [INFO]  ------------------------- Batch round 1, loss: 0.5818 -------------------------
2023-03-25 18:14:31,448 : [INFO]  ------------------------- Batch 163, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:31,688 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:31,690 : [INFO]  ------------------------- Batch 163 training: round 2 -------------------------
2023-03-25 18:14:34,531 : [INFO]  ------------------------- Batch round 2, loss: 0.5796 -------------------------
2023-03-25 18:14:34,532 : [INFO]  ------------------------- Batch 163, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:34,695 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:34,698 : [INFO]  ------------------------- Batch 163 training: round 3 -------------------------
2023-03-25 18:14:37,528 : [INFO]  ------------------------- Batch round 3, loss: 0.5775 -------------------------
2023-03-25 18:14:37,528 : [INFO]  ------------------------- Batch 163, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:37,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:37,753 : [INFO]  Batch number 163 model fetched from the server
2023-03-25 18:14:37,753 : [INFO]  ################ Batch 163: final global model evalution after 3 rounds ################
2023-03-25 18:14:39,552 : [INFO]  Batch 163: Training set : loss - 0.5933, accuracy - 0.712, recall - 0.8804, AUC - 0.7981, F1 - 0.7535, precision - 0.6585, training time - -12.0 seconds
2023-03-25 18:14:39,552 : [INFO]  Batch 163: Testing set : loss - 0.5609, accuracy - 0.7353, recall - 0.8431, AUC - 0.8573, F1 - 0.7611, precision - 0.6935
2023-03-25 18:14:39,565 : [INFO]  Batch 164 initialized 
2023-03-25 18:14:40,138 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:40,676 : [INFO]  ------------------------- Batch 164 training: round 1 -------------------------
2023-03-25 18:14:46,027 : [INFO]  ------------------------- Batch round 1, loss: 0.5923 -------------------------
2023-03-25 18:14:46,027 : [INFO]  ------------------------- Batch 164, round 1: Sent local model to the server -------------------------
2023-03-25 18:14:46,223 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:46,225 : [INFO]  ------------------------- Batch 164 training: round 2 -------------------------
2023-03-25 18:14:49,057 : [INFO]  ------------------------- Batch round 2, loss: 0.5943 -------------------------
2023-03-25 18:14:49,058 : [INFO]  ------------------------- Batch 164, round 2: Sent local model to the server -------------------------
2023-03-25 18:14:49,296 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:49,299 : [INFO]  ------------------------- Batch 164 training: round 3 -------------------------
2023-03-25 18:14:52,170 : [INFO]  ------------------------- Batch round 3, loss: 0.6002 -------------------------
2023-03-25 18:14:52,170 : [INFO]  ------------------------- Batch 164, round 3: Sent local model to the server -------------------------
2023-03-25 18:14:52,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:14:52,353 : [INFO]  Batch number 164 model fetched from the server
2023-03-25 18:14:52,354 : [INFO]  ################ Batch 164: final global model evalution after 3 rounds ################
2023-03-25 18:14:54,083 : [INFO]  Batch 164: Training set : loss - 0.6059, accuracy - 0.6685, recall - 0.9022, AUC - 0.7899, F1 - 0.7313, precision - 0.6148, training time - -12.0 seconds
2023-03-25 18:14:54,083 : [INFO]  Batch 164: Testing set : loss - 0.5906, accuracy - 0.6961, recall - 0.8922, AUC - 0.8163, F1 - 0.7459, precision - 0.6408
2023-03-25 18:14:54,126 : [INFO]  Batch 165 initialized 
2023-03-25 18:14:54,681 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:14:55,201 : [INFO]  ------------------------- Batch 165 training: round 1 -------------------------
2023-03-25 18:15:00,732 : [INFO]  ------------------------- Batch round 1, loss: 0.5842 -------------------------
2023-03-25 18:15:00,732 : [INFO]  ------------------------- Batch 165, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:00,743 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:00,746 : [INFO]  ------------------------- Batch 165 training: round 2 -------------------------
2023-03-25 18:15:03,810 : [INFO]  ------------------------- Batch round 2, loss: 0.5777 -------------------------
2023-03-25 18:15:03,810 : [INFO]  ------------------------- Batch 165, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:03,821 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:03,823 : [INFO]  ------------------------- Batch 165 training: round 3 -------------------------
2023-03-25 18:15:06,817 : [INFO]  ------------------------- Batch round 3, loss: 0.5865 -------------------------
2023-03-25 18:15:06,817 : [INFO]  ------------------------- Batch 165, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:06,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:06,830 : [INFO]  Batch number 165 model fetched from the server
2023-03-25 18:15:06,830 : [INFO]  ################ Batch 165: final global model evalution after 3 rounds ################
2023-03-25 18:15:08,652 : [INFO]  Batch 165: Training set : loss - 0.5927, accuracy - 0.6957, recall - 0.8913, AUC - 0.8072, F1 - 0.7455, precision - 0.6406, training time - -12.0 seconds
2023-03-25 18:15:08,652 : [INFO]  Batch 165: Testing set : loss - 0.596, accuracy - 0.6422, recall - 0.8235, AUC - 0.8199, F1 - 0.6971, precision - 0.6043
2023-03-25 18:15:08,659 : [INFO]  Batch 166 initialized 
2023-03-25 18:15:09,207 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:09,767 : [INFO]  ------------------------- Batch 166 training: round 1 -------------------------
2023-03-25 18:15:15,232 : [INFO]  ------------------------- Batch round 1, loss: 0.5726 -------------------------
2023-03-25 18:15:15,233 : [INFO]  ------------------------- Batch 166, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:15,243 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:15,245 : [INFO]  ------------------------- Batch 166 training: round 2 -------------------------
2023-03-25 18:15:18,127 : [INFO]  ------------------------- Batch round 2, loss: 0.5825 -------------------------
2023-03-25 18:15:18,127 : [INFO]  ------------------------- Batch 166, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:18,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:18,141 : [INFO]  ------------------------- Batch 166 training: round 3 -------------------------
2023-03-25 18:15:21,124 : [INFO]  ------------------------- Batch round 3, loss: 0.5811 -------------------------
2023-03-25 18:15:21,124 : [INFO]  ------------------------- Batch 166, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:21,136 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:21,138 : [INFO]  Batch number 166 model fetched from the server
2023-03-25 18:15:21,139 : [INFO]  ################ Batch 166: final global model evalution after 3 rounds ################
2023-03-25 18:15:22,948 : [INFO]  Batch 166: Training set : loss - 0.587, accuracy - 0.6957, recall - 0.9022, AUC - 0.8635, F1 - 0.7477, precision - 0.6385, training time - -11.0 seconds
2023-03-25 18:15:22,949 : [INFO]  Batch 166: Testing set : loss - 0.5763, accuracy - 0.7402, recall - 0.951, AUC - 0.853, F1 - 0.7854, precision - 0.669
2023-03-25 18:15:22,960 : [INFO]  Batch 167 initialized 
2023-03-25 18:15:23,558 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:24,121 : [INFO]  ------------------------- Batch 167 training: round 1 -------------------------
2023-03-25 18:15:29,433 : [INFO]  ------------------------- Batch round 1, loss: 0.5567 -------------------------
2023-03-25 18:15:29,433 : [INFO]  ------------------------- Batch 167, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:29,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:29,458 : [INFO]  ------------------------- Batch 167 training: round 2 -------------------------
2023-03-25 18:15:32,242 : [INFO]  ------------------------- Batch round 2, loss: 0.552 -------------------------
2023-03-25 18:15:32,242 : [INFO]  ------------------------- Batch 167, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:32,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:32,298 : [INFO]  ------------------------- Batch 167 training: round 3 -------------------------
2023-03-25 18:15:35,100 : [INFO]  ------------------------- Batch round 3, loss: 0.5552 -------------------------
2023-03-25 18:15:35,100 : [INFO]  ------------------------- Batch 167, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:35,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:35,155 : [INFO]  Batch number 167 model fetched from the server
2023-03-25 18:15:35,155 : [INFO]  ################ Batch 167: final global model evalution after 3 rounds ################
2023-03-25 18:15:36,978 : [INFO]  Batch 167: Training set : loss - 0.5626, accuracy - 0.7391, recall - 0.9239, AUC - 0.8817, F1 - 0.7798, precision - 0.6746, training time - -11.0 seconds
2023-03-25 18:15:36,979 : [INFO]  Batch 167: Testing set : loss - 0.562, accuracy - 0.7255, recall - 0.951, AUC - 0.9028, F1 - 0.776, precision - 0.6554
2023-03-25 18:15:36,990 : [INFO]  Batch 168 initialized 
2023-03-25 18:15:37,540 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:38,078 : [INFO]  ------------------------- Batch 168 training: round 1 -------------------------
2023-03-25 18:15:43,704 : [INFO]  ------------------------- Batch round 1, loss: 0.5832 -------------------------
2023-03-25 18:15:43,704 : [INFO]  ------------------------- Batch 168, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:43,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:43,717 : [INFO]  ------------------------- Batch 168 training: round 2 -------------------------
2023-03-25 18:15:46,772 : [INFO]  ------------------------- Batch round 2, loss: 0.5816 -------------------------
2023-03-25 18:15:46,772 : [INFO]  ------------------------- Batch 168, round 2: Sent local model to the server -------------------------
2023-03-25 18:15:46,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:46,785 : [INFO]  ------------------------- Batch 168 training: round 3 -------------------------
2023-03-25 18:15:49,812 : [INFO]  ------------------------- Batch round 3, loss: 0.5815 -------------------------
2023-03-25 18:15:49,812 : [INFO]  ------------------------- Batch 168, round 3: Sent local model to the server -------------------------
2023-03-25 18:15:49,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:49,827 : [INFO]  Batch number 168 model fetched from the server
2023-03-25 18:15:49,827 : [INFO]  ################ Batch 168: final global model evalution after 3 rounds ################
2023-03-25 18:15:51,694 : [INFO]  Batch 168: Training set : loss - 0.5908, accuracy - 0.7228, recall - 0.9348, AUC - 0.8305, F1 - 0.7713, precision - 0.6565, training time - -12.0 seconds
2023-03-25 18:15:51,694 : [INFO]  Batch 168: Testing set : loss - 0.5681, accuracy - 0.7108, recall - 0.9118, AUC - 0.8729, F1 - 0.7592, precision - 0.6503
2023-03-25 18:15:51,705 : [INFO]  Batch 169 initialized 
2023-03-25 18:15:52,254 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:15:52,814 : [INFO]  ------------------------- Batch 169 training: round 1 -------------------------
2023-03-25 18:15:58,296 : [INFO]  ------------------------- Batch round 1, loss: 0.5613 -------------------------
2023-03-25 18:15:58,296 : [INFO]  ------------------------- Batch 169, round 1: Sent local model to the server -------------------------
2023-03-25 18:15:58,306 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:15:58,309 : [INFO]  ------------------------- Batch 169 training: round 2 -------------------------
2023-03-25 18:16:01,287 : [INFO]  ------------------------- Batch round 2, loss: 0.5666 -------------------------
2023-03-25 18:16:01,288 : [INFO]  ------------------------- Batch 169, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:01,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:01,301 : [INFO]  ------------------------- Batch 169 training: round 3 -------------------------
2023-03-25 18:16:04,422 : [INFO]  ------------------------- Batch round 3, loss: 0.5624 -------------------------
2023-03-25 18:16:04,422 : [INFO]  ------------------------- Batch 169, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:04,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:04,443 : [INFO]  Batch number 169 model fetched from the server
2023-03-25 18:16:04,443 : [INFO]  ################ Batch 169: final global model evalution after 3 rounds ################
2023-03-25 18:16:06,324 : [INFO]  Batch 169: Training set : loss - 0.574, accuracy - 0.7174, recall - 0.9022, AUC - 0.8602, F1 - 0.7615, precision - 0.6587, training time - -12.0 seconds
2023-03-25 18:16:06,324 : [INFO]  Batch 169: Testing set : loss - 0.5688, accuracy - 0.7402, recall - 0.8922, AUC - 0.8598, F1 - 0.7745, precision - 0.6842
2023-03-25 18:16:06,336 : [INFO]  Batch 170 initialized 
2023-03-25 18:16:06,913 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:07,455 : [INFO]  ------------------------- Batch 170 training: round 1 -------------------------
2023-03-25 18:16:13,078 : [INFO]  ------------------------- Batch round 1, loss: 0.5873 -------------------------
2023-03-25 18:16:13,078 : [INFO]  ------------------------- Batch 170, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:13,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:13,121 : [INFO]  ------------------------- Batch 170 training: round 2 -------------------------
2023-03-25 18:16:16,012 : [INFO]  ------------------------- Batch round 2, loss: 0.5825 -------------------------
2023-03-25 18:16:16,013 : [INFO]  ------------------------- Batch 170, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:16,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:16,027 : [INFO]  ------------------------- Batch 170 training: round 3 -------------------------
2023-03-25 18:16:19,016 : [INFO]  ------------------------- Batch round 3, loss: 0.5841 -------------------------
2023-03-25 18:16:19,016 : [INFO]  ------------------------- Batch 170, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:19,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:19,028 : [INFO]  Batch number 170 model fetched from the server
2023-03-25 18:16:19,029 : [INFO]  ################ Batch 170: final global model evalution after 3 rounds ################
2023-03-25 18:16:20,800 : [INFO]  Batch 170: Training set : loss - 0.6024, accuracy - 0.663, recall - 0.7935, AUC - 0.7791, F1 - 0.7019, precision - 0.6293, training time - -12.0 seconds
2023-03-25 18:16:20,800 : [INFO]  Batch 170: Testing set : loss - 0.5788, accuracy - 0.6765, recall - 0.7843, AUC - 0.822, F1 - 0.708, precision - 0.6452
2023-03-25 18:16:20,816 : [INFO]  Batch 171 initialized 
2023-03-25 18:16:21,426 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:21,993 : [INFO]  ------------------------- Batch 171 training: round 1 -------------------------
2023-03-25 18:16:27,386 : [INFO]  ------------------------- Batch round 1, loss: 0.5881 -------------------------
2023-03-25 18:16:27,386 : [INFO]  ------------------------- Batch 171, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:27,527 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:27,529 : [INFO]  ------------------------- Batch 171 training: round 2 -------------------------
2023-03-25 18:16:30,282 : [INFO]  ------------------------- Batch round 2, loss: 0.5878 -------------------------
2023-03-25 18:16:30,283 : [INFO]  ------------------------- Batch 171, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:30,469 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:30,471 : [INFO]  ------------------------- Batch 171 training: round 3 -------------------------
2023-03-25 18:16:33,215 : [INFO]  ------------------------- Batch round 3, loss: 0.5812 -------------------------
2023-03-25 18:16:33,216 : [INFO]  ------------------------- Batch 171, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:33,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:33,476 : [INFO]  Batch number 171 model fetched from the server
2023-03-25 18:16:33,477 : [INFO]  ################ Batch 171: final global model evalution after 3 rounds ################
2023-03-25 18:16:35,194 : [INFO]  Batch 171: Training set : loss - 0.5906, accuracy - 0.7283, recall - 0.9239, AUC - 0.8104, F1 - 0.7727, precision - 0.6641, training time - -11.0 seconds
2023-03-25 18:16:35,194 : [INFO]  Batch 171: Testing set : loss - 0.5594, accuracy - 0.75, recall - 0.8627, AUC - 0.851, F1 - 0.7753, precision - 0.704
2023-03-25 18:16:35,207 : [INFO]  Batch 172 initialized 
2023-03-25 18:16:35,760 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:36,309 : [INFO]  ------------------------- Batch 172 training: round 1 -------------------------
2023-03-25 18:16:41,639 : [INFO]  ------------------------- Batch round 1, loss: 0.5635 -------------------------
2023-03-25 18:16:41,640 : [INFO]  ------------------------- Batch 172, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:41,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:41,796 : [INFO]  ------------------------- Batch 172 training: round 2 -------------------------
2023-03-25 18:16:44,607 : [INFO]  ------------------------- Batch round 2, loss: 0.5664 -------------------------
2023-03-25 18:16:44,607 : [INFO]  ------------------------- Batch 172, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:44,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:44,723 : [INFO]  ------------------------- Batch 172 training: round 3 -------------------------
2023-03-25 18:16:47,488 : [INFO]  ------------------------- Batch round 3, loss: 0.5635 -------------------------
2023-03-25 18:16:47,488 : [INFO]  ------------------------- Batch 172, round 3: Sent local model to the server -------------------------
2023-03-25 18:16:47,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:47,578 : [INFO]  Batch number 172 model fetched from the server
2023-03-25 18:16:47,578 : [INFO]  ################ Batch 172: final global model evalution after 3 rounds ################
2023-03-25 18:16:49,316 : [INFO]  Batch 172: Training set : loss - 0.571, accuracy - 0.7283, recall - 0.9022, AUC - 0.8515, F1 - 0.7685, precision - 0.6694, training time - -11.0 seconds
2023-03-25 18:16:49,316 : [INFO]  Batch 172: Testing set : loss - 0.585, accuracy - 0.6961, recall - 0.8235, AUC - 0.8107, F1 - 0.7304, precision - 0.6562
2023-03-25 18:16:49,331 : [INFO]  Batch 173 initialized 
2023-03-25 18:16:49,890 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:16:50,444 : [INFO]  ------------------------- Batch 173 training: round 1 -------------------------
2023-03-25 18:16:55,683 : [INFO]  ------------------------- Batch round 1, loss: 0.5876 -------------------------
2023-03-25 18:16:55,683 : [INFO]  ------------------------- Batch 173, round 1: Sent local model to the server -------------------------
2023-03-25 18:16:55,908 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:55,911 : [INFO]  ------------------------- Batch 173 training: round 2 -------------------------
2023-03-25 18:16:58,631 : [INFO]  ------------------------- Batch round 2, loss: 0.5967 -------------------------
2023-03-25 18:16:58,631 : [INFO]  ------------------------- Batch 173, round 2: Sent local model to the server -------------------------
2023-03-25 18:16:58,819 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:16:58,821 : [INFO]  ------------------------- Batch 173 training: round 3 -------------------------
2023-03-25 18:17:01,591 : [INFO]  ------------------------- Batch round 3, loss: 0.6004 -------------------------
2023-03-25 18:17:01,591 : [INFO]  ------------------------- Batch 173, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:01,711 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:01,714 : [INFO]  Batch number 173 model fetched from the server
2023-03-25 18:17:01,714 : [INFO]  ################ Batch 173: final global model evalution after 3 rounds ################
2023-03-25 18:17:03,501 : [INFO]  Batch 173: Training set : loss - 0.6058, accuracy - 0.663, recall - 0.8478, AUC - 0.7987, F1 - 0.7156, precision - 0.619, training time - -11.0 seconds
2023-03-25 18:17:03,501 : [INFO]  Batch 173: Testing set : loss - 0.5849, accuracy - 0.7059, recall - 0.8824, AUC - 0.8428, F1 - 0.75, precision - 0.6522
2023-03-25 18:17:03,516 : [INFO]  Batch 174 initialized 
2023-03-25 18:17:04,089 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:04,636 : [INFO]  ------------------------- Batch 174 training: round 1 -------------------------
2023-03-25 18:17:09,866 : [INFO]  ------------------------- Batch round 1, loss: 0.5549 -------------------------
2023-03-25 18:17:09,866 : [INFO]  ------------------------- Batch 174, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:10,065 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:10,068 : [INFO]  ------------------------- Batch 174 training: round 2 -------------------------
2023-03-25 18:17:12,856 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-25 18:17:12,856 : [INFO]  ------------------------- Batch 174, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:13,037 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:13,039 : [INFO]  ------------------------- Batch 174 training: round 3 -------------------------
2023-03-25 18:17:15,745 : [INFO]  ------------------------- Batch round 3, loss: 0.5615 -------------------------
2023-03-25 18:17:15,745 : [INFO]  ------------------------- Batch 174, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:16,130 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:16,133 : [INFO]  Batch number 174 model fetched from the server
2023-03-25 18:17:16,133 : [INFO]  ################ Batch 174: final global model evalution after 3 rounds ################
2023-03-25 18:17:17,881 : [INFO]  Batch 174: Training set : loss - 0.5732, accuracy - 0.712, recall - 0.8913, AUC - 0.8399, F1 - 0.7558, precision - 0.656, training time - -11.0 seconds
2023-03-25 18:17:17,881 : [INFO]  Batch 174: Testing set : loss - 0.5652, accuracy - 0.7206, recall - 0.9216, AUC - 0.8832, F1 - 0.7673, precision - 0.6573
2023-03-25 18:17:17,896 : [INFO]  Batch 175 initialized 
2023-03-25 18:17:18,452 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:18,993 : [INFO]  ------------------------- Batch 175 training: round 1 -------------------------
2023-03-25 18:17:24,276 : [INFO]  ------------------------- Batch round 1, loss: 0.6033 -------------------------
2023-03-25 18:17:24,276 : [INFO]  ------------------------- Batch 175, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:24,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:24,656 : [INFO]  ------------------------- Batch 175 training: round 2 -------------------------
2023-03-25 18:17:27,480 : [INFO]  ------------------------- Batch round 2, loss: 0.6042 -------------------------
2023-03-25 18:17:27,481 : [INFO]  ------------------------- Batch 175, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:27,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:27,709 : [INFO]  ------------------------- Batch 175 training: round 3 -------------------------
2023-03-25 18:17:30,623 : [INFO]  ------------------------- Batch round 3, loss: 0.6095 -------------------------
2023-03-25 18:17:30,624 : [INFO]  ------------------------- Batch 175, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:30,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:30,883 : [INFO]  Batch number 175 model fetched from the server
2023-03-25 18:17:30,883 : [INFO]  ################ Batch 175: final global model evalution after 3 rounds ################
2023-03-25 18:17:32,674 : [INFO]  Batch 175: Training set : loss - 0.6115, accuracy - 0.6739, recall - 0.8913, AUC - 0.7646, F1 - 0.7321, precision - 0.6212, training time - -12.0 seconds
2023-03-25 18:17:32,675 : [INFO]  Batch 175: Testing set : loss - 0.565, accuracy - 0.7108, recall - 0.8725, AUC - 0.8398, F1 - 0.7511, precision - 0.6593
2023-03-25 18:17:32,689 : [INFO]  Batch 176 initialized 
2023-03-25 18:17:33,245 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:33,773 : [INFO]  ------------------------- Batch 176 training: round 1 -------------------------
2023-03-25 18:17:39,239 : [INFO]  ------------------------- Batch round 1, loss: 0.58 -------------------------
2023-03-25 18:17:39,239 : [INFO]  ------------------------- Batch 176, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:39,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:39,436 : [INFO]  ------------------------- Batch 176 training: round 2 -------------------------
2023-03-25 18:17:42,444 : [INFO]  ------------------------- Batch round 2, loss: 0.5757 -------------------------
2023-03-25 18:17:42,444 : [INFO]  ------------------------- Batch 176, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:42,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:42,457 : [INFO]  ------------------------- Batch 176 training: round 3 -------------------------
2023-03-25 18:17:45,416 : [INFO]  ------------------------- Batch round 3, loss: 0.5814 -------------------------
2023-03-25 18:17:45,417 : [INFO]  ------------------------- Batch 176, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:45,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:45,430 : [INFO]  Batch number 176 model fetched from the server
2023-03-25 18:17:45,430 : [INFO]  ################ Batch 176: final global model evalution after 3 rounds ################
2023-03-25 18:17:47,160 : [INFO]  Batch 176: Training set : loss - 0.5866, accuracy - 0.6848, recall - 0.8804, AUC - 0.823, F1 - 0.7364, precision - 0.6328, training time - -12.0 seconds
2023-03-25 18:17:47,160 : [INFO]  Batch 176: Testing set : loss - 0.5876, accuracy - 0.6912, recall - 0.8627, AUC - 0.8126, F1 - 0.7364, precision - 0.6423
2023-03-25 18:17:47,173 : [INFO]  Batch 177 initialized 
2023-03-25 18:17:47,737 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:17:48,305 : [INFO]  ------------------------- Batch 177 training: round 1 -------------------------
2023-03-25 18:17:53,676 : [INFO]  ------------------------- Batch round 1, loss: 0.5763 -------------------------
2023-03-25 18:17:53,676 : [INFO]  ------------------------- Batch 177, round 1: Sent local model to the server -------------------------
2023-03-25 18:17:53,734 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:53,737 : [INFO]  ------------------------- Batch 177 training: round 2 -------------------------
2023-03-25 18:17:56,630 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 18:17:56,630 : [INFO]  ------------------------- Batch 177, round 2: Sent local model to the server -------------------------
2023-03-25 18:17:56,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:56,642 : [INFO]  ------------------------- Batch 177 training: round 3 -------------------------
2023-03-25 18:17:59,580 : [INFO]  ------------------------- Batch round 3, loss: 0.5758 -------------------------
2023-03-25 18:17:59,580 : [INFO]  ------------------------- Batch 177, round 3: Sent local model to the server -------------------------
2023-03-25 18:17:59,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:17:59,592 : [INFO]  Batch number 177 model fetched from the server
2023-03-25 18:17:59,592 : [INFO]  ################ Batch 177: final global model evalution after 3 rounds ################
2023-03-25 18:18:01,405 : [INFO]  Batch 177: Training set : loss - 0.5779, accuracy - 0.7174, recall - 0.8913, AUC - 0.8414, F1 - 0.7593, precision - 0.6613, training time - -11.0 seconds
2023-03-25 18:18:01,405 : [INFO]  Batch 177: Testing set : loss - 0.5887, accuracy - 0.6667, recall - 0.8529, AUC - 0.834, F1 - 0.719, precision - 0.6214
2023-03-25 18:18:01,415 : [INFO]  Batch 178 initialized 
2023-03-25 18:18:01,969 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:02,540 : [INFO]  ------------------------- Batch 178 training: round 1 -------------------------
2023-03-25 18:18:08,067 : [INFO]  ------------------------- Batch round 1, loss: 0.5777 -------------------------
2023-03-25 18:18:08,067 : [INFO]  ------------------------- Batch 178, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:08,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:08,083 : [INFO]  ------------------------- Batch 178 training: round 2 -------------------------
2023-03-25 18:18:11,147 : [INFO]  ------------------------- Batch round 2, loss: 0.5728 -------------------------
2023-03-25 18:18:11,147 : [INFO]  ------------------------- Batch 178, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:11,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:11,163 : [INFO]  ------------------------- Batch 178 training: round 3 -------------------------
2023-03-25 18:18:14,167 : [INFO]  ------------------------- Batch round 3, loss: 0.5748 -------------------------
2023-03-25 18:18:14,167 : [INFO]  ------------------------- Batch 178, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:14,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:14,181 : [INFO]  Batch number 178 model fetched from the server
2023-03-25 18:18:14,181 : [INFO]  ################ Batch 178: final global model evalution after 3 rounds ################
2023-03-25 18:18:16,036 : [INFO]  Batch 178: Training set : loss - 0.5812, accuracy - 0.7228, recall - 0.8587, AUC - 0.8317, F1 - 0.756, precision - 0.6752, training time - -12.0 seconds
2023-03-25 18:18:16,036 : [INFO]  Batch 178: Testing set : loss - 0.6013, accuracy - 0.701, recall - 0.8725, AUC - 0.8076, F1 - 0.7448, precision - 0.6496
2023-03-25 18:18:16,043 : [INFO]  Batch 179 initialized 
2023-03-25 18:18:16,589 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:17,158 : [INFO]  ------------------------- Batch 179 training: round 1 -------------------------
2023-03-25 18:18:22,682 : [INFO]  ------------------------- Batch round 1, loss: 0.5935 -------------------------
2023-03-25 18:18:22,682 : [INFO]  ------------------------- Batch 179, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:22,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:22,697 : [INFO]  ------------------------- Batch 179 training: round 2 -------------------------
2023-03-25 18:18:25,747 : [INFO]  ------------------------- Batch round 2, loss: 0.5973 -------------------------
2023-03-25 18:18:25,747 : [INFO]  ------------------------- Batch 179, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:25,759 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:25,761 : [INFO]  ------------------------- Batch 179 training: round 3 -------------------------
2023-03-25 18:18:28,748 : [INFO]  ------------------------- Batch round 3, loss: 0.5922 -------------------------
2023-03-25 18:18:28,748 : [INFO]  ------------------------- Batch 179, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:28,761 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:28,764 : [INFO]  Batch number 179 model fetched from the server
2023-03-25 18:18:28,764 : [INFO]  ################ Batch 179: final global model evalution after 3 rounds ################
2023-03-25 18:18:30,621 : [INFO]  Batch 179: Training set : loss - 0.6159, accuracy - 0.6576, recall - 0.9022, AUC - 0.7907, F1 - 0.7249, precision - 0.6058, training time - -12.0 seconds
2023-03-25 18:18:30,621 : [INFO]  Batch 179: Testing set : loss - 0.6322, accuracy - 0.6275, recall - 0.8725, AUC - 0.7556, F1 - 0.7008, precision - 0.5855
2023-03-25 18:18:30,633 : [INFO]  Batch 180 initialized 
2023-03-25 18:18:31,198 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:31,757 : [INFO]  ------------------------- Batch 180 training: round 1 -------------------------
2023-03-25 18:18:37,163 : [INFO]  ------------------------- Batch round 1, loss: 0.5837 -------------------------
2023-03-25 18:18:37,163 : [INFO]  ------------------------- Batch 180, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:37,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:37,177 : [INFO]  ------------------------- Batch 180 training: round 2 -------------------------
2023-03-25 18:18:40,183 : [INFO]  ------------------------- Batch round 2, loss: 0.5826 -------------------------
2023-03-25 18:18:40,183 : [INFO]  ------------------------- Batch 180, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:40,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:40,224 : [INFO]  ------------------------- Batch 180 training: round 3 -------------------------
2023-03-25 18:18:43,198 : [INFO]  ------------------------- Batch round 3, loss: 0.5806 -------------------------
2023-03-25 18:18:43,199 : [INFO]  ------------------------- Batch 180, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:43,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:43,212 : [INFO]  Batch number 180 model fetched from the server
2023-03-25 18:18:43,212 : [INFO]  ################ Batch 180: final global model evalution after 3 rounds ################
2023-03-25 18:18:44,996 : [INFO]  Batch 180: Training set : loss - 0.5919, accuracy - 0.7065, recall - 0.8587, AUC - 0.813, F1 - 0.7453, precision - 0.6583, training time - -11.0 seconds
2023-03-25 18:18:44,996 : [INFO]  Batch 180: Testing set : loss - 0.5715, accuracy - 0.7402, recall - 0.902, AUC - 0.8647, F1 - 0.7764, precision - 0.6815
2023-03-25 18:18:45,010 : [INFO]  Batch 181 initialized 
2023-03-25 18:18:45,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:18:46,161 : [INFO]  ------------------------- Batch 181 training: round 1 -------------------------
2023-03-25 18:18:51,523 : [INFO]  ------------------------- Batch round 1, loss: 0.5549 -------------------------
2023-03-25 18:18:51,524 : [INFO]  ------------------------- Batch 181, round 1: Sent local model to the server -------------------------
2023-03-25 18:18:51,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:51,551 : [INFO]  ------------------------- Batch 181 training: round 2 -------------------------
2023-03-25 18:18:54,410 : [INFO]  ------------------------- Batch round 2, loss: 0.5677 -------------------------
2023-03-25 18:18:54,411 : [INFO]  ------------------------- Batch 181, round 2: Sent local model to the server -------------------------
2023-03-25 18:18:54,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:54,424 : [INFO]  ------------------------- Batch 181 training: round 3 -------------------------
2023-03-25 18:18:57,322 : [INFO]  ------------------------- Batch round 3, loss: 0.5646 -------------------------
2023-03-25 18:18:57,322 : [INFO]  ------------------------- Batch 181, round 3: Sent local model to the server -------------------------
2023-03-25 18:18:57,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:18:57,336 : [INFO]  Batch number 181 model fetched from the server
2023-03-25 18:18:57,337 : [INFO]  ################ Batch 181: final global model evalution after 3 rounds ################
2023-03-25 18:18:59,068 : [INFO]  Batch 181: Training set : loss - 0.5723, accuracy - 0.7446, recall - 0.8478, AUC - 0.808, F1 - 0.7685, precision - 0.7027, training time - -11.0 seconds
2023-03-25 18:18:59,068 : [INFO]  Batch 181: Testing set : loss - 0.574, accuracy - 0.7255, recall - 0.9216, AUC - 0.8378, F1 - 0.7705, precision - 0.662
2023-03-25 18:18:59,076 : [INFO]  Batch 182 initialized 
2023-03-25 18:18:59,640 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:00,220 : [INFO]  ------------------------- Batch 182 training: round 1 -------------------------
2023-03-25 18:19:05,585 : [INFO]  ------------------------- Batch round 1, loss: 0.5901 -------------------------
2023-03-25 18:19:05,585 : [INFO]  ------------------------- Batch 182, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:05,597 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:05,600 : [INFO]  ------------------------- Batch 182 training: round 2 -------------------------
2023-03-25 18:19:08,512 : [INFO]  ------------------------- Batch round 2, loss: 0.5929 -------------------------
2023-03-25 18:19:08,512 : [INFO]  ------------------------- Batch 182, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:08,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:08,526 : [INFO]  ------------------------- Batch 182 training: round 3 -------------------------
2023-03-25 18:19:11,432 : [INFO]  ------------------------- Batch round 3, loss: 0.5936 -------------------------
2023-03-25 18:19:11,432 : [INFO]  ------------------------- Batch 182, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:11,442 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:11,444 : [INFO]  Batch number 182 model fetched from the server
2023-03-25 18:19:11,445 : [INFO]  ################ Batch 182: final global model evalution after 3 rounds ################
2023-03-25 18:19:13,205 : [INFO]  Batch 182: Training set : loss - 0.6092, accuracy - 0.6413, recall - 0.837, AUC - 0.7871, F1 - 0.7, precision - 0.6016, training time - -11.0 seconds
2023-03-25 18:19:13,205 : [INFO]  Batch 182: Testing set : loss - 0.5988, accuracy - 0.6422, recall - 0.7843, AUC - 0.7806, F1 - 0.6867, precision - 0.6107
2023-03-25 18:19:13,214 : [INFO]  Batch 183 initialized 
2023-03-25 18:19:13,774 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:14,354 : [INFO]  ------------------------- Batch 183 training: round 1 -------------------------
2023-03-25 18:19:19,654 : [INFO]  ------------------------- Batch round 1, loss: 0.5638 -------------------------
2023-03-25 18:19:19,654 : [INFO]  ------------------------- Batch 183, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:19,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:19,755 : [INFO]  ------------------------- Batch 183 training: round 2 -------------------------
2023-03-25 18:19:22,796 : [INFO]  ------------------------- Batch round 2, loss: 0.5625 -------------------------
2023-03-25 18:19:22,796 : [INFO]  ------------------------- Batch 183, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:22,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:22,830 : [INFO]  ------------------------- Batch 183 training: round 3 -------------------------
2023-03-25 18:19:25,628 : [INFO]  ------------------------- Batch round 3, loss: 0.5634 -------------------------
2023-03-25 18:19:25,629 : [INFO]  ------------------------- Batch 183, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:25,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:25,744 : [INFO]  Batch number 183 model fetched from the server
2023-03-25 18:19:25,744 : [INFO]  ################ Batch 183: final global model evalution after 3 rounds ################
2023-03-25 18:19:27,537 : [INFO]  Batch 183: Training set : loss - 0.5663, accuracy - 0.7337, recall - 0.9565, AUC - 0.8655, F1 - 0.7822, precision - 0.6617, training time - -11.0 seconds
2023-03-25 18:19:27,537 : [INFO]  Batch 183: Testing set : loss - 0.5696, accuracy - 0.7402, recall - 0.8824, AUC - 0.8288, F1 - 0.7725, precision - 0.687
2023-03-25 18:19:27,546 : [INFO]  Batch 184 initialized 
2023-03-25 18:19:28,111 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:28,691 : [INFO]  ------------------------- Batch 184 training: round 1 -------------------------
2023-03-25 18:19:33,995 : [INFO]  ------------------------- Batch round 1, loss: 0.5728 -------------------------
2023-03-25 18:19:33,995 : [INFO]  ------------------------- Batch 184, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:34,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:34,098 : [INFO]  ------------------------- Batch 184 training: round 2 -------------------------
2023-03-25 18:19:36,900 : [INFO]  ------------------------- Batch round 2, loss: 0.5712 -------------------------
2023-03-25 18:19:36,900 : [INFO]  ------------------------- Batch 184, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:36,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:36,960 : [INFO]  ------------------------- Batch 184 training: round 3 -------------------------
2023-03-25 18:19:39,726 : [INFO]  ------------------------- Batch round 3, loss: 0.5674 -------------------------
2023-03-25 18:19:39,726 : [INFO]  ------------------------- Batch 184, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:39,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:39,761 : [INFO]  Batch number 184 model fetched from the server
2023-03-25 18:19:39,761 : [INFO]  ################ Batch 184: final global model evalution after 3 rounds ################
2023-03-25 18:19:41,531 : [INFO]  Batch 184: Training set : loss - 0.5748, accuracy - 0.7011, recall - 0.913, AUC - 0.8573, F1 - 0.7534, precision - 0.6412, training time - -11.0 seconds
2023-03-25 18:19:41,531 : [INFO]  Batch 184: Testing set : loss - 0.5668, accuracy - 0.6961, recall - 0.8922, AUC - 0.8673, F1 - 0.7459, precision - 0.6408
2023-03-25 18:19:41,546 : [INFO]  Batch 185 initialized 
2023-03-25 18:19:42,108 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:42,697 : [INFO]  ------------------------- Batch 185 training: round 1 -------------------------
2023-03-25 18:19:48,084 : [INFO]  ------------------------- Batch round 1, loss: 0.5619 -------------------------
2023-03-25 18:19:48,084 : [INFO]  ------------------------- Batch 185, round 1: Sent local model to the server -------------------------
2023-03-25 18:19:48,095 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:48,098 : [INFO]  ------------------------- Batch 185 training: round 2 -------------------------
2023-03-25 18:19:50,819 : [INFO]  ------------------------- Batch round 2, loss: 0.5569 -------------------------
2023-03-25 18:19:50,819 : [INFO]  ------------------------- Batch 185, round 2: Sent local model to the server -------------------------
2023-03-25 18:19:50,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:50,833 : [INFO]  ------------------------- Batch 185 training: round 3 -------------------------
2023-03-25 18:19:53,680 : [INFO]  ------------------------- Batch round 3, loss: 0.5623 -------------------------
2023-03-25 18:19:53,680 : [INFO]  ------------------------- Batch 185, round 3: Sent local model to the server -------------------------
2023-03-25 18:19:53,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:19:53,695 : [INFO]  Batch number 185 model fetched from the server
2023-03-25 18:19:53,695 : [INFO]  ################ Batch 185: final global model evalution after 3 rounds ################
2023-03-25 18:19:55,491 : [INFO]  Batch 185: Training set : loss - 0.5613, accuracy - 0.75, recall - 0.9457, AUC - 0.867, F1 - 0.7909, precision - 0.6797, training time - -11.0 seconds
2023-03-25 18:19:55,491 : [INFO]  Batch 185: Testing set : loss - 0.5553, accuracy - 0.7549, recall - 0.9216, AUC - 0.8651, F1 - 0.7899, precision - 0.6912
2023-03-25 18:19:55,502 : [INFO]  Batch 186 initialized 
2023-03-25 18:19:56,069 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:19:56,650 : [INFO]  ------------------------- Batch 186 training: round 1 -------------------------
2023-03-25 18:20:02,081 : [INFO]  ------------------------- Batch round 1, loss: 0.5788 -------------------------
2023-03-25 18:20:02,081 : [INFO]  ------------------------- Batch 186, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:02,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:02,238 : [INFO]  ------------------------- Batch 186 training: round 2 -------------------------
2023-03-25 18:20:05,152 : [INFO]  ------------------------- Batch round 2, loss: 0.5705 -------------------------
2023-03-25 18:20:05,152 : [INFO]  ------------------------- Batch 186, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:05,220 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:05,222 : [INFO]  ------------------------- Batch 186 training: round 3 -------------------------
2023-03-25 18:20:08,049 : [INFO]  ------------------------- Batch round 3, loss: 0.5787 -------------------------
2023-03-25 18:20:08,049 : [INFO]  ------------------------- Batch 186, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:08,197 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:08,201 : [INFO]  Batch number 186 model fetched from the server
2023-03-25 18:20:08,201 : [INFO]  ################ Batch 186: final global model evalution after 3 rounds ################
2023-03-25 18:20:09,964 : [INFO]  Batch 186: Training set : loss - 0.594, accuracy - 0.6739, recall - 0.8478, AUC - 0.8166, F1 - 0.7222, precision - 0.629, training time - -12.0 seconds
2023-03-25 18:20:09,965 : [INFO]  Batch 186: Testing set : loss - 0.5893, accuracy - 0.7255, recall - 0.8627, AUC - 0.821, F1 - 0.7586, precision - 0.6769
2023-03-25 18:20:09,974 : [INFO]  Batch 187 initialized 
2023-03-25 18:20:10,542 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:11,093 : [INFO]  ------------------------- Batch 187 training: round 1 -------------------------
2023-03-25 18:20:16,548 : [INFO]  ------------------------- Batch round 1, loss: 0.5927 -------------------------
2023-03-25 18:20:16,549 : [INFO]  ------------------------- Batch 187, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:16,603 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:16,607 : [INFO]  ------------------------- Batch 187 training: round 2 -------------------------
2023-03-25 18:20:19,527 : [INFO]  ------------------------- Batch round 2, loss: 0.588 -------------------------
2023-03-25 18:20:19,527 : [INFO]  ------------------------- Batch 187, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:19,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:19,540 : [INFO]  ------------------------- Batch 187 training: round 3 -------------------------
2023-03-25 18:20:22,509 : [INFO]  ------------------------- Batch round 3, loss: 0.5894 -------------------------
2023-03-25 18:20:22,510 : [INFO]  ------------------------- Batch 187, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:22,520 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:22,522 : [INFO]  Batch number 187 model fetched from the server
2023-03-25 18:20:22,522 : [INFO]  ################ Batch 187: final global model evalution after 3 rounds ################
2023-03-25 18:20:24,405 : [INFO]  Batch 187: Training set : loss - 0.6119, accuracy - 0.6359, recall - 0.8152, AUC - 0.7791, F1 - 0.6912, precision - 0.6, training time - -11.0 seconds
2023-03-25 18:20:24,405 : [INFO]  Batch 187: Testing set : loss - 0.6351, accuracy - 0.6127, recall - 0.7451, AUC - 0.722, F1 - 0.658, precision - 0.5891
2023-03-25 18:20:24,413 : [INFO]  Batch 188 initialized 
2023-03-25 18:20:24,983 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:25,554 : [INFO]  ------------------------- Batch 188 training: round 1 -------------------------
2023-03-25 18:20:31,139 : [INFO]  ------------------------- Batch round 1, loss: 0.5796 -------------------------
2023-03-25 18:20:31,139 : [INFO]  ------------------------- Batch 188, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:31,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:31,218 : [INFO]  ------------------------- Batch 188 training: round 2 -------------------------
2023-03-25 18:20:34,242 : [INFO]  ------------------------- Batch round 2, loss: 0.5779 -------------------------
2023-03-25 18:20:34,243 : [INFO]  ------------------------- Batch 188, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:34,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:34,259 : [INFO]  ------------------------- Batch 188 training: round 3 -------------------------
2023-03-25 18:20:37,144 : [INFO]  ------------------------- Batch round 3, loss: 0.5811 -------------------------
2023-03-25 18:20:37,144 : [INFO]  ------------------------- Batch 188, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:37,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:37,178 : [INFO]  Batch number 188 model fetched from the server
2023-03-25 18:20:37,178 : [INFO]  ################ Batch 188: final global model evalution after 3 rounds ################
2023-03-25 18:20:38,956 : [INFO]  Batch 188: Training set : loss - 0.5911, accuracy - 0.663, recall - 0.8804, AUC - 0.8413, F1 - 0.7232, precision - 0.6136, training time - -12.0 seconds
2023-03-25 18:20:38,957 : [INFO]  Batch 188: Testing set : loss - 0.5837, accuracy - 0.6765, recall - 0.8529, AUC - 0.829, F1 - 0.725, precision - 0.6304
2023-03-25 18:20:38,969 : [INFO]  Batch 189 initialized 
2023-03-25 18:20:39,560 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:40,172 : [INFO]  ------------------------- Batch 189 training: round 1 -------------------------
2023-03-25 18:20:45,691 : [INFO]  ------------------------- Batch round 1, loss: 0.5981 -------------------------
2023-03-25 18:20:45,691 : [INFO]  ------------------------- Batch 189, round 1: Sent local model to the server -------------------------
2023-03-25 18:20:45,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:45,704 : [INFO]  ------------------------- Batch 189 training: round 2 -------------------------
2023-03-25 18:20:48,584 : [INFO]  ------------------------- Batch round 2, loss: 0.5946 -------------------------
2023-03-25 18:20:48,584 : [INFO]  ------------------------- Batch 189, round 2: Sent local model to the server -------------------------
2023-03-25 18:20:48,596 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:48,599 : [INFO]  ------------------------- Batch 189 training: round 3 -------------------------
2023-03-25 18:20:51,474 : [INFO]  ------------------------- Batch round 3, loss: 0.5866 -------------------------
2023-03-25 18:20:51,475 : [INFO]  ------------------------- Batch 189, round 3: Sent local model to the server -------------------------
2023-03-25 18:20:51,486 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:20:51,488 : [INFO]  Batch number 189 model fetched from the server
2023-03-25 18:20:51,489 : [INFO]  ################ Batch 189: final global model evalution after 3 rounds ################
2023-03-25 18:20:53,245 : [INFO]  Batch 189: Training set : loss - 0.6052, accuracy - 0.6467, recall - 0.837, AUC - 0.8217, F1 - 0.7032, precision - 0.6063, training time - -11.0 seconds
2023-03-25 18:20:53,246 : [INFO]  Batch 189: Testing set : loss - 0.5858, accuracy - 0.6961, recall - 0.8922, AUC - 0.8355, F1 - 0.7459, precision - 0.6408
2023-03-25 18:20:53,260 : [INFO]  Batch 190 initialized 
2023-03-25 18:20:53,819 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:20:54,427 : [INFO]  ------------------------- Batch 190 training: round 1 -------------------------
2023-03-25 18:20:59,893 : [INFO]  ------------------------- Batch round 1, loss: 0.5712 -------------------------
2023-03-25 18:20:59,893 : [INFO]  ------------------------- Batch 190, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:00,055 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:00,057 : [INFO]  ------------------------- Batch 190 training: round 2 -------------------------
2023-03-25 18:21:02,885 : [INFO]  ------------------------- Batch round 2, loss: 0.574 -------------------------
2023-03-25 18:21:02,885 : [INFO]  ------------------------- Batch 190, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:03,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:03,040 : [INFO]  ------------------------- Batch 190 training: round 3 -------------------------
2023-03-25 18:21:05,909 : [INFO]  ------------------------- Batch round 3, loss: 0.5705 -------------------------
2023-03-25 18:21:05,909 : [INFO]  ------------------------- Batch 190, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:06,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:06,119 : [INFO]  Batch number 190 model fetched from the server
2023-03-25 18:21:06,119 : [INFO]  ################ Batch 190: final global model evalution after 3 rounds ################
2023-03-25 18:21:07,923 : [INFO]  Batch 190: Training set : loss - 0.582, accuracy - 0.7337, recall - 0.9348, AUC - 0.8259, F1 - 0.7783, precision - 0.6667, training time - -12.0 seconds
2023-03-25 18:21:07,924 : [INFO]  Batch 190: Testing set : loss - 0.5756, accuracy - 0.701, recall - 0.8431, AUC - 0.8391, F1 - 0.7382, precision - 0.6565
2023-03-25 18:21:07,938 : [INFO]  Batch 191 initialized 
2023-03-25 18:21:08,515 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:09,083 : [INFO]  ------------------------- Batch 191 training: round 1 -------------------------
2023-03-25 18:21:14,553 : [INFO]  ------------------------- Batch round 1, loss: 0.559 -------------------------
2023-03-25 18:21:14,553 : [INFO]  ------------------------- Batch 191, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:14,564 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:14,566 : [INFO]  ------------------------- Batch 191 training: round 2 -------------------------
2023-03-25 18:21:17,402 : [INFO]  ------------------------- Batch round 2, loss: 0.5646 -------------------------
2023-03-25 18:21:17,403 : [INFO]  ------------------------- Batch 191, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:17,413 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:17,416 : [INFO]  ------------------------- Batch 191 training: round 3 -------------------------
2023-03-25 18:21:20,322 : [INFO]  ------------------------- Batch round 3, loss: 0.5654 -------------------------
2023-03-25 18:21:20,322 : [INFO]  ------------------------- Batch 191, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:20,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:20,336 : [INFO]  Batch number 191 model fetched from the server
2023-03-25 18:21:20,336 : [INFO]  ################ Batch 191: final global model evalution after 3 rounds ################
2023-03-25 18:21:22,147 : [INFO]  Batch 191: Training set : loss - 0.5689, accuracy - 0.7446, recall - 0.8804, AUC - 0.83, F1 - 0.7751, precision - 0.6923, training time - -11.0 seconds
2023-03-25 18:21:22,147 : [INFO]  Batch 191: Testing set : loss - 0.5911, accuracy - 0.6912, recall - 0.8529, AUC - 0.8156, F1 - 0.7342, precision - 0.6444
2023-03-25 18:21:22,160 : [INFO]  Batch 192 initialized 
2023-03-25 18:21:22,749 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:23,353 : [INFO]  ------------------------- Batch 192 training: round 1 -------------------------
2023-03-25 18:21:28,974 : [INFO]  ------------------------- Batch round 1, loss: 0.5418 -------------------------
2023-03-25 18:21:28,974 : [INFO]  ------------------------- Batch 192, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:28,987 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:28,990 : [INFO]  ------------------------- Batch 192 training: round 2 -------------------------
2023-03-25 18:21:31,932 : [INFO]  ------------------------- Batch round 2, loss: 0.5433 -------------------------
2023-03-25 18:21:31,932 : [INFO]  ------------------------- Batch 192, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:31,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:31,951 : [INFO]  ------------------------- Batch 192 training: round 3 -------------------------
2023-03-25 18:21:34,850 : [INFO]  ------------------------- Batch round 3, loss: 0.5433 -------------------------
2023-03-25 18:21:34,850 : [INFO]  ------------------------- Batch 192, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:34,872 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:34,875 : [INFO]  Batch number 192 model fetched from the server
2023-03-25 18:21:34,875 : [INFO]  ################ Batch 192: final global model evalution after 3 rounds ################
2023-03-25 18:21:36,738 : [INFO]  Batch 192: Training set : loss - 0.5567, accuracy - 0.7337, recall - 0.8804, AUC - 0.8746, F1 - 0.7678, precision - 0.6807, training time - -12.0 seconds
2023-03-25 18:21:36,738 : [INFO]  Batch 192: Testing set : loss - 0.5576, accuracy - 0.7402, recall - 0.9118, AUC - 0.8835, F1 - 0.7782, precision - 0.6788
2023-03-25 18:21:36,753 : [INFO]  Batch 193 initialized 
2023-03-25 18:21:37,342 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:37,950 : [INFO]  ------------------------- Batch 193 training: round 1 -------------------------
2023-03-25 18:21:43,445 : [INFO]  ------------------------- Batch round 1, loss: 0.5723 -------------------------
2023-03-25 18:21:43,445 : [INFO]  ------------------------- Batch 193, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:43,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:43,459 : [INFO]  ------------------------- Batch 193 training: round 2 -------------------------
2023-03-25 18:21:46,356 : [INFO]  ------------------------- Batch round 2, loss: 0.5771 -------------------------
2023-03-25 18:21:46,356 : [INFO]  ------------------------- Batch 193, round 2: Sent local model to the server -------------------------
2023-03-25 18:21:46,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:46,371 : [INFO]  ------------------------- Batch 193 training: round 3 -------------------------
2023-03-25 18:21:49,493 : [INFO]  ------------------------- Batch round 3, loss: 0.5772 -------------------------
2023-03-25 18:21:49,493 : [INFO]  ------------------------- Batch 193, round 3: Sent local model to the server -------------------------
2023-03-25 18:21:49,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:49,532 : [INFO]  Batch number 193 model fetched from the server
2023-03-25 18:21:49,533 : [INFO]  ################ Batch 193: final global model evalution after 3 rounds ################
2023-03-25 18:21:51,334 : [INFO]  Batch 193: Training set : loss - 0.5882, accuracy - 0.6793, recall - 0.8804, AUC - 0.8347, F1 - 0.733, precision - 0.6279, training time - -12.0 seconds
2023-03-25 18:21:51,334 : [INFO]  Batch 193: Testing set : loss - 0.571, accuracy - 0.6765, recall - 0.8922, AUC - 0.8678, F1 - 0.7339, precision - 0.6233
2023-03-25 18:21:51,347 : [INFO]  Batch 194 initialized 
2023-03-25 18:21:51,917 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:21:52,512 : [INFO]  ------------------------- Batch 194 training: round 1 -------------------------
2023-03-25 18:21:57,935 : [INFO]  ------------------------- Batch round 1, loss: 0.5901 -------------------------
2023-03-25 18:21:57,935 : [INFO]  ------------------------- Batch 194, round 1: Sent local model to the server -------------------------
2023-03-25 18:21:57,948 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:21:57,951 : [INFO]  ------------------------- Batch 194 training: round 2 -------------------------
2023-03-25 18:22:00,777 : [INFO]  ------------------------- Batch round 2, loss: 0.5975 -------------------------
2023-03-25 18:22:00,778 : [INFO]  ------------------------- Batch 194, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:00,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:00,859 : [INFO]  ------------------------- Batch 194 training: round 3 -------------------------
2023-03-25 18:22:03,768 : [INFO]  ------------------------- Batch round 3, loss: 0.5936 -------------------------
2023-03-25 18:22:03,768 : [INFO]  ------------------------- Batch 194, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:03,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:03,816 : [INFO]  Batch number 194 model fetched from the server
2023-03-25 18:22:03,817 : [INFO]  ################ Batch 194: final global model evalution after 3 rounds ################
2023-03-25 18:22:05,655 : [INFO]  Batch 194: Training set : loss - 0.6043, accuracy - 0.6467, recall - 0.8261, AUC - 0.7975, F1 - 0.7005, precision - 0.608, training time - -11.0 seconds
2023-03-25 18:22:05,656 : [INFO]  Batch 194: Testing set : loss - 0.5915, accuracy - 0.6667, recall - 0.8039, AUC - 0.8044, F1 - 0.7069, precision - 0.6308
2023-03-25 18:22:05,672 : [INFO]  Batch 195 initialized 
2023-03-25 18:22:06,235 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:06,853 : [INFO]  ------------------------- Batch 195 training: round 1 -------------------------
2023-03-25 18:22:12,317 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 18:22:12,317 : [INFO]  ------------------------- Batch 195, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:12,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:12,540 : [INFO]  ------------------------- Batch 195 training: round 2 -------------------------
2023-03-25 18:22:15,632 : [INFO]  ------------------------- Batch round 2, loss: 0.5728 -------------------------
2023-03-25 18:22:15,632 : [INFO]  ------------------------- Batch 195, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:15,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:15,692 : [INFO]  ------------------------- Batch 195 training: round 3 -------------------------
2023-03-25 18:22:18,654 : [INFO]  ------------------------- Batch round 3, loss: 0.5694 -------------------------
2023-03-25 18:22:18,655 : [INFO]  ------------------------- Batch 195, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:18,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:18,723 : [INFO]  Batch number 195 model fetched from the server
2023-03-25 18:22:18,723 : [INFO]  ################ Batch 195: final global model evalution after 3 rounds ################
2023-03-25 18:22:20,672 : [INFO]  Batch 195: Training set : loss - 0.5787, accuracy - 0.7065, recall - 0.8587, AUC - 0.8352, F1 - 0.7453, precision - 0.6583, training time - -12.0 seconds
2023-03-25 18:22:20,673 : [INFO]  Batch 195: Testing set : loss - 0.5752, accuracy - 0.7255, recall - 0.8627, AUC - 0.8405, F1 - 0.7586, precision - 0.6769
2023-03-25 18:22:20,682 : [INFO]  Batch 196 initialized 
2023-03-25 18:22:21,258 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:21,830 : [INFO]  ------------------------- Batch 196 training: round 1 -------------------------
2023-03-25 18:22:27,420 : [INFO]  ------------------------- Batch round 1, loss: 0.5502 -------------------------
2023-03-25 18:22:27,421 : [INFO]  ------------------------- Batch 196, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:27,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:27,624 : [INFO]  ------------------------- Batch 196 training: round 2 -------------------------
2023-03-25 18:22:30,520 : [INFO]  ------------------------- Batch round 2, loss: 0.5484 -------------------------
2023-03-25 18:22:30,520 : [INFO]  ------------------------- Batch 196, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:30,534 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:30,537 : [INFO]  ------------------------- Batch 196 training: round 3 -------------------------
2023-03-25 18:22:33,366 : [INFO]  ------------------------- Batch round 3, loss: 0.5498 -------------------------
2023-03-25 18:22:33,366 : [INFO]  ------------------------- Batch 196, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:33,393 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:33,396 : [INFO]  Batch number 196 model fetched from the server
2023-03-25 18:22:33,396 : [INFO]  ################ Batch 196: final global model evalution after 3 rounds ################
2023-03-25 18:22:35,120 : [INFO]  Batch 196: Training set : loss - 0.5624, accuracy - 0.6957, recall - 0.9239, AUC - 0.8999, F1 - 0.7522, precision - 0.6343, training time - -12.0 seconds
2023-03-25 18:22:35,120 : [INFO]  Batch 196: Testing set : loss - 0.5679, accuracy - 0.7255, recall - 0.902, AUC - 0.8692, F1 - 0.7667, precision - 0.6667
2023-03-25 18:22:35,134 : [INFO]  Batch 197 initialized 
2023-03-25 18:22:35,714 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:36,332 : [INFO]  ------------------------- Batch 197 training: round 1 -------------------------
2023-03-25 18:22:41,712 : [INFO]  ------------------------- Batch round 1, loss: 0.5752 -------------------------
2023-03-25 18:22:41,713 : [INFO]  ------------------------- Batch 197, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:41,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:41,858 : [INFO]  ------------------------- Batch 197 training: round 2 -------------------------
2023-03-25 18:22:44,673 : [INFO]  ------------------------- Batch round 2, loss: 0.5803 -------------------------
2023-03-25 18:22:44,673 : [INFO]  ------------------------- Batch 197, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:44,818 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:44,821 : [INFO]  ------------------------- Batch 197 training: round 3 -------------------------
2023-03-25 18:22:47,760 : [INFO]  ------------------------- Batch round 3, loss: 0.579 -------------------------
2023-03-25 18:22:47,760 : [INFO]  ------------------------- Batch 197, round 3: Sent local model to the server -------------------------
2023-03-25 18:22:47,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:47,924 : [INFO]  Batch number 197 model fetched from the server
2023-03-25 18:22:47,924 : [INFO]  ################ Batch 197: final global model evalution after 3 rounds ################
2023-03-25 18:22:49,740 : [INFO]  Batch 197: Training set : loss - 0.5954, accuracy - 0.6739, recall - 0.8696, AUC - 0.8315, F1 - 0.7273, precision - 0.625, training time - -12.0 seconds
2023-03-25 18:22:49,740 : [INFO]  Batch 197: Testing set : loss - 0.5696, accuracy - 0.701, recall - 0.8725, AUC - 0.8564, F1 - 0.7448, precision - 0.6496
2023-03-25 18:22:49,755 : [INFO]  Batch 198 initialized 
2023-03-25 18:22:50,334 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:22:50,916 : [INFO]  ------------------------- Batch 198 training: round 1 -------------------------
2023-03-25 18:22:56,340 : [INFO]  ------------------------- Batch round 1, loss: 0.5871 -------------------------
2023-03-25 18:22:56,340 : [INFO]  ------------------------- Batch 198, round 1: Sent local model to the server -------------------------
2023-03-25 18:22:56,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:56,454 : [INFO]  ------------------------- Batch 198 training: round 2 -------------------------
2023-03-25 18:22:59,298 : [INFO]  ------------------------- Batch round 2, loss: 0.5831 -------------------------
2023-03-25 18:22:59,299 : [INFO]  ------------------------- Batch 198, round 2: Sent local model to the server -------------------------
2023-03-25 18:22:59,309 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:22:59,312 : [INFO]  ------------------------- Batch 198 training: round 3 -------------------------
2023-03-25 18:23:02,177 : [INFO]  ------------------------- Batch round 3, loss: 0.5792 -------------------------
2023-03-25 18:23:02,177 : [INFO]  ------------------------- Batch 198, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:02,194 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:02,197 : [INFO]  Batch number 198 model fetched from the server
2023-03-25 18:23:02,197 : [INFO]  ################ Batch 198: final global model evalution after 3 rounds ################
2023-03-25 18:23:03,958 : [INFO]  Batch 198: Training set : loss - 0.5926, accuracy - 0.7337, recall - 0.9457, AUC - 0.8092, F1 - 0.7803, precision - 0.6641, training time - -11.0 seconds
2023-03-25 18:23:03,958 : [INFO]  Batch 198: Testing set : loss - 0.56, accuracy - 0.7745, recall - 0.9412, AUC - 0.8707, F1 - 0.8067, precision - 0.7059
2023-03-25 18:23:03,972 : [INFO]  Batch 199 initialized 
2023-03-25 18:23:04,524 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:05,129 : [INFO]  ------------------------- Batch 199 training: round 1 -------------------------
2023-03-25 18:23:10,503 : [INFO]  ------------------------- Batch round 1, loss: 0.5752 -------------------------
2023-03-25 18:23:10,504 : [INFO]  ------------------------- Batch 199, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:10,568 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:10,572 : [INFO]  ------------------------- Batch 199 training: round 2 -------------------------
2023-03-25 18:23:13,527 : [INFO]  ------------------------- Batch round 2, loss: 0.5721 -------------------------
2023-03-25 18:23:13,527 : [INFO]  ------------------------- Batch 199, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:13,558 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:13,561 : [INFO]  ------------------------- Batch 199 training: round 3 -------------------------
2023-03-25 18:23:16,420 : [INFO]  ------------------------- Batch round 3, loss: 0.5754 -------------------------
2023-03-25 18:23:16,420 : [INFO]  ------------------------- Batch 199, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:16,432 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:16,434 : [INFO]  Batch number 199 model fetched from the server
2023-03-25 18:23:16,435 : [INFO]  ################ Batch 199: final global model evalution after 3 rounds ################
2023-03-25 18:23:18,234 : [INFO]  Batch 199: Training set : loss - 0.5804, accuracy - 0.7065, recall - 0.8913, AUC - 0.841, F1 - 0.7523, precision - 0.6508, training time - -11.0 seconds
2023-03-25 18:23:18,234 : [INFO]  Batch 199: Testing set : loss - 0.5889, accuracy - 0.7059, recall - 0.8824, AUC - 0.8195, F1 - 0.75, precision - 0.6522
2023-03-25 18:23:18,242 : [INFO]  Batch 200 initialized 
2023-03-25 18:23:18,798 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:19,421 : [INFO]  ------------------------- Batch 200 training: round 1 -------------------------
2023-03-25 18:23:24,917 : [INFO]  ------------------------- Batch round 1, loss: 0.5701 -------------------------
2023-03-25 18:23:24,918 : [INFO]  ------------------------- Batch 200, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:24,929 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:24,932 : [INFO]  ------------------------- Batch 200 training: round 2 -------------------------
2023-03-25 18:23:27,914 : [INFO]  ------------------------- Batch round 2, loss: 0.5683 -------------------------
2023-03-25 18:23:27,914 : [INFO]  ------------------------- Batch 200, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:27,927 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:27,930 : [INFO]  ------------------------- Batch 200 training: round 3 -------------------------
2023-03-25 18:23:30,913 : [INFO]  ------------------------- Batch round 3, loss: 0.5716 -------------------------
2023-03-25 18:23:30,913 : [INFO]  ------------------------- Batch 200, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:30,930 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:30,934 : [INFO]  Batch number 200 model fetched from the server
2023-03-25 18:23:30,934 : [INFO]  ################ Batch 200: final global model evalution after 3 rounds ################
2023-03-25 18:23:32,806 : [INFO]  Batch 200: Training set : loss - 0.5795, accuracy - 0.6957, recall - 0.8696, AUC - 0.8495, F1 - 0.7407, precision - 0.6452, training time - -12.0 seconds
2023-03-25 18:23:32,806 : [INFO]  Batch 200: Testing set : loss - 0.6074, accuracy - 0.6569, recall - 0.8627, AUC - 0.7919, F1 - 0.7154, precision - 0.6111
2023-03-25 18:23:32,816 : [INFO]  Batch 201 initialized 
2023-03-25 18:23:33,394 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:34,015 : [INFO]  ------------------------- Batch 201 training: round 1 -------------------------
2023-03-25 18:23:39,321 : [INFO]  ------------------------- Batch round 1, loss: 0.5963 -------------------------
2023-03-25 18:23:39,321 : [INFO]  ------------------------- Batch 201, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:39,333 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:39,335 : [INFO]  ------------------------- Batch 201 training: round 2 -------------------------
2023-03-25 18:23:42,178 : [INFO]  ------------------------- Batch round 2, loss: 0.593 -------------------------
2023-03-25 18:23:42,179 : [INFO]  ------------------------- Batch 201, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:42,201 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:42,203 : [INFO]  ------------------------- Batch 201 training: round 3 -------------------------
2023-03-25 18:23:45,174 : [INFO]  ------------------------- Batch round 3, loss: 0.5998 -------------------------
2023-03-25 18:23:45,174 : [INFO]  ------------------------- Batch 201, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:45,187 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:45,189 : [INFO]  Batch number 201 model fetched from the server
2023-03-25 18:23:45,189 : [INFO]  ################ Batch 201: final global model evalution after 3 rounds ################
2023-03-25 18:23:47,139 : [INFO]  Batch 201: Training set : loss - 0.6053, accuracy - 0.6739, recall - 0.8696, AUC - 0.792, F1 - 0.7273, precision - 0.625, training time - -11.0 seconds
2023-03-25 18:23:47,139 : [INFO]  Batch 201: Testing set : loss - 0.5694, accuracy - 0.7451, recall - 0.9118, AUC - 0.8556, F1 - 0.7815, precision - 0.6838
2023-03-25 18:23:47,153 : [INFO]  Batch 202 initialized 
2023-03-25 18:23:47,735 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:23:48,295 : [INFO]  ------------------------- Batch 202 training: round 1 -------------------------
2023-03-25 18:23:53,714 : [INFO]  ------------------------- Batch round 1, loss: 0.5574 -------------------------
2023-03-25 18:23:53,714 : [INFO]  ------------------------- Batch 202, round 1: Sent local model to the server -------------------------
2023-03-25 18:23:53,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:53,727 : [INFO]  ------------------------- Batch 202 training: round 2 -------------------------
2023-03-25 18:23:56,595 : [INFO]  ------------------------- Batch round 2, loss: 0.5635 -------------------------
2023-03-25 18:23:56,595 : [INFO]  ------------------------- Batch 202, round 2: Sent local model to the server -------------------------
2023-03-25 18:23:56,611 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:56,614 : [INFO]  ------------------------- Batch 202 training: round 3 -------------------------
2023-03-25 18:23:59,597 : [INFO]  ------------------------- Batch round 3, loss: 0.5616 -------------------------
2023-03-25 18:23:59,598 : [INFO]  ------------------------- Batch 202, round 3: Sent local model to the server -------------------------
2023-03-25 18:23:59,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:23:59,619 : [INFO]  Batch number 202 model fetched from the server
2023-03-25 18:23:59,619 : [INFO]  ################ Batch 202: final global model evalution after 3 rounds ################
2023-03-25 18:24:01,509 : [INFO]  Batch 202: Training set : loss - 0.57, accuracy - 0.7174, recall - 0.8478, AUC - 0.8213, F1 - 0.75, precision - 0.6724, training time - -11.0 seconds
2023-03-25 18:24:01,509 : [INFO]  Batch 202: Testing set : loss - 0.5674, accuracy - 0.7353, recall - 0.8922, AUC - 0.8545, F1 - 0.7712, precision - 0.6791
2023-03-25 18:24:01,522 : [INFO]  Batch 203 initialized 
2023-03-25 18:24:02,094 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:02,712 : [INFO]  ------------------------- Batch 203 training: round 1 -------------------------
2023-03-25 18:24:08,109 : [INFO]  ------------------------- Batch round 1, loss: 0.5608 -------------------------
2023-03-25 18:24:08,109 : [INFO]  ------------------------- Batch 203, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:08,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:08,136 : [INFO]  ------------------------- Batch 203 training: round 2 -------------------------
2023-03-25 18:24:10,934 : [INFO]  ------------------------- Batch round 2, loss: 0.5637 -------------------------
2023-03-25 18:24:10,934 : [INFO]  ------------------------- Batch 203, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:11,098 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:11,101 : [INFO]  ------------------------- Batch 203 training: round 3 -------------------------
2023-03-25 18:24:13,975 : [INFO]  ------------------------- Batch round 3, loss: 0.56 -------------------------
2023-03-25 18:24:13,975 : [INFO]  ------------------------- Batch 203, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:13,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:13,991 : [INFO]  Batch number 203 model fetched from the server
2023-03-25 18:24:13,991 : [INFO]  ################ Batch 203: final global model evalution after 3 rounds ################
2023-03-25 18:24:15,738 : [INFO]  Batch 203: Training set : loss - 0.5734, accuracy - 0.712, recall - 0.913, AUC - 0.8676, F1 - 0.7602, precision - 0.6512, training time - -11.0 seconds
2023-03-25 18:24:15,738 : [INFO]  Batch 203: Testing set : loss - 0.5465, accuracy - 0.7647, recall - 0.8725, AUC - 0.8786, F1 - 0.7876, precision - 0.7177
2023-03-25 18:24:15,753 : [INFO]  Batch 204 initialized 
2023-03-25 18:24:16,329 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:16,945 : [INFO]  ------------------------- Batch 204 training: round 1 -------------------------
2023-03-25 18:24:22,381 : [INFO]  ------------------------- Batch round 1, loss: 0.5779 -------------------------
2023-03-25 18:24:22,381 : [INFO]  ------------------------- Batch 204, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:22,392 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:22,395 : [INFO]  ------------------------- Batch 204 training: round 2 -------------------------
2023-03-25 18:24:25,300 : [INFO]  ------------------------- Batch round 2, loss: 0.576 -------------------------
2023-03-25 18:24:25,300 : [INFO]  ------------------------- Batch 204, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:25,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:25,331 : [INFO]  ------------------------- Batch 204 training: round 3 -------------------------
2023-03-25 18:24:28,212 : [INFO]  ------------------------- Batch round 3, loss: 0.5766 -------------------------
2023-03-25 18:24:28,212 : [INFO]  ------------------------- Batch 204, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:28,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:28,228 : [INFO]  Batch number 204 model fetched from the server
2023-03-25 18:24:28,228 : [INFO]  ################ Batch 204: final global model evalution after 3 rounds ################
2023-03-25 18:24:30,020 : [INFO]  Batch 204: Training set : loss - 0.5751, accuracy - 0.7174, recall - 0.8587, AUC - 0.8336, F1 - 0.7524, precision - 0.6695, training time - -11.0 seconds
2023-03-25 18:24:30,021 : [INFO]  Batch 204: Testing set : loss - 0.6096, accuracy - 0.6618, recall - 0.8039, AUC - 0.7688, F1 - 0.7039, precision - 0.626
2023-03-25 18:24:30,032 : [INFO]  Batch 205 initialized 
2023-03-25 18:24:30,598 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:31,200 : [INFO]  ------------------------- Batch 205 training: round 1 -------------------------
2023-03-25 18:24:36,614 : [INFO]  ------------------------- Batch round 1, loss: 0.5891 -------------------------
2023-03-25 18:24:36,614 : [INFO]  ------------------------- Batch 205, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:36,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:36,627 : [INFO]  ------------------------- Batch 205 training: round 2 -------------------------
2023-03-25 18:24:39,517 : [INFO]  ------------------------- Batch round 2, loss: 0.5859 -------------------------
2023-03-25 18:24:39,517 : [INFO]  ------------------------- Batch 205, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:39,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:39,531 : [INFO]  ------------------------- Batch 205 training: round 3 -------------------------
2023-03-25 18:24:42,504 : [INFO]  ------------------------- Batch round 3, loss: 0.5892 -------------------------
2023-03-25 18:24:42,504 : [INFO]  ------------------------- Batch 205, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:42,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:42,519 : [INFO]  Batch number 205 model fetched from the server
2023-03-25 18:24:42,519 : [INFO]  ################ Batch 205: final global model evalution after 3 rounds ################
2023-03-25 18:24:44,274 : [INFO]  Batch 205: Training set : loss - 0.6013, accuracy - 0.6576, recall - 0.8587, AUC - 0.8065, F1 - 0.7149, precision - 0.6124, training time - -11.0 seconds
2023-03-25 18:24:44,275 : [INFO]  Batch 205: Testing set : loss - 0.6092, accuracy - 0.6275, recall - 0.8039, AUC - 0.7809, F1 - 0.6833, precision - 0.5942
2023-03-25 18:24:44,286 : [INFO]  Batch 206 initialized 
2023-03-25 18:24:44,855 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:45,471 : [INFO]  ------------------------- Batch 206 training: round 1 -------------------------
2023-03-25 18:24:50,735 : [INFO]  ------------------------- Batch round 1, loss: 0.569 -------------------------
2023-03-25 18:24:50,736 : [INFO]  ------------------------- Batch 206, round 1: Sent local model to the server -------------------------
2023-03-25 18:24:50,761 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:50,764 : [INFO]  ------------------------- Batch 206 training: round 2 -------------------------
2023-03-25 18:24:53,627 : [INFO]  ------------------------- Batch round 2, loss: 0.5664 -------------------------
2023-03-25 18:24:53,627 : [INFO]  ------------------------- Batch 206, round 2: Sent local model to the server -------------------------
2023-03-25 18:24:53,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:53,783 : [INFO]  ------------------------- Batch 206 training: round 3 -------------------------
2023-03-25 18:24:56,765 : [INFO]  ------------------------- Batch round 3, loss: 0.5698 -------------------------
2023-03-25 18:24:56,766 : [INFO]  ------------------------- Batch 206, round 3: Sent local model to the server -------------------------
2023-03-25 18:24:56,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:24:56,815 : [INFO]  Batch number 206 model fetched from the server
2023-03-25 18:24:56,815 : [INFO]  ################ Batch 206: final global model evalution after 3 rounds ################
2023-03-25 18:24:58,509 : [INFO]  Batch 206: Training set : loss - 0.5778, accuracy - 0.6957, recall - 0.837, AUC - 0.8362, F1 - 0.7333, precision - 0.6525, training time - -11.0 seconds
2023-03-25 18:24:58,510 : [INFO]  Batch 206: Testing set : loss - 0.5756, accuracy - 0.7059, recall - 0.8529, AUC - 0.8292, F1 - 0.7436, precision - 0.6591
2023-03-25 18:24:58,521 : [INFO]  Batch 207 initialized 
2023-03-25 18:24:59,084 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:24:59,709 : [INFO]  ------------------------- Batch 207 training: round 1 -------------------------
2023-03-25 18:25:05,250 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-25 18:25:05,251 : [INFO]  ------------------------- Batch 207, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:05,262 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:05,265 : [INFO]  ------------------------- Batch 207 training: round 2 -------------------------
2023-03-25 18:25:08,184 : [INFO]  ------------------------- Batch round 2, loss: 0.5753 -------------------------
2023-03-25 18:25:08,184 : [INFO]  ------------------------- Batch 207, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:08,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:08,325 : [INFO]  ------------------------- Batch 207 training: round 3 -------------------------
2023-03-25 18:25:11,155 : [INFO]  ------------------------- Batch round 3, loss: 0.5703 -------------------------
2023-03-25 18:25:11,155 : [INFO]  ------------------------- Batch 207, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:11,275 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:11,278 : [INFO]  Batch number 207 model fetched from the server
2023-03-25 18:25:11,278 : [INFO]  ################ Batch 207: final global model evalution after 3 rounds ################
2023-03-25 18:25:13,040 : [INFO]  Batch 207: Training set : loss - 0.5798, accuracy - 0.712, recall - 0.8913, AUC - 0.8432, F1 - 0.7558, precision - 0.656, training time - -12.0 seconds
2023-03-25 18:25:13,041 : [INFO]  Batch 207: Testing set : loss - 0.6046, accuracy - 0.6618, recall - 0.8333, AUC - 0.7961, F1 - 0.7113, precision - 0.6204
2023-03-25 18:25:13,050 : [INFO]  Batch 208 initialized 
2023-03-25 18:25:13,636 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:14,250 : [INFO]  ------------------------- Batch 208 training: round 1 -------------------------
2023-03-25 18:25:19,621 : [INFO]  ------------------------- Batch round 1, loss: 0.5701 -------------------------
2023-03-25 18:25:19,621 : [INFO]  ------------------------- Batch 208, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:19,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:19,743 : [INFO]  ------------------------- Batch 208 training: round 2 -------------------------
2023-03-25 18:25:22,607 : [INFO]  ------------------------- Batch round 2, loss: 0.5605 -------------------------
2023-03-25 18:25:22,607 : [INFO]  ------------------------- Batch 208, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:22,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:22,634 : [INFO]  ------------------------- Batch 208 training: round 3 -------------------------
2023-03-25 18:25:25,486 : [INFO]  ------------------------- Batch round 3, loss: 0.5678 -------------------------
2023-03-25 18:25:25,486 : [INFO]  ------------------------- Batch 208, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:25,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:25,556 : [INFO]  Batch number 208 model fetched from the server
2023-03-25 18:25:25,556 : [INFO]  ################ Batch 208: final global model evalution after 3 rounds ################
2023-03-25 18:25:27,287 : [INFO]  Batch 208: Training set : loss - 0.5752, accuracy - 0.712, recall - 0.8913, AUC - 0.8439, F1 - 0.7558, precision - 0.656, training time - -11.0 seconds
2023-03-25 18:25:27,288 : [INFO]  Batch 208: Testing set : loss - 0.573, accuracy - 0.7059, recall - 0.902, AUC - 0.8576, F1 - 0.7541, precision - 0.6479
2023-03-25 18:25:27,303 : [INFO]  Batch 209 initialized 
2023-03-25 18:25:27,867 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:28,501 : [INFO]  ------------------------- Batch 209 training: round 1 -------------------------
2023-03-25 18:25:33,927 : [INFO]  ------------------------- Batch round 1, loss: 0.5636 -------------------------
2023-03-25 18:25:33,927 : [INFO]  ------------------------- Batch 209, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:33,939 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:33,941 : [INFO]  ------------------------- Batch 209 training: round 2 -------------------------
2023-03-25 18:25:36,748 : [INFO]  ------------------------- Batch round 2, loss: 0.5747 -------------------------
2023-03-25 18:25:36,748 : [INFO]  ------------------------- Batch 209, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:36,759 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:36,762 : [INFO]  ------------------------- Batch 209 training: round 3 -------------------------
2023-03-25 18:25:39,736 : [INFO]  ------------------------- Batch round 3, loss: 0.5606 -------------------------
2023-03-25 18:25:39,736 : [INFO]  ------------------------- Batch 209, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:39,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:39,753 : [INFO]  Batch number 209 model fetched from the server
2023-03-25 18:25:39,753 : [INFO]  ################ Batch 209: final global model evalution after 3 rounds ################
2023-03-25 18:25:41,618 : [INFO]  Batch 209: Training set : loss - 0.5876, accuracy - 0.712, recall - 0.8587, AUC - 0.8246, F1 - 0.7488, precision - 0.6639, training time - -11.0 seconds
2023-03-25 18:25:41,619 : [INFO]  Batch 209: Testing set : loss - 0.5946, accuracy - 0.6863, recall - 0.8333, AUC - 0.7968, F1 - 0.7265, precision - 0.6439
2023-03-25 18:25:41,631 : [INFO]  Batch 210 initialized 
2023-03-25 18:25:42,215 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:42,837 : [INFO]  ------------------------- Batch 210 training: round 1 -------------------------
2023-03-25 18:25:48,158 : [INFO]  ------------------------- Batch round 1, loss: 0.555 -------------------------
2023-03-25 18:25:48,158 : [INFO]  ------------------------- Batch 210, round 1: Sent local model to the server -------------------------
2023-03-25 18:25:48,226 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:48,229 : [INFO]  ------------------------- Batch 210 training: round 2 -------------------------
2023-03-25 18:25:51,033 : [INFO]  ------------------------- Batch round 2, loss: 0.5596 -------------------------
2023-03-25 18:25:51,033 : [INFO]  ------------------------- Batch 210, round 2: Sent local model to the server -------------------------
2023-03-25 18:25:51,075 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:51,077 : [INFO]  ------------------------- Batch 210 training: round 3 -------------------------
2023-03-25 18:25:53,847 : [INFO]  ------------------------- Batch round 3, loss: 0.5506 -------------------------
2023-03-25 18:25:53,848 : [INFO]  ------------------------- Batch 210, round 3: Sent local model to the server -------------------------
2023-03-25 18:25:53,915 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:25:53,918 : [INFO]  Batch number 210 model fetched from the server
2023-03-25 18:25:53,918 : [INFO]  ################ Batch 210: final global model evalution after 3 rounds ################
2023-03-25 18:25:55,636 : [INFO]  Batch 210: Training set : loss - 0.5611, accuracy - 0.7391, recall - 0.9022, AUC - 0.8658, F1 - 0.7757, precision - 0.6803, training time - -11.0 seconds
2023-03-25 18:25:55,636 : [INFO]  Batch 210: Testing set : loss - 0.569, accuracy - 0.7402, recall - 0.8824, AUC - 0.8573, F1 - 0.7725, precision - 0.687
2023-03-25 18:25:55,651 : [INFO]  Batch 211 initialized 
2023-03-25 18:25:56,211 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:25:56,829 : [INFO]  ------------------------- Batch 211 training: round 1 -------------------------
2023-03-25 18:26:02,073 : [INFO]  ------------------------- Batch round 1, loss: 0.5844 -------------------------
2023-03-25 18:26:02,074 : [INFO]  ------------------------- Batch 211, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:02,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:02,257 : [INFO]  ------------------------- Batch 211 training: round 2 -------------------------
2023-03-25 18:26:05,173 : [INFO]  ------------------------- Batch round 2, loss: 0.5876 -------------------------
2023-03-25 18:26:05,173 : [INFO]  ------------------------- Batch 211, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:05,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:05,191 : [INFO]  ------------------------- Batch 211 training: round 3 -------------------------
2023-03-25 18:26:08,004 : [INFO]  ------------------------- Batch round 3, loss: 0.583 -------------------------
2023-03-25 18:26:08,005 : [INFO]  ------------------------- Batch 211, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:08,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:08,218 : [INFO]  Batch number 211 model fetched from the server
2023-03-25 18:26:08,218 : [INFO]  ################ Batch 211: final global model evalution after 3 rounds ################
2023-03-25 18:26:09,929 : [INFO]  Batch 211: Training set : loss - 0.5988, accuracy - 0.6467, recall - 0.837, AUC - 0.7925, F1 - 0.7032, precision - 0.6063, training time - -11.0 seconds
2023-03-25 18:26:09,930 : [INFO]  Batch 211: Testing set : loss - 0.597, accuracy - 0.6863, recall - 0.8235, AUC - 0.7938, F1 - 0.7241, precision - 0.6462
2023-03-25 18:26:09,963 : [INFO]  Batch 212 initialized 
2023-03-25 18:26:10,526 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:11,146 : [INFO]  ------------------------- Batch 212 training: round 1 -------------------------
2023-03-25 18:26:16,462 : [INFO]  ------------------------- Batch round 1, loss: 0.5908 -------------------------
2023-03-25 18:26:16,462 : [INFO]  ------------------------- Batch 212, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:16,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:16,591 : [INFO]  ------------------------- Batch 212 training: round 2 -------------------------
2023-03-25 18:26:19,574 : [INFO]  ------------------------- Batch round 2, loss: 0.5938 -------------------------
2023-03-25 18:26:19,574 : [INFO]  ------------------------- Batch 212, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:19,678 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:19,681 : [INFO]  ------------------------- Batch 212 training: round 3 -------------------------
2023-03-25 18:26:22,760 : [INFO]  ------------------------- Batch round 3, loss: 0.5916 -------------------------
2023-03-25 18:26:22,760 : [INFO]  ------------------------- Batch 212, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:22,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:22,790 : [INFO]  Batch number 212 model fetched from the server
2023-03-25 18:26:22,790 : [INFO]  ################ Batch 212: final global model evalution after 3 rounds ################
2023-03-25 18:26:24,591 : [INFO]  Batch 212: Training set : loss - 0.6111, accuracy - 0.663, recall - 0.8478, AUC - 0.773, F1 - 0.7156, precision - 0.619, training time - -12.0 seconds
2023-03-25 18:26:24,591 : [INFO]  Batch 212: Testing set : loss - 0.585, accuracy - 0.701, recall - 0.8627, AUC - 0.8228, F1 - 0.7426, precision - 0.6519
2023-03-25 18:26:24,606 : [INFO]  Batch 213 initialized 
2023-03-25 18:26:25,189 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:25,829 : [INFO]  ------------------------- Batch 213 training: round 1 -------------------------
2023-03-25 18:26:31,267 : [INFO]  ------------------------- Batch round 1, loss: 0.5862 -------------------------
2023-03-25 18:26:31,267 : [INFO]  ------------------------- Batch 213, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:31,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:31,326 : [INFO]  ------------------------- Batch 213 training: round 2 -------------------------
2023-03-25 18:26:34,172 : [INFO]  ------------------------- Batch round 2, loss: 0.5799 -------------------------
2023-03-25 18:26:34,172 : [INFO]  ------------------------- Batch 213, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:34,185 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:34,189 : [INFO]  ------------------------- Batch 213 training: round 3 -------------------------
2023-03-25 18:26:37,009 : [INFO]  ------------------------- Batch round 3, loss: 0.5815 -------------------------
2023-03-25 18:26:37,010 : [INFO]  ------------------------- Batch 213, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:37,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:37,053 : [INFO]  Batch number 213 model fetched from the server
2023-03-25 18:26:37,053 : [INFO]  ################ Batch 213: final global model evalution after 3 rounds ################
2023-03-25 18:26:38,778 : [INFO]  Batch 213: Training set : loss - 0.6005, accuracy - 0.6848, recall - 0.8043, AUC - 0.7697, F1 - 0.7184, precision - 0.6491, training time - -11.0 seconds
2023-03-25 18:26:38,778 : [INFO]  Batch 213: Testing set : loss - 0.5816, accuracy - 0.6765, recall - 0.8137, AUC - 0.8262, F1 - 0.7155, precision - 0.6385
2023-03-25 18:26:38,787 : [INFO]  Batch 214 initialized 
2023-03-25 18:26:39,350 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:40,010 : [INFO]  ------------------------- Batch 214 training: round 1 -------------------------
2023-03-25 18:26:45,450 : [INFO]  ------------------------- Batch round 1, loss: 0.5512 -------------------------
2023-03-25 18:26:45,450 : [INFO]  ------------------------- Batch 214, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:45,462 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:45,465 : [INFO]  ------------------------- Batch 214 training: round 2 -------------------------
2023-03-25 18:26:48,342 : [INFO]  ------------------------- Batch round 2, loss: 0.5398 -------------------------
2023-03-25 18:26:48,343 : [INFO]  ------------------------- Batch 214, round 2: Sent local model to the server -------------------------
2023-03-25 18:26:48,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:48,357 : [INFO]  ------------------------- Batch 214 training: round 3 -------------------------
2023-03-25 18:26:51,251 : [INFO]  ------------------------- Batch round 3, loss: 0.547 -------------------------
2023-03-25 18:26:51,251 : [INFO]  ------------------------- Batch 214, round 3: Sent local model to the server -------------------------
2023-03-25 18:26:51,264 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:51,266 : [INFO]  Batch number 214 model fetched from the server
2023-03-25 18:26:51,267 : [INFO]  ################ Batch 214: final global model evalution after 3 rounds ################
2023-03-25 18:26:53,060 : [INFO]  Batch 214: Training set : loss - 0.5531, accuracy - 0.7554, recall - 0.9239, AUC - 0.8771, F1 - 0.7907, precision - 0.6911, training time - -11.0 seconds
2023-03-25 18:26:53,061 : [INFO]  Batch 214: Testing set : loss - 0.5787, accuracy - 0.7255, recall - 0.8529, AUC - 0.8258, F1 - 0.7565, precision - 0.6797
2023-03-25 18:26:53,070 : [INFO]  Batch 215 initialized 
2023-03-25 18:26:53,653 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:26:54,298 : [INFO]  ------------------------- Batch 215 training: round 1 -------------------------
2023-03-25 18:26:59,726 : [INFO]  ------------------------- Batch round 1, loss: 0.5525 -------------------------
2023-03-25 18:26:59,727 : [INFO]  ------------------------- Batch 215, round 1: Sent local model to the server -------------------------
2023-03-25 18:26:59,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:26:59,742 : [INFO]  ------------------------- Batch 215 training: round 2 -------------------------
2023-03-25 18:27:02,651 : [INFO]  ------------------------- Batch round 2, loss: 0.5584 -------------------------
2023-03-25 18:27:02,651 : [INFO]  ------------------------- Batch 215, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:02,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:02,675 : [INFO]  ------------------------- Batch 215 training: round 3 -------------------------
2023-03-25 18:27:05,704 : [INFO]  ------------------------- Batch round 3, loss: 0.5558 -------------------------
2023-03-25 18:27:05,705 : [INFO]  ------------------------- Batch 215, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:05,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:05,725 : [INFO]  Batch number 215 model fetched from the server
2023-03-25 18:27:05,725 : [INFO]  ################ Batch 215: final global model evalution after 3 rounds ################
2023-03-25 18:27:07,476 : [INFO]  Batch 215: Training set : loss - 0.5623, accuracy - 0.7228, recall - 0.8913, AUC - 0.8819, F1 - 0.7628, precision - 0.6667, training time - -11.0 seconds
2023-03-25 18:27:07,476 : [INFO]  Batch 215: Testing set : loss - 0.5629, accuracy - 0.7255, recall - 0.8627, AUC - 0.8664, F1 - 0.7586, precision - 0.6769
2023-03-25 18:27:07,486 : [INFO]  Batch 216 initialized 
2023-03-25 18:27:08,066 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:08,759 : [INFO]  ------------------------- Batch 216 training: round 1 -------------------------
2023-03-25 18:27:14,377 : [INFO]  ------------------------- Batch round 1, loss: 0.5856 -------------------------
2023-03-25 18:27:14,377 : [INFO]  ------------------------- Batch 216, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:14,390 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:14,394 : [INFO]  ------------------------- Batch 216 training: round 2 -------------------------
2023-03-25 18:27:17,369 : [INFO]  ------------------------- Batch round 2, loss: 0.5894 -------------------------
2023-03-25 18:27:17,369 : [INFO]  ------------------------- Batch 216, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:17,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:17,392 : [INFO]  ------------------------- Batch 216 training: round 3 -------------------------
2023-03-25 18:27:20,320 : [INFO]  ------------------------- Batch round 3, loss: 0.5878 -------------------------
2023-03-25 18:27:20,320 : [INFO]  ------------------------- Batch 216, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:20,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:20,413 : [INFO]  Batch number 216 model fetched from the server
2023-03-25 18:27:20,413 : [INFO]  ################ Batch 216: final global model evalution after 3 rounds ################
2023-03-25 18:27:22,214 : [INFO]  Batch 216: Training set : loss - 0.5972, accuracy - 0.6848, recall - 0.913, AUC - 0.8357, F1 - 0.7434, precision - 0.6269, training time - -12.0 seconds
2023-03-25 18:27:22,214 : [INFO]  Batch 216: Testing set : loss - 0.5946, accuracy - 0.6618, recall - 0.8824, AUC - 0.8311, F1 - 0.7229, precision - 0.6122
2023-03-25 18:27:22,222 : [INFO]  Batch 217 initialized 
2023-03-25 18:27:22,776 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:23,426 : [INFO]  ------------------------- Batch 217 training: round 1 -------------------------
2023-03-25 18:27:29,015 : [INFO]  ------------------------- Batch round 1, loss: 0.5975 -------------------------
2023-03-25 18:27:29,015 : [INFO]  ------------------------- Batch 217, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:29,028 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:29,030 : [INFO]  ------------------------- Batch 217 training: round 2 -------------------------
2023-03-25 18:27:31,979 : [INFO]  ------------------------- Batch round 2, loss: 0.5931 -------------------------
2023-03-25 18:27:31,980 : [INFO]  ------------------------- Batch 217, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:31,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:31,994 : [INFO]  ------------------------- Batch 217 training: round 3 -------------------------
2023-03-25 18:27:34,941 : [INFO]  ------------------------- Batch round 3, loss: 0.5963 -------------------------
2023-03-25 18:27:34,941 : [INFO]  ------------------------- Batch 217, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:34,956 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:34,958 : [INFO]  Batch number 217 model fetched from the server
2023-03-25 18:27:34,958 : [INFO]  ################ Batch 217: final global model evalution after 3 rounds ################
2023-03-25 18:27:36,762 : [INFO]  Batch 217: Training set : loss - 0.6115, accuracy - 0.6793, recall - 0.9239, AUC - 0.813, F1 - 0.7424, precision - 0.6204, training time - -12.0 seconds
2023-03-25 18:27:36,762 : [INFO]  Batch 217: Testing set : loss - 0.6122, accuracy - 0.6176, recall - 0.8627, AUC - 0.8122, F1 - 0.6929, precision - 0.5789
2023-03-25 18:27:36,774 : [INFO]  Batch 218 initialized 
2023-03-25 18:27:37,349 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:38,001 : [INFO]  ------------------------- Batch 218 training: round 1 -------------------------
2023-03-25 18:27:43,468 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-25 18:27:43,468 : [INFO]  ------------------------- Batch 218, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:43,550 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:43,553 : [INFO]  ------------------------- Batch 218 training: round 2 -------------------------
2023-03-25 18:27:46,401 : [INFO]  ------------------------- Batch round 2, loss: 0.5678 -------------------------
2023-03-25 18:27:46,401 : [INFO]  ------------------------- Batch 218, round 2: Sent local model to the server -------------------------
2023-03-25 18:27:46,470 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:46,472 : [INFO]  ------------------------- Batch 218 training: round 3 -------------------------
2023-03-25 18:27:49,315 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 18:27:49,315 : [INFO]  ------------------------- Batch 218, round 3: Sent local model to the server -------------------------
2023-03-25 18:27:49,387 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:49,390 : [INFO]  Batch number 218 model fetched from the server
2023-03-25 18:27:49,390 : [INFO]  ################ Batch 218: final global model evalution after 3 rounds ################
2023-03-25 18:27:51,179 : [INFO]  Batch 218: Training set : loss - 0.5725, accuracy - 0.7228, recall - 0.8587, AUC - 0.8409, F1 - 0.756, precision - 0.6752, training time - -11.0 seconds
2023-03-25 18:27:51,179 : [INFO]  Batch 218: Testing set : loss - 0.5428, accuracy - 0.7696, recall - 0.9608, AUC - 0.9227, F1 - 0.8066, precision - 0.695
2023-03-25 18:27:51,192 : [INFO]  Batch 219 initialized 
2023-03-25 18:27:51,835 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:27:52,478 : [INFO]  ------------------------- Batch 219 training: round 1 -------------------------
2023-03-25 18:27:58,015 : [INFO]  ------------------------- Batch round 1, loss: 0.583 -------------------------
2023-03-25 18:27:58,015 : [INFO]  ------------------------- Batch 219, round 1: Sent local model to the server -------------------------
2023-03-25 18:27:58,045 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:27:58,049 : [INFO]  ------------------------- Batch 219 training: round 2 -------------------------
2023-03-25 18:28:00,943 : [INFO]  ------------------------- Batch round 2, loss: 0.5852 -------------------------
2023-03-25 18:28:00,944 : [INFO]  ------------------------- Batch 219, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:00,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:00,965 : [INFO]  ------------------------- Batch 219 training: round 3 -------------------------
2023-03-25 18:28:03,975 : [INFO]  ------------------------- Batch round 3, loss: 0.593 -------------------------
2023-03-25 18:28:03,976 : [INFO]  ------------------------- Batch 219, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:03,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:03,995 : [INFO]  Batch number 219 model fetched from the server
2023-03-25 18:28:03,995 : [INFO]  ################ Batch 219: final global model evalution after 3 rounds ################
2023-03-25 18:28:05,762 : [INFO]  Batch 219: Training set : loss - 0.5958, accuracy - 0.6793, recall - 0.8804, AUC - 0.8125, F1 - 0.733, precision - 0.6279, training time - -12.0 seconds
2023-03-25 18:28:05,763 : [INFO]  Batch 219: Testing set : loss - 0.5772, accuracy - 0.6863, recall - 0.8431, AUC - 0.8288, F1 - 0.7288, precision - 0.6418
2023-03-25 18:28:05,773 : [INFO]  Batch 220 initialized 
2023-03-25 18:28:06,338 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:06,973 : [INFO]  ------------------------- Batch 220 training: round 1 -------------------------
2023-03-25 18:28:12,358 : [INFO]  ------------------------- Batch round 1, loss: 0.5753 -------------------------
2023-03-25 18:28:12,358 : [INFO]  ------------------------- Batch 220, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:12,546 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:12,553 : [INFO]  ------------------------- Batch 220 training: round 2 -------------------------
2023-03-25 18:28:15,276 : [INFO]  ------------------------- Batch round 2, loss: 0.5752 -------------------------
2023-03-25 18:28:15,276 : [INFO]  ------------------------- Batch 220, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:15,584 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:15,587 : [INFO]  ------------------------- Batch 220 training: round 3 -------------------------
2023-03-25 18:28:18,369 : [INFO]  ------------------------- Batch round 3, loss: 0.5756 -------------------------
2023-03-25 18:28:18,369 : [INFO]  ------------------------- Batch 220, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:18,556 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:18,564 : [INFO]  Batch number 220 model fetched from the server
2023-03-25 18:28:18,564 : [INFO]  ################ Batch 220: final global model evalution after 3 rounds ################
2023-03-25 18:28:20,332 : [INFO]  Batch 220: Training set : loss - 0.5829, accuracy - 0.6739, recall - 0.913, AUC - 0.8344, F1 - 0.7368, precision - 0.6176, training time - -12.0 seconds
2023-03-25 18:28:20,332 : [INFO]  Batch 220: Testing set : loss - 0.5801, accuracy - 0.701, recall - 0.902, AUC - 0.8468, F1 - 0.751, precision - 0.6434
2023-03-25 18:28:20,346 : [INFO]  Batch 221 initialized 
2023-03-25 18:28:20,943 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:21,567 : [INFO]  ------------------------- Batch 221 training: round 1 -------------------------
2023-03-25 18:28:27,065 : [INFO]  ------------------------- Batch round 1, loss: 0.6031 -------------------------
2023-03-25 18:28:27,065 : [INFO]  ------------------------- Batch 221, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:27,076 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:27,079 : [INFO]  ------------------------- Batch 221 training: round 2 -------------------------
2023-03-25 18:28:29,941 : [INFO]  ------------------------- Batch round 2, loss: 0.6042 -------------------------
2023-03-25 18:28:29,941 : [INFO]  ------------------------- Batch 221, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:29,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:29,957 : [INFO]  ------------------------- Batch 221 training: round 3 -------------------------
2023-03-25 18:28:32,770 : [INFO]  ------------------------- Batch round 3, loss: 0.6003 -------------------------
2023-03-25 18:28:32,771 : [INFO]  ------------------------- Batch 221, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:32,788 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:32,790 : [INFO]  Batch number 221 model fetched from the server
2023-03-25 18:28:32,791 : [INFO]  ################ Batch 221: final global model evalution after 3 rounds ################
2023-03-25 18:28:34,560 : [INFO]  Batch 221: Training set : loss - 0.6165, accuracy - 0.6413, recall - 0.8696, AUC - 0.7768, F1 - 0.708, precision - 0.597, training time - -11.0 seconds
2023-03-25 18:28:34,560 : [INFO]  Batch 221: Testing set : loss - 0.5863, accuracy - 0.7304, recall - 0.8627, AUC - 0.836, F1 - 0.7619, precision - 0.6822
2023-03-25 18:28:34,572 : [INFO]  Batch 222 initialized 
2023-03-25 18:28:35,122 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:35,742 : [INFO]  ------------------------- Batch 222 training: round 1 -------------------------
2023-03-25 18:28:41,155 : [INFO]  ------------------------- Batch round 1, loss: 0.5942 -------------------------
2023-03-25 18:28:41,155 : [INFO]  ------------------------- Batch 222, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:41,166 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:41,169 : [INFO]  ------------------------- Batch 222 training: round 2 -------------------------
2023-03-25 18:28:44,178 : [INFO]  ------------------------- Batch round 2, loss: 0.5978 -------------------------
2023-03-25 18:28:44,178 : [INFO]  ------------------------- Batch 222, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:44,195 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:44,198 : [INFO]  ------------------------- Batch 222 training: round 3 -------------------------
2023-03-25 18:28:47,104 : [INFO]  ------------------------- Batch round 3, loss: 0.5966 -------------------------
2023-03-25 18:28:47,104 : [INFO]  ------------------------- Batch 222, round 3: Sent local model to the server -------------------------
2023-03-25 18:28:47,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:47,119 : [INFO]  Batch number 222 model fetched from the server
2023-03-25 18:28:47,119 : [INFO]  ################ Batch 222: final global model evalution after 3 rounds ################
2023-03-25 18:28:48,908 : [INFO]  Batch 222: Training set : loss - 0.5982, accuracy - 0.6793, recall - 0.7717, AUC - 0.7942, F1 - 0.7065, precision - 0.6514, training time - -11.0 seconds
2023-03-25 18:28:48,908 : [INFO]  Batch 222: Testing set : loss - 0.591, accuracy - 0.6814, recall - 0.8824, AUC - 0.8471, F1 - 0.7347, precision - 0.6294
2023-03-25 18:28:48,920 : [INFO]  Batch 223 initialized 
2023-03-25 18:28:49,492 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:28:50,155 : [INFO]  ------------------------- Batch 223 training: round 1 -------------------------
2023-03-25 18:28:55,389 : [INFO]  ------------------------- Batch round 1, loss: 0.5814 -------------------------
2023-03-25 18:28:55,389 : [INFO]  ------------------------- Batch 223, round 1: Sent local model to the server -------------------------
2023-03-25 18:28:55,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:55,659 : [INFO]  ------------------------- Batch 223 training: round 2 -------------------------
2023-03-25 18:28:58,518 : [INFO]  ------------------------- Batch round 2, loss: 0.5798 -------------------------
2023-03-25 18:28:58,518 : [INFO]  ------------------------- Batch 223, round 2: Sent local model to the server -------------------------
2023-03-25 18:28:58,541 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:28:58,544 : [INFO]  ------------------------- Batch 223 training: round 3 -------------------------
2023-03-25 18:29:01,411 : [INFO]  ------------------------- Batch round 3, loss: 0.5805 -------------------------
2023-03-25 18:29:01,411 : [INFO]  ------------------------- Batch 223, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:01,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:01,498 : [INFO]  Batch number 223 model fetched from the server
2023-03-25 18:29:01,498 : [INFO]  ################ Batch 223: final global model evalution after 3 rounds ################
2023-03-25 18:29:03,288 : [INFO]  Batch 223: Training set : loss - 0.5911, accuracy - 0.7283, recall - 0.8478, AUC - 0.8065, F1 - 0.7573, precision - 0.6842, training time - -11.0 seconds
2023-03-25 18:29:03,288 : [INFO]  Batch 223: Testing set : loss - 0.5683, accuracy - 0.75, recall - 0.902, AUC - 0.8532, F1 - 0.783, precision - 0.6917
2023-03-25 18:29:03,298 : [INFO]  Batch 224 initialized 
2023-03-25 18:29:03,867 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:04,525 : [INFO]  ------------------------- Batch 224 training: round 1 -------------------------
2023-03-25 18:29:10,202 : [INFO]  ------------------------- Batch round 1, loss: 0.6019 -------------------------
2023-03-25 18:29:10,202 : [INFO]  ------------------------- Batch 224, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:10,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:10,272 : [INFO]  ------------------------- Batch 224 training: round 2 -------------------------
2023-03-25 18:29:13,070 : [INFO]  ------------------------- Batch round 2, loss: 0.6078 -------------------------
2023-03-25 18:29:13,071 : [INFO]  ------------------------- Batch 224, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:13,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:13,163 : [INFO]  ------------------------- Batch 224 training: round 3 -------------------------
2023-03-25 18:29:15,978 : [INFO]  ------------------------- Batch round 3, loss: 0.6051 -------------------------
2023-03-25 18:29:15,979 : [INFO]  ------------------------- Batch 224, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:16,118 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:16,122 : [INFO]  Batch number 224 model fetched from the server
2023-03-25 18:29:16,123 : [INFO]  ################ Batch 224: final global model evalution after 3 rounds ################
2023-03-25 18:29:18,069 : [INFO]  Batch 224: Training set : loss - 0.6236, accuracy - 0.587, recall - 0.8261, AUC - 0.7619, F1 - 0.6667, precision - 0.5588, training time - -12.0 seconds
2023-03-25 18:29:18,070 : [INFO]  Batch 224: Testing set : loss - 0.5593, accuracy - 0.6912, recall - 0.9216, AUC - 0.8966, F1 - 0.749, precision - 0.6309
2023-03-25 18:29:18,081 : [INFO]  Batch 225 initialized 
2023-03-25 18:29:18,648 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:19,298 : [INFO]  ------------------------- Batch 225 training: round 1 -------------------------
2023-03-25 18:29:24,821 : [INFO]  ------------------------- Batch round 1, loss: 0.5982 -------------------------
2023-03-25 18:29:24,821 : [INFO]  ------------------------- Batch 225, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:24,834 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:24,836 : [INFO]  ------------------------- Batch 225 training: round 2 -------------------------
2023-03-25 18:29:27,797 : [INFO]  ------------------------- Batch round 2, loss: 0.6 -------------------------
2023-03-25 18:29:27,797 : [INFO]  ------------------------- Batch 225, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:27,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:27,836 : [INFO]  ------------------------- Batch 225 training: round 3 -------------------------
2023-03-25 18:29:30,816 : [INFO]  ------------------------- Batch round 3, loss: 0.5966 -------------------------
2023-03-25 18:29:30,817 : [INFO]  ------------------------- Batch 225, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:30,862 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:30,866 : [INFO]  Batch number 225 model fetched from the server
2023-03-25 18:29:30,866 : [INFO]  ################ Batch 225: final global model evalution after 3 rounds ################
2023-03-25 18:29:32,687 : [INFO]  Batch 225: Training set : loss - 0.6096, accuracy - 0.712, recall - 0.8696, AUC - 0.7654, F1 - 0.7512, precision - 0.6612, training time - -12.0 seconds
2023-03-25 18:29:32,687 : [INFO]  Batch 225: Testing set : loss - 0.5835, accuracy - 0.7059, recall - 0.8824, AUC - 0.8305, F1 - 0.75, precision - 0.6522
2023-03-25 18:29:32,699 : [INFO]  Batch 226 initialized 
2023-03-25 18:29:33,284 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:33,916 : [INFO]  ------------------------- Batch 226 training: round 1 -------------------------
2023-03-25 18:29:39,352 : [INFO]  ------------------------- Batch round 1, loss: 0.5917 -------------------------
2023-03-25 18:29:39,352 : [INFO]  ------------------------- Batch 226, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:39,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:39,373 : [INFO]  ------------------------- Batch 226 training: round 2 -------------------------
2023-03-25 18:29:42,170 : [INFO]  ------------------------- Batch round 2, loss: 0.5953 -------------------------
2023-03-25 18:29:42,170 : [INFO]  ------------------------- Batch 226, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:42,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:42,219 : [INFO]  ------------------------- Batch 226 training: round 3 -------------------------
2023-03-25 18:29:44,967 : [INFO]  ------------------------- Batch round 3, loss: 0.5918 -------------------------
2023-03-25 18:29:44,967 : [INFO]  ------------------------- Batch 226, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:45,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:45,028 : [INFO]  Batch number 226 model fetched from the server
2023-03-25 18:29:45,028 : [INFO]  ################ Batch 226: final global model evalution after 3 rounds ################
2023-03-25 18:29:46,751 : [INFO]  Batch 226: Training set : loss - 0.6025, accuracy - 0.7065, recall - 0.8804, AUC - 0.7977, F1 - 0.75, precision - 0.6532, training time - -11.0 seconds
2023-03-25 18:29:46,751 : [INFO]  Batch 226: Testing set : loss - 0.5976, accuracy - 0.701, recall - 0.8824, AUC - 0.8218, F1 - 0.7469, precision - 0.6475
2023-03-25 18:29:46,766 : [INFO]  Batch 227 initialized 
2023-03-25 18:29:47,339 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:29:47,988 : [INFO]  ------------------------- Batch 227 training: round 1 -------------------------
2023-03-25 18:29:53,266 : [INFO]  ------------------------- Batch round 1, loss: 0.5785 -------------------------
2023-03-25 18:29:53,266 : [INFO]  ------------------------- Batch 227, round 1: Sent local model to the server -------------------------
2023-03-25 18:29:53,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:53,405 : [INFO]  ------------------------- Batch 227 training: round 2 -------------------------
2023-03-25 18:29:56,280 : [INFO]  ------------------------- Batch round 2, loss: 0.5757 -------------------------
2023-03-25 18:29:56,280 : [INFO]  ------------------------- Batch 227, round 2: Sent local model to the server -------------------------
2023-03-25 18:29:56,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:56,398 : [INFO]  ------------------------- Batch 227 training: round 3 -------------------------
2023-03-25 18:29:59,175 : [INFO]  ------------------------- Batch round 3, loss: 0.5809 -------------------------
2023-03-25 18:29:59,176 : [INFO]  ------------------------- Batch 227, round 3: Sent local model to the server -------------------------
2023-03-25 18:29:59,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:29:59,287 : [INFO]  Batch number 227 model fetched from the server
2023-03-25 18:29:59,287 : [INFO]  ################ Batch 227: final global model evalution after 3 rounds ################
2023-03-25 18:30:01,078 : [INFO]  Batch 227: Training set : loss - 0.5901, accuracy - 0.6848, recall - 0.9239, AUC - 0.8276, F1 - 0.7456, precision - 0.625, training time - -11.0 seconds
2023-03-25 18:30:01,078 : [INFO]  Batch 227: Testing set : loss - 0.6015, accuracy - 0.6422, recall - 0.8333, AUC - 0.7982, F1 - 0.6996, precision - 0.6028
2023-03-25 18:30:01,092 : [INFO]  Batch 228 initialized 
2023-03-25 18:30:01,684 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:02,358 : [INFO]  ------------------------- Batch 228 training: round 1 -------------------------
2023-03-25 18:30:07,767 : [INFO]  ------------------------- Batch round 1, loss: 0.5978 -------------------------
2023-03-25 18:30:07,768 : [INFO]  ------------------------- Batch 228, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:08,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:08,073 : [INFO]  ------------------------- Batch 228 training: round 2 -------------------------
2023-03-25 18:30:10,919 : [INFO]  ------------------------- Batch round 2, loss: 0.589 -------------------------
2023-03-25 18:30:10,919 : [INFO]  ------------------------- Batch 228, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:10,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:10,936 : [INFO]  ------------------------- Batch 228 training: round 3 -------------------------
2023-03-25 18:30:13,776 : [INFO]  ------------------------- Batch round 3, loss: 0.5925 -------------------------
2023-03-25 18:30:13,776 : [INFO]  ------------------------- Batch 228, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:13,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:13,800 : [INFO]  Batch number 228 model fetched from the server
2023-03-25 18:30:13,800 : [INFO]  ################ Batch 228: final global model evalution after 3 rounds ################
2023-03-25 18:30:15,624 : [INFO]  Batch 228: Training set : loss - 0.6054, accuracy - 0.6685, recall - 0.837, AUC - 0.7772, F1 - 0.7163, precision - 0.626, training time - -11.0 seconds
2023-03-25 18:30:15,625 : [INFO]  Batch 228: Testing set : loss - 0.6111, accuracy - 0.6618, recall - 0.8431, AUC - 0.7813, F1 - 0.7137, precision - 0.6187
2023-03-25 18:30:15,633 : [INFO]  Batch 229 initialized 
2023-03-25 18:30:16,213 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:16,876 : [INFO]  ------------------------- Batch 229 training: round 1 -------------------------
2023-03-25 18:30:22,321 : [INFO]  ------------------------- Batch round 1, loss: 0.5938 -------------------------
2023-03-25 18:30:22,321 : [INFO]  ------------------------- Batch 229, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:22,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:22,398 : [INFO]  ------------------------- Batch 229 training: round 2 -------------------------
2023-03-25 18:30:25,345 : [INFO]  ------------------------- Batch round 2, loss: 0.595 -------------------------
2023-03-25 18:30:25,346 : [INFO]  ------------------------- Batch 229, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:25,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:25,512 : [INFO]  ------------------------- Batch 229 training: round 3 -------------------------
2023-03-25 18:30:28,493 : [INFO]  ------------------------- Batch round 3, loss: 0.5957 -------------------------
2023-03-25 18:30:28,493 : [INFO]  ------------------------- Batch 229, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:28,642 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:28,652 : [INFO]  Batch number 229 model fetched from the server
2023-03-25 18:30:28,653 : [INFO]  ################ Batch 229: final global model evalution after 3 rounds ################
2023-03-25 18:30:30,487 : [INFO]  Batch 229: Training set : loss - 0.6033, accuracy - 0.6957, recall - 0.9022, AUC - 0.7924, F1 - 0.7477, precision - 0.6385, training time - -12.0 seconds
2023-03-25 18:30:30,488 : [INFO]  Batch 229: Testing set : loss - 0.5925, accuracy - 0.7059, recall - 0.9118, AUC - 0.8245, F1 - 0.7561, precision - 0.6458
2023-03-25 18:30:30,503 : [INFO]  Batch 230 initialized 
2023-03-25 18:30:31,110 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:31,728 : [INFO]  ------------------------- Batch 230 training: round 1 -------------------------
2023-03-25 18:30:37,080 : [INFO]  ------------------------- Batch round 1, loss: 0.5807 -------------------------
2023-03-25 18:30:37,081 : [INFO]  ------------------------- Batch 230, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:37,368 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:37,372 : [INFO]  ------------------------- Batch 230 training: round 2 -------------------------
2023-03-25 18:30:40,127 : [INFO]  ------------------------- Batch round 2, loss: 0.5932 -------------------------
2023-03-25 18:30:40,127 : [INFO]  ------------------------- Batch 230, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:40,270 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:40,272 : [INFO]  ------------------------- Batch 230 training: round 3 -------------------------
2023-03-25 18:30:42,981 : [INFO]  ------------------------- Batch round 3, loss: 0.5827 -------------------------
2023-03-25 18:30:42,982 : [INFO]  ------------------------- Batch 230, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:43,181 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:43,184 : [INFO]  Batch number 230 model fetched from the server
2023-03-25 18:30:43,184 : [INFO]  ################ Batch 230: final global model evalution after 3 rounds ################
2023-03-25 18:30:44,923 : [INFO]  Batch 230: Training set : loss - 0.6021, accuracy - 0.6739, recall - 0.8913, AUC - 0.8005, F1 - 0.7321, precision - 0.6212, training time - -11.0 seconds
2023-03-25 18:30:44,923 : [INFO]  Batch 230: Testing set : loss - 0.5767, accuracy - 0.6912, recall - 0.8333, AUC - 0.8438, F1 - 0.7296, precision - 0.6489
2023-03-25 18:30:44,935 : [INFO]  Batch 231 initialized 
2023-03-25 18:30:45,507 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:30:46,164 : [INFO]  ------------------------- Batch 231 training: round 1 -------------------------
2023-03-25 18:30:51,553 : [INFO]  ------------------------- Batch round 1, loss: 0.5767 -------------------------
2023-03-25 18:30:51,553 : [INFO]  ------------------------- Batch 231, round 1: Sent local model to the server -------------------------
2023-03-25 18:30:51,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:51,570 : [INFO]  ------------------------- Batch 231 training: round 2 -------------------------
2023-03-25 18:30:54,398 : [INFO]  ------------------------- Batch round 2, loss: 0.5768 -------------------------
2023-03-25 18:30:54,398 : [INFO]  ------------------------- Batch 231, round 2: Sent local model to the server -------------------------
2023-03-25 18:30:54,411 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:54,413 : [INFO]  ------------------------- Batch 231 training: round 3 -------------------------
2023-03-25 18:30:57,250 : [INFO]  ------------------------- Batch round 3, loss: 0.5793 -------------------------
2023-03-25 18:30:57,250 : [INFO]  ------------------------- Batch 231, round 3: Sent local model to the server -------------------------
2023-03-25 18:30:57,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:30:57,265 : [INFO]  Batch number 231 model fetched from the server
2023-03-25 18:30:57,265 : [INFO]  ################ Batch 231: final global model evalution after 3 rounds ################
2023-03-25 18:30:59,140 : [INFO]  Batch 231: Training set : loss - 0.588, accuracy - 0.7065, recall - 0.8587, AUC - 0.8072, F1 - 0.7453, precision - 0.6583, training time - -11.0 seconds
2023-03-25 18:30:59,141 : [INFO]  Batch 231: Testing set : loss - 0.5729, accuracy - 0.6912, recall - 0.8137, AUC - 0.8278, F1 - 0.7249, precision - 0.6535
2023-03-25 18:30:59,155 : [INFO]  Batch 232 initialized 
2023-03-25 18:30:59,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:00,412 : [INFO]  ------------------------- Batch 232 training: round 1 -------------------------
2023-03-25 18:31:05,814 : [INFO]  ------------------------- Batch round 1, loss: 0.5733 -------------------------
2023-03-25 18:31:05,814 : [INFO]  ------------------------- Batch 232, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:05,831 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:05,834 : [INFO]  ------------------------- Batch 232 training: round 2 -------------------------
2023-03-25 18:31:08,645 : [INFO]  ------------------------- Batch round 2, loss: 0.5773 -------------------------
2023-03-25 18:31:08,645 : [INFO]  ------------------------- Batch 232, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:08,852 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:08,859 : [INFO]  ------------------------- Batch 232 training: round 3 -------------------------
2023-03-25 18:31:11,645 : [INFO]  ------------------------- Batch round 3, loss: 0.5739 -------------------------
2023-03-25 18:31:11,646 : [INFO]  ------------------------- Batch 232, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:11,661 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:11,665 : [INFO]  Batch number 232 model fetched from the server
2023-03-25 18:31:11,665 : [INFO]  ################ Batch 232: final global model evalution after 3 rounds ################
2023-03-25 18:31:13,409 : [INFO]  Batch 232: Training set : loss - 0.5889, accuracy - 0.712, recall - 0.8587, AUC - 0.8014, F1 - 0.7488, precision - 0.6639, training time - -11.0 seconds
2023-03-25 18:31:13,409 : [INFO]  Batch 232: Testing set : loss - 0.5669, accuracy - 0.7157, recall - 0.8431, AUC - 0.8624, F1 - 0.7478, precision - 0.6719
2023-03-25 18:31:13,419 : [INFO]  Batch 233 initialized 
2023-03-25 18:31:13,972 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:14,659 : [INFO]  ------------------------- Batch 233 training: round 1 -------------------------
2023-03-25 18:31:20,023 : [INFO]  ------------------------- Batch round 1, loss: 0.5637 -------------------------
2023-03-25 18:31:20,023 : [INFO]  ------------------------- Batch 233, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:20,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:20,038 : [INFO]  ------------------------- Batch 233 training: round 2 -------------------------
2023-03-25 18:31:23,016 : [INFO]  ------------------------- Batch round 2, loss: 0.5668 -------------------------
2023-03-25 18:31:23,016 : [INFO]  ------------------------- Batch 233, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:23,030 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:23,033 : [INFO]  ------------------------- Batch 233 training: round 3 -------------------------
2023-03-25 18:31:26,038 : [INFO]  ------------------------- Batch round 3, loss: 0.5656 -------------------------
2023-03-25 18:31:26,039 : [INFO]  ------------------------- Batch 233, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:26,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:26,055 : [INFO]  Batch number 233 model fetched from the server
2023-03-25 18:31:26,055 : [INFO]  ################ Batch 233: final global model evalution after 3 rounds ################
2023-03-25 18:31:27,870 : [INFO]  Batch 233: Training set : loss - 0.567, accuracy - 0.7935, recall - 0.9239, AUC - 0.859, F1 - 0.8173, precision - 0.7328, training time - -11.0 seconds
2023-03-25 18:31:27,870 : [INFO]  Batch 233: Testing set : loss - 0.5828, accuracy - 0.7157, recall - 0.9216, AUC - 0.8486, F1 - 0.7642, precision - 0.6528
2023-03-25 18:31:27,880 : [INFO]  Batch 234 initialized 
2023-03-25 18:31:28,442 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:29,121 : [INFO]  ------------------------- Batch 234 training: round 1 -------------------------
2023-03-25 18:31:34,626 : [INFO]  ------------------------- Batch round 1, loss: 0.5685 -------------------------
2023-03-25 18:31:34,626 : [INFO]  ------------------------- Batch 234, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:34,640 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:34,643 : [INFO]  ------------------------- Batch 234 training: round 2 -------------------------
2023-03-25 18:31:37,690 : [INFO]  ------------------------- Batch round 2, loss: 0.5755 -------------------------
2023-03-25 18:31:37,690 : [INFO]  ------------------------- Batch 234, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:37,704 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:37,707 : [INFO]  ------------------------- Batch 234 training: round 3 -------------------------
2023-03-25 18:31:40,678 : [INFO]  ------------------------- Batch round 3, loss: 0.569 -------------------------
2023-03-25 18:31:40,678 : [INFO]  ------------------------- Batch 234, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:40,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:40,710 : [INFO]  Batch number 234 model fetched from the server
2023-03-25 18:31:40,710 : [INFO]  ################ Batch 234: final global model evalution after 3 rounds ################
2023-03-25 18:31:42,537 : [INFO]  Batch 234: Training set : loss - 0.5809, accuracy - 0.6739, recall - 0.8478, AUC - 0.8332, F1 - 0.7222, precision - 0.629, training time - -12.0 seconds
2023-03-25 18:31:42,537 : [INFO]  Batch 234: Testing set : loss - 0.5863, accuracy - 0.7108, recall - 0.8627, AUC - 0.8409, F1 - 0.7489, precision - 0.6617
2023-03-25 18:31:42,555 : [INFO]  Batch 235 initialized 
2023-03-25 18:31:43,144 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:43,833 : [INFO]  ------------------------- Batch 235 training: round 1 -------------------------
2023-03-25 18:31:49,361 : [INFO]  ------------------------- Batch round 1, loss: 0.6056 -------------------------
2023-03-25 18:31:49,361 : [INFO]  ------------------------- Batch 235, round 1: Sent local model to the server -------------------------
2023-03-25 18:31:49,373 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:49,376 : [INFO]  ------------------------- Batch 235 training: round 2 -------------------------
2023-03-25 18:31:52,277 : [INFO]  ------------------------- Batch round 2, loss: 0.6117 -------------------------
2023-03-25 18:31:52,277 : [INFO]  ------------------------- Batch 235, round 2: Sent local model to the server -------------------------
2023-03-25 18:31:52,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:52,293 : [INFO]  ------------------------- Batch 235 training: round 3 -------------------------
2023-03-25 18:31:55,137 : [INFO]  ------------------------- Batch round 3, loss: 0.6085 -------------------------
2023-03-25 18:31:55,137 : [INFO]  ------------------------- Batch 235, round 3: Sent local model to the server -------------------------
2023-03-25 18:31:55,149 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:31:55,152 : [INFO]  Batch number 235 model fetched from the server
2023-03-25 18:31:55,152 : [INFO]  ################ Batch 235: final global model evalution after 3 rounds ################
2023-03-25 18:31:56,884 : [INFO]  Batch 235: Training set : loss - 0.6278, accuracy - 0.6522, recall - 0.8043, AUC - 0.7352, F1 - 0.6981, precision - 0.6167, training time - -11.0 seconds
2023-03-25 18:31:56,884 : [INFO]  Batch 235: Testing set : loss - 0.58, accuracy - 0.6912, recall - 0.8039, AUC - 0.825, F1 - 0.7225, precision - 0.656
2023-03-25 18:31:56,902 : [INFO]  Batch 236 initialized 
2023-03-25 18:31:57,462 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:31:58,121 : [INFO]  ------------------------- Batch 236 training: round 1 -------------------------
2023-03-25 18:32:03,577 : [INFO]  ------------------------- Batch round 1, loss: 0.597 -------------------------
2023-03-25 18:32:03,578 : [INFO]  ------------------------- Batch 236, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:03,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:03,592 : [INFO]  ------------------------- Batch 236 training: round 2 -------------------------
2023-03-25 18:32:06,485 : [INFO]  ------------------------- Batch round 2, loss: 0.5961 -------------------------
2023-03-25 18:32:06,486 : [INFO]  ------------------------- Batch 236, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:06,501 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:06,504 : [INFO]  ------------------------- Batch 236 training: round 3 -------------------------
2023-03-25 18:32:09,311 : [INFO]  ------------------------- Batch round 3, loss: 0.5952 -------------------------
2023-03-25 18:32:09,311 : [INFO]  ------------------------- Batch 236, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:09,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:09,326 : [INFO]  Batch number 236 model fetched from the server
2023-03-25 18:32:09,326 : [INFO]  ################ Batch 236: final global model evalution after 3 rounds ################
2023-03-25 18:32:11,139 : [INFO]  Batch 236: Training set : loss - 0.6048, accuracy - 0.6359, recall - 0.837, AUC - 0.7801, F1 - 0.6968, precision - 0.5969, training time - -11.0 seconds
2023-03-25 18:32:11,139 : [INFO]  Batch 236: Testing set : loss - 0.574, accuracy - 0.7157, recall - 0.8725, AUC - 0.8527, F1 - 0.7542, precision - 0.6642
2023-03-25 18:32:11,154 : [INFO]  Batch 237 initialized 
2023-03-25 18:32:11,732 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:12,392 : [INFO]  ------------------------- Batch 237 training: round 1 -------------------------
2023-03-25 18:32:17,797 : [INFO]  ------------------------- Batch round 1, loss: 0.5839 -------------------------
2023-03-25 18:32:17,797 : [INFO]  ------------------------- Batch 237, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:17,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:17,853 : [INFO]  ------------------------- Batch 237 training: round 2 -------------------------
2023-03-25 18:32:20,693 : [INFO]  ------------------------- Batch round 2, loss: 0.5811 -------------------------
2023-03-25 18:32:20,694 : [INFO]  ------------------------- Batch 237, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:20,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:20,709 : [INFO]  ------------------------- Batch 237 training: round 3 -------------------------
2023-03-25 18:32:23,702 : [INFO]  ------------------------- Batch round 3, loss: 0.5825 -------------------------
2023-03-25 18:32:23,703 : [INFO]  ------------------------- Batch 237, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:23,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:23,723 : [INFO]  Batch number 237 model fetched from the server
2023-03-25 18:32:23,723 : [INFO]  ################ Batch 237: final global model evalution after 3 rounds ################
2023-03-25 18:32:25,477 : [INFO]  Batch 237: Training set : loss - 0.5914, accuracy - 0.7174, recall - 0.8587, AUC - 0.8145, F1 - 0.7524, precision - 0.6695, training time - -11.0 seconds
2023-03-25 18:32:25,478 : [INFO]  Batch 237: Testing set : loss - 0.5739, accuracy - 0.7255, recall - 0.9412, AUC - 0.8653, F1 - 0.7742, precision - 0.6575
2023-03-25 18:32:25,486 : [INFO]  Batch 238 initialized 
2023-03-25 18:32:26,072 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:26,751 : [INFO]  ------------------------- Batch 238 training: round 1 -------------------------
2023-03-25 18:32:32,066 : [INFO]  ------------------------- Batch round 1, loss: 0.5702 -------------------------
2023-03-25 18:32:32,066 : [INFO]  ------------------------- Batch 238, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:32,320 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:32,325 : [INFO]  ------------------------- Batch 238 training: round 2 -------------------------
2023-03-25 18:32:35,059 : [INFO]  ------------------------- Batch round 2, loss: 0.5686 -------------------------
2023-03-25 18:32:35,059 : [INFO]  ------------------------- Batch 238, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:35,072 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:35,074 : [INFO]  ------------------------- Batch 238 training: round 3 -------------------------
2023-03-25 18:32:37,805 : [INFO]  ------------------------- Batch round 3, loss: 0.5743 -------------------------
2023-03-25 18:32:37,805 : [INFO]  ------------------------- Batch 238, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:37,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:37,873 : [INFO]  Batch number 238 model fetched from the server
2023-03-25 18:32:37,873 : [INFO]  ################ Batch 238: final global model evalution after 3 rounds ################
2023-03-25 18:32:39,625 : [INFO]  Batch 238: Training set : loss - 0.5988, accuracy - 0.6739, recall - 0.8587, AUC - 0.814, F1 - 0.7248, precision - 0.627, training time - -11.0 seconds
2023-03-25 18:32:39,626 : [INFO]  Batch 238: Testing set : loss - 0.5791, accuracy - 0.7108, recall - 0.8922, AUC - 0.8411, F1 - 0.7552, precision - 0.6547
2023-03-25 18:32:39,635 : [INFO]  Batch 239 initialized 
2023-03-25 18:32:40,210 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:40,889 : [INFO]  ------------------------- Batch 239 training: round 1 -------------------------
2023-03-25 18:32:46,322 : [INFO]  ------------------------- Batch round 1, loss: 0.599 -------------------------
2023-03-25 18:32:46,322 : [INFO]  ------------------------- Batch 239, round 1: Sent local model to the server -------------------------
2023-03-25 18:32:46,379 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:46,382 : [INFO]  ------------------------- Batch 239 training: round 2 -------------------------
2023-03-25 18:32:49,226 : [INFO]  ------------------------- Batch round 2, loss: 0.6002 -------------------------
2023-03-25 18:32:49,226 : [INFO]  ------------------------- Batch 239, round 2: Sent local model to the server -------------------------
2023-03-25 18:32:49,328 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:49,331 : [INFO]  ------------------------- Batch 239 training: round 3 -------------------------
2023-03-25 18:32:52,182 : [INFO]  ------------------------- Batch round 3, loss: 0.603 -------------------------
2023-03-25 18:32:52,182 : [INFO]  ------------------------- Batch 239, round 3: Sent local model to the server -------------------------
2023-03-25 18:32:52,255 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:32:52,258 : [INFO]  Batch number 239 model fetched from the server
2023-03-25 18:32:52,258 : [INFO]  ################ Batch 239: final global model evalution after 3 rounds ################
2023-03-25 18:32:54,038 : [INFO]  Batch 239: Training set : loss - 0.6197, accuracy - 0.6413, recall - 0.8261, AUC - 0.7641, F1 - 0.6972, precision - 0.6032, training time - -11.0 seconds
2023-03-25 18:32:54,038 : [INFO]  Batch 239: Testing set : loss - 0.6314, accuracy - 0.6225, recall - 0.8235, AUC - 0.7439, F1 - 0.6857, precision - 0.5874
2023-03-25 18:32:54,054 : [INFO]  Batch 240 initialized 
2023-03-25 18:32:54,622 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:32:55,293 : [INFO]  ------------------------- Batch 240 training: round 1 -------------------------
2023-03-25 18:33:00,652 : [INFO]  ------------------------- Batch round 1, loss: 0.5993 -------------------------
2023-03-25 18:33:00,652 : [INFO]  ------------------------- Batch 240, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:00,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:00,975 : [INFO]  ------------------------- Batch 240 training: round 2 -------------------------
2023-03-25 18:33:03,865 : [INFO]  ------------------------- Batch round 2, loss: 0.6008 -------------------------
2023-03-25 18:33:03,865 : [INFO]  ------------------------- Batch 240, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:04,005 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:04,007 : [INFO]  ------------------------- Batch 240 training: round 3 -------------------------
2023-03-25 18:33:06,876 : [INFO]  ------------------------- Batch round 3, loss: 0.6068 -------------------------
2023-03-25 18:33:06,876 : [INFO]  ------------------------- Batch 240, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:06,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:06,996 : [INFO]  Batch number 240 model fetched from the server
2023-03-25 18:33:06,996 : [INFO]  ################ Batch 240: final global model evalution after 3 rounds ################
2023-03-25 18:33:08,754 : [INFO]  Batch 240: Training set : loss - 0.628, accuracy - 0.6033, recall - 0.8043, AUC - 0.754, F1 - 0.6697, precision - 0.5736, training time - -12.0 seconds
2023-03-25 18:33:08,754 : [INFO]  Batch 240: Testing set : loss - 0.6031, accuracy - 0.652, recall - 0.7941, AUC - 0.7786, F1 - 0.6953, precision - 0.6183
2023-03-25 18:33:08,765 : [INFO]  Batch 241 initialized 
2023-03-25 18:33:09,335 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:10,006 : [INFO]  ------------------------- Batch 241 training: round 1 -------------------------
2023-03-25 18:33:15,448 : [INFO]  ------------------------- Batch round 1, loss: 0.5921 -------------------------
2023-03-25 18:33:15,448 : [INFO]  ------------------------- Batch 241, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:15,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:15,466 : [INFO]  ------------------------- Batch 241 training: round 2 -------------------------
2023-03-25 18:33:18,294 : [INFO]  ------------------------- Batch round 2, loss: 0.5983 -------------------------
2023-03-25 18:33:18,294 : [INFO]  ------------------------- Batch 241, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:18,388 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:18,391 : [INFO]  ------------------------- Batch 241 training: round 3 -------------------------
2023-03-25 18:33:21,174 : [INFO]  ------------------------- Batch round 3, loss: 0.591 -------------------------
2023-03-25 18:33:21,174 : [INFO]  ------------------------- Batch 241, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:21,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:21,331 : [INFO]  Batch number 241 model fetched from the server
2023-03-25 18:33:21,331 : [INFO]  ################ Batch 241: final global model evalution after 3 rounds ################
2023-03-25 18:33:23,103 : [INFO]  Batch 241: Training set : loss - 0.6078, accuracy - 0.6739, recall - 0.8152, AUC - 0.7834, F1 - 0.7143, precision - 0.6356, training time - -11.0 seconds
2023-03-25 18:33:23,103 : [INFO]  Batch 241: Testing set : loss - 0.5857, accuracy - 0.6765, recall - 0.8137, AUC - 0.8274, F1 - 0.7155, precision - 0.6385
2023-03-25 18:33:23,121 : [INFO]  Batch 242 initialized 
2023-03-25 18:33:23,682 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:24,375 : [INFO]  ------------------------- Batch 242 training: round 1 -------------------------
2023-03-25 18:33:29,643 : [INFO]  ------------------------- Batch round 1, loss: 0.5716 -------------------------
2023-03-25 18:33:29,643 : [INFO]  ------------------------- Batch 242, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:29,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:29,753 : [INFO]  ------------------------- Batch 242 training: round 2 -------------------------
2023-03-25 18:33:32,529 : [INFO]  ------------------------- Batch round 2, loss: 0.5673 -------------------------
2023-03-25 18:33:32,530 : [INFO]  ------------------------- Batch 242, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:32,672 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:32,675 : [INFO]  ------------------------- Batch 242 training: round 3 -------------------------
2023-03-25 18:33:35,450 : [INFO]  ------------------------- Batch round 3, loss: 0.5669 -------------------------
2023-03-25 18:33:35,451 : [INFO]  ------------------------- Batch 242, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:35,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:35,595 : [INFO]  Batch number 242 model fetched from the server
2023-03-25 18:33:35,595 : [INFO]  ################ Batch 242: final global model evalution after 3 rounds ################
2023-03-25 18:33:37,278 : [INFO]  Batch 242: Training set : loss - 0.5778, accuracy - 0.712, recall - 0.8696, AUC - 0.835, F1 - 0.7512, precision - 0.6612, training time - -11.0 seconds
2023-03-25 18:33:37,278 : [INFO]  Batch 242: Testing set : loss - 0.5785, accuracy - 0.7059, recall - 0.8333, AUC - 0.8163, F1 - 0.7391, precision - 0.6641
2023-03-25 18:33:37,290 : [INFO]  Batch 243 initialized 
2023-03-25 18:33:37,840 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:38,472 : [INFO]  ------------------------- Batch 243 training: round 1 -------------------------
2023-03-25 18:33:44,038 : [INFO]  ------------------------- Batch round 1, loss: 0.571 -------------------------
2023-03-25 18:33:44,039 : [INFO]  ------------------------- Batch 243, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:44,220 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:44,223 : [INFO]  ------------------------- Batch 243 training: round 2 -------------------------
2023-03-25 18:33:47,002 : [INFO]  ------------------------- Batch round 2, loss: 0.5686 -------------------------
2023-03-25 18:33:47,002 : [INFO]  ------------------------- Batch 243, round 2: Sent local model to the server -------------------------
2023-03-25 18:33:47,155 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:47,158 : [INFO]  ------------------------- Batch 243 training: round 3 -------------------------
2023-03-25 18:33:49,969 : [INFO]  ------------------------- Batch round 3, loss: 0.5659 -------------------------
2023-03-25 18:33:49,969 : [INFO]  ------------------------- Batch 243, round 3: Sent local model to the server -------------------------
2023-03-25 18:33:50,083 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:50,086 : [INFO]  Batch number 243 model fetched from the server
2023-03-25 18:33:50,086 : [INFO]  ################ Batch 243: final global model evalution after 3 rounds ################
2023-03-25 18:33:51,844 : [INFO]  Batch 243: Training set : loss - 0.5792, accuracy - 0.6957, recall - 0.8587, AUC - 0.8308, F1 - 0.7383, precision - 0.6475, training time - -12.0 seconds
2023-03-25 18:33:51,845 : [INFO]  Batch 243: Testing set : loss - 0.5822, accuracy - 0.6961, recall - 0.8922, AUC - 0.8393, F1 - 0.7459, precision - 0.6408
2023-03-25 18:33:51,861 : [INFO]  Batch 244 initialized 
2023-03-25 18:33:52,433 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:33:53,113 : [INFO]  ------------------------- Batch 244 training: round 1 -------------------------
2023-03-25 18:33:58,466 : [INFO]  ------------------------- Batch round 1, loss: 0.5746 -------------------------
2023-03-25 18:33:58,466 : [INFO]  ------------------------- Batch 244, round 1: Sent local model to the server -------------------------
2023-03-25 18:33:58,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:33:58,564 : [INFO]  ------------------------- Batch 244 training: round 2 -------------------------
2023-03-25 18:34:01,620 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-25 18:34:01,621 : [INFO]  ------------------------- Batch 244, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:01,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:01,706 : [INFO]  ------------------------- Batch 244 training: round 3 -------------------------
2023-03-25 18:34:04,677 : [INFO]  ------------------------- Batch round 3, loss: 0.5733 -------------------------
2023-03-25 18:34:04,677 : [INFO]  ------------------------- Batch 244, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:04,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:04,838 : [INFO]  Batch number 244 model fetched from the server
2023-03-25 18:34:04,839 : [INFO]  ################ Batch 244: final global model evalution after 3 rounds ################
2023-03-25 18:34:06,644 : [INFO]  Batch 244: Training set : loss - 0.573, accuracy - 0.7011, recall - 0.8587, AUC - 0.8407, F1 - 0.7418, precision - 0.6529, training time - -12.0 seconds
2023-03-25 18:34:06,644 : [INFO]  Batch 244: Testing set : loss - 0.5747, accuracy - 0.7157, recall - 0.8627, AUC - 0.8559, F1 - 0.7521, precision - 0.6667
2023-03-25 18:34:06,657 : [INFO]  Batch 245 initialized 
2023-03-25 18:34:07,228 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:07,912 : [INFO]  ------------------------- Batch 245 training: round 1 -------------------------
2023-03-25 18:34:13,357 : [INFO]  ------------------------- Batch round 1, loss: 0.5923 -------------------------
2023-03-25 18:34:13,357 : [INFO]  ------------------------- Batch 245, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:13,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:13,378 : [INFO]  ------------------------- Batch 245 training: round 2 -------------------------
2023-03-25 18:34:16,318 : [INFO]  ------------------------- Batch round 2, loss: 0.6039 -------------------------
2023-03-25 18:34:16,318 : [INFO]  ------------------------- Batch 245, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:16,335 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:16,338 : [INFO]  ------------------------- Batch 245 training: round 3 -------------------------
2023-03-25 18:34:19,223 : [INFO]  ------------------------- Batch round 3, loss: 0.6082 -------------------------
2023-03-25 18:34:19,224 : [INFO]  ------------------------- Batch 245, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:19,239 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:19,242 : [INFO]  Batch number 245 model fetched from the server
2023-03-25 18:34:19,242 : [INFO]  ################ Batch 245: final global model evalution after 3 rounds ################
2023-03-25 18:34:21,052 : [INFO]  Batch 245: Training set : loss - 0.6057, accuracy - 0.6685, recall - 0.8587, AUC - 0.7865, F1 - 0.7215, precision - 0.622, training time - -11.0 seconds
2023-03-25 18:34:21,052 : [INFO]  Batch 245: Testing set : loss - 0.5984, accuracy - 0.6422, recall - 0.7745, AUC - 0.7961, F1 - 0.684, precision - 0.6124
2023-03-25 18:34:21,060 : [INFO]  Batch 246 initialized 
2023-03-25 18:34:21,610 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:22,280 : [INFO]  ------------------------- Batch 246 training: round 1 -------------------------
2023-03-25 18:34:27,700 : [INFO]  ------------------------- Batch round 1, loss: 0.5847 -------------------------
2023-03-25 18:34:27,700 : [INFO]  ------------------------- Batch 246, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:27,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:27,806 : [INFO]  ------------------------- Batch 246 training: round 2 -------------------------
2023-03-25 18:34:30,733 : [INFO]  ------------------------- Batch round 2, loss: 0.5859 -------------------------
2023-03-25 18:34:30,733 : [INFO]  ------------------------- Batch 246, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:30,853 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:30,857 : [INFO]  ------------------------- Batch 246 training: round 3 -------------------------
2023-03-25 18:34:33,861 : [INFO]  ------------------------- Batch round 3, loss: 0.5835 -------------------------
2023-03-25 18:34:33,862 : [INFO]  ------------------------- Batch 246, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:33,874 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:33,876 : [INFO]  Batch number 246 model fetched from the server
2023-03-25 18:34:33,877 : [INFO]  ################ Batch 246: final global model evalution after 3 rounds ################
2023-03-25 18:34:35,743 : [INFO]  Batch 246: Training set : loss - 0.5886, accuracy - 0.7174, recall - 0.8696, AUC - 0.8112, F1 - 0.7547, precision - 0.6667, training time - -12.0 seconds
2023-03-25 18:34:35,744 : [INFO]  Batch 246: Testing set : loss - 0.5805, accuracy - 0.7402, recall - 0.902, AUC - 0.8444, F1 - 0.7764, precision - 0.6815
2023-03-25 18:34:35,757 : [INFO]  Batch 247 initialized 
2023-03-25 18:34:36,342 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:37,039 : [INFO]  ------------------------- Batch 247 training: round 1 -------------------------
2023-03-25 18:34:42,630 : [INFO]  ------------------------- Batch round 1, loss: 0.5517 -------------------------
2023-03-25 18:34:42,630 : [INFO]  ------------------------- Batch 247, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:42,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:42,687 : [INFO]  ------------------------- Batch 247 training: round 2 -------------------------
2023-03-25 18:34:45,622 : [INFO]  ------------------------- Batch round 2, loss: 0.5472 -------------------------
2023-03-25 18:34:45,622 : [INFO]  ------------------------- Batch 247, round 2: Sent local model to the server -------------------------
2023-03-25 18:34:45,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:45,639 : [INFO]  ------------------------- Batch 247 training: round 3 -------------------------
2023-03-25 18:34:48,565 : [INFO]  ------------------------- Batch round 3, loss: 0.5485 -------------------------
2023-03-25 18:34:48,565 : [INFO]  ------------------------- Batch 247, round 3: Sent local model to the server -------------------------
2023-03-25 18:34:48,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:48,583 : [INFO]  Batch number 247 model fetched from the server
2023-03-25 18:34:48,583 : [INFO]  ################ Batch 247: final global model evalution after 3 rounds ################
2023-03-25 18:34:50,333 : [INFO]  Batch 247: Training set : loss - 0.557, accuracy - 0.7446, recall - 0.9457, AUC - 0.8967, F1 - 0.7873, precision - 0.6744, training time - -12.0 seconds
2023-03-25 18:34:50,333 : [INFO]  Batch 247: Testing set : loss - 0.5867, accuracy - 0.6961, recall - 0.8725, AUC - 0.8231, F1 - 0.7417, precision - 0.6449
2023-03-25 18:34:50,342 : [INFO]  Batch 248 initialized 
2023-03-25 18:34:50,901 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:34:51,622 : [INFO]  ------------------------- Batch 248 training: round 1 -------------------------
2023-03-25 18:34:57,016 : [INFO]  ------------------------- Batch round 1, loss: 0.5579 -------------------------
2023-03-25 18:34:57,016 : [INFO]  ------------------------- Batch 248, round 1: Sent local model to the server -------------------------
2023-03-25 18:34:57,035 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:34:57,038 : [INFO]  ------------------------- Batch 248 training: round 2 -------------------------
2023-03-25 18:35:00,155 : [INFO]  ------------------------- Batch round 2, loss: 0.56 -------------------------
2023-03-25 18:35:00,156 : [INFO]  ------------------------- Batch 248, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:00,176 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:00,180 : [INFO]  ------------------------- Batch 248 training: round 3 -------------------------
2023-03-25 18:35:03,219 : [INFO]  ------------------------- Batch round 3, loss: 0.5679 -------------------------
2023-03-25 18:35:03,219 : [INFO]  ------------------------- Batch 248, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:03,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:03,244 : [INFO]  Batch number 248 model fetched from the server
2023-03-25 18:35:03,244 : [INFO]  ################ Batch 248: final global model evalution after 3 rounds ################
2023-03-25 18:35:05,126 : [INFO]  Batch 248: Training set : loss - 0.5686, accuracy - 0.7446, recall - 0.9022, AUC - 0.8545, F1 - 0.7793, precision - 0.686, training time - -12.0 seconds
2023-03-25 18:35:05,126 : [INFO]  Batch 248: Testing set : loss - 0.6027, accuracy - 0.6667, recall - 0.8039, AUC - 0.7922, F1 - 0.7069, precision - 0.6308
2023-03-25 18:35:05,136 : [INFO]  Batch 249 initialized 
2023-03-25 18:35:05,713 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:06,428 : [INFO]  ------------------------- Batch 249 training: round 1 -------------------------
2023-03-25 18:35:12,113 : [INFO]  ------------------------- Batch round 1, loss: 0.5982 -------------------------
2023-03-25 18:35:12,113 : [INFO]  ------------------------- Batch 249, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:12,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:12,130 : [INFO]  ------------------------- Batch 249 training: round 2 -------------------------
2023-03-25 18:35:15,054 : [INFO]  ------------------------- Batch round 2, loss: 0.5943 -------------------------
2023-03-25 18:35:15,054 : [INFO]  ------------------------- Batch 249, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:15,102 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:15,104 : [INFO]  ------------------------- Batch 249 training: round 3 -------------------------
2023-03-25 18:35:18,014 : [INFO]  ------------------------- Batch round 3, loss: 0.5978 -------------------------
2023-03-25 18:35:18,015 : [INFO]  ------------------------- Batch 249, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:18,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:18,033 : [INFO]  Batch number 249 model fetched from the server
2023-03-25 18:35:18,033 : [INFO]  ################ Batch 249: final global model evalution after 3 rounds ################
2023-03-25 18:35:19,860 : [INFO]  Batch 249: Training set : loss - 0.605, accuracy - 0.6793, recall - 0.8696, AUC - 0.787, F1 - 0.7306, precision - 0.6299, training time - -12.0 seconds
2023-03-25 18:35:19,860 : [INFO]  Batch 249: Testing set : loss - 0.6007, accuracy - 0.6912, recall - 0.7941, AUC - 0.7831, F1 - 0.72, precision - 0.6585
2023-03-25 18:35:19,879 : [INFO]  Batch 250 initialized 
2023-03-25 18:35:20,451 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:21,159 : [INFO]  ------------------------- Batch 250 training: round 1 -------------------------
2023-03-25 18:35:26,526 : [INFO]  ------------------------- Batch round 1, loss: 0.5798 -------------------------
2023-03-25 18:35:26,526 : [INFO]  ------------------------- Batch 250, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:26,736 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:26,739 : [INFO]  ------------------------- Batch 250 training: round 2 -------------------------
2023-03-25 18:35:29,606 : [INFO]  ------------------------- Batch round 2, loss: 0.5813 -------------------------
2023-03-25 18:35:29,606 : [INFO]  ------------------------- Batch 250, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:29,819 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:29,822 : [INFO]  ------------------------- Batch 250 training: round 3 -------------------------
2023-03-25 18:35:32,642 : [INFO]  ------------------------- Batch round 3, loss: 0.5882 -------------------------
2023-03-25 18:35:32,642 : [INFO]  ------------------------- Batch 250, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:32,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:32,843 : [INFO]  Batch number 250 model fetched from the server
2023-03-25 18:35:32,843 : [INFO]  ################ Batch 250: final global model evalution after 3 rounds ################
2023-03-25 18:35:34,628 : [INFO]  Batch 250: Training set : loss - 0.589, accuracy - 0.6685, recall - 0.8804, AUC - 0.8222, F1 - 0.7265, precision - 0.6183, training time - -12.0 seconds
2023-03-25 18:35:34,628 : [INFO]  Batch 250: Testing set : loss - 0.573, accuracy - 0.7451, recall - 0.8824, AUC - 0.8499, F1 - 0.7759, precision - 0.6923
2023-03-25 18:35:34,641 : [INFO]  Batch 251 initialized 
2023-03-25 18:35:35,210 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:35,895 : [INFO]  ------------------------- Batch 251 training: round 1 -------------------------
2023-03-25 18:35:41,499 : [INFO]  ------------------------- Batch round 1, loss: 0.5941 -------------------------
2023-03-25 18:35:41,499 : [INFO]  ------------------------- Batch 251, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:41,529 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:41,532 : [INFO]  ------------------------- Batch 251 training: round 2 -------------------------
2023-03-25 18:35:44,546 : [INFO]  ------------------------- Batch round 2, loss: 0.5904 -------------------------
2023-03-25 18:35:44,546 : [INFO]  ------------------------- Batch 251, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:44,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:44,564 : [INFO]  ------------------------- Batch 251 training: round 3 -------------------------
2023-03-25 18:35:47,543 : [INFO]  ------------------------- Batch round 3, loss: 0.5906 -------------------------
2023-03-25 18:35:47,543 : [INFO]  ------------------------- Batch 251, round 3: Sent local model to the server -------------------------
2023-03-25 18:35:47,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:47,564 : [INFO]  Batch number 251 model fetched from the server
2023-03-25 18:35:47,564 : [INFO]  ################ Batch 251: final global model evalution after 3 rounds ################
2023-03-25 18:35:49,443 : [INFO]  Batch 251: Training set : loss - 0.6088, accuracy - 0.6685, recall - 0.8913, AUC - 0.7924, F1 - 0.7289, precision - 0.6165, training time - -12.0 seconds
2023-03-25 18:35:49,443 : [INFO]  Batch 251: Testing set : loss - 0.5684, accuracy - 0.6863, recall - 0.8627, AUC - 0.8648, F1 - 0.7333, precision - 0.6377
2023-03-25 18:35:49,457 : [INFO]  Batch 252 initialized 
2023-03-25 18:35:50,023 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:35:50,709 : [INFO]  ------------------------- Batch 252 training: round 1 -------------------------
2023-03-25 18:35:56,109 : [INFO]  ------------------------- Batch round 1, loss: 0.6026 -------------------------
2023-03-25 18:35:56,109 : [INFO]  ------------------------- Batch 252, round 1: Sent local model to the server -------------------------
2023-03-25 18:35:56,203 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:56,206 : [INFO]  ------------------------- Batch 252 training: round 2 -------------------------
2023-03-25 18:35:59,011 : [INFO]  ------------------------- Batch round 2, loss: 0.5981 -------------------------
2023-03-25 18:35:59,012 : [INFO]  ------------------------- Batch 252, round 2: Sent local model to the server -------------------------
2023-03-25 18:35:59,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:35:59,112 : [INFO]  ------------------------- Batch 252 training: round 3 -------------------------
2023-03-25 18:36:01,992 : [INFO]  ------------------------- Batch round 3, loss: 0.596 -------------------------
2023-03-25 18:36:01,992 : [INFO]  ------------------------- Batch 252, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:02,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:02,040 : [INFO]  Batch number 252 model fetched from the server
2023-03-25 18:36:02,040 : [INFO]  ################ Batch 252: final global model evalution after 3 rounds ################
2023-03-25 18:36:03,788 : [INFO]  Batch 252: Training set : loss - 0.6087, accuracy - 0.6739, recall - 0.837, AUC - 0.7691, F1 - 0.7196, precision - 0.6311, training time - -11.0 seconds
2023-03-25 18:36:03,789 : [INFO]  Batch 252: Testing set : loss - 0.5901, accuracy - 0.7108, recall - 0.8529, AUC - 0.817, F1 - 0.7468, precision - 0.6641
2023-03-25 18:36:03,804 : [INFO]  Batch 253 initialized 
2023-03-25 18:36:04,382 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:05,080 : [INFO]  ------------------------- Batch 253 training: round 1 -------------------------
2023-03-25 18:36:10,629 : [INFO]  ------------------------- Batch round 1, loss: 0.5903 -------------------------
2023-03-25 18:36:10,629 : [INFO]  ------------------------- Batch 253, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:10,644 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:10,647 : [INFO]  ------------------------- Batch 253 training: round 2 -------------------------
2023-03-25 18:36:13,683 : [INFO]  ------------------------- Batch round 2, loss: 0.5924 -------------------------
2023-03-25 18:36:13,684 : [INFO]  ------------------------- Batch 253, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:13,713 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:13,715 : [INFO]  ------------------------- Batch 253 training: round 3 -------------------------
2023-03-25 18:36:16,643 : [INFO]  ------------------------- Batch round 3, loss: 0.5925 -------------------------
2023-03-25 18:36:16,643 : [INFO]  ------------------------- Batch 253, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:16,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:16,661 : [INFO]  Batch number 253 model fetched from the server
2023-03-25 18:36:16,662 : [INFO]  ################ Batch 253: final global model evalution after 3 rounds ################
2023-03-25 18:36:18,455 : [INFO]  Batch 253: Training set : loss - 0.6118, accuracy - 0.6522, recall - 0.837, AUC - 0.7863, F1 - 0.7064, precision - 0.6111, training time - -12.0 seconds
2023-03-25 18:36:18,455 : [INFO]  Batch 253: Testing set : loss - 0.592, accuracy - 0.6863, recall - 0.8824, AUC - 0.8408, F1 - 0.7377, precision - 0.6338
2023-03-25 18:36:18,475 : [INFO]  Batch 254 initialized 
2023-03-25 18:36:19,041 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:19,764 : [INFO]  ------------------------- Batch 254 training: round 1 -------------------------
2023-03-25 18:36:25,300 : [INFO]  ------------------------- Batch round 1, loss: 0.572 -------------------------
2023-03-25 18:36:25,301 : [INFO]  ------------------------- Batch 254, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:25,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:25,448 : [INFO]  ------------------------- Batch 254 training: round 2 -------------------------
2023-03-25 18:36:28,314 : [INFO]  ------------------------- Batch round 2, loss: 0.5718 -------------------------
2023-03-25 18:36:28,314 : [INFO]  ------------------------- Batch 254, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:28,450 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:28,453 : [INFO]  ------------------------- Batch 254 training: round 3 -------------------------
2023-03-25 18:36:31,441 : [INFO]  ------------------------- Batch round 3, loss: 0.5731 -------------------------
2023-03-25 18:36:31,441 : [INFO]  ------------------------- Batch 254, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:31,490 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:31,493 : [INFO]  Batch number 254 model fetched from the server
2023-03-25 18:36:31,493 : [INFO]  ################ Batch 254: final global model evalution after 3 rounds ################
2023-03-25 18:36:33,304 : [INFO]  Batch 254: Training set : loss - 0.5772, accuracy - 0.7174, recall - 0.8696, AUC - 0.8402, F1 - 0.7547, precision - 0.6667, training time - -12.0 seconds
2023-03-25 18:36:33,304 : [INFO]  Batch 254: Testing set : loss - 0.5938, accuracy - 0.7059, recall - 0.8627, AUC - 0.8152, F1 - 0.7458, precision - 0.6567
2023-03-25 18:36:33,311 : [INFO]  Batch 255 initialized 
2023-03-25 18:36:33,868 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:34,571 : [INFO]  ------------------------- Batch 255 training: round 1 -------------------------
2023-03-25 18:36:40,299 : [INFO]  ------------------------- Batch round 1, loss: 0.5779 -------------------------
2023-03-25 18:36:40,300 : [INFO]  ------------------------- Batch 255, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:40,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:40,325 : [INFO]  ------------------------- Batch 255 training: round 2 -------------------------
2023-03-25 18:36:43,266 : [INFO]  ------------------------- Batch round 2, loss: 0.5808 -------------------------
2023-03-25 18:36:43,266 : [INFO]  ------------------------- Batch 255, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:43,281 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:43,284 : [INFO]  ------------------------- Batch 255 training: round 3 -------------------------
2023-03-25 18:36:46,255 : [INFO]  ------------------------- Batch round 3, loss: 0.5828 -------------------------
2023-03-25 18:36:46,255 : [INFO]  ------------------------- Batch 255, round 3: Sent local model to the server -------------------------
2023-03-25 18:36:46,271 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:46,274 : [INFO]  Batch number 255 model fetched from the server
2023-03-25 18:36:46,274 : [INFO]  ################ Batch 255: final global model evalution after 3 rounds ################
2023-03-25 18:36:48,079 : [INFO]  Batch 255: Training set : loss - 0.5978, accuracy - 0.6957, recall - 0.8913, AUC - 0.8007, F1 - 0.7455, precision - 0.6406, training time - -12.0 seconds
2023-03-25 18:36:48,080 : [INFO]  Batch 255: Testing set : loss - 0.5787, accuracy - 0.6716, recall - 0.8922, AUC - 0.8437, F1 - 0.7309, precision - 0.619
2023-03-25 18:36:48,094 : [INFO]  Batch 256 initialized 
2023-03-25 18:36:48,664 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:36:49,395 : [INFO]  ------------------------- Batch 256 training: round 1 -------------------------
2023-03-25 18:36:54,960 : [INFO]  ------------------------- Batch round 1, loss: 0.5629 -------------------------
2023-03-25 18:36:54,961 : [INFO]  ------------------------- Batch 256, round 1: Sent local model to the server -------------------------
2023-03-25 18:36:54,978 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:54,980 : [INFO]  ------------------------- Batch 256 training: round 2 -------------------------
2023-03-25 18:36:57,943 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 18:36:57,943 : [INFO]  ------------------------- Batch 256, round 2: Sent local model to the server -------------------------
2023-03-25 18:36:57,957 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:36:57,960 : [INFO]  ------------------------- Batch 256 training: round 3 -------------------------
2023-03-25 18:37:00,868 : [INFO]  ------------------------- Batch round 3, loss: 0.5668 -------------------------
2023-03-25 18:37:00,868 : [INFO]  ------------------------- Batch 256, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:00,882 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:00,885 : [INFO]  Batch number 256 model fetched from the server
2023-03-25 18:37:00,885 : [INFO]  ################ Batch 256: final global model evalution after 3 rounds ################
2023-03-25 18:37:02,685 : [INFO]  Batch 256: Training set : loss - 0.5713, accuracy - 0.7609, recall - 0.8478, AUC - 0.8213, F1 - 0.78, precision - 0.7222, training time - -11.0 seconds
2023-03-25 18:37:02,686 : [INFO]  Batch 256: Testing set : loss - 0.5517, accuracy - 0.7647, recall - 0.9314, AUC - 0.8937, F1 - 0.7983, precision - 0.6985
2023-03-25 18:37:02,698 : [INFO]  Batch 257 initialized 
2023-03-25 18:37:03,256 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:03,970 : [INFO]  ------------------------- Batch 257 training: round 1 -------------------------
2023-03-25 18:37:09,305 : [INFO]  ------------------------- Batch round 1, loss: 0.571 -------------------------
2023-03-25 18:37:09,305 : [INFO]  ------------------------- Batch 257, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:09,375 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:09,379 : [INFO]  ------------------------- Batch 257 training: round 2 -------------------------
2023-03-25 18:37:12,301 : [INFO]  ------------------------- Batch round 2, loss: 0.5718 -------------------------
2023-03-25 18:37:12,301 : [INFO]  ------------------------- Batch 257, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:12,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:12,323 : [INFO]  ------------------------- Batch 257 training: round 3 -------------------------
2023-03-25 18:37:15,195 : [INFO]  ------------------------- Batch round 3, loss: 0.5692 -------------------------
2023-03-25 18:37:15,195 : [INFO]  ------------------------- Batch 257, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:15,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:15,216 : [INFO]  Batch number 257 model fetched from the server
2023-03-25 18:37:15,216 : [INFO]  ################ Batch 257: final global model evalution after 3 rounds ################
2023-03-25 18:37:17,069 : [INFO]  Batch 257: Training set : loss - 0.5809, accuracy - 0.6957, recall - 0.837, AUC - 0.8283, F1 - 0.7333, precision - 0.6525, training time - -11.0 seconds
2023-03-25 18:37:17,069 : [INFO]  Batch 257: Testing set : loss - 0.603, accuracy - 0.6667, recall - 0.8824, AUC - 0.8203, F1 - 0.7258, precision - 0.6164
2023-03-25 18:37:17,116 : [INFO]  Batch 258 initialized 
2023-03-25 18:37:17,696 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:18,421 : [INFO]  ------------------------- Batch 258 training: round 1 -------------------------
2023-03-25 18:37:24,004 : [INFO]  ------------------------- Batch round 1, loss: 0.6373 -------------------------
2023-03-25 18:37:24,004 : [INFO]  ------------------------- Batch 258, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:24,152 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:24,156 : [INFO]  ------------------------- Batch 258 training: round 2 -------------------------
2023-03-25 18:37:27,142 : [INFO]  ------------------------- Batch round 2, loss: 0.6351 -------------------------
2023-03-25 18:37:27,142 : [INFO]  ------------------------- Batch 258, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:27,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:27,163 : [INFO]  ------------------------- Batch 258 training: round 3 -------------------------
2023-03-25 18:37:30,028 : [INFO]  ------------------------- Batch round 3, loss: 0.6405 -------------------------
2023-03-25 18:37:30,028 : [INFO]  ------------------------- Batch 258, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:30,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:30,051 : [INFO]  Batch number 258 model fetched from the server
2023-03-25 18:37:30,051 : [INFO]  ################ Batch 258: final global model evalution after 3 rounds ################
2023-03-25 18:37:31,892 : [INFO]  Batch 258: Training set : loss - 0.645, accuracy - 0.6304, recall - 0.7609, AUC - 0.7012, F1 - 0.6731, precision - 0.6034, training time - -12.0 seconds
2023-03-25 18:37:31,893 : [INFO]  Batch 258: Testing set : loss - 0.5917, accuracy - 0.6863, recall - 0.8529, AUC - 0.8005, F1 - 0.7311, precision - 0.6397
2023-03-25 18:37:31,900 : [INFO]  Batch 259 initialized 
2023-03-25 18:37:32,525 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:33,233 : [INFO]  ------------------------- Batch 259 training: round 1 -------------------------
2023-03-25 18:37:38,660 : [INFO]  ------------------------- Batch round 1, loss: 0.6108 -------------------------
2023-03-25 18:37:38,660 : [INFO]  ------------------------- Batch 259, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:38,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:38,738 : [INFO]  ------------------------- Batch 259 training: round 2 -------------------------
2023-03-25 18:37:41,660 : [INFO]  ------------------------- Batch round 2, loss: 0.6049 -------------------------
2023-03-25 18:37:41,660 : [INFO]  ------------------------- Batch 259, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:41,805 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:41,807 : [INFO]  ------------------------- Batch 259 training: round 3 -------------------------
2023-03-25 18:37:44,661 : [INFO]  ------------------------- Batch round 3, loss: 0.6133 -------------------------
2023-03-25 18:37:44,662 : [INFO]  ------------------------- Batch 259, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:44,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:44,733 : [INFO]  Batch number 259 model fetched from the server
2023-03-25 18:37:44,734 : [INFO]  ################ Batch 259: final global model evalution after 3 rounds ################
2023-03-25 18:37:46,527 : [INFO]  Batch 259: Training set : loss - 0.6183, accuracy - 0.625, recall - 0.7826, AUC - 0.7545, F1 - 0.6761, precision - 0.595, training time - -12.0 seconds
2023-03-25 18:37:46,527 : [INFO]  Batch 259: Testing set : loss - 0.639, accuracy - 0.6078, recall - 0.8137, AUC - 0.7361, F1 - 0.6748, precision - 0.5764
2023-03-25 18:37:46,542 : [INFO]  Batch 260 initialized 
2023-03-25 18:37:47,105 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:37:47,848 : [INFO]  ------------------------- Batch 260 training: round 1 -------------------------
2023-03-25 18:37:53,199 : [INFO]  ------------------------- Batch round 1, loss: 0.5879 -------------------------
2023-03-25 18:37:53,199 : [INFO]  ------------------------- Batch 260, round 1: Sent local model to the server -------------------------
2023-03-25 18:37:53,220 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:53,225 : [INFO]  ------------------------- Batch 260 training: round 2 -------------------------
2023-03-25 18:37:56,130 : [INFO]  ------------------------- Batch round 2, loss: 0.5829 -------------------------
2023-03-25 18:37:56,130 : [INFO]  ------------------------- Batch 260, round 2: Sent local model to the server -------------------------
2023-03-25 18:37:56,252 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:56,255 : [INFO]  ------------------------- Batch 260 training: round 3 -------------------------
2023-03-25 18:37:59,107 : [INFO]  ------------------------- Batch round 3, loss: 0.5881 -------------------------
2023-03-25 18:37:59,108 : [INFO]  ------------------------- Batch 260, round 3: Sent local model to the server -------------------------
2023-03-25 18:37:59,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:37:59,125 : [INFO]  Batch number 260 model fetched from the server
2023-03-25 18:37:59,125 : [INFO]  ################ Batch 260: final global model evalution after 3 rounds ################
2023-03-25 18:38:00,888 : [INFO]  Batch 260: Training set : loss - 0.59, accuracy - 0.7011, recall - 0.8261, AUC - 0.8051, F1 - 0.7343, precision - 0.6609, training time - -11.0 seconds
2023-03-25 18:38:00,888 : [INFO]  Batch 260: Testing set : loss - 0.5883, accuracy - 0.7059, recall - 0.8824, AUC - 0.8108, F1 - 0.75, precision - 0.6522
2023-03-25 18:38:00,903 : [INFO]  Batch 261 initialized 
2023-03-25 18:38:01,470 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:02,180 : [INFO]  ------------------------- Batch 261 training: round 1 -------------------------
2023-03-25 18:38:07,570 : [INFO]  ------------------------- Batch round 1, loss: 0.599 -------------------------
2023-03-25 18:38:07,570 : [INFO]  ------------------------- Batch 261, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:07,627 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:07,630 : [INFO]  ------------------------- Batch 261 training: round 2 -------------------------
2023-03-25 18:38:10,466 : [INFO]  ------------------------- Batch round 2, loss: 0.5947 -------------------------
2023-03-25 18:38:10,466 : [INFO]  ------------------------- Batch 261, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:10,488 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:10,490 : [INFO]  ------------------------- Batch 261 training: round 3 -------------------------
2023-03-25 18:38:13,325 : [INFO]  ------------------------- Batch round 3, loss: 0.592 -------------------------
2023-03-25 18:38:13,325 : [INFO]  ------------------------- Batch 261, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:13,478 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:13,486 : [INFO]  Batch number 261 model fetched from the server
2023-03-25 18:38:13,486 : [INFO]  ################ Batch 261: final global model evalution after 3 rounds ################
2023-03-25 18:38:15,274 : [INFO]  Batch 261: Training set : loss - 0.6095, accuracy - 0.6685, recall - 0.837, AUC - 0.7926, F1 - 0.7163, precision - 0.626, training time - -11.0 seconds
2023-03-25 18:38:15,274 : [INFO]  Batch 261: Testing set : loss - 0.5746, accuracy - 0.7059, recall - 0.9118, AUC - 0.875, F1 - 0.7561, precision - 0.6458
2023-03-25 18:38:15,289 : [INFO]  Batch 262 initialized 
2023-03-25 18:38:15,889 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:16,591 : [INFO]  ------------------------- Batch 262 training: round 1 -------------------------
2023-03-25 18:38:21,935 : [INFO]  ------------------------- Batch round 1, loss: 0.626 -------------------------
2023-03-25 18:38:21,935 : [INFO]  ------------------------- Batch 262, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:21,960 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:21,963 : [INFO]  ------------------------- Batch 262 training: round 2 -------------------------
2023-03-25 18:38:24,811 : [INFO]  ------------------------- Batch round 2, loss: 0.624 -------------------------
2023-03-25 18:38:24,812 : [INFO]  ------------------------- Batch 262, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:24,825 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:24,828 : [INFO]  ------------------------- Batch 262 training: round 3 -------------------------
2023-03-25 18:38:27,751 : [INFO]  ------------------------- Batch round 3, loss: 0.6268 -------------------------
2023-03-25 18:38:27,752 : [INFO]  ------------------------- Batch 262, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:27,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:27,777 : [INFO]  Batch number 262 model fetched from the server
2023-03-25 18:38:27,777 : [INFO]  ################ Batch 262: final global model evalution after 3 rounds ################
2023-03-25 18:38:29,581 : [INFO]  Batch 262: Training set : loss - 0.6395, accuracy - 0.6522, recall - 0.7717, AUC - 0.6972, F1 - 0.6893, precision - 0.6228, training time - -11.0 seconds
2023-03-25 18:38:29,582 : [INFO]  Batch 262: Testing set : loss - 0.5962, accuracy - 0.6912, recall - 0.7941, AUC - 0.7823, F1 - 0.72, precision - 0.6585
2023-03-25 18:38:29,591 : [INFO]  Batch 263 initialized 
2023-03-25 18:38:30,170 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:30,909 : [INFO]  ------------------------- Batch 263 training: round 1 -------------------------
2023-03-25 18:38:36,419 : [INFO]  ------------------------- Batch round 1, loss: 0.5834 -------------------------
2023-03-25 18:38:36,419 : [INFO]  ------------------------- Batch 263, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:36,433 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:36,436 : [INFO]  ------------------------- Batch 263 training: round 2 -------------------------
2023-03-25 18:38:39,407 : [INFO]  ------------------------- Batch round 2, loss: 0.5879 -------------------------
2023-03-25 18:38:39,407 : [INFO]  ------------------------- Batch 263, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:39,419 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:39,422 : [INFO]  ------------------------- Batch 263 training: round 3 -------------------------
2023-03-25 18:38:42,375 : [INFO]  ------------------------- Batch round 3, loss: 0.5809 -------------------------
2023-03-25 18:38:42,375 : [INFO]  ------------------------- Batch 263, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:42,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:42,391 : [INFO]  Batch number 263 model fetched from the server
2023-03-25 18:38:42,391 : [INFO]  ################ Batch 263: final global model evalution after 3 rounds ################
2023-03-25 18:38:44,259 : [INFO]  Batch 263: Training set : loss - 0.5961, accuracy - 0.6902, recall - 0.8261, AUC - 0.7953, F1 - 0.7273, precision - 0.6496, training time - -11.0 seconds
2023-03-25 18:38:44,260 : [INFO]  Batch 263: Testing set : loss - 0.6225, accuracy - 0.6471, recall - 0.7843, AUC - 0.7463, F1 - 0.6897, precision - 0.6154
2023-03-25 18:38:44,271 : [INFO]  Batch 264 initialized 
2023-03-25 18:38:44,837 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:38:45,566 : [INFO]  ------------------------- Batch 264 training: round 1 -------------------------
2023-03-25 18:38:51,074 : [INFO]  ------------------------- Batch round 1, loss: 0.5809 -------------------------
2023-03-25 18:38:51,074 : [INFO]  ------------------------- Batch 264, round 1: Sent local model to the server -------------------------
2023-03-25 18:38:51,088 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:51,091 : [INFO]  ------------------------- Batch 264 training: round 2 -------------------------
2023-03-25 18:38:54,026 : [INFO]  ------------------------- Batch round 2, loss: 0.5859 -------------------------
2023-03-25 18:38:54,026 : [INFO]  ------------------------- Batch 264, round 2: Sent local model to the server -------------------------
2023-03-25 18:38:54,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:54,046 : [INFO]  ------------------------- Batch 264 training: round 3 -------------------------
2023-03-25 18:38:56,932 : [INFO]  ------------------------- Batch round 3, loss: 0.5842 -------------------------
2023-03-25 18:38:56,932 : [INFO]  ------------------------- Batch 264, round 3: Sent local model to the server -------------------------
2023-03-25 18:38:57,077 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:38:57,080 : [INFO]  Batch number 264 model fetched from the server
2023-03-25 18:38:57,080 : [INFO]  ################ Batch 264: final global model evalution after 3 rounds ################
2023-03-25 18:38:58,994 : [INFO]  Batch 264: Training set : loss - 0.5944, accuracy - 0.6902, recall - 0.8478, AUC - 0.8021, F1 - 0.7324, precision - 0.6446, training time - -12.0 seconds
2023-03-25 18:38:58,994 : [INFO]  Batch 264: Testing set : loss - 0.6129, accuracy - 0.6471, recall - 0.7647, AUC - 0.7589, F1 - 0.6842, precision - 0.619
2023-03-25 18:38:59,006 : [INFO]  Batch 265 initialized 
2023-03-25 18:38:59,612 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:00,339 : [INFO]  ------------------------- Batch 265 training: round 1 -------------------------
2023-03-25 18:39:05,950 : [INFO]  ------------------------- Batch round 1, loss: 0.5929 -------------------------
2023-03-25 18:39:05,951 : [INFO]  ------------------------- Batch 265, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:05,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:05,970 : [INFO]  ------------------------- Batch 265 training: round 2 -------------------------
2023-03-25 18:39:08,928 : [INFO]  ------------------------- Batch round 2, loss: 0.5929 -------------------------
2023-03-25 18:39:08,928 : [INFO]  ------------------------- Batch 265, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:08,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:08,946 : [INFO]  ------------------------- Batch 265 training: round 3 -------------------------
2023-03-25 18:39:11,839 : [INFO]  ------------------------- Batch round 3, loss: 0.5934 -------------------------
2023-03-25 18:39:11,840 : [INFO]  ------------------------- Batch 265, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:11,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:11,864 : [INFO]  Batch number 265 model fetched from the server
2023-03-25 18:39:11,864 : [INFO]  ################ Batch 265: final global model evalution after 3 rounds ################
2023-03-25 18:39:13,648 : [INFO]  Batch 265: Training set : loss - 0.6087, accuracy - 0.6902, recall - 0.8043, AUC - 0.7618, F1 - 0.722, precision - 0.6549, training time - -12.0 seconds
2023-03-25 18:39:13,648 : [INFO]  Batch 265: Testing set : loss - 0.5613, accuracy - 0.7353, recall - 0.8529, AUC - 0.8522, F1 - 0.7632, precision - 0.6905
2023-03-25 18:39:13,658 : [INFO]  Batch 266 initialized 
2023-03-25 18:39:14,220 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:14,963 : [INFO]  ------------------------- Batch 266 training: round 1 -------------------------
2023-03-25 18:39:20,373 : [INFO]  ------------------------- Batch round 1, loss: 0.5888 -------------------------
2023-03-25 18:39:20,373 : [INFO]  ------------------------- Batch 266, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:20,451 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:20,454 : [INFO]  ------------------------- Batch 266 training: round 2 -------------------------
2023-03-25 18:39:23,348 : [INFO]  ------------------------- Batch round 2, loss: 0.589 -------------------------
2023-03-25 18:39:23,348 : [INFO]  ------------------------- Batch 266, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:23,420 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:23,423 : [INFO]  ------------------------- Batch 266 training: round 3 -------------------------
2023-03-25 18:39:26,305 : [INFO]  ------------------------- Batch round 3, loss: 0.5881 -------------------------
2023-03-25 18:39:26,305 : [INFO]  ------------------------- Batch 266, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:26,368 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:26,371 : [INFO]  Batch number 266 model fetched from the server
2023-03-25 18:39:26,371 : [INFO]  ################ Batch 266: final global model evalution after 3 rounds ################
2023-03-25 18:39:28,151 : [INFO]  Batch 266: Training set : loss - 0.6001, accuracy - 0.6739, recall - 0.7935, AUC - 0.7903, F1 - 0.7087, precision - 0.6404, training time - -11.0 seconds
2023-03-25 18:39:28,151 : [INFO]  Batch 266: Testing set : loss - 0.6271, accuracy - 0.6078, recall - 0.7745, AUC - 0.7436, F1 - 0.6639, precision - 0.5809
2023-03-25 18:39:28,186 : [INFO]  Batch 267 initialized 
2023-03-25 18:39:28,790 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:29,526 : [INFO]  ------------------------- Batch 267 training: round 1 -------------------------
2023-03-25 18:39:34,859 : [INFO]  ------------------------- Batch round 1, loss: 0.6178 -------------------------
2023-03-25 18:39:34,859 : [INFO]  ------------------------- Batch 267, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:35,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:35,007 : [INFO]  ------------------------- Batch 267 training: round 2 -------------------------
2023-03-25 18:39:37,880 : [INFO]  ------------------------- Batch round 2, loss: 0.6143 -------------------------
2023-03-25 18:39:37,881 : [INFO]  ------------------------- Batch 267, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:38,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:38,039 : [INFO]  ------------------------- Batch 267 training: round 3 -------------------------
2023-03-25 18:39:40,806 : [INFO]  ------------------------- Batch round 3, loss: 0.6098 -------------------------
2023-03-25 18:39:40,806 : [INFO]  ------------------------- Batch 267, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:40,989 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:40,992 : [INFO]  Batch number 267 model fetched from the server
2023-03-25 18:39:40,992 : [INFO]  ################ Batch 267: final global model evalution after 3 rounds ################
2023-03-25 18:39:42,783 : [INFO]  Batch 267: Training set : loss - 0.6176, accuracy - 0.625, recall - 0.7174, AUC - 0.7293, F1 - 0.6567, precision - 0.6055, training time - -11.0 seconds
2023-03-25 18:39:42,784 : [INFO]  Batch 267: Testing set : loss - 0.6088, accuracy - 0.6667, recall - 0.8333, AUC - 0.7844, F1 - 0.7143, precision - 0.625
2023-03-25 18:39:42,798 : [INFO]  Batch 268 initialized 
2023-03-25 18:39:43,378 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:44,099 : [INFO]  ------------------------- Batch 268 training: round 1 -------------------------
2023-03-25 18:39:49,509 : [INFO]  ------------------------- Batch round 1, loss: 0.5739 -------------------------
2023-03-25 18:39:49,509 : [INFO]  ------------------------- Batch 268, round 1: Sent local model to the server -------------------------
2023-03-25 18:39:49,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:49,753 : [INFO]  ------------------------- Batch 268 training: round 2 -------------------------
2023-03-25 18:39:52,568 : [INFO]  ------------------------- Batch round 2, loss: 0.5778 -------------------------
2023-03-25 18:39:52,569 : [INFO]  ------------------------- Batch 268, round 2: Sent local model to the server -------------------------
2023-03-25 18:39:52,748 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:52,751 : [INFO]  ------------------------- Batch 268 training: round 3 -------------------------
2023-03-25 18:39:55,732 : [INFO]  ------------------------- Batch round 3, loss: 0.5724 -------------------------
2023-03-25 18:39:55,732 : [INFO]  ------------------------- Batch 268, round 3: Sent local model to the server -------------------------
2023-03-25 18:39:55,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:39:55,749 : [INFO]  Batch number 268 model fetched from the server
2023-03-25 18:39:55,750 : [INFO]  ################ Batch 268: final global model evalution after 3 rounds ################
2023-03-25 18:39:57,525 : [INFO]  Batch 268: Training set : loss - 0.5894, accuracy - 0.7065, recall - 0.8478, AUC - 0.8107, F1 - 0.7429, precision - 0.661, training time - -12.0 seconds
2023-03-25 18:39:57,525 : [INFO]  Batch 268: Testing set : loss - 0.6463, accuracy - 0.5931, recall - 0.6863, AUC - 0.6814, F1 - 0.6278, precision - 0.5785
2023-03-25 18:39:57,534 : [INFO]  Batch 269 initialized 
2023-03-25 18:39:58,110 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:39:58,830 : [INFO]  ------------------------- Batch 269 training: round 1 -------------------------
2023-03-25 18:40:04,182 : [INFO]  ------------------------- Batch round 1, loss: 0.5829 -------------------------
2023-03-25 18:40:04,182 : [INFO]  ------------------------- Batch 269, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:04,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:04,271 : [INFO]  ------------------------- Batch 269 training: round 2 -------------------------
2023-03-25 18:40:07,127 : [INFO]  ------------------------- Batch round 2, loss: 0.5836 -------------------------
2023-03-25 18:40:07,127 : [INFO]  ------------------------- Batch 269, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:07,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:07,256 : [INFO]  ------------------------- Batch 269 training: round 3 -------------------------
2023-03-25 18:40:10,052 : [INFO]  ------------------------- Batch round 3, loss: 0.5855 -------------------------
2023-03-25 18:40:10,052 : [INFO]  ------------------------- Batch 269, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:10,206 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:10,209 : [INFO]  Batch number 269 model fetched from the server
2023-03-25 18:40:10,209 : [INFO]  ################ Batch 269: final global model evalution after 3 rounds ################
2023-03-25 18:40:12,055 : [INFO]  Batch 269: Training set : loss - 0.5994, accuracy - 0.6739, recall - 0.8587, AUC - 0.8026, F1 - 0.7248, precision - 0.627, training time - -11.0 seconds
2023-03-25 18:40:12,055 : [INFO]  Batch 269: Testing set : loss - 0.6005, accuracy - 0.6716, recall - 0.8824, AUC - 0.8174, F1 - 0.7287, precision - 0.6207
2023-03-25 18:40:12,070 : [INFO]  Batch 270 initialized 
2023-03-25 18:40:12,652 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:13,386 : [INFO]  ------------------------- Batch 270 training: round 1 -------------------------
2023-03-25 18:40:18,852 : [INFO]  ------------------------- Batch round 1, loss: 0.5867 -------------------------
2023-03-25 18:40:18,853 : [INFO]  ------------------------- Batch 270, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:18,986 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:18,990 : [INFO]  ------------------------- Batch 270 training: round 2 -------------------------
2023-03-25 18:40:21,872 : [INFO]  ------------------------- Batch round 2, loss: 0.5856 -------------------------
2023-03-25 18:40:21,872 : [INFO]  ------------------------- Batch 270, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:21,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:21,943 : [INFO]  ------------------------- Batch 270 training: round 3 -------------------------
2023-03-25 18:40:24,822 : [INFO]  ------------------------- Batch round 3, loss: 0.5829 -------------------------
2023-03-25 18:40:24,822 : [INFO]  ------------------------- Batch 270, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:24,895 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:24,898 : [INFO]  Batch number 270 model fetched from the server
2023-03-25 18:40:24,898 : [INFO]  ################ Batch 270: final global model evalution after 3 rounds ################
2023-03-25 18:40:26,765 : [INFO]  Batch 270: Training set : loss - 0.5908, accuracy - 0.712, recall - 0.8478, AUC - 0.8094, F1 - 0.7464, precision - 0.6667, training time - -12.0 seconds
2023-03-25 18:40:26,765 : [INFO]  Batch 270: Testing set : loss - 0.6279, accuracy - 0.6225, recall - 0.7745, AUC - 0.7398, F1 - 0.6723, precision - 0.594
2023-03-25 18:40:26,780 : [INFO]  Batch 271 initialized 
2023-03-25 18:40:27,359 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:28,099 : [INFO]  ------------------------- Batch 271 training: round 1 -------------------------
2023-03-25 18:40:33,719 : [INFO]  ------------------------- Batch round 1, loss: 0.6115 -------------------------
2023-03-25 18:40:33,719 : [INFO]  ------------------------- Batch 271, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:33,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:33,738 : [INFO]  ------------------------- Batch 271 training: round 2 -------------------------
2023-03-25 18:40:36,675 : [INFO]  ------------------------- Batch round 2, loss: 0.6156 -------------------------
2023-03-25 18:40:36,675 : [INFO]  ------------------------- Batch 271, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:36,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:36,696 : [INFO]  ------------------------- Batch 271 training: round 3 -------------------------
2023-03-25 18:40:39,762 : [INFO]  ------------------------- Batch round 3, loss: 0.6083 -------------------------
2023-03-25 18:40:39,763 : [INFO]  ------------------------- Batch 271, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:39,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:39,796 : [INFO]  Batch number 271 model fetched from the server
2023-03-25 18:40:39,796 : [INFO]  ################ Batch 271: final global model evalution after 3 rounds ################
2023-03-25 18:40:41,693 : [INFO]  Batch 271: Training set : loss - 0.632, accuracy - 0.6359, recall - 0.8478, AUC - 0.7485, F1 - 0.6996, precision - 0.5954, training time - -12.0 seconds
2023-03-25 18:40:41,694 : [INFO]  Batch 271: Testing set : loss - 0.6001, accuracy - 0.6863, recall - 0.8039, AUC - 0.7847, F1 - 0.7193, precision - 0.6508
2023-03-25 18:40:41,707 : [INFO]  Batch 272 initialized 
2023-03-25 18:40:42,323 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:43,071 : [INFO]  ------------------------- Batch 272 training: round 1 -------------------------
2023-03-25 18:40:48,563 : [INFO]  ------------------------- Batch round 1, loss: 0.5673 -------------------------
2023-03-25 18:40:48,563 : [INFO]  ------------------------- Batch 272, round 1: Sent local model to the server -------------------------
2023-03-25 18:40:48,725 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:48,727 : [INFO]  ------------------------- Batch 272 training: round 2 -------------------------
2023-03-25 18:40:51,551 : [INFO]  ------------------------- Batch round 2, loss: 0.5612 -------------------------
2023-03-25 18:40:51,551 : [INFO]  ------------------------- Batch 272, round 2: Sent local model to the server -------------------------
2023-03-25 18:40:51,735 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:51,738 : [INFO]  ------------------------- Batch 272 training: round 3 -------------------------
2023-03-25 18:40:54,564 : [INFO]  ------------------------- Batch round 3, loss: 0.5673 -------------------------
2023-03-25 18:40:54,565 : [INFO]  ------------------------- Batch 272, round 3: Sent local model to the server -------------------------
2023-03-25 18:40:54,801 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:40:54,806 : [INFO]  Batch number 272 model fetched from the server
2023-03-25 18:40:54,806 : [INFO]  ################ Batch 272: final global model evalution after 3 rounds ################
2023-03-25 18:40:56,535 : [INFO]  Batch 272: Training set : loss - 0.5781, accuracy - 0.7283, recall - 0.8043, AUC - 0.8023, F1 - 0.7475, precision - 0.6981, training time - -12.0 seconds
2023-03-25 18:40:56,535 : [INFO]  Batch 272: Testing set : loss - 0.5741, accuracy - 0.75, recall - 0.8235, AUC - 0.8153, F1 - 0.7671, precision - 0.7179
2023-03-25 18:40:56,550 : [INFO]  Batch 273 initialized 
2023-03-25 18:40:57,127 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:40:57,858 : [INFO]  ------------------------- Batch 273 training: round 1 -------------------------
2023-03-25 18:41:03,435 : [INFO]  ------------------------- Batch round 1, loss: 0.5814 -------------------------
2023-03-25 18:41:03,435 : [INFO]  ------------------------- Batch 273, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:03,453 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:03,456 : [INFO]  ------------------------- Batch 273 training: round 2 -------------------------
2023-03-25 18:41:06,250 : [INFO]  ------------------------- Batch round 2, loss: 0.5834 -------------------------
2023-03-25 18:41:06,250 : [INFO]  ------------------------- Batch 273, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:06,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:06,291 : [INFO]  ------------------------- Batch 273 training: round 3 -------------------------
2023-03-25 18:41:09,198 : [INFO]  ------------------------- Batch round 3, loss: 0.5846 -------------------------
2023-03-25 18:41:09,198 : [INFO]  ------------------------- Batch 273, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:09,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:09,220 : [INFO]  Batch number 273 model fetched from the server
2023-03-25 18:41:09,220 : [INFO]  ################ Batch 273: final global model evalution after 3 rounds ################
2023-03-25 18:41:10,985 : [INFO]  Batch 273: Training set : loss - 0.5931, accuracy - 0.7283, recall - 0.8478, AUC - 0.7925, F1 - 0.7573, precision - 0.6842, training time - -11.0 seconds
2023-03-25 18:41:10,986 : [INFO]  Batch 273: Testing set : loss - 0.6025, accuracy - 0.6569, recall - 0.8235, AUC - 0.7934, F1 - 0.7059, precision - 0.6176
2023-03-25 18:41:10,997 : [INFO]  Batch 274 initialized 
2023-03-25 18:41:11,571 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:12,312 : [INFO]  ------------------------- Batch 274 training: round 1 -------------------------
2023-03-25 18:41:17,780 : [INFO]  ------------------------- Batch round 1, loss: 0.5947 -------------------------
2023-03-25 18:41:17,780 : [INFO]  ------------------------- Batch 274, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:17,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:17,842 : [INFO]  ------------------------- Batch 274 training: round 2 -------------------------
2023-03-25 18:41:20,644 : [INFO]  ------------------------- Batch round 2, loss: 0.5925 -------------------------
2023-03-25 18:41:20,645 : [INFO]  ------------------------- Batch 274, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:20,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:20,733 : [INFO]  ------------------------- Batch 274 training: round 3 -------------------------
2023-03-25 18:41:23,637 : [INFO]  ------------------------- Batch round 3, loss: 0.5967 -------------------------
2023-03-25 18:41:23,637 : [INFO]  ------------------------- Batch 274, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:23,657 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:23,661 : [INFO]  Batch number 274 model fetched from the server
2023-03-25 18:41:23,661 : [INFO]  ################ Batch 274: final global model evalution after 3 rounds ################
2023-03-25 18:41:25,458 : [INFO]  Batch 274: Training set : loss - 0.6034, accuracy - 0.6576, recall - 0.7174, AUC - 0.7739, F1 - 0.6769, precision - 0.6408, training time - -11.0 seconds
2023-03-25 18:41:25,458 : [INFO]  Batch 274: Testing set : loss - 0.6399, accuracy - 0.5931, recall - 0.6863, AUC - 0.6976, F1 - 0.6278, precision - 0.5785
2023-03-25 18:41:25,473 : [INFO]  Batch 275 initialized 
2023-03-25 18:41:26,042 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:26,811 : [INFO]  ------------------------- Batch 275 training: round 1 -------------------------
2023-03-25 18:41:32,255 : [INFO]  ------------------------- Batch round 1, loss: 0.603 -------------------------
2023-03-25 18:41:32,255 : [INFO]  ------------------------- Batch 275, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:32,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:32,271 : [INFO]  ------------------------- Batch 275 training: round 2 -------------------------
2023-03-25 18:41:35,123 : [INFO]  ------------------------- Batch round 2, loss: 0.6056 -------------------------
2023-03-25 18:41:35,123 : [INFO]  ------------------------- Batch 275, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:35,138 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:35,142 : [INFO]  ------------------------- Batch 275 training: round 3 -------------------------
2023-03-25 18:41:38,164 : [INFO]  ------------------------- Batch round 3, loss: 0.606 -------------------------
2023-03-25 18:41:38,164 : [INFO]  ------------------------- Batch 275, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:38,186 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:38,189 : [INFO]  Batch number 275 model fetched from the server
2023-03-25 18:41:38,190 : [INFO]  ################ Batch 275: final global model evalution after 3 rounds ################
2023-03-25 18:41:39,958 : [INFO]  Batch 275: Training set : loss - 0.6183, accuracy - 0.6576, recall - 0.6957, AUC - 0.7334, F1 - 0.6702, precision - 0.6465, training time - -11.0 seconds
2023-03-25 18:41:39,958 : [INFO]  Batch 275: Testing set : loss - 0.618, accuracy - 0.6324, recall - 0.8137, AUC - 0.7788, F1 - 0.6888, precision - 0.5971
2023-03-25 18:41:39,973 : [INFO]  Batch 276 initialized 
2023-03-25 18:41:40,538 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:41,284 : [INFO]  ------------------------- Batch 276 training: round 1 -------------------------
2023-03-25 18:41:46,599 : [INFO]  ------------------------- Batch round 1, loss: 0.6291 -------------------------
2023-03-25 18:41:46,599 : [INFO]  ------------------------- Batch 276, round 1: Sent local model to the server -------------------------
2023-03-25 18:41:46,681 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:46,684 : [INFO]  ------------------------- Batch 276 training: round 2 -------------------------
2023-03-25 18:41:49,490 : [INFO]  ------------------------- Batch round 2, loss: 0.6163 -------------------------
2023-03-25 18:41:49,490 : [INFO]  ------------------------- Batch 276, round 2: Sent local model to the server -------------------------
2023-03-25 18:41:49,554 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:49,557 : [INFO]  ------------------------- Batch 276 training: round 3 -------------------------
2023-03-25 18:41:52,364 : [INFO]  ------------------------- Batch round 3, loss: 0.62 -------------------------
2023-03-25 18:41:52,364 : [INFO]  ------------------------- Batch 276, round 3: Sent local model to the server -------------------------
2023-03-25 18:41:52,416 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:41:52,418 : [INFO]  Batch number 276 model fetched from the server
2023-03-25 18:41:52,419 : [INFO]  ################ Batch 276: final global model evalution after 3 rounds ################
2023-03-25 18:41:54,165 : [INFO]  Batch 276: Training set : loss - 0.6434, accuracy - 0.6359, recall - 0.7609, AUC - 0.6824, F1 - 0.6763, precision - 0.6087, training time - -11.0 seconds
2023-03-25 18:41:54,165 : [INFO]  Batch 276: Testing set : loss - 0.6205, accuracy - 0.6324, recall - 0.7745, AUC - 0.7453, F1 - 0.6781, precision - 0.6031
2023-03-25 18:41:54,176 : [INFO]  Batch 277 initialized 
2023-03-25 18:41:54,739 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:41:55,487 : [INFO]  ------------------------- Batch 277 training: round 1 -------------------------
2023-03-25 18:42:01,068 : [INFO]  ------------------------- Batch round 1, loss: 0.6122 -------------------------
2023-03-25 18:42:01,068 : [INFO]  ------------------------- Batch 277, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:01,083 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:01,085 : [INFO]  ------------------------- Batch 277 training: round 2 -------------------------
2023-03-25 18:42:03,982 : [INFO]  ------------------------- Batch round 2, loss: 0.6049 -------------------------
2023-03-25 18:42:03,982 : [INFO]  ------------------------- Batch 277, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:03,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:03,998 : [INFO]  ------------------------- Batch 277 training: round 3 -------------------------
2023-03-25 18:42:06,961 : [INFO]  ------------------------- Batch round 3, loss: 0.6011 -------------------------
2023-03-25 18:42:06,961 : [INFO]  ------------------------- Batch 277, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:06,974 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:06,977 : [INFO]  Batch number 277 model fetched from the server
2023-03-25 18:42:06,977 : [INFO]  ################ Batch 277: final global model evalution after 3 rounds ################
2023-03-25 18:42:08,761 : [INFO]  Batch 277: Training set : loss - 0.6208, accuracy - 0.6196, recall - 0.7826, AUC - 0.753, F1 - 0.6729, precision - 0.5902, training time - -11.0 seconds
2023-03-25 18:42:08,762 : [INFO]  Batch 277: Testing set : loss - 0.6117, accuracy - 0.6569, recall - 0.7843, AUC - 0.7688, F1 - 0.6957, precision - 0.625
2023-03-25 18:42:08,775 : [INFO]  Batch 278 initialized 
2023-03-25 18:42:09,354 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:10,120 : [INFO]  ------------------------- Batch 278 training: round 1 -------------------------
2023-03-25 18:42:15,584 : [INFO]  ------------------------- Batch round 1, loss: 0.6013 -------------------------
2023-03-25 18:42:15,584 : [INFO]  ------------------------- Batch 278, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:15,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:15,605 : [INFO]  ------------------------- Batch 278 training: round 2 -------------------------
2023-03-25 18:42:18,531 : [INFO]  ------------------------- Batch round 2, loss: 0.5999 -------------------------
2023-03-25 18:42:18,531 : [INFO]  ------------------------- Batch 278, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:18,553 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:18,556 : [INFO]  ------------------------- Batch 278 training: round 3 -------------------------
2023-03-25 18:42:21,557 : [INFO]  ------------------------- Batch round 3, loss: 0.6011 -------------------------
2023-03-25 18:42:21,557 : [INFO]  ------------------------- Batch 278, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:21,635 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:21,640 : [INFO]  Batch number 278 model fetched from the server
2023-03-25 18:42:21,641 : [INFO]  ################ Batch 278: final global model evalution after 3 rounds ################
2023-03-25 18:42:23,495 : [INFO]  Batch 278: Training set : loss - 0.6079, accuracy - 0.6957, recall - 0.8261, AUC - 0.7733, F1 - 0.7308, precision - 0.6552, training time - -12.0 seconds
2023-03-25 18:42:23,495 : [INFO]  Batch 278: Testing set : loss - 0.6007, accuracy - 0.6912, recall - 0.8137, AUC - 0.7967, F1 - 0.7249, precision - 0.6535
2023-03-25 18:42:23,535 : [INFO]  Batch 279 initialized 
2023-03-25 18:42:24,116 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:24,888 : [INFO]  ------------------------- Batch 279 training: round 1 -------------------------
2023-03-25 18:42:30,398 : [INFO]  ------------------------- Batch round 1, loss: 0.621 -------------------------
2023-03-25 18:42:30,398 : [INFO]  ------------------------- Batch 279, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:30,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:30,443 : [INFO]  ------------------------- Batch 279 training: round 2 -------------------------
2023-03-25 18:42:33,285 : [INFO]  ------------------------- Batch round 2, loss: 0.628 -------------------------
2023-03-25 18:42:33,285 : [INFO]  ------------------------- Batch 279, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:33,345 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:33,348 : [INFO]  ------------------------- Batch 279 training: round 3 -------------------------
2023-03-25 18:42:36,150 : [INFO]  ------------------------- Batch round 3, loss: 0.6227 -------------------------
2023-03-25 18:42:36,150 : [INFO]  ------------------------- Batch 279, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:36,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:36,222 : [INFO]  Batch number 279 model fetched from the server
2023-03-25 18:42:36,222 : [INFO]  ################ Batch 279: final global model evalution after 3 rounds ################
2023-03-25 18:42:37,990 : [INFO]  Batch 279: Training set : loss - 0.6432, accuracy - 0.5815, recall - 0.7609, AUC - 0.7079, F1 - 0.6452, precision - 0.56, training time - -11.0 seconds
2023-03-25 18:42:37,991 : [INFO]  Batch 279: Testing set : loss - 0.6228, accuracy - 0.6127, recall - 0.7941, AUC - 0.7488, F1 - 0.6722, precision - 0.5827
2023-03-25 18:42:38,001 : [INFO]  Batch 280 initialized 
2023-03-25 18:42:38,568 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:39,329 : [INFO]  ------------------------- Batch 280 training: round 1 -------------------------
2023-03-25 18:42:44,799 : [INFO]  ------------------------- Batch round 1, loss: 0.6056 -------------------------
2023-03-25 18:42:44,799 : [INFO]  ------------------------- Batch 280, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:44,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:44,818 : [INFO]  ------------------------- Batch 280 training: round 2 -------------------------
2023-03-25 18:42:47,735 : [INFO]  ------------------------- Batch round 2, loss: 0.6044 -------------------------
2023-03-25 18:42:47,735 : [INFO]  ------------------------- Batch 280, round 2: Sent local model to the server -------------------------
2023-03-25 18:42:47,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:47,753 : [INFO]  ------------------------- Batch 280 training: round 3 -------------------------
2023-03-25 18:42:50,718 : [INFO]  ------------------------- Batch round 3, loss: 0.6062 -------------------------
2023-03-25 18:42:50,719 : [INFO]  ------------------------- Batch 280, round 3: Sent local model to the server -------------------------
2023-03-25 18:42:50,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:50,735 : [INFO]  Batch number 280 model fetched from the server
2023-03-25 18:42:50,735 : [INFO]  ################ Batch 280: final global model evalution after 3 rounds ################
2023-03-25 18:42:52,549 : [INFO]  Batch 280: Training set : loss - 0.6229, accuracy - 0.6359, recall - 0.7609, AUC - 0.7303, F1 - 0.6763, precision - 0.6087, training time - -11.0 seconds
2023-03-25 18:42:52,550 : [INFO]  Batch 280: Testing set : loss - 0.6491, accuracy - 0.5735, recall - 0.6863, AUC - 0.6847, F1 - 0.6167, precision - 0.56
2023-03-25 18:42:52,559 : [INFO]  Batch 281 initialized 
2023-03-25 18:42:53,142 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:42:53,891 : [INFO]  ------------------------- Batch 281 training: round 1 -------------------------
2023-03-25 18:42:59,505 : [INFO]  ------------------------- Batch round 1, loss: 0.5842 -------------------------
2023-03-25 18:42:59,505 : [INFO]  ------------------------- Batch 281, round 1: Sent local model to the server -------------------------
2023-03-25 18:42:59,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:42:59,524 : [INFO]  ------------------------- Batch 281 training: round 2 -------------------------
2023-03-25 18:43:02,393 : [INFO]  ------------------------- Batch round 2, loss: 0.5943 -------------------------
2023-03-25 18:43:02,394 : [INFO]  ------------------------- Batch 281, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:02,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:02,479 : [INFO]  ------------------------- Batch 281 training: round 3 -------------------------
2023-03-25 18:43:05,370 : [INFO]  ------------------------- Batch round 3, loss: 0.5875 -------------------------
2023-03-25 18:43:05,370 : [INFO]  ------------------------- Batch 281, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:05,384 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:05,386 : [INFO]  Batch number 281 model fetched from the server
2023-03-25 18:43:05,386 : [INFO]  ################ Batch 281: final global model evalution after 3 rounds ################
2023-03-25 18:43:07,209 : [INFO]  Batch 281: Training set : loss - 0.6044, accuracy - 0.6359, recall - 0.7935, AUC - 0.7895, F1 - 0.6854, precision - 0.6033, training time - -11.0 seconds
2023-03-25 18:43:07,210 : [INFO]  Batch 281: Testing set : loss - 0.5935, accuracy - 0.6961, recall - 0.8333, AUC - 0.8057, F1 - 0.7328, precision - 0.6538
2023-03-25 18:43:07,221 : [INFO]  Batch 282 initialized 
2023-03-25 18:43:07,782 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:08,531 : [INFO]  ------------------------- Batch 282 training: round 1 -------------------------
2023-03-25 18:43:13,869 : [INFO]  ------------------------- Batch round 1, loss: 0.5783 -------------------------
2023-03-25 18:43:13,869 : [INFO]  ------------------------- Batch 282, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:13,918 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:13,922 : [INFO]  ------------------------- Batch 282 training: round 2 -------------------------
2023-03-25 18:43:16,780 : [INFO]  ------------------------- Batch round 2, loss: 0.5864 -------------------------
2023-03-25 18:43:16,780 : [INFO]  ------------------------- Batch 282, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:16,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:16,798 : [INFO]  ------------------------- Batch 282 training: round 3 -------------------------
2023-03-25 18:43:19,576 : [INFO]  ------------------------- Batch round 3, loss: 0.583 -------------------------
2023-03-25 18:43:19,576 : [INFO]  ------------------------- Batch 282, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:19,604 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:19,607 : [INFO]  Batch number 282 model fetched from the server
2023-03-25 18:43:19,607 : [INFO]  ################ Batch 282: final global model evalution after 3 rounds ################
2023-03-25 18:43:21,342 : [INFO]  Batch 282: Training set : loss - 0.6054, accuracy - 0.6304, recall - 0.837, AUC - 0.7943, F1 - 0.6937, precision - 0.5923, training time - -11.0 seconds
2023-03-25 18:43:21,342 : [INFO]  Batch 282: Testing set : loss - 0.6384, accuracy - 0.6078, recall - 0.8137, AUC - 0.7295, F1 - 0.6748, precision - 0.5764
2023-03-25 18:43:21,350 : [INFO]  Batch 283 initialized 
2023-03-25 18:43:21,910 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:22,670 : [INFO]  ------------------------- Batch 283 training: round 1 -------------------------
2023-03-25 18:43:28,076 : [INFO]  ------------------------- Batch round 1, loss: 0.6168 -------------------------
2023-03-25 18:43:28,076 : [INFO]  ------------------------- Batch 283, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:28,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:28,113 : [INFO]  ------------------------- Batch 283 training: round 2 -------------------------
2023-03-25 18:43:31,131 : [INFO]  ------------------------- Batch round 2, loss: 0.6211 -------------------------
2023-03-25 18:43:31,131 : [INFO]  ------------------------- Batch 283, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:31,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:31,147 : [INFO]  ------------------------- Batch 283 training: round 3 -------------------------
2023-03-25 18:43:34,085 : [INFO]  ------------------------- Batch round 3, loss: 0.6182 -------------------------
2023-03-25 18:43:34,086 : [INFO]  ------------------------- Batch 283, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:34,100 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:34,103 : [INFO]  Batch number 283 model fetched from the server
2023-03-25 18:43:34,103 : [INFO]  ################ Batch 283: final global model evalution after 3 rounds ################
2023-03-25 18:43:35,957 : [INFO]  Batch 283: Training set : loss - 0.6395, accuracy - 0.6141, recall - 0.7174, AUC - 0.6976, F1 - 0.6502, precision - 0.5946, training time - -11.0 seconds
2023-03-25 18:43:35,957 : [INFO]  Batch 283: Testing set : loss - 0.6086, accuracy - 0.6471, recall - 0.7941, AUC - 0.7765, F1 - 0.6923, precision - 0.6136
2023-03-25 18:43:35,967 : [INFO]  Batch 284 initialized 
2023-03-25 18:43:36,546 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:37,321 : [INFO]  ------------------------- Batch 284 training: round 1 -------------------------
2023-03-25 18:43:42,706 : [INFO]  ------------------------- Batch round 1, loss: 0.5994 -------------------------
2023-03-25 18:43:42,707 : [INFO]  ------------------------- Batch 284, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:42,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:42,722 : [INFO]  ------------------------- Batch 284 training: round 2 -------------------------
2023-03-25 18:43:45,610 : [INFO]  ------------------------- Batch round 2, loss: 0.6098 -------------------------
2023-03-25 18:43:45,610 : [INFO]  ------------------------- Batch 284, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:45,632 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:45,635 : [INFO]  ------------------------- Batch 284 training: round 3 -------------------------
2023-03-25 18:43:48,353 : [INFO]  ------------------------- Batch round 3, loss: 0.6011 -------------------------
2023-03-25 18:43:48,353 : [INFO]  ------------------------- Batch 284, round 3: Sent local model to the server -------------------------
2023-03-25 18:43:48,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:48,422 : [INFO]  Batch number 284 model fetched from the server
2023-03-25 18:43:48,422 : [INFO]  ################ Batch 284: final global model evalution after 3 rounds ################
2023-03-25 18:43:50,175 : [INFO]  Batch 284: Training set : loss - 0.6245, accuracy - 0.6359, recall - 0.8261, AUC - 0.7661, F1 - 0.6941, precision - 0.5984, training time - -11.0 seconds
2023-03-25 18:43:50,175 : [INFO]  Batch 284: Testing set : loss - 0.6503, accuracy - 0.5735, recall - 0.7255, AUC - 0.7054, F1 - 0.6298, precision - 0.5564
2023-03-25 18:43:50,188 : [INFO]  Batch 285 initialized 
2023-03-25 18:43:50,763 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:43:51,553 : [INFO]  ------------------------- Batch 285 training: round 1 -------------------------
2023-03-25 18:43:57,030 : [INFO]  ------------------------- Batch round 1, loss: 0.6075 -------------------------
2023-03-25 18:43:57,031 : [INFO]  ------------------------- Batch 285, round 1: Sent local model to the server -------------------------
2023-03-25 18:43:57,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:57,048 : [INFO]  ------------------------- Batch 285 training: round 2 -------------------------
2023-03-25 18:43:59,980 : [INFO]  ------------------------- Batch round 2, loss: 0.6163 -------------------------
2023-03-25 18:43:59,980 : [INFO]  ------------------------- Batch 285, round 2: Sent local model to the server -------------------------
2023-03-25 18:43:59,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:43:59,999 : [INFO]  ------------------------- Batch 285 training: round 3 -------------------------
2023-03-25 18:44:02,933 : [INFO]  ------------------------- Batch round 3, loss: 0.6237 -------------------------
2023-03-25 18:44:02,933 : [INFO]  ------------------------- Batch 285, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:02,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:02,954 : [INFO]  Batch number 285 model fetched from the server
2023-03-25 18:44:02,954 : [INFO]  ################ Batch 285: final global model evalution after 3 rounds ################
2023-03-25 18:44:04,757 : [INFO]  Batch 285: Training set : loss - 0.648, accuracy - 0.5598, recall - 0.75, AUC - 0.7058, F1 - 0.6301, precision - 0.5433, training time - -11.0 seconds
2023-03-25 18:44:04,757 : [INFO]  Batch 285: Testing set : loss - 0.6334, accuracy - 0.6324, recall - 0.8039, AUC - 0.7417, F1 - 0.6862, precision - 0.5985
2023-03-25 18:44:04,767 : [INFO]  Batch 286 initialized 
2023-03-25 18:44:05,352 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:06,117 : [INFO]  ------------------------- Batch 286 training: round 1 -------------------------
2023-03-25 18:44:11,413 : [INFO]  ------------------------- Batch round 1, loss: 0.6276 -------------------------
2023-03-25 18:44:11,413 : [INFO]  ------------------------- Batch 286, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:11,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:11,432 : [INFO]  ------------------------- Batch 286 training: round 2 -------------------------
2023-03-25 18:44:14,145 : [INFO]  ------------------------- Batch round 2, loss: 0.6322 -------------------------
2023-03-25 18:44:14,145 : [INFO]  ------------------------- Batch 286, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:14,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:14,168 : [INFO]  ------------------------- Batch 286 training: round 3 -------------------------
2023-03-25 18:44:16,948 : [INFO]  ------------------------- Batch round 3, loss: 0.6287 -------------------------
2023-03-25 18:44:16,948 : [INFO]  ------------------------- Batch 286, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:16,962 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:16,965 : [INFO]  Batch number 286 model fetched from the server
2023-03-25 18:44:16,965 : [INFO]  ################ Batch 286: final global model evalution after 3 rounds ################
2023-03-25 18:44:18,781 : [INFO]  Batch 286: Training set : loss - 0.6512, accuracy - 0.5761, recall - 0.7283, AUC - 0.6943, F1 - 0.6321, precision - 0.5583, training time - -11.0 seconds
2023-03-25 18:44:18,781 : [INFO]  Batch 286: Testing set : loss - 0.6239, accuracy - 0.6176, recall - 0.7647, AUC - 0.7424, F1 - 0.6667, precision - 0.5909
2023-03-25 18:44:18,793 : [INFO]  Batch 287 initialized 
2023-03-25 18:44:19,372 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:20,112 : [INFO]  ------------------------- Batch 287 training: round 1 -------------------------
2023-03-25 18:44:25,618 : [INFO]  ------------------------- Batch round 1, loss: 0.6226 -------------------------
2023-03-25 18:44:25,619 : [INFO]  ------------------------- Batch 287, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:25,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:25,776 : [INFO]  ------------------------- Batch 287 training: round 2 -------------------------
2023-03-25 18:44:28,661 : [INFO]  ------------------------- Batch round 2, loss: 0.6298 -------------------------
2023-03-25 18:44:28,661 : [INFO]  ------------------------- Batch 287, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:28,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:28,679 : [INFO]  ------------------------- Batch 287 training: round 3 -------------------------
2023-03-25 18:44:31,597 : [INFO]  ------------------------- Batch round 3, loss: 0.6308 -------------------------
2023-03-25 18:44:31,597 : [INFO]  ------------------------- Batch 287, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:31,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:31,616 : [INFO]  Batch number 287 model fetched from the server
2023-03-25 18:44:31,617 : [INFO]  ################ Batch 287: final global model evalution after 3 rounds ################
2023-03-25 18:44:33,382 : [INFO]  Batch 287: Training set : loss - 0.6631, accuracy - 0.5435, recall - 0.7174, AUC - 0.6625, F1 - 0.6111, precision - 0.5323, training time - -12.0 seconds
2023-03-25 18:44:33,382 : [INFO]  Batch 287: Testing set : loss - 0.6634, accuracy - 0.5441, recall - 0.7255, AUC - 0.6615, F1 - 0.6141, precision - 0.5324
2023-03-25 18:44:33,394 : [INFO]  Batch 288 initialized 
2023-03-25 18:44:33,980 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:34,765 : [INFO]  ------------------------- Batch 288 training: round 1 -------------------------
2023-03-25 18:44:40,128 : [INFO]  ------------------------- Batch round 1, loss: 0.6225 -------------------------
2023-03-25 18:44:40,128 : [INFO]  ------------------------- Batch 288, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:40,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:40,148 : [INFO]  ------------------------- Batch 288 training: round 2 -------------------------
2023-03-25 18:44:42,889 : [INFO]  ------------------------- Batch round 2, loss: 0.6217 -------------------------
2023-03-25 18:44:42,889 : [INFO]  ------------------------- Batch 288, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:42,958 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:42,961 : [INFO]  ------------------------- Batch 288 training: round 3 -------------------------
2023-03-25 18:44:45,722 : [INFO]  ------------------------- Batch round 3, loss: 0.621 -------------------------
2023-03-25 18:44:45,722 : [INFO]  ------------------------- Batch 288, round 3: Sent local model to the server -------------------------
2023-03-25 18:44:45,775 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:45,779 : [INFO]  Batch number 288 model fetched from the server
2023-03-25 18:44:45,779 : [INFO]  ################ Batch 288: final global model evalution after 3 rounds ################
2023-03-25 18:44:47,511 : [INFO]  Batch 288: Training set : loss - 0.6477, accuracy - 0.5707, recall - 0.7391, AUC - 0.6935, F1 - 0.6326, precision - 0.5528, training time - -11.0 seconds
2023-03-25 18:44:47,511 : [INFO]  Batch 288: Testing set : loss - 0.7024, accuracy - 0.4951, recall - 0.7059, AUC - 0.5727, F1 - 0.583, precision - 0.4966
2023-03-25 18:44:47,527 : [INFO]  Batch 289 initialized 
2023-03-25 18:44:48,124 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:44:48,911 : [INFO]  ------------------------- Batch 289 training: round 1 -------------------------
2023-03-25 18:44:54,278 : [INFO]  ------------------------- Batch round 1, loss: 0.618 -------------------------
2023-03-25 18:44:54,278 : [INFO]  ------------------------- Batch 289, round 1: Sent local model to the server -------------------------
2023-03-25 18:44:54,372 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:54,375 : [INFO]  ------------------------- Batch 289 training: round 2 -------------------------
2023-03-25 18:44:57,155 : [INFO]  ------------------------- Batch round 2, loss: 0.6224 -------------------------
2023-03-25 18:44:57,155 : [INFO]  ------------------------- Batch 289, round 2: Sent local model to the server -------------------------
2023-03-25 18:44:57,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:44:57,178 : [INFO]  ------------------------- Batch 289 training: round 3 -------------------------
2023-03-25 18:44:59,958 : [INFO]  ------------------------- Batch round 3, loss: 0.6227 -------------------------
2023-03-25 18:44:59,959 : [INFO]  ------------------------- Batch 289, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:00,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:00,041 : [INFO]  Batch number 289 model fetched from the server
2023-03-25 18:45:00,042 : [INFO]  ################ Batch 289: final global model evalution after 3 rounds ################
2023-03-25 18:45:01,785 : [INFO]  Batch 289: Training set : loss - 0.6675, accuracy - 0.5598, recall - 0.75, AUC - 0.6532, F1 - 0.6301, precision - 0.5433, training time - -11.0 seconds
2023-03-25 18:45:01,785 : [INFO]  Batch 289: Testing set : loss - 0.6949, accuracy - 0.5196, recall - 0.7451, AUC - 0.594, F1 - 0.608, precision - 0.5135
2023-03-25 18:45:01,802 : [INFO]  Batch 290 initialized 
2023-03-25 18:45:02,378 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:03,150 : [INFO]  ------------------------- Batch 290 training: round 1 -------------------------
2023-03-25 18:45:08,415 : [INFO]  ------------------------- Batch round 1, loss: 0.645 -------------------------
2023-03-25 18:45:08,415 : [INFO]  ------------------------- Batch 290, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:08,514 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:08,517 : [INFO]  ------------------------- Batch 290 training: round 2 -------------------------
2023-03-25 18:45:11,290 : [INFO]  ------------------------- Batch round 2, loss: 0.6398 -------------------------
2023-03-25 18:45:11,290 : [INFO]  ------------------------- Batch 290, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:11,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:11,358 : [INFO]  ------------------------- Batch 290 training: round 3 -------------------------
2023-03-25 18:45:14,106 : [INFO]  ------------------------- Batch round 3, loss: 0.6424 -------------------------
2023-03-25 18:45:14,106 : [INFO]  ------------------------- Batch 290, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:14,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:14,148 : [INFO]  Batch number 290 model fetched from the server
2023-03-25 18:45:14,148 : [INFO]  ################ Batch 290: final global model evalution after 3 rounds ################
2023-03-25 18:45:15,885 : [INFO]  Batch 290: Training set : loss - 0.69, accuracy - 0.5326, recall - 0.6413, AUC - 0.5919, F1 - 0.5784, precision - 0.5268, training time - -11.0 seconds
2023-03-25 18:45:15,885 : [INFO]  Batch 290: Testing set : loss - 0.658, accuracy - 0.5539, recall - 0.7157, AUC - 0.6727, F1 - 0.616, precision - 0.5407
2023-03-25 18:45:15,902 : [INFO]  Batch 291 initialized 
2023-03-25 18:45:16,523 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:17,318 : [INFO]  ------------------------- Batch 291 training: round 1 -------------------------
2023-03-25 18:45:22,510 : [INFO]  ------------------------- Batch round 1, loss: 0.657 -------------------------
2023-03-25 18:45:22,510 : [INFO]  ------------------------- Batch 291, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:22,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:22,666 : [INFO]  ------------------------- Batch 291 training: round 2 -------------------------
2023-03-25 18:45:25,278 : [INFO]  ------------------------- Batch round 2, loss: 0.6603 -------------------------
2023-03-25 18:45:25,278 : [INFO]  ------------------------- Batch 291, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:25,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:25,437 : [INFO]  ------------------------- Batch 291 training: round 3 -------------------------
2023-03-25 18:45:28,000 : [INFO]  ------------------------- Batch round 3, loss: 0.6491 -------------------------
2023-03-25 18:45:28,000 : [INFO]  ------------------------- Batch 291, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:28,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:28,108 : [INFO]  Batch number 291 model fetched from the server
2023-03-25 18:45:28,108 : [INFO]  ################ Batch 291: final global model evalution after 3 rounds ################
2023-03-25 18:45:29,760 : [INFO]  Batch 291: Training set : loss - 0.7061, accuracy - 0.4837, recall - 0.6739, AUC - 0.5862, F1 - 0.5662, precision - 0.4882, training time - -11.0 seconds
2023-03-25 18:45:29,761 : [INFO]  Batch 291: Testing set : loss - 0.713, accuracy - 0.4608, recall - 0.7059, AUC - 0.5989, F1 - 0.5669, precision - 0.4737
2023-03-25 18:45:29,779 : [INFO]  Batch 292 initialized 
2023-03-25 18:45:30,362 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:31,113 : [INFO]  ------------------------- Batch 292 training: round 1 -------------------------
2023-03-25 18:45:36,334 : [INFO]  ------------------------- Batch round 1, loss: 0.5996 -------------------------
2023-03-25 18:45:36,334 : [INFO]  ------------------------- Batch 292, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:36,482 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:36,484 : [INFO]  ------------------------- Batch 292 training: round 2 -------------------------
2023-03-25 18:45:39,198 : [INFO]  ------------------------- Batch round 2, loss: 0.6023 -------------------------
2023-03-25 18:45:39,198 : [INFO]  ------------------------- Batch 292, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:39,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:39,222 : [INFO]  ------------------------- Batch 292 training: round 3 -------------------------
2023-03-25 18:45:41,877 : [INFO]  ------------------------- Batch round 3, loss: 0.5966 -------------------------
2023-03-25 18:45:41,877 : [INFO]  ------------------------- Batch 292, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:41,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:41,970 : [INFO]  Batch number 292 model fetched from the server
2023-03-25 18:45:41,970 : [INFO]  ################ Batch 292: final global model evalution after 3 rounds ################
2023-03-25 18:45:43,651 : [INFO]  Batch 292: Training set : loss - 0.6099, accuracy - 0.663, recall - 0.7826, AUC - 0.7741, F1 - 0.699, precision - 0.6316, training time - -11.0 seconds
2023-03-25 18:45:43,652 : [INFO]  Batch 292: Testing set : loss - 0.5828, accuracy - 0.7108, recall - 0.8529, AUC - 0.8302, F1 - 0.7468, precision - 0.6641
2023-03-25 18:45:43,665 : [INFO]  Batch 293 initialized 
2023-03-25 18:45:44,263 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:45,038 : [INFO]  ------------------------- Batch 293 training: round 1 -------------------------
2023-03-25 18:45:50,361 : [INFO]  ------------------------- Batch round 1, loss: 0.6026 -------------------------
2023-03-25 18:45:50,361 : [INFO]  ------------------------- Batch 293, round 1: Sent local model to the server -------------------------
2023-03-25 18:45:50,385 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:50,388 : [INFO]  ------------------------- Batch 293 training: round 2 -------------------------
2023-03-25 18:45:53,128 : [INFO]  ------------------------- Batch round 2, loss: 0.6019 -------------------------
2023-03-25 18:45:53,129 : [INFO]  ------------------------- Batch 293, round 2: Sent local model to the server -------------------------
2023-03-25 18:45:53,145 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:53,148 : [INFO]  ------------------------- Batch 293 training: round 3 -------------------------
2023-03-25 18:45:55,975 : [INFO]  ------------------------- Batch round 3, loss: 0.6009 -------------------------
2023-03-25 18:45:55,975 : [INFO]  ------------------------- Batch 293, round 3: Sent local model to the server -------------------------
2023-03-25 18:45:56,005 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:45:56,008 : [INFO]  Batch number 293 model fetched from the server
2023-03-25 18:45:56,008 : [INFO]  ################ Batch 293: final global model evalution after 3 rounds ################
2023-03-25 18:45:57,728 : [INFO]  Batch 293: Training set : loss - 0.6069, accuracy - 0.7065, recall - 0.7609, AUC - 0.7586, F1 - 0.7216, precision - 0.6863, training time - -11.0 seconds
2023-03-25 18:45:57,728 : [INFO]  Batch 293: Testing set : loss - 0.629, accuracy - 0.6225, recall - 0.8039, AUC - 0.7459, F1 - 0.6805, precision - 0.5899
2023-03-25 18:45:57,740 : [INFO]  Batch 294 initialized 
2023-03-25 18:45:58,326 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:45:59,108 : [INFO]  ------------------------- Batch 294 training: round 1 -------------------------
2023-03-25 18:46:04,332 : [INFO]  ------------------------- Batch round 1, loss: 0.6239 -------------------------
2023-03-25 18:46:04,333 : [INFO]  ------------------------- Batch 294, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:04,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:04,354 : [INFO]  ------------------------- Batch 294 training: round 2 -------------------------
2023-03-25 18:46:07,234 : [INFO]  ------------------------- Batch round 2, loss: 0.6255 -------------------------
2023-03-25 18:46:07,234 : [INFO]  ------------------------- Batch 294, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:07,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:07,256 : [INFO]  ------------------------- Batch 294 training: round 3 -------------------------
2023-03-25 18:46:10,024 : [INFO]  ------------------------- Batch round 3, loss: 0.6256 -------------------------
2023-03-25 18:46:10,025 : [INFO]  ------------------------- Batch 294, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:10,049 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:10,051 : [INFO]  Batch number 294 model fetched from the server
2023-03-25 18:46:10,052 : [INFO]  ################ Batch 294: final global model evalution after 3 rounds ################
2023-03-25 18:46:11,843 : [INFO]  Batch 294: Training set : loss - 0.6376, accuracy - 0.5924, recall - 0.7065, AUC - 0.7026, F1 - 0.6341, precision - 0.5752, training time - -11.0 seconds
2023-03-25 18:46:11,844 : [INFO]  Batch 294: Testing set : loss - 0.6404, accuracy - 0.6029, recall - 0.7353, AUC - 0.7145, F1 - 0.6494, precision - 0.5814
2023-03-25 18:46:11,855 : [INFO]  Batch 295 initialized 
2023-03-25 18:46:12,444 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:13,223 : [INFO]  ------------------------- Batch 295 training: round 1 -------------------------
2023-03-25 18:46:18,497 : [INFO]  ------------------------- Batch round 1, loss: 0.614 -------------------------
2023-03-25 18:46:18,497 : [INFO]  ------------------------- Batch 295, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:18,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:18,516 : [INFO]  ------------------------- Batch 295 training: round 2 -------------------------
2023-03-25 18:46:21,255 : [INFO]  ------------------------- Batch round 2, loss: 0.6171 -------------------------
2023-03-25 18:46:21,255 : [INFO]  ------------------------- Batch 295, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:21,269 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:21,272 : [INFO]  ------------------------- Batch 295 training: round 3 -------------------------
2023-03-25 18:46:24,065 : [INFO]  ------------------------- Batch round 3, loss: 0.609 -------------------------
2023-03-25 18:46:24,065 : [INFO]  ------------------------- Batch 295, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:24,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:24,085 : [INFO]  Batch number 295 model fetched from the server
2023-03-25 18:46:24,085 : [INFO]  ################ Batch 295: final global model evalution after 3 rounds ################
2023-03-25 18:46:25,774 : [INFO]  Batch 295: Training set : loss - 0.6282, accuracy - 0.6087, recall - 0.6848, AUC - 0.7117, F1 - 0.6364, precision - 0.5943, training time - -11.0 seconds
2023-03-25 18:46:25,774 : [INFO]  Batch 295: Testing set : loss - 0.6342, accuracy - 0.6275, recall - 0.6863, AUC - 0.6981, F1 - 0.6481, precision - 0.614
2023-03-25 18:46:25,783 : [INFO]  Batch 296 initialized 
2023-03-25 18:46:26,391 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:27,194 : [INFO]  ------------------------- Batch 296 training: round 1 -------------------------
2023-03-25 18:46:32,462 : [INFO]  ------------------------- Batch round 1, loss: 0.6321 -------------------------
2023-03-25 18:46:32,462 : [INFO]  ------------------------- Batch 296, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:32,507 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:32,510 : [INFO]  ------------------------- Batch 296 training: round 2 -------------------------
2023-03-25 18:46:35,218 : [INFO]  ------------------------- Batch round 2, loss: 0.6272 -------------------------
2023-03-25 18:46:35,219 : [INFO]  ------------------------- Batch 296, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:35,302 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:35,305 : [INFO]  ------------------------- Batch 296 training: round 3 -------------------------
2023-03-25 18:46:38,030 : [INFO]  ------------------------- Batch round 3, loss: 0.6274 -------------------------
2023-03-25 18:46:38,031 : [INFO]  ------------------------- Batch 296, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:38,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:38,121 : [INFO]  Batch number 296 model fetched from the server
2023-03-25 18:46:38,121 : [INFO]  ################ Batch 296: final global model evalution after 3 rounds ################
2023-03-25 18:46:39,885 : [INFO]  Batch 296: Training set : loss - 0.6407, accuracy - 0.6087, recall - 0.7065, AUC - 0.7038, F1 - 0.6436, precision - 0.5909, training time - -11.0 seconds
2023-03-25 18:46:39,886 : [INFO]  Batch 296: Testing set : loss - 0.5996, accuracy - 0.6667, recall - 0.7647, AUC - 0.782, F1 - 0.6964, precision - 0.6393
2023-03-25 18:46:39,895 : [INFO]  Batch 297 initialized 
2023-03-25 18:46:40,495 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:41,314 : [INFO]  ------------------------- Batch 297 training: round 1 -------------------------
2023-03-25 18:46:46,552 : [INFO]  ------------------------- Batch round 1, loss: 0.623 -------------------------
2023-03-25 18:46:46,552 : [INFO]  ------------------------- Batch 297, round 1: Sent local model to the server -------------------------
2023-03-25 18:46:46,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:46,571 : [INFO]  ------------------------- Batch 297 training: round 2 -------------------------
2023-03-25 18:46:49,290 : [INFO]  ------------------------- Batch round 2, loss: 0.6259 -------------------------
2023-03-25 18:46:49,290 : [INFO]  ------------------------- Batch 297, round 2: Sent local model to the server -------------------------
2023-03-25 18:46:49,308 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:49,311 : [INFO]  ------------------------- Batch 297 training: round 3 -------------------------
2023-03-25 18:46:51,990 : [INFO]  ------------------------- Batch round 3, loss: 0.6225 -------------------------
2023-03-25 18:46:51,991 : [INFO]  ------------------------- Batch 297, round 3: Sent local model to the server -------------------------
2023-03-25 18:46:52,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:46:52,017 : [INFO]  Batch number 297 model fetched from the server
2023-03-25 18:46:52,017 : [INFO]  ################ Batch 297: final global model evalution after 3 rounds ################
2023-03-25 18:46:53,745 : [INFO]  Batch 297: Training set : loss - 0.6322, accuracy - 0.6576, recall - 0.837, AUC - 0.7398, F1 - 0.7097, precision - 0.616, training time - -11.0 seconds
2023-03-25 18:46:53,745 : [INFO]  Batch 297: Testing set : loss - 0.6304, accuracy - 0.6275, recall - 0.7451, AUC - 0.7273, F1 - 0.6667, precision - 0.6032
2023-03-25 18:46:53,755 : [INFO]  Batch 298 initialized 
2023-03-25 18:46:54,328 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:46:55,136 : [INFO]  ------------------------- Batch 298 training: round 1 -------------------------
2023-03-25 18:47:00,442 : [INFO]  ------------------------- Batch round 1, loss: 0.5985 -------------------------
2023-03-25 18:47:00,442 : [INFO]  ------------------------- Batch 298, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:00,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:00,519 : [INFO]  ------------------------- Batch 298 training: round 2 -------------------------
2023-03-25 18:47:03,185 : [INFO]  ------------------------- Batch round 2, loss: 0.595 -------------------------
2023-03-25 18:47:03,185 : [INFO]  ------------------------- Batch 298, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:03,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:03,251 : [INFO]  ------------------------- Batch 298 training: round 3 -------------------------
2023-03-25 18:47:05,924 : [INFO]  ------------------------- Batch round 3, loss: 0.6001 -------------------------
2023-03-25 18:47:05,925 : [INFO]  ------------------------- Batch 298, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:05,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:05,970 : [INFO]  Batch number 298 model fetched from the server
2023-03-25 18:47:05,971 : [INFO]  ################ Batch 298: final global model evalution after 3 rounds ################
2023-03-25 18:47:07,710 : [INFO]  Batch 298: Training set : loss - 0.6168, accuracy - 0.6413, recall - 0.8261, AUC - 0.7632, F1 - 0.6972, precision - 0.6032, training time - -11.0 seconds
2023-03-25 18:47:07,710 : [INFO]  Batch 298: Testing set : loss - 0.623, accuracy - 0.6275, recall - 0.7549, AUC - 0.7368, F1 - 0.6696, precision - 0.6016
2023-03-25 18:47:07,722 : [INFO]  Batch 299 initialized 
2023-03-25 18:47:08,304 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:09,085 : [INFO]  ------------------------- Batch 299 training: round 1 -------------------------
2023-03-25 18:47:14,269 : [INFO]  ------------------------- Batch round 1, loss: 0.6004 -------------------------
2023-03-25 18:47:14,269 : [INFO]  ------------------------- Batch 299, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:14,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:14,292 : [INFO]  ------------------------- Batch 299 training: round 2 -------------------------
2023-03-25 18:47:16,999 : [INFO]  ------------------------- Batch round 2, loss: 0.605 -------------------------
2023-03-25 18:47:16,999 : [INFO]  ------------------------- Batch 299, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:17,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:17,029 : [INFO]  ------------------------- Batch 299 training: round 3 -------------------------
2023-03-25 18:47:19,709 : [INFO]  ------------------------- Batch round 3, loss: 0.6087 -------------------------
2023-03-25 18:47:19,709 : [INFO]  ------------------------- Batch 299, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:19,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:19,728 : [INFO]  Batch number 299 model fetched from the server
2023-03-25 18:47:19,728 : [INFO]  ################ Batch 299: final global model evalution after 3 rounds ################
2023-03-25 18:47:21,439 : [INFO]  Batch 299: Training set : loss - 0.614, accuracy - 0.663, recall - 0.7826, AUC - 0.7587, F1 - 0.699, precision - 0.6316, training time - -11.0 seconds
2023-03-25 18:47:21,439 : [INFO]  Batch 299: Testing set : loss - 0.6436, accuracy - 0.6029, recall - 0.7255, AUC - 0.695, F1 - 0.6463, precision - 0.5827
2023-03-25 18:47:21,454 : [INFO]  Batch 300 initialized 
2023-03-25 18:47:22,040 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:22,865 : [INFO]  ------------------------- Batch 300 training: round 1 -------------------------
2023-03-25 18:47:28,194 : [INFO]  ------------------------- Batch round 1, loss: 0.6006 -------------------------
2023-03-25 18:47:28,194 : [INFO]  ------------------------- Batch 300, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:28,213 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:28,216 : [INFO]  ------------------------- Batch 300 training: round 2 -------------------------
2023-03-25 18:47:30,924 : [INFO]  ------------------------- Batch round 2, loss: 0.5982 -------------------------
2023-03-25 18:47:30,925 : [INFO]  ------------------------- Batch 300, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:30,969 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:30,971 : [INFO]  ------------------------- Batch 300 training: round 3 -------------------------
2023-03-25 18:47:33,670 : [INFO]  ------------------------- Batch round 3, loss: 0.6 -------------------------
2023-03-25 18:47:33,671 : [INFO]  ------------------------- Batch 300, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:33,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:33,696 : [INFO]  Batch number 300 model fetched from the server
2023-03-25 18:47:33,696 : [INFO]  ################ Batch 300: final global model evalution after 3 rounds ################
2023-03-25 18:47:35,389 : [INFO]  Batch 300: Training set : loss - 0.6091, accuracy - 0.6739, recall - 0.7826, AUC - 0.7661, F1 - 0.7059, precision - 0.6429, training time - -11.0 seconds
2023-03-25 18:47:35,390 : [INFO]  Batch 300: Testing set : loss - 0.6209, accuracy - 0.6324, recall - 0.7059, AUC - 0.7271, F1 - 0.6575, precision - 0.6154
2023-03-25 18:47:35,410 : [INFO]  Batch 301 initialized 
2023-03-25 18:47:36,035 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:36,839 : [INFO]  ------------------------- Batch 301 training: round 1 -------------------------
2023-03-25 18:47:42,103 : [INFO]  ------------------------- Batch round 1, loss: 0.6337 -------------------------
2023-03-25 18:47:42,103 : [INFO]  ------------------------- Batch 301, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:42,119 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:42,122 : [INFO]  ------------------------- Batch 301 training: round 2 -------------------------
2023-03-25 18:47:44,929 : [INFO]  ------------------------- Batch round 2, loss: 0.6224 -------------------------
2023-03-25 18:47:44,929 : [INFO]  ------------------------- Batch 301, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:44,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:44,956 : [INFO]  ------------------------- Batch 301 training: round 3 -------------------------
2023-03-25 18:47:47,676 : [INFO]  ------------------------- Batch round 3, loss: 0.625 -------------------------
2023-03-25 18:47:47,676 : [INFO]  ------------------------- Batch 301, round 3: Sent local model to the server -------------------------
2023-03-25 18:47:47,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:47,696 : [INFO]  Batch number 301 model fetched from the server
2023-03-25 18:47:47,696 : [INFO]  ################ Batch 301: final global model evalution after 3 rounds ################
2023-03-25 18:47:49,484 : [INFO]  Batch 301: Training set : loss - 0.633, accuracy - 0.6413, recall - 0.8043, AUC - 0.7358, F1 - 0.6916, precision - 0.6066, training time - -11.0 seconds
2023-03-25 18:47:49,484 : [INFO]  Batch 301: Testing set : loss - 0.6129, accuracy - 0.6569, recall - 0.7941, AUC - 0.77, F1 - 0.6983, precision - 0.6231
2023-03-25 18:47:49,495 : [INFO]  Batch 302 initialized 
2023-03-25 18:47:50,159 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:47:50,942 : [INFO]  ------------------------- Batch 302 training: round 1 -------------------------
2023-03-25 18:47:56,161 : [INFO]  ------------------------- Batch round 1, loss: 0.5874 -------------------------
2023-03-25 18:47:56,161 : [INFO]  ------------------------- Batch 302, round 1: Sent local model to the server -------------------------
2023-03-25 18:47:56,182 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:56,184 : [INFO]  ------------------------- Batch 302 training: round 2 -------------------------
2023-03-25 18:47:58,797 : [INFO]  ------------------------- Batch round 2, loss: 0.5867 -------------------------
2023-03-25 18:47:58,798 : [INFO]  ------------------------- Batch 302, round 2: Sent local model to the server -------------------------
2023-03-25 18:47:58,850 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:47:58,854 : [INFO]  ------------------------- Batch 302 training: round 3 -------------------------
2023-03-25 18:48:01,468 : [INFO]  ------------------------- Batch round 3, loss: 0.5888 -------------------------
2023-03-25 18:48:01,468 : [INFO]  ------------------------- Batch 302, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:01,492 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:01,496 : [INFO]  Batch number 302 model fetched from the server
2023-03-25 18:48:01,497 : [INFO]  ################ Batch 302: final global model evalution after 3 rounds ################
2023-03-25 18:48:03,366 : [INFO]  Batch 302: Training set : loss - 0.5939, accuracy - 0.6793, recall - 0.7935, AUC - 0.7958, F1 - 0.7122, precision - 0.646, training time - -11.0 seconds
2023-03-25 18:48:03,366 : [INFO]  Batch 302: Testing set : loss - 0.635, accuracy - 0.6176, recall - 0.7157, AUC - 0.7092, F1 - 0.6518, precision - 0.5984
2023-03-25 18:48:03,381 : [INFO]  Batch 303 initialized 
2023-03-25 18:48:03,978 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:04,725 : [INFO]  ------------------------- Batch 303 training: round 1 -------------------------
2023-03-25 18:48:09,853 : [INFO]  ------------------------- Batch round 1, loss: 0.6424 -------------------------
2023-03-25 18:48:09,853 : [INFO]  ------------------------- Batch 303, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:09,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:09,870 : [INFO]  ------------------------- Batch 303 training: round 2 -------------------------
2023-03-25 18:48:12,400 : [INFO]  ------------------------- Batch round 2, loss: 0.6443 -------------------------
2023-03-25 18:48:12,400 : [INFO]  ------------------------- Batch 303, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:12,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:12,421 : [INFO]  ------------------------- Batch 303 training: round 3 -------------------------
2023-03-25 18:48:14,923 : [INFO]  ------------------------- Batch round 3, loss: 0.6503 -------------------------
2023-03-25 18:48:14,924 : [INFO]  ------------------------- Batch 303, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:14,949 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:14,951 : [INFO]  Batch number 303 model fetched from the server
2023-03-25 18:48:14,951 : [INFO]  ################ Batch 303: final global model evalution after 3 rounds ################
2023-03-25 18:48:16,606 : [INFO]  Batch 303: Training set : loss - 0.6607, accuracy - 0.5815, recall - 0.7283, AUC - 0.6708, F1 - 0.6351, precision - 0.563, training time - -10.0 seconds
2023-03-25 18:48:16,607 : [INFO]  Batch 303: Testing set : loss - 0.6199, accuracy - 0.6569, recall - 0.7451, AUC - 0.7514, F1 - 0.6847, precision - 0.6333
2023-03-25 18:48:16,622 : [INFO]  Batch 304 initialized 
2023-03-25 18:48:17,193 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:17,987 : [INFO]  ------------------------- Batch 304 training: round 1 -------------------------
2023-03-25 18:48:23,146 : [INFO]  ------------------------- Batch round 1, loss: 0.602 -------------------------
2023-03-25 18:48:23,147 : [INFO]  ------------------------- Batch 304, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:23,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:23,220 : [INFO]  ------------------------- Batch 304 training: round 2 -------------------------
2023-03-25 18:48:26,033 : [INFO]  ------------------------- Batch round 2, loss: 0.6081 -------------------------
2023-03-25 18:48:26,033 : [INFO]  ------------------------- Batch 304, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:26,047 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:26,051 : [INFO]  ------------------------- Batch 304 training: round 3 -------------------------
2023-03-25 18:48:28,681 : [INFO]  ------------------------- Batch round 3, loss: 0.6084 -------------------------
2023-03-25 18:48:28,682 : [INFO]  ------------------------- Batch 304, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:28,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:28,700 : [INFO]  Batch number 304 model fetched from the server
2023-03-25 18:48:28,700 : [INFO]  ################ Batch 304: final global model evalution after 3 rounds ################
2023-03-25 18:48:30,381 : [INFO]  Batch 304: Training set : loss - 0.6136, accuracy - 0.6685, recall - 0.7283, AUC - 0.7563, F1 - 0.6872, precision - 0.6505, training time - -11.0 seconds
2023-03-25 18:48:30,382 : [INFO]  Batch 304: Testing set : loss - 0.6089, accuracy - 0.6373, recall - 0.6863, AUC - 0.7552, F1 - 0.6542, precision - 0.625
2023-03-25 18:48:30,396 : [INFO]  Batch 305 initialized 
2023-03-25 18:48:30,974 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:31,801 : [INFO]  ------------------------- Batch 305 training: round 1 -------------------------
2023-03-25 18:48:36,901 : [INFO]  ------------------------- Batch round 1, loss: 0.6266 -------------------------
2023-03-25 18:48:36,901 : [INFO]  ------------------------- Batch 305, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:36,935 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:36,937 : [INFO]  ------------------------- Batch 305 training: round 2 -------------------------
2023-03-25 18:48:39,497 : [INFO]  ------------------------- Batch round 2, loss: 0.6334 -------------------------
2023-03-25 18:48:39,497 : [INFO]  ------------------------- Batch 305, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:39,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:39,602 : [INFO]  ------------------------- Batch 305 training: round 3 -------------------------
2023-03-25 18:48:42,193 : [INFO]  ------------------------- Batch round 3, loss: 0.6294 -------------------------
2023-03-25 18:48:42,193 : [INFO]  ------------------------- Batch 305, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:42,240 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:42,243 : [INFO]  Batch number 305 model fetched from the server
2023-03-25 18:48:42,243 : [INFO]  ################ Batch 305: final global model evalution after 3 rounds ################
2023-03-25 18:48:43,909 : [INFO]  Batch 305: Training set : loss - 0.6375, accuracy - 0.6359, recall - 0.7935, AUC - 0.7222, F1 - 0.6854, precision - 0.6033, training time - -10.0 seconds
2023-03-25 18:48:43,909 : [INFO]  Batch 305: Testing set : loss - 0.604, accuracy - 0.6814, recall - 0.7843, AUC - 0.7821, F1 - 0.7111, precision - 0.6504
2023-03-25 18:48:43,924 : [INFO]  Batch 306 initialized 
2023-03-25 18:48:44,494 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:45,297 : [INFO]  ------------------------- Batch 306 training: round 1 -------------------------
2023-03-25 18:48:50,682 : [INFO]  ------------------------- Batch round 1, loss: 0.6176 -------------------------
2023-03-25 18:48:50,682 : [INFO]  ------------------------- Batch 306, round 1: Sent local model to the server -------------------------
2023-03-25 18:48:50,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:50,724 : [INFO]  ------------------------- Batch 306 training: round 2 -------------------------
2023-03-25 18:48:53,361 : [INFO]  ------------------------- Batch round 2, loss: 0.613 -------------------------
2023-03-25 18:48:53,362 : [INFO]  ------------------------- Batch 306, round 2: Sent local model to the server -------------------------
2023-03-25 18:48:53,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:53,385 : [INFO]  ------------------------- Batch 306 training: round 3 -------------------------
2023-03-25 18:48:56,087 : [INFO]  ------------------------- Batch round 3, loss: 0.614 -------------------------
2023-03-25 18:48:56,087 : [INFO]  ------------------------- Batch 306, round 3: Sent local model to the server -------------------------
2023-03-25 18:48:56,136 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:48:56,139 : [INFO]  Batch number 306 model fetched from the server
2023-03-25 18:48:56,140 : [INFO]  ################ Batch 306: final global model evalution after 3 rounds ################
2023-03-25 18:48:57,845 : [INFO]  Batch 306: Training set : loss - 0.6281, accuracy - 0.6087, recall - 0.7609, AUC - 0.736, F1 - 0.6604, precision - 0.5833, training time - -11.0 seconds
2023-03-25 18:48:57,845 : [INFO]  Batch 306: Testing set : loss - 0.5966, accuracy - 0.6863, recall - 0.8333, AUC - 0.8056, F1 - 0.7265, precision - 0.6439
2023-03-25 18:48:57,864 : [INFO]  Batch 307 initialized 
2023-03-25 18:48:58,460 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:48:59,268 : [INFO]  ------------------------- Batch 307 training: round 1 -------------------------
2023-03-25 18:49:04,619 : [INFO]  ------------------------- Batch round 1, loss: 0.6134 -------------------------
2023-03-25 18:49:04,619 : [INFO]  ------------------------- Batch 307, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:04,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:04,656 : [INFO]  ------------------------- Batch 307 training: round 2 -------------------------
2023-03-25 18:49:07,386 : [INFO]  ------------------------- Batch round 2, loss: 0.615 -------------------------
2023-03-25 18:49:07,387 : [INFO]  ------------------------- Batch 307, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:07,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:07,572 : [INFO]  ------------------------- Batch 307 training: round 3 -------------------------
2023-03-25 18:49:10,276 : [INFO]  ------------------------- Batch round 3, loss: 0.61 -------------------------
2023-03-25 18:49:10,276 : [INFO]  ------------------------- Batch 307, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:10,293 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:10,297 : [INFO]  Batch number 307 model fetched from the server
2023-03-25 18:49:10,297 : [INFO]  ################ Batch 307: final global model evalution after 3 rounds ################
2023-03-25 18:49:12,028 : [INFO]  Batch 307: Training set : loss - 0.6218, accuracy - 0.625, recall - 0.7826, AUC - 0.7629, F1 - 0.6761, precision - 0.595, training time - -11.0 seconds
2023-03-25 18:49:12,028 : [INFO]  Batch 307: Testing set : loss - 0.597, accuracy - 0.6863, recall - 0.7647, AUC - 0.7821, F1 - 0.7091, precision - 0.661
2023-03-25 18:49:12,042 : [INFO]  Batch 308 initialized 
2023-03-25 18:49:12,626 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:13,407 : [INFO]  ------------------------- Batch 308 training: round 1 -------------------------
2023-03-25 18:49:18,499 : [INFO]  ------------------------- Batch round 1, loss: 0.5987 -------------------------
2023-03-25 18:49:18,500 : [INFO]  ------------------------- Batch 308, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:18,515 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:18,518 : [INFO]  ------------------------- Batch 308 training: round 2 -------------------------
2023-03-25 18:49:21,113 : [INFO]  ------------------------- Batch round 2, loss: 0.6068 -------------------------
2023-03-25 18:49:21,113 : [INFO]  ------------------------- Batch 308, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:21,128 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:21,132 : [INFO]  ------------------------- Batch 308 training: round 3 -------------------------
2023-03-25 18:49:23,999 : [INFO]  ------------------------- Batch round 3, loss: 0.6026 -------------------------
2023-03-25 18:49:24,000 : [INFO]  ------------------------- Batch 308, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:24,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:24,042 : [INFO]  Batch number 308 model fetched from the server
2023-03-25 18:49:24,043 : [INFO]  ################ Batch 308: final global model evalution after 3 rounds ################
2023-03-25 18:49:25,756 : [INFO]  Batch 308: Training set : loss - 0.6119, accuracy - 0.6739, recall - 0.7935, AUC - 0.7693, F1 - 0.7087, precision - 0.6404, training time - -11.0 seconds
2023-03-25 18:49:25,756 : [INFO]  Batch 308: Testing set : loss - 0.6148, accuracy - 0.6569, recall - 0.7549, AUC - 0.754, F1 - 0.6875, precision - 0.6311
2023-03-25 18:49:25,769 : [INFO]  Batch 309 initialized 
2023-03-25 18:49:26,376 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:27,203 : [INFO]  ------------------------- Batch 309 training: round 1 -------------------------
2023-03-25 18:49:32,456 : [INFO]  ------------------------- Batch round 1, loss: 0.6322 -------------------------
2023-03-25 18:49:32,456 : [INFO]  ------------------------- Batch 309, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:32,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:32,488 : [INFO]  ------------------------- Batch 309 training: round 2 -------------------------
2023-03-25 18:49:35,198 : [INFO]  ------------------------- Batch round 2, loss: 0.6339 -------------------------
2023-03-25 18:49:35,198 : [INFO]  ------------------------- Batch 309, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:35,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:35,218 : [INFO]  ------------------------- Batch 309 training: round 3 -------------------------
2023-03-25 18:49:37,843 : [INFO]  ------------------------- Batch round 3, loss: 0.629 -------------------------
2023-03-25 18:49:37,843 : [INFO]  ------------------------- Batch 309, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:37,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:37,868 : [INFO]  Batch number 309 model fetched from the server
2023-03-25 18:49:37,868 : [INFO]  ################ Batch 309: final global model evalution after 3 rounds ################
2023-03-25 18:49:39,564 : [INFO]  Batch 309: Training set : loss - 0.6462, accuracy - 0.6087, recall - 0.7391, AUC - 0.6921, F1 - 0.6538, precision - 0.5862, training time - -11.0 seconds
2023-03-25 18:49:39,565 : [INFO]  Batch 309: Testing set : loss - 0.6179, accuracy - 0.6618, recall - 0.7941, AUC - 0.7619, F1 - 0.7013, precision - 0.6279
2023-03-25 18:49:39,577 : [INFO]  Batch 310 initialized 
2023-03-25 18:49:40,164 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:40,968 : [INFO]  ------------------------- Batch 310 training: round 1 -------------------------
2023-03-25 18:49:46,195 : [INFO]  ------------------------- Batch round 1, loss: 0.5945 -------------------------
2023-03-25 18:49:46,195 : [INFO]  ------------------------- Batch 310, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:46,210 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:46,213 : [INFO]  ------------------------- Batch 310 training: round 2 -------------------------
2023-03-25 18:49:48,842 : [INFO]  ------------------------- Batch round 2, loss: 0.6004 -------------------------
2023-03-25 18:49:48,842 : [INFO]  ------------------------- Batch 310, round 2: Sent local model to the server -------------------------
2023-03-25 18:49:48,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:48,883 : [INFO]  ------------------------- Batch 310 training: round 3 -------------------------
2023-03-25 18:49:51,462 : [INFO]  ------------------------- Batch round 3, loss: 0.5971 -------------------------
2023-03-25 18:49:51,462 : [INFO]  ------------------------- Batch 310, round 3: Sent local model to the server -------------------------
2023-03-25 18:49:51,478 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:51,481 : [INFO]  Batch number 310 model fetched from the server
2023-03-25 18:49:51,481 : [INFO]  ################ Batch 310: final global model evalution after 3 rounds ################
2023-03-25 18:49:53,187 : [INFO]  Batch 310: Training set : loss - 0.6055, accuracy - 0.6522, recall - 0.8478, AUC - 0.7952, F1 - 0.7091, precision - 0.6094, training time - -11.0 seconds
2023-03-25 18:49:53,187 : [INFO]  Batch 310: Testing set : loss - 0.6226, accuracy - 0.6373, recall - 0.7745, AUC - 0.7529, F1 - 0.681, precision - 0.6077
2023-03-25 18:49:53,205 : [INFO]  Batch 311 initialized 
2023-03-25 18:49:53,808 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:49:54,618 : [INFO]  ------------------------- Batch 311 training: round 1 -------------------------
2023-03-25 18:49:59,836 : [INFO]  ------------------------- Batch round 1, loss: 0.5736 -------------------------
2023-03-25 18:49:59,836 : [INFO]  ------------------------- Batch 311, round 1: Sent local model to the server -------------------------
2023-03-25 18:49:59,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:49:59,888 : [INFO]  ------------------------- Batch 311 training: round 2 -------------------------
2023-03-25 18:50:02,421 : [INFO]  ------------------------- Batch round 2, loss: 0.5764 -------------------------
2023-03-25 18:50:02,421 : [INFO]  ------------------------- Batch 311, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:02,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:02,529 : [INFO]  ------------------------- Batch 311 training: round 3 -------------------------
2023-03-25 18:50:05,119 : [INFO]  ------------------------- Batch round 3, loss: 0.5785 -------------------------
2023-03-25 18:50:05,120 : [INFO]  ------------------------- Batch 311, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:05,154 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:05,157 : [INFO]  Batch number 311 model fetched from the server
2023-03-25 18:50:05,158 : [INFO]  ################ Batch 311: final global model evalution after 3 rounds ################
2023-03-25 18:50:06,794 : [INFO]  Batch 311: Training set : loss - 0.5765, accuracy - 0.7283, recall - 0.8152, AUC - 0.8313, F1 - 0.75, precision - 0.6944, training time - -11.0 seconds
2023-03-25 18:50:06,794 : [INFO]  Batch 311: Testing set : loss - 0.6178, accuracy - 0.6422, recall - 0.8137, AUC - 0.7661, F1 - 0.6946, precision - 0.6058
2023-03-25 18:50:06,811 : [INFO]  Batch 312 initialized 
2023-03-25 18:50:07,381 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:08,180 : [INFO]  ------------------------- Batch 312 training: round 1 -------------------------
2023-03-25 18:50:13,352 : [INFO]  ------------------------- Batch round 1, loss: 0.5989 -------------------------
2023-03-25 18:50:13,352 : [INFO]  ------------------------- Batch 312, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:13,369 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:13,371 : [INFO]  ------------------------- Batch 312 training: round 2 -------------------------
2023-03-25 18:50:15,965 : [INFO]  ------------------------- Batch round 2, loss: 0.593 -------------------------
2023-03-25 18:50:15,965 : [INFO]  ------------------------- Batch 312, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:15,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:15,988 : [INFO]  ------------------------- Batch 312 training: round 3 -------------------------
2023-03-25 18:50:18,642 : [INFO]  ------------------------- Batch round 3, loss: 0.597 -------------------------
2023-03-25 18:50:18,642 : [INFO]  ------------------------- Batch 312, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:18,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:18,671 : [INFO]  Batch number 312 model fetched from the server
2023-03-25 18:50:18,672 : [INFO]  ################ Batch 312: final global model evalution after 3 rounds ################
2023-03-25 18:50:20,374 : [INFO]  Batch 312: Training set : loss - 0.6057, accuracy - 0.6739, recall - 0.837, AUC - 0.7895, F1 - 0.7196, precision - 0.6311, training time - -10.0 seconds
2023-03-25 18:50:20,374 : [INFO]  Batch 312: Testing set : loss - 0.6415, accuracy - 0.598, recall - 0.7157, AUC - 0.6973, F1 - 0.6404, precision - 0.5794
2023-03-25 18:50:20,384 : [INFO]  Batch 313 initialized 
2023-03-25 18:50:20,973 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:21,789 : [INFO]  ------------------------- Batch 313 training: round 1 -------------------------
2023-03-25 18:50:27,030 : [INFO]  ------------------------- Batch round 1, loss: 0.5862 -------------------------
2023-03-25 18:50:27,031 : [INFO]  ------------------------- Batch 313, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:27,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:27,051 : [INFO]  ------------------------- Batch 313 training: round 2 -------------------------
2023-03-25 18:50:29,647 : [INFO]  ------------------------- Batch round 2, loss: 0.5744 -------------------------
2023-03-25 18:50:29,647 : [INFO]  ------------------------- Batch 313, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:29,666 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:29,669 : [INFO]  ------------------------- Batch 313 training: round 3 -------------------------
2023-03-25 18:50:32,345 : [INFO]  ------------------------- Batch round 3, loss: 0.5759 -------------------------
2023-03-25 18:50:32,345 : [INFO]  ------------------------- Batch 313, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:32,361 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:32,364 : [INFO]  Batch number 313 model fetched from the server
2023-03-25 18:50:32,364 : [INFO]  ################ Batch 313: final global model evalution after 3 rounds ################
2023-03-25 18:50:34,165 : [INFO]  Batch 313: Training set : loss - 0.5861, accuracy - 0.6576, recall - 0.7609, AUC - 0.8044, F1 - 0.6897, precision - 0.6306, training time - -11.0 seconds
2023-03-25 18:50:34,165 : [INFO]  Batch 313: Testing set : loss - 0.6155, accuracy - 0.6569, recall - 0.7745, AUC - 0.7587, F1 - 0.693, precision - 0.627
2023-03-25 18:50:34,179 : [INFO]  Batch 314 initialized 
2023-03-25 18:50:34,777 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:35,590 : [INFO]  ------------------------- Batch 314 training: round 1 -------------------------
2023-03-25 18:50:40,779 : [INFO]  ------------------------- Batch round 1, loss: 0.6143 -------------------------
2023-03-25 18:50:40,779 : [INFO]  ------------------------- Batch 314, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:40,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:40,807 : [INFO]  ------------------------- Batch 314 training: round 2 -------------------------
2023-03-25 18:50:43,408 : [INFO]  ------------------------- Batch round 2, loss: 0.6132 -------------------------
2023-03-25 18:50:43,408 : [INFO]  ------------------------- Batch 314, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:43,444 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:43,447 : [INFO]  ------------------------- Batch 314 training: round 3 -------------------------
2023-03-25 18:50:46,049 : [INFO]  ------------------------- Batch round 3, loss: 0.604 -------------------------
2023-03-25 18:50:46,050 : [INFO]  ------------------------- Batch 314, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:46,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:46,119 : [INFO]  Batch number 314 model fetched from the server
2023-03-25 18:50:46,119 : [INFO]  ################ Batch 314: final global model evalution after 3 rounds ################
2023-03-25 18:50:48,084 : [INFO]  Batch 314: Training set : loss - 0.6126, accuracy - 0.6739, recall - 0.8043, AUC - 0.7681, F1 - 0.7115, precision - 0.6379, training time - -11.0 seconds
2023-03-25 18:50:48,084 : [INFO]  Batch 314: Testing set : loss - 0.6135, accuracy - 0.6618, recall - 0.7549, AUC - 0.7572, F1 - 0.6906, precision - 0.6364
2023-03-25 18:50:48,099 : [INFO]  Batch 315 initialized 
2023-03-25 18:50:48,706 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:50:49,429 : [INFO]  ------------------------- Batch 315 training: round 1 -------------------------
2023-03-25 18:50:54,561 : [INFO]  ------------------------- Batch round 1, loss: 0.6061 -------------------------
2023-03-25 18:50:54,561 : [INFO]  ------------------------- Batch 315, round 1: Sent local model to the server -------------------------
2023-03-25 18:50:54,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:54,579 : [INFO]  ------------------------- Batch 315 training: round 2 -------------------------
2023-03-25 18:50:57,213 : [INFO]  ------------------------- Batch round 2, loss: 0.6084 -------------------------
2023-03-25 18:50:57,213 : [INFO]  ------------------------- Batch 315, round 2: Sent local model to the server -------------------------
2023-03-25 18:50:57,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:57,234 : [INFO]  ------------------------- Batch 315 training: round 3 -------------------------
2023-03-25 18:50:59,830 : [INFO]  ------------------------- Batch round 3, loss: 0.6058 -------------------------
2023-03-25 18:50:59,830 : [INFO]  ------------------------- Batch 315, round 3: Sent local model to the server -------------------------
2023-03-25 18:50:59,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:50:59,854 : [INFO]  Batch number 315 model fetched from the server
2023-03-25 18:50:59,854 : [INFO]  ################ Batch 315: final global model evalution after 3 rounds ################
2023-03-25 18:51:01,540 : [INFO]  Batch 315: Training set : loss - 0.6185, accuracy - 0.6739, recall - 0.8261, AUC - 0.7583, F1 - 0.717, precision - 0.6333, training time - -10.0 seconds
2023-03-25 18:51:01,541 : [INFO]  Batch 315: Testing set : loss - 0.5925, accuracy - 0.6961, recall - 0.8431, AUC - 0.8176, F1 - 0.735, precision - 0.6515
2023-03-25 18:51:01,553 : [INFO]  Batch 316 initialized 
2023-03-25 18:51:02,126 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:02,953 : [INFO]  ------------------------- Batch 316 training: round 1 -------------------------
2023-03-25 18:51:08,041 : [INFO]  ------------------------- Batch round 1, loss: 0.594 -------------------------
2023-03-25 18:51:08,041 : [INFO]  ------------------------- Batch 316, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:08,183 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:08,185 : [INFO]  ------------------------- Batch 316 training: round 2 -------------------------
2023-03-25 18:51:10,727 : [INFO]  ------------------------- Batch round 2, loss: 0.5946 -------------------------
2023-03-25 18:51:10,728 : [INFO]  ------------------------- Batch 316, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:10,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:10,815 : [INFO]  ------------------------- Batch 316 training: round 3 -------------------------
2023-03-25 18:51:13,461 : [INFO]  ------------------------- Batch round 3, loss: 0.5974 -------------------------
2023-03-25 18:51:13,462 : [INFO]  ------------------------- Batch 316, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:13,549 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:13,556 : [INFO]  Batch number 316 model fetched from the server
2023-03-25 18:51:13,557 : [INFO]  ################ Batch 316: final global model evalution after 3 rounds ################
2023-03-25 18:51:15,224 : [INFO]  Batch 316: Training set : loss - 0.6067, accuracy - 0.6739, recall - 0.7609, AUC - 0.7658, F1 - 0.7, precision - 0.6481, training time - -11.0 seconds
2023-03-25 18:51:15,225 : [INFO]  Batch 316: Testing set : loss - 0.6148, accuracy - 0.6618, recall - 0.7843, AUC - 0.7573, F1 - 0.6987, precision - 0.6299
2023-03-25 18:51:15,251 : [INFO]  Batch 317 initialized 
2023-03-25 18:51:15,846 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:16,689 : [INFO]  ------------------------- Batch 317 training: round 1 -------------------------
2023-03-25 18:51:21,861 : [INFO]  ------------------------- Batch round 1, loss: 0.6031 -------------------------
2023-03-25 18:51:21,862 : [INFO]  ------------------------- Batch 317, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:21,889 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:21,892 : [INFO]  ------------------------- Batch 317 training: round 2 -------------------------
2023-03-25 18:51:24,653 : [INFO]  ------------------------- Batch round 2, loss: 0.6029 -------------------------
2023-03-25 18:51:24,653 : [INFO]  ------------------------- Batch 317, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:24,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:24,671 : [INFO]  ------------------------- Batch 317 training: round 3 -------------------------
2023-03-25 18:51:27,186 : [INFO]  ------------------------- Batch round 3, loss: 0.6007 -------------------------
2023-03-25 18:51:27,187 : [INFO]  ------------------------- Batch 317, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:27,202 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:27,204 : [INFO]  Batch number 317 model fetched from the server
2023-03-25 18:51:27,205 : [INFO]  ################ Batch 317: final global model evalution after 3 rounds ################
2023-03-25 18:51:28,284 : [INFO]  Batch 317: Training set : loss - 0.6168, accuracy - 0.6413, recall - 0.8043, AUC - 0.7712, F1 - 0.6916, precision - 0.6066, training time - -11.0 seconds
2023-03-25 18:51:28,284 : [INFO]  Batch 317: Testing set : loss - 0.5811, accuracy - 0.6961, recall - 0.8922, AUC - 0.8588, F1 - 0.7459, precision - 0.6408
2023-03-25 18:51:28,294 : [INFO]  Batch 318 initialized 
2023-03-25 18:51:28,652 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:29,477 : [INFO]  ------------------------- Batch 318 training: round 1 -------------------------
2023-03-25 18:51:33,685 : [INFO]  ------------------------- Batch round 1, loss: 0.5853 -------------------------
2023-03-25 18:51:33,690 : [INFO]  ------------------------- Batch 318, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:33,705 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:33,707 : [INFO]  ------------------------- Batch 318 training: round 2 -------------------------
2023-03-25 18:51:35,415 : [INFO]  ------------------------- Batch round 2, loss: 0.5832 -------------------------
2023-03-25 18:51:35,415 : [INFO]  ------------------------- Batch 318, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:35,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:35,450 : [INFO]  ------------------------- Batch 318 training: round 3 -------------------------
2023-03-25 18:51:37,140 : [INFO]  ------------------------- Batch round 3, loss: 0.5821 -------------------------
2023-03-25 18:51:37,140 : [INFO]  ------------------------- Batch 318, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:37,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:37,190 : [INFO]  Batch number 318 model fetched from the server
2023-03-25 18:51:37,190 : [INFO]  ################ Batch 318: final global model evalution after 3 rounds ################
2023-03-25 18:51:38,225 : [INFO]  Batch 318: Training set : loss - 0.5858, accuracy - 0.6957, recall - 0.837, AUC - 0.8273, F1 - 0.7333, precision - 0.6525, training time - -8.0 seconds
2023-03-25 18:51:38,225 : [INFO]  Batch 318: Testing set : loss - 0.6118, accuracy - 0.6422, recall - 0.7647, AUC - 0.7649, F1 - 0.6812, precision - 0.6142
2023-03-25 18:51:38,244 : [INFO]  Batch 319 initialized 
2023-03-25 18:51:38,612 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:39,504 : [INFO]  ------------------------- Batch 319 training: round 1 -------------------------
2023-03-25 18:51:42,798 : [INFO]  ------------------------- Batch round 1, loss: 0.5931 -------------------------
2023-03-25 18:51:42,798 : [INFO]  ------------------------- Batch 319, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:42,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:42,838 : [INFO]  ------------------------- Batch 319 training: round 2 -------------------------
2023-03-25 18:51:44,536 : [INFO]  ------------------------- Batch round 2, loss: 0.5992 -------------------------
2023-03-25 18:51:44,536 : [INFO]  ------------------------- Batch 319, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:44,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:44,550 : [INFO]  ------------------------- Batch 319 training: round 3 -------------------------
2023-03-25 18:51:46,202 : [INFO]  ------------------------- Batch round 3, loss: 0.5937 -------------------------
2023-03-25 18:51:46,202 : [INFO]  ------------------------- Batch 319, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:46,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:46,217 : [INFO]  Batch number 319 model fetched from the server
2023-03-25 18:51:46,217 : [INFO]  ################ Batch 319: final global model evalution after 3 rounds ################
2023-03-25 18:51:47,260 : [INFO]  Batch 319: Training set : loss - 0.6062, accuracy - 0.6685, recall - 0.75, AUC - 0.774, F1 - 0.6935, precision - 0.6449, training time - -7.0 seconds
2023-03-25 18:51:47,261 : [INFO]  Batch 319: Testing set : loss - 0.6331, accuracy - 0.6373, recall - 0.7843, AUC - 0.7228, F1 - 0.6838, precision - 0.6061
2023-03-25 18:51:47,267 : [INFO]  Batch 320 initialized 
2023-03-25 18:51:47,688 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:48,508 : [INFO]  ------------------------- Batch 320 training: round 1 -------------------------
2023-03-25 18:51:51,886 : [INFO]  ------------------------- Batch round 1, loss: 0.6116 -------------------------
2023-03-25 18:51:51,886 : [INFO]  ------------------------- Batch 320, round 1: Sent local model to the server -------------------------
2023-03-25 18:51:51,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:51,898 : [INFO]  ------------------------- Batch 320 training: round 2 -------------------------
2023-03-25 18:51:53,554 : [INFO]  ------------------------- Batch round 2, loss: 0.6096 -------------------------
2023-03-25 18:51:53,554 : [INFO]  ------------------------- Batch 320, round 2: Sent local model to the server -------------------------
2023-03-25 18:51:53,606 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:53,607 : [INFO]  ------------------------- Batch 320 training: round 3 -------------------------
2023-03-25 18:51:55,309 : [INFO]  ------------------------- Batch round 3, loss: 0.6115 -------------------------
2023-03-25 18:51:55,309 : [INFO]  ------------------------- Batch 320, round 3: Sent local model to the server -------------------------
2023-03-25 18:51:55,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:51:55,328 : [INFO]  Batch number 320 model fetched from the server
2023-03-25 18:51:55,329 : [INFO]  ################ Batch 320: final global model evalution after 3 rounds ################
2023-03-25 18:51:56,368 : [INFO]  Batch 320: Training set : loss - 0.6164, accuracy - 0.6576, recall - 0.7935, AUC - 0.7606, F1 - 0.6986, precision - 0.6239, training time - -7.0 seconds
2023-03-25 18:51:56,369 : [INFO]  Batch 320: Testing set : loss - 0.6124, accuracy - 0.652, recall - 0.7843, AUC - 0.7634, F1 - 0.6926, precision - 0.6202
2023-03-25 18:51:56,381 : [INFO]  Batch 321 initialized 
2023-03-25 18:51:56,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:51:57,579 : [INFO]  ------------------------- Batch 321 training: round 1 -------------------------
2023-03-25 18:52:00,823 : [INFO]  ------------------------- Batch round 1, loss: 0.6112 -------------------------
2023-03-25 18:52:00,823 : [INFO]  ------------------------- Batch 321, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:00,906 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:00,908 : [INFO]  ------------------------- Batch 321 training: round 2 -------------------------
2023-03-25 18:52:02,490 : [INFO]  ------------------------- Batch round 2, loss: 0.6061 -------------------------
2023-03-25 18:52:02,490 : [INFO]  ------------------------- Batch 321, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:02,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:02,521 : [INFO]  ------------------------- Batch 321 training: round 3 -------------------------
2023-03-25 18:52:04,151 : [INFO]  ------------------------- Batch round 3, loss: 0.606 -------------------------
2023-03-25 18:52:04,151 : [INFO]  ------------------------- Batch 321, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:04,253 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:04,254 : [INFO]  Batch number 321 model fetched from the server
2023-03-25 18:52:04,255 : [INFO]  ################ Batch 321: final global model evalution after 3 rounds ################
2023-03-25 18:52:05,453 : [INFO]  Batch 321: Training set : loss - 0.6227, accuracy - 0.6467, recall - 0.7935, AUC - 0.7515, F1 - 0.6919, precision - 0.6134, training time - -7.0 seconds
2023-03-25 18:52:05,453 : [INFO]  Batch 321: Testing set : loss - 0.6136, accuracy - 0.598, recall - 0.7451, AUC - 0.7597, F1 - 0.6496, precision - 0.5758
2023-03-25 18:52:05,465 : [INFO]  Batch 322 initialized 
2023-03-25 18:52:05,896 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:06,734 : [INFO]  ------------------------- Batch 322 training: round 1 -------------------------
2023-03-25 18:52:10,362 : [INFO]  ------------------------- Batch round 1, loss: 0.6226 -------------------------
2023-03-25 18:52:10,362 : [INFO]  ------------------------- Batch 322, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:10,375 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:10,377 : [INFO]  ------------------------- Batch 322 training: round 2 -------------------------
2023-03-25 18:52:12,316 : [INFO]  ------------------------- Batch round 2, loss: 0.62 -------------------------
2023-03-25 18:52:12,316 : [INFO]  ------------------------- Batch 322, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:12,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:12,331 : [INFO]  ------------------------- Batch 322 training: round 3 -------------------------
2023-03-25 18:52:14,256 : [INFO]  ------------------------- Batch round 3, loss: 0.61 -------------------------
2023-03-25 18:52:14,256 : [INFO]  ------------------------- Batch 322, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:14,270 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:14,273 : [INFO]  Batch number 322 model fetched from the server
2023-03-25 18:52:14,273 : [INFO]  ################ Batch 322: final global model evalution after 3 rounds ################
2023-03-25 18:52:15,472 : [INFO]  Batch 322: Training set : loss - 0.629, accuracy - 0.6087, recall - 0.7174, AUC - 0.7306, F1 - 0.6471, precision - 0.5893, training time - -8.0 seconds
2023-03-25 18:52:15,472 : [INFO]  Batch 322: Testing set : loss - 0.6088, accuracy - 0.6716, recall - 0.8529, AUC - 0.793, F1 - 0.722, precision - 0.6259
2023-03-25 18:52:15,481 : [INFO]  Batch 323 initialized 
2023-03-25 18:52:15,917 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:16,745 : [INFO]  ------------------------- Batch 323 training: round 1 -------------------------
2023-03-25 18:52:20,516 : [INFO]  ------------------------- Batch round 1, loss: 0.6267 -------------------------
2023-03-25 18:52:20,516 : [INFO]  ------------------------- Batch 323, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:20,532 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:20,534 : [INFO]  ------------------------- Batch 323 training: round 2 -------------------------
2023-03-25 18:52:22,424 : [INFO]  ------------------------- Batch round 2, loss: 0.6233 -------------------------
2023-03-25 18:52:22,424 : [INFO]  ------------------------- Batch 323, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:22,439 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:22,441 : [INFO]  ------------------------- Batch 323 training: round 3 -------------------------
2023-03-25 18:52:24,424 : [INFO]  ------------------------- Batch round 3, loss: 0.6238 -------------------------
2023-03-25 18:52:24,424 : [INFO]  ------------------------- Batch 323, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:24,437 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:24,439 : [INFO]  Batch number 323 model fetched from the server
2023-03-25 18:52:24,439 : [INFO]  ################ Batch 323: final global model evalution after 3 rounds ################
2023-03-25 18:52:25,697 : [INFO]  Batch 323: Training set : loss - 0.6333, accuracy - 0.625, recall - 0.7283, AUC - 0.7261, F1 - 0.6601, precision - 0.6036, training time - -8.0 seconds
2023-03-25 18:52:25,697 : [INFO]  Batch 323: Testing set : loss - 0.619, accuracy - 0.6422, recall - 0.7647, AUC - 0.7551, F1 - 0.6812, precision - 0.6142
2023-03-25 18:52:25,709 : [INFO]  Batch 324 initialized 
2023-03-25 18:52:26,170 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:27,039 : [INFO]  ------------------------- Batch 324 training: round 1 -------------------------
2023-03-25 18:52:30,712 : [INFO]  ------------------------- Batch round 1, loss: 0.5772 -------------------------
2023-03-25 18:52:30,712 : [INFO]  ------------------------- Batch 324, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:30,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:30,743 : [INFO]  ------------------------- Batch 324 training: round 2 -------------------------
2023-03-25 18:52:32,717 : [INFO]  ------------------------- Batch round 2, loss: 0.582 -------------------------
2023-03-25 18:52:32,718 : [INFO]  ------------------------- Batch 324, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:32,731 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:32,733 : [INFO]  ------------------------- Batch 324 training: round 3 -------------------------
2023-03-25 18:52:34,642 : [INFO]  ------------------------- Batch round 3, loss: 0.5778 -------------------------
2023-03-25 18:52:34,643 : [INFO]  ------------------------- Batch 324, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:34,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:34,658 : [INFO]  Batch number 324 model fetched from the server
2023-03-25 18:52:34,658 : [INFO]  ################ Batch 324: final global model evalution after 3 rounds ################
2023-03-25 18:52:35,946 : [INFO]  Batch 324: Training set : loss - 0.5886, accuracy - 0.6793, recall - 0.8261, AUC - 0.8179, F1 - 0.7204, precision - 0.6387, training time - -8.0 seconds
2023-03-25 18:52:35,946 : [INFO]  Batch 324: Testing set : loss - 0.5964, accuracy - 0.6716, recall - 0.8039, AUC - 0.7908, F1 - 0.71, precision - 0.6357
2023-03-25 18:52:35,956 : [INFO]  Batch 325 initialized 
2023-03-25 18:52:36,402 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:37,229 : [INFO]  ------------------------- Batch 325 training: round 1 -------------------------
2023-03-25 18:52:40,826 : [INFO]  ------------------------- Batch round 1, loss: 0.6279 -------------------------
2023-03-25 18:52:40,826 : [INFO]  ------------------------- Batch 325, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:40,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:40,842 : [INFO]  ------------------------- Batch 325 training: round 2 -------------------------
2023-03-25 18:52:42,689 : [INFO]  ------------------------- Batch round 2, loss: 0.6222 -------------------------
2023-03-25 18:52:42,690 : [INFO]  ------------------------- Batch 325, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:42,704 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:42,706 : [INFO]  ------------------------- Batch 325 training: round 3 -------------------------
2023-03-25 18:52:44,541 : [INFO]  ------------------------- Batch round 3, loss: 0.6196 -------------------------
2023-03-25 18:52:44,541 : [INFO]  ------------------------- Batch 325, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:44,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:44,558 : [INFO]  Batch number 325 model fetched from the server
2023-03-25 18:52:44,558 : [INFO]  ################ Batch 325: final global model evalution after 3 rounds ################
2023-03-25 18:52:45,822 : [INFO]  Batch 325: Training set : loss - 0.6391, accuracy - 0.625, recall - 0.7826, AUC - 0.7253, F1 - 0.6761, precision - 0.595, training time - -7.0 seconds
2023-03-25 18:52:45,822 : [INFO]  Batch 325: Testing set : loss - 0.6151, accuracy - 0.6373, recall - 0.7843, AUC - 0.7704, F1 - 0.6838, precision - 0.6061
2023-03-25 18:52:45,829 : [INFO]  Batch 326 initialized 
2023-03-25 18:52:46,275 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:47,112 : [INFO]  ------------------------- Batch 326 training: round 1 -------------------------
2023-03-25 18:52:50,750 : [INFO]  ------------------------- Batch round 1, loss: 0.6104 -------------------------
2023-03-25 18:52:50,750 : [INFO]  ------------------------- Batch 326, round 1: Sent local model to the server -------------------------
2023-03-25 18:52:50,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:50,804 : [INFO]  ------------------------- Batch 326 training: round 2 -------------------------
2023-03-25 18:52:52,792 : [INFO]  ------------------------- Batch round 2, loss: 0.605 -------------------------
2023-03-25 18:52:52,792 : [INFO]  ------------------------- Batch 326, round 2: Sent local model to the server -------------------------
2023-03-25 18:52:52,815 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:52,818 : [INFO]  ------------------------- Batch 326 training: round 3 -------------------------
2023-03-25 18:52:54,727 : [INFO]  ------------------------- Batch round 3, loss: 0.6105 -------------------------
2023-03-25 18:52:54,728 : [INFO]  ------------------------- Batch 326, round 3: Sent local model to the server -------------------------
2023-03-25 18:52:54,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:52:54,772 : [INFO]  Batch number 326 model fetched from the server
2023-03-25 18:52:54,773 : [INFO]  ################ Batch 326: final global model evalution after 3 rounds ################
2023-03-25 18:52:56,083 : [INFO]  Batch 326: Training set : loss - 0.615, accuracy - 0.6304, recall - 0.75, AUC - 0.7556, F1 - 0.6699, precision - 0.6053, training time - -8.0 seconds
2023-03-25 18:52:56,083 : [INFO]  Batch 326: Testing set : loss - 0.6077, accuracy - 0.6961, recall - 0.7843, AUC - 0.7697, F1 - 0.7207, precision - 0.6667
2023-03-25 18:52:56,090 : [INFO]  Batch 327 initialized 
2023-03-25 18:52:56,539 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:52:57,379 : [INFO]  ------------------------- Batch 327 training: round 1 -------------------------
2023-03-25 18:53:01,023 : [INFO]  ------------------------- Batch round 1, loss: 0.5911 -------------------------
2023-03-25 18:53:01,023 : [INFO]  ------------------------- Batch 327, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:01,085 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:01,090 : [INFO]  ------------------------- Batch 327 training: round 2 -------------------------
2023-03-25 18:53:02,981 : [INFO]  ------------------------- Batch round 2, loss: 0.5899 -------------------------
2023-03-25 18:53:02,982 : [INFO]  ------------------------- Batch 327, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:03,044 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:03,046 : [INFO]  ------------------------- Batch 327 training: round 3 -------------------------
2023-03-25 18:53:05,022 : [INFO]  ------------------------- Batch round 3, loss: 0.5891 -------------------------
2023-03-25 18:53:05,022 : [INFO]  ------------------------- Batch 327, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:05,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:05,129 : [INFO]  Batch number 327 model fetched from the server
2023-03-25 18:53:05,129 : [INFO]  ################ Batch 327: final global model evalution after 3 rounds ################
2023-03-25 18:53:06,357 : [INFO]  Batch 327: Training set : loss - 0.6007, accuracy - 0.6576, recall - 0.7826, AUC - 0.7868, F1 - 0.6957, precision - 0.6261, training time - -8.0 seconds
2023-03-25 18:53:06,358 : [INFO]  Batch 327: Testing set : loss - 0.5928, accuracy - 0.6765, recall - 0.8039, AUC - 0.7948, F1 - 0.713, precision - 0.6406
2023-03-25 18:53:06,370 : [INFO]  Batch 328 initialized 
2023-03-25 18:53:06,849 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:07,693 : [INFO]  ------------------------- Batch 328 training: round 1 -------------------------
2023-03-25 18:53:11,402 : [INFO]  ------------------------- Batch round 1, loss: 0.6219 -------------------------
2023-03-25 18:53:11,403 : [INFO]  ------------------------- Batch 328, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:11,416 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:11,418 : [INFO]  ------------------------- Batch 328 training: round 2 -------------------------
2023-03-25 18:53:13,360 : [INFO]  ------------------------- Batch round 2, loss: 0.6111 -------------------------
2023-03-25 18:53:13,361 : [INFO]  ------------------------- Batch 328, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:13,375 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:13,377 : [INFO]  ------------------------- Batch 328 training: round 3 -------------------------
2023-03-25 18:53:15,310 : [INFO]  ------------------------- Batch round 3, loss: 0.6158 -------------------------
2023-03-25 18:53:15,310 : [INFO]  ------------------------- Batch 328, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:15,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:15,326 : [INFO]  Batch number 328 model fetched from the server
2023-03-25 18:53:15,326 : [INFO]  ################ Batch 328: final global model evalution after 3 rounds ################
2023-03-25 18:53:16,583 : [INFO]  Batch 328: Training set : loss - 0.6279, accuracy - 0.6304, recall - 0.7391, AUC - 0.7348, F1 - 0.6667, precision - 0.6071, training time - -8.0 seconds
2023-03-25 18:53:16,583 : [INFO]  Batch 328: Testing set : loss - 0.6334, accuracy - 0.6176, recall - 0.7451, AUC - 0.7304, F1 - 0.6609, precision - 0.5938
2023-03-25 18:53:16,590 : [INFO]  Batch 329 initialized 
2023-03-25 18:53:17,048 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:17,886 : [INFO]  ------------------------- Batch 329 training: round 1 -------------------------
2023-03-25 18:53:21,626 : [INFO]  ------------------------- Batch round 1, loss: 0.6179 -------------------------
2023-03-25 18:53:21,626 : [INFO]  ------------------------- Batch 329, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:21,639 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:21,641 : [INFO]  ------------------------- Batch 329 training: round 2 -------------------------
2023-03-25 18:53:23,635 : [INFO]  ------------------------- Batch round 2, loss: 0.6136 -------------------------
2023-03-25 18:53:23,636 : [INFO]  ------------------------- Batch 329, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:23,650 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:23,652 : [INFO]  ------------------------- Batch 329 training: round 3 -------------------------
2023-03-25 18:53:25,608 : [INFO]  ------------------------- Batch round 3, loss: 0.6116 -------------------------
2023-03-25 18:53:25,608 : [INFO]  ------------------------- Batch 329, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:25,622 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:25,624 : [INFO]  Batch number 329 model fetched from the server
2023-03-25 18:53:25,624 : [INFO]  ################ Batch 329: final global model evalution after 3 rounds ################
2023-03-25 18:53:26,906 : [INFO]  Batch 329: Training set : loss - 0.6353, accuracy - 0.5815, recall - 0.7935, AUC - 0.7438, F1 - 0.6547, precision - 0.5573, training time - -8.0 seconds
2023-03-25 18:53:26,906 : [INFO]  Batch 329: Testing set : loss - 0.5822, accuracy - 0.7157, recall - 0.8333, AUC - 0.8249, F1 - 0.7456, precision - 0.6746
2023-03-25 18:53:26,914 : [INFO]  Batch 330 initialized 
2023-03-25 18:53:27,356 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:28,189 : [INFO]  ------------------------- Batch 330 training: round 1 -------------------------
2023-03-25 18:53:31,898 : [INFO]  ------------------------- Batch round 1, loss: 0.6027 -------------------------
2023-03-25 18:53:31,898 : [INFO]  ------------------------- Batch 330, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:31,912 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:31,914 : [INFO]  ------------------------- Batch 330 training: round 2 -------------------------
2023-03-25 18:53:33,792 : [INFO]  ------------------------- Batch round 2, loss: 0.604 -------------------------
2023-03-25 18:53:33,792 : [INFO]  ------------------------- Batch 330, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:33,812 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:33,814 : [INFO]  ------------------------- Batch 330 training: round 3 -------------------------
2023-03-25 18:53:35,728 : [INFO]  ------------------------- Batch round 3, loss: 0.6007 -------------------------
2023-03-25 18:53:35,728 : [INFO]  ------------------------- Batch 330, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:35,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:35,754 : [INFO]  Batch number 330 model fetched from the server
2023-03-25 18:53:35,754 : [INFO]  ################ Batch 330: final global model evalution after 3 rounds ################
2023-03-25 18:53:36,974 : [INFO]  Batch 330: Training set : loss - 0.6129, accuracy - 0.6739, recall - 0.7826, AUC - 0.7626, F1 - 0.7059, precision - 0.6429, training time - -8.0 seconds
2023-03-25 18:53:36,974 : [INFO]  Batch 330: Testing set : loss - 0.6092, accuracy - 0.6667, recall - 0.7941, AUC - 0.7774, F1 - 0.7043, precision - 0.6328
2023-03-25 18:53:36,982 : [INFO]  Batch 331 initialized 
2023-03-25 18:53:37,438 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:38,304 : [INFO]  ------------------------- Batch 331 training: round 1 -------------------------
2023-03-25 18:53:41,824 : [INFO]  ------------------------- Batch round 1, loss: 0.5909 -------------------------
2023-03-25 18:53:41,824 : [INFO]  ------------------------- Batch 331, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:41,892 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:41,895 : [INFO]  ------------------------- Batch 331 training: round 2 -------------------------
2023-03-25 18:53:43,714 : [INFO]  ------------------------- Batch round 2, loss: 0.5896 -------------------------
2023-03-25 18:53:43,714 : [INFO]  ------------------------- Batch 331, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:44,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:44,101 : [INFO]  ------------------------- Batch 331 training: round 3 -------------------------
2023-03-25 18:53:45,871 : [INFO]  ------------------------- Batch round 3, loss: 0.5888 -------------------------
2023-03-25 18:53:45,871 : [INFO]  ------------------------- Batch 331, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:45,952 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:45,955 : [INFO]  Batch number 331 model fetched from the server
2023-03-25 18:53:45,955 : [INFO]  ################ Batch 331: final global model evalution after 3 rounds ################
2023-03-25 18:53:47,179 : [INFO]  Batch 331: Training set : loss - 0.5969, accuracy - 0.6576, recall - 0.8152, AUC - 0.8058, F1 - 0.7042, precision - 0.6198, training time - -8.0 seconds
2023-03-25 18:53:47,179 : [INFO]  Batch 331: Testing set : loss - 0.5899, accuracy - 0.6569, recall - 0.7255, AUC - 0.7851, F1 - 0.6789, precision - 0.6379
2023-03-25 18:53:47,199 : [INFO]  Batch 332 initialized 
2023-03-25 18:53:47,648 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:48,498 : [INFO]  ------------------------- Batch 332 training: round 1 -------------------------
2023-03-25 18:53:52,218 : [INFO]  ------------------------- Batch round 1, loss: 0.6215 -------------------------
2023-03-25 18:53:52,219 : [INFO]  ------------------------- Batch 332, round 1: Sent local model to the server -------------------------
2023-03-25 18:53:52,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:52,244 : [INFO]  ------------------------- Batch 332 training: round 2 -------------------------
2023-03-25 18:53:54,146 : [INFO]  ------------------------- Batch round 2, loss: 0.6245 -------------------------
2023-03-25 18:53:54,146 : [INFO]  ------------------------- Batch 332, round 2: Sent local model to the server -------------------------
2023-03-25 18:53:54,160 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:54,162 : [INFO]  ------------------------- Batch 332 training: round 3 -------------------------
2023-03-25 18:53:56,080 : [INFO]  ------------------------- Batch round 3, loss: 0.6137 -------------------------
2023-03-25 18:53:56,080 : [INFO]  ------------------------- Batch 332, round 3: Sent local model to the server -------------------------
2023-03-25 18:53:56,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:53:56,096 : [INFO]  Batch number 332 model fetched from the server
2023-03-25 18:53:56,096 : [INFO]  ################ Batch 332: final global model evalution after 3 rounds ################
2023-03-25 18:53:57,390 : [INFO]  Batch 332: Training set : loss - 0.629, accuracy - 0.625, recall - 0.7174, AUC - 0.7134, F1 - 0.6567, precision - 0.6055, training time - -8.0 seconds
2023-03-25 18:53:57,391 : [INFO]  Batch 332: Testing set : loss - 0.6228, accuracy - 0.6078, recall - 0.7353, AUC - 0.7564, F1 - 0.6522, precision - 0.5859
2023-03-25 18:53:57,407 : [INFO]  Batch 333 initialized 
2023-03-25 18:53:57,901 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:53:58,756 : [INFO]  ------------------------- Batch 333 training: round 1 -------------------------
2023-03-25 18:54:02,735 : [INFO]  ------------------------- Batch round 1, loss: 0.6002 -------------------------
2023-03-25 18:54:02,735 : [INFO]  ------------------------- Batch 333, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:02,748 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:02,750 : [INFO]  ------------------------- Batch 333 training: round 2 -------------------------
2023-03-25 18:54:04,615 : [INFO]  ------------------------- Batch round 2, loss: 0.5969 -------------------------
2023-03-25 18:54:04,615 : [INFO]  ------------------------- Batch 333, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:04,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:04,692 : [INFO]  ------------------------- Batch 333 training: round 3 -------------------------
2023-03-25 18:54:06,664 : [INFO]  ------------------------- Batch round 3, loss: 0.602 -------------------------
2023-03-25 18:54:06,664 : [INFO]  ------------------------- Batch 333, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:06,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:06,689 : [INFO]  Batch number 333 model fetched from the server
2023-03-25 18:54:06,689 : [INFO]  ################ Batch 333: final global model evalution after 3 rounds ################
2023-03-25 18:54:07,910 : [INFO]  Batch 333: Training set : loss - 0.6093, accuracy - 0.6467, recall - 0.7609, AUC - 0.7689, F1 - 0.6829, precision - 0.6195, training time - -8.0 seconds
2023-03-25 18:54:07,910 : [INFO]  Batch 333: Testing set : loss - 0.5865, accuracy - 0.6716, recall - 0.8039, AUC - 0.8178, F1 - 0.71, precision - 0.6357
2023-03-25 18:54:07,920 : [INFO]  Batch 334 initialized 
2023-03-25 18:54:08,370 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:09,213 : [INFO]  ------------------------- Batch 334 training: round 1 -------------------------
2023-03-25 18:54:12,781 : [INFO]  ------------------------- Batch round 1, loss: 0.6116 -------------------------
2023-03-25 18:54:12,781 : [INFO]  ------------------------- Batch 334, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:12,854 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:12,857 : [INFO]  ------------------------- Batch 334 training: round 2 -------------------------
2023-03-25 18:54:14,680 : [INFO]  ------------------------- Batch round 2, loss: 0.6108 -------------------------
2023-03-25 18:54:14,680 : [INFO]  ------------------------- Batch 334, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:14,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:14,754 : [INFO]  ------------------------- Batch 334 training: round 3 -------------------------
2023-03-25 18:54:16,582 : [INFO]  ------------------------- Batch round 3, loss: 0.6098 -------------------------
2023-03-25 18:54:16,582 : [INFO]  ------------------------- Batch 334, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:16,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:16,624 : [INFO]  Batch number 334 model fetched from the server
2023-03-25 18:54:16,624 : [INFO]  ################ Batch 334: final global model evalution after 3 rounds ################
2023-03-25 18:54:17,850 : [INFO]  Batch 334: Training set : loss - 0.6202, accuracy - 0.6304, recall - 0.7935, AUC - 0.776, F1 - 0.6822, precision - 0.5984, training time - -7.0 seconds
2023-03-25 18:54:17,850 : [INFO]  Batch 334: Testing set : loss - 0.6247, accuracy - 0.598, recall - 0.7647, AUC - 0.7552, F1 - 0.6555, precision - 0.5735
2023-03-25 18:54:17,865 : [INFO]  Batch 335 initialized 
2023-03-25 18:54:18,330 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:19,204 : [INFO]  ------------------------- Batch 335 training: round 1 -------------------------
2023-03-25 18:54:22,950 : [INFO]  ------------------------- Batch round 1, loss: 0.6083 -------------------------
2023-03-25 18:54:22,950 : [INFO]  ------------------------- Batch 335, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:22,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:22,970 : [INFO]  ------------------------- Batch 335 training: round 2 -------------------------
2023-03-25 18:54:25,062 : [INFO]  ------------------------- Batch round 2, loss: 0.6095 -------------------------
2023-03-25 18:54:25,062 : [INFO]  ------------------------- Batch 335, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:25,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:25,083 : [INFO]  ------------------------- Batch 335 training: round 3 -------------------------
2023-03-25 18:54:27,092 : [INFO]  ------------------------- Batch round 3, loss: 0.6086 -------------------------
2023-03-25 18:54:27,092 : [INFO]  ------------------------- Batch 335, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:27,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:27,110 : [INFO]  Batch number 335 model fetched from the server
2023-03-25 18:54:27,110 : [INFO]  ################ Batch 335: final global model evalution after 3 rounds ################
2023-03-25 18:54:28,348 : [INFO]  Batch 335: Training set : loss - 0.6171, accuracy - 0.6359, recall - 0.75, AUC - 0.76, F1 - 0.6732, precision - 0.6106, training time - -8.0 seconds
2023-03-25 18:54:28,348 : [INFO]  Batch 335: Testing set : loss - 0.5773, accuracy - 0.7157, recall - 0.8235, AUC - 0.8332, F1 - 0.7434, precision - 0.6774
2023-03-25 18:54:28,362 : [INFO]  Batch 336 initialized 
2023-03-25 18:54:28,811 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:29,665 : [INFO]  ------------------------- Batch 336 training: round 1 -------------------------
2023-03-25 18:54:33,246 : [INFO]  ------------------------- Batch round 1, loss: 0.6016 -------------------------
2023-03-25 18:54:33,246 : [INFO]  ------------------------- Batch 336, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:33,307 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:33,310 : [INFO]  ------------------------- Batch 336 training: round 2 -------------------------
2023-03-25 18:54:35,227 : [INFO]  ------------------------- Batch round 2, loss: 0.5945 -------------------------
2023-03-25 18:54:35,227 : [INFO]  ------------------------- Batch 336, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:35,241 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:35,243 : [INFO]  ------------------------- Batch 336 training: round 3 -------------------------
2023-03-25 18:54:37,219 : [INFO]  ------------------------- Batch round 3, loss: 0.5909 -------------------------
2023-03-25 18:54:37,219 : [INFO]  ------------------------- Batch 336, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:37,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:37,269 : [INFO]  Batch number 336 model fetched from the server
2023-03-25 18:54:37,269 : [INFO]  ################ Batch 336: final global model evalution after 3 rounds ################
2023-03-25 18:54:38,502 : [INFO]  Batch 336: Training set : loss - 0.6, accuracy - 0.6576, recall - 0.7391, AUC - 0.784, F1 - 0.6834, precision - 0.6355, training time - -8.0 seconds
2023-03-25 18:54:38,502 : [INFO]  Batch 336: Testing set : loss - 0.6062, accuracy - 0.6225, recall - 0.7451, AUC - 0.7687, F1 - 0.6638, precision - 0.5984
2023-03-25 18:54:38,539 : [INFO]  Batch 337 initialized 
2023-03-25 18:54:38,983 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:39,861 : [INFO]  ------------------------- Batch 337 training: round 1 -------------------------
2023-03-25 18:54:43,447 : [INFO]  ------------------------- Batch round 1, loss: 0.5998 -------------------------
2023-03-25 18:54:43,447 : [INFO]  ------------------------- Batch 337, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:43,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:43,486 : [INFO]  ------------------------- Batch 337 training: round 2 -------------------------
2023-03-25 18:54:45,374 : [INFO]  ------------------------- Batch round 2, loss: 0.5951 -------------------------
2023-03-25 18:54:45,374 : [INFO]  ------------------------- Batch 337, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:45,406 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:45,409 : [INFO]  ------------------------- Batch 337 training: round 3 -------------------------
2023-03-25 18:54:47,242 : [INFO]  ------------------------- Batch round 3, loss: 0.5989 -------------------------
2023-03-25 18:54:47,242 : [INFO]  ------------------------- Batch 337, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:47,305 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:47,307 : [INFO]  Batch number 337 model fetched from the server
2023-03-25 18:54:47,307 : [INFO]  ################ Batch 337: final global model evalution after 3 rounds ################
2023-03-25 18:54:48,530 : [INFO]  Batch 337: Training set : loss - 0.6078, accuracy - 0.625, recall - 0.7826, AUC - 0.7863, F1 - 0.6761, precision - 0.595, training time - -7.0 seconds
2023-03-25 18:54:48,530 : [INFO]  Batch 337: Testing set : loss - 0.5863, accuracy - 0.6814, recall - 0.8333, AUC - 0.8391, F1 - 0.7234, precision - 0.6391
2023-03-25 18:54:48,542 : [INFO]  Batch 338 initialized 
2023-03-25 18:54:48,993 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:54:49,881 : [INFO]  ------------------------- Batch 338 training: round 1 -------------------------
2023-03-25 18:54:53,508 : [INFO]  ------------------------- Batch round 1, loss: 0.573 -------------------------
2023-03-25 18:54:53,508 : [INFO]  ------------------------- Batch 338, round 1: Sent local model to the server -------------------------
2023-03-25 18:54:53,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:53,554 : [INFO]  ------------------------- Batch 338 training: round 2 -------------------------
2023-03-25 18:54:55,468 : [INFO]  ------------------------- Batch round 2, loss: 0.5793 -------------------------
2023-03-25 18:54:55,468 : [INFO]  ------------------------- Batch 338, round 2: Sent local model to the server -------------------------
2023-03-25 18:54:55,511 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:55,514 : [INFO]  ------------------------- Batch 338 training: round 3 -------------------------
2023-03-25 18:54:57,455 : [INFO]  ------------------------- Batch round 3, loss: 0.5734 -------------------------
2023-03-25 18:54:57,455 : [INFO]  ------------------------- Batch 338, round 3: Sent local model to the server -------------------------
2023-03-25 18:54:57,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:54:57,498 : [INFO]  Batch number 338 model fetched from the server
2023-03-25 18:54:57,498 : [INFO]  ################ Batch 338: final global model evalution after 3 rounds ################
2023-03-25 18:54:58,738 : [INFO]  Batch 338: Training set : loss - 0.5873, accuracy - 0.7174, recall - 0.7717, AUC - 0.8029, F1 - 0.732, precision - 0.6961, training time - -8.0 seconds
2023-03-25 18:54:58,738 : [INFO]  Batch 338: Testing set : loss - 0.6132, accuracy - 0.6324, recall - 0.7647, AUC - 0.7724, F1 - 0.6753, precision - 0.6047
2023-03-25 18:54:58,746 : [INFO]  Batch 339 initialized 
2023-03-25 18:54:59,204 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:00,069 : [INFO]  ------------------------- Batch 339 training: round 1 -------------------------
2023-03-25 18:55:03,740 : [INFO]  ------------------------- Batch round 1, loss: 0.5919 -------------------------
2023-03-25 18:55:03,740 : [INFO]  ------------------------- Batch 339, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:03,756 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:03,758 : [INFO]  ------------------------- Batch 339 training: round 2 -------------------------
2023-03-25 18:55:05,673 : [INFO]  ------------------------- Batch round 2, loss: 0.5962 -------------------------
2023-03-25 18:55:05,673 : [INFO]  ------------------------- Batch 339, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:05,690 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:05,692 : [INFO]  ------------------------- Batch 339 training: round 3 -------------------------
2023-03-25 18:55:07,586 : [INFO]  ------------------------- Batch round 3, loss: 0.6008 -------------------------
2023-03-25 18:55:07,586 : [INFO]  ------------------------- Batch 339, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:07,618 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:07,621 : [INFO]  Batch number 339 model fetched from the server
2023-03-25 18:55:07,621 : [INFO]  ################ Batch 339: final global model evalution after 3 rounds ################
2023-03-25 18:55:08,931 : [INFO]  Batch 339: Training set : loss - 0.6061, accuracy - 0.6793, recall - 0.8478, AUC - 0.7802, F1 - 0.7256, precision - 0.6341, training time - -8.0 seconds
2023-03-25 18:55:08,931 : [INFO]  Batch 339: Testing set : loss - 0.6054, accuracy - 0.6422, recall - 0.7255, AUC - 0.778, F1 - 0.6697, precision - 0.6218
2023-03-25 18:55:08,938 : [INFO]  Batch 340 initialized 
2023-03-25 18:55:09,408 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:10,280 : [INFO]  ------------------------- Batch 340 training: round 1 -------------------------
2023-03-25 18:55:13,971 : [INFO]  ------------------------- Batch round 1, loss: 0.5942 -------------------------
2023-03-25 18:55:13,971 : [INFO]  ------------------------- Batch 340, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:14,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:14,094 : [INFO]  ------------------------- Batch 340 training: round 2 -------------------------
2023-03-25 18:55:15,917 : [INFO]  ------------------------- Batch round 2, loss: 0.5909 -------------------------
2023-03-25 18:55:15,917 : [INFO]  ------------------------- Batch 340, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:15,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:15,978 : [INFO]  ------------------------- Batch 340 training: round 3 -------------------------
2023-03-25 18:55:17,793 : [INFO]  ------------------------- Batch round 3, loss: 0.5979 -------------------------
2023-03-25 18:55:17,793 : [INFO]  ------------------------- Batch 340, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:17,901 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:17,903 : [INFO]  Batch number 340 model fetched from the server
2023-03-25 18:55:17,903 : [INFO]  ################ Batch 340: final global model evalution after 3 rounds ################
2023-03-25 18:55:19,161 : [INFO]  Batch 340: Training set : loss - 0.6026, accuracy - 0.6902, recall - 0.8587, AUC - 0.8012, F1 - 0.7349, precision - 0.6423, training time - -8.0 seconds
2023-03-25 18:55:19,162 : [INFO]  Batch 340: Testing set : loss - 0.5986, accuracy - 0.652, recall - 0.7941, AUC - 0.7851, F1 - 0.6953, precision - 0.6183
2023-03-25 18:55:19,172 : [INFO]  Batch 341 initialized 
2023-03-25 18:55:19,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:20,511 : [INFO]  ------------------------- Batch 341 training: round 1 -------------------------
2023-03-25 18:55:24,200 : [INFO]  ------------------------- Batch round 1, loss: 0.583 -------------------------
2023-03-25 18:55:24,200 : [INFO]  ------------------------- Batch 341, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:24,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:24,216 : [INFO]  ------------------------- Batch 341 training: round 2 -------------------------
2023-03-25 18:55:26,113 : [INFO]  ------------------------- Batch round 2, loss: 0.5828 -------------------------
2023-03-25 18:55:26,113 : [INFO]  ------------------------- Batch 341, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:26,127 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:26,129 : [INFO]  ------------------------- Batch 341 training: round 3 -------------------------
2023-03-25 18:55:28,027 : [INFO]  ------------------------- Batch round 3, loss: 0.5833 -------------------------
2023-03-25 18:55:28,027 : [INFO]  ------------------------- Batch 341, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:28,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:28,045 : [INFO]  Batch number 341 model fetched from the server
2023-03-25 18:55:28,045 : [INFO]  ################ Batch 341: final global model evalution after 3 rounds ################
2023-03-25 18:55:29,338 : [INFO]  Batch 341: Training set : loss - 0.591, accuracy - 0.7011, recall - 0.8587, AUC - 0.8116, F1 - 0.7418, precision - 0.6529, training time - -8.0 seconds
2023-03-25 18:55:29,338 : [INFO]  Batch 341: Testing set : loss - 0.6093, accuracy - 0.6176, recall - 0.6961, AUC - 0.7556, F1 - 0.6455, precision - 0.6017
2023-03-25 18:55:29,346 : [INFO]  Batch 342 initialized 
2023-03-25 18:55:29,807 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:30,682 : [INFO]  ------------------------- Batch 342 training: round 1 -------------------------
2023-03-25 18:55:34,362 : [INFO]  ------------------------- Batch round 1, loss: 0.5622 -------------------------
2023-03-25 18:55:34,362 : [INFO]  ------------------------- Batch 342, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:34,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:34,379 : [INFO]  ------------------------- Batch 342 training: round 2 -------------------------
2023-03-25 18:55:36,341 : [INFO]  ------------------------- Batch round 2, loss: 0.569 -------------------------
2023-03-25 18:55:36,341 : [INFO]  ------------------------- Batch 342, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:36,356 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:36,359 : [INFO]  ------------------------- Batch 342 training: round 3 -------------------------
2023-03-25 18:55:38,256 : [INFO]  ------------------------- Batch round 3, loss: 0.5691 -------------------------
2023-03-25 18:55:38,256 : [INFO]  ------------------------- Batch 342, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:38,278 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:38,280 : [INFO]  Batch number 342 model fetched from the server
2023-03-25 18:55:38,280 : [INFO]  ################ Batch 342: final global model evalution after 3 rounds ################
2023-03-25 18:55:39,513 : [INFO]  Batch 342: Training set : loss - 0.5826, accuracy - 0.6739, recall - 0.8043, AUC - 0.8128, F1 - 0.7115, precision - 0.6379, training time - -8.0 seconds
2023-03-25 18:55:39,513 : [INFO]  Batch 342: Testing set : loss - 0.5818, accuracy - 0.6814, recall - 0.7843, AUC - 0.8245, F1 - 0.7111, precision - 0.6504
2023-03-25 18:55:39,529 : [INFO]  Batch 343 initialized 
2023-03-25 18:55:39,985 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:40,877 : [INFO]  ------------------------- Batch 343 training: round 1 -------------------------
2023-03-25 18:55:44,364 : [INFO]  ------------------------- Batch round 1, loss: 0.5936 -------------------------
2023-03-25 18:55:44,365 : [INFO]  ------------------------- Batch 343, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:44,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:44,499 : [INFO]  ------------------------- Batch 343 training: round 2 -------------------------
2023-03-25 18:55:46,269 : [INFO]  ------------------------- Batch round 2, loss: 0.5865 -------------------------
2023-03-25 18:55:46,269 : [INFO]  ------------------------- Batch 343, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:46,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:46,385 : [INFO]  ------------------------- Batch 343 training: round 3 -------------------------
2023-03-25 18:55:48,230 : [INFO]  ------------------------- Batch round 3, loss: 0.5895 -------------------------
2023-03-25 18:55:48,231 : [INFO]  ------------------------- Batch 343, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:48,332 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:48,334 : [INFO]  Batch number 343 model fetched from the server
2023-03-25 18:55:48,334 : [INFO]  ################ Batch 343: final global model evalution after 3 rounds ################
2023-03-25 18:55:49,540 : [INFO]  Batch 343: Training set : loss - 0.5953, accuracy - 0.6957, recall - 0.8043, AUC - 0.7917, F1 - 0.7255, precision - 0.6607, training time - -7.0 seconds
2023-03-25 18:55:49,540 : [INFO]  Batch 343: Testing set : loss - 0.6, accuracy - 0.6618, recall - 0.7843, AUC - 0.7922, F1 - 0.6987, precision - 0.6299
2023-03-25 18:55:49,550 : [INFO]  Batch 344 initialized 
2023-03-25 18:55:49,998 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:55:50,865 : [INFO]  ------------------------- Batch 344 training: round 1 -------------------------
2023-03-25 18:55:54,439 : [INFO]  ------------------------- Batch round 1, loss: 0.5862 -------------------------
2023-03-25 18:55:54,439 : [INFO]  ------------------------- Batch 344, round 1: Sent local model to the server -------------------------
2023-03-25 18:55:54,467 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:54,469 : [INFO]  ------------------------- Batch 344 training: round 2 -------------------------
2023-03-25 18:55:56,330 : [INFO]  ------------------------- Batch round 2, loss: 0.5847 -------------------------
2023-03-25 18:55:56,330 : [INFO]  ------------------------- Batch 344, round 2: Sent local model to the server -------------------------
2023-03-25 18:55:56,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:56,405 : [INFO]  ------------------------- Batch 344 training: round 3 -------------------------
2023-03-25 18:55:58,269 : [INFO]  ------------------------- Batch round 3, loss: 0.5879 -------------------------
2023-03-25 18:55:58,269 : [INFO]  ------------------------- Batch 344, round 3: Sent local model to the server -------------------------
2023-03-25 18:55:58,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:55:58,329 : [INFO]  Batch number 344 model fetched from the server
2023-03-25 18:55:58,329 : [INFO]  ################ Batch 344: final global model evalution after 3 rounds ################
2023-03-25 18:55:59,547 : [INFO]  Batch 344: Training set : loss - 0.5921, accuracy - 0.6957, recall - 0.837, AUC - 0.811, F1 - 0.7333, precision - 0.6525, training time - -7.0 seconds
2023-03-25 18:55:59,548 : [INFO]  Batch 344: Testing set : loss - 0.6073, accuracy - 0.6765, recall - 0.7843, AUC - 0.7814, F1 - 0.708, precision - 0.6452
2023-03-25 18:55:59,555 : [INFO]  Batch 345 initialized 
2023-03-25 18:56:00,007 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:00,891 : [INFO]  ------------------------- Batch 345 training: round 1 -------------------------
2023-03-25 18:56:04,483 : [INFO]  ------------------------- Batch round 1, loss: 0.6111 -------------------------
2023-03-25 18:56:04,483 : [INFO]  ------------------------- Batch 345, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:04,536 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:04,538 : [INFO]  ------------------------- Batch 345 training: round 2 -------------------------
2023-03-25 18:56:06,431 : [INFO]  ------------------------- Batch round 2, loss: 0.6108 -------------------------
2023-03-25 18:56:06,431 : [INFO]  ------------------------- Batch 345, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:06,460 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:06,462 : [INFO]  ------------------------- Batch 345 training: round 3 -------------------------
2023-03-25 18:56:08,321 : [INFO]  ------------------------- Batch round 3, loss: 0.6129 -------------------------
2023-03-25 18:56:08,321 : [INFO]  ------------------------- Batch 345, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:08,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:08,366 : [INFO]  Batch number 345 model fetched from the server
2023-03-25 18:56:08,366 : [INFO]  ################ Batch 345: final global model evalution after 3 rounds ################
2023-03-25 18:56:09,596 : [INFO]  Batch 345: Training set : loss - 0.625, accuracy - 0.6033, recall - 0.7717, AUC - 0.7491, F1 - 0.6605, precision - 0.5772, training time - -7.0 seconds
2023-03-25 18:56:09,596 : [INFO]  Batch 345: Testing set : loss - 0.589, accuracy - 0.6814, recall - 0.7745, AUC - 0.8056, F1 - 0.7085, precision - 0.6529
2023-03-25 18:56:09,645 : [INFO]  Batch 346 initialized 
2023-03-25 18:56:10,085 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:10,974 : [INFO]  ------------------------- Batch 346 training: round 1 -------------------------
2023-03-25 18:56:14,621 : [INFO]  ------------------------- Batch round 1, loss: 0.5608 -------------------------
2023-03-25 18:56:14,621 : [INFO]  ------------------------- Batch 346, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:14,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:14,639 : [INFO]  ------------------------- Batch 346 training: round 2 -------------------------
2023-03-25 18:56:16,545 : [INFO]  ------------------------- Batch round 2, loss: 0.5616 -------------------------
2023-03-25 18:56:16,546 : [INFO]  ------------------------- Batch 346, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:16,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:16,583 : [INFO]  ------------------------- Batch 346 training: round 3 -------------------------
2023-03-25 18:56:18,536 : [INFO]  ------------------------- Batch round 3, loss: 0.5584 -------------------------
2023-03-25 18:56:18,536 : [INFO]  ------------------------- Batch 346, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:18,551 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:18,554 : [INFO]  Batch number 346 model fetched from the server
2023-03-25 18:56:18,554 : [INFO]  ################ Batch 346: final global model evalution after 3 rounds ################
2023-03-25 18:56:19,791 : [INFO]  Batch 346: Training set : loss - 0.5677, accuracy - 0.7065, recall - 0.8696, AUC - 0.8651, F1 - 0.7477, precision - 0.6557, training time - -8.0 seconds
2023-03-25 18:56:19,791 : [INFO]  Batch 346: Testing set : loss - 0.5844, accuracy - 0.7059, recall - 0.7941, AUC - 0.8054, F1 - 0.7297, precision - 0.675
2023-03-25 18:56:19,803 : [INFO]  Batch 347 initialized 
2023-03-25 18:56:20,269 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:21,121 : [INFO]  ------------------------- Batch 347 training: round 1 -------------------------
2023-03-25 18:56:24,769 : [INFO]  ------------------------- Batch round 1, loss: 0.5668 -------------------------
2023-03-25 18:56:24,770 : [INFO]  ------------------------- Batch 347, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:24,912 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:24,914 : [INFO]  ------------------------- Batch 347 training: round 2 -------------------------
2023-03-25 18:56:27,233 : [INFO]  ------------------------- Batch round 2, loss: 0.5685 -------------------------
2023-03-25 18:56:27,233 : [INFO]  ------------------------- Batch 347, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:27,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:27,282 : [INFO]  ------------------------- Batch 347 training: round 3 -------------------------
2023-03-25 18:56:29,253 : [INFO]  ------------------------- Batch round 3, loss: 0.5675 -------------------------
2023-03-25 18:56:29,253 : [INFO]  ------------------------- Batch 347, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:29,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:29,307 : [INFO]  Batch number 347 model fetched from the server
2023-03-25 18:56:29,307 : [INFO]  ################ Batch 347: final global model evalution after 3 rounds ################
2023-03-25 18:56:30,644 : [INFO]  Batch 347: Training set : loss - 0.5822, accuracy - 0.6793, recall - 0.8587, AUC - 0.848, F1 - 0.7281, precision - 0.632, training time - -8.0 seconds
2023-03-25 18:56:30,644 : [INFO]  Batch 347: Testing set : loss - 0.6032, accuracy - 0.6618, recall - 0.7451, AUC - 0.7775, F1 - 0.6878, precision - 0.6387
2023-03-25 18:56:30,657 : [INFO]  Batch 348 initialized 
2023-03-25 18:56:31,140 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:32,108 : [INFO]  ------------------------- Batch 348 training: round 1 -------------------------
2023-03-25 18:56:35,889 : [INFO]  ------------------------- Batch round 1, loss: 0.5616 -------------------------
2023-03-25 18:56:35,889 : [INFO]  ------------------------- Batch 348, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:35,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:35,907 : [INFO]  ------------------------- Batch 348 training: round 2 -------------------------
2023-03-25 18:56:37,868 : [INFO]  ------------------------- Batch round 2, loss: 0.5537 -------------------------
2023-03-25 18:56:37,869 : [INFO]  ------------------------- Batch 348, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:37,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:37,887 : [INFO]  ------------------------- Batch 348 training: round 3 -------------------------
2023-03-25 18:56:39,773 : [INFO]  ------------------------- Batch round 3, loss: 0.5531 -------------------------
2023-03-25 18:56:39,773 : [INFO]  ------------------------- Batch 348, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:39,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:39,800 : [INFO]  Batch number 348 model fetched from the server
2023-03-25 18:56:39,800 : [INFO]  ################ Batch 348: final global model evalution after 3 rounds ################
2023-03-25 18:56:41,027 : [INFO]  Batch 348: Training set : loss - 0.5589, accuracy - 0.7391, recall - 0.8696, AUC - 0.8595, F1 - 0.7692, precision - 0.6897, training time - -8.0 seconds
2023-03-25 18:56:41,027 : [INFO]  Batch 348: Testing set : loss - 0.5887, accuracy - 0.6863, recall - 0.8333, AUC - 0.8233, F1 - 0.7265, precision - 0.6439
2023-03-25 18:56:41,036 : [INFO]  Batch 349 initialized 
2023-03-25 18:56:41,488 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:42,377 : [INFO]  ------------------------- Batch 349 training: round 1 -------------------------
2023-03-25 18:56:46,083 : [INFO]  ------------------------- Batch round 1, loss: 0.5727 -------------------------
2023-03-25 18:56:46,083 : [INFO]  ------------------------- Batch 349, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:46,098 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:46,100 : [INFO]  ------------------------- Batch 349 training: round 2 -------------------------
2023-03-25 18:56:47,997 : [INFO]  ------------------------- Batch round 2, loss: 0.5701 -------------------------
2023-03-25 18:56:47,997 : [INFO]  ------------------------- Batch 349, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:48,011 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:48,013 : [INFO]  ------------------------- Batch 349 training: round 3 -------------------------
2023-03-25 18:56:49,975 : [INFO]  ------------------------- Batch round 3, loss: 0.5667 -------------------------
2023-03-25 18:56:49,976 : [INFO]  ------------------------- Batch 349, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:49,991 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:49,994 : [INFO]  Batch number 349 model fetched from the server
2023-03-25 18:56:49,994 : [INFO]  ################ Batch 349: final global model evalution after 3 rounds ################
2023-03-25 18:56:51,245 : [INFO]  Batch 349: Training set : loss - 0.5799, accuracy - 0.7011, recall - 0.837, AUC - 0.8296, F1 - 0.7368, precision - 0.6581, training time - -8.0 seconds
2023-03-25 18:56:51,245 : [INFO]  Batch 349: Testing set : loss - 0.5954, accuracy - 0.6961, recall - 0.8627, AUC - 0.8095, F1 - 0.7395, precision - 0.6471
2023-03-25 18:56:51,253 : [INFO]  Batch 350 initialized 
2023-03-25 18:56:51,706 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:56:52,596 : [INFO]  ------------------------- Batch 350 training: round 1 -------------------------
2023-03-25 18:56:56,201 : [INFO]  ------------------------- Batch round 1, loss: 0.5742 -------------------------
2023-03-25 18:56:56,201 : [INFO]  ------------------------- Batch 350, round 1: Sent local model to the server -------------------------
2023-03-25 18:56:56,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:56,220 : [INFO]  ------------------------- Batch 350 training: round 2 -------------------------
2023-03-25 18:56:58,080 : [INFO]  ------------------------- Batch round 2, loss: 0.5708 -------------------------
2023-03-25 18:56:58,080 : [INFO]  ------------------------- Batch 350, round 2: Sent local model to the server -------------------------
2023-03-25 18:56:58,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:58,102 : [INFO]  ------------------------- Batch 350 training: round 3 -------------------------
2023-03-25 18:56:59,950 : [INFO]  ------------------------- Batch round 3, loss: 0.5713 -------------------------
2023-03-25 18:56:59,950 : [INFO]  ------------------------- Batch 350, round 3: Sent local model to the server -------------------------
2023-03-25 18:56:59,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:56:59,978 : [INFO]  Batch number 350 model fetched from the server
2023-03-25 18:56:59,978 : [INFO]  ################ Batch 350: final global model evalution after 3 rounds ################
2023-03-25 18:57:01,194 : [INFO]  Batch 350: Training set : loss - 0.575, accuracy - 0.7391, recall - 0.8152, AUC - 0.8185, F1 - 0.7576, precision - 0.7075, training time - -7.0 seconds
2023-03-25 18:57:01,194 : [INFO]  Batch 350: Testing set : loss - 0.6232, accuracy - 0.6127, recall - 0.7451, AUC - 0.7513, F1 - 0.658, precision - 0.5891
2023-03-25 18:57:01,210 : [INFO]  Batch 351 initialized 
2023-03-25 18:57:01,661 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:02,541 : [INFO]  ------------------------- Batch 351 training: round 1 -------------------------
2023-03-25 18:57:06,140 : [INFO]  ------------------------- Batch round 1, loss: 0.5852 -------------------------
2023-03-25 18:57:06,140 : [INFO]  ------------------------- Batch 351, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:06,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:06,218 : [INFO]  ------------------------- Batch 351 training: round 2 -------------------------
2023-03-25 18:57:08,044 : [INFO]  ------------------------- Batch round 2, loss: 0.5864 -------------------------
2023-03-25 18:57:08,044 : [INFO]  ------------------------- Batch 351, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:08,086 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:08,088 : [INFO]  ------------------------- Batch 351 training: round 3 -------------------------
2023-03-25 18:57:09,925 : [INFO]  ------------------------- Batch round 3, loss: 0.5844 -------------------------
2023-03-25 18:57:09,925 : [INFO]  ------------------------- Batch 351, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:09,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:09,966 : [INFO]  Batch number 351 model fetched from the server
2023-03-25 18:57:09,966 : [INFO]  ################ Batch 351: final global model evalution after 3 rounds ################
2023-03-25 18:57:11,170 : [INFO]  Batch 351: Training set : loss - 0.5973, accuracy - 0.6685, recall - 0.8478, AUC - 0.8157, F1 - 0.7189, precision - 0.624, training time - -7.0 seconds
2023-03-25 18:57:11,170 : [INFO]  Batch 351: Testing set : loss - 0.5902, accuracy - 0.6765, recall - 0.7941, AUC - 0.7987, F1 - 0.7105, precision - 0.6429
2023-03-25 18:57:11,183 : [INFO]  Batch 352 initialized 
2023-03-25 18:57:11,639 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:12,536 : [INFO]  ------------------------- Batch 352 training: round 1 -------------------------
2023-03-25 18:57:16,006 : [INFO]  ------------------------- Batch round 1, loss: 0.5956 -------------------------
2023-03-25 18:57:16,006 : [INFO]  ------------------------- Batch 352, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:16,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:16,093 : [INFO]  ------------------------- Batch 352 training: round 2 -------------------------
2023-03-25 18:57:17,959 : [INFO]  ------------------------- Batch round 2, loss: 0.5963 -------------------------
2023-03-25 18:57:17,959 : [INFO]  ------------------------- Batch 352, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:18,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:18,041 : [INFO]  ------------------------- Batch 352 training: round 3 -------------------------
2023-03-25 18:57:20,140 : [INFO]  ------------------------- Batch round 3, loss: 0.5964 -------------------------
2023-03-25 18:57:20,140 : [INFO]  ------------------------- Batch 352, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:20,153 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:20,155 : [INFO]  Batch number 352 model fetched from the server
2023-03-25 18:57:20,155 : [INFO]  ################ Batch 352: final global model evalution after 3 rounds ################
2023-03-25 18:57:21,331 : [INFO]  Batch 352: Training set : loss - 0.6066, accuracy - 0.6359, recall - 0.7717, AUC - 0.7711, F1 - 0.6794, precision - 0.6068, training time - -8.0 seconds
2023-03-25 18:57:21,331 : [INFO]  Batch 352: Testing set : loss - 0.5943, accuracy - 0.6765, recall - 0.7745, AUC - 0.8052, F1 - 0.7054, precision - 0.6475
2023-03-25 18:57:21,368 : [INFO]  Batch 353 initialized 
2023-03-25 18:57:21,812 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:22,705 : [INFO]  ------------------------- Batch 353 training: round 1 -------------------------
2023-03-25 18:57:26,313 : [INFO]  ------------------------- Batch round 1, loss: 0.5807 -------------------------
2023-03-25 18:57:26,313 : [INFO]  ------------------------- Batch 353, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:26,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:26,407 : [INFO]  ------------------------- Batch 353 training: round 2 -------------------------
2023-03-25 18:57:28,331 : [INFO]  ------------------------- Batch round 2, loss: 0.5766 -------------------------
2023-03-25 18:57:28,331 : [INFO]  ------------------------- Batch 353, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:28,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:28,398 : [INFO]  ------------------------- Batch 353 training: round 3 -------------------------
2023-03-25 18:57:30,207 : [INFO]  ------------------------- Batch round 3, loss: 0.5851 -------------------------
2023-03-25 18:57:30,207 : [INFO]  ------------------------- Batch 353, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:30,267 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:30,269 : [INFO]  Batch number 353 model fetched from the server
2023-03-25 18:57:30,269 : [INFO]  ################ Batch 353: final global model evalution after 3 rounds ################
2023-03-25 18:57:31,505 : [INFO]  Batch 353: Training set : loss - 0.5978, accuracy - 0.6576, recall - 0.7826, AUC - 0.7854, F1 - 0.6957, precision - 0.6261, training time - -8.0 seconds
2023-03-25 18:57:31,506 : [INFO]  Batch 353: Testing set : loss - 0.581, accuracy - 0.6814, recall - 0.8333, AUC - 0.8383, F1 - 0.7234, precision - 0.6391
2023-03-25 18:57:31,521 : [INFO]  Batch 354 initialized 
2023-03-25 18:57:32,106 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:33,077 : [INFO]  ------------------------- Batch 354 training: round 1 -------------------------
2023-03-25 18:57:36,905 : [INFO]  ------------------------- Batch round 1, loss: 0.595 -------------------------
2023-03-25 18:57:36,905 : [INFO]  ------------------------- Batch 354, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:36,920 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:36,922 : [INFO]  ------------------------- Batch 354 training: round 2 -------------------------
2023-03-25 18:57:38,832 : [INFO]  ------------------------- Batch round 2, loss: 0.5857 -------------------------
2023-03-25 18:57:38,832 : [INFO]  ------------------------- Batch 354, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:38,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:38,850 : [INFO]  ------------------------- Batch 354 training: round 3 -------------------------
2023-03-25 18:57:40,759 : [INFO]  ------------------------- Batch round 3, loss: 0.5883 -------------------------
2023-03-25 18:57:40,759 : [INFO]  ------------------------- Batch 354, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:40,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:40,777 : [INFO]  Batch number 354 model fetched from the server
2023-03-25 18:57:40,777 : [INFO]  ################ Batch 354: final global model evalution after 3 rounds ################
2023-03-25 18:57:42,009 : [INFO]  Batch 354: Training set : loss - 0.6017, accuracy - 0.6739, recall - 0.8043, AUC - 0.7912, F1 - 0.7115, precision - 0.6379, training time - -8.0 seconds
2023-03-25 18:57:42,010 : [INFO]  Batch 354: Testing set : loss - 0.5932, accuracy - 0.6814, recall - 0.7647, AUC - 0.789, F1 - 0.7059, precision - 0.6555
2023-03-25 18:57:42,019 : [INFO]  Batch 355 initialized 
2023-03-25 18:57:42,515 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:43,412 : [INFO]  ------------------------- Batch 355 training: round 1 -------------------------
2023-03-25 18:57:46,968 : [INFO]  ------------------------- Batch round 1, loss: 0.5606 -------------------------
2023-03-25 18:57:46,968 : [INFO]  ------------------------- Batch 355, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:46,982 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:46,984 : [INFO]  ------------------------- Batch 355 training: round 2 -------------------------
2023-03-25 18:57:48,763 : [INFO]  ------------------------- Batch round 2, loss: 0.5564 -------------------------
2023-03-25 18:57:48,763 : [INFO]  ------------------------- Batch 355, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:48,780 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:48,782 : [INFO]  ------------------------- Batch 355 training: round 3 -------------------------
2023-03-25 18:57:50,607 : [INFO]  ------------------------- Batch round 3, loss: 0.557 -------------------------
2023-03-25 18:57:50,607 : [INFO]  ------------------------- Batch 355, round 3: Sent local model to the server -------------------------
2023-03-25 18:57:50,621 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:50,623 : [INFO]  Batch number 355 model fetched from the server
2023-03-25 18:57:50,623 : [INFO]  ################ Batch 355: final global model evalution after 3 rounds ################
2023-03-25 18:57:51,858 : [INFO]  Batch 355: Training set : loss - 0.5683, accuracy - 0.6957, recall - 0.8587, AUC - 0.8452, F1 - 0.7383, precision - 0.6475, training time - -7.0 seconds
2023-03-25 18:57:51,859 : [INFO]  Batch 355: Testing set : loss - 0.6035, accuracy - 0.652, recall - 0.7941, AUC - 0.7975, F1 - 0.6953, precision - 0.6183
2023-03-25 18:57:51,873 : [INFO]  Batch 356 initialized 
2023-03-25 18:57:52,348 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:57:53,236 : [INFO]  ------------------------- Batch 356 training: round 1 -------------------------
2023-03-25 18:57:56,846 : [INFO]  ------------------------- Batch round 1, loss: 0.6067 -------------------------
2023-03-25 18:57:56,846 : [INFO]  ------------------------- Batch 356, round 1: Sent local model to the server -------------------------
2023-03-25 18:57:56,860 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:56,862 : [INFO]  ------------------------- Batch 356 training: round 2 -------------------------
2023-03-25 18:57:58,788 : [INFO]  ------------------------- Batch round 2, loss: 0.6075 -------------------------
2023-03-25 18:57:58,788 : [INFO]  ------------------------- Batch 356, round 2: Sent local model to the server -------------------------
2023-03-25 18:57:58,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:57:58,806 : [INFO]  ------------------------- Batch 356 training: round 3 -------------------------
2023-03-25 18:58:00,662 : [INFO]  ------------------------- Batch round 3, loss: 0.6082 -------------------------
2023-03-25 18:58:00,662 : [INFO]  ------------------------- Batch 356, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:00,677 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:00,679 : [INFO]  Batch number 356 model fetched from the server
2023-03-25 18:58:00,679 : [INFO]  ################ Batch 356: final global model evalution after 3 rounds ################
2023-03-25 18:58:01,941 : [INFO]  Batch 356: Training set : loss - 0.6204, accuracy - 0.587, recall - 0.7391, AUC - 0.7463, F1 - 0.6415, precision - 0.5667, training time - -7.0 seconds
2023-03-25 18:58:01,941 : [INFO]  Batch 356: Testing set : loss - 0.5991, accuracy - 0.6275, recall - 0.8137, AUC - 0.7951, F1 - 0.686, precision - 0.5929
2023-03-25 18:58:01,948 : [INFO]  Batch 357 initialized 
2023-03-25 18:58:02,397 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:03,278 : [INFO]  ------------------------- Batch 357 training: round 1 -------------------------
2023-03-25 18:58:06,868 : [INFO]  ------------------------- Batch round 1, loss: 0.5688 -------------------------
2023-03-25 18:58:06,868 : [INFO]  ------------------------- Batch 357, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:06,960 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:06,962 : [INFO]  ------------------------- Batch 357 training: round 2 -------------------------
2023-03-25 18:58:08,831 : [INFO]  ------------------------- Batch round 2, loss: 0.5785 -------------------------
2023-03-25 18:58:08,831 : [INFO]  ------------------------- Batch 357, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:08,852 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:08,854 : [INFO]  ------------------------- Batch 357 training: round 3 -------------------------
2023-03-25 18:58:10,703 : [INFO]  ------------------------- Batch round 3, loss: 0.5726 -------------------------
2023-03-25 18:58:10,703 : [INFO]  ------------------------- Batch 357, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:10,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:10,747 : [INFO]  Batch number 357 model fetched from the server
2023-03-25 18:58:10,747 : [INFO]  ################ Batch 357: final global model evalution after 3 rounds ################
2023-03-25 18:58:11,962 : [INFO]  Batch 357: Training set : loss - 0.5832, accuracy - 0.6848, recall - 0.8152, AUC - 0.8142, F1 - 0.7212, precision - 0.6466, training time - -7.0 seconds
2023-03-25 18:58:11,962 : [INFO]  Batch 357: Testing set : loss - 0.598, accuracy - 0.6471, recall - 0.7941, AUC - 0.801, F1 - 0.6923, precision - 0.6136
2023-03-25 18:58:11,976 : [INFO]  Batch 358 initialized 
2023-03-25 18:58:12,423 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:13,327 : [INFO]  ------------------------- Batch 358 training: round 1 -------------------------
2023-03-25 18:58:16,871 : [INFO]  ------------------------- Batch round 1, loss: 0.5709 -------------------------
2023-03-25 18:58:16,871 : [INFO]  ------------------------- Batch 358, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:16,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:16,888 : [INFO]  ------------------------- Batch 358 training: round 2 -------------------------
2023-03-25 18:58:18,766 : [INFO]  ------------------------- Batch round 2, loss: 0.5697 -------------------------
2023-03-25 18:58:18,767 : [INFO]  ------------------------- Batch 358, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:18,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:18,783 : [INFO]  ------------------------- Batch 358 training: round 3 -------------------------
2023-03-25 18:58:20,652 : [INFO]  ------------------------- Batch round 3, loss: 0.5698 -------------------------
2023-03-25 18:58:20,652 : [INFO]  ------------------------- Batch 358, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:20,667 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:20,668 : [INFO]  Batch number 358 model fetched from the server
2023-03-25 18:58:20,669 : [INFO]  ################ Batch 358: final global model evalution after 3 rounds ################
2023-03-25 18:58:21,894 : [INFO]  Batch 358: Training set : loss - 0.5825, accuracy - 0.7065, recall - 0.837, AUC - 0.822, F1 - 0.7404, precision - 0.6638, training time - -7.0 seconds
2023-03-25 18:58:21,894 : [INFO]  Batch 358: Testing set : loss - 0.5723, accuracy - 0.7353, recall - 0.8333, AUC - 0.8432, F1 - 0.7589, precision - 0.6967
2023-03-25 18:58:21,901 : [INFO]  Batch 359 initialized 
2023-03-25 18:58:22,362 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:23,251 : [INFO]  ------------------------- Batch 359 training: round 1 -------------------------
2023-03-25 18:58:26,816 : [INFO]  ------------------------- Batch round 1, loss: 0.6053 -------------------------
2023-03-25 18:58:26,816 : [INFO]  ------------------------- Batch 359, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:26,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:26,915 : [INFO]  ------------------------- Batch 359 training: round 2 -------------------------
2023-03-25 18:58:28,764 : [INFO]  ------------------------- Batch round 2, loss: 0.6058 -------------------------
2023-03-25 18:58:28,764 : [INFO]  ------------------------- Batch 359, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:28,778 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:28,780 : [INFO]  ------------------------- Batch 359 training: round 3 -------------------------
2023-03-25 18:58:30,611 : [INFO]  ------------------------- Batch round 3, loss: 0.5991 -------------------------
2023-03-25 18:58:30,611 : [INFO]  ------------------------- Batch 359, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:30,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:30,646 : [INFO]  Batch number 359 model fetched from the server
2023-03-25 18:58:30,646 : [INFO]  ################ Batch 359: final global model evalution after 3 rounds ################
2023-03-25 18:58:31,851 : [INFO]  Batch 359: Training set : loss - 0.6216, accuracy - 0.6141, recall - 0.7065, AUC - 0.7446, F1 - 0.6468, precision - 0.5963, training time - -7.0 seconds
2023-03-25 18:58:31,851 : [INFO]  Batch 359: Testing set : loss - 0.5746, accuracy - 0.6863, recall - 0.8137, AUC - 0.8268, F1 - 0.7217, precision - 0.6484
2023-03-25 18:58:31,869 : [INFO]  Batch 360 initialized 
2023-03-25 18:58:32,327 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:33,193 : [INFO]  ------------------------- Batch 360 training: round 1 -------------------------
2023-03-25 18:58:36,741 : [INFO]  ------------------------- Batch round 1, loss: 0.5936 -------------------------
2023-03-25 18:58:36,741 : [INFO]  ------------------------- Batch 360, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:36,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:36,838 : [INFO]  ------------------------- Batch 360 training: round 2 -------------------------
2023-03-25 18:58:38,690 : [INFO]  ------------------------- Batch round 2, loss: 0.599 -------------------------
2023-03-25 18:58:38,690 : [INFO]  ------------------------- Batch 360, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:38,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:38,710 : [INFO]  ------------------------- Batch 360 training: round 3 -------------------------
2023-03-25 18:58:40,573 : [INFO]  ------------------------- Batch round 3, loss: 0.5973 -------------------------
2023-03-25 18:58:40,573 : [INFO]  ------------------------- Batch 360, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:40,589 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:40,591 : [INFO]  Batch number 360 model fetched from the server
2023-03-25 18:58:40,591 : [INFO]  ################ Batch 360: final global model evalution after 3 rounds ################
2023-03-25 18:58:41,813 : [INFO]  Batch 360: Training set : loss - 0.6176, accuracy - 0.625, recall - 0.7826, AUC - 0.7739, F1 - 0.6761, precision - 0.595, training time - -7.0 seconds
2023-03-25 18:58:41,814 : [INFO]  Batch 360: Testing set : loss - 0.5907, accuracy - 0.6863, recall - 0.8039, AUC - 0.7955, F1 - 0.7193, precision - 0.6508
2023-03-25 18:58:41,823 : [INFO]  Batch 361 initialized 
2023-03-25 18:58:42,268 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:43,128 : [INFO]  ------------------------- Batch 361 training: round 1 -------------------------
2023-03-25 18:58:46,692 : [INFO]  ------------------------- Batch round 1, loss: 0.5751 -------------------------
2023-03-25 18:58:46,694 : [INFO]  ------------------------- Batch 361, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:46,772 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:46,774 : [INFO]  ------------------------- Batch 361 training: round 2 -------------------------
2023-03-25 18:58:48,677 : [INFO]  ------------------------- Batch round 2, loss: 0.5715 -------------------------
2023-03-25 18:58:48,678 : [INFO]  ------------------------- Batch 361, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:48,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:48,694 : [INFO]  ------------------------- Batch 361 training: round 3 -------------------------
2023-03-25 18:58:50,564 : [INFO]  ------------------------- Batch round 3, loss: 0.579 -------------------------
2023-03-25 18:58:50,564 : [INFO]  ------------------------- Batch 361, round 3: Sent local model to the server -------------------------
2023-03-25 18:58:50,582 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:50,586 : [INFO]  Batch number 361 model fetched from the server
2023-03-25 18:58:50,586 : [INFO]  ################ Batch 361: final global model evalution after 3 rounds ################
2023-03-25 18:58:51,811 : [INFO]  Batch 361: Training set : loss - 0.5785, accuracy - 0.7065, recall - 0.8152, AUC - 0.8272, F1 - 0.7353, precision - 0.6696, training time - -7.0 seconds
2023-03-25 18:58:51,811 : [INFO]  Batch 361: Testing set : loss - 0.5797, accuracy - 0.6814, recall - 0.9216, AUC - 0.8758, F1 - 0.7431, precision - 0.6225
2023-03-25 18:58:51,825 : [INFO]  Batch 362 initialized 
2023-03-25 18:58:52,278 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:58:53,162 : [INFO]  ------------------------- Batch 362 training: round 1 -------------------------
2023-03-25 18:58:56,884 : [INFO]  ------------------------- Batch round 1, loss: 0.5895 -------------------------
2023-03-25 18:58:56,884 : [INFO]  ------------------------- Batch 362, round 1: Sent local model to the server -------------------------
2023-03-25 18:58:56,930 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:56,932 : [INFO]  ------------------------- Batch 362 training: round 2 -------------------------
2023-03-25 18:58:58,798 : [INFO]  ------------------------- Batch round 2, loss: 0.5911 -------------------------
2023-03-25 18:58:58,798 : [INFO]  ------------------------- Batch 362, round 2: Sent local model to the server -------------------------
2023-03-25 18:58:58,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:58:58,876 : [INFO]  ------------------------- Batch 362 training: round 3 -------------------------
2023-03-25 18:59:00,766 : [INFO]  ------------------------- Batch round 3, loss: 0.5886 -------------------------
2023-03-25 18:59:00,766 : [INFO]  ------------------------- Batch 362, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:00,796 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:00,798 : [INFO]  Batch number 362 model fetched from the server
2023-03-25 18:59:00,798 : [INFO]  ################ Batch 362: final global model evalution after 3 rounds ################
2023-03-25 18:59:02,024 : [INFO]  Batch 362: Training set : loss - 0.6072, accuracy - 0.6576, recall - 0.7717, AUC - 0.7678, F1 - 0.6927, precision - 0.6283, training time - -8.0 seconds
2023-03-25 18:59:02,024 : [INFO]  Batch 362: Testing set : loss - 0.5992, accuracy - 0.6814, recall - 0.8333, AUC - 0.7957, F1 - 0.7234, precision - 0.6391
2023-03-25 18:59:02,041 : [INFO]  Batch 363 initialized 
2023-03-25 18:59:02,527 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:03,424 : [INFO]  ------------------------- Batch 363 training: round 1 -------------------------
2023-03-25 18:59:07,028 : [INFO]  ------------------------- Batch round 1, loss: 0.5808 -------------------------
2023-03-25 18:59:07,028 : [INFO]  ------------------------- Batch 363, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:07,139 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:07,141 : [INFO]  ------------------------- Batch 363 training: round 2 -------------------------
2023-03-25 18:59:09,035 : [INFO]  ------------------------- Batch round 2, loss: 0.5833 -------------------------
2023-03-25 18:59:09,035 : [INFO]  ------------------------- Batch 363, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:09,050 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:09,052 : [INFO]  ------------------------- Batch 363 training: round 3 -------------------------
2023-03-25 18:59:10,924 : [INFO]  ------------------------- Batch round 3, loss: 0.5801 -------------------------
2023-03-25 18:59:10,924 : [INFO]  ------------------------- Batch 363, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:10,938 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:10,940 : [INFO]  Batch number 363 model fetched from the server
2023-03-25 18:59:10,940 : [INFO]  ################ Batch 363: final global model evalution after 3 rounds ################
2023-03-25 18:59:12,180 : [INFO]  Batch 363: Training set : loss - 0.5944, accuracy - 0.6793, recall - 0.7935, AUC - 0.7997, F1 - 0.7122, precision - 0.646, training time - -8.0 seconds
2023-03-25 18:59:12,180 : [INFO]  Batch 363: Testing set : loss - 0.5755, accuracy - 0.6912, recall - 0.7843, AUC - 0.8225, F1 - 0.7175, precision - 0.6612
2023-03-25 18:59:12,205 : [INFO]  Batch 364 initialized 
2023-03-25 18:59:12,654 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:13,566 : [INFO]  ------------------------- Batch 364 training: round 1 -------------------------
2023-03-25 18:59:17,142 : [INFO]  ------------------------- Batch round 1, loss: 0.6043 -------------------------
2023-03-25 18:59:17,142 : [INFO]  ------------------------- Batch 364, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:17,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:17,249 : [INFO]  ------------------------- Batch 364 training: round 2 -------------------------
2023-03-25 18:59:19,044 : [INFO]  ------------------------- Batch round 2, loss: 0.602 -------------------------
2023-03-25 18:59:19,044 : [INFO]  ------------------------- Batch 364, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:19,189 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:19,190 : [INFO]  ------------------------- Batch 364 training: round 3 -------------------------
2023-03-25 18:59:20,976 : [INFO]  ------------------------- Batch round 3, loss: 0.6024 -------------------------
2023-03-25 18:59:20,976 : [INFO]  ------------------------- Batch 364, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:21,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:21,081 : [INFO]  Batch number 364 model fetched from the server
2023-03-25 18:59:21,081 : [INFO]  ################ Batch 364: final global model evalution after 3 rounds ################
2023-03-25 18:59:22,270 : [INFO]  Batch 364: Training set : loss - 0.6157, accuracy - 0.6413, recall - 0.8152, AUC - 0.7664, F1 - 0.6944, precision - 0.6048, training time - -8.0 seconds
2023-03-25 18:59:22,270 : [INFO]  Batch 364: Testing set : loss - 0.5613, accuracy - 0.7255, recall - 0.8431, AUC - 0.857, F1 - 0.7544, precision - 0.6825
2023-03-25 18:59:22,284 : [INFO]  Batch 365 initialized 
2023-03-25 18:59:22,732 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:23,611 : [INFO]  ------------------------- Batch 365 training: round 1 -------------------------
2023-03-25 18:59:27,446 : [INFO]  ------------------------- Batch round 1, loss: 0.6179 -------------------------
2023-03-25 18:59:27,446 : [INFO]  ------------------------- Batch 365, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:27,459 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:27,461 : [INFO]  ------------------------- Batch 365 training: round 2 -------------------------
2023-03-25 18:59:29,274 : [INFO]  ------------------------- Batch round 2, loss: 0.6228 -------------------------
2023-03-25 18:59:29,275 : [INFO]  ------------------------- Batch 365, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:29,290 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:29,292 : [INFO]  ------------------------- Batch 365 training: round 3 -------------------------
2023-03-25 18:59:31,142 : [INFO]  ------------------------- Batch round 3, loss: 0.6181 -------------------------
2023-03-25 18:59:31,142 : [INFO]  ------------------------- Batch 365, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:31,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:31,158 : [INFO]  Batch number 365 model fetched from the server
2023-03-25 18:59:31,158 : [INFO]  ################ Batch 365: final global model evalution after 3 rounds ################
2023-03-25 18:59:32,335 : [INFO]  Batch 365: Training set : loss - 0.6339, accuracy - 0.6196, recall - 0.7935, AUC - 0.7323, F1 - 0.6759, precision - 0.5887, training time - -8.0 seconds
2023-03-25 18:59:32,335 : [INFO]  Batch 365: Testing set : loss - 0.5842, accuracy - 0.6765, recall - 0.8529, AUC - 0.8326, F1 - 0.725, precision - 0.6304
2023-03-25 18:59:32,349 : [INFO]  Batch 366 initialized 
2023-03-25 18:59:32,804 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:33,702 : [INFO]  ------------------------- Batch 366 training: round 1 -------------------------
2023-03-25 18:59:37,215 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-25 18:59:37,215 : [INFO]  ------------------------- Batch 366, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:37,231 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:37,235 : [INFO]  ------------------------- Batch 366 training: round 2 -------------------------
2023-03-25 18:59:39,055 : [INFO]  ------------------------- Batch round 2, loss: 0.5668 -------------------------
2023-03-25 18:59:39,055 : [INFO]  ------------------------- Batch 366, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:39,091 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:39,093 : [INFO]  ------------------------- Batch 366 training: round 3 -------------------------
2023-03-25 18:59:40,872 : [INFO]  ------------------------- Batch round 3, loss: 0.5643 -------------------------
2023-03-25 18:59:40,872 : [INFO]  ------------------------- Batch 366, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:40,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:40,913 : [INFO]  Batch number 366 model fetched from the server
2023-03-25 18:59:40,913 : [INFO]  ################ Batch 366: final global model evalution after 3 rounds ################
2023-03-25 18:59:42,116 : [INFO]  Batch 366: Training set : loss - 0.5721, accuracy - 0.7011, recall - 0.8587, AUC - 0.8706, F1 - 0.7418, precision - 0.6529, training time - -7.0 seconds
2023-03-25 18:59:42,116 : [INFO]  Batch 366: Testing set : loss - 0.6244, accuracy - 0.6176, recall - 0.7549, AUC - 0.7493, F1 - 0.6638, precision - 0.5923
2023-03-25 18:59:42,124 : [INFO]  Batch 367 initialized 
2023-03-25 18:59:42,576 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:43,456 : [INFO]  ------------------------- Batch 367 training: round 1 -------------------------
2023-03-25 18:59:46,916 : [INFO]  ------------------------- Batch round 1, loss: 0.5904 -------------------------
2023-03-25 18:59:46,916 : [INFO]  ------------------------- Batch 367, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:46,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:46,949 : [INFO]  ------------------------- Batch 367 training: round 2 -------------------------
2023-03-25 18:59:48,734 : [INFO]  ------------------------- Batch round 2, loss: 0.5946 -------------------------
2023-03-25 18:59:48,734 : [INFO]  ------------------------- Batch 367, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:48,749 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:48,751 : [INFO]  ------------------------- Batch 367 training: round 3 -------------------------
2023-03-25 18:59:50,492 : [INFO]  ------------------------- Batch round 3, loss: 0.5941 -------------------------
2023-03-25 18:59:50,492 : [INFO]  ------------------------- Batch 367, round 3: Sent local model to the server -------------------------
2023-03-25 18:59:50,509 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:50,511 : [INFO]  Batch number 367 model fetched from the server
2023-03-25 18:59:50,511 : [INFO]  ################ Batch 367: final global model evalution after 3 rounds ################
2023-03-25 18:59:51,713 : [INFO]  Batch 367: Training set : loss - 0.6059, accuracy - 0.6413, recall - 0.7935, AUC - 0.7852, F1 - 0.6887, precision - 0.6083, training time - -7.0 seconds
2023-03-25 18:59:51,714 : [INFO]  Batch 367: Testing set : loss - 0.6007, accuracy - 0.652, recall - 0.8333, AUC - 0.806, F1 - 0.7054, precision - 0.6115
2023-03-25 18:59:51,732 : [INFO]  Batch 368 initialized 
2023-03-25 18:59:52,180 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 18:59:53,084 : [INFO]  ------------------------- Batch 368 training: round 1 -------------------------
2023-03-25 18:59:56,607 : [INFO]  ------------------------- Batch round 1, loss: 0.5606 -------------------------
2023-03-25 18:59:56,607 : [INFO]  ------------------------- Batch 368, round 1: Sent local model to the server -------------------------
2023-03-25 18:59:56,677 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:56,679 : [INFO]  ------------------------- Batch 368 training: round 2 -------------------------
2023-03-25 18:59:58,468 : [INFO]  ------------------------- Batch round 2, loss: 0.5588 -------------------------
2023-03-25 18:59:58,468 : [INFO]  ------------------------- Batch 368, round 2: Sent local model to the server -------------------------
2023-03-25 18:59:58,537 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 18:59:58,540 : [INFO]  ------------------------- Batch 368 training: round 3 -------------------------
2023-03-25 19:00:00,359 : [INFO]  ------------------------- Batch round 3, loss: 0.5636 -------------------------
2023-03-25 19:00:00,359 : [INFO]  ------------------------- Batch 368, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:00,431 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:00,433 : [INFO]  Batch number 368 model fetched from the server
2023-03-25 19:00:00,433 : [INFO]  ################ Batch 368: final global model evalution after 3 rounds ################
2023-03-25 19:00:01,648 : [INFO]  Batch 368: Training set : loss - 0.5656, accuracy - 0.7174, recall - 0.8043, AUC - 0.8354, F1 - 0.74, precision - 0.6852, training time - -7.0 seconds
2023-03-25 19:00:01,648 : [INFO]  Batch 368: Testing set : loss - 0.5887, accuracy - 0.6912, recall - 0.8039, AUC - 0.8106, F1 - 0.7225, precision - 0.656
2023-03-25 19:00:01,662 : [INFO]  Batch 369 initialized 
2023-03-25 19:00:02,130 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:03,052 : [INFO]  ------------------------- Batch 369 training: round 1 -------------------------
2023-03-25 19:00:06,660 : [INFO]  ------------------------- Batch round 1, loss: 0.5924 -------------------------
2023-03-25 19:00:06,660 : [INFO]  ------------------------- Batch 369, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:06,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:06,679 : [INFO]  ------------------------- Batch 369 training: round 2 -------------------------
2023-03-25 19:00:08,550 : [INFO]  ------------------------- Batch round 2, loss: 0.5957 -------------------------
2023-03-25 19:00:08,550 : [INFO]  ------------------------- Batch 369, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:08,571 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:08,574 : [INFO]  ------------------------- Batch 369 training: round 3 -------------------------
2023-03-25 19:00:10,458 : [INFO]  ------------------------- Batch round 3, loss: 0.5952 -------------------------
2023-03-25 19:00:10,458 : [INFO]  ------------------------- Batch 369, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:10,474 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:10,477 : [INFO]  Batch number 369 model fetched from the server
2023-03-25 19:00:10,477 : [INFO]  ################ Batch 369: final global model evalution after 3 rounds ################
2023-03-25 19:00:11,681 : [INFO]  Batch 369: Training set : loss - 0.6029, accuracy - 0.6685, recall - 0.7935, AUC - 0.7732, F1 - 0.7053, precision - 0.6348, training time - -7.0 seconds
2023-03-25 19:00:11,682 : [INFO]  Batch 369: Testing set : loss - 0.5905, accuracy - 0.6716, recall - 0.7549, AUC - 0.7838, F1 - 0.6968, precision - 0.6471
2023-03-25 19:00:11,693 : [INFO]  Batch 370 initialized 
2023-03-25 19:00:12,152 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:13,070 : [INFO]  ------------------------- Batch 370 training: round 1 -------------------------
2023-03-25 19:00:16,662 : [INFO]  ------------------------- Batch round 1, loss: 0.5846 -------------------------
2023-03-25 19:00:16,662 : [INFO]  ------------------------- Batch 370, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:16,677 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:16,679 : [INFO]  ------------------------- Batch 370 training: round 2 -------------------------
2023-03-25 19:00:18,570 : [INFO]  ------------------------- Batch round 2, loss: 0.5838 -------------------------
2023-03-25 19:00:18,570 : [INFO]  ------------------------- Batch 370, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:18,585 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:18,587 : [INFO]  ------------------------- Batch 370 training: round 3 -------------------------
2023-03-25 19:00:20,346 : [INFO]  ------------------------- Batch round 3, loss: 0.5909 -------------------------
2023-03-25 19:00:20,346 : [INFO]  ------------------------- Batch 370, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:20,608 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:20,611 : [INFO]  Batch number 370 model fetched from the server
2023-03-25 19:00:20,611 : [INFO]  ################ Batch 370: final global model evalution after 3 rounds ################
2023-03-25 19:00:21,830 : [INFO]  Batch 370: Training set : loss - 0.5899, accuracy - 0.6793, recall - 0.8043, AUC - 0.804, F1 - 0.715, precision - 0.6435, training time - -8.0 seconds
2023-03-25 19:00:21,831 : [INFO]  Batch 370: Testing set : loss - 0.5732, accuracy - 0.6961, recall - 0.8235, AUC - 0.8466, F1 - 0.7304, precision - 0.6562
2023-03-25 19:00:21,840 : [INFO]  Batch 371 initialized 
2023-03-25 19:00:22,296 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:23,215 : [INFO]  ------------------------- Batch 371 training: round 1 -------------------------
2023-03-25 19:00:26,751 : [INFO]  ------------------------- Batch round 1, loss: 0.5853 -------------------------
2023-03-25 19:00:26,751 : [INFO]  ------------------------- Batch 371, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:26,765 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:26,767 : [INFO]  ------------------------- Batch 371 training: round 2 -------------------------
2023-03-25 19:00:28,575 : [INFO]  ------------------------- Batch round 2, loss: 0.5842 -------------------------
2023-03-25 19:00:28,575 : [INFO]  ------------------------- Batch 371, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:28,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:28,828 : [INFO]  ------------------------- Batch 371 training: round 3 -------------------------
2023-03-25 19:00:30,702 : [INFO]  ------------------------- Batch round 3, loss: 0.5832 -------------------------
2023-03-25 19:00:30,702 : [INFO]  ------------------------- Batch 371, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:30,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:30,720 : [INFO]  Batch number 371 model fetched from the server
2023-03-25 19:00:30,720 : [INFO]  ################ Batch 371: final global model evalution after 3 rounds ################
2023-03-25 19:00:31,975 : [INFO]  Batch 371: Training set : loss - 0.5995, accuracy - 0.6576, recall - 0.7935, AUC - 0.7941, F1 - 0.6986, precision - 0.6239, training time - -8.0 seconds
2023-03-25 19:00:31,975 : [INFO]  Batch 371: Testing set : loss - 0.5819, accuracy - 0.6961, recall - 0.8235, AUC - 0.8143, F1 - 0.7304, precision - 0.6562
2023-03-25 19:00:31,983 : [INFO]  Batch 372 initialized 
2023-03-25 19:00:32,441 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:33,386 : [INFO]  ------------------------- Batch 372 training: round 1 -------------------------
2023-03-25 19:00:36,977 : [INFO]  ------------------------- Batch round 1, loss: 0.5765 -------------------------
2023-03-25 19:00:36,977 : [INFO]  ------------------------- Batch 372, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:37,020 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:37,023 : [INFO]  ------------------------- Batch 372 training: round 2 -------------------------
2023-03-25 19:00:38,915 : [INFO]  ------------------------- Batch round 2, loss: 0.5729 -------------------------
2023-03-25 19:00:38,915 : [INFO]  ------------------------- Batch 372, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:38,930 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:38,932 : [INFO]  ------------------------- Batch 372 training: round 3 -------------------------
2023-03-25 19:00:40,755 : [INFO]  ------------------------- Batch round 3, loss: 0.5817 -------------------------
2023-03-25 19:00:40,755 : [INFO]  ------------------------- Batch 372, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:40,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:40,772 : [INFO]  Batch number 372 model fetched from the server
2023-03-25 19:00:40,772 : [INFO]  ################ Batch 372: final global model evalution after 3 rounds ################
2023-03-25 19:00:42,004 : [INFO]  Batch 372: Training set : loss - 0.5875, accuracy - 0.7011, recall - 0.7826, AUC - 0.7923, F1 - 0.7236, precision - 0.6729, training time - -7.0 seconds
2023-03-25 19:00:42,004 : [INFO]  Batch 372: Testing set : loss - 0.5673, accuracy - 0.701, recall - 0.8333, AUC - 0.8415, F1 - 0.7359, precision - 0.6589
2023-03-25 19:00:42,011 : [INFO]  Batch 373 initialized 
2023-03-25 19:00:42,462 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:43,381 : [INFO]  ------------------------- Batch 373 training: round 1 -------------------------
2023-03-25 19:00:47,055 : [INFO]  ------------------------- Batch round 1, loss: 0.6132 -------------------------
2023-03-25 19:00:47,055 : [INFO]  ------------------------- Batch 373, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:47,069 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:47,071 : [INFO]  ------------------------- Batch 373 training: round 2 -------------------------
2023-03-25 19:00:49,005 : [INFO]  ------------------------- Batch round 2, loss: 0.615 -------------------------
2023-03-25 19:00:49,005 : [INFO]  ------------------------- Batch 373, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:49,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:49,024 : [INFO]  ------------------------- Batch 373 training: round 3 -------------------------
2023-03-25 19:00:51,002 : [INFO]  ------------------------- Batch round 3, loss: 0.6143 -------------------------
2023-03-25 19:00:51,002 : [INFO]  ------------------------- Batch 373, round 3: Sent local model to the server -------------------------
2023-03-25 19:00:51,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:51,044 : [INFO]  Batch number 373 model fetched from the server
2023-03-25 19:00:51,044 : [INFO]  ################ Batch 373: final global model evalution after 3 rounds ################
2023-03-25 19:00:52,250 : [INFO]  Batch 373: Training set : loss - 0.6345, accuracy - 0.5815, recall - 0.6848, AUC - 0.7004, F1 - 0.6207, precision - 0.5676, training time - -8.0 seconds
2023-03-25 19:00:52,251 : [INFO]  Batch 373: Testing set : loss - 0.6281, accuracy - 0.6422, recall - 0.7549, AUC - 0.7364, F1 - 0.6784, precision - 0.616
2023-03-25 19:00:52,259 : [INFO]  Batch 374 initialized 
2023-03-25 19:00:52,717 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:00:53,628 : [INFO]  ------------------------- Batch 374 training: round 1 -------------------------
2023-03-25 19:00:57,165 : [INFO]  ------------------------- Batch round 1, loss: 0.5837 -------------------------
2023-03-25 19:00:57,165 : [INFO]  ------------------------- Batch 374, round 1: Sent local model to the server -------------------------
2023-03-25 19:00:57,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:57,182 : [INFO]  ------------------------- Batch 374 training: round 2 -------------------------
2023-03-25 19:00:59,088 : [INFO]  ------------------------- Batch round 2, loss: 0.5821 -------------------------
2023-03-25 19:00:59,088 : [INFO]  ------------------------- Batch 374, round 2: Sent local model to the server -------------------------
2023-03-25 19:00:59,103 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:00:59,105 : [INFO]  ------------------------- Batch 374 training: round 3 -------------------------
2023-03-25 19:01:00,980 : [INFO]  ------------------------- Batch round 3, loss: 0.587 -------------------------
2023-03-25 19:01:00,980 : [INFO]  ------------------------- Batch 374, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:00,996 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:00,997 : [INFO]  Batch number 374 model fetched from the server
2023-03-25 19:01:00,998 : [INFO]  ################ Batch 374: final global model evalution after 3 rounds ################
2023-03-25 19:01:02,192 : [INFO]  Batch 374: Training set : loss - 0.5913, accuracy - 0.6576, recall - 0.8152, AUC - 0.8173, F1 - 0.7042, precision - 0.6198, training time - -7.0 seconds
2023-03-25 19:01:02,193 : [INFO]  Batch 374: Testing set : loss - 0.5831, accuracy - 0.6912, recall - 0.8235, AUC - 0.8295, F1 - 0.7273, precision - 0.6512
2023-03-25 19:01:02,207 : [INFO]  Batch 375 initialized 
2023-03-25 19:01:02,663 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:03,582 : [INFO]  ------------------------- Batch 375 training: round 1 -------------------------
2023-03-25 19:01:07,094 : [INFO]  ------------------------- Batch round 1, loss: 0.5806 -------------------------
2023-03-25 19:01:07,094 : [INFO]  ------------------------- Batch 375, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:07,132 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:07,135 : [INFO]  ------------------------- Batch 375 training: round 2 -------------------------
2023-03-25 19:01:08,916 : [INFO]  ------------------------- Batch round 2, loss: 0.5759 -------------------------
2023-03-25 19:01:08,916 : [INFO]  ------------------------- Batch 375, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:08,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:08,967 : [INFO]  ------------------------- Batch 375 training: round 3 -------------------------
2023-03-25 19:01:10,775 : [INFO]  ------------------------- Batch round 3, loss: 0.5764 -------------------------
2023-03-25 19:01:10,776 : [INFO]  ------------------------- Batch 375, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:10,835 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:10,837 : [INFO]  Batch number 375 model fetched from the server
2023-03-25 19:01:10,837 : [INFO]  ################ Batch 375: final global model evalution after 3 rounds ################
2023-03-25 19:01:12,050 : [INFO]  Batch 375: Training set : loss - 0.588, accuracy - 0.7174, recall - 0.8152, AUC - 0.8185, F1 - 0.7426, precision - 0.6818, training time - -7.0 seconds
2023-03-25 19:01:12,050 : [INFO]  Batch 375: Testing set : loss - 0.59, accuracy - 0.652, recall - 0.7941, AUC - 0.8048, F1 - 0.6953, precision - 0.6183
2023-03-25 19:01:12,058 : [INFO]  Batch 376 initialized 
2023-03-25 19:01:12,519 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:13,438 : [INFO]  ------------------------- Batch 376 training: round 1 -------------------------
2023-03-25 19:01:16,952 : [INFO]  ------------------------- Batch round 1, loss: 0.5556 -------------------------
2023-03-25 19:01:16,952 : [INFO]  ------------------------- Batch 376, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:17,071 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:17,073 : [INFO]  ------------------------- Batch 376 training: round 2 -------------------------
2023-03-25 19:01:18,871 : [INFO]  ------------------------- Batch round 2, loss: 0.5538 -------------------------
2023-03-25 19:01:18,871 : [INFO]  ------------------------- Batch 376, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:18,944 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:18,947 : [INFO]  ------------------------- Batch 376 training: round 3 -------------------------
2023-03-25 19:01:20,755 : [INFO]  ------------------------- Batch round 3, loss: 0.5557 -------------------------
2023-03-25 19:01:20,756 : [INFO]  ------------------------- Batch 376, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:20,804 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:20,806 : [INFO]  Batch number 376 model fetched from the server
2023-03-25 19:01:20,806 : [INFO]  ################ Batch 376: final global model evalution after 3 rounds ################
2023-03-25 19:01:22,016 : [INFO]  Batch 376: Training set : loss - 0.5689, accuracy - 0.6957, recall - 0.8696, AUC - 0.8552, F1 - 0.7407, precision - 0.6452, training time - -7.0 seconds
2023-03-25 19:01:22,016 : [INFO]  Batch 376: Testing set : loss - 0.5788, accuracy - 0.7157, recall - 0.8824, AUC - 0.8586, F1 - 0.7563, precision - 0.6618
2023-03-25 19:01:22,031 : [INFO]  Batch 377 initialized 
2023-03-25 19:01:22,481 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:23,418 : [INFO]  ------------------------- Batch 377 training: round 1 -------------------------
2023-03-25 19:01:26,846 : [INFO]  ------------------------- Batch round 1, loss: 0.5754 -------------------------
2023-03-25 19:01:26,847 : [INFO]  ------------------------- Batch 377, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:26,861 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:26,863 : [INFO]  ------------------------- Batch 377 training: round 2 -------------------------
2023-03-25 19:01:28,728 : [INFO]  ------------------------- Batch round 2, loss: 0.5826 -------------------------
2023-03-25 19:01:28,728 : [INFO]  ------------------------- Batch 377, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:28,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:28,746 : [INFO]  ------------------------- Batch 377 training: round 3 -------------------------
2023-03-25 19:01:30,579 : [INFO]  ------------------------- Batch round 3, loss: 0.5754 -------------------------
2023-03-25 19:01:30,579 : [INFO]  ------------------------- Batch 377, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:30,593 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:30,595 : [INFO]  Batch number 377 model fetched from the server
2023-03-25 19:01:30,596 : [INFO]  ################ Batch 377: final global model evalution after 3 rounds ################
2023-03-25 19:01:31,807 : [INFO]  Batch 377: Training set : loss - 0.59, accuracy - 0.6467, recall - 0.8152, AUC - 0.8191, F1 - 0.6977, precision - 0.6098, training time - -7.0 seconds
2023-03-25 19:01:31,807 : [INFO]  Batch 377: Testing set : loss - 0.6015, accuracy - 0.6569, recall - 0.8039, AUC - 0.7973, F1 - 0.7009, precision - 0.6212
2023-03-25 19:01:31,820 : [INFO]  Batch 378 initialized 
2023-03-25 19:01:32,274 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:33,220 : [INFO]  ------------------------- Batch 378 training: round 1 -------------------------
2023-03-25 19:01:36,741 : [INFO]  ------------------------- Batch round 1, loss: 0.5647 -------------------------
2023-03-25 19:01:36,741 : [INFO]  ------------------------- Batch 378, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:36,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:36,761 : [INFO]  ------------------------- Batch 378 training: round 2 -------------------------
2023-03-25 19:01:38,622 : [INFO]  ------------------------- Batch round 2, loss: 0.5732 -------------------------
2023-03-25 19:01:38,622 : [INFO]  ------------------------- Batch 378, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:38,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:38,639 : [INFO]  ------------------------- Batch 378 training: round 3 -------------------------
2023-03-25 19:01:40,441 : [INFO]  ------------------------- Batch round 3, loss: 0.5679 -------------------------
2023-03-25 19:01:40,441 : [INFO]  ------------------------- Batch 378, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:40,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:40,460 : [INFO]  Batch number 378 model fetched from the server
2023-03-25 19:01:40,460 : [INFO]  ################ Batch 378: final global model evalution after 3 rounds ################
2023-03-25 19:01:41,652 : [INFO]  Batch 378: Training set : loss - 0.5827, accuracy - 0.6793, recall - 0.837, AUC - 0.8407, F1 - 0.723, precision - 0.6364, training time - -7.0 seconds
2023-03-25 19:01:41,652 : [INFO]  Batch 378: Testing set : loss - 0.5805, accuracy - 0.701, recall - 0.8137, AUC - 0.8217, F1 - 0.7313, precision - 0.664
2023-03-25 19:01:41,674 : [INFO]  Batch 379 initialized 
2023-03-25 19:01:42,126 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:43,046 : [INFO]  ------------------------- Batch 379 training: round 1 -------------------------
2023-03-25 19:01:46,638 : [INFO]  ------------------------- Batch round 1, loss: 0.58 -------------------------
2023-03-25 19:01:46,638 : [INFO]  ------------------------- Batch 379, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:46,652 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:46,655 : [INFO]  ------------------------- Batch 379 training: round 2 -------------------------
2023-03-25 19:01:48,757 : [INFO]  ------------------------- Batch round 2, loss: 0.5837 -------------------------
2023-03-25 19:01:48,757 : [INFO]  ------------------------- Batch 379, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:48,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:48,775 : [INFO]  ------------------------- Batch 379 training: round 3 -------------------------
2023-03-25 19:01:50,636 : [INFO]  ------------------------- Batch round 3, loss: 0.5751 -------------------------
2023-03-25 19:01:50,637 : [INFO]  ------------------------- Batch 379, round 3: Sent local model to the server -------------------------
2023-03-25 19:01:50,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:50,658 : [INFO]  Batch number 379 model fetched from the server
2023-03-25 19:01:50,658 : [INFO]  ################ Batch 379: final global model evalution after 3 rounds ################
2023-03-25 19:01:51,865 : [INFO]  Batch 379: Training set : loss - 0.5916, accuracy - 0.663, recall - 0.7935, AUC - 0.7948, F1 - 0.7019, precision - 0.6293, training time - -8.0 seconds
2023-03-25 19:01:51,865 : [INFO]  Batch 379: Testing set : loss - 0.5657, accuracy - 0.7255, recall - 0.8431, AUC - 0.8474, F1 - 0.7544, precision - 0.6825
2023-03-25 19:01:51,880 : [INFO]  Batch 380 initialized 
2023-03-25 19:01:52,327 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:01:53,269 : [INFO]  ------------------------- Batch 380 training: round 1 -------------------------
2023-03-25 19:01:56,746 : [INFO]  ------------------------- Batch round 1, loss: 0.5595 -------------------------
2023-03-25 19:01:56,746 : [INFO]  ------------------------- Batch 380, round 1: Sent local model to the server -------------------------
2023-03-25 19:01:56,809 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:56,812 : [INFO]  ------------------------- Batch 380 training: round 2 -------------------------
2023-03-25 19:01:58,596 : [INFO]  ------------------------- Batch round 2, loss: 0.5542 -------------------------
2023-03-25 19:01:58,596 : [INFO]  ------------------------- Batch 380, round 2: Sent local model to the server -------------------------
2023-03-25 19:01:58,612 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:01:58,615 : [INFO]  ------------------------- Batch 380 training: round 3 -------------------------
2023-03-25 19:02:00,411 : [INFO]  ------------------------- Batch round 3, loss: 0.5618 -------------------------
2023-03-25 19:02:00,411 : [INFO]  ------------------------- Batch 380, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:00,427 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:00,429 : [INFO]  Batch number 380 model fetched from the server
2023-03-25 19:02:00,429 : [INFO]  ################ Batch 380: final global model evalution after 3 rounds ################
2023-03-25 19:02:01,623 : [INFO]  Batch 380: Training set : loss - 0.5699, accuracy - 0.7011, recall - 0.7935, AUC - 0.8212, F1 - 0.7264, precision - 0.6697, training time - -7.0 seconds
2023-03-25 19:02:01,623 : [INFO]  Batch 380: Testing set : loss - 0.6067, accuracy - 0.6324, recall - 0.7745, AUC - 0.7907, F1 - 0.6781, precision - 0.6031
2023-03-25 19:02:01,640 : [INFO]  Batch 381 initialized 
2023-03-25 19:02:02,106 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:03,026 : [INFO]  ------------------------- Batch 381 training: round 1 -------------------------
2023-03-25 19:02:06,562 : [INFO]  ------------------------- Batch round 1, loss: 0.59 -------------------------
2023-03-25 19:02:06,562 : [INFO]  ------------------------- Batch 381, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:06,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:06,580 : [INFO]  ------------------------- Batch 381 training: round 2 -------------------------
2023-03-25 19:02:08,433 : [INFO]  ------------------------- Batch round 2, loss: 0.5906 -------------------------
2023-03-25 19:02:08,433 : [INFO]  ------------------------- Batch 381, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:08,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:08,450 : [INFO]  ------------------------- Batch 381 training: round 3 -------------------------
2023-03-25 19:02:10,262 : [INFO]  ------------------------- Batch round 3, loss: 0.5893 -------------------------
2023-03-25 19:02:10,262 : [INFO]  ------------------------- Batch 381, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:10,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:10,289 : [INFO]  Batch number 381 model fetched from the server
2023-03-25 19:02:10,289 : [INFO]  ################ Batch 381: final global model evalution after 3 rounds ################
2023-03-25 19:02:11,479 : [INFO]  Batch 381: Training set : loss - 0.6018, accuracy - 0.6793, recall - 0.7826, AUC - 0.7781, F1 - 0.7094, precision - 0.6486, training time - -7.0 seconds
2023-03-25 19:02:11,479 : [INFO]  Batch 381: Testing set : loss - 0.5576, accuracy - 0.7549, recall - 0.8627, AUC - 0.8832, F1 - 0.7788, precision - 0.7097
2023-03-25 19:02:11,488 : [INFO]  Batch 382 initialized 
2023-03-25 19:02:11,963 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:12,899 : [INFO]  ------------------------- Batch 382 training: round 1 -------------------------
2023-03-25 19:02:16,362 : [INFO]  ------------------------- Batch round 1, loss: 0.5728 -------------------------
2023-03-25 19:02:16,363 : [INFO]  ------------------------- Batch 382, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:16,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:16,457 : [INFO]  ------------------------- Batch 382 training: round 2 -------------------------
2023-03-25 19:02:18,245 : [INFO]  ------------------------- Batch round 2, loss: 0.5754 -------------------------
2023-03-25 19:02:18,245 : [INFO]  ------------------------- Batch 382, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:18,300 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:18,302 : [INFO]  ------------------------- Batch 382 training: round 3 -------------------------
2023-03-25 19:02:20,087 : [INFO]  ------------------------- Batch round 3, loss: 0.5722 -------------------------
2023-03-25 19:02:20,087 : [INFO]  ------------------------- Batch 382, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:20,125 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:20,127 : [INFO]  Batch number 382 model fetched from the server
2023-03-25 19:02:20,127 : [INFO]  ################ Batch 382: final global model evalution after 3 rounds ################
2023-03-25 19:02:21,309 : [INFO]  Batch 382: Training set : loss - 0.5851, accuracy - 0.6902, recall - 0.8478, AUC - 0.8417, F1 - 0.7324, precision - 0.6446, training time - -7.0 seconds
2023-03-25 19:02:21,309 : [INFO]  Batch 382: Testing set : loss - 0.5959, accuracy - 0.6961, recall - 0.8039, AUC - 0.7942, F1 - 0.7257, precision - 0.6613
2023-03-25 19:02:21,322 : [INFO]  Batch 383 initialized 
2023-03-25 19:02:21,775 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:22,689 : [INFO]  ------------------------- Batch 383 training: round 1 -------------------------
2023-03-25 19:02:26,342 : [INFO]  ------------------------- Batch round 1, loss: 0.5614 -------------------------
2023-03-25 19:02:26,342 : [INFO]  ------------------------- Batch 383, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:26,466 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:26,468 : [INFO]  ------------------------- Batch 383 training: round 2 -------------------------
2023-03-25 19:02:28,314 : [INFO]  ------------------------- Batch round 2, loss: 0.5578 -------------------------
2023-03-25 19:02:28,314 : [INFO]  ------------------------- Batch 383, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:28,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:28,344 : [INFO]  ------------------------- Batch 383 training: round 3 -------------------------
2023-03-25 19:02:30,158 : [INFO]  ------------------------- Batch round 3, loss: 0.5624 -------------------------
2023-03-25 19:02:30,158 : [INFO]  ------------------------- Batch 383, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:30,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:30,221 : [INFO]  Batch number 383 model fetched from the server
2023-03-25 19:02:30,221 : [INFO]  ################ Batch 383: final global model evalution after 3 rounds ################
2023-03-25 19:02:31,443 : [INFO]  Batch 383: Training set : loss - 0.5703, accuracy - 0.6957, recall - 0.9239, AUC - 0.8848, F1 - 0.7522, precision - 0.6343, training time - -8.0 seconds
2023-03-25 19:02:31,444 : [INFO]  Batch 383: Testing set : loss - 0.5955, accuracy - 0.6471, recall - 0.7843, AUC - 0.8026, F1 - 0.6897, precision - 0.6154
2023-03-25 19:02:31,455 : [INFO]  Batch 384 initialized 
2023-03-25 19:02:31,912 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:32,867 : [INFO]  ------------------------- Batch 384 training: round 1 -------------------------
2023-03-25 19:02:36,341 : [INFO]  ------------------------- Batch round 1, loss: 0.5813 -------------------------
2023-03-25 19:02:36,342 : [INFO]  ------------------------- Batch 384, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:36,371 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:36,374 : [INFO]  ------------------------- Batch 384 training: round 2 -------------------------
2023-03-25 19:02:38,192 : [INFO]  ------------------------- Batch round 2, loss: 0.5825 -------------------------
2023-03-25 19:02:38,192 : [INFO]  ------------------------- Batch 384, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:38,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:38,239 : [INFO]  ------------------------- Batch 384 training: round 3 -------------------------
2023-03-25 19:02:39,988 : [INFO]  ------------------------- Batch round 3, loss: 0.5811 -------------------------
2023-03-25 19:02:39,988 : [INFO]  ------------------------- Batch 384, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:40,019 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:40,021 : [INFO]  Batch number 384 model fetched from the server
2023-03-25 19:02:40,021 : [INFO]  ################ Batch 384: final global model evalution after 3 rounds ################
2023-03-25 19:02:41,273 : [INFO]  Batch 384: Training set : loss - 0.5945, accuracy - 0.6739, recall - 0.8152, AUC - 0.8168, F1 - 0.7143, precision - 0.6356, training time - -7.0 seconds
2023-03-25 19:02:41,274 : [INFO]  Batch 384: Testing set : loss - 0.5859, accuracy - 0.6667, recall - 0.7549, AUC - 0.8195, F1 - 0.6937, precision - 0.6417
2023-03-25 19:02:41,281 : [INFO]  Batch 385 initialized 
2023-03-25 19:02:41,737 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:42,680 : [INFO]  ------------------------- Batch 385 training: round 1 -------------------------
2023-03-25 19:02:46,161 : [INFO]  ------------------------- Batch round 1, loss: 0.5976 -------------------------
2023-03-25 19:02:46,161 : [INFO]  ------------------------- Batch 385, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:46,218 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:46,220 : [INFO]  ------------------------- Batch 385 training: round 2 -------------------------
2023-03-25 19:02:48,013 : [INFO]  ------------------------- Batch round 2, loss: 0.5982 -------------------------
2023-03-25 19:02:48,013 : [INFO]  ------------------------- Batch 385, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:48,047 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:48,049 : [INFO]  ------------------------- Batch 385 training: round 3 -------------------------
2023-03-25 19:02:49,869 : [INFO]  ------------------------- Batch round 3, loss: 0.596 -------------------------
2023-03-25 19:02:49,869 : [INFO]  ------------------------- Batch 385, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:49,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:49,893 : [INFO]  Batch number 385 model fetched from the server
2023-03-25 19:02:49,893 : [INFO]  ################ Batch 385: final global model evalution after 3 rounds ################
2023-03-25 19:02:51,078 : [INFO]  Batch 385: Training set : loss - 0.6089, accuracy - 0.6304, recall - 0.7935, AUC - 0.7938, F1 - 0.6822, precision - 0.5984, training time - -7.0 seconds
2023-03-25 19:02:51,078 : [INFO]  Batch 385: Testing set : loss - 0.5911, accuracy - 0.6618, recall - 0.8039, AUC - 0.8174, F1 - 0.7039, precision - 0.626
2023-03-25 19:02:51,097 : [INFO]  Batch 386 initialized 
2023-03-25 19:02:51,559 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:02:52,510 : [INFO]  ------------------------- Batch 386 training: round 1 -------------------------
2023-03-25 19:02:55,924 : [INFO]  ------------------------- Batch round 1, loss: 0.5582 -------------------------
2023-03-25 19:02:55,924 : [INFO]  ------------------------- Batch 386, round 1: Sent local model to the server -------------------------
2023-03-25 19:02:55,976 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:55,978 : [INFO]  ------------------------- Batch 386 training: round 2 -------------------------
2023-03-25 19:02:57,813 : [INFO]  ------------------------- Batch round 2, loss: 0.5521 -------------------------
2023-03-25 19:02:57,814 : [INFO]  ------------------------- Batch 386, round 2: Sent local model to the server -------------------------
2023-03-25 19:02:57,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:57,915 : [INFO]  ------------------------- Batch 386 training: round 3 -------------------------
2023-03-25 19:02:59,685 : [INFO]  ------------------------- Batch round 3, loss: 0.5492 -------------------------
2023-03-25 19:02:59,685 : [INFO]  ------------------------- Batch 386, round 3: Sent local model to the server -------------------------
2023-03-25 19:02:59,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:02:59,804 : [INFO]  Batch number 386 model fetched from the server
2023-03-25 19:02:59,804 : [INFO]  ################ Batch 386: final global model evalution after 3 rounds ################
2023-03-25 19:03:00,997 : [INFO]  Batch 386: Training set : loss - 0.5639, accuracy - 0.7283, recall - 0.9239, AUC - 0.8924, F1 - 0.7727, precision - 0.6641, training time - -7.0 seconds
2023-03-25 19:03:00,997 : [INFO]  Batch 386: Testing set : loss - 0.5952, accuracy - 0.701, recall - 0.8039, AUC - 0.7883, F1 - 0.7289, precision - 0.6667
2023-03-25 19:03:01,016 : [INFO]  Batch 387 initialized 
2023-03-25 19:03:01,475 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:02,417 : [INFO]  ------------------------- Batch 387 training: round 1 -------------------------
2023-03-25 19:03:05,987 : [INFO]  ------------------------- Batch round 1, loss: 0.5744 -------------------------
2023-03-25 19:03:05,987 : [INFO]  ------------------------- Batch 387, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:06,003 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:06,005 : [INFO]  ------------------------- Batch 387 training: round 2 -------------------------
2023-03-25 19:03:07,845 : [INFO]  ------------------------- Batch round 2, loss: 0.5761 -------------------------
2023-03-25 19:03:07,846 : [INFO]  ------------------------- Batch 387, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:07,875 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:07,878 : [INFO]  ------------------------- Batch 387 training: round 3 -------------------------
2023-03-25 19:03:09,730 : [INFO]  ------------------------- Batch round 3, loss: 0.5729 -------------------------
2023-03-25 19:03:09,731 : [INFO]  ------------------------- Batch 387, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:09,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:09,752 : [INFO]  Batch number 387 model fetched from the server
2023-03-25 19:03:09,752 : [INFO]  ################ Batch 387: final global model evalution after 3 rounds ################
2023-03-25 19:03:10,971 : [INFO]  Batch 387: Training set : loss - 0.5818, accuracy - 0.7011, recall - 0.8261, AUC - 0.8269, F1 - 0.7343, precision - 0.6609, training time - -7.0 seconds
2023-03-25 19:03:10,972 : [INFO]  Batch 387: Testing set : loss - 0.596, accuracy - 0.6912, recall - 0.8039, AUC - 0.8042, F1 - 0.7225, precision - 0.656
2023-03-25 19:03:11,039 : [INFO]  Batch 388 initialized 
2023-03-25 19:03:11,484 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:12,402 : [INFO]  ------------------------- Batch 388 training: round 1 -------------------------
2023-03-25 19:03:15,824 : [INFO]  ------------------------- Batch round 1, loss: 0.5564 -------------------------
2023-03-25 19:03:15,824 : [INFO]  ------------------------- Batch 388, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:15,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:15,899 : [INFO]  ------------------------- Batch 388 training: round 2 -------------------------
2023-03-25 19:03:17,676 : [INFO]  ------------------------- Batch round 2, loss: 0.5581 -------------------------
2023-03-25 19:03:17,677 : [INFO]  ------------------------- Batch 388, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:17,712 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:17,715 : [INFO]  ------------------------- Batch 388 training: round 3 -------------------------
2023-03-25 19:03:19,513 : [INFO]  ------------------------- Batch round 3, loss: 0.5601 -------------------------
2023-03-25 19:03:19,514 : [INFO]  ------------------------- Batch 388, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:19,545 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:19,548 : [INFO]  Batch number 388 model fetched from the server
2023-03-25 19:03:19,548 : [INFO]  ################ Batch 388: final global model evalution after 3 rounds ################
2023-03-25 19:03:20,735 : [INFO]  Batch 388: Training set : loss - 0.563, accuracy - 0.7283, recall - 0.8587, AUC - 0.8696, F1 - 0.7596, precision - 0.681, training time - -7.0 seconds
2023-03-25 19:03:20,735 : [INFO]  Batch 388: Testing set : loss - 0.5696, accuracy - 0.6765, recall - 0.8529, AUC - 0.8596, F1 - 0.725, precision - 0.6304
2023-03-25 19:03:20,750 : [INFO]  Batch 389 initialized 
2023-03-25 19:03:21,210 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:22,156 : [INFO]  ------------------------- Batch 389 training: round 1 -------------------------
2023-03-25 19:03:25,688 : [INFO]  ------------------------- Batch round 1, loss: 0.5835 -------------------------
2023-03-25 19:03:25,688 : [INFO]  ------------------------- Batch 389, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:25,703 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:25,706 : [INFO]  ------------------------- Batch 389 training: round 2 -------------------------
2023-03-25 19:03:27,600 : [INFO]  ------------------------- Batch round 2, loss: 0.5828 -------------------------
2023-03-25 19:03:27,600 : [INFO]  ------------------------- Batch 389, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:27,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:27,618 : [INFO]  ------------------------- Batch 389 training: round 3 -------------------------
2023-03-25 19:03:29,433 : [INFO]  ------------------------- Batch round 3, loss: 0.587 -------------------------
2023-03-25 19:03:29,434 : [INFO]  ------------------------- Batch 389, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:29,449 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:29,451 : [INFO]  Batch number 389 model fetched from the server
2023-03-25 19:03:29,451 : [INFO]  ################ Batch 389: final global model evalution after 3 rounds ################
2023-03-25 19:03:30,639 : [INFO]  Batch 389: Training set : loss - 0.5976, accuracy - 0.6739, recall - 0.8913, AUC - 0.8284, F1 - 0.7321, precision - 0.6212, training time - -7.0 seconds
2023-03-25 19:03:30,639 : [INFO]  Batch 389: Testing set : loss - 0.6096, accuracy - 0.6373, recall - 0.8039, AUC - 0.7844, F1 - 0.6891, precision - 0.6029
2023-03-25 19:03:30,656 : [INFO]  Batch 390 initialized 
2023-03-25 19:03:31,119 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:32,071 : [INFO]  ------------------------- Batch 390 training: round 1 -------------------------
2023-03-25 19:03:35,574 : [INFO]  ------------------------- Batch round 1, loss: 0.5701 -------------------------
2023-03-25 19:03:35,574 : [INFO]  ------------------------- Batch 390, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:35,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:35,593 : [INFO]  ------------------------- Batch 390 training: round 2 -------------------------
2023-03-25 19:03:37,390 : [INFO]  ------------------------- Batch round 2, loss: 0.566 -------------------------
2023-03-25 19:03:37,390 : [INFO]  ------------------------- Batch 390, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:37,405 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:37,408 : [INFO]  ------------------------- Batch 390 training: round 3 -------------------------
2023-03-25 19:03:39,246 : [INFO]  ------------------------- Batch round 3, loss: 0.5734 -------------------------
2023-03-25 19:03:39,247 : [INFO]  ------------------------- Batch 390, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:39,263 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:39,266 : [INFO]  Batch number 390 model fetched from the server
2023-03-25 19:03:39,266 : [INFO]  ################ Batch 390: final global model evalution after 3 rounds ################
2023-03-25 19:03:40,484 : [INFO]  Batch 390: Training set : loss - 0.5739, accuracy - 0.7174, recall - 0.8587, AUC - 0.839, F1 - 0.7524, precision - 0.6695, training time - -7.0 seconds
2023-03-25 19:03:40,484 : [INFO]  Batch 390: Testing set : loss - 0.5918, accuracy - 0.6863, recall - 0.8333, AUC - 0.8195, F1 - 0.7265, precision - 0.6439
2023-03-25 19:03:40,492 : [INFO]  Batch 391 initialized 
2023-03-25 19:03:40,944 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:41,866 : [INFO]  ------------------------- Batch 391 training: round 1 -------------------------
2023-03-25 19:03:45,319 : [INFO]  ------------------------- Batch round 1, loss: 0.5588 -------------------------
2023-03-25 19:03:45,319 : [INFO]  ------------------------- Batch 391, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:45,399 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:45,401 : [INFO]  ------------------------- Batch 391 training: round 2 -------------------------
2023-03-25 19:03:47,180 : [INFO]  ------------------------- Batch round 2, loss: 0.5617 -------------------------
2023-03-25 19:03:47,180 : [INFO]  ------------------------- Batch 391, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:47,219 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:47,221 : [INFO]  ------------------------- Batch 391 training: round 3 -------------------------
2023-03-25 19:03:48,973 : [INFO]  ------------------------- Batch round 3, loss: 0.5554 -------------------------
2023-03-25 19:03:48,973 : [INFO]  ------------------------- Batch 391, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:49,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:49,053 : [INFO]  Batch number 391 model fetched from the server
2023-03-25 19:03:49,053 : [INFO]  ################ Batch 391: final global model evalution after 3 rounds ################
2023-03-25 19:03:50,232 : [INFO]  Batch 391: Training set : loss - 0.5618, accuracy - 0.7174, recall - 0.9022, AUC - 0.8859, F1 - 0.7615, precision - 0.6587, training time - -7.0 seconds
2023-03-25 19:03:50,232 : [INFO]  Batch 391: Testing set : loss - 0.5984, accuracy - 0.6373, recall - 0.8039, AUC - 0.7982, F1 - 0.6891, precision - 0.6029
2023-03-25 19:03:50,239 : [INFO]  Batch 392 initialized 
2023-03-25 19:03:50,692 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:03:51,635 : [INFO]  ------------------------- Batch 392 training: round 1 -------------------------
2023-03-25 19:03:55,161 : [INFO]  ------------------------- Batch round 1, loss: 0.5686 -------------------------
2023-03-25 19:03:55,161 : [INFO]  ------------------------- Batch 392, round 1: Sent local model to the server -------------------------
2023-03-25 19:03:55,261 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:55,263 : [INFO]  ------------------------- Batch 392 training: round 2 -------------------------
2023-03-25 19:03:57,082 : [INFO]  ------------------------- Batch round 2, loss: 0.5662 -------------------------
2023-03-25 19:03:57,082 : [INFO]  ------------------------- Batch 392, round 2: Sent local model to the server -------------------------
2023-03-25 19:03:57,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:57,150 : [INFO]  ------------------------- Batch 392 training: round 3 -------------------------
2023-03-25 19:03:58,988 : [INFO]  ------------------------- Batch round 3, loss: 0.5669 -------------------------
2023-03-25 19:03:58,988 : [INFO]  ------------------------- Batch 392, round 3: Sent local model to the server -------------------------
2023-03-25 19:03:59,027 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:03:59,029 : [INFO]  Batch number 392 model fetched from the server
2023-03-25 19:03:59,029 : [INFO]  ################ Batch 392: final global model evalution after 3 rounds ################
2023-03-25 19:04:00,230 : [INFO]  Batch 392: Training set : loss - 0.5774, accuracy - 0.663, recall - 0.7826, AUC - 0.8277, F1 - 0.699, precision - 0.6316, training time - -7.0 seconds
2023-03-25 19:04:00,230 : [INFO]  Batch 392: Testing set : loss - 0.5763, accuracy - 0.6961, recall - 0.8627, AUC - 0.8397, F1 - 0.7395, precision - 0.6471
2023-03-25 19:04:00,245 : [INFO]  Batch 393 initialized 
2023-03-25 19:04:00,689 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:01,626 : [INFO]  ------------------------- Batch 393 training: round 1 -------------------------
2023-03-25 19:04:05,118 : [INFO]  ------------------------- Batch round 1, loss: 0.56 -------------------------
2023-03-25 19:04:05,119 : [INFO]  ------------------------- Batch 393, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:05,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:05,274 : [INFO]  ------------------------- Batch 393 training: round 2 -------------------------
2023-03-25 19:04:07,046 : [INFO]  ------------------------- Batch round 2, loss: 0.5639 -------------------------
2023-03-25 19:04:07,046 : [INFO]  ------------------------- Batch 393, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:07,193 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:07,195 : [INFO]  ------------------------- Batch 393 training: round 3 -------------------------
2023-03-25 19:04:09,085 : [INFO]  ------------------------- Batch round 3, loss: 0.5582 -------------------------
2023-03-25 19:04:09,085 : [INFO]  ------------------------- Batch 393, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:09,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:09,234 : [INFO]  Batch number 393 model fetched from the server
2023-03-25 19:04:09,235 : [INFO]  ################ Batch 393: final global model evalution after 3 rounds ################
2023-03-25 19:04:10,408 : [INFO]  Batch 393: Training set : loss - 0.567, accuracy - 0.7228, recall - 0.8478, AUC - 0.8533, F1 - 0.7536, precision - 0.6783, training time - -8.0 seconds
2023-03-25 19:04:10,409 : [INFO]  Batch 393: Testing set : loss - 0.5865, accuracy - 0.6863, recall - 0.8137, AUC - 0.822, F1 - 0.7217, precision - 0.6484
2023-03-25 19:04:10,423 : [INFO]  Batch 394 initialized 
2023-03-25 19:04:10,881 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:11,792 : [INFO]  ------------------------- Batch 394 training: round 1 -------------------------
2023-03-25 19:04:15,402 : [INFO]  ------------------------- Batch round 1, loss: 0.573 -------------------------
2023-03-25 19:04:15,403 : [INFO]  ------------------------- Batch 394, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:15,545 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:15,547 : [INFO]  ------------------------- Batch 394 training: round 2 -------------------------
2023-03-25 19:04:17,318 : [INFO]  ------------------------- Batch round 2, loss: 0.5771 -------------------------
2023-03-25 19:04:17,318 : [INFO]  ------------------------- Batch 394, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:17,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:17,391 : [INFO]  ------------------------- Batch 394 training: round 3 -------------------------
2023-03-25 19:04:19,179 : [INFO]  ------------------------- Batch round 3, loss: 0.5731 -------------------------
2023-03-25 19:04:19,179 : [INFO]  ------------------------- Batch 394, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:19,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:19,217 : [INFO]  Batch number 394 model fetched from the server
2023-03-25 19:04:19,217 : [INFO]  ################ Batch 394: final global model evalution after 3 rounds ################
2023-03-25 19:04:20,433 : [INFO]  Batch 394: Training set : loss - 0.581, accuracy - 0.712, recall - 0.8804, AUC - 0.8417, F1 - 0.7535, precision - 0.6585, training time - -7.0 seconds
2023-03-25 19:04:20,433 : [INFO]  Batch 394: Testing set : loss - 0.5987, accuracy - 0.6667, recall - 0.8039, AUC - 0.7996, F1 - 0.7069, precision - 0.6308
2023-03-25 19:04:20,441 : [INFO]  Batch 395 initialized 
2023-03-25 19:04:20,928 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:21,866 : [INFO]  ------------------------- Batch 395 training: round 1 -------------------------
2023-03-25 19:04:25,552 : [INFO]  ------------------------- Batch round 1, loss: 0.5839 -------------------------
2023-03-25 19:04:25,553 : [INFO]  ------------------------- Batch 395, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:25,573 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:25,575 : [INFO]  ------------------------- Batch 395 training: round 2 -------------------------
2023-03-25 19:04:27,468 : [INFO]  ------------------------- Batch round 2, loss: 0.5851 -------------------------
2023-03-25 19:04:27,468 : [INFO]  ------------------------- Batch 395, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:27,484 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:27,487 : [INFO]  ------------------------- Batch 395 training: round 3 -------------------------
2023-03-25 19:04:29,312 : [INFO]  ------------------------- Batch round 3, loss: 0.5861 -------------------------
2023-03-25 19:04:29,313 : [INFO]  ------------------------- Batch 395, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:29,329 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:29,331 : [INFO]  Batch number 395 model fetched from the server
2023-03-25 19:04:29,331 : [INFO]  ################ Batch 395: final global model evalution after 3 rounds ################
2023-03-25 19:04:30,532 : [INFO]  Batch 395: Training set : loss - 0.5898, accuracy - 0.7011, recall - 0.8043, AUC - 0.8111, F1 - 0.7291, precision - 0.6667, training time - -7.0 seconds
2023-03-25 19:04:30,532 : [INFO]  Batch 395: Testing set : loss - 0.5992, accuracy - 0.6422, recall - 0.7255, AUC - 0.7742, F1 - 0.6697, precision - 0.6218
2023-03-25 19:04:30,548 : [INFO]  Batch 396 initialized 
2023-03-25 19:04:31,012 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:31,961 : [INFO]  ------------------------- Batch 396 training: round 1 -------------------------
2023-03-25 19:04:35,521 : [INFO]  ------------------------- Batch round 1, loss: 0.5854 -------------------------
2023-03-25 19:04:35,521 : [INFO]  ------------------------- Batch 396, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:35,538 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:35,540 : [INFO]  ------------------------- Batch 396 training: round 2 -------------------------
2023-03-25 19:04:37,399 : [INFO]  ------------------------- Batch round 2, loss: 0.5868 -------------------------
2023-03-25 19:04:37,399 : [INFO]  ------------------------- Batch 396, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:37,415 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:37,416 : [INFO]  ------------------------- Batch 396 training: round 3 -------------------------
2023-03-25 19:04:39,276 : [INFO]  ------------------------- Batch round 3, loss: 0.581 -------------------------
2023-03-25 19:04:39,276 : [INFO]  ------------------------- Batch 396, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:39,291 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:39,293 : [INFO]  Batch number 396 model fetched from the server
2023-03-25 19:04:39,294 : [INFO]  ################ Batch 396: final global model evalution after 3 rounds ################
2023-03-25 19:04:40,508 : [INFO]  Batch 396: Training set : loss - 0.5982, accuracy - 0.6902, recall - 0.8261, AUC - 0.8132, F1 - 0.7273, precision - 0.6496, training time - -7.0 seconds
2023-03-25 19:04:40,509 : [INFO]  Batch 396: Testing set : loss - 0.5733, accuracy - 0.701, recall - 0.8137, AUC - 0.8335, F1 - 0.7313, precision - 0.664
2023-03-25 19:04:40,518 : [INFO]  Batch 397 initialized 
2023-03-25 19:04:41,019 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:41,985 : [INFO]  ------------------------- Batch 397 training: round 1 -------------------------
2023-03-25 19:04:45,614 : [INFO]  ------------------------- Batch round 1, loss: 0.574 -------------------------
2023-03-25 19:04:45,614 : [INFO]  ------------------------- Batch 397, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:45,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:45,633 : [INFO]  ------------------------- Batch 397 training: round 2 -------------------------
2023-03-25 19:04:47,479 : [INFO]  ------------------------- Batch round 2, loss: 0.5753 -------------------------
2023-03-25 19:04:47,479 : [INFO]  ------------------------- Batch 397, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:47,499 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:47,501 : [INFO]  ------------------------- Batch 397 training: round 3 -------------------------
2023-03-25 19:04:49,320 : [INFO]  ------------------------- Batch round 3, loss: 0.5676 -------------------------
2023-03-25 19:04:49,320 : [INFO]  ------------------------- Batch 397, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:49,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:49,345 : [INFO]  Batch number 397 model fetched from the server
2023-03-25 19:04:49,345 : [INFO]  ################ Batch 397: final global model evalution after 3 rounds ################
2023-03-25 19:04:50,576 : [INFO]  Batch 397: Training set : loss - 0.5831, accuracy - 0.6793, recall - 0.7391, AUC - 0.7919, F1 - 0.6974, precision - 0.6602, training time - -7.0 seconds
2023-03-25 19:04:50,576 : [INFO]  Batch 397: Testing set : loss - 0.575, accuracy - 0.7402, recall - 0.8039, AUC - 0.8249, F1 - 0.7558, precision - 0.713
2023-03-25 19:04:50,586 : [INFO]  Batch 398 initialized 
2023-03-25 19:04:51,056 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:04:52,059 : [INFO]  ------------------------- Batch 398 training: round 1 -------------------------
2023-03-25 19:04:55,653 : [INFO]  ------------------------- Batch round 1, loss: 0.5865 -------------------------
2023-03-25 19:04:55,653 : [INFO]  ------------------------- Batch 398, round 1: Sent local model to the server -------------------------
2023-03-25 19:04:55,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:55,672 : [INFO]  ------------------------- Batch 398 training: round 2 -------------------------
2023-03-25 19:04:57,530 : [INFO]  ------------------------- Batch round 2, loss: 0.5934 -------------------------
2023-03-25 19:04:57,530 : [INFO]  ------------------------- Batch 398, round 2: Sent local model to the server -------------------------
2023-03-25 19:04:57,548 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:57,551 : [INFO]  ------------------------- Batch 398 training: round 3 -------------------------
2023-03-25 19:04:59,465 : [INFO]  ------------------------- Batch round 3, loss: 0.597 -------------------------
2023-03-25 19:04:59,465 : [INFO]  ------------------------- Batch 398, round 3: Sent local model to the server -------------------------
2023-03-25 19:04:59,483 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:04:59,486 : [INFO]  Batch number 398 model fetched from the server
2023-03-25 19:04:59,486 : [INFO]  ################ Batch 398: final global model evalution after 3 rounds ################
2023-03-25 19:05:00,685 : [INFO]  Batch 398: Training set : loss - 0.6091, accuracy - 0.6033, recall - 0.7717, AUC - 0.7831, F1 - 0.6605, precision - 0.5772, training time - -7.0 seconds
2023-03-25 19:05:00,685 : [INFO]  Batch 398: Testing set : loss - 0.5962, accuracy - 0.6471, recall - 0.8039, AUC - 0.8142, F1 - 0.6949, precision - 0.6119
2023-03-25 19:05:00,714 : [INFO]  Batch 399 initialized 
2023-03-25 19:05:01,204 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:02,193 : [INFO]  ------------------------- Batch 399 training: round 1 -------------------------
2023-03-25 19:05:05,715 : [INFO]  ------------------------- Batch round 1, loss: 0.5929 -------------------------
2023-03-25 19:05:05,715 : [INFO]  ------------------------- Batch 399, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:05,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:05,735 : [INFO]  ------------------------- Batch 399 training: round 2 -------------------------
2023-03-25 19:05:07,553 : [INFO]  ------------------------- Batch round 2, loss: 0.5913 -------------------------
2023-03-25 19:05:07,553 : [INFO]  ------------------------- Batch 399, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:07,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:07,581 : [INFO]  ------------------------- Batch 399 training: round 3 -------------------------
2023-03-25 19:05:09,391 : [INFO]  ------------------------- Batch round 3, loss: 0.5928 -------------------------
2023-03-25 19:05:09,392 : [INFO]  ------------------------- Batch 399, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:09,408 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:09,410 : [INFO]  Batch number 399 model fetched from the server
2023-03-25 19:05:09,410 : [INFO]  ################ Batch 399: final global model evalution after 3 rounds ################
2023-03-25 19:05:10,609 : [INFO]  Batch 399: Training set : loss - 0.6046, accuracy - 0.6576, recall - 0.8043, AUC - 0.7761, F1 - 0.7014, precision - 0.6218, training time - -7.0 seconds
2023-03-25 19:05:10,610 : [INFO]  Batch 399: Testing set : loss - 0.5697, accuracy - 0.6912, recall - 0.8431, AUC - 0.8577, F1 - 0.7319, precision - 0.6466
2023-03-25 19:05:10,617 : [INFO]  Batch 400 initialized 
2023-03-25 19:05:11,082 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:12,086 : [INFO]  ------------------------- Batch 400 training: round 1 -------------------------
2023-03-25 19:05:15,814 : [INFO]  ------------------------- Batch round 1, loss: 0.5709 -------------------------
2023-03-25 19:05:15,814 : [INFO]  ------------------------- Batch 400, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:15,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:15,854 : [INFO]  ------------------------- Batch 400 training: round 2 -------------------------
2023-03-25 19:05:17,754 : [INFO]  ------------------------- Batch round 2, loss: 0.5706 -------------------------
2023-03-25 19:05:17,754 : [INFO]  ------------------------- Batch 400, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:17,784 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:17,786 : [INFO]  ------------------------- Batch 400 training: round 3 -------------------------
2023-03-25 19:05:19,629 : [INFO]  ------------------------- Batch round 3, loss: 0.5716 -------------------------
2023-03-25 19:05:19,629 : [INFO]  ------------------------- Batch 400, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:19,653 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:19,655 : [INFO]  Batch number 400 model fetched from the server
2023-03-25 19:05:19,656 : [INFO]  ################ Batch 400: final global model evalution after 3 rounds ################
2023-03-25 19:05:20,882 : [INFO]  Batch 400: Training set : loss - 0.5826, accuracy - 0.663, recall - 0.8478, AUC - 0.8391, F1 - 0.7156, precision - 0.619, training time - -8.0 seconds
2023-03-25 19:05:20,883 : [INFO]  Batch 400: Testing set : loss - 0.5857, accuracy - 0.7108, recall - 0.8333, AUC - 0.8236, F1 - 0.7424, precision - 0.6693
2023-03-25 19:05:20,892 : [INFO]  Batch 401 initialized 
2023-03-25 19:05:21,387 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:22,378 : [INFO]  ------------------------- Batch 401 training: round 1 -------------------------
2023-03-25 19:05:26,024 : [INFO]  ------------------------- Batch round 1, loss: 0.5852 -------------------------
2023-03-25 19:05:26,024 : [INFO]  ------------------------- Batch 401, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:26,043 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:26,045 : [INFO]  ------------------------- Batch 401 training: round 2 -------------------------
2023-03-25 19:05:27,870 : [INFO]  ------------------------- Batch round 2, loss: 0.5898 -------------------------
2023-03-25 19:05:27,870 : [INFO]  ------------------------- Batch 401, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:27,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:27,893 : [INFO]  ------------------------- Batch 401 training: round 3 -------------------------
2023-03-25 19:05:29,897 : [INFO]  ------------------------- Batch round 3, loss: 0.5928 -------------------------
2023-03-25 19:05:29,897 : [INFO]  ------------------------- Batch 401, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:29,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:29,915 : [INFO]  Batch number 401 model fetched from the server
2023-03-25 19:05:29,915 : [INFO]  ################ Batch 401: final global model evalution after 3 rounds ################
2023-03-25 19:05:31,310 : [INFO]  Batch 401: Training set : loss - 0.6036, accuracy - 0.6685, recall - 0.7609, AUC - 0.7842, F1 - 0.6965, precision - 0.6422, training time - -8.0 seconds
2023-03-25 19:05:31,311 : [INFO]  Batch 401: Testing set : loss - 0.5959, accuracy - 0.6471, recall - 0.8235, AUC - 0.818, F1 - 0.7, precision - 0.6087
2023-03-25 19:05:31,350 : [INFO]  Batch 402 initialized 
2023-03-25 19:05:31,894 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:32,816 : [INFO]  ------------------------- Batch 402 training: round 1 -------------------------
2023-03-25 19:05:36,403 : [INFO]  ------------------------- Batch round 1, loss: 0.5664 -------------------------
2023-03-25 19:05:36,403 : [INFO]  ------------------------- Batch 402, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:36,418 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:36,420 : [INFO]  ------------------------- Batch 402 training: round 2 -------------------------
2023-03-25 19:05:38,299 : [INFO]  ------------------------- Batch round 2, loss: 0.5689 -------------------------
2023-03-25 19:05:38,299 : [INFO]  ------------------------- Batch 402, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:38,315 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:38,316 : [INFO]  ------------------------- Batch 402 training: round 3 -------------------------
2023-03-25 19:05:40,200 : [INFO]  ------------------------- Batch round 3, loss: 0.5607 -------------------------
2023-03-25 19:05:40,200 : [INFO]  ------------------------- Batch 402, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:40,216 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:40,218 : [INFO]  Batch number 402 model fetched from the server
2023-03-25 19:05:40,219 : [INFO]  ################ Batch 402: final global model evalution after 3 rounds ################
2023-03-25 19:05:41,440 : [INFO]  Batch 402: Training set : loss - 0.5773, accuracy - 0.6848, recall - 0.8152, AUC - 0.8201, F1 - 0.7212, precision - 0.6466, training time - -7.0 seconds
2023-03-25 19:05:41,440 : [INFO]  Batch 402: Testing set : loss - 0.5992, accuracy - 0.6618, recall - 0.7549, AUC - 0.7728, F1 - 0.6906, precision - 0.6364
2023-03-25 19:05:41,448 : [INFO]  Batch 403 initialized 
2023-03-25 19:05:41,977 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:42,931 : [INFO]  ------------------------- Batch 403 training: round 1 -------------------------
2023-03-25 19:05:46,500 : [INFO]  ------------------------- Batch round 1, loss: 0.5457 -------------------------
2023-03-25 19:05:46,500 : [INFO]  ------------------------- Batch 403, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:46,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:46,537 : [INFO]  ------------------------- Batch 403 training: round 2 -------------------------
2023-03-25 19:05:48,319 : [INFO]  ------------------------- Batch round 2, loss: 0.5545 -------------------------
2023-03-25 19:05:48,319 : [INFO]  ------------------------- Batch 403, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:48,416 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:48,419 : [INFO]  ------------------------- Batch 403 training: round 3 -------------------------
2023-03-25 19:05:50,188 : [INFO]  ------------------------- Batch round 3, loss: 0.5587 -------------------------
2023-03-25 19:05:50,189 : [INFO]  ------------------------- Batch 403, round 3: Sent local model to the server -------------------------
2023-03-25 19:05:50,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:50,347 : [INFO]  Batch number 403 model fetched from the server
2023-03-25 19:05:50,347 : [INFO]  ################ Batch 403: final global model evalution after 3 rounds ################
2023-03-25 19:05:51,660 : [INFO]  Batch 403: Training set : loss - 0.5591, accuracy - 0.7446, recall - 0.9022, AUC - 0.871, F1 - 0.7793, precision - 0.686, training time - -7.0 seconds
2023-03-25 19:05:51,660 : [INFO]  Batch 403: Testing set : loss - 0.5561, accuracy - 0.7255, recall - 0.8333, AUC - 0.8739, F1 - 0.7522, precision - 0.6855
2023-03-25 19:05:51,675 : [INFO]  Batch 404 initialized 
2023-03-25 19:05:52,143 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:05:53,121 : [INFO]  ------------------------- Batch 404 training: round 1 -------------------------
2023-03-25 19:05:56,679 : [INFO]  ------------------------- Batch round 1, loss: 0.5562 -------------------------
2023-03-25 19:05:56,679 : [INFO]  ------------------------- Batch 404, round 1: Sent local model to the server -------------------------
2023-03-25 19:05:56,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:56,718 : [INFO]  ------------------------- Batch 404 training: round 2 -------------------------
2023-03-25 19:05:58,564 : [INFO]  ------------------------- Batch round 2, loss: 0.5553 -------------------------
2023-03-25 19:05:58,564 : [INFO]  ------------------------- Batch 404, round 2: Sent local model to the server -------------------------
2023-03-25 19:05:58,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:05:58,626 : [INFO]  ------------------------- Batch 404 training: round 3 -------------------------
2023-03-25 19:06:00,427 : [INFO]  ------------------------- Batch round 3, loss: 0.5553 -------------------------
2023-03-25 19:06:00,427 : [INFO]  ------------------------- Batch 404, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:00,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:00,523 : [INFO]  Batch number 404 model fetched from the server
2023-03-25 19:06:00,523 : [INFO]  ################ Batch 404: final global model evalution after 3 rounds ################
2023-03-25 19:06:01,715 : [INFO]  Batch 404: Training set : loss - 0.5614, accuracy - 0.7609, recall - 0.9239, AUC - 0.8864, F1 - 0.7944, precision - 0.6967, training time - -7.0 seconds
2023-03-25 19:06:01,715 : [INFO]  Batch 404: Testing set : loss - 0.5903, accuracy - 0.6765, recall - 0.7941, AUC - 0.8224, F1 - 0.7105, precision - 0.6429
2023-03-25 19:06:01,730 : [INFO]  Batch 405 initialized 
2023-03-25 19:06:02,188 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:03,141 : [INFO]  ------------------------- Batch 405 training: round 1 -------------------------
2023-03-25 19:06:06,606 : [INFO]  ------------------------- Batch round 1, loss: 0.5626 -------------------------
2023-03-25 19:06:06,606 : [INFO]  ------------------------- Batch 405, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:06,720 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:06,722 : [INFO]  ------------------------- Batch 405 training: round 2 -------------------------
2023-03-25 19:06:08,442 : [INFO]  ------------------------- Batch round 2, loss: 0.5645 -------------------------
2023-03-25 19:06:08,442 : [INFO]  ------------------------- Batch 405, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:08,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:08,479 : [INFO]  ------------------------- Batch 405 training: round 3 -------------------------
2023-03-25 19:06:10,218 : [INFO]  ------------------------- Batch round 3, loss: 0.5623 -------------------------
2023-03-25 19:06:10,218 : [INFO]  ------------------------- Batch 405, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:10,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:10,253 : [INFO]  Batch number 405 model fetched from the server
2023-03-25 19:06:10,253 : [INFO]  ################ Batch 405: final global model evalution after 3 rounds ################
2023-03-25 19:06:11,447 : [INFO]  Batch 405: Training set : loss - 0.5677, accuracy - 0.7337, recall - 0.9022, AUC - 0.8536, F1 - 0.7721, precision - 0.6748, training time - -7.0 seconds
2023-03-25 19:06:11,447 : [INFO]  Batch 405: Testing set : loss - 0.5984, accuracy - 0.6569, recall - 0.7843, AUC - 0.7982, F1 - 0.6957, precision - 0.625
2023-03-25 19:06:11,455 : [INFO]  Batch 406 initialized 
2023-03-25 19:06:11,911 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:12,889 : [INFO]  ------------------------- Batch 406 training: round 1 -------------------------
2023-03-25 19:06:16,360 : [INFO]  ------------------------- Batch round 1, loss: 0.5512 -------------------------
2023-03-25 19:06:16,360 : [INFO]  ------------------------- Batch 406, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:16,376 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:16,378 : [INFO]  ------------------------- Batch 406 training: round 2 -------------------------
2023-03-25 19:06:18,104 : [INFO]  ------------------------- Batch round 2, loss: 0.5534 -------------------------
2023-03-25 19:06:18,104 : [INFO]  ------------------------- Batch 406, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:18,151 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:18,154 : [INFO]  ------------------------- Batch 406 training: round 3 -------------------------
2023-03-25 19:06:19,915 : [INFO]  ------------------------- Batch round 3, loss: 0.5511 -------------------------
2023-03-25 19:06:19,915 : [INFO]  ------------------------- Batch 406, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:19,966 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:19,968 : [INFO]  Batch number 406 model fetched from the server
2023-03-25 19:06:19,968 : [INFO]  ################ Batch 406: final global model evalution after 3 rounds ################
2023-03-25 19:06:21,159 : [INFO]  Batch 406: Training set : loss - 0.5582, accuracy - 0.7228, recall - 0.837, AUC - 0.8576, F1 - 0.7512, precision - 0.6814, training time - -7.0 seconds
2023-03-25 19:06:21,159 : [INFO]  Batch 406: Testing set : loss - 0.5856, accuracy - 0.6716, recall - 0.7941, AUC - 0.8153, F1 - 0.7074, precision - 0.6378
2023-03-25 19:06:21,166 : [INFO]  Batch 407 initialized 
2023-03-25 19:06:21,619 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:22,594 : [INFO]  ------------------------- Batch 407 training: round 1 -------------------------
2023-03-25 19:06:26,269 : [INFO]  ------------------------- Batch round 1, loss: 0.583 -------------------------
2023-03-25 19:06:26,269 : [INFO]  ------------------------- Batch 407, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:26,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:26,287 : [INFO]  ------------------------- Batch 407 training: round 2 -------------------------
2023-03-25 19:06:28,128 : [INFO]  ------------------------- Batch round 2, loss: 0.5849 -------------------------
2023-03-25 19:06:28,128 : [INFO]  ------------------------- Batch 407, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:28,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:28,146 : [INFO]  ------------------------- Batch 407 training: round 3 -------------------------
2023-03-25 19:06:30,280 : [INFO]  ------------------------- Batch round 3, loss: 0.582 -------------------------
2023-03-25 19:06:30,280 : [INFO]  ------------------------- Batch 407, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:30,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:30,300 : [INFO]  Batch number 407 model fetched from the server
2023-03-25 19:06:30,300 : [INFO]  ################ Batch 407: final global model evalution after 3 rounds ################
2023-03-25 19:06:31,495 : [INFO]  Batch 407: Training set : loss - 0.599, accuracy - 0.6848, recall - 0.7717, AUC - 0.7962, F1 - 0.71, precision - 0.6574, training time - -8.0 seconds
2023-03-25 19:06:31,495 : [INFO]  Batch 407: Testing set : loss - 0.5877, accuracy - 0.6667, recall - 0.7941, AUC - 0.8116, F1 - 0.7043, precision - 0.6328
2023-03-25 19:06:31,510 : [INFO]  Batch 408 initialized 
2023-03-25 19:06:31,983 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:32,964 : [INFO]  ------------------------- Batch 408 training: round 1 -------------------------
2023-03-25 19:06:36,554 : [INFO]  ------------------------- Batch round 1, loss: 0.5876 -------------------------
2023-03-25 19:06:36,554 : [INFO]  ------------------------- Batch 408, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:36,572 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:36,574 : [INFO]  ------------------------- Batch 408 training: round 2 -------------------------
2023-03-25 19:06:38,383 : [INFO]  ------------------------- Batch round 2, loss: 0.5897 -------------------------
2023-03-25 19:06:38,383 : [INFO]  ------------------------- Batch 408, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:38,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:38,403 : [INFO]  ------------------------- Batch 408 training: round 3 -------------------------
2023-03-25 19:06:40,258 : [INFO]  ------------------------- Batch round 3, loss: 0.5864 -------------------------
2023-03-25 19:06:40,258 : [INFO]  ------------------------- Batch 408, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:40,274 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:40,276 : [INFO]  Batch number 408 model fetched from the server
2023-03-25 19:06:40,277 : [INFO]  ################ Batch 408: final global model evalution after 3 rounds ################
2023-03-25 19:06:41,479 : [INFO]  Batch 408: Training set : loss - 0.6025, accuracy - 0.6685, recall - 0.8261, AUC - 0.8048, F1 - 0.7136, precision - 0.6281, training time - -7.0 seconds
2023-03-25 19:06:41,479 : [INFO]  Batch 408: Testing set : loss - 0.5691, accuracy - 0.7206, recall - 0.7941, AUC - 0.8391, F1 - 0.7397, precision - 0.6923
2023-03-25 19:06:41,491 : [INFO]  Batch 409 initialized 
2023-03-25 19:06:41,947 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:42,930 : [INFO]  ------------------------- Batch 409 training: round 1 -------------------------
2023-03-25 19:06:46,392 : [INFO]  ------------------------- Batch round 1, loss: 0.5594 -------------------------
2023-03-25 19:06:46,393 : [INFO]  ------------------------- Batch 409, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:46,424 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:46,426 : [INFO]  ------------------------- Batch 409 training: round 2 -------------------------
2023-03-25 19:06:48,252 : [INFO]  ------------------------- Batch round 2, loss: 0.5558 -------------------------
2023-03-25 19:06:48,253 : [INFO]  ------------------------- Batch 409, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:48,313 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:48,315 : [INFO]  ------------------------- Batch 409 training: round 3 -------------------------
2023-03-25 19:06:50,105 : [INFO]  ------------------------- Batch round 3, loss: 0.5612 -------------------------
2023-03-25 19:06:50,106 : [INFO]  ------------------------- Batch 409, round 3: Sent local model to the server -------------------------
2023-03-25 19:06:50,168 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:50,170 : [INFO]  Batch number 409 model fetched from the server
2023-03-25 19:06:50,170 : [INFO]  ################ Batch 409: final global model evalution after 3 rounds ################
2023-03-25 19:06:51,372 : [INFO]  Batch 409: Training set : loss - 0.5672, accuracy - 0.7065, recall - 0.8587, AUC - 0.8586, F1 - 0.7453, precision - 0.6583, training time - -7.0 seconds
2023-03-25 19:06:51,372 : [INFO]  Batch 409: Testing set : loss - 0.5825, accuracy - 0.6961, recall - 0.7843, AUC - 0.7964, F1 - 0.7207, precision - 0.6667
2023-03-25 19:06:51,386 : [INFO]  Batch 410 initialized 
2023-03-25 19:06:51,850 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:06:52,848 : [INFO]  ------------------------- Batch 410 training: round 1 -------------------------
2023-03-25 19:06:56,373 : [INFO]  ------------------------- Batch round 1, loss: 0.5747 -------------------------
2023-03-25 19:06:56,373 : [INFO]  ------------------------- Batch 410, round 1: Sent local model to the server -------------------------
2023-03-25 19:06:56,437 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:56,439 : [INFO]  ------------------------- Batch 410 training: round 2 -------------------------
2023-03-25 19:06:58,202 : [INFO]  ------------------------- Batch round 2, loss: 0.5821 -------------------------
2023-03-25 19:06:58,202 : [INFO]  ------------------------- Batch 410, round 2: Sent local model to the server -------------------------
2023-03-25 19:06:58,268 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:06:58,270 : [INFO]  ------------------------- Batch 410 training: round 3 -------------------------
2023-03-25 19:07:00,031 : [INFO]  ------------------------- Batch round 3, loss: 0.576 -------------------------
2023-03-25 19:07:00,031 : [INFO]  ------------------------- Batch 410, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:00,134 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:00,136 : [INFO]  Batch number 410 model fetched from the server
2023-03-25 19:07:00,136 : [INFO]  ################ Batch 410: final global model evalution after 3 rounds ################
2023-03-25 19:07:01,337 : [INFO]  Batch 410: Training set : loss - 0.5884, accuracy - 0.6522, recall - 0.8152, AUC - 0.8055, F1 - 0.7009, precision - 0.6148, training time - -7.0 seconds
2023-03-25 19:07:01,337 : [INFO]  Batch 410: Testing set : loss - 0.577, accuracy - 0.652, recall - 0.8431, AUC - 0.8433, F1 - 0.7078, precision - 0.6099
2023-03-25 19:07:01,345 : [INFO]  Batch 411 initialized 
2023-03-25 19:07:01,794 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:02,743 : [INFO]  ------------------------- Batch 411 training: round 1 -------------------------
2023-03-25 19:07:06,222 : [INFO]  ------------------------- Batch round 1, loss: 0.5805 -------------------------
2023-03-25 19:07:06,222 : [INFO]  ------------------------- Batch 411, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:06,364 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:06,367 : [INFO]  ------------------------- Batch 411 training: round 2 -------------------------
2023-03-25 19:07:08,154 : [INFO]  ------------------------- Batch round 2, loss: 0.589 -------------------------
2023-03-25 19:07:08,154 : [INFO]  ------------------------- Batch 411, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:08,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:08,202 : [INFO]  ------------------------- Batch 411 training: round 3 -------------------------
2023-03-25 19:07:10,035 : [INFO]  ------------------------- Batch round 3, loss: 0.5856 -------------------------
2023-03-25 19:07:10,035 : [INFO]  ------------------------- Batch 411, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:10,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:10,055 : [INFO]  Batch number 411 model fetched from the server
2023-03-25 19:07:10,055 : [INFO]  ################ Batch 411: final global model evalution after 3 rounds ################
2023-03-25 19:07:11,246 : [INFO]  Batch 411: Training set : loss - 0.5995, accuracy - 0.6793, recall - 0.8587, AUC - 0.8234, F1 - 0.7281, precision - 0.632, training time - -7.0 seconds
2023-03-25 19:07:11,246 : [INFO]  Batch 411: Testing set : loss - 0.5853, accuracy - 0.6716, recall - 0.8235, AUC - 0.8301, F1 - 0.7149, precision - 0.6316
2023-03-25 19:07:11,256 : [INFO]  Batch 412 initialized 
2023-03-25 19:07:11,708 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:12,672 : [INFO]  ------------------------- Batch 412 training: round 1 -------------------------
2023-03-25 19:07:16,065 : [INFO]  ------------------------- Batch round 1, loss: 0.5842 -------------------------
2023-03-25 19:07:16,065 : [INFO]  ------------------------- Batch 412, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:16,241 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:16,243 : [INFO]  ------------------------- Batch 412 training: round 2 -------------------------
2023-03-25 19:07:17,996 : [INFO]  ------------------------- Batch round 2, loss: 0.5805 -------------------------
2023-03-25 19:07:17,997 : [INFO]  ------------------------- Batch 412, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:18,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:18,058 : [INFO]  ------------------------- Batch 412 training: round 3 -------------------------
2023-03-25 19:07:19,793 : [INFO]  ------------------------- Batch round 3, loss: 0.578 -------------------------
2023-03-25 19:07:19,793 : [INFO]  ------------------------- Batch 412, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:19,895 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:19,897 : [INFO]  Batch number 412 model fetched from the server
2023-03-25 19:07:19,897 : [INFO]  ################ Batch 412: final global model evalution after 3 rounds ################
2023-03-25 19:07:21,035 : [INFO]  Batch 412: Training set : loss - 0.5908, accuracy - 0.6359, recall - 0.837, AUC - 0.8332, F1 - 0.6968, precision - 0.5969, training time - -7.0 seconds
2023-03-25 19:07:21,035 : [INFO]  Batch 412: Testing set : loss - 0.5417, accuracy - 0.7598, recall - 0.8431, AUC - 0.8809, F1 - 0.7783, precision - 0.7227
2023-03-25 19:07:21,048 : [INFO]  Batch 413 initialized 
2023-03-25 19:07:21,500 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:22,457 : [INFO]  ------------------------- Batch 413 training: round 1 -------------------------
2023-03-25 19:07:26,077 : [INFO]  ------------------------- Batch round 1, loss: 0.5545 -------------------------
2023-03-25 19:07:26,077 : [INFO]  ------------------------- Batch 413, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:26,156 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:26,158 : [INFO]  ------------------------- Batch 413 training: round 2 -------------------------
2023-03-25 19:07:27,985 : [INFO]  ------------------------- Batch round 2, loss: 0.5526 -------------------------
2023-03-25 19:07:27,986 : [INFO]  ------------------------- Batch 413, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:28,004 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:28,007 : [INFO]  ------------------------- Batch 413 training: round 3 -------------------------
2023-03-25 19:07:29,865 : [INFO]  ------------------------- Batch round 3, loss: 0.554 -------------------------
2023-03-25 19:07:29,865 : [INFO]  ------------------------- Batch 413, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:29,881 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:29,883 : [INFO]  Batch number 413 model fetched from the server
2023-03-25 19:07:29,884 : [INFO]  ################ Batch 413: final global model evalution after 3 rounds ################
2023-03-25 19:07:31,101 : [INFO]  Batch 413: Training set : loss - 0.557, accuracy - 0.7228, recall - 0.8152, AUC - 0.8485, F1 - 0.7463, precision - 0.6881, training time - -7.0 seconds
2023-03-25 19:07:31,101 : [INFO]  Batch 413: Testing set : loss - 0.5697, accuracy - 0.7059, recall - 0.8922, AUC - 0.8778, F1 - 0.7521, precision - 0.65
2023-03-25 19:07:31,118 : [INFO]  Batch 414 initialized 
2023-03-25 19:07:31,584 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:32,549 : [INFO]  ------------------------- Batch 414 training: round 1 -------------------------
2023-03-25 19:07:36,039 : [INFO]  ------------------------- Batch round 1, loss: 0.5926 -------------------------
2023-03-25 19:07:36,039 : [INFO]  ------------------------- Batch 414, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:36,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:36,058 : [INFO]  ------------------------- Batch 414 training: round 2 -------------------------
2023-03-25 19:07:37,849 : [INFO]  ------------------------- Batch round 2, loss: 0.6003 -------------------------
2023-03-25 19:07:37,849 : [INFO]  ------------------------- Batch 414, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:37,910 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:37,912 : [INFO]  ------------------------- Batch 414 training: round 3 -------------------------
2023-03-25 19:07:39,649 : [INFO]  ------------------------- Batch round 3, loss: 0.5945 -------------------------
2023-03-25 19:07:39,650 : [INFO]  ------------------------- Batch 414, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:39,706 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:39,708 : [INFO]  Batch number 414 model fetched from the server
2023-03-25 19:07:39,708 : [INFO]  ################ Batch 414: final global model evalution after 3 rounds ################
2023-03-25 19:07:40,907 : [INFO]  Batch 414: Training set : loss - 0.6013, accuracy - 0.6522, recall - 0.8261, AUC - 0.8003, F1 - 0.7037, precision - 0.6129, training time - -7.0 seconds
2023-03-25 19:07:40,907 : [INFO]  Batch 414: Testing set : loss - 0.5911, accuracy - 0.6716, recall - 0.8137, AUC - 0.815, F1 - 0.7124, precision - 0.6336
2023-03-25 19:07:40,915 : [INFO]  Batch 415 initialized 
2023-03-25 19:07:41,369 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:42,337 : [INFO]  ------------------------- Batch 415 training: round 1 -------------------------
2023-03-25 19:07:45,811 : [INFO]  ------------------------- Batch round 1, loss: 0.593 -------------------------
2023-03-25 19:07:45,812 : [INFO]  ------------------------- Batch 415, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:45,828 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:45,830 : [INFO]  ------------------------- Batch 415 training: round 2 -------------------------
2023-03-25 19:07:47,662 : [INFO]  ------------------------- Batch round 2, loss: 0.595 -------------------------
2023-03-25 19:07:47,663 : [INFO]  ------------------------- Batch 415, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:47,679 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:47,682 : [INFO]  ------------------------- Batch 415 training: round 3 -------------------------
2023-03-25 19:07:49,512 : [INFO]  ------------------------- Batch round 3, loss: 0.597 -------------------------
2023-03-25 19:07:49,512 : [INFO]  ------------------------- Batch 415, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:49,528 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:49,530 : [INFO]  Batch number 415 model fetched from the server
2023-03-25 19:07:49,531 : [INFO]  ################ Batch 415: final global model evalution after 3 rounds ################
2023-03-25 19:07:50,755 : [INFO]  Batch 415: Training set : loss - 0.601, accuracy - 0.6576, recall - 0.7826, AUC - 0.7882, F1 - 0.6957, precision - 0.6261, training time - -7.0 seconds
2023-03-25 19:07:50,756 : [INFO]  Batch 415: Testing set : loss - 0.5787, accuracy - 0.7108, recall - 0.8627, AUC - 0.841, F1 - 0.7489, precision - 0.6617
2023-03-25 19:07:50,768 : [INFO]  Batch 416 initialized 
2023-03-25 19:07:51,216 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:07:52,213 : [INFO]  ------------------------- Batch 416 training: round 1 -------------------------
2023-03-25 19:07:55,727 : [INFO]  ------------------------- Batch round 1, loss: 0.5948 -------------------------
2023-03-25 19:07:55,728 : [INFO]  ------------------------- Batch 416, round 1: Sent local model to the server -------------------------
2023-03-25 19:07:55,746 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:55,749 : [INFO]  ------------------------- Batch 416 training: round 2 -------------------------
2023-03-25 19:07:57,716 : [INFO]  ------------------------- Batch round 2, loss: 0.5944 -------------------------
2023-03-25 19:07:57,717 : [INFO]  ------------------------- Batch 416, round 2: Sent local model to the server -------------------------
2023-03-25 19:07:57,733 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:57,735 : [INFO]  ------------------------- Batch 416 training: round 3 -------------------------
2023-03-25 19:07:59,599 : [INFO]  ------------------------- Batch round 3, loss: 0.5935 -------------------------
2023-03-25 19:07:59,599 : [INFO]  ------------------------- Batch 416, round 3: Sent local model to the server -------------------------
2023-03-25 19:07:59,617 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:07:59,620 : [INFO]  Batch number 416 model fetched from the server
2023-03-25 19:07:59,620 : [INFO]  ################ Batch 416: final global model evalution after 3 rounds ################
2023-03-25 19:08:00,897 : [INFO]  Batch 416: Training set : loss - 0.6094, accuracy - 0.6522, recall - 0.7935, AUC - 0.7835, F1 - 0.6952, precision - 0.6186, training time - -7.0 seconds
2023-03-25 19:08:00,897 : [INFO]  Batch 416: Testing set : loss - 0.5733, accuracy - 0.6912, recall - 0.8627, AUC - 0.854, F1 - 0.7364, precision - 0.6423
2023-03-25 19:08:00,904 : [INFO]  Batch 417 initialized 
2023-03-25 19:08:01,356 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:02,337 : [INFO]  ------------------------- Batch 417 training: round 1 -------------------------
2023-03-25 19:08:05,973 : [INFO]  ------------------------- Batch round 1, loss: 0.5601 -------------------------
2023-03-25 19:08:05,973 : [INFO]  ------------------------- Batch 417, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:05,988 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:05,990 : [INFO]  ------------------------- Batch 417 training: round 2 -------------------------
2023-03-25 19:08:07,963 : [INFO]  ------------------------- Batch round 2, loss: 0.5658 -------------------------
2023-03-25 19:08:07,963 : [INFO]  ------------------------- Batch 417, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:07,980 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:07,982 : [INFO]  ------------------------- Batch 417 training: round 3 -------------------------
2023-03-25 19:08:09,854 : [INFO]  ------------------------- Batch round 3, loss: 0.5638 -------------------------
2023-03-25 19:08:09,854 : [INFO]  ------------------------- Batch 417, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:09,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:09,873 : [INFO]  Batch number 417 model fetched from the server
2023-03-25 19:08:09,873 : [INFO]  ################ Batch 417: final global model evalution after 3 rounds ################
2023-03-25 19:08:11,127 : [INFO]  Batch 417: Training set : loss - 0.5729, accuracy - 0.6685, recall - 0.8152, AUC - 0.8455, F1 - 0.7109, precision - 0.6303, training time - -8.0 seconds
2023-03-25 19:08:11,127 : [INFO]  Batch 417: Testing set : loss - 0.5746, accuracy - 0.701, recall - 0.7843, AUC - 0.8222, F1 - 0.724, precision - 0.6723
2023-03-25 19:08:11,138 : [INFO]  Batch 418 initialized 
2023-03-25 19:08:11,599 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:12,581 : [INFO]  ------------------------- Batch 418 training: round 1 -------------------------
2023-03-25 19:08:16,059 : [INFO]  ------------------------- Batch round 1, loss: 0.5797 -------------------------
2023-03-25 19:08:16,059 : [INFO]  ------------------------- Batch 418, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:16,119 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:16,121 : [INFO]  ------------------------- Batch 418 training: round 2 -------------------------
2023-03-25 19:08:17,905 : [INFO]  ------------------------- Batch round 2, loss: 0.5843 -------------------------
2023-03-25 19:08:17,905 : [INFO]  ------------------------- Batch 418, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:17,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:17,923 : [INFO]  ------------------------- Batch 418 training: round 3 -------------------------
2023-03-25 19:08:19,733 : [INFO]  ------------------------- Batch round 3, loss: 0.5798 -------------------------
2023-03-25 19:08:19,733 : [INFO]  ------------------------- Batch 418, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:19,750 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:19,752 : [INFO]  Batch number 418 model fetched from the server
2023-03-25 19:08:19,752 : [INFO]  ################ Batch 418: final global model evalution after 3 rounds ################
2023-03-25 19:08:20,950 : [INFO]  Batch 418: Training set : loss - 0.5912, accuracy - 0.663, recall - 0.837, AUC - 0.8211, F1 - 0.713, precision - 0.621, training time - -7.0 seconds
2023-03-25 19:08:20,951 : [INFO]  Batch 418: Testing set : loss - 0.5995, accuracy - 0.6324, recall - 0.8039, AUC - 0.7987, F1 - 0.6862, precision - 0.5985
2023-03-25 19:08:20,965 : [INFO]  Batch 419 initialized 
2023-03-25 19:08:21,419 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:22,401 : [INFO]  ------------------------- Batch 419 training: round 1 -------------------------
2023-03-25 19:08:25,889 : [INFO]  ------------------------- Batch round 1, loss: 0.5616 -------------------------
2023-03-25 19:08:25,889 : [INFO]  ------------------------- Batch 419, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:25,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:25,924 : [INFO]  ------------------------- Batch 419 training: round 2 -------------------------
2023-03-25 19:08:27,697 : [INFO]  ------------------------- Batch round 2, loss: 0.5628 -------------------------
2023-03-25 19:08:27,697 : [INFO]  ------------------------- Batch 419, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:27,738 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:27,740 : [INFO]  ------------------------- Batch 419 training: round 3 -------------------------
2023-03-25 19:08:29,538 : [INFO]  ------------------------- Batch round 3, loss: 0.5632 -------------------------
2023-03-25 19:08:29,538 : [INFO]  ------------------------- Batch 419, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:29,581 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:29,583 : [INFO]  Batch number 419 model fetched from the server
2023-03-25 19:08:29,583 : [INFO]  ################ Batch 419: final global model evalution after 3 rounds ################
2023-03-25 19:08:30,752 : [INFO]  Batch 419: Training set : loss - 0.5761, accuracy - 0.7174, recall - 0.8913, AUC - 0.8543, F1 - 0.7593, precision - 0.6613, training time - -7.0 seconds
2023-03-25 19:08:30,752 : [INFO]  Batch 419: Testing set : loss - 0.5886, accuracy - 0.6667, recall - 0.7549, AUC - 0.7995, F1 - 0.6937, precision - 0.6417
2023-03-25 19:08:30,767 : [INFO]  Batch 420 initialized 
2023-03-25 19:08:31,227 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:32,236 : [INFO]  ------------------------- Batch 420 training: round 1 -------------------------
2023-03-25 19:08:35,805 : [INFO]  ------------------------- Batch round 1, loss: 0.5269 -------------------------
2023-03-25 19:08:35,805 : [INFO]  ------------------------- Batch 420, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:35,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:35,846 : [INFO]  ------------------------- Batch 420 training: round 2 -------------------------
2023-03-25 19:08:37,653 : [INFO]  ------------------------- Batch round 2, loss: 0.5288 -------------------------
2023-03-25 19:08:37,653 : [INFO]  ------------------------- Batch 420, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:37,669 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:37,671 : [INFO]  ------------------------- Batch 420 training: round 3 -------------------------
2023-03-25 19:08:39,516 : [INFO]  ------------------------- Batch round 3, loss: 0.5282 -------------------------
2023-03-25 19:08:39,516 : [INFO]  ------------------------- Batch 420, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:39,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:39,537 : [INFO]  Batch number 420 model fetched from the server
2023-03-25 19:08:39,537 : [INFO]  ################ Batch 420: final global model evalution after 3 rounds ################
2023-03-25 19:08:40,745 : [INFO]  Batch 420: Training set : loss - 0.5319, accuracy - 0.7989, recall - 0.9022, AUC - 0.9113, F1 - 0.8177, precision - 0.7477, training time - -7.0 seconds
2023-03-25 19:08:40,746 : [INFO]  Batch 420: Testing set : loss - 0.5807, accuracy - 0.6863, recall - 0.8529, AUC - 0.8394, F1 - 0.7311, precision - 0.6397
2023-03-25 19:08:40,763 : [INFO]  Batch 421 initialized 
2023-03-25 19:08:41,224 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:42,250 : [INFO]  ------------------------- Batch 421 training: round 1 -------------------------
2023-03-25 19:08:45,725 : [INFO]  ------------------------- Batch round 1, loss: 0.5381 -------------------------
2023-03-25 19:08:45,725 : [INFO]  ------------------------- Batch 421, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:45,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:45,765 : [INFO]  ------------------------- Batch 421 training: round 2 -------------------------
2023-03-25 19:08:47,577 : [INFO]  ------------------------- Batch round 2, loss: 0.5429 -------------------------
2023-03-25 19:08:47,577 : [INFO]  ------------------------- Batch 421, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:47,594 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:47,596 : [INFO]  ------------------------- Batch 421 training: round 3 -------------------------
2023-03-25 19:08:49,377 : [INFO]  ------------------------- Batch round 3, loss: 0.5435 -------------------------
2023-03-25 19:08:49,377 : [INFO]  ------------------------- Batch 421, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:49,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:49,457 : [INFO]  Batch number 421 model fetched from the server
2023-03-25 19:08:49,457 : [INFO]  ################ Batch 421: final global model evalution after 3 rounds ################
2023-03-25 19:08:50,630 : [INFO]  Batch 421: Training set : loss - 0.5467, accuracy - 0.7337, recall - 0.9022, AUC - 0.8849, F1 - 0.7721, precision - 0.6748, training time - -7.0 seconds
2023-03-25 19:08:50,630 : [INFO]  Batch 421: Testing set : loss - 0.5744, accuracy - 0.6814, recall - 0.8333, AUC - 0.842, F1 - 0.7234, precision - 0.6391
2023-03-25 19:08:50,645 : [INFO]  Batch 422 initialized 
2023-03-25 19:08:51,097 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:08:52,087 : [INFO]  ------------------------- Batch 422 training: round 1 -------------------------
2023-03-25 19:08:55,638 : [INFO]  ------------------------- Batch round 1, loss: 0.5805 -------------------------
2023-03-25 19:08:55,638 : [INFO]  ------------------------- Batch 422, round 1: Sent local model to the server -------------------------
2023-03-25 19:08:55,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:55,656 : [INFO]  ------------------------- Batch 422 training: round 2 -------------------------
2023-03-25 19:08:57,469 : [INFO]  ------------------------- Batch round 2, loss: 0.5895 -------------------------
2023-03-25 19:08:57,469 : [INFO]  ------------------------- Batch 422, round 2: Sent local model to the server -------------------------
2023-03-25 19:08:57,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:57,487 : [INFO]  ------------------------- Batch 422 training: round 3 -------------------------
2023-03-25 19:08:59,301 : [INFO]  ------------------------- Batch round 3, loss: 0.5776 -------------------------
2023-03-25 19:08:59,301 : [INFO]  ------------------------- Batch 422, round 3: Sent local model to the server -------------------------
2023-03-25 19:08:59,321 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:08:59,323 : [INFO]  Batch number 422 model fetched from the server
2023-03-25 19:08:59,323 : [INFO]  ################ Batch 422: final global model evalution after 3 rounds ################
2023-03-25 19:09:00,543 : [INFO]  Batch 422: Training set : loss - 0.5974, accuracy - 0.6848, recall - 0.8261, AUC - 0.8013, F1 - 0.7238, precision - 0.6441, training time - -7.0 seconds
2023-03-25 19:09:00,543 : [INFO]  Batch 422: Testing set : loss - 0.6256, accuracy - 0.5931, recall - 0.7157, AUC - 0.7438, F1 - 0.6376, precision - 0.5748
2023-03-25 19:09:00,551 : [INFO]  Batch 423 initialized 
2023-03-25 19:09:01,006 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:01,992 : [INFO]  ------------------------- Batch 423 training: round 1 -------------------------
2023-03-25 19:09:05,497 : [INFO]  ------------------------- Batch round 1, loss: 0.5718 -------------------------
2023-03-25 19:09:05,497 : [INFO]  ------------------------- Batch 423, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:05,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:05,518 : [INFO]  ------------------------- Batch 423 training: round 2 -------------------------
2023-03-25 19:09:07,325 : [INFO]  ------------------------- Batch round 2, loss: 0.5707 -------------------------
2023-03-25 19:09:07,325 : [INFO]  ------------------------- Batch 423, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:07,342 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:07,344 : [INFO]  ------------------------- Batch 423 training: round 3 -------------------------
2023-03-25 19:09:09,168 : [INFO]  ------------------------- Batch round 3, loss: 0.5721 -------------------------
2023-03-25 19:09:09,168 : [INFO]  ------------------------- Batch 423, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:09,184 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:09,186 : [INFO]  Batch number 423 model fetched from the server
2023-03-25 19:09:09,186 : [INFO]  ################ Batch 423: final global model evalution after 3 rounds ################
2023-03-25 19:09:10,353 : [INFO]  Batch 423: Training set : loss - 0.5787, accuracy - 0.7011, recall - 0.837, AUC - 0.8284, F1 - 0.7368, precision - 0.6581, training time - -7.0 seconds
2023-03-25 19:09:10,353 : [INFO]  Batch 423: Testing set : loss - 0.5805, accuracy - 0.6716, recall - 0.8529, AUC - 0.8472, F1 - 0.722, precision - 0.6259
2023-03-25 19:09:10,367 : [INFO]  Batch 424 initialized 
2023-03-25 19:09:10,830 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:11,821 : [INFO]  ------------------------- Batch 424 training: round 1 -------------------------
2023-03-25 19:09:15,229 : [INFO]  ------------------------- Batch round 1, loss: 0.5414 -------------------------
2023-03-25 19:09:15,229 : [INFO]  ------------------------- Batch 424, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:15,246 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:15,248 : [INFO]  ------------------------- Batch 424 training: round 2 -------------------------
2023-03-25 19:09:16,997 : [INFO]  ------------------------- Batch round 2, loss: 0.5446 -------------------------
2023-03-25 19:09:16,997 : [INFO]  ------------------------- Batch 424, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:17,026 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:17,032 : [INFO]  ------------------------- Batch 424 training: round 3 -------------------------
2023-03-25 19:09:18,782 : [INFO]  ------------------------- Batch round 3, loss: 0.5456 -------------------------
2023-03-25 19:09:18,782 : [INFO]  ------------------------- Batch 424, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:18,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:18,828 : [INFO]  Batch number 424 model fetched from the server
2023-03-25 19:09:18,828 : [INFO]  ################ Batch 424: final global model evalution after 3 rounds ################
2023-03-25 19:09:20,012 : [INFO]  Batch 424: Training set : loss - 0.5427, accuracy - 0.7554, recall - 0.913, AUC - 0.9039, F1 - 0.7887, precision - 0.6942, training time - -7.0 seconds
2023-03-25 19:09:20,013 : [INFO]  Batch 424: Testing set : loss - 0.5949, accuracy - 0.7059, recall - 0.8333, AUC - 0.8054, F1 - 0.7391, precision - 0.6641
2023-03-25 19:09:20,054 : [INFO]  Batch 425 initialized 
2023-03-25 19:09:20,520 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:21,524 : [INFO]  ------------------------- Batch 425 training: round 1 -------------------------
2023-03-25 19:09:25,074 : [INFO]  ------------------------- Batch round 1, loss: 0.5877 -------------------------
2023-03-25 19:09:25,074 : [INFO]  ------------------------- Batch 425, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:25,122 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:25,124 : [INFO]  ------------------------- Batch 425 training: round 2 -------------------------
2023-03-25 19:09:26,972 : [INFO]  ------------------------- Batch round 2, loss: 0.5831 -------------------------
2023-03-25 19:09:26,973 : [INFO]  ------------------------- Batch 425, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:27,010 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:27,013 : [INFO]  ------------------------- Batch 425 training: round 3 -------------------------
2023-03-25 19:09:28,831 : [INFO]  ------------------------- Batch round 3, loss: 0.586 -------------------------
2023-03-25 19:09:28,831 : [INFO]  ------------------------- Batch 425, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:28,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:28,942 : [INFO]  Batch number 425 model fetched from the server
2023-03-25 19:09:28,942 : [INFO]  ################ Batch 425: final global model evalution after 3 rounds ################
2023-03-25 19:09:30,132 : [INFO]  Batch 425: Training set : loss - 0.6016, accuracy - 0.6413, recall - 0.837, AUC - 0.8191, F1 - 0.7, precision - 0.6016, training time - -7.0 seconds
2023-03-25 19:09:30,133 : [INFO]  Batch 425: Testing set : loss - 0.5906, accuracy - 0.6569, recall - 0.8235, AUC - 0.8409, F1 - 0.7059, precision - 0.6176
2023-03-25 19:09:30,146 : [INFO]  Batch 426 initialized 
2023-03-25 19:09:30,623 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:31,616 : [INFO]  ------------------------- Batch 426 training: round 1 -------------------------
2023-03-25 19:09:35,209 : [INFO]  ------------------------- Batch round 1, loss: 0.5736 -------------------------
2023-03-25 19:09:35,210 : [INFO]  ------------------------- Batch 426, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:35,347 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:35,349 : [INFO]  ------------------------- Batch 426 training: round 2 -------------------------
2023-03-25 19:09:37,128 : [INFO]  ------------------------- Batch round 2, loss: 0.5752 -------------------------
2023-03-25 19:09:37,128 : [INFO]  ------------------------- Batch 426, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:37,217 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:37,219 : [INFO]  ------------------------- Batch 426 training: round 3 -------------------------
2023-03-25 19:09:39,023 : [INFO]  ------------------------- Batch round 3, loss: 0.5742 -------------------------
2023-03-25 19:09:39,023 : [INFO]  ------------------------- Batch 426, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:39,094 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:39,097 : [INFO]  Batch number 426 model fetched from the server
2023-03-25 19:09:39,097 : [INFO]  ################ Batch 426: final global model evalution after 3 rounds ################
2023-03-25 19:09:40,294 : [INFO]  Batch 426: Training set : loss - 0.5898, accuracy - 0.6793, recall - 0.8043, AUC - 0.8083, F1 - 0.715, precision - 0.6435, training time - -7.0 seconds
2023-03-25 19:09:40,294 : [INFO]  Batch 426: Testing set : loss - 0.6009, accuracy - 0.6324, recall - 0.8235, AUC - 0.8119, F1 - 0.6914, precision - 0.5957
2023-03-25 19:09:40,309 : [INFO]  Batch 427 initialized 
2023-03-25 19:09:40,773 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:41,774 : [INFO]  ------------------------- Batch 427 training: round 1 -------------------------
2023-03-25 19:09:45,237 : [INFO]  ------------------------- Batch round 1, loss: 0.5622 -------------------------
2023-03-25 19:09:45,237 : [INFO]  ------------------------- Batch 427, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:45,287 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:45,290 : [INFO]  ------------------------- Batch 427 training: round 2 -------------------------
2023-03-25 19:09:47,041 : [INFO]  ------------------------- Batch round 2, loss: 0.5664 -------------------------
2023-03-25 19:09:47,041 : [INFO]  ------------------------- Batch 427, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:47,063 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:47,066 : [INFO]  ------------------------- Batch 427 training: round 3 -------------------------
2023-03-25 19:09:48,866 : [INFO]  ------------------------- Batch round 3, loss: 0.5681 -------------------------
2023-03-25 19:09:48,866 : [INFO]  ------------------------- Batch 427, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:48,887 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:48,890 : [INFO]  Batch number 427 model fetched from the server
2023-03-25 19:09:48,890 : [INFO]  ################ Batch 427: final global model evalution after 3 rounds ################
2023-03-25 19:09:50,086 : [INFO]  Batch 427: Training set : loss - 0.577, accuracy - 0.6957, recall - 0.837, AUC - 0.8488, F1 - 0.7333, precision - 0.6525, training time - -7.0 seconds
2023-03-25 19:09:50,086 : [INFO]  Batch 427: Testing set : loss - 0.5887, accuracy - 0.6667, recall - 0.8137, AUC - 0.8234, F1 - 0.7094, precision - 0.6288
2023-03-25 19:09:50,101 : [INFO]  Batch 428 initialized 
2023-03-25 19:09:50,571 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:09:51,611 : [INFO]  ------------------------- Batch 428 training: round 1 -------------------------
2023-03-25 19:09:55,178 : [INFO]  ------------------------- Batch round 1, loss: 0.5744 -------------------------
2023-03-25 19:09:55,178 : [INFO]  ------------------------- Batch 428, round 1: Sent local model to the server -------------------------
2023-03-25 19:09:55,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:55,235 : [INFO]  ------------------------- Batch 428 training: round 2 -------------------------
2023-03-25 19:09:57,036 : [INFO]  ------------------------- Batch round 2, loss: 0.5758 -------------------------
2023-03-25 19:09:57,037 : [INFO]  ------------------------- Batch 428, round 2: Sent local model to the server -------------------------
2023-03-25 19:09:57,129 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:57,131 : [INFO]  ------------------------- Batch 428 training: round 3 -------------------------
2023-03-25 19:09:59,000 : [INFO]  ------------------------- Batch round 3, loss: 0.5682 -------------------------
2023-03-25 19:09:59,000 : [INFO]  ------------------------- Batch 428, round 3: Sent local model to the server -------------------------
2023-03-25 19:09:59,104 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:09:59,106 : [INFO]  Batch number 428 model fetched from the server
2023-03-25 19:09:59,106 : [INFO]  ################ Batch 428: final global model evalution after 3 rounds ################
2023-03-25 19:10:00,283 : [INFO]  Batch 428: Training set : loss - 0.585, accuracy - 0.7174, recall - 0.837, AUC - 0.8191, F1 - 0.7476, precision - 0.6754, training time - -7.0 seconds
2023-03-25 19:10:00,283 : [INFO]  Batch 428: Testing set : loss - 0.596, accuracy - 0.6422, recall - 0.8137, AUC - 0.827, F1 - 0.6946, precision - 0.6058
2023-03-25 19:10:00,298 : [INFO]  Batch 429 initialized 
2023-03-25 19:10:00,773 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:01,769 : [INFO]  ------------------------- Batch 429 training: round 1 -------------------------
2023-03-25 19:10:05,229 : [INFO]  ------------------------- Batch round 1, loss: 0.5851 -------------------------
2023-03-25 19:10:05,230 : [INFO]  ------------------------- Batch 429, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:05,247 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:05,249 : [INFO]  ------------------------- Batch 429 training: round 2 -------------------------
2023-03-25 19:10:07,024 : [INFO]  ------------------------- Batch round 2, loss: 0.5809 -------------------------
2023-03-25 19:10:07,024 : [INFO]  ------------------------- Batch 429, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:07,041 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:07,043 : [INFO]  ------------------------- Batch 429 training: round 3 -------------------------
2023-03-25 19:10:08,799 : [INFO]  ------------------------- Batch round 3, loss: 0.5781 -------------------------
2023-03-25 19:10:08,799 : [INFO]  ------------------------- Batch 429, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:08,816 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:08,818 : [INFO]  Batch number 429 model fetched from the server
2023-03-25 19:10:08,818 : [INFO]  ################ Batch 429: final global model evalution after 3 rounds ################
2023-03-25 19:10:10,000 : [INFO]  Batch 429: Training set : loss - 0.5924, accuracy - 0.663, recall - 0.8043, AUC - 0.8077, F1 - 0.7048, precision - 0.6271, training time - -7.0 seconds
2023-03-25 19:10:10,000 : [INFO]  Batch 429: Testing set : loss - 0.5774, accuracy - 0.6912, recall - 0.8235, AUC - 0.8357, F1 - 0.7273, precision - 0.6512
2023-03-25 19:10:10,011 : [INFO]  Batch 430 initialized 
2023-03-25 19:10:10,474 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:11,488 : [INFO]  ------------------------- Batch 430 training: round 1 -------------------------
2023-03-25 19:10:14,938 : [INFO]  ------------------------- Batch round 1, loss: 0.5659 -------------------------
2023-03-25 19:10:14,938 : [INFO]  ------------------------- Batch 430, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:14,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:14,957 : [INFO]  ------------------------- Batch 430 training: round 2 -------------------------
2023-03-25 19:10:16,749 : [INFO]  ------------------------- Batch round 2, loss: 0.5642 -------------------------
2023-03-25 19:10:16,749 : [INFO]  ------------------------- Batch 430, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:16,783 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:16,786 : [INFO]  ------------------------- Batch 430 training: round 3 -------------------------
2023-03-25 19:10:18,613 : [INFO]  ------------------------- Batch round 3, loss: 0.5665 -------------------------
2023-03-25 19:10:18,613 : [INFO]  ------------------------- Batch 430, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:18,643 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:18,645 : [INFO]  Batch number 430 model fetched from the server
2023-03-25 19:10:18,645 : [INFO]  ################ Batch 430: final global model evalution after 3 rounds ################
2023-03-25 19:10:19,848 : [INFO]  Batch 430: Training set : loss - 0.574, accuracy - 0.6739, recall - 0.7935, AUC - 0.8306, F1 - 0.7087, precision - 0.6404, training time - -7.0 seconds
2023-03-25 19:10:19,848 : [INFO]  Batch 430: Testing set : loss - 0.5748, accuracy - 0.6765, recall - 0.8137, AUC - 0.8452, F1 - 0.7155, precision - 0.6385
2023-03-25 19:10:19,861 : [INFO]  Batch 431 initialized 
2023-03-25 19:10:20,313 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:21,328 : [INFO]  ------------------------- Batch 431 training: round 1 -------------------------
2023-03-25 19:10:24,761 : [INFO]  ------------------------- Batch round 1, loss: 0.5767 -------------------------
2023-03-25 19:10:24,761 : [INFO]  ------------------------- Batch 431, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:24,873 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:24,875 : [INFO]  ------------------------- Batch 431 training: round 2 -------------------------
2023-03-25 19:10:26,602 : [INFO]  ------------------------- Batch round 2, loss: 0.5801 -------------------------
2023-03-25 19:10:26,602 : [INFO]  ------------------------- Batch 431, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:26,681 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:26,687 : [INFO]  ------------------------- Batch 431 training: round 3 -------------------------
2023-03-25 19:10:28,425 : [INFO]  ------------------------- Batch round 3, loss: 0.5717 -------------------------
2023-03-25 19:10:28,425 : [INFO]  ------------------------- Batch 431, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:28,522 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:28,524 : [INFO]  Batch number 431 model fetched from the server
2023-03-25 19:10:28,525 : [INFO]  ################ Batch 431: final global model evalution after 3 rounds ################
2023-03-25 19:10:29,701 : [INFO]  Batch 431: Training set : loss - 0.5916, accuracy - 0.6848, recall - 0.8587, AUC - 0.8241, F1 - 0.7315, precision - 0.6371, training time - -7.0 seconds
2023-03-25 19:10:29,702 : [INFO]  Batch 431: Testing set : loss - 0.5682, accuracy - 0.6912, recall - 0.8333, AUC - 0.8581, F1 - 0.7296, precision - 0.6489
2023-03-25 19:10:29,716 : [INFO]  Batch 432 initialized 
2023-03-25 19:10:30,165 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:31,180 : [INFO]  ------------------------- Batch 432 training: round 1 -------------------------
2023-03-25 19:10:34,681 : [INFO]  ------------------------- Batch round 1, loss: 0.5642 -------------------------
2023-03-25 19:10:34,681 : [INFO]  ------------------------- Batch 432, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:34,698 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:34,700 : [INFO]  ------------------------- Batch 432 training: round 2 -------------------------
2023-03-25 19:10:36,513 : [INFO]  ------------------------- Batch round 2, loss: 0.5691 -------------------------
2023-03-25 19:10:36,513 : [INFO]  ------------------------- Batch 432, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:36,530 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:36,532 : [INFO]  ------------------------- Batch 432 training: round 3 -------------------------
2023-03-25 19:10:38,305 : [INFO]  ------------------------- Batch round 3, loss: 0.5664 -------------------------
2023-03-25 19:10:38,306 : [INFO]  ------------------------- Batch 432, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:38,324 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:38,326 : [INFO]  Batch number 432 model fetched from the server
2023-03-25 19:10:38,326 : [INFO]  ################ Batch 432: final global model evalution after 3 rounds ################
2023-03-25 19:10:39,538 : [INFO]  Batch 432: Training set : loss - 0.5788, accuracy - 0.712, recall - 0.8478, AUC - 0.8491, F1 - 0.7464, precision - 0.6667, training time - -7.0 seconds
2023-03-25 19:10:39,538 : [INFO]  Batch 432: Testing set : loss - 0.593, accuracy - 0.6765, recall - 0.8725, AUC - 0.8235, F1 - 0.7295, precision - 0.6268
2023-03-25 19:10:39,546 : [INFO]  Batch 433 initialized 
2023-03-25 19:10:39,993 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:40,995 : [INFO]  ------------------------- Batch 433 training: round 1 -------------------------
2023-03-25 19:10:44,720 : [INFO]  ------------------------- Batch round 1, loss: 0.5636 -------------------------
2023-03-25 19:10:44,721 : [INFO]  ------------------------- Batch 433, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:44,864 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:44,867 : [INFO]  ------------------------- Batch 433 training: round 2 -------------------------
2023-03-25 19:10:46,612 : [INFO]  ------------------------- Batch round 2, loss: 0.5648 -------------------------
2023-03-25 19:10:46,613 : [INFO]  ------------------------- Batch 433, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:46,760 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:46,763 : [INFO]  ------------------------- Batch 433 training: round 3 -------------------------
2023-03-25 19:10:48,521 : [INFO]  ------------------------- Batch round 3, loss: 0.5609 -------------------------
2023-03-25 19:10:48,521 : [INFO]  ------------------------- Batch 433, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:48,625 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:48,627 : [INFO]  Batch number 433 model fetched from the server
2023-03-25 19:10:48,627 : [INFO]  ################ Batch 433: final global model evalution after 3 rounds ################
2023-03-25 19:10:49,867 : [INFO]  Batch 433: Training set : loss - 0.5744, accuracy - 0.6793, recall - 0.8804, AUC - 0.8678, F1 - 0.733, precision - 0.6279, training time - -8.0 seconds
2023-03-25 19:10:49,868 : [INFO]  Batch 433: Testing set : loss - 0.6073, accuracy - 0.6618, recall - 0.7843, AUC - 0.7907, F1 - 0.6987, precision - 0.6299
2023-03-25 19:10:49,878 : [INFO]  Batch 434 initialized 
2023-03-25 19:10:50,354 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:10:51,439 : [INFO]  ------------------------- Batch 434 training: round 1 -------------------------
2023-03-25 19:10:54,827 : [INFO]  ------------------------- Batch round 1, loss: 0.5621 -------------------------
2023-03-25 19:10:54,828 : [INFO]  ------------------------- Batch 434, round 1: Sent local model to the server -------------------------
2023-03-25 19:10:54,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:54,911 : [INFO]  ------------------------- Batch 434 training: round 2 -------------------------
2023-03-25 19:10:56,649 : [INFO]  ------------------------- Batch round 2, loss: 0.5586 -------------------------
2023-03-25 19:10:56,650 : [INFO]  ------------------------- Batch 434, round 2: Sent local model to the server -------------------------
2023-03-25 19:10:56,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:56,716 : [INFO]  ------------------------- Batch 434 training: round 3 -------------------------
2023-03-25 19:10:58,463 : [INFO]  ------------------------- Batch round 3, loss: 0.5524 -------------------------
2023-03-25 19:10:58,463 : [INFO]  ------------------------- Batch 434, round 3: Sent local model to the server -------------------------
2023-03-25 19:10:58,496 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:10:58,499 : [INFO]  Batch number 434 model fetched from the server
2023-03-25 19:10:58,499 : [INFO]  ################ Batch 434: final global model evalution after 3 rounds ################
2023-03-25 19:10:59,699 : [INFO]  Batch 434: Training set : loss - 0.5674, accuracy - 0.7011, recall - 0.8696, AUC - 0.8728, F1 - 0.7442, precision - 0.6504, training time - -7.0 seconds
2023-03-25 19:10:59,700 : [INFO]  Batch 434: Testing set : loss - 0.5948, accuracy - 0.6618, recall - 0.7745, AUC - 0.7996, F1 - 0.696, precision - 0.632
2023-03-25 19:10:59,710 : [INFO]  Batch 435 initialized 
2023-03-25 19:11:00,172 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:01,195 : [INFO]  ------------------------- Batch 435 training: round 1 -------------------------
2023-03-25 19:11:04,548 : [INFO]  ------------------------- Batch round 1, loss: 0.5501 -------------------------
2023-03-25 19:11:04,548 : [INFO]  ------------------------- Batch 435, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:04,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:04,667 : [INFO]  ------------------------- Batch 435 training: round 2 -------------------------
2023-03-25 19:11:06,354 : [INFO]  ------------------------- Batch round 2, loss: 0.546 -------------------------
2023-03-25 19:11:06,355 : [INFO]  ------------------------- Batch 435, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:06,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:06,466 : [INFO]  ------------------------- Batch 435 training: round 3 -------------------------
2023-03-25 19:11:08,223 : [INFO]  ------------------------- Batch round 3, loss: 0.5544 -------------------------
2023-03-25 19:11:08,223 : [INFO]  ------------------------- Batch 435, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:08,298 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:08,300 : [INFO]  Batch number 435 model fetched from the server
2023-03-25 19:11:08,300 : [INFO]  ################ Batch 435: final global model evalution after 3 rounds ################
2023-03-25 19:11:09,458 : [INFO]  Batch 435: Training set : loss - 0.5578, accuracy - 0.7228, recall - 0.9239, AUC - 0.893, F1 - 0.7692, precision - 0.6589, training time - -7.0 seconds
2023-03-25 19:11:09,458 : [INFO]  Batch 435: Testing set : loss - 0.5904, accuracy - 0.6569, recall - 0.8333, AUC - 0.8312, F1 - 0.7083, precision - 0.6159
2023-03-25 19:11:09,472 : [INFO]  Batch 436 initialized 
2023-03-25 19:11:09,925 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:10,929 : [INFO]  ------------------------- Batch 436 training: round 1 -------------------------
2023-03-25 19:11:14,437 : [INFO]  ------------------------- Batch round 1, loss: 0.6015 -------------------------
2023-03-25 19:11:14,437 : [INFO]  ------------------------- Batch 436, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:14,455 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:14,457 : [INFO]  ------------------------- Batch 436 training: round 2 -------------------------
2023-03-25 19:11:16,300 : [INFO]  ------------------------- Batch round 2, loss: 0.6039 -------------------------
2023-03-25 19:11:16,301 : [INFO]  ------------------------- Batch 436, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:16,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:16,321 : [INFO]  ------------------------- Batch 436 training: round 3 -------------------------
2023-03-25 19:11:18,153 : [INFO]  ------------------------- Batch round 3, loss: 0.6026 -------------------------
2023-03-25 19:11:18,153 : [INFO]  ------------------------- Batch 436, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:18,170 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:18,172 : [INFO]  Batch number 436 model fetched from the server
2023-03-25 19:11:18,172 : [INFO]  ################ Batch 436: final global model evalution after 3 rounds ################
2023-03-25 19:11:19,353 : [INFO]  Batch 436: Training set : loss - 0.6185, accuracy - 0.6413, recall - 0.7826, AUC - 0.7676, F1 - 0.6857, precision - 0.6102, training time - -7.0 seconds
2023-03-25 19:11:19,354 : [INFO]  Batch 436: Testing set : loss - 0.5895, accuracy - 0.6765, recall - 0.8039, AUC - 0.8253, F1 - 0.713, precision - 0.6406
2023-03-25 19:11:19,368 : [INFO]  Batch 437 initialized 
2023-03-25 19:11:19,822 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:20,853 : [INFO]  ------------------------- Batch 437 training: round 1 -------------------------
2023-03-25 19:11:24,437 : [INFO]  ------------------------- Batch round 1, loss: 0.5507 -------------------------
2023-03-25 19:11:24,437 : [INFO]  ------------------------- Batch 437, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:24,453 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:24,456 : [INFO]  ------------------------- Batch 437 training: round 2 -------------------------
2023-03-25 19:11:26,357 : [INFO]  ------------------------- Batch round 2, loss: 0.5595 -------------------------
2023-03-25 19:11:26,357 : [INFO]  ------------------------- Batch 437, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:26,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:26,376 : [INFO]  ------------------------- Batch 437 training: round 3 -------------------------
2023-03-25 19:11:28,231 : [INFO]  ------------------------- Batch round 3, loss: 0.5556 -------------------------
2023-03-25 19:11:28,231 : [INFO]  ------------------------- Batch 437, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:28,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:28,250 : [INFO]  Batch number 437 model fetched from the server
2023-03-25 19:11:28,250 : [INFO]  ################ Batch 437: final global model evalution after 3 rounds ################
2023-03-25 19:11:29,441 : [INFO]  Batch 437: Training set : loss - 0.5681, accuracy - 0.712, recall - 0.8261, AUC - 0.8415, F1 - 0.7415, precision - 0.6726, training time - -7.0 seconds
2023-03-25 19:11:29,442 : [INFO]  Batch 437: Testing set : loss - 0.5881, accuracy - 0.6716, recall - 0.8039, AUC - 0.8097, F1 - 0.71, precision - 0.6357
2023-03-25 19:11:29,454 : [INFO]  Batch 438 initialized 
2023-03-25 19:11:29,911 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:30,931 : [INFO]  ------------------------- Batch 438 training: round 1 -------------------------
2023-03-25 19:11:34,427 : [INFO]  ------------------------- Batch round 1, loss: 0.5619 -------------------------
2023-03-25 19:11:34,427 : [INFO]  ------------------------- Batch 438, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:34,445 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:34,447 : [INFO]  ------------------------- Batch 438 training: round 2 -------------------------
2023-03-25 19:11:36,238 : [INFO]  ------------------------- Batch round 2, loss: 0.5561 -------------------------
2023-03-25 19:11:36,238 : [INFO]  ------------------------- Batch 438, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:36,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:36,258 : [INFO]  ------------------------- Batch 438 training: round 3 -------------------------
2023-03-25 19:11:38,047 : [INFO]  ------------------------- Batch round 3, loss: 0.5571 -------------------------
2023-03-25 19:11:38,047 : [INFO]  ------------------------- Batch 438, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:38,082 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:38,084 : [INFO]  Batch number 438 model fetched from the server
2023-03-25 19:11:38,084 : [INFO]  ################ Batch 438: final global model evalution after 3 rounds ################
2023-03-25 19:11:39,283 : [INFO]  Batch 438: Training set : loss - 0.5683, accuracy - 0.712, recall - 0.8587, AUC - 0.8539, F1 - 0.7488, precision - 0.6639, training time - -7.0 seconds
2023-03-25 19:11:39,284 : [INFO]  Batch 438: Testing set : loss - 0.5926, accuracy - 0.652, recall - 0.8235, AUC - 0.8073, F1 - 0.7029, precision - 0.6131
2023-03-25 19:11:39,294 : [INFO]  Batch 439 initialized 
2023-03-25 19:11:39,769 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:40,763 : [INFO]  ------------------------- Batch 439 training: round 1 -------------------------
2023-03-25 19:11:44,209 : [INFO]  ------------------------- Batch round 1, loss: 0.5751 -------------------------
2023-03-25 19:11:44,209 : [INFO]  ------------------------- Batch 439, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:44,323 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:44,325 : [INFO]  ------------------------- Batch 439 training: round 2 -------------------------
2023-03-25 19:11:46,101 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 19:11:46,101 : [INFO]  ------------------------- Batch 439, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:46,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:46,177 : [INFO]  ------------------------- Batch 439 training: round 3 -------------------------
2023-03-25 19:11:47,928 : [INFO]  ------------------------- Batch round 3, loss: 0.568 -------------------------
2023-03-25 19:11:47,929 : [INFO]  ------------------------- Batch 439, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:48,029 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:48,031 : [INFO]  Batch number 439 model fetched from the server
2023-03-25 19:11:48,032 : [INFO]  ################ Batch 439: final global model evalution after 3 rounds ################
2023-03-25 19:11:49,212 : [INFO]  Batch 439: Training set : loss - 0.58, accuracy - 0.6793, recall - 0.8478, AUC - 0.8441, F1 - 0.7256, precision - 0.6341, training time - -7.0 seconds
2023-03-25 19:11:49,213 : [INFO]  Batch 439: Testing set : loss - 0.5788, accuracy - 0.7206, recall - 0.8137, AUC - 0.8262, F1 - 0.7444, precision - 0.686
2023-03-25 19:11:49,227 : [INFO]  Batch 440 initialized 
2023-03-25 19:11:49,689 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:11:50,715 : [INFO]  ------------------------- Batch 440 training: round 1 -------------------------
2023-03-25 19:11:54,102 : [INFO]  ------------------------- Batch round 1, loss: 0.5671 -------------------------
2023-03-25 19:11:54,103 : [INFO]  ------------------------- Batch 440, round 1: Sent local model to the server -------------------------
2023-03-25 19:11:54,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:54,122 : [INFO]  ------------------------- Batch 440 training: round 2 -------------------------
2023-03-25 19:11:55,916 : [INFO]  ------------------------- Batch round 2, loss: 0.577 -------------------------
2023-03-25 19:11:55,916 : [INFO]  ------------------------- Batch 440, round 2: Sent local model to the server -------------------------
2023-03-25 19:11:55,941 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:55,943 : [INFO]  ------------------------- Batch 440 training: round 3 -------------------------
2023-03-25 19:11:57,710 : [INFO]  ------------------------- Batch round 3, loss: 0.5707 -------------------------
2023-03-25 19:11:57,710 : [INFO]  ------------------------- Batch 440, round 3: Sent local model to the server -------------------------
2023-03-25 19:11:57,729 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:11:57,731 : [INFO]  Batch number 440 model fetched from the server
2023-03-25 19:11:57,731 : [INFO]  ################ Batch 440: final global model evalution after 3 rounds ################
2023-03-25 19:11:58,954 : [INFO]  Batch 440: Training set : loss - 0.5798, accuracy - 0.7011, recall - 0.8261, AUC - 0.8329, F1 - 0.7343, precision - 0.6609, training time - -7.0 seconds
2023-03-25 19:11:58,955 : [INFO]  Batch 440: Testing set : loss - 0.5944, accuracy - 0.6863, recall - 0.8137, AUC - 0.8222, F1 - 0.7217, precision - 0.6484
2023-03-25 19:11:58,962 : [INFO]  Batch 441 initialized 
2023-03-25 19:11:59,411 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:00,436 : [INFO]  ------------------------- Batch 441 training: round 1 -------------------------
2023-03-25 19:12:03,868 : [INFO]  ------------------------- Batch round 1, loss: 0.563 -------------------------
2023-03-25 19:12:03,868 : [INFO]  ------------------------- Batch 441, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:03,885 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:03,887 : [INFO]  ------------------------- Batch 441 training: round 2 -------------------------
2023-03-25 19:12:05,715 : [INFO]  ------------------------- Batch round 2, loss: 0.5619 -------------------------
2023-03-25 19:12:05,716 : [INFO]  ------------------------- Batch 441, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:05,741 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:05,743 : [INFO]  ------------------------- Batch 441 training: round 3 -------------------------
2023-03-25 19:12:07,506 : [INFO]  ------------------------- Batch round 3, loss: 0.5605 -------------------------
2023-03-25 19:12:07,506 : [INFO]  ------------------------- Batch 441, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:07,523 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:07,525 : [INFO]  Batch number 441 model fetched from the server
2023-03-25 19:12:07,525 : [INFO]  ################ Batch 441: final global model evalution after 3 rounds ################
2023-03-25 19:12:08,699 : [INFO]  Batch 441: Training set : loss - 0.5708, accuracy - 0.6848, recall - 0.8696, AUC - 0.8613, F1 - 0.7339, precision - 0.6349, training time - -7.0 seconds
2023-03-25 19:12:08,699 : [INFO]  Batch 441: Testing set : loss - 0.6153, accuracy - 0.6029, recall - 0.7843, AUC - 0.7848, F1 - 0.6639, precision - 0.5755
2023-03-25 19:12:08,717 : [INFO]  Batch 442 initialized 
2023-03-25 19:12:09,166 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:10,176 : [INFO]  ------------------------- Batch 442 training: round 1 -------------------------
2023-03-25 19:12:13,684 : [INFO]  ------------------------- Batch round 1, loss: 0.5717 -------------------------
2023-03-25 19:12:13,684 : [INFO]  ------------------------- Batch 442, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:13,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:13,746 : [INFO]  ------------------------- Batch 442 training: round 2 -------------------------
2023-03-25 19:12:15,535 : [INFO]  ------------------------- Batch round 2, loss: 0.5703 -------------------------
2023-03-25 19:12:15,535 : [INFO]  ------------------------- Batch 442, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:15,583 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:15,586 : [INFO]  ------------------------- Batch 442 training: round 3 -------------------------
2023-03-25 19:12:17,434 : [INFO]  ------------------------- Batch round 3, loss: 0.5668 -------------------------
2023-03-25 19:12:17,434 : [INFO]  ------------------------- Batch 442, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:17,904 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:17,906 : [INFO]  Batch number 442 model fetched from the server
2023-03-25 19:12:17,906 : [INFO]  ################ Batch 442: final global model evalution after 3 rounds ################
2023-03-25 19:12:19,075 : [INFO]  Batch 442: Training set : loss - 0.5818, accuracy - 0.7174, recall - 0.8804, AUC - 0.8619, F1 - 0.757, precision - 0.6639, training time - -8.0 seconds
2023-03-25 19:12:19,075 : [INFO]  Batch 442: Testing set : loss - 0.5769, accuracy - 0.7059, recall - 0.7941, AUC - 0.8296, F1 - 0.7297, precision - 0.675
2023-03-25 19:12:19,092 : [INFO]  Batch 443 initialized 
2023-03-25 19:12:19,540 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:20,583 : [INFO]  ------------------------- Batch 443 training: round 1 -------------------------
2023-03-25 19:12:24,052 : [INFO]  ------------------------- Batch round 1, loss: 0.5819 -------------------------
2023-03-25 19:12:24,052 : [INFO]  ------------------------- Batch 443, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:24,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:24,092 : [INFO]  ------------------------- Batch 443 training: round 2 -------------------------
2023-03-25 19:12:25,863 : [INFO]  ------------------------- Batch round 2, loss: 0.5823 -------------------------
2023-03-25 19:12:25,863 : [INFO]  ------------------------- Batch 443, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:25,880 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:25,882 : [INFO]  ------------------------- Batch 443 training: round 3 -------------------------
2023-03-25 19:12:27,650 : [INFO]  ------------------------- Batch round 3, loss: 0.5806 -------------------------
2023-03-25 19:12:27,650 : [INFO]  ------------------------- Batch 443, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:27,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:27,671 : [INFO]  Batch number 443 model fetched from the server
2023-03-25 19:12:27,671 : [INFO]  ################ Batch 443: final global model evalution after 3 rounds ################
2023-03-25 19:12:28,832 : [INFO]  Batch 443: Training set : loss - 0.5918, accuracy - 0.7065, recall - 0.837, AUC - 0.8172, F1 - 0.7404, precision - 0.6638, training time - -7.0 seconds
2023-03-25 19:12:28,832 : [INFO]  Batch 443: Testing set : loss - 0.6048, accuracy - 0.6471, recall - 0.8431, AUC - 0.8121, F1 - 0.7049, precision - 0.6056
2023-03-25 19:12:28,850 : [INFO]  Batch 444 initialized 
2023-03-25 19:12:29,313 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:30,339 : [INFO]  ------------------------- Batch 444 training: round 1 -------------------------
2023-03-25 19:12:33,797 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-25 19:12:33,797 : [INFO]  ------------------------- Batch 444, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:33,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:33,842 : [INFO]  ------------------------- Batch 444 training: round 2 -------------------------
2023-03-25 19:12:35,650 : [INFO]  ------------------------- Batch round 2, loss: 0.5715 -------------------------
2023-03-25 19:12:35,650 : [INFO]  ------------------------- Batch 444, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:35,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:35,672 : [INFO]  ------------------------- Batch 444 training: round 3 -------------------------
2023-03-25 19:12:37,445 : [INFO]  ------------------------- Batch round 3, loss: 0.5745 -------------------------
2023-03-25 19:12:37,445 : [INFO]  ------------------------- Batch 444, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:37,492 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:37,494 : [INFO]  Batch number 444 model fetched from the server
2023-03-25 19:12:37,494 : [INFO]  ################ Batch 444: final global model evalution after 3 rounds ################
2023-03-25 19:12:38,667 : [INFO]  Batch 444: Training set : loss - 0.5783, accuracy - 0.712, recall - 0.837, AUC - 0.8149, F1 - 0.744, precision - 0.6696, training time - -7.0 seconds
2023-03-25 19:12:38,668 : [INFO]  Batch 444: Testing set : loss - 0.5939, accuracy - 0.652, recall - 0.7745, AUC - 0.8028, F1 - 0.69, precision - 0.622
2023-03-25 19:12:38,680 : [INFO]  Batch 445 initialized 
2023-03-25 19:12:39,138 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:40,141 : [INFO]  ------------------------- Batch 445 training: round 1 -------------------------
2023-03-25 19:12:43,585 : [INFO]  ------------------------- Batch round 1, loss: 0.5873 -------------------------
2023-03-25 19:12:43,585 : [INFO]  ------------------------- Batch 445, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:43,660 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:43,662 : [INFO]  ------------------------- Batch 445 training: round 2 -------------------------
2023-03-25 19:12:45,422 : [INFO]  ------------------------- Batch round 2, loss: 0.5852 -------------------------
2023-03-25 19:12:45,422 : [INFO]  ------------------------- Batch 445, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:45,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:45,467 : [INFO]  ------------------------- Batch 445 training: round 3 -------------------------
2023-03-25 19:12:47,246 : [INFO]  ------------------------- Batch round 3, loss: 0.5826 -------------------------
2023-03-25 19:12:47,246 : [INFO]  ------------------------- Batch 445, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:47,265 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:47,268 : [INFO]  Batch number 445 model fetched from the server
2023-03-25 19:12:47,268 : [INFO]  ################ Batch 445: final global model evalution after 3 rounds ################
2023-03-25 19:12:48,508 : [INFO]  Batch 445: Training set : loss - 0.593, accuracy - 0.6522, recall - 0.7935, AUC - 0.8005, F1 - 0.6952, precision - 0.6186, training time - -7.0 seconds
2023-03-25 19:12:48,508 : [INFO]  Batch 445: Testing set : loss - 0.5537, accuracy - 0.7108, recall - 0.8627, AUC - 0.8737, F1 - 0.7489, precision - 0.6617
2023-03-25 19:12:48,520 : [INFO]  Batch 446 initialized 
2023-03-25 19:12:48,962 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:49,968 : [INFO]  ------------------------- Batch 446 training: round 1 -------------------------
2023-03-25 19:12:53,458 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-25 19:12:53,458 : [INFO]  ------------------------- Batch 446, round 1: Sent local model to the server -------------------------
2023-03-25 19:12:53,476 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:53,478 : [INFO]  ------------------------- Batch 446 training: round 2 -------------------------
2023-03-25 19:12:55,246 : [INFO]  ------------------------- Batch round 2, loss: 0.5691 -------------------------
2023-03-25 19:12:55,246 : [INFO]  ------------------------- Batch 446, round 2: Sent local model to the server -------------------------
2023-03-25 19:12:55,264 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:55,266 : [INFO]  ------------------------- Batch 446 training: round 3 -------------------------
2023-03-25 19:12:57,069 : [INFO]  ------------------------- Batch round 3, loss: 0.5657 -------------------------
2023-03-25 19:12:57,070 : [INFO]  ------------------------- Batch 446, round 3: Sent local model to the server -------------------------
2023-03-25 19:12:57,087 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:12:57,089 : [INFO]  Batch number 446 model fetched from the server
2023-03-25 19:12:57,089 : [INFO]  ################ Batch 446: final global model evalution after 3 rounds ################
2023-03-25 19:12:58,314 : [INFO]  Batch 446: Training set : loss - 0.5789, accuracy - 0.6957, recall - 0.8587, AUC - 0.8441, F1 - 0.7383, precision - 0.6475, training time - -7.0 seconds
2023-03-25 19:12:58,314 : [INFO]  Batch 446: Testing set : loss - 0.587, accuracy - 0.6765, recall - 0.7941, AUC - 0.8088, F1 - 0.7105, precision - 0.6429
2023-03-25 19:12:58,323 : [INFO]  Batch 447 initialized 
2023-03-25 19:12:58,782 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:12:59,825 : [INFO]  ------------------------- Batch 447 training: round 1 -------------------------
2023-03-25 19:13:03,286 : [INFO]  ------------------------- Batch round 1, loss: 0.5548 -------------------------
2023-03-25 19:13:03,287 : [INFO]  ------------------------- Batch 447, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:03,322 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:03,324 : [INFO]  ------------------------- Batch 447 training: round 2 -------------------------
2023-03-25 19:13:05,172 : [INFO]  ------------------------- Batch round 2, loss: 0.5484 -------------------------
2023-03-25 19:13:05,172 : [INFO]  ------------------------- Batch 447, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:05,188 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:05,190 : [INFO]  ------------------------- Batch 447 training: round 3 -------------------------
2023-03-25 19:13:07,074 : [INFO]  ------------------------- Batch round 3, loss: 0.5534 -------------------------
2023-03-25 19:13:07,074 : [INFO]  ------------------------- Batch 447, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:07,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:07,101 : [INFO]  Batch number 447 model fetched from the server
2023-03-25 19:13:07,101 : [INFO]  ################ Batch 447: final global model evalution after 3 rounds ################
2023-03-25 19:13:08,313 : [INFO]  Batch 447: Training set : loss - 0.5613, accuracy - 0.7609, recall - 0.8696, AUC - 0.8552, F1 - 0.7843, precision - 0.7143, training time - -7.0 seconds
2023-03-25 19:13:08,313 : [INFO]  Batch 447: Testing set : loss - 0.5786, accuracy - 0.7157, recall - 0.8137, AUC - 0.8182, F1 - 0.7411, precision - 0.6803
2023-03-25 19:13:08,324 : [INFO]  Batch 448 initialized 
2023-03-25 19:13:08,782 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:09,806 : [INFO]  ------------------------- Batch 448 training: round 1 -------------------------
2023-03-25 19:13:13,378 : [INFO]  ------------------------- Batch round 1, loss: 0.5649 -------------------------
2023-03-25 19:13:13,378 : [INFO]  ------------------------- Batch 448, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:13,396 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:13,398 : [INFO]  ------------------------- Batch 448 training: round 2 -------------------------
2023-03-25 19:13:15,234 : [INFO]  ------------------------- Batch round 2, loss: 0.5636 -------------------------
2023-03-25 19:13:15,234 : [INFO]  ------------------------- Batch 448, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:15,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:15,253 : [INFO]  ------------------------- Batch 448 training: round 3 -------------------------
2023-03-25 19:13:17,088 : [INFO]  ------------------------- Batch round 3, loss: 0.5681 -------------------------
2023-03-25 19:13:17,088 : [INFO]  ------------------------- Batch 448, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:17,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:17,108 : [INFO]  Batch number 448 model fetched from the server
2023-03-25 19:13:17,108 : [INFO]  ################ Batch 448: final global model evalution after 3 rounds ################
2023-03-25 19:13:18,332 : [INFO]  Batch 448: Training set : loss - 0.5732, accuracy - 0.6739, recall - 0.837, AUC - 0.8461, F1 - 0.7196, precision - 0.6311, training time - -7.0 seconds
2023-03-25 19:13:18,333 : [INFO]  Batch 448: Testing set : loss - 0.588, accuracy - 0.701, recall - 0.8431, AUC - 0.8433, F1 - 0.7382, precision - 0.6565
2023-03-25 19:13:18,340 : [INFO]  Batch 449 initialized 
2023-03-25 19:13:18,795 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:19,868 : [INFO]  ------------------------- Batch 449 training: round 1 -------------------------
2023-03-25 19:13:23,437 : [INFO]  ------------------------- Batch round 1, loss: 0.5528 -------------------------
2023-03-25 19:13:23,438 : [INFO]  ------------------------- Batch 449, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:23,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:23,490 : [INFO]  ------------------------- Batch 449 training: round 2 -------------------------
2023-03-25 19:13:25,484 : [INFO]  ------------------------- Batch round 2, loss: 0.5541 -------------------------
2023-03-25 19:13:25,484 : [INFO]  ------------------------- Batch 449, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:25,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:25,579 : [INFO]  ------------------------- Batch 449 training: round 3 -------------------------
2023-03-25 19:13:27,307 : [INFO]  ------------------------- Batch round 3, loss: 0.5493 -------------------------
2023-03-25 19:13:27,308 : [INFO]  ------------------------- Batch 449, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:27,407 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:27,409 : [INFO]  Batch number 449 model fetched from the server
2023-03-25 19:13:27,409 : [INFO]  ################ Batch 449: final global model evalution after 3 rounds ################
2023-03-25 19:13:28,586 : [INFO]  Batch 449: Training set : loss - 0.5576, accuracy - 0.7283, recall - 0.8696, AUC - 0.8774, F1 - 0.7619, precision - 0.678, training time - -8.0 seconds
2023-03-25 19:13:28,586 : [INFO]  Batch 449: Testing set : loss - 0.5961, accuracy - 0.6176, recall - 0.8137, AUC - 0.8142, F1 - 0.6803, precision - 0.5845
2023-03-25 19:13:28,601 : [INFO]  Batch 450 initialized 
2023-03-25 19:13:29,075 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:30,135 : [INFO]  ------------------------- Batch 450 training: round 1 -------------------------
2023-03-25 19:13:33,503 : [INFO]  ------------------------- Batch round 1, loss: 0.5643 -------------------------
2023-03-25 19:13:33,504 : [INFO]  ------------------------- Batch 450, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:33,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:33,523 : [INFO]  ------------------------- Batch 450 training: round 2 -------------------------
2023-03-25 19:13:35,261 : [INFO]  ------------------------- Batch round 2, loss: 0.5615 -------------------------
2023-03-25 19:13:35,261 : [INFO]  ------------------------- Batch 450, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:35,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:35,281 : [INFO]  ------------------------- Batch 450 training: round 3 -------------------------
2023-03-25 19:13:36,967 : [INFO]  ------------------------- Batch round 3, loss: 0.5576 -------------------------
2023-03-25 19:13:36,967 : [INFO]  ------------------------- Batch 450, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:37,008 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:37,010 : [INFO]  Batch number 450 model fetched from the server
2023-03-25 19:13:37,010 : [INFO]  ################ Batch 450: final global model evalution after 3 rounds ################
2023-03-25 19:13:38,179 : [INFO]  Batch 450: Training set : loss - 0.5678, accuracy - 0.712, recall - 0.8587, AUC - 0.8674, F1 - 0.7488, precision - 0.6639, training time - -7.0 seconds
2023-03-25 19:13:38,179 : [INFO]  Batch 450: Testing set : loss - 0.569, accuracy - 0.6863, recall - 0.8529, AUC - 0.8616, F1 - 0.7311, precision - 0.6397
2023-03-25 19:13:38,196 : [INFO]  Batch 451 initialized 
2023-03-25 19:13:38,651 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:39,709 : [INFO]  ------------------------- Batch 451 training: round 1 -------------------------
2023-03-25 19:13:43,145 : [INFO]  ------------------------- Batch round 1, loss: 0.5608 -------------------------
2023-03-25 19:13:43,146 : [INFO]  ------------------------- Batch 451, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:43,163 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:43,165 : [INFO]  ------------------------- Batch 451 training: round 2 -------------------------
2023-03-25 19:13:44,937 : [INFO]  ------------------------- Batch round 2, loss: 0.5623 -------------------------
2023-03-25 19:13:44,937 : [INFO]  ------------------------- Batch 451, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:44,956 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:44,958 : [INFO]  ------------------------- Batch 451 training: round 3 -------------------------
2023-03-25 19:13:46,756 : [INFO]  ------------------------- Batch round 3, loss: 0.5604 -------------------------
2023-03-25 19:13:46,756 : [INFO]  ------------------------- Batch 451, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:46,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:46,775 : [INFO]  Batch number 451 model fetched from the server
2023-03-25 19:13:46,775 : [INFO]  ################ Batch 451: final global model evalution after 3 rounds ################
2023-03-25 19:13:47,988 : [INFO]  Batch 451: Training set : loss - 0.5699, accuracy - 0.7011, recall - 0.8261, AUC - 0.851, F1 - 0.7343, precision - 0.6609, training time - -7.0 seconds
2023-03-25 19:13:47,988 : [INFO]  Batch 451: Testing set : loss - 0.5865, accuracy - 0.6471, recall - 0.7745, AUC - 0.8067, F1 - 0.687, precision - 0.6172
2023-03-25 19:13:47,996 : [INFO]  Batch 452 initialized 
2023-03-25 19:13:48,451 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:49,486 : [INFO]  ------------------------- Batch 452 training: round 1 -------------------------
2023-03-25 19:13:52,927 : [INFO]  ------------------------- Batch round 1, loss: 0.5693 -------------------------
2023-03-25 19:13:52,927 : [INFO]  ------------------------- Batch 452, round 1: Sent local model to the server -------------------------
2023-03-25 19:13:52,947 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:52,949 : [INFO]  ------------------------- Batch 452 training: round 2 -------------------------
2023-03-25 19:13:54,756 : [INFO]  ------------------------- Batch round 2, loss: 0.5695 -------------------------
2023-03-25 19:13:54,756 : [INFO]  ------------------------- Batch 452, round 2: Sent local model to the server -------------------------
2023-03-25 19:13:54,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:54,775 : [INFO]  ------------------------- Batch 452 training: round 3 -------------------------
2023-03-25 19:13:56,543 : [INFO]  ------------------------- Batch round 3, loss: 0.5666 -------------------------
2023-03-25 19:13:56,543 : [INFO]  ------------------------- Batch 452, round 3: Sent local model to the server -------------------------
2023-03-25 19:13:56,563 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:13:56,566 : [INFO]  Batch number 452 model fetched from the server
2023-03-25 19:13:56,566 : [INFO]  ################ Batch 452: final global model evalution after 3 rounds ################
2023-03-25 19:13:57,755 : [INFO]  Batch 452: Training set : loss - 0.578, accuracy - 0.7174, recall - 0.9022, AUC - 0.865, F1 - 0.7615, precision - 0.6587, training time - -7.0 seconds
2023-03-25 19:13:57,755 : [INFO]  Batch 452: Testing set : loss - 0.5882, accuracy - 0.6912, recall - 0.8431, AUC - 0.8209, F1 - 0.7319, precision - 0.6466
2023-03-25 19:13:57,770 : [INFO]  Batch 453 initialized 
2023-03-25 19:13:58,219 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:13:59,244 : [INFO]  ------------------------- Batch 453 training: round 1 -------------------------
2023-03-25 19:14:02,602 : [INFO]  ------------------------- Batch round 1, loss: 0.5583 -------------------------
2023-03-25 19:14:02,602 : [INFO]  ------------------------- Batch 453, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:02,684 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:02,686 : [INFO]  ------------------------- Batch 453 training: round 2 -------------------------
2023-03-25 19:14:04,413 : [INFO]  ------------------------- Batch round 2, loss: 0.5595 -------------------------
2023-03-25 19:14:04,413 : [INFO]  ------------------------- Batch 453, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:04,477 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:04,479 : [INFO]  ------------------------- Batch 453 training: round 3 -------------------------
2023-03-25 19:14:06,234 : [INFO]  ------------------------- Batch round 3, loss: 0.5579 -------------------------
2023-03-25 19:14:06,234 : [INFO]  ------------------------- Batch 453, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:06,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:06,254 : [INFO]  Batch number 453 model fetched from the server
2023-03-25 19:14:06,254 : [INFO]  ################ Batch 453: final global model evalution after 3 rounds ################
2023-03-25 19:14:07,593 : [INFO]  Batch 453: Training set : loss - 0.5663, accuracy - 0.7011, recall - 0.837, AUC - 0.8582, F1 - 0.7368, precision - 0.6581, training time - -7.0 seconds
2023-03-25 19:14:07,593 : [INFO]  Batch 453: Testing set : loss - 0.5907, accuracy - 0.6667, recall - 0.8039, AUC - 0.8188, F1 - 0.7069, precision - 0.6308
2023-03-25 19:14:07,603 : [INFO]  Batch 454 initialized 
2023-03-25 19:14:08,082 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:09,084 : [INFO]  ------------------------- Batch 454 training: round 1 -------------------------
2023-03-25 19:14:12,578 : [INFO]  ------------------------- Batch round 1, loss: 0.5508 -------------------------
2023-03-25 19:14:12,578 : [INFO]  ------------------------- Batch 454, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:12,683 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:12,686 : [INFO]  ------------------------- Batch 454 training: round 2 -------------------------
2023-03-25 19:14:14,401 : [INFO]  ------------------------- Batch round 2, loss: 0.5518 -------------------------
2023-03-25 19:14:14,401 : [INFO]  ------------------------- Batch 454, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:14,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:14,473 : [INFO]  ------------------------- Batch 454 training: round 3 -------------------------
2023-03-25 19:14:16,181 : [INFO]  ------------------------- Batch round 3, loss: 0.548 -------------------------
2023-03-25 19:14:16,181 : [INFO]  ------------------------- Batch 454, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:16,237 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:16,239 : [INFO]  Batch number 454 model fetched from the server
2023-03-25 19:14:16,239 : [INFO]  ################ Batch 454: final global model evalution after 3 rounds ################
2023-03-25 19:14:17,445 : [INFO]  Batch 454: Training set : loss - 0.5613, accuracy - 0.6685, recall - 0.8587, AUC - 0.8735, F1 - 0.7215, precision - 0.622, training time - -7.0 seconds
2023-03-25 19:14:17,445 : [INFO]  Batch 454: Testing set : loss - 0.573, accuracy - 0.6814, recall - 0.902, AUC - 0.8706, F1 - 0.739, precision - 0.6259
2023-03-25 19:14:17,461 : [INFO]  Batch 455 initialized 
2023-03-25 19:14:17,944 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:19,017 : [INFO]  ------------------------- Batch 455 training: round 1 -------------------------
2023-03-25 19:14:22,404 : [INFO]  ------------------------- Batch round 1, loss: 0.5907 -------------------------
2023-03-25 19:14:22,404 : [INFO]  ------------------------- Batch 455, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:22,473 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:22,475 : [INFO]  ------------------------- Batch 455 training: round 2 -------------------------
2023-03-25 19:14:24,230 : [INFO]  ------------------------- Batch round 2, loss: 0.5872 -------------------------
2023-03-25 19:14:24,230 : [INFO]  ------------------------- Batch 455, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:24,295 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:24,297 : [INFO]  ------------------------- Batch 455 training: round 3 -------------------------
2023-03-25 19:14:26,049 : [INFO]  ------------------------- Batch round 3, loss: 0.591 -------------------------
2023-03-25 19:14:26,049 : [INFO]  ------------------------- Batch 455, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:26,137 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:26,139 : [INFO]  Batch number 455 model fetched from the server
2023-03-25 19:14:26,139 : [INFO]  ################ Batch 455: final global model evalution after 3 rounds ################
2023-03-25 19:14:27,312 : [INFO]  Batch 455: Training set : loss - 0.6077, accuracy - 0.6739, recall - 0.8043, AUC - 0.7765, F1 - 0.7115, precision - 0.6379, training time - -7.0 seconds
2023-03-25 19:14:27,312 : [INFO]  Batch 455: Testing set : loss - 0.5686, accuracy - 0.7157, recall - 0.8529, AUC - 0.8635, F1 - 0.75, precision - 0.6692
2023-03-25 19:14:27,327 : [INFO]  Batch 456 initialized 
2023-03-25 19:14:27,787 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:28,838 : [INFO]  ------------------------- Batch 456 training: round 1 -------------------------
2023-03-25 19:14:32,239 : [INFO]  ------------------------- Batch round 1, loss: 0.5546 -------------------------
2023-03-25 19:14:32,239 : [INFO]  ------------------------- Batch 456, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:32,273 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:32,275 : [INFO]  ------------------------- Batch 456 training: round 2 -------------------------
2023-03-25 19:14:34,105 : [INFO]  ------------------------- Batch round 2, loss: 0.5578 -------------------------
2023-03-25 19:14:34,105 : [INFO]  ------------------------- Batch 456, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:34,159 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:34,161 : [INFO]  ------------------------- Batch 456 training: round 3 -------------------------
2023-03-25 19:14:35,909 : [INFO]  ------------------------- Batch round 3, loss: 0.56 -------------------------
2023-03-25 19:14:35,910 : [INFO]  ------------------------- Batch 456, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:35,953 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:35,955 : [INFO]  Batch number 456 model fetched from the server
2023-03-25 19:14:35,956 : [INFO]  ################ Batch 456: final global model evalution after 3 rounds ################
2023-03-25 19:14:37,202 : [INFO]  Batch 456: Training set : loss - 0.5648, accuracy - 0.6902, recall - 0.837, AUC - 0.8595, F1 - 0.7299, precision - 0.6471, training time - -7.0 seconds
2023-03-25 19:14:37,203 : [INFO]  Batch 456: Testing set : loss - 0.5714, accuracy - 0.6569, recall - 0.8235, AUC - 0.8507, F1 - 0.7059, precision - 0.6176
2023-03-25 19:14:37,218 : [INFO]  Batch 457 initialized 
2023-03-25 19:14:37,677 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:38,746 : [INFO]  ------------------------- Batch 457 training: round 1 -------------------------
2023-03-25 19:14:42,212 : [INFO]  ------------------------- Batch round 1, loss: 0.5818 -------------------------
2023-03-25 19:14:42,212 : [INFO]  ------------------------- Batch 457, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:42,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:42,230 : [INFO]  ------------------------- Batch 457 training: round 2 -------------------------
2023-03-25 19:14:44,004 : [INFO]  ------------------------- Batch round 2, loss: 0.5834 -------------------------
2023-03-25 19:14:44,004 : [INFO]  ------------------------- Batch 457, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:44,022 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:44,024 : [INFO]  ------------------------- Batch 457 training: round 3 -------------------------
2023-03-25 19:14:45,777 : [INFO]  ------------------------- Batch round 3, loss: 0.5797 -------------------------
2023-03-25 19:14:45,777 : [INFO]  ------------------------- Batch 457, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:45,795 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:45,797 : [INFO]  Batch number 457 model fetched from the server
2023-03-25 19:14:45,797 : [INFO]  ################ Batch 457: final global model evalution after 3 rounds ################
2023-03-25 19:14:47,014 : [INFO]  Batch 457: Training set : loss - 0.5963, accuracy - 0.6739, recall - 0.7935, AUC - 0.8065, F1 - 0.7087, precision - 0.6404, training time - -7.0 seconds
2023-03-25 19:14:47,014 : [INFO]  Batch 457: Testing set : loss - 0.5742, accuracy - 0.701, recall - 0.8137, AUC - 0.8184, F1 - 0.7313, precision - 0.664
2023-03-25 19:14:47,024 : [INFO]  Batch 458 initialized 
2023-03-25 19:14:47,499 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:48,581 : [INFO]  ------------------------- Batch 458 training: round 1 -------------------------
2023-03-25 19:14:52,043 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-25 19:14:52,043 : [INFO]  ------------------------- Batch 458, round 1: Sent local model to the server -------------------------
2023-03-25 19:14:52,060 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:52,062 : [INFO]  ------------------------- Batch 458 training: round 2 -------------------------
2023-03-25 19:14:53,825 : [INFO]  ------------------------- Batch round 2, loss: 0.5672 -------------------------
2023-03-25 19:14:53,825 : [INFO]  ------------------------- Batch 458, round 2: Sent local model to the server -------------------------
2023-03-25 19:14:53,843 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:53,846 : [INFO]  ------------------------- Batch 458 training: round 3 -------------------------
2023-03-25 19:14:55,644 : [INFO]  ------------------------- Batch round 3, loss: 0.5642 -------------------------
2023-03-25 19:14:55,644 : [INFO]  ------------------------- Batch 458, round 3: Sent local model to the server -------------------------
2023-03-25 19:14:55,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:14:55,664 : [INFO]  Batch number 458 model fetched from the server
2023-03-25 19:14:55,665 : [INFO]  ################ Batch 458: final global model evalution after 3 rounds ################
2023-03-25 19:14:56,915 : [INFO]  Batch 458: Training set : loss - 0.5756, accuracy - 0.7174, recall - 0.8587, AUC - 0.8453, F1 - 0.7524, precision - 0.6695, training time - -7.0 seconds
2023-03-25 19:14:56,916 : [INFO]  Batch 458: Testing set : loss - 0.5888, accuracy - 0.6765, recall - 0.7941, AUC - 0.8056, F1 - 0.7105, precision - 0.6429
2023-03-25 19:14:56,923 : [INFO]  Batch 459 initialized 
2023-03-25 19:14:57,377 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:14:58,447 : [INFO]  ------------------------- Batch 459 training: round 1 -------------------------
2023-03-25 19:15:01,895 : [INFO]  ------------------------- Batch round 1, loss: 0.6007 -------------------------
2023-03-25 19:15:01,896 : [INFO]  ------------------------- Batch 459, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:01,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:01,915 : [INFO]  ------------------------- Batch 459 training: round 2 -------------------------
2023-03-25 19:15:03,726 : [INFO]  ------------------------- Batch round 2, loss: 0.6016 -------------------------
2023-03-25 19:15:03,726 : [INFO]  ------------------------- Batch 459, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:03,747 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:03,749 : [INFO]  ------------------------- Batch 459 training: round 3 -------------------------
2023-03-25 19:15:05,570 : [INFO]  ------------------------- Batch round 3, loss: 0.597 -------------------------
2023-03-25 19:15:05,570 : [INFO]  ------------------------- Batch 459, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:05,588 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:05,590 : [INFO]  Batch number 459 model fetched from the server
2023-03-25 19:15:05,590 : [INFO]  ################ Batch 459: final global model evalution after 3 rounds ################
2023-03-25 19:15:06,788 : [INFO]  Batch 459: Training set : loss - 0.61, accuracy - 0.625, recall - 0.8043, AUC - 0.7788, F1 - 0.682, precision - 0.592, training time - -7.0 seconds
2023-03-25 19:15:06,788 : [INFO]  Batch 459: Testing set : loss - 0.5813, accuracy - 0.6716, recall - 0.8333, AUC - 0.8317, F1 - 0.7173, precision - 0.6296
2023-03-25 19:15:06,805 : [INFO]  Batch 460 initialized 
2023-03-25 19:15:07,266 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:08,318 : [INFO]  ------------------------- Batch 460 training: round 1 -------------------------
2023-03-25 19:15:11,863 : [INFO]  ------------------------- Batch round 1, loss: 0.5749 -------------------------
2023-03-25 19:15:11,863 : [INFO]  ------------------------- Batch 460, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:11,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:11,952 : [INFO]  ------------------------- Batch 460 training: round 2 -------------------------
2023-03-25 19:15:13,757 : [INFO]  ------------------------- Batch round 2, loss: 0.5807 -------------------------
2023-03-25 19:15:13,757 : [INFO]  ------------------------- Batch 460, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:13,788 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:13,790 : [INFO]  ------------------------- Batch 460 training: round 3 -------------------------
2023-03-25 19:15:15,606 : [INFO]  ------------------------- Batch round 3, loss: 0.5732 -------------------------
2023-03-25 19:15:15,606 : [INFO]  ------------------------- Batch 460, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:15,628 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:15,630 : [INFO]  Batch number 460 model fetched from the server
2023-03-25 19:15:15,631 : [INFO]  ################ Batch 460: final global model evalution after 3 rounds ################
2023-03-25 19:15:16,858 : [INFO]  Batch 460: Training set : loss - 0.5884, accuracy - 0.6848, recall - 0.8043, AUC - 0.7937, F1 - 0.7184, precision - 0.6491, training time - -7.0 seconds
2023-03-25 19:15:16,858 : [INFO]  Batch 460: Testing set : loss - 0.5642, accuracy - 0.701, recall - 0.8431, AUC - 0.872, F1 - 0.7382, precision - 0.6565
2023-03-25 19:15:16,873 : [INFO]  Batch 461 initialized 
2023-03-25 19:15:17,331 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:18,410 : [INFO]  ------------------------- Batch 461 training: round 1 -------------------------
2023-03-25 19:15:21,913 : [INFO]  ------------------------- Batch round 1, loss: 0.5801 -------------------------
2023-03-25 19:15:21,913 : [INFO]  ------------------------- Batch 461, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:21,965 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:21,970 : [INFO]  ------------------------- Batch 461 training: round 2 -------------------------
2023-03-25 19:15:23,843 : [INFO]  ------------------------- Batch round 2, loss: 0.5865 -------------------------
2023-03-25 19:15:23,843 : [INFO]  ------------------------- Batch 461, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:23,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:23,888 : [INFO]  ------------------------- Batch 461 training: round 3 -------------------------
2023-03-25 19:15:25,677 : [INFO]  ------------------------- Batch round 3, loss: 0.584 -------------------------
2023-03-25 19:15:25,677 : [INFO]  ------------------------- Batch 461, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:25,713 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:25,715 : [INFO]  Batch number 461 model fetched from the server
2023-03-25 19:15:25,716 : [INFO]  ################ Batch 461: final global model evalution after 3 rounds ################
2023-03-25 19:15:26,896 : [INFO]  Batch 461: Training set : loss - 0.598, accuracy - 0.6413, recall - 0.8043, AUC - 0.8023, F1 - 0.6916, precision - 0.6066, training time - -7.0 seconds
2023-03-25 19:15:26,896 : [INFO]  Batch 461: Testing set : loss - 0.6011, accuracy - 0.6471, recall - 0.8333, AUC - 0.8117, F1 - 0.7025, precision - 0.6071
2023-03-25 19:15:26,910 : [INFO]  Batch 462 initialized 
2023-03-25 19:15:27,384 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:28,468 : [INFO]  ------------------------- Batch 462 training: round 1 -------------------------
2023-03-25 19:15:31,993 : [INFO]  ------------------------- Batch round 1, loss: 0.5668 -------------------------
2023-03-25 19:15:31,993 : [INFO]  ------------------------- Batch 462, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:32,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:32,026 : [INFO]  ------------------------- Batch 462 training: round 2 -------------------------
2023-03-25 19:15:33,829 : [INFO]  ------------------------- Batch round 2, loss: 0.5726 -------------------------
2023-03-25 19:15:33,829 : [INFO]  ------------------------- Batch 462, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:33,848 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:33,850 : [INFO]  ------------------------- Batch 462 training: round 3 -------------------------
2023-03-25 19:15:35,696 : [INFO]  ------------------------- Batch round 3, loss: 0.5675 -------------------------
2023-03-25 19:15:35,697 : [INFO]  ------------------------- Batch 462, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:35,716 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:35,718 : [INFO]  Batch number 462 model fetched from the server
2023-03-25 19:15:35,719 : [INFO]  ################ Batch 462: final global model evalution after 3 rounds ################
2023-03-25 19:15:36,896 : [INFO]  Batch 462: Training set : loss - 0.5799, accuracy - 0.6957, recall - 0.8152, AUC - 0.8309, F1 - 0.7282, precision - 0.6579, training time - -7.0 seconds
2023-03-25 19:15:36,896 : [INFO]  Batch 462: Testing set : loss - 0.5484, accuracy - 0.7255, recall - 0.8529, AUC - 0.8764, F1 - 0.7565, precision - 0.6797
2023-03-25 19:15:36,906 : [INFO]  Batch 463 initialized 
2023-03-25 19:15:37,382 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:38,442 : [INFO]  ------------------------- Batch 463 training: round 1 -------------------------
2023-03-25 19:15:41,796 : [INFO]  ------------------------- Batch round 1, loss: 0.5416 -------------------------
2023-03-25 19:15:41,796 : [INFO]  ------------------------- Batch 463, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:41,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:41,966 : [INFO]  ------------------------- Batch 463 training: round 2 -------------------------
2023-03-25 19:15:43,657 : [INFO]  ------------------------- Batch round 2, loss: 0.5459 -------------------------
2023-03-25 19:15:43,657 : [INFO]  ------------------------- Batch 463, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:43,779 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:43,781 : [INFO]  ------------------------- Batch 463 training: round 3 -------------------------
2023-03-25 19:15:45,603 : [INFO]  ------------------------- Batch round 3, loss: 0.549 -------------------------
2023-03-25 19:15:45,603 : [INFO]  ------------------------- Batch 463, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:45,689 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:45,691 : [INFO]  Batch number 463 model fetched from the server
2023-03-25 19:15:45,692 : [INFO]  ################ Batch 463: final global model evalution after 3 rounds ################
2023-03-25 19:15:46,860 : [INFO]  Batch 463: Training set : loss - 0.5554, accuracy - 0.75, recall - 0.8478, AUC - 0.8602, F1 - 0.7723, precision - 0.7091, training time - -7.0 seconds
2023-03-25 19:15:46,860 : [INFO]  Batch 463: Testing set : loss - 0.5612, accuracy - 0.7059, recall - 0.8529, AUC - 0.8649, F1 - 0.7436, precision - 0.6591
2023-03-25 19:15:46,868 : [INFO]  Batch 464 initialized 
2023-03-25 19:15:47,338 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:48,408 : [INFO]  ------------------------- Batch 464 training: round 1 -------------------------
2023-03-25 19:15:51,925 : [INFO]  ------------------------- Batch round 1, loss: 0.577 -------------------------
2023-03-25 19:15:51,925 : [INFO]  ------------------------- Batch 464, round 1: Sent local model to the server -------------------------
2023-03-25 19:15:51,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:51,945 : [INFO]  ------------------------- Batch 464 training: round 2 -------------------------
2023-03-25 19:15:53,756 : [INFO]  ------------------------- Batch round 2, loss: 0.5762 -------------------------
2023-03-25 19:15:53,756 : [INFO]  ------------------------- Batch 464, round 2: Sent local model to the server -------------------------
2023-03-25 19:15:53,773 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:53,775 : [INFO]  ------------------------- Batch 464 training: round 3 -------------------------
2023-03-25 19:15:55,560 : [INFO]  ------------------------- Batch round 3, loss: 0.5748 -------------------------
2023-03-25 19:15:55,560 : [INFO]  ------------------------- Batch 464, round 3: Sent local model to the server -------------------------
2023-03-25 19:15:55,578 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:15:55,580 : [INFO]  Batch number 464 model fetched from the server
2023-03-25 19:15:55,580 : [INFO]  ################ Batch 464: final global model evalution after 3 rounds ################
2023-03-25 19:15:56,782 : [INFO]  Batch 464: Training set : loss - 0.5918, accuracy - 0.6848, recall - 0.7717, AUC - 0.7803, F1 - 0.71, precision - 0.6574, training time - -7.0 seconds
2023-03-25 19:15:56,782 : [INFO]  Batch 464: Testing set : loss - 0.5652, accuracy - 0.7059, recall - 0.8333, AUC - 0.8532, F1 - 0.7391, precision - 0.6641
2023-03-25 19:15:56,790 : [INFO]  Batch 465 initialized 
2023-03-25 19:15:57,342 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:15:58,395 : [INFO]  ------------------------- Batch 465 training: round 1 -------------------------
2023-03-25 19:16:01,844 : [INFO]  ------------------------- Batch round 1, loss: 0.5513 -------------------------
2023-03-25 19:16:01,844 : [INFO]  ------------------------- Batch 465, round 1: Sent local model to the server -------------------------
2023-03-25 19:16:01,868 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:01,870 : [INFO]  ------------------------- Batch 465 training: round 2 -------------------------
2023-03-25 19:16:03,617 : [INFO]  ------------------------- Batch round 2, loss: 0.5574 -------------------------
2023-03-25 19:16:03,617 : [INFO]  ------------------------- Batch 465, round 2: Sent local model to the server -------------------------
2023-03-25 19:16:03,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:03,639 : [INFO]  ------------------------- Batch 465 training: round 3 -------------------------
2023-03-25 19:16:05,438 : [INFO]  ------------------------- Batch round 3, loss: 0.5516 -------------------------
2023-03-25 19:16:05,438 : [INFO]  ------------------------- Batch 465, round 3: Sent local model to the server -------------------------
2023-03-25 19:16:05,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:05,459 : [INFO]  Batch number 465 model fetched from the server
2023-03-25 19:16:05,459 : [INFO]  ################ Batch 465: final global model evalution after 3 rounds ################
2023-03-25 19:16:06,624 : [INFO]  Batch 465: Training set : loss - 0.5647, accuracy - 0.7011, recall - 0.8804, AUC - 0.8764, F1 - 0.7465, precision - 0.648, training time - -7.0 seconds
2023-03-25 19:16:06,624 : [INFO]  Batch 465: Testing set : loss - 0.5613, accuracy - 0.7059, recall - 0.9216, AUC - 0.8949, F1 - 0.7581, precision - 0.6438
2023-03-25 19:16:06,638 : [INFO]  Batch 466 initialized 
2023-03-25 19:16:07,092 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 19:16:08,141 : [INFO]  ------------------------- Batch 466 training: round 1 -------------------------
2023-03-25 19:16:11,677 : [INFO]  ------------------------- Batch round 1, loss: 0.5585 -------------------------
2023-03-25 19:16:11,677 : [INFO]  ------------------------- Batch 466, round 1: Sent local model to the server -------------------------
2023-03-25 19:16:11,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:11,699 : [INFO]  ------------------------- Batch 466 training: round 2 -------------------------
2023-03-25 19:16:13,581 : [INFO]  ------------------------- Batch round 2, loss: 0.5671 -------------------------
2023-03-25 19:16:13,581 : [INFO]  ------------------------- Batch 466, round 2: Sent local model to the server -------------------------
2023-03-25 19:16:13,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:13,602 : [INFO]  ------------------------- Batch 466 training: round 3 -------------------------
2023-03-25 19:16:15,412 : [INFO]  ------------------------- Batch round 3, loss: 0.5636 -------------------------
2023-03-25 19:16:15,412 : [INFO]  ------------------------- Batch 466, round 3: Sent local model to the server -------------------------
2023-03-25 19:16:15,430 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 19:16:15,432 : [INFO]  Batch number 466 model fetched from the server
2023-03-25 19:16:15,432 : [INFO]  ################ Batch 466: final global model evalution after 3 rounds ################
2023-03-25 19:16:16,670 : [INFO]  Batch 466: Training set : loss - 0.5755, accuracy - 0.6739, recall - 0.8696, AUC - 0.8612, F1 - 0.7273, precision - 0.625, training time - -7.0 seconds
2023-03-25 19:16:16,670 : [INFO]  Batch 466: Testing set : loss - 0.568, accuracy - 0.7059, recall - 0.8333, AUC - 0.8454, F1 - 0.7391, precision - 0.6641
2023-03-25 19:16:16,684 : [INFO]  Result report : Accuracy - 0.6805 (0.0419), Recall - 0.8441 (0.0594), AUC - 0.8167 (0.0479), F1 - 0.7251 (0.0368), Precision - 0.6367 (0.0332)
2023-03-25 19:16:16,685 : [INFO]  Result report : Accuracy - 0.6805 (0.0419), Recall - 0.8441 (0.0594), AUC - 0.8167 (0.0479), F1 - 0.7251 (0.0368), Precision - 0.6367 (0.0332), Mean time for a batch - 10.04 (1.86) seconds
2023-03-25 19:16:16,685 : [INFO]  Distributed training done!
2023-03-25 19:16:16,685 : [INFO]  Training report : Total elapsed time 6952.403483565002 seconds, graph name facebook, graph ID 1, partition ID 0, training epochs 6, epochs 6
