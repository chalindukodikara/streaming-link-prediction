2023-03-27 14:43:53,046 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-27 14:43:53,046 : [INFO]  Client started, graph name wikipedia, graph ID 1, partition ID 1, training epochs 6, epochs 6
2023-03-27 14:43:57,385 : [INFO]  Model initialized for training
2023-03-27 14:43:59,392 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:43:59,422 : [INFO]  Number of training examples - 1842, Number of testing examples - 2046
2023-03-27 14:43:59,422 : [INFO]  Connected to the server
2023-03-27 14:43:59,514 : [INFO]  Distributed training for streaming graphs started!
2023-03-27 14:43:59,515 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:43:59,525 : [INFO]  ################################## Initial model training started ##################################
2023-03-27 14:43:59,526 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-27 14:44:17,421 : [INFO]  ------------------------- Training round 1, loss: 0.7002 -------------------------
2023-03-27 14:44:17,421 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-27 14:44:17,425 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:44:17,427 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-27 14:44:38,505 : [INFO]  ------------------------- Training round 2, loss: 0.6263 -------------------------
2023-03-27 14:44:38,505 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-27 14:44:38,513 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:44:38,521 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-27 14:44:59,778 : [INFO]  ------------------------- Training round 3, loss: 0.6015 -------------------------
2023-03-27 14:44:59,778 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-27 14:44:59,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:44:59,873 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-27 14:45:22,183 : [INFO]  ------------------------- Training round 4, loss: 0.5903 -------------------------
2023-03-27 14:45:22,184 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-27 14:45:23,559 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:45:23,564 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-27 14:45:45,008 : [INFO]  ------------------------- Training round 5, loss: 0.5858 -------------------------
2023-03-27 14:45:45,009 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-27 14:45:45,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:45:45,019 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-27 14:46:06,776 : [INFO]  ------------------------- Training round 6, loss: 0.5813 -------------------------
2023-03-27 14:46:06,776 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-27 14:46:06,782 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:06,784 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-27 14:46:15,217 : [INFO]  Initially trained model: Training set : loss - 0.57, accuracy - 0.73, recall - 0.9, AUC - 0.86, F1 - 0.77, precision - 0.68, training time - -127.0 seconds
2023-03-27 14:46:15,217 : [INFO]  Initially trained model: Testing set : loss - 0.57, accuracy - 0.74, recall - 0.91, AUC - 0.86, F1 - 0.78, precision - 0.68
2023-03-27 14:46:15,233 : [INFO]  Batch 1 initialized 
2023-03-27 14:46:15,951 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:16,191 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-27 14:46:16,191 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-27 14:46:21,920 : [INFO]  ------------------------- Batch round 1, loss: 0.564 -------------------------
2023-03-27 14:46:21,920 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-27 14:46:21,923 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:21,925 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-27 14:46:24,239 : [INFO]  ------------------------- Batch round 2, loss: 0.549 -------------------------
2023-03-27 14:46:24,239 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-27 14:46:24,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:24,287 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-27 14:46:26,743 : [INFO]  ------------------------- Batch round 3, loss: 0.5501 -------------------------
2023-03-27 14:46:26,744 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-27 14:46:26,758 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:26,761 : [INFO]  Batch number 1 model fetched from the server
2023-03-27 14:46:26,761 : [INFO]  ################ Batch 1: final global model evalution after 3 rounds ################
2023-03-27 14:46:28,745 : [INFO]  Batch 1: Training set : loss - 0.5361, accuracy - 0.7989, recall - 0.9783, AUC - 0.8888, F1 - 0.8295, precision - 0.72, training time - -11.0 seconds
2023-03-27 14:46:28,746 : [INFO]  Batch 1: Testing set : loss - 0.5571, accuracy - 0.7745, recall - 0.9706, AUC - 0.8883, F1 - 0.8115, precision - 0.6972
2023-03-27 14:46:28,754 : [INFO]  Batch 2 initialized 
2023-03-27 14:46:29,402 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:29,581 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-27 14:46:35,011 : [INFO]  ------------------------- Batch round 1, loss: 0.6174 -------------------------
2023-03-27 14:46:35,012 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-27 14:46:35,025 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:35,027 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-27 14:46:37,744 : [INFO]  ------------------------- Batch round 2, loss: 0.6123 -------------------------
2023-03-27 14:46:37,746 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-27 14:46:37,754 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:37,757 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-27 14:46:40,550 : [INFO]  ------------------------- Batch round 3, loss: 0.6104 -------------------------
2023-03-27 14:46:40,553 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-27 14:46:40,561 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:40,570 : [INFO]  Batch number 2 model fetched from the server
2023-03-27 14:46:40,570 : [INFO]  ################ Batch 2: final global model evalution after 3 rounds ################
2023-03-27 14:46:42,658 : [INFO]  Batch 2: Training set : loss - 0.605, accuracy - 0.6957, recall - 0.9674, AUC - 0.7873, F1 - 0.7607, precision - 0.6268, training time - -11.0 seconds
2023-03-27 14:46:42,658 : [INFO]  Batch 2: Testing set : loss - 0.6125, accuracy - 0.6667, recall - 0.902, AUC - 0.7898, F1 - 0.7302, precision - 0.6133
2023-03-27 14:46:42,692 : [INFO]  Batch 3 initialized 
2023-03-27 14:46:43,356 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:43,722 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-27 14:46:49,340 : [INFO]  ------------------------- Batch round 1, loss: 0.5719 -------------------------
2023-03-27 14:46:49,340 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-27 14:46:49,344 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:49,350 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-27 14:46:51,914 : [INFO]  ------------------------- Batch round 2, loss: 0.564 -------------------------
2023-03-27 14:46:51,915 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-27 14:46:51,922 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:51,929 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-27 14:46:54,712 : [INFO]  ------------------------- Batch round 3, loss: 0.5649 -------------------------
2023-03-27 14:46:54,712 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-27 14:46:54,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:46:54,717 : [INFO]  Batch number 3 model fetched from the server
2023-03-27 14:46:54,717 : [INFO]  ################ Batch 3: final global model evalution after 3 rounds ################
2023-03-27 14:46:56,482 : [INFO]  Batch 3: Training set : loss - 0.5579, accuracy - 0.7609, recall - 0.9457, AUC - 0.8476, F1 - 0.7982, precision - 0.6905, training time - -11.0 seconds
2023-03-27 14:46:56,483 : [INFO]  Batch 3: Testing set : loss - 0.5829, accuracy - 0.7206, recall - 0.9118, AUC - 0.8177, F1 - 0.7654, precision - 0.6596
2023-03-27 14:46:56,491 : [INFO]  Batch 4 initialized 
2023-03-27 14:46:57,100 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:46:57,507 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-27 14:47:02,901 : [INFO]  ------------------------- Batch round 1, loss: 0.5624 -------------------------
2023-03-27 14:47:02,902 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:02,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:02,968 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-27 14:47:05,686 : [INFO]  ------------------------- Batch round 2, loss: 0.5576 -------------------------
2023-03-27 14:47:05,687 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:05,692 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:05,694 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-27 14:47:08,630 : [INFO]  ------------------------- Batch round 3, loss: 0.5566 -------------------------
2023-03-27 14:47:08,631 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:08,654 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:08,664 : [INFO]  Batch number 4 model fetched from the server
2023-03-27 14:47:08,664 : [INFO]  ################ Batch 4: final global model evalution after 3 rounds ################
2023-03-27 14:47:10,950 : [INFO]  Batch 4: Training set : loss - 0.5518, accuracy - 0.75, recall - 0.9348, AUC - 0.8734, F1 - 0.789, precision - 0.6825, training time - -11.0 seconds
2023-03-27 14:47:10,950 : [INFO]  Batch 4: Testing set : loss - 0.5379, accuracy - 0.7794, recall - 0.9706, AUC - 0.8911, F1 - 0.8148, precision - 0.7021
2023-03-27 14:47:10,964 : [INFO]  Batch 5 initialized 
2023-03-27 14:47:11,655 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:12,105 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-27 14:47:17,926 : [INFO]  ------------------------- Batch round 1, loss: 0.5778 -------------------------
2023-03-27 14:47:17,928 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:17,934 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:17,937 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-27 14:47:21,102 : [INFO]  ------------------------- Batch round 2, loss: 0.58 -------------------------
2023-03-27 14:47:21,102 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:21,106 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:21,107 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-27 14:47:23,642 : [INFO]  ------------------------- Batch round 3, loss: 0.5748 -------------------------
2023-03-27 14:47:23,642 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:23,646 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:23,650 : [INFO]  Batch number 5 model fetched from the server
2023-03-27 14:47:23,650 : [INFO]  ################ Batch 5: final global model evalution after 3 rounds ################
2023-03-27 14:47:25,360 : [INFO]  Batch 5: Training set : loss - 0.5701, accuracy - 0.7065, recall - 0.9239, AUC - 0.8575, F1 - 0.7589, precision - 0.6439, training time - -12.0 seconds
2023-03-27 14:47:25,361 : [INFO]  Batch 5: Testing set : loss - 0.595, accuracy - 0.6667, recall - 0.8922, AUC - 0.8401, F1 - 0.728, precision - 0.6149
2023-03-27 14:47:25,378 : [INFO]  Batch 6 initialized 
2023-03-27 14:47:26,091 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:26,513 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-27 14:47:31,271 : [INFO]  ------------------------- Batch round 1, loss: 0.5636 -------------------------
2023-03-27 14:47:31,271 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:31,280 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:31,291 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-27 14:47:33,621 : [INFO]  ------------------------- Batch round 2, loss: 0.5609 -------------------------
2023-03-27 14:47:33,621 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:33,670 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:33,676 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-27 14:47:36,361 : [INFO]  ------------------------- Batch round 3, loss: 0.5559 -------------------------
2023-03-27 14:47:36,362 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:36,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:36,367 : [INFO]  Batch number 6 model fetched from the server
2023-03-27 14:47:36,367 : [INFO]  ################ Batch 6: final global model evalution after 3 rounds ################
2023-03-27 14:47:38,445 : [INFO]  Batch 6: Training set : loss - 0.5463, accuracy - 0.75, recall - 0.9348, AUC - 0.8685, F1 - 0.789, precision - 0.6825, training time - -10.0 seconds
2023-03-27 14:47:38,446 : [INFO]  Batch 6: Testing set : loss - 0.5517, accuracy - 0.7304, recall - 0.951, AUC - 0.8777, F1 - 0.7791, precision - 0.6599
2023-03-27 14:47:38,466 : [INFO]  Batch 7 initialized 
2023-03-27 14:47:39,305 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:39,654 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-27 14:47:44,810 : [INFO]  ------------------------- Batch round 1, loss: 0.5552 -------------------------
2023-03-27 14:47:44,811 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:44,814 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:44,816 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-27 14:47:47,591 : [INFO]  ------------------------- Batch round 2, loss: 0.5507 -------------------------
2023-03-27 14:47:47,592 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-27 14:47:47,598 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:47,600 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-27 14:47:50,383 : [INFO]  ------------------------- Batch round 3, loss: 0.5493 -------------------------
2023-03-27 14:47:50,384 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-27 14:47:50,401 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:50,412 : [INFO]  Batch number 7 model fetched from the server
2023-03-27 14:47:50,413 : [INFO]  ################ Batch 7: final global model evalution after 3 rounds ################
2023-03-27 14:47:52,165 : [INFO]  Batch 7: Training set : loss - 0.5427, accuracy - 0.7663, recall - 0.9348, AUC - 0.8668, F1 - 0.8, precision - 0.6992, training time - -11.0 seconds
2023-03-27 14:47:52,166 : [INFO]  Batch 7: Testing set : loss - 0.5897, accuracy - 0.7206, recall - 0.9314, AUC - 0.7996, F1 - 0.7692, precision - 0.6552
2023-03-27 14:47:52,177 : [INFO]  Batch 8 initialized 
2023-03-27 14:47:52,781 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:47:53,040 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-27 14:47:57,637 : [INFO]  ------------------------- Batch round 1, loss: 0.5575 -------------------------
2023-03-27 14:47:57,640 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-27 14:47:57,648 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:47:57,652 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-27 14:48:00,685 : [INFO]  ------------------------- Batch round 2, loss: 0.5519 -------------------------
2023-03-27 14:48:00,687 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:00,693 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:00,695 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-27 14:48:03,195 : [INFO]  ------------------------- Batch round 3, loss: 0.5506 -------------------------
2023-03-27 14:48:03,196 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:03,200 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:03,203 : [INFO]  Batch number 8 model fetched from the server
2023-03-27 14:48:03,203 : [INFO]  ################ Batch 8: final global model evalution after 3 rounds ################
2023-03-27 14:48:05,061 : [INFO]  Batch 8: Training set : loss - 0.5436, accuracy - 0.7609, recall - 0.9348, AUC - 0.8901, F1 - 0.7963, precision - 0.6935, training time - -10.0 seconds
2023-03-27 14:48:05,062 : [INFO]  Batch 8: Testing set : loss - 0.6029, accuracy - 0.7059, recall - 0.902, AUC - 0.7885, F1 - 0.7541, precision - 0.6479
2023-03-27 14:48:05,072 : [INFO]  Batch 9 initialized 
2023-03-27 14:48:05,571 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:48:05,871 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-27 14:48:11,200 : [INFO]  ------------------------- Batch round 1, loss: 0.5707 -------------------------
2023-03-27 14:48:11,201 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-27 14:48:11,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:11,219 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-27 14:48:13,983 : [INFO]  ------------------------- Batch round 2, loss: 0.5636 -------------------------
2023-03-27 14:48:13,983 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:13,989 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:13,991 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-27 14:48:16,620 : [INFO]  ------------------------- Batch round 3, loss: 0.5651 -------------------------
2023-03-27 14:48:16,623 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:16,789 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:16,793 : [INFO]  Batch number 9 model fetched from the server
2023-03-27 14:48:16,793 : [INFO]  ################ Batch 9: final global model evalution after 3 rounds ################
2023-03-27 14:48:18,328 : [INFO]  Batch 9: Training set : loss - 0.5583, accuracy - 0.7283, recall - 0.9674, AUC - 0.8896, F1 - 0.7807, precision - 0.6544, training time - -11.0 seconds
2023-03-27 14:48:18,329 : [INFO]  Batch 9: Testing set : loss - 0.5372, accuracy - 0.7794, recall - 0.9706, AUC - 0.8813, F1 - 0.8148, precision - 0.7021
2023-03-27 14:48:18,337 : [INFO]  Batch 10 initialized 
2023-03-27 14:48:18,868 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:48:19,180 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-27 14:48:24,045 : [INFO]  ------------------------- Batch round 1, loss: 0.5742 -------------------------
2023-03-27 14:48:24,046 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-27 14:48:24,052 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:24,054 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-27 14:48:26,746 : [INFO]  ------------------------- Batch round 2, loss: 0.564 -------------------------
2023-03-27 14:48:26,746 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:26,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:26,754 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-27 14:48:29,834 : [INFO]  ------------------------- Batch round 3, loss: 0.5639 -------------------------
2023-03-27 14:48:29,835 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:29,840 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:29,843 : [INFO]  Batch number 10 model fetched from the server
2023-03-27 14:48:29,843 : [INFO]  ################ Batch 10: final global model evalution after 3 rounds ################
2023-03-27 14:48:31,804 : [INFO]  Batch 10: Training set : loss - 0.5564, accuracy - 0.7446, recall - 0.9565, AUC - 0.8635, F1 - 0.7892, precision - 0.6718, training time - -11.0 seconds
2023-03-27 14:48:31,804 : [INFO]  Batch 10: Testing set : loss - 0.575, accuracy - 0.7206, recall - 0.9314, AUC - 0.8762, F1 - 0.7692, precision - 0.6552
2023-03-27 14:48:31,814 : [INFO]  Batch 11 initialized 
2023-03-27 14:48:32,658 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:48:33,025 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-27 14:48:38,312 : [INFO]  ------------------------- Batch round 1, loss: 0.5696 -------------------------
2023-03-27 14:48:38,312 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-27 14:48:38,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:38,317 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-27 14:48:40,648 : [INFO]  ------------------------- Batch round 2, loss: 0.565 -------------------------
2023-03-27 14:48:40,652 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-27 14:48:40,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:40,894 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-27 14:48:44,717 : [INFO]  ------------------------- Batch round 3, loss: 0.5626 -------------------------
2023-03-27 14:48:44,718 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-27 14:48:44,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-27 14:48:44,723 : [INFO]  Batch number 11 model fetched from the server
2023-03-27 14:48:44,723 : [INFO]  ################ Batch 11: final global model evalution after 3 rounds ################
2023-03-27 14:48:46,846 : [INFO]  Batch 11: Training set : loss - 0.5515, accuracy - 0.7609, recall - 0.9457, AUC - 0.8708, F1 - 0.7982, precision - 0.6905, training time - -12.0 seconds
2023-03-27 14:48:46,847 : [INFO]  Batch 11: Testing set : loss - 0.5835, accuracy - 0.7206, recall - 0.9118, AUC - 0.8436, F1 - 0.7654, precision - 0.6596
2023-03-27 14:48:46,859 : [INFO]  Batch 12 initialized 
2023-03-27 14:48:47,578 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-27 14:48:47,792 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-27 14:48:51,036 : [INFO]  ------------------------- Batch round 1, loss: 0.6043 -------------------------
2023-03-27 14:48:51,037 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-27 14:48:51,039 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
