2023-03-25 20:26:44,421 : [WARNING]  ####################################### New Training Session: Client 1 #######################################
2023-03-25 20:26:44,421 : [INFO]  Client started, graph name facebook, graph ID 1, partition ID 1, training epochs 6, epochs 3
2023-03-25 20:26:48,071 : [INFO]  Model initialized for training
2023-03-25 20:27:01,661 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:27:01,778 : [INFO]  Number of training examples - 11796, Number of testing examples - 13106
2023-03-25 20:27:01,779 : [INFO]  Connected to the server
2023-03-25 20:27:01,859 : [INFO]  Distributed training for streaming graphs started!
2023-03-25 20:27:01,859 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:27:01,867 : [INFO]  ################################## Initial model training started ##################################
2023-03-25 20:27:01,867 : [INFO]  ------------------------- Initial model training: round 1 -------------------------
2023-03-25 20:29:25,250 : [INFO]  ------------------------- Training round 1, loss: 0.6208 -------------------------
2023-03-25 20:29:25,250 : [INFO]  ------------------------- Training, round 1: Sent local model to the server -------------------------
2023-03-25 20:29:39,793 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:29:39,795 : [INFO]  ------------------------- Initial model training: round 2 -------------------------
2023-03-25 20:31:49,424 : [INFO]  ------------------------- Training round 2, loss: 0.5945 -------------------------
2023-03-25 20:31:49,424 : [INFO]  ------------------------- Training, round 2: Sent local model to the server -------------------------
2023-03-25 20:31:50,614 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:31:50,615 : [INFO]  ------------------------- Initial model training: round 3 -------------------------
2023-03-25 20:34:00,151 : [INFO]  ------------------------- Training round 3, loss: 0.5912 -------------------------
2023-03-25 20:34:00,151 : [INFO]  ------------------------- Training, round 3: Sent local model to the server -------------------------
2023-03-25 20:34:01,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:34:01,436 : [INFO]  ------------------------- Initial model training: round 4 -------------------------
2023-03-25 20:36:11,237 : [INFO]  ------------------------- Training round 4, loss: 0.589 -------------------------
2023-03-25 20:36:11,237 : [INFO]  ------------------------- Training, round 4: Sent local model to the server -------------------------
2023-03-25 20:36:12,544 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:36:12,545 : [INFO]  ------------------------- Initial model training: round 5 -------------------------
2023-03-25 20:38:36,825 : [INFO]  ------------------------- Training round 5, loss: 0.5887 -------------------------
2023-03-25 20:38:36,825 : [INFO]  ------------------------- Training, round 5: Sent local model to the server -------------------------
2023-03-25 20:38:36,827 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:38:36,829 : [INFO]  ------------------------- Initial model training: round 6 -------------------------
2023-03-25 20:40:46,637 : [INFO]  ------------------------- Training round 6, loss: 0.5866 -------------------------
2023-03-25 20:40:46,637 : [INFO]  ------------------------- Training, round 6: Sent local model to the server -------------------------
2023-03-25 20:40:48,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:40:48,076 : [INFO]  ################ Initial trained model: Final global model evalution after 6 rounds ################
2023-03-25 20:41:31,587 : [INFO]  Initially trained model: Training set : loss - 0.58, accuracy - 0.71, recall - 0.88, AUC - 0.84, F1 - 0.75, precision - 0.66, training time - -826.0 seconds
2023-03-25 20:41:31,587 : [INFO]  Initially trained model: Testing set : loss - 0.59, accuracy - 0.7, recall - 0.88, AUC - 0.84, F1 - 0.74, precision - 0.65
2023-03-25 20:41:31,599 : [INFO]  Batch 1 initialized 
2023-03-25 20:41:32,034 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:41:32,139 : [INFO]  ################################## Next batch processing started: transfer learning is ON ##################################
2023-03-25 20:41:32,140 : [INFO]  ------------------------- Batch 1 training: round 1 -------------------------
2023-03-25 20:41:35,043 : [INFO]  ------------------------- Batch round 1, loss: 0.592 -------------------------
2023-03-25 20:41:35,043 : [INFO]  ------------------------- Batch 1, round 1: Sent local model to the server -------------------------
2023-03-25 20:41:35,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:35,327 : [INFO]  ------------------------- Batch 1 training: round 2 -------------------------
2023-03-25 20:41:36,397 : [INFO]  ------------------------- Batch round 2, loss: 0.5767 -------------------------
2023-03-25 20:41:36,397 : [INFO]  ------------------------- Batch 1, round 2: Sent local model to the server -------------------------
2023-03-25 20:41:36,457 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:36,459 : [INFO]  ------------------------- Batch 1 training: round 3 -------------------------
2023-03-25 20:41:37,487 : [INFO]  ------------------------- Batch round 3, loss: 0.5767 -------------------------
2023-03-25 20:41:37,487 : [INFO]  ------------------------- Batch 1, round 3: Sent local model to the server -------------------------
2023-03-25 20:41:37,580 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:37,582 : [INFO]  ------------------------- Batch 1 training: round 4 -------------------------
2023-03-25 20:41:38,636 : [INFO]  ------------------------- Batch round 4, loss: 0.5707 -------------------------
2023-03-25 20:41:38,636 : [INFO]  ------------------------- Batch 1, round 4: Sent local model to the server -------------------------
2023-03-25 20:41:38,697 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:38,699 : [INFO]  ------------------------- Batch 1 training: round 5 -------------------------
2023-03-25 20:41:39,738 : [INFO]  ------------------------- Batch round 5, loss: 0.5696 -------------------------
2023-03-25 20:41:39,738 : [INFO]  ------------------------- Batch 1, round 5: Sent local model to the server -------------------------
2023-03-25 20:41:39,824 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:39,826 : [INFO]  ------------------------- Batch 1 training: round 6 -------------------------
2023-03-25 20:41:40,856 : [INFO]  ------------------------- Batch round 6, loss: 0.5726 -------------------------
2023-03-25 20:41:40,856 : [INFO]  ------------------------- Batch 1, round 6: Sent local model to the server -------------------------
2023-03-25 20:41:40,943 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:40,945 : [INFO]  Batch number 1 model fetched from the server
2023-03-25 20:41:40,945 : [INFO]  ################ Batch 1: final global model evalution after 6 rounds ################
2023-03-25 20:41:42,187 : [INFO]  Batch 1: Training set : loss - 0.5658, accuracy - 0.7717, recall - 0.8913, AUC - 0.8675, F1 - 0.7961, precision - 0.7193, training time - -9.0 seconds
2023-03-25 20:41:42,187 : [INFO]  Batch 1: Testing set : loss - 0.5557, accuracy - 0.7206, recall - 0.8824, AUC - 0.8792, F1 - 0.7595, precision - 0.6667
2023-03-25 20:41:42,198 : [INFO]  Batch 2 initialized 
2023-03-25 20:41:42,640 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:41:42,783 : [INFO]  ------------------------- Batch 2 training: round 1 -------------------------
2023-03-25 20:41:45,637 : [INFO]  ------------------------- Batch round 1, loss: 0.5576 -------------------------
2023-03-25 20:41:45,637 : [INFO]  ------------------------- Batch 2, round 1: Sent local model to the server -------------------------
2023-03-25 20:41:45,656 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:45,658 : [INFO]  ------------------------- Batch 2 training: round 2 -------------------------
2023-03-25 20:41:46,680 : [INFO]  ------------------------- Batch round 2, loss: 0.5404 -------------------------
2023-03-25 20:41:46,680 : [INFO]  ------------------------- Batch 2, round 2: Sent local model to the server -------------------------
2023-03-25 20:41:46,751 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:46,753 : [INFO]  ------------------------- Batch 2 training: round 3 -------------------------
2023-03-25 20:41:47,779 : [INFO]  ------------------------- Batch round 3, loss: 0.5456 -------------------------
2023-03-25 20:41:47,779 : [INFO]  ------------------------- Batch 2, round 3: Sent local model to the server -------------------------
2023-03-25 20:41:47,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:47,789 : [INFO]  ------------------------- Batch 2 training: round 4 -------------------------
2023-03-25 20:41:48,892 : [INFO]  ------------------------- Batch round 4, loss: 0.5417 -------------------------
2023-03-25 20:41:48,892 : [INFO]  ------------------------- Batch 2, round 4: Sent local model to the server -------------------------
2023-03-25 20:41:48,895 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:48,898 : [INFO]  ------------------------- Batch 2 training: round 5 -------------------------
2023-03-25 20:41:49,930 : [INFO]  ------------------------- Batch round 5, loss: 0.5335 -------------------------
2023-03-25 20:41:49,930 : [INFO]  ------------------------- Batch 2, round 5: Sent local model to the server -------------------------
2023-03-25 20:41:49,954 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:49,955 : [INFO]  ------------------------- Batch 2 training: round 6 -------------------------
2023-03-25 20:41:50,974 : [INFO]  ------------------------- Batch round 6, loss: 0.5312 -------------------------
2023-03-25 20:41:50,974 : [INFO]  ------------------------- Batch 2, round 6: Sent local model to the server -------------------------
2023-03-25 20:41:51,012 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:51,014 : [INFO]  Batch number 2 model fetched from the server
2023-03-25 20:41:51,014 : [INFO]  ################ Batch 2: final global model evalution after 6 rounds ################
2023-03-25 20:41:52,274 : [INFO]  Batch 2: Training set : loss - 0.5277, accuracy - 0.8315, recall - 0.9457, AUC - 0.8988, F1 - 0.8488, precision - 0.7699, training time - -8.0 seconds
2023-03-25 20:41:52,275 : [INFO]  Batch 2: Testing set : loss - 0.5423, accuracy - 0.7647, recall - 0.9314, AUC - 0.906, F1 - 0.7983, precision - 0.6985
2023-03-25 20:41:52,286 : [INFO]  Batch 3 initialized 
2023-03-25 20:41:52,706 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:41:52,920 : [INFO]  ------------------------- Batch 3 training: round 1 -------------------------
2023-03-25 20:41:55,697 : [INFO]  ------------------------- Batch round 1, loss: 0.5657 -------------------------
2023-03-25 20:41:55,697 : [INFO]  ------------------------- Batch 3, round 1: Sent local model to the server -------------------------
2023-03-25 20:41:55,700 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:55,703 : [INFO]  ------------------------- Batch 3 training: round 2 -------------------------
2023-03-25 20:41:56,809 : [INFO]  ------------------------- Batch round 2, loss: 0.5608 -------------------------
2023-03-25 20:41:56,809 : [INFO]  ------------------------- Batch 3, round 2: Sent local model to the server -------------------------
2023-03-25 20:41:57,058 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:57,059 : [INFO]  ------------------------- Batch 3 training: round 3 -------------------------
2023-03-25 20:41:58,118 : [INFO]  ------------------------- Batch round 3, loss: 0.5464 -------------------------
2023-03-25 20:41:58,118 : [INFO]  ------------------------- Batch 3, round 3: Sent local model to the server -------------------------
2023-03-25 20:41:58,121 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:58,123 : [INFO]  ------------------------- Batch 3 training: round 4 -------------------------
2023-03-25 20:41:59,158 : [INFO]  ------------------------- Batch round 4, loss: 0.5496 -------------------------
2023-03-25 20:41:59,158 : [INFO]  ------------------------- Batch 3, round 4: Sent local model to the server -------------------------
2023-03-25 20:41:59,447 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:41:59,449 : [INFO]  ------------------------- Batch 3 training: round 5 -------------------------
2023-03-25 20:42:00,513 : [INFO]  ------------------------- Batch round 5, loss: 0.5426 -------------------------
2023-03-25 20:42:00,513 : [INFO]  ------------------------- Batch 3, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:00,516 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:00,519 : [INFO]  ------------------------- Batch 3 training: round 6 -------------------------
2023-03-25 20:42:01,620 : [INFO]  ------------------------- Batch round 6, loss: 0.5401 -------------------------
2023-03-25 20:42:01,620 : [INFO]  ------------------------- Batch 3, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:01,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:01,625 : [INFO]  Batch number 3 model fetched from the server
2023-03-25 20:42:01,625 : [INFO]  ################ Batch 3: final global model evalution after 6 rounds ################
2023-03-25 20:42:02,948 : [INFO]  Batch 3: Training set : loss - 0.5424, accuracy - 0.7717, recall - 0.9565, AUC - 0.921, F1 - 0.8073, precision - 0.6984, training time - -9.0 seconds
2023-03-25 20:42:02,948 : [INFO]  Batch 3: Testing set : loss - 0.5661, accuracy - 0.701, recall - 0.9118, AUC - 0.9026, F1 - 0.753, precision - 0.6414
2023-03-25 20:42:02,958 : [INFO]  Batch 4 initialized 
2023-03-25 20:42:03,378 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:03,597 : [INFO]  ------------------------- Batch 4 training: round 1 -------------------------
2023-03-25 20:42:06,327 : [INFO]  ------------------------- Batch round 1, loss: 0.5592 -------------------------
2023-03-25 20:42:06,327 : [INFO]  ------------------------- Batch 4, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:06,330 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:06,333 : [INFO]  ------------------------- Batch 4 training: round 2 -------------------------
2023-03-25 20:42:07,398 : [INFO]  ------------------------- Batch round 2, loss: 0.555 -------------------------
2023-03-25 20:42:07,398 : [INFO]  ------------------------- Batch 4, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:07,428 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:07,431 : [INFO]  ------------------------- Batch 4 training: round 3 -------------------------
2023-03-25 20:42:08,457 : [INFO]  ------------------------- Batch round 3, loss: 0.5631 -------------------------
2023-03-25 20:42:08,457 : [INFO]  ------------------------- Batch 4, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:08,505 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:08,508 : [INFO]  ------------------------- Batch 4 training: round 4 -------------------------
2023-03-25 20:42:09,547 : [INFO]  ------------------------- Batch round 4, loss: 0.5482 -------------------------
2023-03-25 20:42:09,547 : [INFO]  ------------------------- Batch 4, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:09,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:09,572 : [INFO]  ------------------------- Batch 4 training: round 5 -------------------------
2023-03-25 20:42:10,633 : [INFO]  ------------------------- Batch round 5, loss: 0.546 -------------------------
2023-03-25 20:42:10,633 : [INFO]  ------------------------- Batch 4, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:10,659 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:10,662 : [INFO]  ------------------------- Batch 4 training: round 6 -------------------------
2023-03-25 20:42:11,721 : [INFO]  ------------------------- Batch round 6, loss: 0.5426 -------------------------
2023-03-25 20:42:11,721 : [INFO]  ------------------------- Batch 4, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:11,740 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:11,743 : [INFO]  Batch number 4 model fetched from the server
2023-03-25 20:42:11,744 : [INFO]  ################ Batch 4: final global model evalution after 6 rounds ################
2023-03-25 20:42:13,032 : [INFO]  Batch 4: Training set : loss - 0.5464, accuracy - 0.7337, recall - 0.9239, AUC - 0.9035, F1 - 0.7763, precision - 0.6693, training time - -8.0 seconds
2023-03-25 20:42:13,032 : [INFO]  Batch 4: Testing set : loss - 0.5528, accuracy - 0.7304, recall - 0.9608, AUC - 0.9221, F1 - 0.7809, precision - 0.6577
2023-03-25 20:42:13,038 : [INFO]  Batch 5 initialized 
2023-03-25 20:42:13,451 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:13,674 : [INFO]  ------------------------- Batch 5 training: round 1 -------------------------
2023-03-25 20:42:16,442 : [INFO]  ------------------------- Batch round 1, loss: 0.5633 -------------------------
2023-03-25 20:42:16,443 : [INFO]  ------------------------- Batch 5, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:16,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:16,495 : [INFO]  ------------------------- Batch 5 training: round 2 -------------------------
2023-03-25 20:42:17,586 : [INFO]  ------------------------- Batch round 2, loss: 0.5559 -------------------------
2023-03-25 20:42:17,586 : [INFO]  ------------------------- Batch 5, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:17,591 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:17,593 : [INFO]  ------------------------- Batch 5 training: round 3 -------------------------
2023-03-25 20:42:18,672 : [INFO]  ------------------------- Batch round 3, loss: 0.5601 -------------------------
2023-03-25 20:42:18,672 : [INFO]  ------------------------- Batch 5, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:18,764 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:18,766 : [INFO]  ------------------------- Batch 5 training: round 4 -------------------------
2023-03-25 20:42:20,048 : [INFO]  ------------------------- Batch round 4, loss: 0.5385 -------------------------
2023-03-25 20:42:20,048 : [INFO]  ------------------------- Batch 5, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:20,051 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:20,052 : [INFO]  ------------------------- Batch 5 training: round 5 -------------------------
2023-03-25 20:42:21,075 : [INFO]  ------------------------- Batch round 5, loss: 0.5422 -------------------------
2023-03-25 20:42:21,075 : [INFO]  ------------------------- Batch 5, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:21,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:21,103 : [INFO]  ------------------------- Batch 5 training: round 6 -------------------------
2023-03-25 20:42:22,177 : [INFO]  ------------------------- Batch round 6, loss: 0.5395 -------------------------
2023-03-25 20:42:22,178 : [INFO]  ------------------------- Batch 5, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:22,192 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:22,194 : [INFO]  Batch number 5 model fetched from the server
2023-03-25 20:42:22,194 : [INFO]  ################ Batch 5: final global model evalution after 6 rounds ################
2023-03-25 20:42:23,485 : [INFO]  Batch 5: Training set : loss - 0.5327, accuracy - 0.7772, recall - 0.9457, AUC - 0.9071, F1 - 0.8093, precision - 0.7073, training time - -9.0 seconds
2023-03-25 20:42:23,485 : [INFO]  Batch 5: Testing set : loss - 0.5387, accuracy - 0.75, recall - 0.8922, AUC - 0.9028, F1 - 0.7811, precision - 0.6947
2023-03-25 20:42:23,494 : [INFO]  Batch 6 initialized 
2023-03-25 20:42:23,921 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:24,152 : [INFO]  ------------------------- Batch 6 training: round 1 -------------------------
2023-03-25 20:42:26,949 : [INFO]  ------------------------- Batch round 1, loss: 0.5415 -------------------------
2023-03-25 20:42:26,949 : [INFO]  ------------------------- Batch 6, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:26,967 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:26,968 : [INFO]  ------------------------- Batch 6 training: round 2 -------------------------
2023-03-25 20:42:28,043 : [INFO]  ------------------------- Batch round 2, loss: 0.5379 -------------------------
2023-03-25 20:42:28,043 : [INFO]  ------------------------- Batch 6, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:28,046 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:28,049 : [INFO]  ------------------------- Batch 6 training: round 3 -------------------------
2023-03-25 20:42:29,136 : [INFO]  ------------------------- Batch round 3, loss: 0.5326 -------------------------
2023-03-25 20:42:29,136 : [INFO]  ------------------------- Batch 6, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:29,142 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:29,144 : [INFO]  ------------------------- Batch 6 training: round 4 -------------------------
2023-03-25 20:42:30,233 : [INFO]  ------------------------- Batch round 4, loss: 0.5304 -------------------------
2023-03-25 20:42:30,233 : [INFO]  ------------------------- Batch 6, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:30,236 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:30,237 : [INFO]  ------------------------- Batch 6 training: round 5 -------------------------
2023-03-25 20:42:31,298 : [INFO]  ------------------------- Batch round 5, loss: 0.5247 -------------------------
2023-03-25 20:42:31,298 : [INFO]  ------------------------- Batch 6, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:31,301 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:31,303 : [INFO]  ------------------------- Batch 6 training: round 6 -------------------------
2023-03-25 20:42:32,335 : [INFO]  ------------------------- Batch round 6, loss: 0.5261 -------------------------
2023-03-25 20:42:32,335 : [INFO]  ------------------------- Batch 6, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:32,363 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:32,365 : [INFO]  Batch number 6 model fetched from the server
2023-03-25 20:42:32,365 : [INFO]  ################ Batch 6: final global model evalution after 6 rounds ################
2023-03-25 20:42:33,647 : [INFO]  Batch 6: Training set : loss - 0.5137, accuracy - 0.8261, recall - 0.9457, AUC - 0.9133, F1 - 0.8447, precision - 0.7632, training time - -8.0 seconds
2023-03-25 20:42:33,647 : [INFO]  Batch 6: Testing set : loss - 0.5495, accuracy - 0.7451, recall - 0.8922, AUC - 0.8917, F1 - 0.7778, precision - 0.6894
2023-03-25 20:42:33,667 : [INFO]  Batch 7 initialized 
2023-03-25 20:42:34,089 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:34,324 : [INFO]  ------------------------- Batch 7 training: round 1 -------------------------
2023-03-25 20:42:37,432 : [INFO]  ------------------------- Batch round 1, loss: 0.5537 -------------------------
2023-03-25 20:42:37,432 : [INFO]  ------------------------- Batch 7, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:37,442 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:37,451 : [INFO]  ------------------------- Batch 7 training: round 2 -------------------------
2023-03-25 20:42:38,459 : [INFO]  ------------------------- Batch round 2, loss: 0.5437 -------------------------
2023-03-25 20:42:38,459 : [INFO]  ------------------------- Batch 7, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:38,521 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:38,523 : [INFO]  ------------------------- Batch 7 training: round 3 -------------------------
2023-03-25 20:42:39,620 : [INFO]  ------------------------- Batch round 3, loss: 0.538 -------------------------
2023-03-25 20:42:39,620 : [INFO]  ------------------------- Batch 7, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:39,645 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:39,647 : [INFO]  ------------------------- Batch 7 training: round 4 -------------------------
2023-03-25 20:42:40,713 : [INFO]  ------------------------- Batch round 4, loss: 0.5364 -------------------------
2023-03-25 20:42:40,713 : [INFO]  ------------------------- Batch 7, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:40,730 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:40,732 : [INFO]  ------------------------- Batch 7 training: round 5 -------------------------
2023-03-25 20:42:41,842 : [INFO]  ------------------------- Batch round 5, loss: 0.5329 -------------------------
2023-03-25 20:42:41,843 : [INFO]  ------------------------- Batch 7, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:41,886 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:41,887 : [INFO]  ------------------------- Batch 7 training: round 6 -------------------------
2023-03-25 20:42:42,954 : [INFO]  ------------------------- Batch round 6, loss: 0.5197 -------------------------
2023-03-25 20:42:42,954 : [INFO]  ------------------------- Batch 7, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:42,993 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:42,995 : [INFO]  Batch number 7 model fetched from the server
2023-03-25 20:42:42,995 : [INFO]  ################ Batch 7: final global model evalution after 6 rounds ################
2023-03-25 20:42:44,312 : [INFO]  Batch 7: Training set : loss - 0.5169, accuracy - 0.8043, recall - 0.9348, AUC - 0.9143, F1 - 0.8269, precision - 0.7414, training time - -9.0 seconds
2023-03-25 20:42:44,312 : [INFO]  Batch 7: Testing set : loss - 0.58, accuracy - 0.7206, recall - 0.9216, AUC - 0.8623, F1 - 0.7673, precision - 0.6573
2023-03-25 20:42:44,326 : [INFO]  Batch 8 initialized 
2023-03-25 20:42:44,746 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:44,977 : [INFO]  ------------------------- Batch 8 training: round 1 -------------------------
2023-03-25 20:42:47,754 : [INFO]  ------------------------- Batch round 1, loss: 0.5691 -------------------------
2023-03-25 20:42:47,754 : [INFO]  ------------------------- Batch 8, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:47,798 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:47,801 : [INFO]  ------------------------- Batch 8 training: round 2 -------------------------
2023-03-25 20:42:48,890 : [INFO]  ------------------------- Batch round 2, loss: 0.5672 -------------------------
2023-03-25 20:42:48,890 : [INFO]  ------------------------- Batch 8, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:48,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:48,913 : [INFO]  ------------------------- Batch 8 training: round 3 -------------------------
2023-03-25 20:42:50,006 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 20:42:50,006 : [INFO]  ------------------------- Batch 8, round 3: Sent local model to the server -------------------------
2023-03-25 20:42:50,009 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:50,012 : [INFO]  ------------------------- Batch 8 training: round 4 -------------------------
2023-03-25 20:42:51,124 : [INFO]  ------------------------- Batch round 4, loss: 0.5647 -------------------------
2023-03-25 20:42:51,124 : [INFO]  ------------------------- Batch 8, round 4: Sent local model to the server -------------------------
2023-03-25 20:42:51,131 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:51,133 : [INFO]  ------------------------- Batch 8 training: round 5 -------------------------
2023-03-25 20:42:52,211 : [INFO]  ------------------------- Batch round 5, loss: 0.5545 -------------------------
2023-03-25 20:42:52,211 : [INFO]  ------------------------- Batch 8, round 5: Sent local model to the server -------------------------
2023-03-25 20:42:52,228 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:52,229 : [INFO]  ------------------------- Batch 8 training: round 6 -------------------------
2023-03-25 20:42:53,568 : [INFO]  ------------------------- Batch round 6, loss: 0.5529 -------------------------
2023-03-25 20:42:53,568 : [INFO]  ------------------------- Batch 8, round 6: Sent local model to the server -------------------------
2023-03-25 20:42:53,570 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:53,572 : [INFO]  Batch number 8 model fetched from the server
2023-03-25 20:42:53,572 : [INFO]  ################ Batch 8: final global model evalution after 6 rounds ################
2023-03-25 20:42:54,809 : [INFO]  Batch 8: Training set : loss - 0.5477, accuracy - 0.788, recall - 0.9022, AUC - 0.8897, F1 - 0.8098, precision - 0.7345, training time - -9.0 seconds
2023-03-25 20:42:54,809 : [INFO]  Batch 8: Testing set : loss - 0.5832, accuracy - 0.6814, recall - 0.8725, AUC - 0.8514, F1 - 0.7325, precision - 0.6312
2023-03-25 20:42:54,821 : [INFO]  Batch 9 initialized 
2023-03-25 20:42:55,248 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:42:55,492 : [INFO]  ------------------------- Batch 9 training: round 1 -------------------------
2023-03-25 20:42:58,355 : [INFO]  ------------------------- Batch round 1, loss: 0.5986 -------------------------
2023-03-25 20:42:58,355 : [INFO]  ------------------------- Batch 9, round 1: Sent local model to the server -------------------------
2023-03-25 20:42:58,359 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:58,360 : [INFO]  ------------------------- Batch 9 training: round 2 -------------------------
2023-03-25 20:42:59,494 : [INFO]  ------------------------- Batch round 2, loss: 0.5978 -------------------------
2023-03-25 20:42:59,494 : [INFO]  ------------------------- Batch 9, round 2: Sent local model to the server -------------------------
2023-03-25 20:42:59,497 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:42:59,499 : [INFO]  ------------------------- Batch 9 training: round 3 -------------------------
2023-03-25 20:43:00,634 : [INFO]  ------------------------- Batch round 3, loss: 0.5887 -------------------------
2023-03-25 20:43:00,634 : [INFO]  ------------------------- Batch 9, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:00,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:00,639 : [INFO]  ------------------------- Batch 9 training: round 4 -------------------------
2023-03-25 20:43:01,807 : [INFO]  ------------------------- Batch round 4, loss: 0.571 -------------------------
2023-03-25 20:43:01,807 : [INFO]  ------------------------- Batch 9, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:01,810 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:01,812 : [INFO]  ------------------------- Batch 9 training: round 5 -------------------------
2023-03-25 20:43:02,948 : [INFO]  ------------------------- Batch round 5, loss: 0.5759 -------------------------
2023-03-25 20:43:02,948 : [INFO]  ------------------------- Batch 9, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:02,951 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:02,953 : [INFO]  ------------------------- Batch 9 training: round 6 -------------------------
2023-03-25 20:43:04,089 : [INFO]  ------------------------- Batch round 6, loss: 0.5667 -------------------------
2023-03-25 20:43:04,089 : [INFO]  ------------------------- Batch 9, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:04,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:04,094 : [INFO]  Batch number 9 model fetched from the server
2023-03-25 20:43:04,094 : [INFO]  ################ Batch 9: final global model evalution after 6 rounds ################
2023-03-25 20:43:05,403 : [INFO]  Batch 9: Training set : loss - 0.5703, accuracy - 0.7228, recall - 0.8696, AUC - 0.8482, F1 - 0.7583, precision - 0.6723, training time - -9.0 seconds
2023-03-25 20:43:05,404 : [INFO]  Batch 9: Testing set : loss - 0.6151, accuracy - 0.652, recall - 0.8137, AUC - 0.7807, F1 - 0.7004, precision - 0.6148
2023-03-25 20:43:05,410 : [INFO]  Batch 10 initialized 
2023-03-25 20:43:05,828 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:06,070 : [INFO]  ------------------------- Batch 10 training: round 1 -------------------------
2023-03-25 20:43:08,876 : [INFO]  ------------------------- Batch round 1, loss: 0.5578 -------------------------
2023-03-25 20:43:08,876 : [INFO]  ------------------------- Batch 10, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:08,879 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:08,880 : [INFO]  ------------------------- Batch 10 training: round 2 -------------------------
2023-03-25 20:43:09,969 : [INFO]  ------------------------- Batch round 2, loss: 0.5476 -------------------------
2023-03-25 20:43:09,969 : [INFO]  ------------------------- Batch 10, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:09,972 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:09,974 : [INFO]  ------------------------- Batch 10 training: round 3 -------------------------
2023-03-25 20:43:11,077 : [INFO]  ------------------------- Batch round 3, loss: 0.5455 -------------------------
2023-03-25 20:43:11,077 : [INFO]  ------------------------- Batch 10, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:11,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:11,082 : [INFO]  ------------------------- Batch 10 training: round 4 -------------------------
2023-03-25 20:43:12,179 : [INFO]  ------------------------- Batch round 4, loss: 0.5448 -------------------------
2023-03-25 20:43:12,179 : [INFO]  ------------------------- Batch 10, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:12,182 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:12,184 : [INFO]  ------------------------- Batch 10 training: round 5 -------------------------
2023-03-25 20:43:13,302 : [INFO]  ------------------------- Batch round 5, loss: 0.5326 -------------------------
2023-03-25 20:43:13,302 : [INFO]  ------------------------- Batch 10, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:13,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:13,318 : [INFO]  ------------------------- Batch 10 training: round 6 -------------------------
2023-03-25 20:43:14,461 : [INFO]  ------------------------- Batch round 6, loss: 0.5386 -------------------------
2023-03-25 20:43:14,461 : [INFO]  ------------------------- Batch 10, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:14,464 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:14,466 : [INFO]  Batch number 10 model fetched from the server
2023-03-25 20:43:14,466 : [INFO]  ################ Batch 10: final global model evalution after 6 rounds ################
2023-03-25 20:43:15,786 : [INFO]  Batch 10: Training set : loss - 0.5278, accuracy - 0.7935, recall - 0.9239, AUC - 0.8892, F1 - 0.8173, precision - 0.7328, training time - -8.0 seconds
2023-03-25 20:43:15,786 : [INFO]  Batch 10: Testing set : loss - 0.5652, accuracy - 0.7108, recall - 0.8725, AUC - 0.8611, F1 - 0.7511, precision - 0.6593
2023-03-25 20:43:15,792 : [INFO]  Batch 11 initialized 
2023-03-25 20:43:16,214 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:16,466 : [INFO]  ------------------------- Batch 11 training: round 1 -------------------------
2023-03-25 20:43:19,306 : [INFO]  ------------------------- Batch round 1, loss: 0.5637 -------------------------
2023-03-25 20:43:19,307 : [INFO]  ------------------------- Batch 11, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:19,310 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:19,311 : [INFO]  ------------------------- Batch 11 training: round 2 -------------------------
2023-03-25 20:43:20,367 : [INFO]  ------------------------- Batch round 2, loss: 0.5634 -------------------------
2023-03-25 20:43:20,367 : [INFO]  ------------------------- Batch 11, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:20,389 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:20,391 : [INFO]  ------------------------- Batch 11 training: round 3 -------------------------
2023-03-25 20:43:21,489 : [INFO]  ------------------------- Batch round 3, loss: 0.5709 -------------------------
2023-03-25 20:43:21,490 : [INFO]  ------------------------- Batch 11, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:21,504 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:21,506 : [INFO]  ------------------------- Batch 11 training: round 4 -------------------------
2023-03-25 20:43:22,626 : [INFO]  ------------------------- Batch round 4, loss: 0.5581 -------------------------
2023-03-25 20:43:22,626 : [INFO]  ------------------------- Batch 11, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:22,629 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:22,631 : [INFO]  ------------------------- Batch 11 training: round 5 -------------------------
2023-03-25 20:43:23,750 : [INFO]  ------------------------- Batch round 5, loss: 0.5538 -------------------------
2023-03-25 20:43:23,750 : [INFO]  ------------------------- Batch 11, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:23,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:23,789 : [INFO]  ------------------------- Batch 11 training: round 6 -------------------------
2023-03-25 20:43:24,879 : [INFO]  ------------------------- Batch round 6, loss: 0.5598 -------------------------
2023-03-25 20:43:24,879 : [INFO]  ------------------------- Batch 11, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:24,888 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:24,890 : [INFO]  Batch number 11 model fetched from the server
2023-03-25 20:43:24,890 : [INFO]  ################ Batch 11: final global model evalution after 6 rounds ################
2023-03-25 20:43:26,195 : [INFO]  Batch 11: Training set : loss - 0.552, accuracy - 0.75, recall - 0.8913, AUC - 0.8657, F1 - 0.781, precision - 0.6949, training time - -8.0 seconds
2023-03-25 20:43:26,195 : [INFO]  Batch 11: Testing set : loss - 0.5752, accuracy - 0.6912, recall - 0.9118, AUC - 0.8802, F1 - 0.747, precision - 0.6327
2023-03-25 20:43:26,205 : [INFO]  Batch 12 initialized 
2023-03-25 20:43:26,634 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:26,892 : [INFO]  ------------------------- Batch 12 training: round 1 -------------------------
2023-03-25 20:43:29,619 : [INFO]  ------------------------- Batch round 1, loss: 0.5652 -------------------------
2023-03-25 20:43:29,619 : [INFO]  ------------------------- Batch 12, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:29,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:29,718 : [INFO]  ------------------------- Batch 12 training: round 2 -------------------------
2023-03-25 20:43:30,773 : [INFO]  ------------------------- Batch round 2, loss: 0.5508 -------------------------
2023-03-25 20:43:30,773 : [INFO]  ------------------------- Batch 12, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:30,844 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:30,846 : [INFO]  ------------------------- Batch 12 training: round 3 -------------------------
2023-03-25 20:43:31,903 : [INFO]  ------------------------- Batch round 3, loss: 0.5518 -------------------------
2023-03-25 20:43:31,903 : [INFO]  ------------------------- Batch 12, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:32,000 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:32,002 : [INFO]  ------------------------- Batch 12 training: round 4 -------------------------
2023-03-25 20:43:33,075 : [INFO]  ------------------------- Batch round 4, loss: 0.544 -------------------------
2023-03-25 20:43:33,075 : [INFO]  ------------------------- Batch 12, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:33,157 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:33,159 : [INFO]  ------------------------- Batch 12 training: round 5 -------------------------
2023-03-25 20:43:34,224 : [INFO]  ------------------------- Batch round 5, loss: 0.5468 -------------------------
2023-03-25 20:43:34,224 : [INFO]  ------------------------- Batch 12, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:34,311 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:34,313 : [INFO]  ------------------------- Batch 12 training: round 6 -------------------------
2023-03-25 20:43:35,381 : [INFO]  ------------------------- Batch round 6, loss: 0.5466 -------------------------
2023-03-25 20:43:35,381 : [INFO]  ------------------------- Batch 12, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:35,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:35,450 : [INFO]  Batch number 12 model fetched from the server
2023-03-25 20:43:35,450 : [INFO]  ################ Batch 12: final global model evalution after 6 rounds ################
2023-03-25 20:43:36,710 : [INFO]  Batch 12: Training set : loss - 0.5402, accuracy - 0.7935, recall - 0.8913, AUC - 0.8982, F1 - 0.8119, precision - 0.7455, training time - -9.0 seconds
2023-03-25 20:43:36,710 : [INFO]  Batch 12: Testing set : loss - 0.5721, accuracy - 0.7353, recall - 0.8725, AUC - 0.8509, F1 - 0.7672, precision - 0.6846
2023-03-25 20:43:36,723 : [INFO]  Batch 13 initialized 
2023-03-25 20:43:37,166 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:37,410 : [INFO]  ------------------------- Batch 13 training: round 1 -------------------------
2023-03-25 20:43:40,231 : [INFO]  ------------------------- Batch round 1, loss: 0.565 -------------------------
2023-03-25 20:43:40,232 : [INFO]  ------------------------- Batch 13, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:40,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:40,286 : [INFO]  ------------------------- Batch 13 training: round 2 -------------------------
2023-03-25 20:43:41,356 : [INFO]  ------------------------- Batch round 2, loss: 0.5425 -------------------------
2023-03-25 20:43:41,356 : [INFO]  ------------------------- Batch 13, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:41,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:41,384 : [INFO]  ------------------------- Batch 13 training: round 3 -------------------------
2023-03-25 20:43:42,482 : [INFO]  ------------------------- Batch round 3, loss: 0.5376 -------------------------
2023-03-25 20:43:42,482 : [INFO]  ------------------------- Batch 13, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:42,485 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:42,487 : [INFO]  ------------------------- Batch 13 training: round 4 -------------------------
2023-03-25 20:43:43,559 : [INFO]  ------------------------- Batch round 4, loss: 0.5449 -------------------------
2023-03-25 20:43:43,559 : [INFO]  ------------------------- Batch 13, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:43,566 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:43,568 : [INFO]  ------------------------- Batch 13 training: round 5 -------------------------
2023-03-25 20:43:44,644 : [INFO]  ------------------------- Batch round 5, loss: 0.5318 -------------------------
2023-03-25 20:43:44,644 : [INFO]  ------------------------- Batch 13, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:44,663 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:44,665 : [INFO]  ------------------------- Batch 13 training: round 6 -------------------------
2023-03-25 20:43:45,743 : [INFO]  ------------------------- Batch round 6, loss: 0.5341 -------------------------
2023-03-25 20:43:45,743 : [INFO]  ------------------------- Batch 13, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:45,787 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:45,789 : [INFO]  Batch number 13 model fetched from the server
2023-03-25 20:43:45,789 : [INFO]  ################ Batch 13: final global model evalution after 6 rounds ################
2023-03-25 20:43:47,134 : [INFO]  Batch 13: Training set : loss - 0.5287, accuracy - 0.7826, recall - 0.9348, AUC - 0.9095, F1 - 0.8113, precision - 0.7167, training time - -8.0 seconds
2023-03-25 20:43:47,135 : [INFO]  Batch 13: Testing set : loss - 0.5593, accuracy - 0.7157, recall - 0.8725, AUC - 0.8753, F1 - 0.7542, precision - 0.6642
2023-03-25 20:43:47,146 : [INFO]  Batch 14 initialized 
2023-03-25 20:43:47,569 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:47,832 : [INFO]  ------------------------- Batch 14 training: round 1 -------------------------
2023-03-25 20:43:50,582 : [INFO]  ------------------------- Batch round 1, loss: 0.5417 -------------------------
2023-03-25 20:43:50,582 : [INFO]  ------------------------- Batch 14, round 1: Sent local model to the server -------------------------
2023-03-25 20:43:50,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:50,612 : [INFO]  ------------------------- Batch 14 training: round 2 -------------------------
2023-03-25 20:43:51,671 : [INFO]  ------------------------- Batch round 2, loss: 0.5514 -------------------------
2023-03-25 20:43:51,672 : [INFO]  ------------------------- Batch 14, round 2: Sent local model to the server -------------------------
2023-03-25 20:43:51,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:51,703 : [INFO]  ------------------------- Batch 14 training: round 3 -------------------------
2023-03-25 20:43:52,794 : [INFO]  ------------------------- Batch round 3, loss: 0.5408 -------------------------
2023-03-25 20:43:52,794 : [INFO]  ------------------------- Batch 14, round 3: Sent local model to the server -------------------------
2023-03-25 20:43:52,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:52,828 : [INFO]  ------------------------- Batch 14 training: round 4 -------------------------
2023-03-25 20:43:53,919 : [INFO]  ------------------------- Batch round 4, loss: 0.5373 -------------------------
2023-03-25 20:43:53,920 : [INFO]  ------------------------- Batch 14, round 4: Sent local model to the server -------------------------
2023-03-25 20:43:53,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:53,957 : [INFO]  ------------------------- Batch 14 training: round 5 -------------------------
2023-03-25 20:43:55,008 : [INFO]  ------------------------- Batch round 5, loss: 0.5395 -------------------------
2023-03-25 20:43:55,008 : [INFO]  ------------------------- Batch 14, round 5: Sent local model to the server -------------------------
2023-03-25 20:43:55,036 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:55,038 : [INFO]  ------------------------- Batch 14 training: round 6 -------------------------
2023-03-25 20:43:56,112 : [INFO]  ------------------------- Batch round 6, loss: 0.5354 -------------------------
2023-03-25 20:43:56,112 : [INFO]  ------------------------- Batch 14, round 6: Sent local model to the server -------------------------
2023-03-25 20:43:56,142 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:43:56,144 : [INFO]  Batch number 14 model fetched from the server
2023-03-25 20:43:56,144 : [INFO]  ################ Batch 14: final global model evalution after 6 rounds ################
2023-03-25 20:43:57,408 : [INFO]  Batch 14: Training set : loss - 0.5314, accuracy - 0.8043, recall - 0.9674, AUC - 0.9046, F1 - 0.8318, precision - 0.7295, training time - -8.0 seconds
2023-03-25 20:43:57,408 : [INFO]  Batch 14: Testing set : loss - 0.5545, accuracy - 0.7451, recall - 0.902, AUC - 0.8943, F1 - 0.7797, precision - 0.6866
2023-03-25 20:43:57,421 : [INFO]  Batch 15 initialized 
2023-03-25 20:43:57,853 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:43:58,119 : [INFO]  ------------------------- Batch 15 training: round 1 -------------------------
2023-03-25 20:44:00,966 : [INFO]  ------------------------- Batch round 1, loss: 0.5902 -------------------------
2023-03-25 20:44:00,967 : [INFO]  ------------------------- Batch 15, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:00,987 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:00,989 : [INFO]  ------------------------- Batch 15 training: round 2 -------------------------
2023-03-25 20:44:02,056 : [INFO]  ------------------------- Batch round 2, loss: 0.5831 -------------------------
2023-03-25 20:44:02,056 : [INFO]  ------------------------- Batch 15, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:02,116 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:02,118 : [INFO]  ------------------------- Batch 15 training: round 3 -------------------------
2023-03-25 20:44:03,207 : [INFO]  ------------------------- Batch round 3, loss: 0.5871 -------------------------
2023-03-25 20:44:03,207 : [INFO]  ------------------------- Batch 15, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:03,233 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:03,235 : [INFO]  ------------------------- Batch 15 training: round 4 -------------------------
2023-03-25 20:44:04,295 : [INFO]  ------------------------- Batch round 4, loss: 0.5805 -------------------------
2023-03-25 20:44:04,296 : [INFO]  ------------------------- Batch 15, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:04,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:04,356 : [INFO]  ------------------------- Batch 15 training: round 5 -------------------------
2023-03-25 20:44:05,437 : [INFO]  ------------------------- Batch round 5, loss: 0.583 -------------------------
2023-03-25 20:44:05,438 : [INFO]  ------------------------- Batch 15, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:05,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:05,481 : [INFO]  ------------------------- Batch 15 training: round 6 -------------------------
2023-03-25 20:44:06,572 : [INFO]  ------------------------- Batch round 6, loss: 0.5733 -------------------------
2023-03-25 20:44:06,572 : [INFO]  ------------------------- Batch 15, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:06,602 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:06,604 : [INFO]  Batch number 15 model fetched from the server
2023-03-25 20:44:06,604 : [INFO]  ################ Batch 15: final global model evalution after 6 rounds ################
2023-03-25 20:44:07,905 : [INFO]  Batch 15: Training set : loss - 0.572, accuracy - 0.7446, recall - 0.9457, AUC - 0.8594, F1 - 0.7873, precision - 0.6744, training time - -8.0 seconds
2023-03-25 20:44:07,905 : [INFO]  Batch 15: Testing set : loss - 0.5575, accuracy - 0.7108, recall - 0.9412, AUC - 0.8976, F1 - 0.7649, precision - 0.6443
2023-03-25 20:44:07,917 : [INFO]  Batch 16 initialized 
2023-03-25 20:44:08,352 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:08,610 : [INFO]  ------------------------- Batch 16 training: round 1 -------------------------
2023-03-25 20:44:11,395 : [INFO]  ------------------------- Batch round 1, loss: 0.5823 -------------------------
2023-03-25 20:44:11,395 : [INFO]  ------------------------- Batch 16, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:11,398 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:11,400 : [INFO]  ------------------------- Batch 16 training: round 2 -------------------------
2023-03-25 20:44:12,514 : [INFO]  ------------------------- Batch round 2, loss: 0.5779 -------------------------
2023-03-25 20:44:12,514 : [INFO]  ------------------------- Batch 16, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:12,517 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:12,519 : [INFO]  ------------------------- Batch 16 training: round 3 -------------------------
2023-03-25 20:44:13,607 : [INFO]  ------------------------- Batch round 3, loss: 0.5739 -------------------------
2023-03-25 20:44:13,607 : [INFO]  ------------------------- Batch 16, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:13,610 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:13,612 : [INFO]  ------------------------- Batch 16 training: round 4 -------------------------
2023-03-25 20:44:14,717 : [INFO]  ------------------------- Batch round 4, loss: 0.5637 -------------------------
2023-03-25 20:44:14,718 : [INFO]  ------------------------- Batch 16, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:14,721 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:14,722 : [INFO]  ------------------------- Batch 16 training: round 5 -------------------------
2023-03-25 20:44:15,791 : [INFO]  ------------------------- Batch round 5, loss: 0.5665 -------------------------
2023-03-25 20:44:15,791 : [INFO]  ------------------------- Batch 16, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:15,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:15,796 : [INFO]  ------------------------- Batch 16 training: round 6 -------------------------
2023-03-25 20:44:16,908 : [INFO]  ------------------------- Batch round 6, loss: 0.5602 -------------------------
2023-03-25 20:44:16,908 : [INFO]  ------------------------- Batch 16, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:16,911 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:16,913 : [INFO]  Batch number 16 model fetched from the server
2023-03-25 20:44:16,913 : [INFO]  ################ Batch 16: final global model evalution after 6 rounds ################
2023-03-25 20:44:18,206 : [INFO]  Batch 16: Training set : loss - 0.5608, accuracy - 0.7554, recall - 0.8804, AUC - 0.8444, F1 - 0.7826, precision - 0.7043, training time - -8.0 seconds
2023-03-25 20:44:18,206 : [INFO]  Batch 16: Testing set : loss - 0.5591, accuracy - 0.7255, recall - 0.8725, AUC - 0.881, F1 - 0.7607, precision - 0.6742
2023-03-25 20:44:18,214 : [INFO]  Batch 17 initialized 
2023-03-25 20:44:18,634 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:18,906 : [INFO]  ------------------------- Batch 17 training: round 1 -------------------------
2023-03-25 20:44:21,695 : [INFO]  ------------------------- Batch round 1, loss: 0.5627 -------------------------
2023-03-25 20:44:21,695 : [INFO]  ------------------------- Batch 17, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:21,698 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:21,700 : [INFO]  ------------------------- Batch 17 training: round 2 -------------------------
2023-03-25 20:44:22,742 : [INFO]  ------------------------- Batch round 2, loss: 0.5461 -------------------------
2023-03-25 20:44:22,743 : [INFO]  ------------------------- Batch 17, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:22,995 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:22,997 : [INFO]  ------------------------- Batch 17 training: round 3 -------------------------
2023-03-25 20:44:24,065 : [INFO]  ------------------------- Batch round 3, loss: 0.5371 -------------------------
2023-03-25 20:44:24,065 : [INFO]  ------------------------- Batch 17, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:24,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:24,070 : [INFO]  ------------------------- Batch 17 training: round 4 -------------------------
2023-03-25 20:44:25,166 : [INFO]  ------------------------- Batch round 4, loss: 0.535 -------------------------
2023-03-25 20:44:25,166 : [INFO]  ------------------------- Batch 17, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:25,169 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:25,171 : [INFO]  ------------------------- Batch 17 training: round 5 -------------------------
2023-03-25 20:44:26,244 : [INFO]  ------------------------- Batch round 5, loss: 0.5332 -------------------------
2023-03-25 20:44:26,245 : [INFO]  ------------------------- Batch 17, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:26,248 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:26,249 : [INFO]  ------------------------- Batch 17 training: round 6 -------------------------
2023-03-25 20:44:27,294 : [INFO]  ------------------------- Batch round 6, loss: 0.5333 -------------------------
2023-03-25 20:44:27,294 : [INFO]  ------------------------- Batch 17, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:27,297 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:27,299 : [INFO]  Batch number 17 model fetched from the server
2023-03-25 20:44:27,299 : [INFO]  ################ Batch 17: final global model evalution after 6 rounds ################
2023-03-25 20:44:28,579 : [INFO]  Batch 17: Training set : loss - 0.5179, accuracy - 0.8207, recall - 0.9457, AUC - 0.8998, F1 - 0.8406, precision - 0.7565, training time - -8.0 seconds
2023-03-25 20:44:28,579 : [INFO]  Batch 17: Testing set : loss - 0.5515, accuracy - 0.7108, recall - 0.9706, AUC - 0.9181, F1 - 0.7704, precision - 0.6387
2023-03-25 20:44:28,588 : [INFO]  Batch 18 initialized 
2023-03-25 20:44:29,004 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:29,274 : [INFO]  ------------------------- Batch 18 training: round 1 -------------------------
2023-03-25 20:44:32,341 : [INFO]  ------------------------- Batch round 1, loss: 0.6063 -------------------------
2023-03-25 20:44:32,341 : [INFO]  ------------------------- Batch 18, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:32,343 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:32,345 : [INFO]  ------------------------- Batch 18 training: round 2 -------------------------
2023-03-25 20:44:33,465 : [INFO]  ------------------------- Batch round 2, loss: 0.6009 -------------------------
2023-03-25 20:44:33,465 : [INFO]  ------------------------- Batch 18, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:33,468 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:33,469 : [INFO]  ------------------------- Batch 18 training: round 3 -------------------------
2023-03-25 20:44:34,627 : [INFO]  ------------------------- Batch round 3, loss: 0.597 -------------------------
2023-03-25 20:44:34,627 : [INFO]  ------------------------- Batch 18, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:34,630 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:34,631 : [INFO]  ------------------------- Batch 18 training: round 4 -------------------------
2023-03-25 20:44:35,760 : [INFO]  ------------------------- Batch round 4, loss: 0.6002 -------------------------
2023-03-25 20:44:35,760 : [INFO]  ------------------------- Batch 18, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:35,763 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:35,765 : [INFO]  ------------------------- Batch 18 training: round 5 -------------------------
2023-03-25 20:44:36,894 : [INFO]  ------------------------- Batch round 5, loss: 0.5801 -------------------------
2023-03-25 20:44:36,894 : [INFO]  ------------------------- Batch 18, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:36,897 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:36,899 : [INFO]  ------------------------- Batch 18 training: round 6 -------------------------
2023-03-25 20:44:38,032 : [INFO]  ------------------------- Batch round 6, loss: 0.5728 -------------------------
2023-03-25 20:44:38,032 : [INFO]  ------------------------- Batch 18, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:38,035 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:38,036 : [INFO]  Batch number 18 model fetched from the server
2023-03-25 20:44:38,037 : [INFO]  ################ Batch 18: final global model evalution after 6 rounds ################
2023-03-25 20:44:39,363 : [INFO]  Batch 18: Training set : loss - 0.585, accuracy - 0.6739, recall - 0.8804, AUC - 0.8438, F1 - 0.7297, precision - 0.6231, training time - -9.0 seconds
2023-03-25 20:44:39,363 : [INFO]  Batch 18: Testing set : loss - 0.6153, accuracy - 0.6569, recall - 0.8137, AUC - 0.7854, F1 - 0.7034, precision - 0.6194
2023-03-25 20:44:39,369 : [INFO]  Batch 19 initialized 
2023-03-25 20:44:39,789 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:40,054 : [INFO]  ------------------------- Batch 19 training: round 1 -------------------------
2023-03-25 20:44:42,899 : [INFO]  ------------------------- Batch round 1, loss: 0.5706 -------------------------
2023-03-25 20:44:42,899 : [INFO]  ------------------------- Batch 19, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:42,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:42,904 : [INFO]  ------------------------- Batch 19 training: round 2 -------------------------
2023-03-25 20:44:44,021 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 20:44:44,021 : [INFO]  ------------------------- Batch 19, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:44,024 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:44,026 : [INFO]  ------------------------- Batch 19 training: round 3 -------------------------
2023-03-25 20:44:45,105 : [INFO]  ------------------------- Batch round 3, loss: 0.5444 -------------------------
2023-03-25 20:44:45,105 : [INFO]  ------------------------- Batch 19, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:45,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:45,110 : [INFO]  ------------------------- Batch 19 training: round 4 -------------------------
2023-03-25 20:44:46,240 : [INFO]  ------------------------- Batch round 4, loss: 0.5628 -------------------------
2023-03-25 20:44:46,240 : [INFO]  ------------------------- Batch 19, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:46,243 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:46,245 : [INFO]  ------------------------- Batch 19 training: round 5 -------------------------
2023-03-25 20:44:47,381 : [INFO]  ------------------------- Batch round 5, loss: 0.5439 -------------------------
2023-03-25 20:44:47,381 : [INFO]  ------------------------- Batch 19, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:47,384 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:47,386 : [INFO]  ------------------------- Batch 19 training: round 6 -------------------------
2023-03-25 20:44:48,472 : [INFO]  ------------------------- Batch round 6, loss: 0.5478 -------------------------
2023-03-25 20:44:48,472 : [INFO]  ------------------------- Batch 19, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:48,475 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:48,477 : [INFO]  Batch number 19 model fetched from the server
2023-03-25 20:44:48,477 : [INFO]  ################ Batch 19: final global model evalution after 6 rounds ################
2023-03-25 20:44:49,801 : [INFO]  Batch 19: Training set : loss - 0.536, accuracy - 0.8207, recall - 0.9565, AUC - 0.8689, F1 - 0.8421, precision - 0.7521, training time - -8.0 seconds
2023-03-25 20:44:49,801 : [INFO]  Batch 19: Testing set : loss - 0.6011, accuracy - 0.6618, recall - 0.8922, AUC - 0.8213, F1 - 0.7251, precision - 0.6107
2023-03-25 20:44:49,811 : [INFO]  Batch 20 initialized 
2023-03-25 20:44:50,227 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:44:50,507 : [INFO]  ------------------------- Batch 20 training: round 1 -------------------------
2023-03-25 20:44:53,359 : [INFO]  ------------------------- Batch round 1, loss: 0.5948 -------------------------
2023-03-25 20:44:53,359 : [INFO]  ------------------------- Batch 20, round 1: Sent local model to the server -------------------------
2023-03-25 20:44:53,362 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:53,364 : [INFO]  ------------------------- Batch 20 training: round 2 -------------------------
2023-03-25 20:44:54,489 : [INFO]  ------------------------- Batch round 2, loss: 0.5974 -------------------------
2023-03-25 20:44:54,489 : [INFO]  ------------------------- Batch 20, round 2: Sent local model to the server -------------------------
2023-03-25 20:44:54,493 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:54,494 : [INFO]  ------------------------- Batch 20 training: round 3 -------------------------
2023-03-25 20:44:55,636 : [INFO]  ------------------------- Batch round 3, loss: 0.5762 -------------------------
2023-03-25 20:44:55,636 : [INFO]  ------------------------- Batch 20, round 3: Sent local model to the server -------------------------
2023-03-25 20:44:55,639 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:55,641 : [INFO]  ------------------------- Batch 20 training: round 4 -------------------------
2023-03-25 20:44:56,788 : [INFO]  ------------------------- Batch round 4, loss: 0.5741 -------------------------
2023-03-25 20:44:56,788 : [INFO]  ------------------------- Batch 20, round 4: Sent local model to the server -------------------------
2023-03-25 20:44:56,791 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:56,793 : [INFO]  ------------------------- Batch 20 training: round 5 -------------------------
2023-03-25 20:44:57,906 : [INFO]  ------------------------- Batch round 5, loss: 0.5765 -------------------------
2023-03-25 20:44:57,906 : [INFO]  ------------------------- Batch 20, round 5: Sent local model to the server -------------------------
2023-03-25 20:44:57,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:57,911 : [INFO]  ------------------------- Batch 20 training: round 6 -------------------------
2023-03-25 20:44:59,032 : [INFO]  ------------------------- Batch round 6, loss: 0.5604 -------------------------
2023-03-25 20:44:59,032 : [INFO]  ------------------------- Batch 20, round 6: Sent local model to the server -------------------------
2023-03-25 20:44:59,035 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:44:59,037 : [INFO]  Batch number 20 model fetched from the server
2023-03-25 20:44:59,038 : [INFO]  ################ Batch 20: final global model evalution after 6 rounds ################
2023-03-25 20:45:00,389 : [INFO]  Batch 20: Training set : loss - 0.5643, accuracy - 0.7337, recall - 0.8913, AUC - 0.8708, F1 - 0.77, precision - 0.6777, training time - -9.0 seconds
2023-03-25 20:45:00,389 : [INFO]  Batch 20: Testing set : loss - 0.57, accuracy - 0.7304, recall - 0.9314, AUC - 0.872, F1 - 0.7755, precision - 0.6643
2023-03-25 20:45:00,395 : [INFO]  Batch 21 initialized 
2023-03-25 20:45:00,813 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:01,095 : [INFO]  ------------------------- Batch 21 training: round 1 -------------------------
2023-03-25 20:45:03,897 : [INFO]  ------------------------- Batch round 1, loss: 0.6031 -------------------------
2023-03-25 20:45:03,897 : [INFO]  ------------------------- Batch 21, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:03,900 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:03,902 : [INFO]  ------------------------- Batch 21 training: round 2 -------------------------
2023-03-25 20:45:04,982 : [INFO]  ------------------------- Batch round 2, loss: 0.5981 -------------------------
2023-03-25 20:45:04,982 : [INFO]  ------------------------- Batch 21, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:04,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:04,987 : [INFO]  ------------------------- Batch 21 training: round 3 -------------------------
2023-03-25 20:45:06,101 : [INFO]  ------------------------- Batch round 3, loss: 0.5963 -------------------------
2023-03-25 20:45:06,101 : [INFO]  ------------------------- Batch 21, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:06,104 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:06,106 : [INFO]  ------------------------- Batch 21 training: round 4 -------------------------
2023-03-25 20:45:07,251 : [INFO]  ------------------------- Batch round 4, loss: 0.6057 -------------------------
2023-03-25 20:45:07,251 : [INFO]  ------------------------- Batch 21, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:07,254 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:07,256 : [INFO]  ------------------------- Batch 21 training: round 5 -------------------------
2023-03-25 20:45:08,357 : [INFO]  ------------------------- Batch round 5, loss: 0.5889 -------------------------
2023-03-25 20:45:08,357 : [INFO]  ------------------------- Batch 21, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:08,360 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:08,361 : [INFO]  ------------------------- Batch 21 training: round 6 -------------------------
2023-03-25 20:45:09,466 : [INFO]  ------------------------- Batch round 6, loss: 0.5939 -------------------------
2023-03-25 20:45:09,467 : [INFO]  ------------------------- Batch 21, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:09,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:09,472 : [INFO]  Batch number 21 model fetched from the server
2023-03-25 20:45:09,472 : [INFO]  ################ Batch 21: final global model evalution after 6 rounds ################
2023-03-25 20:45:10,798 : [INFO]  Batch 21: Training set : loss - 0.5903, accuracy - 0.7065, recall - 0.913, AUC - 0.846, F1 - 0.7568, precision - 0.6462, training time - -8.0 seconds
2023-03-25 20:45:10,798 : [INFO]  Batch 21: Testing set : loss - 0.5568, accuracy - 0.7108, recall - 0.9804, AUC - 0.9523, F1 - 0.7722, precision - 0.6369
2023-03-25 20:45:10,806 : [INFO]  Batch 22 initialized 
2023-03-25 20:45:11,221 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:11,504 : [INFO]  ------------------------- Batch 22 training: round 1 -------------------------
2023-03-25 20:45:14,378 : [INFO]  ------------------------- Batch round 1, loss: 0.6066 -------------------------
2023-03-25 20:45:14,378 : [INFO]  ------------------------- Batch 22, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:14,382 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:14,383 : [INFO]  ------------------------- Batch 22 training: round 2 -------------------------
2023-03-25 20:45:15,502 : [INFO]  ------------------------- Batch round 2, loss: 0.6159 -------------------------
2023-03-25 20:45:15,502 : [INFO]  ------------------------- Batch 22, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:15,535 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:15,537 : [INFO]  ------------------------- Batch 22 training: round 3 -------------------------
2023-03-25 20:45:16,676 : [INFO]  ------------------------- Batch round 3, loss: 0.5921 -------------------------
2023-03-25 20:45:16,676 : [INFO]  ------------------------- Batch 22, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:16,701 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:16,703 : [INFO]  ------------------------- Batch 22 training: round 4 -------------------------
2023-03-25 20:45:18,089 : [INFO]  ------------------------- Batch round 4, loss: 0.5754 -------------------------
2023-03-25 20:45:18,089 : [INFO]  ------------------------- Batch 22, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:18,092 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:18,094 : [INFO]  ------------------------- Batch 22 training: round 5 -------------------------
2023-03-25 20:45:19,170 : [INFO]  ------------------------- Batch round 5, loss: 0.5854 -------------------------
2023-03-25 20:45:19,170 : [INFO]  ------------------------- Batch 22, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:19,222 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:19,224 : [INFO]  ------------------------- Batch 22 training: round 6 -------------------------
2023-03-25 20:45:20,348 : [INFO]  ------------------------- Batch round 6, loss: 0.5916 -------------------------
2023-03-25 20:45:20,348 : [INFO]  ------------------------- Batch 22, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:20,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:20,412 : [INFO]  Batch number 22 model fetched from the server
2023-03-25 20:45:20,412 : [INFO]  ################ Batch 22: final global model evalution after 6 rounds ################
2023-03-25 20:45:21,726 : [INFO]  Batch 22: Training set : loss - 0.5839, accuracy - 0.663, recall - 0.8804, AUC - 0.8511, F1 - 0.7232, precision - 0.6136, training time - -9.0 seconds
2023-03-25 20:45:21,726 : [INFO]  Batch 22: Testing set : loss - 0.6081, accuracy - 0.6471, recall - 0.8431, AUC - 0.8105, F1 - 0.7049, precision - 0.6056
2023-03-25 20:45:21,738 : [INFO]  Batch 23 initialized 
2023-03-25 20:45:22,153 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:22,437 : [INFO]  ------------------------- Batch 23 training: round 1 -------------------------
2023-03-25 20:45:25,269 : [INFO]  ------------------------- Batch round 1, loss: 0.6097 -------------------------
2023-03-25 20:45:25,269 : [INFO]  ------------------------- Batch 23, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:25,354 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:25,356 : [INFO]  ------------------------- Batch 23 training: round 2 -------------------------
2023-03-25 20:45:26,454 : [INFO]  ------------------------- Batch round 2, loss: 0.5909 -------------------------
2023-03-25 20:45:26,454 : [INFO]  ------------------------- Batch 23, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:26,506 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:26,509 : [INFO]  ------------------------- Batch 23 training: round 3 -------------------------
2023-03-25 20:45:27,664 : [INFO]  ------------------------- Batch round 3, loss: 0.5971 -------------------------
2023-03-25 20:45:27,664 : [INFO]  ------------------------- Batch 23, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:27,707 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:27,709 : [INFO]  ------------------------- Batch 23 training: round 4 -------------------------
2023-03-25 20:45:28,814 : [INFO]  ------------------------- Batch round 4, loss: 0.5857 -------------------------
2023-03-25 20:45:28,814 : [INFO]  ------------------------- Batch 23, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:28,870 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:28,872 : [INFO]  ------------------------- Batch 23 training: round 5 -------------------------
2023-03-25 20:45:29,997 : [INFO]  ------------------------- Batch round 5, loss: 0.5767 -------------------------
2023-03-25 20:45:29,997 : [INFO]  ------------------------- Batch 23, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:30,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:30,068 : [INFO]  ------------------------- Batch 23 training: round 6 -------------------------
2023-03-25 20:45:31,155 : [INFO]  ------------------------- Batch round 6, loss: 0.5723 -------------------------
2023-03-25 20:45:31,155 : [INFO]  ------------------------- Batch 23, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:31,201 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:31,203 : [INFO]  Batch number 23 model fetched from the server
2023-03-25 20:45:31,203 : [INFO]  ################ Batch 23: final global model evalution after 6 rounds ################
2023-03-25 20:45:32,513 : [INFO]  Batch 23: Training set : loss - 0.5701, accuracy - 0.7228, recall - 0.8696, AUC - 0.826, F1 - 0.7583, precision - 0.6723, training time - -9.0 seconds
2023-03-25 20:45:32,513 : [INFO]  Batch 23: Testing set : loss - 0.602, accuracy - 0.6569, recall - 0.8235, AUC - 0.7904, F1 - 0.7059, precision - 0.6176
2023-03-25 20:45:32,523 : [INFO]  Batch 24 initialized 
2023-03-25 20:45:32,939 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:33,218 : [INFO]  ------------------------- Batch 24 training: round 1 -------------------------
2023-03-25 20:45:36,067 : [INFO]  ------------------------- Batch round 1, loss: 0.5944 -------------------------
2023-03-25 20:45:36,067 : [INFO]  ------------------------- Batch 24, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:36,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:36,176 : [INFO]  ------------------------- Batch 24 training: round 2 -------------------------
2023-03-25 20:45:37,263 : [INFO]  ------------------------- Batch round 2, loss: 0.5842 -------------------------
2023-03-25 20:45:37,263 : [INFO]  ------------------------- Batch 24, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:37,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:37,286 : [INFO]  ------------------------- Batch 24 training: round 3 -------------------------
2023-03-25 20:45:38,406 : [INFO]  ------------------------- Batch round 3, loss: 0.5743 -------------------------
2023-03-25 20:45:38,406 : [INFO]  ------------------------- Batch 24, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:38,434 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:38,437 : [INFO]  ------------------------- Batch 24 training: round 4 -------------------------
2023-03-25 20:45:39,531 : [INFO]  ------------------------- Batch round 4, loss: 0.5817 -------------------------
2023-03-25 20:45:39,531 : [INFO]  ------------------------- Batch 24, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:39,567 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:39,569 : [INFO]  ------------------------- Batch 24 training: round 5 -------------------------
2023-03-25 20:45:40,676 : [INFO]  ------------------------- Batch round 5, loss: 0.5806 -------------------------
2023-03-25 20:45:40,676 : [INFO]  ------------------------- Batch 24, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:40,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:40,719 : [INFO]  ------------------------- Batch 24 training: round 6 -------------------------
2023-03-25 20:45:41,842 : [INFO]  ------------------------- Batch round 6, loss: 0.5719 -------------------------
2023-03-25 20:45:41,842 : [INFO]  ------------------------- Batch 24, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:41,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:41,869 : [INFO]  Batch number 24 model fetched from the server
2023-03-25 20:45:41,869 : [INFO]  ################ Batch 24: final global model evalution after 6 rounds ################
2023-03-25 20:45:43,205 : [INFO]  Batch 24: Training set : loss - 0.5739, accuracy - 0.7283, recall - 0.8261, AUC - 0.8076, F1 - 0.7525, precision - 0.6909, training time - -9.0 seconds
2023-03-25 20:45:43,205 : [INFO]  Batch 24: Testing set : loss - 0.5916, accuracy - 0.6765, recall - 0.8333, AUC - 0.8131, F1 - 0.7203, precision - 0.6343
2023-03-25 20:45:43,217 : [INFO]  Batch 25 initialized 
2023-03-25 20:45:43,636 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:43,934 : [INFO]  ------------------------- Batch 25 training: round 1 -------------------------
2023-03-25 20:45:46,752 : [INFO]  ------------------------- Batch round 1, loss: 0.6478 -------------------------
2023-03-25 20:45:46,752 : [INFO]  ------------------------- Batch 25, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:46,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:46,771 : [INFO]  ------------------------- Batch 25 training: round 2 -------------------------
2023-03-25 20:45:47,812 : [INFO]  ------------------------- Batch round 2, loss: 0.6108 -------------------------
2023-03-25 20:45:47,812 : [INFO]  ------------------------- Batch 25, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:48,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:48,169 : [INFO]  ------------------------- Batch 25 training: round 3 -------------------------
2023-03-25 20:45:49,199 : [INFO]  ------------------------- Batch round 3, loss: 0.6 -------------------------
2023-03-25 20:45:49,199 : [INFO]  ------------------------- Batch 25, round 3: Sent local model to the server -------------------------
2023-03-25 20:45:49,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:49,321 : [INFO]  ------------------------- Batch 25 training: round 4 -------------------------
2023-03-25 20:45:50,436 : [INFO]  ------------------------- Batch round 4, loss: 0.6028 -------------------------
2023-03-25 20:45:50,436 : [INFO]  ------------------------- Batch 25, round 4: Sent local model to the server -------------------------
2023-03-25 20:45:50,524 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:50,526 : [INFO]  ------------------------- Batch 25 training: round 5 -------------------------
2023-03-25 20:45:51,625 : [INFO]  ------------------------- Batch round 5, loss: 0.5894 -------------------------
2023-03-25 20:45:51,626 : [INFO]  ------------------------- Batch 25, round 5: Sent local model to the server -------------------------
2023-03-25 20:45:51,676 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:51,677 : [INFO]  ------------------------- Batch 25 training: round 6 -------------------------
2023-03-25 20:45:52,772 : [INFO]  ------------------------- Batch round 6, loss: 0.5846 -------------------------
2023-03-25 20:45:52,772 : [INFO]  ------------------------- Batch 25, round 6: Sent local model to the server -------------------------
2023-03-25 20:45:52,847 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:52,849 : [INFO]  Batch number 25 model fetched from the server
2023-03-25 20:45:52,849 : [INFO]  ################ Batch 25: final global model evalution after 6 rounds ################
2023-03-25 20:45:54,182 : [INFO]  Batch 25: Training set : loss - 0.5883, accuracy - 0.6902, recall - 0.8587, AUC - 0.805, F1 - 0.7349, precision - 0.6423, training time - -9.0 seconds
2023-03-25 20:45:54,182 : [INFO]  Batch 25: Testing set : loss - 0.6125, accuracy - 0.6373, recall - 0.8431, AUC - 0.7869, F1 - 0.6992, precision - 0.5972
2023-03-25 20:45:54,221 : [INFO]  Batch 26 initialized 
2023-03-25 20:45:54,633 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:45:54,930 : [INFO]  ------------------------- Batch 26 training: round 1 -------------------------
2023-03-25 20:45:57,734 : [INFO]  ------------------------- Batch round 1, loss: 0.5815 -------------------------
2023-03-25 20:45:57,734 : [INFO]  ------------------------- Batch 26, round 1: Sent local model to the server -------------------------
2023-03-25 20:45:57,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:57,755 : [INFO]  ------------------------- Batch 26 training: round 2 -------------------------
2023-03-25 20:45:58,830 : [INFO]  ------------------------- Batch round 2, loss: 0.5778 -------------------------
2023-03-25 20:45:58,830 : [INFO]  ------------------------- Batch 26, round 2: Sent local model to the server -------------------------
2023-03-25 20:45:58,910 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:45:58,911 : [INFO]  ------------------------- Batch 26 training: round 3 -------------------------
2023-03-25 20:45:59,972 : [INFO]  ------------------------- Batch round 3, loss: 0.568 -------------------------
2023-03-25 20:45:59,972 : [INFO]  ------------------------- Batch 26, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:00,048 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:00,050 : [INFO]  ------------------------- Batch 26 training: round 4 -------------------------
2023-03-25 20:46:01,107 : [INFO]  ------------------------- Batch round 4, loss: 0.5675 -------------------------
2023-03-25 20:46:01,107 : [INFO]  ------------------------- Batch 26, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:01,177 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:01,180 : [INFO]  ------------------------- Batch 26 training: round 5 -------------------------
2023-03-25 20:46:02,261 : [INFO]  ------------------------- Batch round 5, loss: 0.5583 -------------------------
2023-03-25 20:46:02,261 : [INFO]  ------------------------- Batch 26, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:02,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:02,318 : [INFO]  ------------------------- Batch 26 training: round 6 -------------------------
2023-03-25 20:46:03,370 : [INFO]  ------------------------- Batch round 6, loss: 0.5575 -------------------------
2023-03-25 20:46:03,370 : [INFO]  ------------------------- Batch 26, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:03,440 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:03,442 : [INFO]  Batch number 26 model fetched from the server
2023-03-25 20:46:03,442 : [INFO]  ################ Batch 26: final global model evalution after 6 rounds ################
2023-03-25 20:46:04,727 : [INFO]  Batch 26: Training set : loss - 0.5574, accuracy - 0.7663, recall - 0.9022, AUC - 0.8608, F1 - 0.7943, precision - 0.7094, training time - -9.0 seconds
2023-03-25 20:46:04,727 : [INFO]  Batch 26: Testing set : loss - 0.5478, accuracy - 0.7647, recall - 0.9412, AUC - 0.9183, F1 - 0.8, precision - 0.6957
2023-03-25 20:46:04,738 : [INFO]  Batch 27 initialized 
2023-03-25 20:46:05,165 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:05,460 : [INFO]  ------------------------- Batch 27 training: round 1 -------------------------
2023-03-25 20:46:08,270 : [INFO]  ------------------------- Batch round 1, loss: 0.5785 -------------------------
2023-03-25 20:46:08,270 : [INFO]  ------------------------- Batch 27, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:08,292 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:08,294 : [INFO]  ------------------------- Batch 27 training: round 2 -------------------------
2023-03-25 20:46:09,400 : [INFO]  ------------------------- Batch round 2, loss: 0.5794 -------------------------
2023-03-25 20:46:09,400 : [INFO]  ------------------------- Batch 27, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:09,410 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:09,412 : [INFO]  ------------------------- Batch 27 training: round 3 -------------------------
2023-03-25 20:46:10,502 : [INFO]  ------------------------- Batch round 3, loss: 0.5705 -------------------------
2023-03-25 20:46:10,503 : [INFO]  ------------------------- Batch 27, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:10,510 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:10,512 : [INFO]  ------------------------- Batch 27 training: round 4 -------------------------
2023-03-25 20:46:11,590 : [INFO]  ------------------------- Batch round 4, loss: 0.5677 -------------------------
2023-03-25 20:46:11,590 : [INFO]  ------------------------- Batch 27, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:11,607 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:11,609 : [INFO]  ------------------------- Batch 27 training: round 5 -------------------------
2023-03-25 20:46:12,707 : [INFO]  ------------------------- Batch round 5, loss: 0.5628 -------------------------
2023-03-25 20:46:12,707 : [INFO]  ------------------------- Batch 27, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:12,710 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:12,712 : [INFO]  ------------------------- Batch 27 training: round 6 -------------------------
2023-03-25 20:46:13,804 : [INFO]  ------------------------- Batch round 6, loss: 0.5472 -------------------------
2023-03-25 20:46:13,804 : [INFO]  ------------------------- Batch 27, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:13,820 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:13,821 : [INFO]  Batch number 27 model fetched from the server
2023-03-25 20:46:13,821 : [INFO]  ################ Batch 27: final global model evalution after 6 rounds ################
2023-03-25 20:46:15,157 : [INFO]  Batch 27: Training set : loss - 0.5552, accuracy - 0.7663, recall - 0.9565, AUC - 0.873, F1 - 0.8037, precision - 0.6929, training time - -8.0 seconds
2023-03-25 20:46:15,157 : [INFO]  Batch 27: Testing set : loss - 0.6003, accuracy - 0.6667, recall - 0.8137, AUC - 0.8005, F1 - 0.7094, precision - 0.6288
2023-03-25 20:46:15,163 : [INFO]  Batch 28 initialized 
2023-03-25 20:46:15,587 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:15,893 : [INFO]  ------------------------- Batch 28 training: round 1 -------------------------
2023-03-25 20:46:18,753 : [INFO]  ------------------------- Batch round 1, loss: 0.608 -------------------------
2023-03-25 20:46:18,753 : [INFO]  ------------------------- Batch 28, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:18,756 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:18,758 : [INFO]  ------------------------- Batch 28 training: round 2 -------------------------
2023-03-25 20:46:19,886 : [INFO]  ------------------------- Batch round 2, loss: 0.5889 -------------------------
2023-03-25 20:46:19,886 : [INFO]  ------------------------- Batch 28, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:19,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:19,893 : [INFO]  ------------------------- Batch 28 training: round 3 -------------------------
2023-03-25 20:46:21,013 : [INFO]  ------------------------- Batch round 3, loss: 0.5758 -------------------------
2023-03-25 20:46:21,013 : [INFO]  ------------------------- Batch 28, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:21,016 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:21,018 : [INFO]  ------------------------- Batch 28 training: round 4 -------------------------
2023-03-25 20:46:22,140 : [INFO]  ------------------------- Batch round 4, loss: 0.5779 -------------------------
2023-03-25 20:46:22,141 : [INFO]  ------------------------- Batch 28, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:22,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:22,146 : [INFO]  ------------------------- Batch 28 training: round 5 -------------------------
2023-03-25 20:46:23,280 : [INFO]  ------------------------- Batch round 5, loss: 0.5792 -------------------------
2023-03-25 20:46:23,280 : [INFO]  ------------------------- Batch 28, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:23,283 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:23,285 : [INFO]  ------------------------- Batch 28 training: round 6 -------------------------
2023-03-25 20:46:24,419 : [INFO]  ------------------------- Batch round 6, loss: 0.5711 -------------------------
2023-03-25 20:46:24,419 : [INFO]  ------------------------- Batch 28, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:24,422 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:24,424 : [INFO]  Batch number 28 model fetched from the server
2023-03-25 20:46:24,424 : [INFO]  ################ Batch 28: final global model evalution after 6 rounds ################
2023-03-25 20:46:25,750 : [INFO]  Batch 28: Training set : loss - 0.5635, accuracy - 0.7391, recall - 0.8478, AUC - 0.8406, F1 - 0.7647, precision - 0.6964, training time - -9.0 seconds
2023-03-25 20:46:25,750 : [INFO]  Batch 28: Testing set : loss - 0.6006, accuracy - 0.6667, recall - 0.8627, AUC - 0.8308, F1 - 0.7213, precision - 0.6197
2023-03-25 20:46:25,761 : [INFO]  Batch 29 initialized 
2023-03-25 20:46:26,176 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:26,482 : [INFO]  ------------------------- Batch 29 training: round 1 -------------------------
2023-03-25 20:46:29,371 : [INFO]  ------------------------- Batch round 1, loss: 0.5892 -------------------------
2023-03-25 20:46:29,371 : [INFO]  ------------------------- Batch 29, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:29,374 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:29,375 : [INFO]  ------------------------- Batch 29 training: round 2 -------------------------
2023-03-25 20:46:30,528 : [INFO]  ------------------------- Batch round 2, loss: 0.5759 -------------------------
2023-03-25 20:46:30,528 : [INFO]  ------------------------- Batch 29, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:30,531 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:30,533 : [INFO]  ------------------------- Batch 29 training: round 3 -------------------------
2023-03-25 20:46:31,683 : [INFO]  ------------------------- Batch round 3, loss: 0.562 -------------------------
2023-03-25 20:46:31,683 : [INFO]  ------------------------- Batch 29, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:31,686 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:31,688 : [INFO]  ------------------------- Batch 29 training: round 4 -------------------------
2023-03-25 20:46:32,800 : [INFO]  ------------------------- Batch round 4, loss: 0.5587 -------------------------
2023-03-25 20:46:32,800 : [INFO]  ------------------------- Batch 29, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:32,803 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:32,805 : [INFO]  ------------------------- Batch 29 training: round 5 -------------------------
2023-03-25 20:46:33,961 : [INFO]  ------------------------- Batch round 5, loss: 0.5583 -------------------------
2023-03-25 20:46:33,961 : [INFO]  ------------------------- Batch 29, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:33,964 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:33,965 : [INFO]  ------------------------- Batch 29 training: round 6 -------------------------
2023-03-25 20:46:35,105 : [INFO]  ------------------------- Batch round 6, loss: 0.5582 -------------------------
2023-03-25 20:46:35,105 : [INFO]  ------------------------- Batch 29, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:35,108 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:35,109 : [INFO]  Batch number 29 model fetched from the server
2023-03-25 20:46:35,109 : [INFO]  ################ Batch 29: final global model evalution after 6 rounds ################
2023-03-25 20:46:36,416 : [INFO]  Batch 29: Training set : loss - 0.5508, accuracy - 0.7337, recall - 0.8804, AUC - 0.8806, F1 - 0.7678, precision - 0.6807, training time - -9.0 seconds
2023-03-25 20:46:36,416 : [INFO]  Batch 29: Testing set : loss - 0.5773, accuracy - 0.7108, recall - 0.8725, AUC - 0.8553, F1 - 0.7511, precision - 0.6593
2023-03-25 20:46:36,425 : [INFO]  Batch 30 initialized 
2023-03-25 20:46:36,861 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:37,156 : [INFO]  ------------------------- Batch 30 training: round 1 -------------------------
2023-03-25 20:46:39,936 : [INFO]  ------------------------- Batch round 1, loss: 0.5968 -------------------------
2023-03-25 20:46:39,937 : [INFO]  ------------------------- Batch 30, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:39,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:39,941 : [INFO]  ------------------------- Batch 30 training: round 2 -------------------------
2023-03-25 20:46:41,034 : [INFO]  ------------------------- Batch round 2, loss: 0.5988 -------------------------
2023-03-25 20:46:41,035 : [INFO]  ------------------------- Batch 30, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:41,038 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:41,039 : [INFO]  ------------------------- Batch 30 training: round 3 -------------------------
2023-03-25 20:46:42,139 : [INFO]  ------------------------- Batch round 3, loss: 0.5886 -------------------------
2023-03-25 20:46:42,139 : [INFO]  ------------------------- Batch 30, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:42,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:42,146 : [INFO]  ------------------------- Batch 30 training: round 4 -------------------------
2023-03-25 20:46:43,263 : [INFO]  ------------------------- Batch round 4, loss: 0.5774 -------------------------
2023-03-25 20:46:43,263 : [INFO]  ------------------------- Batch 30, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:43,266 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:43,267 : [INFO]  ------------------------- Batch 30 training: round 5 -------------------------
2023-03-25 20:46:44,362 : [INFO]  ------------------------- Batch round 5, loss: 0.5884 -------------------------
2023-03-25 20:46:44,362 : [INFO]  ------------------------- Batch 30, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:44,365 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:44,367 : [INFO]  ------------------------- Batch 30 training: round 6 -------------------------
2023-03-25 20:46:45,451 : [INFO]  ------------------------- Batch round 6, loss: 0.5826 -------------------------
2023-03-25 20:46:45,451 : [INFO]  ------------------------- Batch 30, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:45,483 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:45,485 : [INFO]  Batch number 30 model fetched from the server
2023-03-25 20:46:45,485 : [INFO]  ################ Batch 30: final global model evalution after 6 rounds ################
2023-03-25 20:46:46,773 : [INFO]  Batch 30: Training set : loss - 0.5789, accuracy - 0.7446, recall - 0.837, AUC - 0.7961, F1 - 0.7662, precision - 0.7064, training time - -8.0 seconds
2023-03-25 20:46:46,774 : [INFO]  Batch 30: Testing set : loss - 0.592, accuracy - 0.6814, recall - 0.8235, AUC - 0.8139, F1 - 0.721, precision - 0.6412
2023-03-25 20:46:46,785 : [INFO]  Batch 31 initialized 
2023-03-25 20:46:47,208 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:47,522 : [INFO]  ------------------------- Batch 31 training: round 1 -------------------------
2023-03-25 20:46:50,307 : [INFO]  ------------------------- Batch round 1, loss: 0.5618 -------------------------
2023-03-25 20:46:50,307 : [INFO]  ------------------------- Batch 31, round 1: Sent local model to the server -------------------------
2023-03-25 20:46:50,341 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:50,343 : [INFO]  ------------------------- Batch 31 training: round 2 -------------------------
2023-03-25 20:46:51,429 : [INFO]  ------------------------- Batch round 2, loss: 0.5537 -------------------------
2023-03-25 20:46:51,429 : [INFO]  ------------------------- Batch 31, round 2: Sent local model to the server -------------------------
2023-03-25 20:46:51,479 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:51,481 : [INFO]  ------------------------- Batch 31 training: round 3 -------------------------
2023-03-25 20:46:52,566 : [INFO]  ------------------------- Batch round 3, loss: 0.55 -------------------------
2023-03-25 20:46:52,566 : [INFO]  ------------------------- Batch 31, round 3: Sent local model to the server -------------------------
2023-03-25 20:46:52,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:52,626 : [INFO]  ------------------------- Batch 31 training: round 4 -------------------------
2023-03-25 20:46:53,740 : [INFO]  ------------------------- Batch round 4, loss: 0.5534 -------------------------
2023-03-25 20:46:53,740 : [INFO]  ------------------------- Batch 31, round 4: Sent local model to the server -------------------------
2023-03-25 20:46:53,771 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:53,774 : [INFO]  ------------------------- Batch 31 training: round 5 -------------------------
2023-03-25 20:46:54,867 : [INFO]  ------------------------- Batch round 5, loss: 0.5534 -------------------------
2023-03-25 20:46:54,867 : [INFO]  ------------------------- Batch 31, round 5: Sent local model to the server -------------------------
2023-03-25 20:46:54,921 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:54,923 : [INFO]  ------------------------- Batch 31 training: round 6 -------------------------
2023-03-25 20:46:55,988 : [INFO]  ------------------------- Batch round 6, loss: 0.5427 -------------------------
2023-03-25 20:46:55,988 : [INFO]  ------------------------- Batch 31, round 6: Sent local model to the server -------------------------
2023-03-25 20:46:56,062 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:46:56,064 : [INFO]  Batch number 31 model fetched from the server
2023-03-25 20:46:56,064 : [INFO]  ################ Batch 31: final global model evalution after 6 rounds ################
2023-03-25 20:46:57,366 : [INFO]  Batch 31: Training set : loss - 0.5314, accuracy - 0.8043, recall - 0.9239, AUC - 0.9069, F1 - 0.8252, precision - 0.7456, training time - -9.0 seconds
2023-03-25 20:46:57,366 : [INFO]  Batch 31: Testing set : loss - 0.5661, accuracy - 0.75, recall - 0.8725, AUC - 0.852, F1 - 0.7773, precision - 0.7008
2023-03-25 20:46:57,378 : [INFO]  Batch 32 initialized 
2023-03-25 20:46:57,801 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:46:58,119 : [INFO]  ------------------------- Batch 32 training: round 1 -------------------------
2023-03-25 20:47:00,858 : [INFO]  ------------------------- Batch round 1, loss: 0.5775 -------------------------
2023-03-25 20:47:00,858 : [INFO]  ------------------------- Batch 32, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:01,008 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:01,010 : [INFO]  ------------------------- Batch 32 training: round 2 -------------------------
2023-03-25 20:47:02,025 : [INFO]  ------------------------- Batch round 2, loss: 0.5678 -------------------------
2023-03-25 20:47:02,025 : [INFO]  ------------------------- Batch 32, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:02,136 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:02,138 : [INFO]  ------------------------- Batch 32 training: round 3 -------------------------
2023-03-25 20:47:03,169 : [INFO]  ------------------------- Batch round 3, loss: 0.567 -------------------------
2023-03-25 20:47:03,169 : [INFO]  ------------------------- Batch 32, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:03,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:03,290 : [INFO]  ------------------------- Batch 32 training: round 4 -------------------------
2023-03-25 20:47:04,339 : [INFO]  ------------------------- Batch round 4, loss: 0.5688 -------------------------
2023-03-25 20:47:04,340 : [INFO]  ------------------------- Batch 32, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:04,438 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:04,440 : [INFO]  ------------------------- Batch 32 training: round 5 -------------------------
2023-03-25 20:47:05,464 : [INFO]  ------------------------- Batch round 5, loss: 0.5532 -------------------------
2023-03-25 20:47:05,464 : [INFO]  ------------------------- Batch 32, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:05,552 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:05,555 : [INFO]  ------------------------- Batch 32 training: round 6 -------------------------
2023-03-25 20:47:06,598 : [INFO]  ------------------------- Batch round 6, loss: 0.5475 -------------------------
2023-03-25 20:47:06,598 : [INFO]  ------------------------- Batch 32, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:06,702 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:06,704 : [INFO]  Batch number 32 model fetched from the server
2023-03-25 20:47:06,704 : [INFO]  ################ Batch 32: final global model evalution after 6 rounds ################
2023-03-25 20:47:07,959 : [INFO]  Batch 32: Training set : loss - 0.5451, accuracy - 0.7989, recall - 0.9348, AUC - 0.8756, F1 - 0.823, precision - 0.735, training time - -9.0 seconds
2023-03-25 20:47:07,959 : [INFO]  Batch 32: Testing set : loss - 0.5596, accuracy - 0.7206, recall - 0.9314, AUC - 0.905, F1 - 0.7692, precision - 0.6552
2023-03-25 20:47:07,969 : [INFO]  Batch 33 initialized 
2023-03-25 20:47:08,384 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:08,685 : [INFO]  ------------------------- Batch 33 training: round 1 -------------------------
2023-03-25 20:47:11,523 : [INFO]  ------------------------- Batch round 1, loss: 0.5716 -------------------------
2023-03-25 20:47:11,524 : [INFO]  ------------------------- Batch 33, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:11,674 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:11,676 : [INFO]  ------------------------- Batch 33 training: round 2 -------------------------
2023-03-25 20:47:12,725 : [INFO]  ------------------------- Batch round 2, loss: 0.5693 -------------------------
2023-03-25 20:47:12,725 : [INFO]  ------------------------- Batch 33, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:12,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:12,754 : [INFO]  ------------------------- Batch 33 training: round 3 -------------------------
2023-03-25 20:47:13,794 : [INFO]  ------------------------- Batch round 3, loss: 0.5727 -------------------------
2023-03-25 20:47:13,794 : [INFO]  ------------------------- Batch 33, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:13,876 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:13,879 : [INFO]  ------------------------- Batch 33 training: round 4 -------------------------
2023-03-25 20:47:14,925 : [INFO]  ------------------------- Batch round 4, loss: 0.569 -------------------------
2023-03-25 20:47:14,925 : [INFO]  ------------------------- Batch 33, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:14,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:14,971 : [INFO]  ------------------------- Batch 33 training: round 5 -------------------------
2023-03-25 20:47:15,980 : [INFO]  ------------------------- Batch round 5, loss: 0.5728 -------------------------
2023-03-25 20:47:15,980 : [INFO]  ------------------------- Batch 33, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:16,079 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:16,081 : [INFO]  ------------------------- Batch 33 training: round 6 -------------------------
2023-03-25 20:47:17,121 : [INFO]  ------------------------- Batch round 6, loss: 0.5629 -------------------------
2023-03-25 20:47:17,121 : [INFO]  ------------------------- Batch 33, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:17,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:17,164 : [INFO]  Batch number 33 model fetched from the server
2023-03-25 20:47:17,164 : [INFO]  ################ Batch 33: final global model evalution after 6 rounds ################
2023-03-25 20:47:18,448 : [INFO]  Batch 33: Training set : loss - 0.5608, accuracy - 0.7717, recall - 0.9565, AUC - 0.8884, F1 - 0.8073, precision - 0.6984, training time - -8.0 seconds
2023-03-25 20:47:18,448 : [INFO]  Batch 33: Testing set : loss - 0.5668, accuracy - 0.7402, recall - 0.9706, AUC - 0.8855, F1 - 0.7888, precision - 0.6644
2023-03-25 20:47:18,460 : [INFO]  Batch 34 initialized 
2023-03-25 20:47:18,878 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:19,193 : [INFO]  ------------------------- Batch 34 training: round 1 -------------------------
2023-03-25 20:47:22,025 : [INFO]  ------------------------- Batch round 1, loss: 0.5694 -------------------------
2023-03-25 20:47:22,025 : [INFO]  ------------------------- Batch 34, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:22,074 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:22,076 : [INFO]  ------------------------- Batch 34 training: round 2 -------------------------
2023-03-25 20:47:23,164 : [INFO]  ------------------------- Batch round 2, loss: 0.5701 -------------------------
2023-03-25 20:47:23,164 : [INFO]  ------------------------- Batch 34, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:23,167 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:23,169 : [INFO]  ------------------------- Batch 34 training: round 3 -------------------------
2023-03-25 20:47:24,283 : [INFO]  ------------------------- Batch round 3, loss: 0.5619 -------------------------
2023-03-25 20:47:24,283 : [INFO]  ------------------------- Batch 34, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:24,286 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:24,287 : [INFO]  ------------------------- Batch 34 training: round 4 -------------------------
2023-03-25 20:47:25,380 : [INFO]  ------------------------- Batch round 4, loss: 0.5613 -------------------------
2023-03-25 20:47:25,380 : [INFO]  ------------------------- Batch 34, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:25,383 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:25,385 : [INFO]  ------------------------- Batch 34 training: round 5 -------------------------
2023-03-25 20:47:26,488 : [INFO]  ------------------------- Batch round 5, loss: 0.5459 -------------------------
2023-03-25 20:47:26,488 : [INFO]  ------------------------- Batch 34, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:26,491 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:26,493 : [INFO]  ------------------------- Batch 34 training: round 6 -------------------------
2023-03-25 20:47:27,589 : [INFO]  ------------------------- Batch round 6, loss: 0.5533 -------------------------
2023-03-25 20:47:27,589 : [INFO]  ------------------------- Batch 34, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:27,592 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:27,593 : [INFO]  Batch number 34 model fetched from the server
2023-03-25 20:47:27,594 : [INFO]  ################ Batch 34: final global model evalution after 6 rounds ################
2023-03-25 20:47:28,880 : [INFO]  Batch 34: Training set : loss - 0.5464, accuracy - 0.7989, recall - 0.9565, AUC - 0.8966, F1 - 0.8263, precision - 0.7273, training time - -8.0 seconds
2023-03-25 20:47:28,880 : [INFO]  Batch 34: Testing set : loss - 0.5488, accuracy - 0.7745, recall - 0.9314, AUC - 0.9079, F1 - 0.8051, precision - 0.709
2023-03-25 20:47:28,888 : [INFO]  Batch 35 initialized 
2023-03-25 20:47:29,306 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:29,627 : [INFO]  ------------------------- Batch 35 training: round 1 -------------------------
2023-03-25 20:47:32,763 : [INFO]  ------------------------- Batch round 1, loss: 0.5612 -------------------------
2023-03-25 20:47:32,764 : [INFO]  ------------------------- Batch 35, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:32,774 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:32,781 : [INFO]  ------------------------- Batch 35 training: round 2 -------------------------
2023-03-25 20:47:33,808 : [INFO]  ------------------------- Batch round 2, loss: 0.5541 -------------------------
2023-03-25 20:47:33,808 : [INFO]  ------------------------- Batch 35, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:33,847 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:33,850 : [INFO]  ------------------------- Batch 35 training: round 3 -------------------------
2023-03-25 20:47:34,955 : [INFO]  ------------------------- Batch round 3, loss: 0.5479 -------------------------
2023-03-25 20:47:34,955 : [INFO]  ------------------------- Batch 35, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:34,963 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:34,965 : [INFO]  ------------------------- Batch 35 training: round 4 -------------------------
2023-03-25 20:47:36,077 : [INFO]  ------------------------- Batch round 4, loss: 0.5474 -------------------------
2023-03-25 20:47:36,077 : [INFO]  ------------------------- Batch 35, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:36,080 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:36,082 : [INFO]  ------------------------- Batch 35 training: round 5 -------------------------
2023-03-25 20:47:37,153 : [INFO]  ------------------------- Batch round 5, loss: 0.5439 -------------------------
2023-03-25 20:47:37,153 : [INFO]  ------------------------- Batch 35, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:37,175 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:37,177 : [INFO]  ------------------------- Batch 35 training: round 6 -------------------------
2023-03-25 20:47:38,239 : [INFO]  ------------------------- Batch round 6, loss: 0.5392 -------------------------
2023-03-25 20:47:38,239 : [INFO]  ------------------------- Batch 35, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:38,280 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:38,282 : [INFO]  Batch number 35 model fetched from the server
2023-03-25 20:47:38,282 : [INFO]  ################ Batch 35: final global model evalution after 6 rounds ################
2023-03-25 20:47:39,680 : [INFO]  Batch 35: Training set : loss - 0.5342, accuracy - 0.7772, recall - 0.913, AUC - 0.8916, F1 - 0.8038, precision - 0.7179, training time - -9.0 seconds
2023-03-25 20:47:39,680 : [INFO]  Batch 35: Testing set : loss - 0.5589, accuracy - 0.7402, recall - 0.9412, AUC - 0.8861, F1 - 0.7837, precision - 0.6713
2023-03-25 20:47:39,694 : [INFO]  Batch 36 initialized 
2023-03-25 20:47:40,121 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:40,434 : [INFO]  ------------------------- Batch 36 training: round 1 -------------------------
2023-03-25 20:47:43,348 : [INFO]  ------------------------- Batch round 1, loss: 0.5712 -------------------------
2023-03-25 20:47:43,348 : [INFO]  ------------------------- Batch 36, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:43,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:43,369 : [INFO]  ------------------------- Batch 36 training: round 2 -------------------------
2023-03-25 20:47:44,489 : [INFO]  ------------------------- Batch round 2, loss: 0.5606 -------------------------
2023-03-25 20:47:44,491 : [INFO]  ------------------------- Batch 36, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:44,494 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:44,496 : [INFO]  ------------------------- Batch 36 training: round 3 -------------------------
2023-03-25 20:47:45,573 : [INFO]  ------------------------- Batch round 3, loss: 0.5734 -------------------------
2023-03-25 20:47:45,573 : [INFO]  ------------------------- Batch 36, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:45,600 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:45,602 : [INFO]  ------------------------- Batch 36 training: round 4 -------------------------
2023-03-25 20:47:46,702 : [INFO]  ------------------------- Batch round 4, loss: 0.5663 -------------------------
2023-03-25 20:47:46,702 : [INFO]  ------------------------- Batch 36, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:46,714 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:46,716 : [INFO]  ------------------------- Batch 36 training: round 5 -------------------------
2023-03-25 20:47:47,784 : [INFO]  ------------------------- Batch round 5, loss: 0.5456 -------------------------
2023-03-25 20:47:47,785 : [INFO]  ------------------------- Batch 36, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:47,790 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:47,792 : [INFO]  ------------------------- Batch 36 training: round 6 -------------------------
2023-03-25 20:47:48,889 : [INFO]  ------------------------- Batch round 6, loss: 0.5628 -------------------------
2023-03-25 20:47:48,890 : [INFO]  ------------------------- Batch 36, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:48,902 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:48,904 : [INFO]  Batch number 36 model fetched from the server
2023-03-25 20:47:48,904 : [INFO]  ################ Batch 36: final global model evalution after 6 rounds ################
2023-03-25 20:47:50,200 : [INFO]  Batch 36: Training set : loss - 0.5569, accuracy - 0.75, recall - 0.913, AUC - 0.879, F1 - 0.785, precision - 0.6885, training time - -8.0 seconds
2023-03-25 20:47:50,200 : [INFO]  Batch 36: Testing set : loss - 0.5432, accuracy - 0.7108, recall - 0.951, AUC - 0.9415, F1 - 0.7668, precision - 0.6424
2023-03-25 20:47:50,213 : [INFO]  Batch 37 initialized 
2023-03-25 20:47:50,636 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:47:50,962 : [INFO]  ------------------------- Batch 37 training: round 1 -------------------------
2023-03-25 20:47:53,864 : [INFO]  ------------------------- Batch round 1, loss: 0.598 -------------------------
2023-03-25 20:47:53,864 : [INFO]  ------------------------- Batch 37, round 1: Sent local model to the server -------------------------
2023-03-25 20:47:53,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:53,868 : [INFO]  ------------------------- Batch 37 training: round 2 -------------------------
2023-03-25 20:47:54,974 : [INFO]  ------------------------- Batch round 2, loss: 0.5851 -------------------------
2023-03-25 20:47:54,974 : [INFO]  ------------------------- Batch 37, round 2: Sent local model to the server -------------------------
2023-03-25 20:47:54,977 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:54,978 : [INFO]  ------------------------- Batch 37 training: round 3 -------------------------
2023-03-25 20:47:56,069 : [INFO]  ------------------------- Batch round 3, loss: 0.5871 -------------------------
2023-03-25 20:47:56,069 : [INFO]  ------------------------- Batch 37, round 3: Sent local model to the server -------------------------
2023-03-25 20:47:56,096 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:56,098 : [INFO]  ------------------------- Batch 37 training: round 4 -------------------------
2023-03-25 20:47:57,168 : [INFO]  ------------------------- Batch round 4, loss: 0.5833 -------------------------
2023-03-25 20:47:57,168 : [INFO]  ------------------------- Batch 37, round 4: Sent local model to the server -------------------------
2023-03-25 20:47:57,171 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:57,173 : [INFO]  ------------------------- Batch 37 training: round 5 -------------------------
2023-03-25 20:47:58,278 : [INFO]  ------------------------- Batch round 5, loss: 0.5796 -------------------------
2023-03-25 20:47:58,279 : [INFO]  ------------------------- Batch 37, round 5: Sent local model to the server -------------------------
2023-03-25 20:47:58,281 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:58,283 : [INFO]  ------------------------- Batch 37 training: round 6 -------------------------
2023-03-25 20:47:59,391 : [INFO]  ------------------------- Batch round 6, loss: 0.5878 -------------------------
2023-03-25 20:47:59,391 : [INFO]  ------------------------- Batch 37, round 6: Sent local model to the server -------------------------
2023-03-25 20:47:59,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:47:59,396 : [INFO]  Batch number 37 model fetched from the server
2023-03-25 20:47:59,396 : [INFO]  ################ Batch 37: final global model evalution after 6 rounds ################
2023-03-25 20:48:00,714 : [INFO]  Batch 37: Training set : loss - 0.58, accuracy - 0.7228, recall - 0.8587, AUC - 0.8138, F1 - 0.756, precision - 0.6752, training time - -8.0 seconds
2023-03-25 20:48:00,714 : [INFO]  Batch 37: Testing set : loss - 0.5644, accuracy - 0.7549, recall - 0.8039, AUC - 0.8347, F1 - 0.7664, precision - 0.7321
2023-03-25 20:48:00,720 : [INFO]  Batch 38 initialized 
2023-03-25 20:48:01,150 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:01,482 : [INFO]  ------------------------- Batch 38 training: round 1 -------------------------
2023-03-25 20:48:04,274 : [INFO]  ------------------------- Batch round 1, loss: 0.5852 -------------------------
2023-03-25 20:48:04,274 : [INFO]  ------------------------- Batch 38, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:04,304 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:04,308 : [INFO]  ------------------------- Batch 38 training: round 2 -------------------------
2023-03-25 20:48:05,399 : [INFO]  ------------------------- Batch round 2, loss: 0.568 -------------------------
2023-03-25 20:48:05,399 : [INFO]  ------------------------- Batch 38, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:05,429 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:05,432 : [INFO]  ------------------------- Batch 38 training: round 3 -------------------------
2023-03-25 20:48:06,541 : [INFO]  ------------------------- Batch round 3, loss: 0.5755 -------------------------
2023-03-25 20:48:06,542 : [INFO]  ------------------------- Batch 38, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:06,577 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:06,579 : [INFO]  ------------------------- Batch 38 training: round 4 -------------------------
2023-03-25 20:48:07,650 : [INFO]  ------------------------- Batch round 4, loss: 0.5728 -------------------------
2023-03-25 20:48:07,650 : [INFO]  ------------------------- Batch 38, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:07,687 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:07,690 : [INFO]  ------------------------- Batch 38 training: round 5 -------------------------
2023-03-25 20:48:08,819 : [INFO]  ------------------------- Batch round 5, loss: 0.5622 -------------------------
2023-03-25 20:48:08,819 : [INFO]  ------------------------- Batch 38, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:08,860 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:08,862 : [INFO]  ------------------------- Batch 38 training: round 6 -------------------------
2023-03-25 20:48:09,938 : [INFO]  ------------------------- Batch round 6, loss: 0.5648 -------------------------
2023-03-25 20:48:09,939 : [INFO]  ------------------------- Batch 38, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:10,006 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:10,008 : [INFO]  Batch number 38 model fetched from the server
2023-03-25 20:48:10,008 : [INFO]  ################ Batch 38: final global model evalution after 6 rounds ################
2023-03-25 20:48:11,304 : [INFO]  Batch 38: Training set : loss - 0.5614, accuracy - 0.7446, recall - 0.8804, AUC - 0.8623, F1 - 0.7751, precision - 0.6923, training time - -9.0 seconds
2023-03-25 20:48:11,304 : [INFO]  Batch 38: Testing set : loss - 0.5621, accuracy - 0.7206, recall - 0.9314, AUC - 0.8913, F1 - 0.7692, precision - 0.6552
2023-03-25 20:48:11,316 : [INFO]  Batch 39 initialized 
2023-03-25 20:48:11,734 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:12,063 : [INFO]  ------------------------- Batch 39 training: round 1 -------------------------
2023-03-25 20:48:14,817 : [INFO]  ------------------------- Batch round 1, loss: 0.5698 -------------------------
2023-03-25 20:48:14,817 : [INFO]  ------------------------- Batch 39, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:14,871 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:14,873 : [INFO]  ------------------------- Batch 39 training: round 2 -------------------------
2023-03-25 20:48:15,937 : [INFO]  ------------------------- Batch round 2, loss: 0.563 -------------------------
2023-03-25 20:48:15,937 : [INFO]  ------------------------- Batch 39, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:15,940 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:15,942 : [INFO]  ------------------------- Batch 39 training: round 3 -------------------------
2023-03-25 20:48:17,006 : [INFO]  ------------------------- Batch round 3, loss: 0.5549 -------------------------
2023-03-25 20:48:17,007 : [INFO]  ------------------------- Batch 39, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:17,014 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:17,016 : [INFO]  ------------------------- Batch 39 training: round 4 -------------------------
2023-03-25 20:48:18,101 : [INFO]  ------------------------- Batch round 4, loss: 0.5533 -------------------------
2023-03-25 20:48:18,101 : [INFO]  ------------------------- Batch 39, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:18,120 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:18,121 : [INFO]  ------------------------- Batch 39 training: round 5 -------------------------
2023-03-25 20:48:19,205 : [INFO]  ------------------------- Batch round 5, loss: 0.555 -------------------------
2023-03-25 20:48:19,205 : [INFO]  ------------------------- Batch 39, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:19,214 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:19,216 : [INFO]  ------------------------- Batch 39 training: round 6 -------------------------
2023-03-25 20:48:20,233 : [INFO]  ------------------------- Batch round 6, loss: 0.5608 -------------------------
2023-03-25 20:48:20,233 : [INFO]  ------------------------- Batch 39, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:20,251 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:20,253 : [INFO]  Batch number 39 model fetched from the server
2023-03-25 20:48:20,253 : [INFO]  ################ Batch 39: final global model evalution after 6 rounds ################
2023-03-25 20:48:21,539 : [INFO]  Batch 39: Training set : loss - 0.5509, accuracy - 0.7554, recall - 0.9674, AUC - 0.9057, F1 - 0.7982, precision - 0.6794, training time - -8.0 seconds
2023-03-25 20:48:21,539 : [INFO]  Batch 39: Testing set : loss - 0.5332, accuracy - 0.7745, recall - 0.9902, AUC - 0.9472, F1 - 0.8145, precision - 0.6918
2023-03-25 20:48:21,552 : [INFO]  Batch 40 initialized 
2023-03-25 20:48:21,971 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:22,317 : [INFO]  ------------------------- Batch 40 training: round 1 -------------------------
2023-03-25 20:48:25,214 : [INFO]  ------------------------- Batch round 1, loss: 0.5773 -------------------------
2023-03-25 20:48:25,214 : [INFO]  ------------------------- Batch 40, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:25,319 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:25,321 : [INFO]  ------------------------- Batch 40 training: round 2 -------------------------
2023-03-25 20:48:26,429 : [INFO]  ------------------------- Batch round 2, loss: 0.5724 -------------------------
2023-03-25 20:48:26,430 : [INFO]  ------------------------- Batch 40, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:26,495 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:26,498 : [INFO]  ------------------------- Batch 40 training: round 3 -------------------------
2023-03-25 20:48:27,583 : [INFO]  ------------------------- Batch round 3, loss: 0.565 -------------------------
2023-03-25 20:48:27,583 : [INFO]  ------------------------- Batch 40, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:27,649 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:27,651 : [INFO]  ------------------------- Batch 40 training: round 4 -------------------------
2023-03-25 20:48:28,737 : [INFO]  ------------------------- Batch round 4, loss: 0.5548 -------------------------
2023-03-25 20:48:28,737 : [INFO]  ------------------------- Batch 40, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:28,794 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:28,796 : [INFO]  ------------------------- Batch 40 training: round 5 -------------------------
2023-03-25 20:48:29,935 : [INFO]  ------------------------- Batch round 5, loss: 0.5424 -------------------------
2023-03-25 20:48:29,935 : [INFO]  ------------------------- Batch 40, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:29,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:29,987 : [INFO]  ------------------------- Batch 40 training: round 6 -------------------------
2023-03-25 20:48:31,058 : [INFO]  ------------------------- Batch round 6, loss: 0.5466 -------------------------
2023-03-25 20:48:31,059 : [INFO]  ------------------------- Batch 40, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:31,099 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:31,101 : [INFO]  Batch number 40 model fetched from the server
2023-03-25 20:48:31,101 : [INFO]  ################ Batch 40: final global model evalution after 6 rounds ################
2023-03-25 20:48:32,409 : [INFO]  Batch 40: Training set : loss - 0.5441, accuracy - 0.7609, recall - 0.9022, AUC - 0.8794, F1 - 0.7905, precision - 0.7034, training time - -9.0 seconds
2023-03-25 20:48:32,409 : [INFO]  Batch 40: Testing set : loss - 0.5726, accuracy - 0.7206, recall - 0.8627, AUC - 0.8592, F1 - 0.7554, precision - 0.6718
2023-03-25 20:48:32,424 : [INFO]  Batch 41 initialized 
2023-03-25 20:48:32,853 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:33,196 : [INFO]  ------------------------- Batch 41 training: round 1 -------------------------
2023-03-25 20:48:36,001 : [INFO]  ------------------------- Batch round 1, loss: 0.5403 -------------------------
2023-03-25 20:48:36,001 : [INFO]  ------------------------- Batch 41, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:36,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:36,025 : [INFO]  ------------------------- Batch 41 training: round 2 -------------------------
2023-03-25 20:48:37,110 : [INFO]  ------------------------- Batch round 2, loss: 0.5344 -------------------------
2023-03-25 20:48:37,110 : [INFO]  ------------------------- Batch 41, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:37,117 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:37,119 : [INFO]  ------------------------- Batch 41 training: round 3 -------------------------
2023-03-25 20:48:38,241 : [INFO]  ------------------------- Batch round 3, loss: 0.5366 -------------------------
2023-03-25 20:48:38,241 : [INFO]  ------------------------- Batch 41, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:38,244 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:38,247 : [INFO]  ------------------------- Batch 41 training: round 4 -------------------------
2023-03-25 20:48:39,382 : [INFO]  ------------------------- Batch round 4, loss: 0.5343 -------------------------
2023-03-25 20:48:39,382 : [INFO]  ------------------------- Batch 41, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:39,699 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:39,707 : [INFO]  ------------------------- Batch 41 training: round 5 -------------------------
2023-03-25 20:48:40,698 : [INFO]  ------------------------- Batch round 5, loss: 0.5281 -------------------------
2023-03-25 20:48:40,698 : [INFO]  ------------------------- Batch 41, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:40,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:40,719 : [INFO]  ------------------------- Batch 41 training: round 6 -------------------------
2023-03-25 20:48:41,836 : [INFO]  ------------------------- Batch round 6, loss: 0.5229 -------------------------
2023-03-25 20:48:41,836 : [INFO]  ------------------------- Batch 41, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:41,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:41,842 : [INFO]  Batch number 41 model fetched from the server
2023-03-25 20:48:41,842 : [INFO]  ################ Batch 41: final global model evalution after 6 rounds ################
2023-03-25 20:48:43,180 : [INFO]  Batch 41: Training set : loss - 0.5259, accuracy - 0.788, recall - 0.9674, AUC - 0.944, F1 - 0.8203, precision - 0.712, training time - -9.0 seconds
2023-03-25 20:48:43,180 : [INFO]  Batch 41: Testing set : loss - 0.571, accuracy - 0.7059, recall - 0.8922, AUC - 0.8922, F1 - 0.7521, precision - 0.65
2023-03-25 20:48:43,192 : [INFO]  Batch 42 initialized 
2023-03-25 20:48:43,619 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:43,956 : [INFO]  ------------------------- Batch 42 training: round 1 -------------------------
2023-03-25 20:48:46,754 : [INFO]  ------------------------- Batch round 1, loss: 0.5342 -------------------------
2023-03-25 20:48:46,755 : [INFO]  ------------------------- Batch 42, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:46,800 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:46,803 : [INFO]  ------------------------- Batch 42 training: round 2 -------------------------
2023-03-25 20:48:47,858 : [INFO]  ------------------------- Batch round 2, loss: 0.5359 -------------------------
2023-03-25 20:48:47,858 : [INFO]  ------------------------- Batch 42, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:47,933 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:47,936 : [INFO]  ------------------------- Batch 42 training: round 3 -------------------------
2023-03-25 20:48:49,030 : [INFO]  ------------------------- Batch round 3, loss: 0.5333 -------------------------
2023-03-25 20:48:49,030 : [INFO]  ------------------------- Batch 42, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:49,063 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:49,065 : [INFO]  ------------------------- Batch 42 training: round 4 -------------------------
2023-03-25 20:48:50,139 : [INFO]  ------------------------- Batch round 4, loss: 0.5286 -------------------------
2023-03-25 20:48:50,139 : [INFO]  ------------------------- Batch 42, round 4: Sent local model to the server -------------------------
2023-03-25 20:48:50,190 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:50,192 : [INFO]  ------------------------- Batch 42 training: round 5 -------------------------
2023-03-25 20:48:51,210 : [INFO]  ------------------------- Batch round 5, loss: 0.5237 -------------------------
2023-03-25 20:48:51,210 : [INFO]  ------------------------- Batch 42, round 5: Sent local model to the server -------------------------
2023-03-25 20:48:51,259 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:51,261 : [INFO]  ------------------------- Batch 42 training: round 6 -------------------------
2023-03-25 20:48:52,312 : [INFO]  ------------------------- Batch round 6, loss: 0.5269 -------------------------
2023-03-25 20:48:52,312 : [INFO]  ------------------------- Batch 42, round 6: Sent local model to the server -------------------------
2023-03-25 20:48:52,352 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:52,354 : [INFO]  Batch number 42 model fetched from the server
2023-03-25 20:48:52,354 : [INFO]  ################ Batch 42: final global model evalution after 6 rounds ################
2023-03-25 20:48:53,618 : [INFO]  Batch 42: Training set : loss - 0.5119, accuracy - 0.8207, recall - 0.9457, AUC - 0.919, F1 - 0.8406, precision - 0.7565, training time - -8.0 seconds
2023-03-25 20:48:53,618 : [INFO]  Batch 42: Testing set : loss - 0.5611, accuracy - 0.7353, recall - 0.9216, AUC - 0.8813, F1 - 0.7769, precision - 0.6714
2023-03-25 20:48:53,631 : [INFO]  Batch 43 initialized 
2023-03-25 20:48:54,057 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:48:54,392 : [INFO]  ------------------------- Batch 43 training: round 1 -------------------------
2023-03-25 20:48:57,173 : [INFO]  ------------------------- Batch round 1, loss: 0.5953 -------------------------
2023-03-25 20:48:57,173 : [INFO]  ------------------------- Batch 43, round 1: Sent local model to the server -------------------------
2023-03-25 20:48:57,262 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:57,264 : [INFO]  ------------------------- Batch 43 training: round 2 -------------------------
2023-03-25 20:48:58,341 : [INFO]  ------------------------- Batch round 2, loss: 0.5933 -------------------------
2023-03-25 20:48:58,341 : [INFO]  ------------------------- Batch 43, round 2: Sent local model to the server -------------------------
2023-03-25 20:48:58,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:58,380 : [INFO]  ------------------------- Batch 43 training: round 3 -------------------------
2023-03-25 20:48:59,438 : [INFO]  ------------------------- Batch round 3, loss: 0.5864 -------------------------
2023-03-25 20:48:59,438 : [INFO]  ------------------------- Batch 43, round 3: Sent local model to the server -------------------------
2023-03-25 20:48:59,500 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:48:59,503 : [INFO]  ------------------------- Batch 43 training: round 4 -------------------------
2023-03-25 20:49:00,560 : [INFO]  ------------------------- Batch round 4, loss: 0.5826 -------------------------
2023-03-25 20:49:00,560 : [INFO]  ------------------------- Batch 43, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:00,624 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:00,627 : [INFO]  ------------------------- Batch 43 training: round 5 -------------------------
2023-03-25 20:49:01,685 : [INFO]  ------------------------- Batch round 5, loss: 0.5898 -------------------------
2023-03-25 20:49:01,685 : [INFO]  ------------------------- Batch 43, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:01,744 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:01,746 : [INFO]  ------------------------- Batch 43 training: round 6 -------------------------
2023-03-25 20:49:02,766 : [INFO]  ------------------------- Batch round 6, loss: 0.5762 -------------------------
2023-03-25 20:49:02,766 : [INFO]  ------------------------- Batch 43, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:02,817 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:02,819 : [INFO]  Batch number 43 model fetched from the server
2023-03-25 20:49:02,819 : [INFO]  ################ Batch 43: final global model evalution after 6 rounds ################
2023-03-25 20:49:04,078 : [INFO]  Batch 43: Training set : loss - 0.5752, accuracy - 0.7283, recall - 0.913, AUC - 0.825, F1 - 0.7706, precision - 0.6667, training time - -8.0 seconds
2023-03-25 20:49:04,078 : [INFO]  Batch 43: Testing set : loss - 0.5383, accuracy - 0.7451, recall - 0.9412, AUC - 0.9019, F1 - 0.7869, precision - 0.6761
2023-03-25 20:49:04,091 : [INFO]  Batch 44 initialized 
2023-03-25 20:49:04,531 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:04,885 : [INFO]  ------------------------- Batch 44 training: round 1 -------------------------
2023-03-25 20:49:07,684 : [INFO]  ------------------------- Batch round 1, loss: 0.5479 -------------------------
2023-03-25 20:49:07,684 : [INFO]  ------------------------- Batch 44, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:07,724 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:07,726 : [INFO]  ------------------------- Batch 44 training: round 2 -------------------------
2023-03-25 20:49:08,795 : [INFO]  ------------------------- Batch round 2, loss: 0.535 -------------------------
2023-03-25 20:49:08,795 : [INFO]  ------------------------- Batch 44, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:08,836 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:08,838 : [INFO]  ------------------------- Batch 44 training: round 3 -------------------------
2023-03-25 20:49:09,908 : [INFO]  ------------------------- Batch round 3, loss: 0.5305 -------------------------
2023-03-25 20:49:09,908 : [INFO]  ------------------------- Batch 44, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:09,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:09,977 : [INFO]  ------------------------- Batch 44 training: round 4 -------------------------
2023-03-25 20:49:11,027 : [INFO]  ------------------------- Batch round 4, loss: 0.5311 -------------------------
2023-03-25 20:49:11,027 : [INFO]  ------------------------- Batch 44, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:11,081 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:11,083 : [INFO]  ------------------------- Batch 44 training: round 5 -------------------------
2023-03-25 20:49:12,153 : [INFO]  ------------------------- Batch round 5, loss: 0.518 -------------------------
2023-03-25 20:49:12,153 : [INFO]  ------------------------- Batch 44, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:12,180 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:12,182 : [INFO]  ------------------------- Batch 44 training: round 6 -------------------------
2023-03-25 20:49:13,258 : [INFO]  ------------------------- Batch round 6, loss: 0.5221 -------------------------
2023-03-25 20:49:13,258 : [INFO]  ------------------------- Batch 44, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:13,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:13,290 : [INFO]  Batch number 44 model fetched from the server
2023-03-25 20:49:13,290 : [INFO]  ################ Batch 44: final global model evalution after 6 rounds ################
2023-03-25 20:49:14,601 : [INFO]  Batch 44: Training set : loss - 0.517, accuracy - 0.7989, recall - 0.9348, AUC - 0.9083, F1 - 0.823, precision - 0.735, training time - -8.0 seconds
2023-03-25 20:49:14,601 : [INFO]  Batch 44: Testing set : loss - 0.5746, accuracy - 0.7157, recall - 0.8824, AUC - 0.8483, F1 - 0.7563, precision - 0.6618
2023-03-25 20:49:14,609 : [INFO]  Batch 45 initialized 
2023-03-25 20:49:15,039 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:15,398 : [INFO]  ------------------------- Batch 45 training: round 1 -------------------------
2023-03-25 20:49:18,186 : [INFO]  ------------------------- Batch round 1, loss: 0.5671 -------------------------
2023-03-25 20:49:18,186 : [INFO]  ------------------------- Batch 45, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:18,279 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:18,281 : [INFO]  ------------------------- Batch 45 training: round 2 -------------------------
2023-03-25 20:49:19,343 : [INFO]  ------------------------- Batch round 2, loss: 0.5579 -------------------------
2023-03-25 20:49:19,343 : [INFO]  ------------------------- Batch 45, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:19,402 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:19,405 : [INFO]  ------------------------- Batch 45 training: round 3 -------------------------
2023-03-25 20:49:20,494 : [INFO]  ------------------------- Batch round 3, loss: 0.5514 -------------------------
2023-03-25 20:49:20,495 : [INFO]  ------------------------- Batch 45, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:20,526 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:20,528 : [INFO]  ------------------------- Batch 45 training: round 4 -------------------------
2023-03-25 20:49:21,595 : [INFO]  ------------------------- Batch round 4, loss: 0.5571 -------------------------
2023-03-25 20:49:21,595 : [INFO]  ------------------------- Batch 45, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:21,664 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:21,666 : [INFO]  ------------------------- Batch 45 training: round 5 -------------------------
2023-03-25 20:49:22,760 : [INFO]  ------------------------- Batch round 5, loss: 0.5546 -------------------------
2023-03-25 20:49:22,760 : [INFO]  ------------------------- Batch 45, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:22,802 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:22,804 : [INFO]  ------------------------- Batch 45 training: round 6 -------------------------
2023-03-25 20:49:23,883 : [INFO]  ------------------------- Batch round 6, loss: 0.549 -------------------------
2023-03-25 20:49:23,883 : [INFO]  ------------------------- Batch 45, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:23,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:23,970 : [INFO]  Batch number 45 model fetched from the server
2023-03-25 20:49:23,970 : [INFO]  ################ Batch 45: final global model evalution after 6 rounds ################
2023-03-25 20:49:25,230 : [INFO]  Batch 45: Training set : loss - 0.5533, accuracy - 0.7772, recall - 0.9457, AUC - 0.8831, F1 - 0.8093, precision - 0.7073, training time - -9.0 seconds
2023-03-25 20:49:25,230 : [INFO]  Batch 45: Testing set : loss - 0.5656, accuracy - 0.7304, recall - 0.9314, AUC - 0.8924, F1 - 0.7755, precision - 0.6643
2023-03-25 20:49:25,240 : [INFO]  Batch 46 initialized 
2023-03-25 20:49:25,664 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:26,016 : [INFO]  ------------------------- Batch 46 training: round 1 -------------------------
2023-03-25 20:49:28,853 : [INFO]  ------------------------- Batch round 1, loss: 0.5733 -------------------------
2023-03-25 20:49:28,853 : [INFO]  ------------------------- Batch 46, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:28,856 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:28,858 : [INFO]  ------------------------- Batch 46 training: round 2 -------------------------
2023-03-25 20:49:29,945 : [INFO]  ------------------------- Batch round 2, loss: 0.566 -------------------------
2023-03-25 20:49:29,945 : [INFO]  ------------------------- Batch 46, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:29,950 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:29,953 : [INFO]  ------------------------- Batch 46 training: round 3 -------------------------
2023-03-25 20:49:31,283 : [INFO]  ------------------------- Batch round 3, loss: 0.5714 -------------------------
2023-03-25 20:49:31,283 : [INFO]  ------------------------- Batch 46, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:31,285 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:31,287 : [INFO]  ------------------------- Batch 46 training: round 4 -------------------------
2023-03-25 20:49:32,348 : [INFO]  ------------------------- Batch round 4, loss: 0.559 -------------------------
2023-03-25 20:49:32,348 : [INFO]  ------------------------- Batch 46, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:32,351 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:32,352 : [INFO]  ------------------------- Batch 46 training: round 5 -------------------------
2023-03-25 20:49:33,472 : [INFO]  ------------------------- Batch round 5, loss: 0.5572 -------------------------
2023-03-25 20:49:33,472 : [INFO]  ------------------------- Batch 46, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:33,475 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:33,477 : [INFO]  ------------------------- Batch 46 training: round 6 -------------------------
2023-03-25 20:49:34,576 : [INFO]  ------------------------- Batch round 6, loss: 0.5517 -------------------------
2023-03-25 20:49:34,576 : [INFO]  ------------------------- Batch 46, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:34,579 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:34,582 : [INFO]  Batch number 46 model fetched from the server
2023-03-25 20:49:34,582 : [INFO]  ################ Batch 46: final global model evalution after 6 rounds ################
2023-03-25 20:49:35,904 : [INFO]  Batch 46: Training set : loss - 0.5544, accuracy - 0.7391, recall - 0.8696, AUC - 0.8583, F1 - 0.7692, precision - 0.6897, training time - -9.0 seconds
2023-03-25 20:49:35,904 : [INFO]  Batch 46: Testing set : loss - 0.5982, accuracy - 0.652, recall - 0.8431, AUC - 0.847, F1 - 0.7078, precision - 0.6099
2023-03-25 20:49:35,920 : [INFO]  Batch 47 initialized 
2023-03-25 20:49:36,343 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:36,702 : [INFO]  ------------------------- Batch 47 training: round 1 -------------------------
2023-03-25 20:49:39,502 : [INFO]  ------------------------- Batch round 1, loss: 0.6054 -------------------------
2023-03-25 20:49:39,502 : [INFO]  ------------------------- Batch 47, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:39,505 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:39,507 : [INFO]  ------------------------- Batch 47 training: round 2 -------------------------
2023-03-25 20:49:40,620 : [INFO]  ------------------------- Batch round 2, loss: 0.599 -------------------------
2023-03-25 20:49:40,620 : [INFO]  ------------------------- Batch 47, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:40,623 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:40,625 : [INFO]  ------------------------- Batch 47 training: round 3 -------------------------
2023-03-25 20:49:41,714 : [INFO]  ------------------------- Batch round 3, loss: 0.5972 -------------------------
2023-03-25 20:49:41,715 : [INFO]  ------------------------- Batch 47, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:41,718 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:41,719 : [INFO]  ------------------------- Batch 47 training: round 4 -------------------------
2023-03-25 20:49:42,797 : [INFO]  ------------------------- Batch round 4, loss: 0.601 -------------------------
2023-03-25 20:49:42,798 : [INFO]  ------------------------- Batch 47, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:42,800 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:42,802 : [INFO]  ------------------------- Batch 47 training: round 5 -------------------------
2023-03-25 20:49:43,888 : [INFO]  ------------------------- Batch round 5, loss: 0.5853 -------------------------
2023-03-25 20:49:43,888 : [INFO]  ------------------------- Batch 47, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:43,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:43,894 : [INFO]  ------------------------- Batch 47 training: round 6 -------------------------
2023-03-25 20:49:44,987 : [INFO]  ------------------------- Batch round 6, loss: 0.5886 -------------------------
2023-03-25 20:49:44,987 : [INFO]  ------------------------- Batch 47, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:44,990 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:44,992 : [INFO]  Batch number 47 model fetched from the server
2023-03-25 20:49:44,992 : [INFO]  ################ Batch 47: final global model evalution after 6 rounds ################
2023-03-25 20:49:46,337 : [INFO]  Batch 47: Training set : loss - 0.5961, accuracy - 0.712, recall - 0.9239, AUC - 0.8081, F1 - 0.7623, precision - 0.6489, training time - -8.0 seconds
2023-03-25 20:49:46,338 : [INFO]  Batch 47: Testing set : loss - 0.5916, accuracy - 0.6716, recall - 0.8725, AUC - 0.8214, F1 - 0.7265, precision - 0.6224
2023-03-25 20:49:46,344 : [INFO]  Batch 48 initialized 
2023-03-25 20:49:46,766 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:47,127 : [INFO]  ------------------------- Batch 48 training: round 1 -------------------------
2023-03-25 20:49:49,902 : [INFO]  ------------------------- Batch round 1, loss: 0.5761 -------------------------
2023-03-25 20:49:49,902 : [INFO]  ------------------------- Batch 48, round 1: Sent local model to the server -------------------------
2023-03-25 20:49:49,905 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:49,906 : [INFO]  ------------------------- Batch 48 training: round 2 -------------------------
2023-03-25 20:49:51,020 : [INFO]  ------------------------- Batch round 2, loss: 0.5559 -------------------------
2023-03-25 20:49:51,020 : [INFO]  ------------------------- Batch 48, round 2: Sent local model to the server -------------------------
2023-03-25 20:49:51,023 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:51,026 : [INFO]  ------------------------- Batch 48 training: round 3 -------------------------
2023-03-25 20:49:52,145 : [INFO]  ------------------------- Batch round 3, loss: 0.5503 -------------------------
2023-03-25 20:49:52,145 : [INFO]  ------------------------- Batch 48, round 3: Sent local model to the server -------------------------
2023-03-25 20:49:52,148 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:52,150 : [INFO]  ------------------------- Batch 48 training: round 4 -------------------------
2023-03-25 20:49:53,247 : [INFO]  ------------------------- Batch round 4, loss: 0.5562 -------------------------
2023-03-25 20:49:53,247 : [INFO]  ------------------------- Batch 48, round 4: Sent local model to the server -------------------------
2023-03-25 20:49:53,250 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:53,252 : [INFO]  ------------------------- Batch 48 training: round 5 -------------------------
2023-03-25 20:49:54,363 : [INFO]  ------------------------- Batch round 5, loss: 0.5566 -------------------------
2023-03-25 20:49:54,363 : [INFO]  ------------------------- Batch 48, round 5: Sent local model to the server -------------------------
2023-03-25 20:49:54,366 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:54,368 : [INFO]  ------------------------- Batch 48 training: round 6 -------------------------
2023-03-25 20:49:55,483 : [INFO]  ------------------------- Batch round 6, loss: 0.5437 -------------------------
2023-03-25 20:49:55,483 : [INFO]  ------------------------- Batch 48, round 6: Sent local model to the server -------------------------
2023-03-25 20:49:55,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:49:55,488 : [INFO]  Batch number 48 model fetched from the server
2023-03-25 20:49:55,488 : [INFO]  ################ Batch 48: final global model evalution after 6 rounds ################
2023-03-25 20:49:56,787 : [INFO]  Batch 48: Training set : loss - 0.5372, accuracy - 0.7663, recall - 0.9674, AUC - 0.8914, F1 - 0.8054, precision - 0.6899, training time - -8.0 seconds
2023-03-25 20:49:56,787 : [INFO]  Batch 48: Testing set : loss - 0.5595, accuracy - 0.7353, recall - 0.8922, AUC - 0.8913, F1 - 0.7712, precision - 0.6791
2023-03-25 20:49:56,798 : [INFO]  Batch 49 initialized 
2023-03-25 20:49:57,223 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:49:57,583 : [INFO]  ------------------------- Batch 49 training: round 1 -------------------------
2023-03-25 20:50:00,445 : [INFO]  ------------------------- Batch round 1, loss: 0.6153 -------------------------
2023-03-25 20:50:00,445 : [INFO]  ------------------------- Batch 49, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:00,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:00,450 : [INFO]  ------------------------- Batch 49 training: round 2 -------------------------
2023-03-25 20:50:01,573 : [INFO]  ------------------------- Batch round 2, loss: 0.6118 -------------------------
2023-03-25 20:50:01,573 : [INFO]  ------------------------- Batch 49, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:01,576 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:01,578 : [INFO]  ------------------------- Batch 49 training: round 3 -------------------------
2023-03-25 20:50:02,712 : [INFO]  ------------------------- Batch round 3, loss: 0.6045 -------------------------
2023-03-25 20:50:02,712 : [INFO]  ------------------------- Batch 49, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:02,715 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:02,717 : [INFO]  ------------------------- Batch 49 training: round 4 -------------------------
2023-03-25 20:50:03,827 : [INFO]  ------------------------- Batch round 4, loss: 0.5923 -------------------------
2023-03-25 20:50:03,827 : [INFO]  ------------------------- Batch 49, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:03,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:03,832 : [INFO]  ------------------------- Batch 49 training: round 5 -------------------------
2023-03-25 20:50:04,968 : [INFO]  ------------------------- Batch round 5, loss: 0.6043 -------------------------
2023-03-25 20:50:04,968 : [INFO]  ------------------------- Batch 49, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:04,971 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:04,972 : [INFO]  ------------------------- Batch 49 training: round 6 -------------------------
2023-03-25 20:50:06,075 : [INFO]  ------------------------- Batch round 6, loss: 0.5924 -------------------------
2023-03-25 20:50:06,075 : [INFO]  ------------------------- Batch 49, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:06,078 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:06,080 : [INFO]  Batch number 49 model fetched from the server
2023-03-25 20:50:06,081 : [INFO]  ################ Batch 49: final global model evalution after 6 rounds ################
2023-03-25 20:50:07,402 : [INFO]  Batch 49: Training set : loss - 0.6006, accuracy - 0.6848, recall - 0.8587, AUC - 0.8358, F1 - 0.7315, precision - 0.6371, training time - -8.0 seconds
2023-03-25 20:50:07,402 : [INFO]  Batch 49: Testing set : loss - 0.5898, accuracy - 0.7108, recall - 0.8627, AUC - 0.8218, F1 - 0.7489, precision - 0.6617
2023-03-25 20:50:07,412 : [INFO]  Batch 50 initialized 
2023-03-25 20:50:07,834 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:08,194 : [INFO]  ------------------------- Batch 50 training: round 1 -------------------------
2023-03-25 20:50:10,982 : [INFO]  ------------------------- Batch round 1, loss: 0.553 -------------------------
2023-03-25 20:50:10,982 : [INFO]  ------------------------- Batch 50, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:10,985 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:10,988 : [INFO]  ------------------------- Batch 50 training: round 2 -------------------------
2023-03-25 20:50:12,105 : [INFO]  ------------------------- Batch round 2, loss: 0.553 -------------------------
2023-03-25 20:50:12,106 : [INFO]  ------------------------- Batch 50, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:12,109 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:12,110 : [INFO]  ------------------------- Batch 50 training: round 3 -------------------------
2023-03-25 20:50:13,212 : [INFO]  ------------------------- Batch round 3, loss: 0.5411 -------------------------
2023-03-25 20:50:13,212 : [INFO]  ------------------------- Batch 50, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:13,215 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:13,217 : [INFO]  ------------------------- Batch 50 training: round 4 -------------------------
2023-03-25 20:50:14,322 : [INFO]  ------------------------- Batch round 4, loss: 0.5463 -------------------------
2023-03-25 20:50:14,322 : [INFO]  ------------------------- Batch 50, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:14,325 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:14,327 : [INFO]  ------------------------- Batch 50 training: round 5 -------------------------
2023-03-25 20:50:15,400 : [INFO]  ------------------------- Batch round 5, loss: 0.538 -------------------------
2023-03-25 20:50:15,400 : [INFO]  ------------------------- Batch 50, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:15,403 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:15,406 : [INFO]  ------------------------- Batch 50 training: round 6 -------------------------
2023-03-25 20:50:16,500 : [INFO]  ------------------------- Batch round 6, loss: 0.5354 -------------------------
2023-03-25 20:50:16,500 : [INFO]  ------------------------- Batch 50, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:16,503 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:16,505 : [INFO]  Batch number 50 model fetched from the server
2023-03-25 20:50:16,505 : [INFO]  ################ Batch 50: final global model evalution after 6 rounds ################
2023-03-25 20:50:17,777 : [INFO]  Batch 50: Training set : loss - 0.53, accuracy - 0.8043, recall - 0.9239, AUC - 0.8849, F1 - 0.8252, precision - 0.7456, training time - -8.0 seconds
2023-03-25 20:50:17,777 : [INFO]  Batch 50: Testing set : loss - 0.5866, accuracy - 0.6765, recall - 0.8627, AUC - 0.8335, F1 - 0.7273, precision - 0.6286
2023-03-25 20:50:17,784 : [INFO]  Batch 51 initialized 
2023-03-25 20:50:18,204 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:18,573 : [INFO]  ------------------------- Batch 51 training: round 1 -------------------------
2023-03-25 20:50:21,364 : [INFO]  ------------------------- Batch round 1, loss: 0.5653 -------------------------
2023-03-25 20:50:21,364 : [INFO]  ------------------------- Batch 51, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:21,367 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:21,369 : [INFO]  ------------------------- Batch 51 training: round 2 -------------------------
2023-03-25 20:50:22,437 : [INFO]  ------------------------- Batch round 2, loss: 0.5612 -------------------------
2023-03-25 20:50:22,437 : [INFO]  ------------------------- Batch 51, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:22,440 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:22,442 : [INFO]  ------------------------- Batch 51 training: round 3 -------------------------
2023-03-25 20:50:23,497 : [INFO]  ------------------------- Batch round 3, loss: 0.5673 -------------------------
2023-03-25 20:50:23,497 : [INFO]  ------------------------- Batch 51, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:23,525 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:23,528 : [INFO]  ------------------------- Batch 51 training: round 4 -------------------------
2023-03-25 20:50:24,658 : [INFO]  ------------------------- Batch round 4, loss: 0.5636 -------------------------
2023-03-25 20:50:24,658 : [INFO]  ------------------------- Batch 51, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:24,668 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:24,670 : [INFO]  ------------------------- Batch 51 training: round 5 -------------------------
2023-03-25 20:50:25,758 : [INFO]  ------------------------- Batch round 5, loss: 0.5474 -------------------------
2023-03-25 20:50:25,758 : [INFO]  ------------------------- Batch 51, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:25,761 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:25,763 : [INFO]  ------------------------- Batch 51 training: round 6 -------------------------
2023-03-25 20:50:26,844 : [INFO]  ------------------------- Batch round 6, loss: 0.5516 -------------------------
2023-03-25 20:50:26,844 : [INFO]  ------------------------- Batch 51, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:26,851 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:26,854 : [INFO]  Batch number 51 model fetched from the server
2023-03-25 20:50:26,854 : [INFO]  ################ Batch 51: final global model evalution after 6 rounds ################
2023-03-25 20:50:28,147 : [INFO]  Batch 51: Training set : loss - 0.5455, accuracy - 0.7826, recall - 0.9457, AUC - 0.8878, F1 - 0.8131, precision - 0.7131, training time - -8.0 seconds
2023-03-25 20:50:28,147 : [INFO]  Batch 51: Testing set : loss - 0.5783, accuracy - 0.6716, recall - 0.8627, AUC - 0.8725, F1 - 0.7243, precision - 0.6241
2023-03-25 20:50:28,162 : [INFO]  Batch 52 initialized 
2023-03-25 20:50:28,583 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:28,951 : [INFO]  ------------------------- Batch 52 training: round 1 -------------------------
2023-03-25 20:50:31,782 : [INFO]  ------------------------- Batch round 1, loss: 0.582 -------------------------
2023-03-25 20:50:31,782 : [INFO]  ------------------------- Batch 52, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:31,786 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:31,787 : [INFO]  ------------------------- Batch 52 training: round 2 -------------------------
2023-03-25 20:50:32,905 : [INFO]  ------------------------- Batch round 2, loss: 0.573 -------------------------
2023-03-25 20:50:32,905 : [INFO]  ------------------------- Batch 52, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:32,908 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:32,910 : [INFO]  ------------------------- Batch 52 training: round 3 -------------------------
2023-03-25 20:50:34,038 : [INFO]  ------------------------- Batch round 3, loss: 0.5763 -------------------------
2023-03-25 20:50:34,039 : [INFO]  ------------------------- Batch 52, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:34,042 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:34,043 : [INFO]  ------------------------- Batch 52 training: round 4 -------------------------
2023-03-25 20:50:35,141 : [INFO]  ------------------------- Batch round 4, loss: 0.5672 -------------------------
2023-03-25 20:50:35,141 : [INFO]  ------------------------- Batch 52, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:35,144 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:35,147 : [INFO]  ------------------------- Batch 52 training: round 5 -------------------------
2023-03-25 20:50:36,274 : [INFO]  ------------------------- Batch round 5, loss: 0.5709 -------------------------
2023-03-25 20:50:36,274 : [INFO]  ------------------------- Batch 52, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:36,277 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:36,279 : [INFO]  ------------------------- Batch 52 training: round 6 -------------------------
2023-03-25 20:50:37,374 : [INFO]  ------------------------- Batch round 6, loss: 0.5643 -------------------------
2023-03-25 20:50:37,374 : [INFO]  ------------------------- Batch 52, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:37,377 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:37,379 : [INFO]  Batch number 52 model fetched from the server
2023-03-25 20:50:37,379 : [INFO]  ################ Batch 52: final global model evalution after 6 rounds ################
2023-03-25 20:50:38,677 : [INFO]  Batch 52: Training set : loss - 0.5684, accuracy - 0.7337, recall - 0.8478, AUC - 0.8352, F1 - 0.761, precision - 0.6903, training time - -8.0 seconds
2023-03-25 20:50:38,677 : [INFO]  Batch 52: Testing set : loss - 0.5794, accuracy - 0.7255, recall - 0.8725, AUC - 0.8488, F1 - 0.7607, precision - 0.6742
2023-03-25 20:50:38,686 : [INFO]  Batch 53 initialized 
2023-03-25 20:50:39,115 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:39,493 : [INFO]  ------------------------- Batch 53 training: round 1 -------------------------
2023-03-25 20:50:42,282 : [INFO]  ------------------------- Batch round 1, loss: 0.5711 -------------------------
2023-03-25 20:50:42,282 : [INFO]  ------------------------- Batch 53, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:42,327 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:42,331 : [INFO]  ------------------------- Batch 53 training: round 2 -------------------------
2023-03-25 20:50:43,437 : [INFO]  ------------------------- Batch round 2, loss: 0.5789 -------------------------
2023-03-25 20:50:43,437 : [INFO]  ------------------------- Batch 53, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:43,470 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:43,472 : [INFO]  ------------------------- Batch 53 training: round 3 -------------------------
2023-03-25 20:50:44,534 : [INFO]  ------------------------- Batch round 3, loss: 0.5743 -------------------------
2023-03-25 20:50:44,534 : [INFO]  ------------------------- Batch 53, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:44,590 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:44,592 : [INFO]  ------------------------- Batch 53 training: round 4 -------------------------
2023-03-25 20:50:45,632 : [INFO]  ------------------------- Batch round 4, loss: 0.5598 -------------------------
2023-03-25 20:50:45,633 : [INFO]  ------------------------- Batch 53, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:45,658 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:45,660 : [INFO]  ------------------------- Batch 53 training: round 5 -------------------------
2023-03-25 20:50:46,756 : [INFO]  ------------------------- Batch round 5, loss: 0.5596 -------------------------
2023-03-25 20:50:46,756 : [INFO]  ------------------------- Batch 53, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:46,781 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:46,783 : [INFO]  ------------------------- Batch 53 training: round 6 -------------------------
2023-03-25 20:50:47,861 : [INFO]  ------------------------- Batch round 6, loss: 0.5607 -------------------------
2023-03-25 20:50:47,861 : [INFO]  ------------------------- Batch 53, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:47,891 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:47,893 : [INFO]  Batch number 53 model fetched from the server
2023-03-25 20:50:47,893 : [INFO]  ################ Batch 53: final global model evalution after 6 rounds ################
2023-03-25 20:50:49,169 : [INFO]  Batch 53: Training set : loss - 0.5579, accuracy - 0.7446, recall - 0.9348, AUC - 0.8693, F1 - 0.7854, precision - 0.6772, training time - -8.0 seconds
2023-03-25 20:50:49,169 : [INFO]  Batch 53: Testing set : loss - 0.5622, accuracy - 0.7451, recall - 0.8824, AUC - 0.8675, F1 - 0.7759, precision - 0.6923
2023-03-25 20:50:49,181 : [INFO]  Batch 54 initialized 
2023-03-25 20:50:49,604 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:50:49,963 : [INFO]  ------------------------- Batch 54 training: round 1 -------------------------
2023-03-25 20:50:52,734 : [INFO]  ------------------------- Batch round 1, loss: 0.5292 -------------------------
2023-03-25 20:50:52,734 : [INFO]  ------------------------- Batch 54, round 1: Sent local model to the server -------------------------
2023-03-25 20:50:52,877 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:52,879 : [INFO]  ------------------------- Batch 54 training: round 2 -------------------------
2023-03-25 20:50:53,918 : [INFO]  ------------------------- Batch round 2, loss: 0.5295 -------------------------
2023-03-25 20:50:53,918 : [INFO]  ------------------------- Batch 54, round 2: Sent local model to the server -------------------------
2023-03-25 20:50:53,975 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:53,976 : [INFO]  ------------------------- Batch 54 training: round 3 -------------------------
2023-03-25 20:50:55,023 : [INFO]  ------------------------- Batch round 3, loss: 0.5294 -------------------------
2023-03-25 20:50:55,023 : [INFO]  ------------------------- Batch 54, round 3: Sent local model to the server -------------------------
2023-03-25 20:50:55,066 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:55,068 : [INFO]  ------------------------- Batch 54 training: round 4 -------------------------
2023-03-25 20:50:56,136 : [INFO]  ------------------------- Batch round 4, loss: 0.5303 -------------------------
2023-03-25 20:50:56,136 : [INFO]  ------------------------- Batch 54, round 4: Sent local model to the server -------------------------
2023-03-25 20:50:56,178 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:56,180 : [INFO]  ------------------------- Batch 54 training: round 5 -------------------------
2023-03-25 20:50:57,252 : [INFO]  ------------------------- Batch round 5, loss: 0.5255 -------------------------
2023-03-25 20:50:57,252 : [INFO]  ------------------------- Batch 54, round 5: Sent local model to the server -------------------------
2023-03-25 20:50:57,316 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:57,318 : [INFO]  ------------------------- Batch 54 training: round 6 -------------------------
2023-03-25 20:50:58,342 : [INFO]  ------------------------- Batch round 6, loss: 0.5136 -------------------------
2023-03-25 20:50:58,343 : [INFO]  ------------------------- Batch 54, round 6: Sent local model to the server -------------------------
2023-03-25 20:50:58,404 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:50:58,406 : [INFO]  Batch number 54 model fetched from the server
2023-03-25 20:50:58,406 : [INFO]  ################ Batch 54: final global model evalution after 6 rounds ################
2023-03-25 20:50:59,668 : [INFO]  Batch 54: Training set : loss - 0.516, accuracy - 0.8098, recall - 0.9674, AUC - 0.9429, F1 - 0.8357, precision - 0.7355, training time - -8.0 seconds
2023-03-25 20:50:59,668 : [INFO]  Batch 54: Testing set : loss - 0.5399, accuracy - 0.7941, recall - 0.9608, AUC - 0.9489, F1 - 0.8235, precision - 0.7206
2023-03-25 20:50:59,681 : [INFO]  Batch 55 initialized 
2023-03-25 20:51:00,105 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:00,476 : [INFO]  ------------------------- Batch 55 training: round 1 -------------------------
2023-03-25 20:51:03,342 : [INFO]  ------------------------- Batch round 1, loss: 0.607 -------------------------
2023-03-25 20:51:03,342 : [INFO]  ------------------------- Batch 55, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:03,448 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:03,450 : [INFO]  ------------------------- Batch 55 training: round 2 -------------------------
2023-03-25 20:51:04,502 : [INFO]  ------------------------- Batch round 2, loss: 0.6045 -------------------------
2023-03-25 20:51:04,502 : [INFO]  ------------------------- Batch 55, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:04,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:04,557 : [INFO]  ------------------------- Batch 55 training: round 3 -------------------------
2023-03-25 20:51:05,610 : [INFO]  ------------------------- Batch round 3, loss: 0.599 -------------------------
2023-03-25 20:51:05,610 : [INFO]  ------------------------- Batch 55, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:05,650 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:05,652 : [INFO]  ------------------------- Batch 55 training: round 4 -------------------------
2023-03-25 20:51:06,726 : [INFO]  ------------------------- Batch round 4, loss: 0.5781 -------------------------
2023-03-25 20:51:06,726 : [INFO]  ------------------------- Batch 55, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:06,752 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:06,754 : [INFO]  ------------------------- Batch 55 training: round 5 -------------------------
2023-03-25 20:51:07,805 : [INFO]  ------------------------- Batch round 5, loss: 0.5911 -------------------------
2023-03-25 20:51:07,806 : [INFO]  ------------------------- Batch 55, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:07,854 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:07,856 : [INFO]  ------------------------- Batch 55 training: round 6 -------------------------
2023-03-25 20:51:08,899 : [INFO]  ------------------------- Batch round 6, loss: 0.577 -------------------------
2023-03-25 20:51:08,900 : [INFO]  ------------------------- Batch 55, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:08,974 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:08,976 : [INFO]  Batch number 55 model fetched from the server
2023-03-25 20:51:08,976 : [INFO]  ################ Batch 55: final global model evalution after 6 rounds ################
2023-03-25 20:51:10,306 : [INFO]  Batch 55: Training set : loss - 0.5864, accuracy - 0.6957, recall - 0.8587, AUC - 0.8345, F1 - 0.7383, precision - 0.6475, training time - -9.0 seconds
2023-03-25 20:51:10,307 : [INFO]  Batch 55: Testing set : loss - 0.5586, accuracy - 0.7157, recall - 0.8922, AUC - 0.8815, F1 - 0.7583, precision - 0.6594
2023-03-25 20:51:10,317 : [INFO]  Batch 56 initialized 
2023-03-25 20:51:10,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:11,131 : [INFO]  ------------------------- Batch 56 training: round 1 -------------------------
2023-03-25 20:51:13,929 : [INFO]  ------------------------- Batch round 1, loss: 0.5796 -------------------------
2023-03-25 20:51:13,929 : [INFO]  ------------------------- Batch 56, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:13,932 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:13,934 : [INFO]  ------------------------- Batch 56 training: round 2 -------------------------
2023-03-25 20:51:15,009 : [INFO]  ------------------------- Batch round 2, loss: 0.5686 -------------------------
2023-03-25 20:51:15,010 : [INFO]  ------------------------- Batch 56, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:15,013 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:15,014 : [INFO]  ------------------------- Batch 56 training: round 3 -------------------------
2023-03-25 20:51:16,139 : [INFO]  ------------------------- Batch round 3, loss: 0.5722 -------------------------
2023-03-25 20:51:16,139 : [INFO]  ------------------------- Batch 56, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:16,142 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:16,144 : [INFO]  ------------------------- Batch 56 training: round 4 -------------------------
2023-03-25 20:51:17,206 : [INFO]  ------------------------- Batch round 4, loss: 0.5765 -------------------------
2023-03-25 20:51:17,206 : [INFO]  ------------------------- Batch 56, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:17,209 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:17,211 : [INFO]  ------------------------- Batch 56 training: round 5 -------------------------
2023-03-25 20:51:18,280 : [INFO]  ------------------------- Batch round 5, loss: 0.5695 -------------------------
2023-03-25 20:51:18,281 : [INFO]  ------------------------- Batch 56, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:18,284 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:18,285 : [INFO]  ------------------------- Batch 56 training: round 6 -------------------------
2023-03-25 20:51:19,376 : [INFO]  ------------------------- Batch round 6, loss: 0.5578 -------------------------
2023-03-25 20:51:19,376 : [INFO]  ------------------------- Batch 56, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:19,379 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:19,381 : [INFO]  Batch number 56 model fetched from the server
2023-03-25 20:51:19,381 : [INFO]  ################ Batch 56: final global model evalution after 6 rounds ################
2023-03-25 20:51:20,686 : [INFO]  Batch 56: Training set : loss - 0.5569, accuracy - 0.7446, recall - 0.8696, AUC - 0.8595, F1 - 0.7729, precision - 0.6957, training time - -8.0 seconds
2023-03-25 20:51:20,687 : [INFO]  Batch 56: Testing set : loss - 0.5766, accuracy - 0.7304, recall - 0.8431, AUC - 0.8367, F1 - 0.7577, precision - 0.688
2023-03-25 20:51:20,694 : [INFO]  Batch 57 initialized 
2023-03-25 20:51:21,113 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:21,499 : [INFO]  ------------------------- Batch 57 training: round 1 -------------------------
2023-03-25 20:51:24,346 : [INFO]  ------------------------- Batch round 1, loss: 0.5971 -------------------------
2023-03-25 20:51:24,347 : [INFO]  ------------------------- Batch 57, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:24,350 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:24,351 : [INFO]  ------------------------- Batch 57 training: round 2 -------------------------
2023-03-25 20:51:25,496 : [INFO]  ------------------------- Batch round 2, loss: 0.5875 -------------------------
2023-03-25 20:51:25,496 : [INFO]  ------------------------- Batch 57, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:25,499 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:25,501 : [INFO]  ------------------------- Batch 57 training: round 3 -------------------------
2023-03-25 20:51:26,613 : [INFO]  ------------------------- Batch round 3, loss: 0.5828 -------------------------
2023-03-25 20:51:26,613 : [INFO]  ------------------------- Batch 57, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:26,616 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:26,618 : [INFO]  ------------------------- Batch 57 training: round 4 -------------------------
2023-03-25 20:51:27,741 : [INFO]  ------------------------- Batch round 4, loss: 0.5772 -------------------------
2023-03-25 20:51:27,742 : [INFO]  ------------------------- Batch 57, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:27,745 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:27,746 : [INFO]  ------------------------- Batch 57 training: round 5 -------------------------
2023-03-25 20:51:28,859 : [INFO]  ------------------------- Batch round 5, loss: 0.5756 -------------------------
2023-03-25 20:51:28,859 : [INFO]  ------------------------- Batch 57, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:28,862 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:28,865 : [INFO]  ------------------------- Batch 57 training: round 6 -------------------------
2023-03-25 20:51:30,042 : [INFO]  ------------------------- Batch round 6, loss: 0.5667 -------------------------
2023-03-25 20:51:30,042 : [INFO]  ------------------------- Batch 57, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:30,045 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:30,047 : [INFO]  Batch number 57 model fetched from the server
2023-03-25 20:51:30,047 : [INFO]  ################ Batch 57: final global model evalution after 6 rounds ################
2023-03-25 20:51:31,413 : [INFO]  Batch 57: Training set : loss - 0.5633, accuracy - 0.7337, recall - 0.8804, AUC - 0.8712, F1 - 0.7678, precision - 0.6807, training time - -9.0 seconds
2023-03-25 20:51:31,413 : [INFO]  Batch 57: Testing set : loss - 0.5834, accuracy - 0.701, recall - 0.8529, AUC - 0.8377, F1 - 0.7404, precision - 0.6541
2023-03-25 20:51:31,419 : [INFO]  Batch 58 initialized 
2023-03-25 20:51:31,843 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:32,224 : [INFO]  ------------------------- Batch 58 training: round 1 -------------------------
2023-03-25 20:51:35,087 : [INFO]  ------------------------- Batch round 1, loss: 0.5846 -------------------------
2023-03-25 20:51:35,087 : [INFO]  ------------------------- Batch 58, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:35,090 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:35,092 : [INFO]  ------------------------- Batch 58 training: round 2 -------------------------
2023-03-25 20:51:36,175 : [INFO]  ------------------------- Batch round 2, loss: 0.5792 -------------------------
2023-03-25 20:51:36,175 : [INFO]  ------------------------- Batch 58, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:36,179 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:36,180 : [INFO]  ------------------------- Batch 58 training: round 3 -------------------------
2023-03-25 20:51:37,285 : [INFO]  ------------------------- Batch round 3, loss: 0.5673 -------------------------
2023-03-25 20:51:37,285 : [INFO]  ------------------------- Batch 58, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:37,288 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:37,290 : [INFO]  ------------------------- Batch 58 training: round 4 -------------------------
2023-03-25 20:51:38,377 : [INFO]  ------------------------- Batch round 4, loss: 0.565 -------------------------
2023-03-25 20:51:38,377 : [INFO]  ------------------------- Batch 58, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:38,380 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:38,382 : [INFO]  ------------------------- Batch 58 training: round 5 -------------------------
2023-03-25 20:51:39,468 : [INFO]  ------------------------- Batch round 5, loss: 0.563 -------------------------
2023-03-25 20:51:39,468 : [INFO]  ------------------------- Batch 58, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:39,471 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:39,473 : [INFO]  ------------------------- Batch 58 training: round 6 -------------------------
2023-03-25 20:51:40,575 : [INFO]  ------------------------- Batch round 6, loss: 0.5676 -------------------------
2023-03-25 20:51:40,575 : [INFO]  ------------------------- Batch 58, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:40,832 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:40,839 : [INFO]  Batch number 58 model fetched from the server
2023-03-25 20:51:40,839 : [INFO]  ################ Batch 58: final global model evalution after 6 rounds ################
2023-03-25 20:51:42,041 : [INFO]  Batch 58: Training set : loss - 0.5579, accuracy - 0.7228, recall - 0.9022, AUC - 0.8746, F1 - 0.765, precision - 0.664, training time - -9.0 seconds
2023-03-25 20:51:42,041 : [INFO]  Batch 58: Testing set : loss - 0.5783, accuracy - 0.7108, recall - 0.8922, AUC - 0.8476, F1 - 0.7552, precision - 0.6547
2023-03-25 20:51:42,047 : [INFO]  Batch 59 initialized 
2023-03-25 20:51:42,478 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:42,876 : [INFO]  ------------------------- Batch 59 training: round 1 -------------------------
2023-03-25 20:51:45,647 : [INFO]  ------------------------- Batch round 1, loss: 0.5465 -------------------------
2023-03-25 20:51:45,647 : [INFO]  ------------------------- Batch 59, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:45,650 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:45,652 : [INFO]  ------------------------- Batch 59 training: round 2 -------------------------
2023-03-25 20:51:46,734 : [INFO]  ------------------------- Batch round 2, loss: 0.5416 -------------------------
2023-03-25 20:51:46,734 : [INFO]  ------------------------- Batch 59, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:46,770 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:46,772 : [INFO]  ------------------------- Batch 59 training: round 3 -------------------------
2023-03-25 20:51:47,812 : [INFO]  ------------------------- Batch round 3, loss: 0.5366 -------------------------
2023-03-25 20:51:47,812 : [INFO]  ------------------------- Batch 59, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:47,829 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:47,831 : [INFO]  ------------------------- Batch 59 training: round 4 -------------------------
2023-03-25 20:51:48,907 : [INFO]  ------------------------- Batch round 4, loss: 0.5284 -------------------------
2023-03-25 20:51:48,907 : [INFO]  ------------------------- Batch 59, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:48,913 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:48,915 : [INFO]  ------------------------- Batch 59 training: round 5 -------------------------
2023-03-25 20:51:49,986 : [INFO]  ------------------------- Batch round 5, loss: 0.5264 -------------------------
2023-03-25 20:51:49,986 : [INFO]  ------------------------- Batch 59, round 5: Sent local model to the server -------------------------
2023-03-25 20:51:49,989 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:49,991 : [INFO]  ------------------------- Batch 59 training: round 6 -------------------------
2023-03-25 20:51:51,052 : [INFO]  ------------------------- Batch round 6, loss: 0.5325 -------------------------
2023-03-25 20:51:51,053 : [INFO]  ------------------------- Batch 59, round 6: Sent local model to the server -------------------------
2023-03-25 20:51:51,056 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:51,058 : [INFO]  Batch number 59 model fetched from the server
2023-03-25 20:51:51,058 : [INFO]  ################ Batch 59: final global model evalution after 6 rounds ################
2023-03-25 20:51:52,355 : [INFO]  Batch 59: Training set : loss - 0.5224, accuracy - 0.7989, recall - 0.9348, AUC - 0.9117, F1 - 0.823, precision - 0.735, training time - -8.0 seconds
2023-03-25 20:51:52,356 : [INFO]  Batch 59: Testing set : loss - 0.5689, accuracy - 0.6912, recall - 0.8627, AUC - 0.8643, F1 - 0.7364, precision - 0.6423
2023-03-25 20:51:52,363 : [INFO]  Batch 60 initialized 
2023-03-25 20:51:52,779 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:51:53,175 : [INFO]  ------------------------- Batch 60 training: round 1 -------------------------
2023-03-25 20:51:55,991 : [INFO]  ------------------------- Batch round 1, loss: 0.5475 -------------------------
2023-03-25 20:51:55,991 : [INFO]  ------------------------- Batch 60, round 1: Sent local model to the server -------------------------
2023-03-25 20:51:55,994 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:55,995 : [INFO]  ------------------------- Batch 60 training: round 2 -------------------------
2023-03-25 20:51:57,093 : [INFO]  ------------------------- Batch round 2, loss: 0.5488 -------------------------
2023-03-25 20:51:57,093 : [INFO]  ------------------------- Batch 60, round 2: Sent local model to the server -------------------------
2023-03-25 20:51:57,096 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:57,098 : [INFO]  ------------------------- Batch 60 training: round 3 -------------------------
2023-03-25 20:51:58,170 : [INFO]  ------------------------- Batch round 3, loss: 0.5338 -------------------------
2023-03-25 20:51:58,170 : [INFO]  ------------------------- Batch 60, round 3: Sent local model to the server -------------------------
2023-03-25 20:51:58,174 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:58,175 : [INFO]  ------------------------- Batch 60 training: round 4 -------------------------
2023-03-25 20:51:59,303 : [INFO]  ------------------------- Batch round 4, loss: 0.5356 -------------------------
2023-03-25 20:51:59,304 : [INFO]  ------------------------- Batch 60, round 4: Sent local model to the server -------------------------
2023-03-25 20:51:59,306 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:51:59,308 : [INFO]  ------------------------- Batch 60 training: round 5 -------------------------
2023-03-25 20:52:00,388 : [INFO]  ------------------------- Batch round 5, loss: 0.5242 -------------------------
2023-03-25 20:52:00,388 : [INFO]  ------------------------- Batch 60, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:00,394 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:00,396 : [INFO]  ------------------------- Batch 60 training: round 6 -------------------------
2023-03-25 20:52:01,460 : [INFO]  ------------------------- Batch round 6, loss: 0.5184 -------------------------
2023-03-25 20:52:01,461 : [INFO]  ------------------------- Batch 60, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:01,480 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:01,483 : [INFO]  Batch number 60 model fetched from the server
2023-03-25 20:52:01,483 : [INFO]  ################ Batch 60: final global model evalution after 6 rounds ################
2023-03-25 20:52:02,795 : [INFO]  Batch 60: Training set : loss - 0.5207, accuracy - 0.7989, recall - 0.9239, AUC - 0.9078, F1 - 0.8213, precision - 0.7391, training time - -8.0 seconds
2023-03-25 20:52:02,795 : [INFO]  Batch 60: Testing set : loss - 0.5539, accuracy - 0.75, recall - 0.9412, AUC - 0.8805, F1 - 0.7901, precision - 0.6809
2023-03-25 20:52:02,807 : [INFO]  Batch 61 initialized 
2023-03-25 20:52:03,234 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:03,624 : [INFO]  ------------------------- Batch 61 training: round 1 -------------------------
2023-03-25 20:52:06,414 : [INFO]  ------------------------- Batch round 1, loss: 0.5215 -------------------------
2023-03-25 20:52:06,415 : [INFO]  ------------------------- Batch 61, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:06,458 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:06,460 : [INFO]  ------------------------- Batch 61 training: round 2 -------------------------
2023-03-25 20:52:07,527 : [INFO]  ------------------------- Batch round 2, loss: 0.52 -------------------------
2023-03-25 20:52:07,527 : [INFO]  ------------------------- Batch 61, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:07,589 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:07,591 : [INFO]  ------------------------- Batch 61 training: round 3 -------------------------
2023-03-25 20:52:08,673 : [INFO]  ------------------------- Batch round 3, loss: 0.5129 -------------------------
2023-03-25 20:52:08,674 : [INFO]  ------------------------- Batch 61, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:08,719 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:08,721 : [INFO]  ------------------------- Batch 61 training: round 4 -------------------------
2023-03-25 20:52:09,795 : [INFO]  ------------------------- Batch round 4, loss: 0.5118 -------------------------
2023-03-25 20:52:09,795 : [INFO]  ------------------------- Batch 61, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:09,839 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:09,841 : [INFO]  ------------------------- Batch 61 training: round 5 -------------------------
2023-03-25 20:52:10,927 : [INFO]  ------------------------- Batch round 5, loss: 0.5114 -------------------------
2023-03-25 20:52:10,928 : [INFO]  ------------------------- Batch 61, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:10,968 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:10,971 : [INFO]  ------------------------- Batch 61 training: round 6 -------------------------
2023-03-25 20:52:12,010 : [INFO]  ------------------------- Batch round 6, loss: 0.4994 -------------------------
2023-03-25 20:52:12,010 : [INFO]  ------------------------- Batch 61, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:12,064 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:12,067 : [INFO]  Batch number 61 model fetched from the server
2023-03-25 20:52:12,067 : [INFO]  ################ Batch 61: final global model evalution after 6 rounds ################
2023-03-25 20:52:13,401 : [INFO]  Batch 61: Training set : loss - 0.5039, accuracy - 0.8424, recall - 1.0, AUC - 0.9361, F1 - 0.8638, precision - 0.7603, training time - -8.0 seconds
2023-03-25 20:52:13,401 : [INFO]  Batch 61: Testing set : loss - 0.5694, accuracy - 0.6912, recall - 0.9118, AUC - 0.8708, F1 - 0.747, precision - 0.6327
2023-03-25 20:52:13,415 : [INFO]  Batch 62 initialized 
2023-03-25 20:52:13,839 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:14,242 : [INFO]  ------------------------- Batch 62 training: round 1 -------------------------
2023-03-25 20:52:17,081 : [INFO]  ------------------------- Batch round 1, loss: 0.5892 -------------------------
2023-03-25 20:52:17,081 : [INFO]  ------------------------- Batch 62, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:17,101 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:17,103 : [INFO]  ------------------------- Batch 62 training: round 2 -------------------------
2023-03-25 20:52:18,180 : [INFO]  ------------------------- Batch round 2, loss: 0.5832 -------------------------
2023-03-25 20:52:18,180 : [INFO]  ------------------------- Batch 62, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:18,207 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:18,211 : [INFO]  ------------------------- Batch 62 training: round 3 -------------------------
2023-03-25 20:52:19,307 : [INFO]  ------------------------- Batch round 3, loss: 0.5746 -------------------------
2023-03-25 20:52:19,307 : [INFO]  ------------------------- Batch 62, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:19,337 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:19,339 : [INFO]  ------------------------- Batch 62 training: round 4 -------------------------
2023-03-25 20:52:20,659 : [INFO]  ------------------------- Batch round 4, loss: 0.5749 -------------------------
2023-03-25 20:52:20,659 : [INFO]  ------------------------- Batch 62, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:20,662 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:20,664 : [INFO]  ------------------------- Batch 62 training: round 5 -------------------------
2023-03-25 20:52:21,725 : [INFO]  ------------------------- Batch round 5, loss: 0.5754 -------------------------
2023-03-25 20:52:21,725 : [INFO]  ------------------------- Batch 62, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:21,785 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:21,787 : [INFO]  ------------------------- Batch 62 training: round 6 -------------------------
2023-03-25 20:52:22,871 : [INFO]  ------------------------- Batch round 6, loss: 0.5725 -------------------------
2023-03-25 20:52:22,871 : [INFO]  ------------------------- Batch 62, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:22,909 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:22,912 : [INFO]  Batch number 62 model fetched from the server
2023-03-25 20:52:22,912 : [INFO]  ################ Batch 62: final global model evalution after 6 rounds ################
2023-03-25 20:52:24,295 : [INFO]  Batch 62: Training set : loss - 0.578, accuracy - 0.712, recall - 0.9239, AUC - 0.8451, F1 - 0.7623, precision - 0.6489, training time - -9.0 seconds
2023-03-25 20:52:24,295 : [INFO]  Batch 62: Testing set : loss - 0.5592, accuracy - 0.7206, recall - 0.9216, AUC - 0.9178, F1 - 0.7673, precision - 0.6573
2023-03-25 20:52:24,308 : [INFO]  Batch 63 initialized 
2023-03-25 20:52:24,741 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:25,121 : [INFO]  ------------------------- Batch 63 training: round 1 -------------------------
2023-03-25 20:52:27,949 : [INFO]  ------------------------- Batch round 1, loss: 0.5449 -------------------------
2023-03-25 20:52:27,949 : [INFO]  ------------------------- Batch 63, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:28,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:28,070 : [INFO]  ------------------------- Batch 63 training: round 2 -------------------------
2023-03-25 20:52:29,159 : [INFO]  ------------------------- Batch round 2, loss: 0.5409 -------------------------
2023-03-25 20:52:29,159 : [INFO]  ------------------------- Batch 63, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:29,162 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:29,164 : [INFO]  ------------------------- Batch 63 training: round 3 -------------------------
2023-03-25 20:52:30,210 : [INFO]  ------------------------- Batch round 3, loss: 0.5331 -------------------------
2023-03-25 20:52:30,210 : [INFO]  ------------------------- Batch 63, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:30,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:30,258 : [INFO]  ------------------------- Batch 63 training: round 4 -------------------------
2023-03-25 20:52:31,354 : [INFO]  ------------------------- Batch round 4, loss: 0.5432 -------------------------
2023-03-25 20:52:31,354 : [INFO]  ------------------------- Batch 63, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:31,381 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:31,383 : [INFO]  ------------------------- Batch 63 training: round 5 -------------------------
2023-03-25 20:52:32,441 : [INFO]  ------------------------- Batch round 5, loss: 0.5255 -------------------------
2023-03-25 20:52:32,441 : [INFO]  ------------------------- Batch 63, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:32,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:32,489 : [INFO]  ------------------------- Batch 63 training: round 6 -------------------------
2023-03-25 20:52:33,550 : [INFO]  ------------------------- Batch round 6, loss: 0.5308 -------------------------
2023-03-25 20:52:33,550 : [INFO]  ------------------------- Batch 63, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:33,555 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:33,557 : [INFO]  Batch number 63 model fetched from the server
2023-03-25 20:52:33,557 : [INFO]  ################ Batch 63: final global model evalution after 6 rounds ################
2023-03-25 20:52:34,846 : [INFO]  Batch 63: Training set : loss - 0.5245, accuracy - 0.7663, recall - 0.913, AUC - 0.9126, F1 - 0.7962, precision - 0.7059, training time - -8.0 seconds
2023-03-25 20:52:34,846 : [INFO]  Batch 63: Testing set : loss - 0.5348, accuracy - 0.7647, recall - 0.8922, AUC - 0.89, F1 - 0.7913, precision - 0.7109
2023-03-25 20:52:34,859 : [INFO]  Batch 64 initialized 
2023-03-25 20:52:35,288 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:35,702 : [INFO]  ------------------------- Batch 64 training: round 1 -------------------------
2023-03-25 20:52:38,516 : [INFO]  ------------------------- Batch round 1, loss: 0.5705 -------------------------
2023-03-25 20:52:38,516 : [INFO]  ------------------------- Batch 64, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:38,519 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:38,521 : [INFO]  ------------------------- Batch 64 training: round 2 -------------------------
2023-03-25 20:52:39,610 : [INFO]  ------------------------- Batch round 2, loss: 0.5633 -------------------------
2023-03-25 20:52:39,610 : [INFO]  ------------------------- Batch 64, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:39,613 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:39,615 : [INFO]  ------------------------- Batch 64 training: round 3 -------------------------
2023-03-25 20:52:40,714 : [INFO]  ------------------------- Batch round 3, loss: 0.5581 -------------------------
2023-03-25 20:52:40,714 : [INFO]  ------------------------- Batch 64, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:40,717 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:40,719 : [INFO]  ------------------------- Batch 64 training: round 4 -------------------------
2023-03-25 20:52:41,864 : [INFO]  ------------------------- Batch round 4, loss: 0.5548 -------------------------
2023-03-25 20:52:41,864 : [INFO]  ------------------------- Batch 64, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:41,867 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:41,869 : [INFO]  ------------------------- Batch 64 training: round 5 -------------------------
2023-03-25 20:52:42,952 : [INFO]  ------------------------- Batch round 5, loss: 0.5613 -------------------------
2023-03-25 20:52:42,952 : [INFO]  ------------------------- Batch 64, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:42,955 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:42,957 : [INFO]  ------------------------- Batch 64 training: round 6 -------------------------
2023-03-25 20:52:43,993 : [INFO]  ------------------------- Batch round 6, loss: 0.5509 -------------------------
2023-03-25 20:52:43,993 : [INFO]  ------------------------- Batch 64, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:44,256 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:44,258 : [INFO]  Batch number 64 model fetched from the server
2023-03-25 20:52:44,258 : [INFO]  ################ Batch 64: final global model evalution after 6 rounds ################
2023-03-25 20:52:45,522 : [INFO]  Batch 64: Training set : loss - 0.5481, accuracy - 0.7337, recall - 0.8913, AUC - 0.8927, F1 - 0.77, precision - 0.6777, training time - -9.0 seconds
2023-03-25 20:52:45,523 : [INFO]  Batch 64: Testing set : loss - 0.5572, accuracy - 0.7255, recall - 0.9216, AUC - 0.8987, F1 - 0.7705, precision - 0.662
2023-03-25 20:52:45,534 : [INFO]  Batch 65 initialized 
2023-03-25 20:52:45,970 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:46,383 : [INFO]  ------------------------- Batch 65 training: round 1 -------------------------
2023-03-25 20:52:49,128 : [INFO]  ------------------------- Batch round 1, loss: 0.5684 -------------------------
2023-03-25 20:52:49,128 : [INFO]  ------------------------- Batch 65, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:49,143 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:49,146 : [INFO]  ------------------------- Batch 65 training: round 2 -------------------------
2023-03-25 20:52:50,233 : [INFO]  ------------------------- Batch round 2, loss: 0.5717 -------------------------
2023-03-25 20:52:50,234 : [INFO]  ------------------------- Batch 65, round 2: Sent local model to the server -------------------------
2023-03-25 20:52:50,294 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:50,296 : [INFO]  ------------------------- Batch 65 training: round 3 -------------------------
2023-03-25 20:52:51,352 : [INFO]  ------------------------- Batch round 3, loss: 0.5747 -------------------------
2023-03-25 20:52:51,352 : [INFO]  ------------------------- Batch 65, round 3: Sent local model to the server -------------------------
2023-03-25 20:52:51,373 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:51,375 : [INFO]  ------------------------- Batch 65 training: round 4 -------------------------
2023-03-25 20:52:52,396 : [INFO]  ------------------------- Batch round 4, loss: 0.5611 -------------------------
2023-03-25 20:52:52,396 : [INFO]  ------------------------- Batch 65, round 4: Sent local model to the server -------------------------
2023-03-25 20:52:52,456 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:52,459 : [INFO]  ------------------------- Batch 65 training: round 5 -------------------------
2023-03-25 20:52:53,766 : [INFO]  ------------------------- Batch round 5, loss: 0.5537 -------------------------
2023-03-25 20:52:53,766 : [INFO]  ------------------------- Batch 65, round 5: Sent local model to the server -------------------------
2023-03-25 20:52:53,769 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:53,770 : [INFO]  ------------------------- Batch 65 training: round 6 -------------------------
2023-03-25 20:52:54,759 : [INFO]  ------------------------- Batch round 6, loss: 0.5562 -------------------------
2023-03-25 20:52:54,760 : [INFO]  ------------------------- Batch 65, round 6: Sent local model to the server -------------------------
2023-03-25 20:52:54,826 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:54,829 : [INFO]  Batch number 65 model fetched from the server
2023-03-25 20:52:54,829 : [INFO]  ################ Batch 65: final global model evalution after 6 rounds ################
2023-03-25 20:52:56,183 : [INFO]  Batch 65: Training set : loss - 0.5471, accuracy - 0.7717, recall - 0.913, AUC - 0.8751, F1 - 0.8, precision - 0.7119, training time - -8.0 seconds
2023-03-25 20:52:56,183 : [INFO]  Batch 65: Testing set : loss - 0.584, accuracy - 0.7206, recall - 0.8725, AUC - 0.8378, F1 - 0.7574, precision - 0.6692
2023-03-25 20:52:56,193 : [INFO]  Batch 66 initialized 
2023-03-25 20:52:56,621 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:52:57,031 : [INFO]  ------------------------- Batch 66 training: round 1 -------------------------
2023-03-25 20:52:59,861 : [INFO]  ------------------------- Batch round 1, loss: 0.5871 -------------------------
2023-03-25 20:52:59,862 : [INFO]  ------------------------- Batch 66, round 1: Sent local model to the server -------------------------
2023-03-25 20:52:59,865 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:52:59,866 : [INFO]  ------------------------- Batch 66 training: round 2 -------------------------
2023-03-25 20:53:01,064 : [INFO]  ------------------------- Batch round 2, loss: 0.5776 -------------------------
2023-03-25 20:53:01,064 : [INFO]  ------------------------- Batch 66, round 2: Sent local model to the server -------------------------
2023-03-25 20:53:01,068 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:01,071 : [INFO]  ------------------------- Batch 66 training: round 3 -------------------------
2023-03-25 20:53:02,632 : [INFO]  ------------------------- Batch round 3, loss: 0.5649 -------------------------
2023-03-25 20:53:02,632 : [INFO]  ------------------------- Batch 66, round 3: Sent local model to the server -------------------------
2023-03-25 20:53:02,637 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:02,641 : [INFO]  ------------------------- Batch 66 training: round 4 -------------------------
2023-03-25 20:53:04,154 : [INFO]  ------------------------- Batch round 4, loss: 0.5609 -------------------------
2023-03-25 20:53:04,154 : [INFO]  ------------------------- Batch 66, round 4: Sent local model to the server -------------------------
2023-03-25 20:53:04,161 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:04,165 : [INFO]  ------------------------- Batch 66 training: round 5 -------------------------
2023-03-25 20:53:05,826 : [INFO]  ------------------------- Batch round 5, loss: 0.5478 -------------------------
2023-03-25 20:53:05,826 : [INFO]  ------------------------- Batch 66, round 5: Sent local model to the server -------------------------
2023-03-25 20:53:05,830 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:05,834 : [INFO]  ------------------------- Batch 66 training: round 6 -------------------------
2023-03-25 20:53:08,480 : [INFO]  ------------------------- Batch round 6, loss: 0.5634 -------------------------
2023-03-25 20:53:08,480 : [INFO]  ------------------------- Batch 66, round 6: Sent local model to the server -------------------------
2023-03-25 20:53:08,487 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:08,489 : [INFO]  Batch number 66 model fetched from the server
2023-03-25 20:53:08,490 : [INFO]  ################ Batch 66: final global model evalution after 6 rounds ################
2023-03-25 20:53:09,926 : [INFO]  Batch 66: Training set : loss - 0.5513, accuracy - 0.75, recall - 0.9348, AUC - 0.8782, F1 - 0.789, precision - 0.6825, training time - -11.0 seconds
2023-03-25 20:53:09,926 : [INFO]  Batch 66: Testing set : loss - 0.5919, accuracy - 0.701, recall - 0.902, AUC - 0.8414, F1 - 0.751, precision - 0.6434
2023-03-25 20:53:09,967 : [INFO]  Batch 67 initialized 
2023-03-25 20:53:10,397 : [WARNING]  `lr` is deprecated, please use `learning_rate` instead, or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.
2023-03-25 20:53:10,831 : [INFO]  ------------------------- Batch 67 training: round 1 -------------------------
2023-03-25 20:53:13,904 : [INFO]  ------------------------- Batch round 1, loss: 0.5414 -------------------------
2023-03-25 20:53:13,904 : [INFO]  ------------------------- Batch 67, round 1: Sent local model to the server -------------------------
2023-03-25 20:53:13,907 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:13,909 : [INFO]  ------------------------- Batch 67 training: round 2 -------------------------
2023-03-25 20:53:15,109 : [INFO]  ------------------------- Batch round 2, loss: 0.5417 -------------------------
2023-03-25 20:53:15,110 : [INFO]  ------------------------- Batch 67, round 2: Sent local model to the server -------------------------
2023-03-25 20:53:15,112 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:15,114 : [INFO]  ------------------------- Batch 67 training: round 3 -------------------------
2023-03-25 20:53:16,540 : [INFO]  ------------------------- Batch round 3, loss: 0.5367 -------------------------
2023-03-25 20:53:16,540 : [INFO]  ------------------------- Batch 67, round 3: Sent local model to the server -------------------------
2023-03-25 20:53:16,543 : [INFO]  ------------------------- Received aggregated global model from the server -------------------------
2023-03-25 20:53:16,545 : [INFO]  ------------------------- Batch 67 training: round 4 -------------------------
